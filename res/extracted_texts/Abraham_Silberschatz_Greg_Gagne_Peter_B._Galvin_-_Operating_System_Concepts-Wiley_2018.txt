OPERATING
SYSTEM
CONCEPTS
(cid:55)(cid:40)(cid:49)(cid:55)(cid:43)(cid:3)(cid:40)(cid:39)(cid:44)(cid:55)(cid:44)(cid:50)(cid:49)OPERATING
SYSTEM
CONCEPTS
ABRAHAM SILBERSCHATZ
(cid:1)
(cid:58)(cid:66)(cid:77)(cid:70)(cid:1)(cid:54)(cid:79)(cid:74)(cid:87)(cid:70)(cid:83)(cid:84)(cid:74)(cid:85)(cid:90)
PETER BAER GALVIN
(cid:1)
(cid:36)(cid:66)(cid:78)(cid:67)(cid:83)(cid:74)(cid:69)(cid:72)(cid:70)(cid:1)(cid:36)(cid:80)(cid:78)(cid:81)(cid:86)(cid:85)(cid:70)(cid:83)(cid:1)(cid:66)(cid:79)(cid:69)(cid:1)(cid:52)(cid:85)(cid:66)(cid:83)(cid:71)(cid:74)(cid:84)(cid:73)(cid:1)(cid:52)(cid:85)(cid:80)(cid:83)(cid:66)(cid:72)(cid:70)
GREG GAGNE
(cid:1)
(cid:56)(cid:70)(cid:84)(cid:85)(cid:78)(cid:74)(cid:79)(cid:84)(cid:85)(cid:70)(cid:83)(cid:1)(cid:36)(cid:80)(cid:77)(cid:77)(cid:70)(cid:72)(cid:70)
(cid:55)(cid:40)(cid:49)(cid:55)(cid:43)(cid:3)(cid:40)(cid:39)(cid:44)(cid:55)(cid:44)(cid:50)(cid:49)Publisher Laurie Rosatone
Editorial Director Don Fowley
Development Editor Ryann Dannelly
Freelance Developmental Editor Chris Nelson/Factotum
Executive Marketing Manager Glenn Wilson
Senior Content Manage Valerie Zaborski
Senior Production Editor Ken Santor
Media Specialist Ashley Patterson
Editorial Assistant Anna Pham
Cover Designer Tom Nery
Cover art © metha189/Shutterstock
This book was set in Palatino by the author using LaTeX and printed and bound by LSC Kendallville.
The cover was printed by LSC Kendallville.
Copyright © 2018, 2013, 2012, 2008 John Wiley & Sons, Inc. All rights reserved.
No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by
any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as permitted
under Sections 107 or 108 of the 1976 United States Copyright Act, without either the prior written
permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the
Copyright Clearance Center, Inc. 222 Rosewood Drive, Danvers, MA 01923, (978)750-8400, fax
(978)750-4470. Requests to the Publisher for permission should be addressed to the Permissions
Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030 (201)748-6011, fax (201)748-
6008, E-Mail: PERMREQ@WILEY.COM.
Evaluation copies are provided to qualified academics and professionals for review purposes only, for use
in their courses during the next academic year. These copies are licensed and may not be sold or
transferred to a third party. Upon completion of the review period, please return the evaluation copy to
Wiley. Return instructions and a free-of-charge return shipping label are available at
www.wiley.com/go/evalreturn. Outside of the United States, please contact your local representative.
Library of Congress Cataloging-in-Publication Data
Names: Silberschatz, Abraham, author. | Galvin, Peter B., author. | Gagne,
Greg, author.
Title: Operating system concepts / Abraham Silberschatz, Yale University,
Peter Baer Galvin, Pluribus Networks, Greg Gagne, Westminster College.
Description: 10th edition. | Hoboken, NJ : Wiley, [2018] | Includes
bibliographical references and index. |
Identifiers: LCCN 2017043464 (print) | LCCN 2017045986 (ebook) | ISBN
9781119320913 (enhanced ePub)
Subjects: LCSH: Operating systems (Computers)
Classification: LCC QA76.76.O63 (ebook) | LCC QA76.76.O63 S55825 2018 (print)
| DDC 005.4/3--dc23
LC record available at https://lccn.loc.gov/2017043464
The inside back cover will contain printing identification and country of origin if omitted from this page. In
addition, if the ISBN on the back cover differs from the ISBN on this page, the one on the back cover is
correct.
Enhanced ePub ISBN 978-1-119-32091-3
Printed in the United States of America
10 9 8 7 6 5 4 3 2 1Tomychildren,Lemor,Sivan,andAaron
andmyNicolette
AviSilberschatz
Tomywife,Carla,
andmychildren,Gwen,Owen,andMaddie
PeterBaerGalvin
Tomywife,Pat,
andoursons,TomandJay
GregGagnePreface
Operating systems are an essential part of any computer system. Similarly, a
courseonoperatingsystemsisanessentialpartofanycomputerscienceedu-
cation.Thisfieldisundergoingrapidchange,ascomputersarenowprevalent
in virtually every arena of day-to-day life—from embedded devices in auto-
mobiles through the most sophisticated planning tools for governments and
multinationalfirms.Yetthefundamentalconceptsremainfairlyclear,anditis
onthesethatwebasethisbook.
We wrote this book as a text for an introductory course in operating sys-
tems at the junior or senior undergraduate level or at the first-year graduate
level. We hope that practitioners will also find it useful. It provides a clear
description of the concepts that underlie operating systems. As prerequisites,
we assume that the reader is familiar with basic data structures, computer
organization,andahigh-levellanguage,suchasCorJava.Thehardwaretopics
requiredforanunderstandingofoperatingsystemsarecoveredinChapter1.
Inthatchapter,wealsoincludeanoverviewofthefundamentaldatastructures
thatareprevalentinmostoperatingsystems.Forcodeexamples,weusepre-
dominantlyC,as wellas asignificant amount of Java,but thereadercan still
understandthealgorithmswithoutathoroughknowledgeoftheselanguages.
Conceptsarepresentedusingintuitivedescriptions.Importanttheoretical
resultsarecovered,butformalproofsarelargelyomitted.Thebibliographical
notes at the end ofeach chapter contain pointers to researchpapers in which
resultswerefirstpresentedandproved,aswellasreferencestorecentmaterial
forfurtherreading.Inplaceofproofs,figuresandexamplesareusedtosuggest
whyweshouldexpecttheresultinquestiontobetrue.
The fundamental concepts and algorithms covered in the book are often
based on those used in both open-source and commercial operating systems.
Our aim is to present these concepts and algorithms in a general setting that
is not tied to one particular operating system. However, we present a large
numberofexamplesthatpertaintothemostpopularandthemostinnovative
operating systems, including Linux, Microsoft Windows, Apple macOS (the
originalname,OSX,waschangedin2016tomatchthenamingschemeofother
Appleproducts),andSolaris.WealsoincludeexamplesofbothAndroidand
iOS,currentlythetwodominantmobileoperatingsystems.
The organization of the text reflects our many years of teaching courses
onoperatingsystems.Considerationwasalsogiventothefeedbackprovided
viiviii Preface
by the reviewersofthetext,along withthemany comments and suggestions
we received from readers of our previous editions and from our current and
formerstudents.ThisTenthEditionalsoreflectsmostofthecurriculumguide-
linesintheoperating-systemsareainComputerScienceCurricula2013,themost
recentcurriculumguidelinesforundergraduatedegreeprogramsincomputer
sciencepublishedbytheIEEEComputingSocietyandtheAssociationforCom-
putingMachinery(ACM).
What’s New in This Edition
For the Tenth Edition, we focused on revisions and enhancements aimed at
lowering costs to the students, better engaging them in the learning process,
andprovidingincreasedsupportforinstructors.
Accordingtothepublishingindustry’smosttrustedmarketresearchfirm,
Outsell, 2015 represented a turning point in text usage: for the first time,
studentpreferencefordigitallearningmaterialswashigherthanforprint,and
theincreaseinpreferencefordigitalhasbeenacceleratingsince.
Whileprintremainsimportantformanystudentsasapedagogicaltool,the
TenthEditionisbeingdeliveredinformsthatemphasizesupportforlearning
fromdigitalmaterials.Allformsweareprovidingdramaticallyreducethecost
tostudentscomparedtotheNinthEdition.Theseformsare:
• Stand-alonee-textnowwithsignifican enhancements.Thee-textformat
for the Tenth Edition adds exercises with solutions at the ends of main
sections,hide/revealdefinitionsforkeyterms,andanumberofanimated
figures. It also includes additional “Practice Exercises”with solutions for
each chapter, extra exercises, programming problems and projects, “Fur-
therReading”sections,acompleteglossary,andfourappendicesforlegacy
operatingsystems.
• E-text with print companion bundle. For a nominal additional cost, the
e-text also is available with an abridged print companion that includes
a loose-leaf copy of the main chapter text, end-of-chapter “Practice Exer-
cises”(solutionsavailableonline),and“FurtherReading”sections.Instruc-
torsmayalsoorderboundprintcompanionsforthebundledpackageby
contactingtheirWileyaccountrepresentative.
Althoughwehighlyencourageallinstructorsandstudentstotakeadvantage
ofthecost,content,andlearningadvantagesofthee-textedition,itispossible
for instructors to work with their Wiley Account Manager to create a custom
printedition.
To explore these options further or to discuss other options, contact your
Wiley account manager (http://www.wiley.com/go/whosmyrep) or visit the
productinformationpageforthistextonwiley.com
Book Material
Thebookconsistsof21chaptersand4appendices.Eachchapterandappendix
containsthetext,aswellasthefollowingenhancements:Preface ix
• Asetofpracticeexercises,includingsolutions
• Asetofregularexercises
• Asetofprogrammingproblems
• Asetofprogrammingprojects
• AFurtherReadingsection
• Pop-updefinitionsofimportant(blue)terms
• Aglossaryofimportantterms
• Animationsthatdescribespecifickeyconcepts
Ahardcopyofthetextisavailableinbookstoresandonline.Thatversionhas
thesametextchaptersastheelectronicversion.Itdoesnot,however,include
the appendices, the regular exercises, the solutions to the practice exercises,
theprogrammingproblems,theprogrammingprojects,andsomeoftheother
enhancementsfoundinthisePubelectronicbook.
Content of This Book
Thetextisorganizedintenmajorparts:
• Overview. Chapters 1 and 2 explain what operating systems are, what
theydo,andhowtheyaredesignedandconstructed.Thesechaptersdis-
cuss what the common features of an operating system are and what an
operating system does for the user. We include coverage of both tradi-
tionalPCandserveroperatingsystemsandoperatingsystemsformobile
devices. The presentation is motivational and explanatory in nature. We
haveavoidedadiscussionofhowthingsaredoneinternallyinthesechap-
ters. Therefore, they are suitable for individualreaders or for students in
lower-levelclasseswhowanttolearnwhatanoperatingsystemiswithout
gettingintothedetailsoftheinternalalgorithms.
• Processmanagement.Chapters3through5describetheprocessconcept
and concurrency as the heart of modern operating systems. Aprocess is
the unit of work in a system. Such a system consists of a collection of
concurrently executingprocesses,someexecuting operating-systemcode
andothersexecutingusercode.Thesechapterscovermethodsforprocess
scheduling and interprocess communication. Also included is a detailed
discussionofthreads,aswellasanexaminationofissuesrelatedtomulti-
coresystemsandparallelprogramming.
• Processsynchronization.Chapters6through8covermethodsforprocess
synchronization and deadlock handling. Because we have increased the
coverageofprocesssynchronization,wehavedividedtheformerChapter
5 (Process Synchronization) into two separate chapters: Chapter 6, Syn-
chronizationTools,andChapter7,SynchronizationExamples.
• Memory management. Chapters 9 and 10 deal with the management of
main memory during the execution of a process. To improve both thex Preface
utilization of the CPU and the speed of its response to its users, the com-
puter must keep several processes in memory. There are many different
memory-managementschemes,reflectingvariousapproachestomemory
management, and the effectiveness of a particular algorithm depends on
thesituation.
• Storagemanagement.Chapters11and12describehowmassstorageand
I/Oarehandledinamoderncomputersystem.TheI/Odevicesthatattach
to a computer vary widely, and the operating system needs to provide a
wide range of functionality to applications to allow them to control all
aspects of these devices. We discuss system I/O in depth, including I/O
system design, interfaces, and internal system structures and functions.
Inmanyways,I/Odevicesaretheslowestmajorcomponentsofthecom-
puter.Becausetheyrepresentaperformancebottleneck,wealsoexamine
performanceissuesassociatedwithI/Odevices.
• Filesystems.Chapters13through15discusshowfilesystemsarehandled
inamoderncomputersystem.Filesystemsprovidethemechanismforon-
linestorageofandaccesstobothdataandprograms.Wedescribetheclas-
sicinternalalgorithmsandstructuresofstoragemanagementandprovide
a firm practical understanding of the algorithms used—their properties,
advantages,anddisadvantages.
• Securityandprotection.Chapters16and17discussthemechanismsnec-
essaryforthesecurityandprotectionofcomputersystems.Theprocesses
in an operating system must be protected from one another’s activities.
Toprovidesuchprotection,wemustensurethatonlyprocessesthathave
gained proper authorization from the operating system can operate on
the files, memory, CPU, and other resources of the system. Protection is
a mechanism for controlling the access of programs, processes, or users
to computer-system resources. This mechanism must provide a means
of specifying the controls to be imposed, as well as a means of enforce-
ment.Securityprotectstheintegrityoftheinformationstoredinthesystem
(bothdataandcode),aswellasthephysicalresourcesofthesystem,from
unauthorized access, malicious destruction or alteration, and accidental
introductionofinconsistency.
• Advanced topics. Chapters 18 and 19 discuss virtual machines and
networks/distributed systems. Chapter 18 provides an overview of
virtual machines and their relationship to contemporary operating
systems. Included is a general description of the hardware and software
techniques that make virtualization possible. Chapter 19 provides an
overviewofcomputernetworksanddistributedsystems,withafocuson
theInternetandTCP/IP.
• Casestudies.Chapter20and21presentdetailedcasestudiesoftworeal
operatingsystems—LinuxandWindows10.
• Appendices.AppendixAdiscussesseveraloldinfluential operatingsys-
tems that are no longer in use. Appendices B through D cover in great
detaislthreeolderoperatingsystems— Windows7,BSD,andMach.Preface xi
Programming Environments
The text provides several example programs written in C and Java. These
programsareintendedtoruninthefollowingprogrammingenvironments:
• POSIX. POSIX (which stands for Portable Operating System Interface) repre-
sents a set of standards implemented primarily for UNIX-based operat-
ing systems. Although Windows systems can also run certain POSIX pro-
grams,ourcoverageofPOSIXfocusesonLinuxandUNIXsystems.POSIX-
compliant systems must implement the POSIX core standard (POSIX.1);
Linux and macOS are examples of POSIX-compliant systems. POSIX also
definesseveralextensionstothestandards,includingreal-timeextensions
(POSIX.1b) and an extension for a threads library (POSIX.1c, better known
as Pthreads). We provide several programming examples written in C
illustratingthePOSIX baseAPI,aswellasPthreadsandtheextensionsfor
real-timeprogramming.TheseexampleprogramsweretestedonLinux4.4
andmacOS10.11systemsusingthegcccompiler.
• Java. Java is a widely used programming language with a rich API and
built-inlanguagesupportforconcurrentandparallelprogramming.Java
programsrunonanyoperatingsystemsupportingaJavavirtualmachine
(orJVM).Weillustratevariousoperating-systemandnetworkingconcepts
withJavaprogramstestedusingVersion1.8oftheJavaDevelopmentKit
(JDK).
• Windowssystems.TheprimaryprogrammingenvironmentforWindows
systemsistheWindowsAPI,whichprovidesacomprehensivesetoffunc-
tions for managing processes, threads, memory, and peripheral devices.
WesupplyamodestnumberofCprogramsillustratingtheuseofthisAPI.
ProgramsweretestedonasystemrunningWindows10.
We have chosen these three programming environments because we
believe that they best represent the two most popular operating-system
models—Linux/UNIX and Windows—along with the widely used Java
environment. Most programming examples are written in C, and we expect
readers to be comfortable with this language. Readers familiar with both the
C and Java languages should easily understand most programs provided in
thistext.
Insomeinstances—such asthreadcreation—we illustrateaspecificcon-
cept using all three programming environments, allowing the reader to con-
trastthethreedifferentlibrariesastheyaddressthesametask.Inothersitua-
tions,wemayusejustoneoftheAPIstodemonstrateaconcept.Forexample,
weillustratesharedmemoryusingjustthePOSIXAPI;socketprogrammingin
TCP/IPishighlightedusingtheJavaAPI.
Linux Virtual Machine
To help students gain a better understanding of the Linux system, we pro-
vide a Linux virtual machine running the Ubuntu distribution with this text.
The virtual machine, which is available for download from the text websitexii Preface
(http://www.os-book.com),alsoprovidesdevelopmentenvironmentsinclud-
ingthegccandJavacompilers.Mostoftheprogrammingassignmentsinthe
bookcanbecompletedusingthisvirtualmachine,withtheexceptionofassign-
mentsthatrequiretheWindowsAPI.Thevirtualmachinecanbeinstalledand
run on any host operating system that can run the VirtualBox virtualization
software,whichcurrentlyincludesWindows10 Linux,andmacOS.
The Tenth Edition
AswewrotethisTenthEditionofOperatingSystemConcepts,wewereguidedby
thesustainedgrowthinfourfundamentalareasthataffectoperatingsystems:
1. Mobileoperatingsystems
2. Multicoresystems
3. Virtualization
4. Nonvolatilememorysecondarystorage
To emphasize these topics, we have integrated relevant coverage throughout
this newedition.Forexample,wehave greatlyincreasedourcoverageof the
Android and iOS mobile operating systems, as well as our coverage of the
ARMv8 architecture that dominates mobile devices. We have also increased
our coverage of multicore systems, including increased coverage of APIs that
providesupportforconcurrencyandparallelism.Nonvolatilememorydevices
likeSSDsarenowtreatedastheequalsofhard-diskdrivesinthechaptersthat
discussI/O,massstorage,andfilesystems.
Several of our readers have expressed support for an increase in Java
coverage, and we have provided additional Java examples throughout this
edition.
Additionally,wehaverewrittenmaterialinalmosteverychapterbybring-
ingoldermaterialuptodateandremovingmaterialthatisnolongerinterest-
ingorrelevant.Wehavereorderedmanychaptersandhave,insomeinstances,
moved sections from one chapter to another. We have also greatly revised
theartwork,creatingseveralnewfiguresaswellasmodifyingmany existing
figures.
MajorChanges
The Tenth Edition update encompasses much more material than previous
updates, in terms of both content and new supporting material. Next, we
provideabriefoutlineofthemajorcontentchangesineachchapter:
• Chapter1:Introductionincludesupdatedcoverageofmulticoresystems,
as well as new coverage of NUMA systems and Hadoop clusters. Old
material has been updated, and new motivation has been added for the
studyofoperatingsystems.
• Chapter2:Operating-SystemStructuresprovidesasignificantlyrevised
discussion of the design and implementation of operating systems. We
have updated our treatment of Android and iOS and have revised ourPreface xiii
coverage of the system boot process with a focus on GRUB for Linux
systems.Newcoverageof the Windows subsystem for Linux is included
aswell.Wehaveaddednewsectionsonlinkersandloaders,andwenow
discuss why applications are often operating-system specific. Finally, we
haveaddedadiscussionoftheBCCdebuggingtoolset.
• Chapter 3: Processes simplifies the discussion of scheduling so that it
now includes only CPU scheduling issues. New coverage describes the
memory layout of a C program, the Android process hierarchy, Mach
message passing, and Android RPCs. We have also replaced coverage of
thetraditionalUNIX/Linuxinitprocesswithcoverageofsystemd.
• Chapter 4: Threads and Concurrency (previously Threads)increases the
coverage of support for concurrent and parallel programming at the API
and library level. We have revised the section on Java threads so that it
now includes futures and have updated the coverage of Apple’s Grand
CentralDispatchsothatitnowincludesSwift.Newsectionsdiscussfork-
join parallelism using the fork-join framework in Java, as well as Intel
threadbuildingblocks.
• Chapter5:CPUScheduling(previouslyChapter6)revisesthecoverageof
multilevelqueueandmulticoreprocessingscheduling.Wehaveintegrated
coverage of NUMA-aware scheduling issues throughout, including how
this scheduling affects load balancing. We also discuss related modifica-
tions to the Linux CFS scheduler. New coverage combines discussions of
round-robinandpriorityscheduling,heterogeneousmultiprocessing,and
Windows10scheduling.
• Chapter 6: SynchronizationTools (previouslypart of Chapter 5, Process
Synchronization) focuses on various tools for synchronizing processes.
Significantnewcoveragediscussesarchitecturalissuessuchasinstruction
reorderinganddelayedwritestobuffers.Thechapteralsointroduceslock-
free algorithms using compare-and-swap (CAS) instructions. No specific
APIs are presented; rather, the chapter provides an introduction to race
conditionsandgeneraltoolsthatcanbeusedtopreventdataraces.Details
includenewcoverageofmemorymodels,memorybarriers,andliveness
issues.
• Chapter 7: Synchronization Examples (previously part of Chapter 5,
Process Synchronization) introduces classical synchronization problems
and discusses specific API support for designing solutions that solve
these problems. The chapter includes new coverage of POSIX named and
unnamed semaphores, as well as condition variables. A new section on
Javasynchronizationisincludedaswell.
• Chapter 8: Deadlocks (previously Chapter 7) provides minor updates,
including a new section on livelock and a discussion of deadlock as an
example of a liveness hazard. The chapter includes new coverage of the
LinuxlockdepandtheBCCdeadlock detectortools,aswellascoverage
ofJavadeadlockdetectionusingthreaddumps.
• Chapter 9: Main Memory (previously Chapter 8) includes several revi-
sions that bring the chapter up to date with respect to memory manage-xiv Preface
mentonmoderncomputersystems.Wehaveaddednewcoverageofthe
ARMv864-bitarchitecture,updatedthecoverageofdynamiclinklibraries,
andchangedswappingcoveragesothatitnowfocusesonswappingpages
ratherthanprocesses.Wehavealsoeliminatedcoverageofsegmentation.
• Chapter10:VirtualMemory(previouslyChapter9)containsseveralrevi-
sions,includingupdatedcoverageofmemoryallocationonNUMAsystems
andglobalallocationusingafree-framelist.Newcoverageincludescom-
pressedmemory, major/minor page faults, and memory management in
LinuxandWindows10.
• Chapter11:Mass-Storage Structure(previouslyChapter10)addscover-
age of nonvolatile memory devices, such as flash and solid-state disks.
Hard-drive scheduling is simplified to show only currently used algo-
rithms.Alsoincludedareanewsectiononcloudstorage,updatedRAID
coverage,andanewdiscussionofobjectstorage.
• Chapter 12, I/O (previously Chapter 13) updates the coverage of
technologies and performance numbers, expands the coverage of
synchronous/asynchronous and blocking/nonblocking I/O, and adds a
section on vectored I/O. It also expands coverage of power management
formobileoperatingsystems.
• Chapter 13: File-System Interface (previously Chapter 11) has been
updated with information about current technologies. In particular, the
coverage of directory structures has been improved, and the coverage of
protectionhasbeenupdated.Thememory-mappedfilessectionhasbeen
expanded,andaWindowsAPIexamplehasbeenaddedtothediscussion
ofsharedmemory.TheorderingoftopicsisrefactoredinChapter13and
14.
• Chapter 14: File-System Implementation (previously Chapter 12) has
been updated with coverage of current technologies. The chapter now
includes discussions of TRIM and the Apple File System. In addition, the
discussionofperformancehasbeenupdated,andthecoverageofjournal-
inghasbeenexpanded.
• Chapter15:FileSystemInternalsisnewandcontains updatedinforma-
tionfrompreviousChapters11and12.
• Chapter 16: Security (previously Chapter 15) now precedes the protec-
tion chapter. It includes revised and updated terms for current security
threatsandsolutions,includingransomwareandremoteaccesstools.The
principleofleastprivilegeisemphasized.Coverageofcode-injectionvul-
nerabilitiesandattackshasbeenrevisedandnowincludescodesamples.
Discussion of encryption technologies has been updated to focus on the
technologies currently used. Coverage of authentication (by passwords
and other methods) has been updated and expanded with helpful hints.
Additionsincludeadiscussionofaddress-spacelayoutrandomizationand
a new summary of security defenses. The Windows 7 example has been
updatedtoWindows10.
• Chapter 17: Protection (previously Chapter 14) contains major changes.
The discussionof protectionrings and layershas beenupdatedand nowPreface xv
referstothe Bell–LaPadulamodeland exploresthe ARMmodelof Trust-
ZonesandSecureMonitorCalls.Coverageoftheneed-to-knowprinciple
hasbeenexpanded,ashascoverageofmandatoryaccesscontrol.Subsec-
tionsonLinuxcapabilities,Darwinentitlements,securityintegrityprotec-
tion,system-callfiltering,sandboxing,andcodesigninghavebeenadded.
Coverage of run-time-based enforcement in Java has also been added,
includingthestackinspectiontechnique.
• Chapter 18: Virtual Machines (previously Chapter 16) includes added
details about hardware assistance technologies. Also expanded is the
topicofapplicationcontainment,nowincludingcontainers,zones,docker,
andKubernetes.Anewsectiondiscussesongoingvirtualizationresearch,
includingunikernels,libraryoperatingsystems,partitioninghypervisors,
andseparationhypervisors.
• Chapter19,NetworksandDistributedSystems(previouslyChapter17)
hasbeensubstantiallyupdatedandnowcombinescoverageofcomputer
networksanddistributedsystems.Thematerialhasbeenrevisedtobring
it up to date with respect to contemporary computer networks and dis-
tributed systems. The TCP/IPmodel receivesadded emphasis, and a dis-
cussionofcloudstoragehasbeenadded.Thesectiononnetworktopolo-
gies has beenremoved.Coverageof name resolutionhas been expanded
andaJavaexampleadded.Thechapteralsoincludesnewcoverageofdis-
tributedfilesystems,includingMapReduceontopofGooglefilesystem,
Hadoop,GPFS,andLustre.
• Chapter20:TheLinuxSystem(previouslyChapter18)hasbeenupdated
tocovertheLinux4.ikernel.
• Chapter 21: The Windows 10 System is a new chapter that covers the
internalsofWindows10.
• AppendixA:Influentia OperatingSystemshasbeenupdatedtoinclude
materialfromchaptersthatarenolongercoveredinthetext.
Supporting Website
When you visitthe website supporting this text at http://www.os-book.com,
youcandownloadthefollowingresources:
• Linuxvirtualmachine
• CandJavasourcecode
• Thecompletesetoffiguresandillustrations
• FreeBSD,Mach,andWindows7casestudies
• Errata
• Bibliography
Notes to Instructors
Onthewebsiteforthistext,weprovideseveralsamplesyllabithatsuggestvar-
iousapproachesforusingthetextinbothintroductoryandadvancedcourses.xvi Preface
As a general rule, we encourage instructors to progress sequentially through
the chapters, as this strategy provides the most thorough study of operat-
ing systems. However, by using the sample syllabi, an instructor can select a
differentorderingofchapters(orsubsectionsofchapters).
In this edition, we have added many new written exercises and pro-
grammingproblemsandprojects.Mostofthenewprogrammingassignments
involve processes, threads, process scheduling, process synchronization, and
memorymanagement.SomeinvolveaddingkernelmodulestotheLinuxsys-
tem,which requiresusing eitherthe Linux virtualmachine that accompanies
thistextoranothersuitableLinuxdistribution.
Solutions to written exercises and programming assignments are avail-
able to instructors who have adopted this text for their operating-system
class.Toobtaintheserestrictedsupplements,contactyourlocalJohnWiley&
Sonssalesrepresentative.YoucanfindyourWileyrepresentativebygoingto
http://www.wiley.com/collegeandclicking“Who’smyrep?”
Notes to Students
Weencourageyoutotakeadvantageofthepracticeexercisesthatappearatthe
endofeachchapter.Wealsoencourage youtoreadthroughthestudyguide,
whichwaspreparedbyoneofourstudents.Finally,forstudentswhoareunfa-
miliarwithUNIXandLinuxsystems,werecommendthatyoudownloadand
install the Linux virtual machine that we include on the supporting website.
Notonlywillthisprovideyouwithanewcomputingexperience,buttheopen-
sourcenatureofLinuxwillallowyoutoeasilyexaminetheinnerdetailsofthis
popularoperatingsystem.Wewishyoutheverybestofluckinyourstudyof
operatingsystems!
Contacting Us
Wehaveendeavoredtoeliminatetypos,bugs,andthelikefromthetext.But,
asinnewreleasesofsoftware,bugsalmostsurelyremain.Anup-to-dateerrata
list is accessible from the book’s website. We would be grateful if you would
notifyusofanyerrorsoromissionsinthebookthatarenotonthecurrentlist
oferrata.
We would be glad to receive suggestions on improvements to the book.
We also welcome any contributions to the book website that could be of use
to other readers, such as programming exercises, project suggestions, on-line
labsandtutorials,andteachingtips.E-mailshouldbeaddressedtoos-book-
authors@cs.yale.edu.
Acknowledgments
Many people have helped us with this Tenth Edition, as well as with the
previousnineeditionsfromwhichitisderived.Preface xvii
TenthEdition
• RickFarrowprovidedexpertadviceasatechnicaleditor.
• Jonathan Levin helped out with coverage of mobile systems, protection,
andsecurity.
• AlexIonescuupdatedthepreviousWindows7chaptertoprovideChapter
21:Windows10.
• SarahDiesburgrevisedChapter19:NetworksandDistributedSystems.
• BrendanGreggprovidedguidanceontheBCCtoolset.
• RichardStallman(RMS)suppliedfeedbackonthedescriptionoffreeand
open-sourcesoftware.
• RobertLoveprovidedupdatestoChapter20:TheLinuxSystem.
• MichaelShapirohelpedwithstorageandI/Otechnologydetails.
• RichardWestprovidedinsightonareasofvirtualizationresearch.
• ClayBreshearshelpedwithcoverageofIntelthread-buildingblocks.
• GerryHowsergavefeedbackonmotivatingthestudyofoperatingsystems
andalsotriedoutnewmaterialinhisclass.
• JudiPaigehelpedwithgeneratingfiguresandpresentationofslides.
• JayGagneandAudraRissmeyerpreparednewartworkforthisedition.
• OwenGalvinprovidedtechnicaleditingforChapter11andChapter12.
• MarkWogahnhasmadesurethatthesoftwaretoproducethisbook(LATEX
andfonts)worksproperly.
• Ranjan Kumar Meher rewrotesome of the LATEX software used inthe pro-
ductionofthisnewtext.
PreviousEditions
• First threeeditions. This book is derivedfrom the previous editions,the
firstthreeofwhichwerecoauthoredbyJamesPeterson.
• General contributions. Others who helped us with previous editions
includeHamidArabnia,RidaBazzi,RandyBentson,DavidBlack,Joseph
Boykin, Jeff Brumfield, Gael Buckley, Roy Campbell, P. C. Capon, John
Carpenter,GilCarrick,ThomasCasavant,BartChilds,AjoyKumarDatta,
Joe Deck, Sudarshan K. Dhall, Thomas Doeppner, Caleb Drake, M. Rasit
Eskiciog˘lu, Hans Flack, Robert Fowler, G. Scott Graham, Richard Guy,
MaxHailperin,RebeccaHartman,WayneHathaway,ChristopherHaynes,
DonHeller,BruceHillyer,MarkHolliday,DeanHougen,MichaelHuang,
Ahmed Kamel, Morty Kewstel, Richard Kieburtz, Carol Kroll, Morty
Kwestel,ThomasLeBlanc,JohnLeggett,JerroldLeichter,TedLeung,Gary
Lippman, Carolyn Miller, Michael Molloy, Euripides Montagne, Yoichi
Muraoka, Jim M. Ng, Banu O¨zden, Ed Posnak, Boris Putanec, Charlesxviii Preface
Qualline, John Quarterman, Mike Reiter, Gustavo Rodriguez-Rivera,
Carolyn J. C. Schauble, Thomas P. Skinner, Yannis Smaragdakis, Jesse
St. Laurent, John Stankovic, Adam Stauffer, Steven Stepanek, John
Sterling, Hal Stern, Louis Stevens, Pete Thomas, David Umbaugh, Steve
Vinoski, Tommy Wagner, Larry L. Wear, John Werth, James M. Westall, J.
S.Weston,andYangXiang
• Specifi Contributions
◦
RobertLoveupdatedbothChapter20andtheLinuxcoveragethrough-
out the text, as well as answering many of our Android-related ques-
tions.
◦
AppendixBwaswrittenbyDaveProbertandwasderivedfromChap-
ter22oftheEighthEditionofOperatingSystemConcepts.
◦
JonathanKatzcontributedtoChapter16.RichardWestprovidedinput
intoChapter18.SalahuddinKhanupdatedSection16.7toprovidenew
coverageofWindows7security.
◦
PartsofChapter19werederivedfromapaperbyLevyandSilberschatz
[1990].
◦
Chapter 20 was derived from an unpublished manuscript by Stephen
Tweedie.
◦
CliffMartinhelpedwithupdatingtheUNIXappendixtocoverFreeBSD.
◦
Some of the exercises and accompanying solutions were supplied by
ArvindKrishnamurthy.
◦
AndrewDeNicolapreparedthestudentstudyguidethatisavailableon
ourwebsite.SomeoftheslideswerepreparedbyMarilynTurnamian.
◦
MikeShapiro,BryanCantrill,andJimMauroansweredseveralSolaris-
related questions, and Bryan Cantrill from Sun Microsystems helped
withtheZFScoverage.JoshDeesandRobReynoldscontributedcover-
ageofMicrosoft’sNET.
◦
OwenGalvinhelpedcopy-editChapter18edition.
BookProduction
TheExecutiveEditorwasDonFowley.TheSeniorProductionEditorwasKen
Santor.TheFreelanceDevelopmentalEditorwasChrisNelson.TheAssistant
DevelopmentalEditorwasRyannDannelly.ThecoverdesignerwasTomNery.
The copyeditor was Beverly Peavler. The freelance proofreader was Katrina
Avery. The freelance indexer was WordCo, Inc. The Aptara LaTex team con-
sistedofNeerajSaxenaandLavkush.
PersonalNotes
Avi would like to acknowledge Valerie for her love, patience, and support
duringtherevisionofthisbook.Preface xix
Peter would like to thank his wife Carla and his children, Gwen, Owen,
andMaddie.
Greg would like to acknowledge the continued support of his family: his
wifePatandsonsThomasandJay.
AbrahamSilberschatz,NewHaven,CT
PeterBaerGalvin,Boston,MA
GregGagne,SaltLakeCity,UTContents
PART ONE OVERVIEW
Chapter1 Introduction
1.1 WhatOperatingSystemsDo 4 1.8 DistributedSystems 35
1.2 Computer-SystemOrganization 7 1.9 KernelDataStructures 36
1.3 Computer-SystemArchitecture 15 1.10 ComputingEnvironments 40
1.4 Operating-SystemOperations 21 1.11 FreeandOpen-SourceOperating
1.5 ResourceManagement 27 Systems 46
1.6 SecurityandProtection 33 PracticeExercises 53
1.7 Virtualization 34 FurtherReading 54
Chapter2 Operating-SystemStructures
2.1 Operating-SystemServices 55 2.7 Operating-SystemDesignand
2.2 UserandOperating-System Implementation 79
Interface 58 2.8 Operating-SystemStructure 81
2.3 SystemCalls 62 2.9 BuildingandBootinganOperating
2.4 SystemServices 74 System 92
2.5 LinkersandLoaders 75 2.10 Operating-SystemDebugging 95
2.6 WhyApplicationsAre 2.11 Summary 100
Operating-SystemSpecific 77 PracticeExercises 101
FurtherReading 101
PART TWO PROCESS MANAGEMENT
Chapter3 Processes
3.1 ProcessConcept 106 3.7 ExamplesofIPCSystems 132
3.2 ProcessScheduling 110 3.8 CommunicationinClient–
3.3 OperationsonProcesses 116 ServerSystems 145
3.4 InterprocessCommunication 123 3.9 Summary 153
3.5 IPCinShared-MemorySystems 125 PracticeExercises 154
3.6 IPCinMessage-PassingSystems 127 FurtherReading 156
(cid:89)(cid:89)(cid:74)Contents
(cid:89)(cid:89)(cid:74)(cid:74)
Chapter4 Threads&Concurrency
4.1 Overview 160 4.6 ThreadingIssues 188
4.2 MulticoreProgramming 162 4.7 Operating-SystemExamples 194
4.3 MultithreadingModels 166 4.8 Summary 196
4.4 ThreadLibraries 168 PracticeExercises 197
4.5 ImplicitThreading 176 FurtherReading 198
Chapter5 CPUScheduling
5.1 BasicConcepts 200 5.7 Operating-SystemExamples 234
5.2 SchedulingCriteria 204 5.8 AlgorithmEvaluation 244
5.3 SchedulingAlgorithms 205 5.9 Summary 250
5.4 ThreadScheduling 217 PracticeExercises 251
5.5 Multi-ProcessorScheduling 220 FurtherReading 254
5.6 Real-TimeCPUScheduling 227
PART THREE PROCESS SYNCHRONIZATION
Chapter6 SynchronizationTools
6.1 Background 257 6.7 Monitors 276
6.2 TheCritical-SectionProblem 260 6.8 Liveness 283
6.3 Peterson’sSolution 262 6.9 Evaluation 284
6.4 HardwareSupportfor 6.10 Summary 286
Synchronization 265 PracticeExercises 287
6.5 MutexLocks 270 FurtherReading 288
6.6 Semaphores 272
Chapter7 SynchronizationExamples
7.1 ClassicProblemsof 7.5 AlternativeApproaches 311
Synchronization 289 7.6 Summary 314
7.2 SynchronizationwithintheKernel 295 PracticeExercises 314
7.3 POSIXSynchronization 299 FurtherReading 315
7.4 SynchronizationinJava 303
Chapter8 Deadlocks
8.1 SystemModel 318 8.6 DeadlockAvoidance 330
8.2 DeadlockinMultithreaded 8.7 DeadlockDetection 337
Applications 319 8.8 RecoveryfromDeadlock 341
8.3 DeadlockCharacterization 321 8.9 Summary 343
8.4 MethodsforHandlingDeadlocks 326 PracticeExercises 344
8.5 DeadlockPrevention 327 FurtherReading 346Contents
(cid:89)(cid:89)(cid:74)(cid:74)(cid:74)
PART FOUR MEMORY MANAGEMENT
Chapter9 Main Memory
9.1 Background 349 9.6 Example:Intel32-and64-bit
9.2 ContiguousMemoryAllocation 356 Architectures 379
9.3 Paging 360 9.7 Example:ARMv8Architecture 383
9.4 StructureofthePageTable 371 9.8 Summary 384
9.5 Swapping 376 PracticeExercises 385
FurtherReading 387
Chapter10 VirtualMemory
10.1 Background 389 10.8 AllocatingKernelMemory 426
10.2 DemandPaging 392 10.9 OtherConsiderations 430
10.3 Copy-on-Write 399 10.10 Operating-SystemExamples 436
10.4 PageReplacement 401 10.11 Summary 440
10.5 AllocationofFrames 413 PracticeExercises 441
10.6 Thrashing 419 FurtherReading 444
10.7 MemoryCompression 425
PART FIVE STORAGE MANAGEMENT
Chapter11 Mass-StorageStructure
11.1 OverviewofMass-Storage 11.6 Swap-SpaceManagement 467
Structure 449 11.7 StorageAttachment 469
11.2 HDDScheduling 457 11.8 RAIDStructure 473
11.3 NVMScheduling 461 11.9 Summary 485
11.4 ErrorDetectionandCorrection 462 PracticeExercises 486
11.5 StorageDeviceManagement 463 FurtherReading 487
Chapter12 I/OSystems
12.1 Overview 489 12.6 STREAMS 519
12.2 I/OHardware 490 12.7 Performance 521
12.3 ApplicationI/OInterface 500 12.8 Summary 524
12.4 KernelI/OSubsystem 508 PracticeExercises 525
12.5 TransformingI/ORequeststo FurtherReading 526
HardwareOperations 516Contents
(cid:89)(cid:89)(cid:74)(cid:87)
PART SIX FILE SYSTEM
Chapter13 File-SystemInterface
13.1 FileConcept 529 13.5 Memory-MappedFiles 555
13.2 AccessMethods 539 13.6 Summary 560
13.3 DirectoryStructure 541 PracticeExercises 560
13.4 Protection 550 FurtherReading 561
Chapter14 File-SystemImplementation
14.1 File-SystemStructure 564 14.7 Recovery 586
14.2 File-SystemOperations 566 14.8 Example:TheWAFLFileSystem 589
14.3 DirectoryImplementation 568 14.9 Summary 593
14.4 AllocationMethods 570 PracticeExercises 594
14.5 Free-SpaceManagement 578 FurtherReading 594
14.6 EfficiencyandPerformance 582
Chapter15 File-SystemInternals
15.1 FileSystems 597 15.7 ConsistencySemantics 608
15.2 File-SystemMounting 598 15.8 NFS 610
15.3 PartitionsandMounting 601 15.9 Summary 615
15.4 FileSharing 602 PracticeExercises 616
15.5 VirtualFileSystems 603 FurtherReading 617
15.6 RemoteFileSystems 605
PART SEVEN SECURITY AND PROTECTION
Chapter16 Security
16.1 TheSecurityProblem 621 16.6 ImplementingSecurityDefenses 653
16.2 ProgramThreats 625 16.7 AnExample:Windows10 662
16.3 SystemandNetworkThreats 634 16.8 Summary 664
16.4 CryptographyasaSecurityTool 637 FurtherReading 665
16.5 UserAuthentication 648
Chapter17 Protection
17.1 GoalsofProtection 667 17.9 MandatoryAccessControl
17.2 PrinciplesofProtection 668 (MAC) 684
17.3 ProtectionRings 669 17.10 Capability-BasedSystems 685
17.4 DomainofProtection 671 17.11 OtherProtectionImprovement
17.5 AccessMatrix 675 Methods 687
17.6 ImplementationoftheAccess 17.12 Language-BasedProtection 690
Matrix 679 17.13 Summary 696
17.7 RevocationofAccessRights 682 FurtherReading 697
17.8 Role-BasedAccessControl 683Contents
(cid:89)(cid:89)(cid:87)
PART EIGHT ADVANCED TOPICS
Chapter18 VirtualMachines
18.1 Overview 701 18.6 VirtualizationandOperating-System
18.2 History 703 Components 719
18.3 BenefitsandFeatures 704 18.7 Examples 726
18.4 BuildingBlocks 707 18.8 VirtualizationResearch 728
18.5 TypesofVMsandTheir 18.9 Summary 729
Implementations 713 FurtherReading 730
Chapter19 NetworksandDistributed Systems
19.1 AdvantagesofDistributed 19.6 DistributedFileSystems 757
Systems 733 19.7 DFSNamingandTransparency 761
19.2 NetworkStructure 735 19.8 RemoteFileAccess 764
19.3 CommunicationStructure 738 19.9 FinalThoughtsonDistributedFile
19.4 NetworkandDistributedOperating Systems 767
Systems 749 19.10 Summary 768
19.5 DesignIssuesinDistributed PracticeExercises 769
Systems 753 FurtherReading 770
PART NINE CASE STUDIES
Chapter20 TheLinuxSystem
20.1 LinuxHistory 775 20.8 InputandOutput 810
20.2 DesignPrinciples 780 20.9 InterprocessCommunication 812
20.3 KernelModules 783 20.10 NetworkStructure 813
20.4 ProcessManagement 786 20.11 Security 816
20.5 Scheduling 790 20.12 Summary 818
20.6 MemoryManagement 795 PracticeExercises 819
20.7 FileSystems 803 FurtherReading 819
Chapter21 Windows10
21.1 History 821 21.5 FileSystem 875
21.2 DesignPrinciples 826 21.6 Networking 880
21.3 SystemComponents 838 21.7 ProgrammerInterface 884
21.4 TerminalServicesandFastUser 21.8 Summary 895
Switching 874 PracticeExercises 896
FurtherReading 897Contents
(cid:89)(cid:89)(cid:87)(cid:74)
PART TEN APPENDICES
ChapterA Influentia OperatingSystems
A.1 FeatureMigration 1 A.10 TOPS-20 15
A.2 EarlySystems 2 A.11 CP/MandMS/DOS 15
A.3 Atlas 9 A.12 MacintoshOperatingSystemand
A.4 XDS-940 10 Windows 16
A.5 THE 11 A.13 Mach 16
A.6 RC4000 11 A.14 Capability-basedSystems—Hydraand
A.7 CTSS 12 CAP 18
A.8 MULTICS 13 A.15 OtherSystems 20
A.9 IBMOS/360 13 FurtherReading 21
ChapterB Windows7
B.1 History 1 B.6 Networking 41
B.2 DesignPrinciples 3 B.7 ProgrammerInterface 46
B.3 SystemComponents 10 B.8 Summary 55
B.4 TerminalServicesandFastUser PracticeExercises 55
Switching 34 FurtherReading 56
B.5 FileSystem 35
ChapterC BSDUNIX
C.1 UNIXHistory 1 C.7 FileSystem 25
C.2 DesignPrinciples 6 C.8 I/OSystem 33
C.3 ProgrammerInterface 8 C.9 InterprocessCommunication 36
C.4 UserInterface 15 C.10 Summary 41
C.5 ProcessManagement 18 FurtherReading 42
C.6 MemoryManagement 22
ChapterD TheMach System
D.1 HistoryoftheMachSystem 1 D.6 MemoryManagement 18
D.2 DesignPrinciples 3 D.7 ProgrammerInterface 23
D.3 SystemComponents 4 D.8 Summary 24
D.4 ProcessManagement 7 FurtherReading 25
D.5 InterprocessCommunication 13
Credits(cid:1) 963 (cid:1)
Index(cid:1) (cid:1)(cid:1)(cid:1)965Part One
Overview
Anoperatingsystemactsasanintermediarybetweentheuserofacom-
puterandthecomputerhardware.Thepurposeofanoperatingsystem
is to provide an environment in which a user can execute programs in a
convenient andefficient manner.
An operating system is software that manages the computer hard-
ware.Thehardwaremustprovideappropriatemechanismstoensurethe
correctoperationofthecomputersystemandtopreventprogramsfrom
interferingwiththeproperoperationofthesystem.
Internally, operating systems vary greatly in their makeup, since they
are organized along many differentlines.The design of a new operating
systemisamajortask,anditisimportantthatthegoalsofthesystembe
welldefinedbeforethedesignbegins.
Because an operating system is large and complex, it must be cre-
ated piece by piece. Each of these pieces should be a well-delineated
portion of the system, with carefully defined inputs, outputs, and func-
tions.1
CHAPTER
Introduction
An operating system is software that manages a computer’s hardware. It
also provides a basis for application programs and acts as an intermediary
between the computer user and the computer hardware. An amazing aspect
ofoperatingsystemsishowtheyvaryinaccomplishingthesetasksinawide
varietyofcomputingenvironments.Operatingsystemsareeverywhere,from
cars and home appliances that include “Internet of Things” devices, to smart
phones,personalcomputers,enterprisecomputers,andcloudcomputingenvi-
ronments.
Inordertoexploretheroleofanoperatingsysteminamoderncomputing
environment,itisimportantfirsttounderstandtheorganizationandarchitec-
tureof computer hardware.This includes the CPU, memory,and I/Odevices,
as well as storage. Afundamental responsibility of an operating system is to
allocatetheseresourcestoprograms.
Because an operating system is large and complex, it must be created
piecebypiece.Eachofthesepiecesshouldbeawell-delineatedportionofthe
system,withcarefullydefinedinputs,outputs,andfunctions. Inthischapter,
we provide a general overview of the major components of a contemporary
computer system as well as the functions provided by the operating system.
Additionally,wecoverseveraltopicstohelpsetthestagefortheremainderof
thetext:datastructuresusedinoperatingsystems,computingenvironments,
andopen-sourceandfreeoperatingsystems.
CHAPTER OBJECTIVES
• Describe the general organization of a computer system and the role of
interrupts.
(cid:129) Describethecomponentsinamodernmultiprocessorcomputersystem.
(cid:129) Illustratethetransitionfromusermodetokernelmode.
(cid:129) Discuss how operating systems are used in various computing environ-
ments.
(cid:129) Provideexamplesoffreeandopen-sourceoperatingsystems.
34 Chapter1 Introduction
1.1 What Operating Systems Do
We begin our discussion by looking at the operating system’s role in the
overallcomputersystem.Acomputersystemcanbedividedroughlyintofour
components: the hardware, the operating system, the application programs,
andauser(Figure1.1).
The hardware—the central processing unit (CPU), the memory, and the
input/output (I/O) devices—provides the basic computing resources for the
system. The application programs—such as word processors, spreadsheets,
compilers, and web browsers—define the ways in which these resources are
used to solve users’ computing problems. The operating system controls the
hardwareandcoordinatesitsuseamongthevariousapplicationprogramsfor
thevarioususers.
Wecanalsoviewacomputersystemasconsistingofhardware,software,
and data. The operating system provides the means for proper use of these
resources in the operation of the computer system. An operating system is
similar to a government. Like a government, it performs no useful function
byitself.Itsimplyprovidesanenvironmentwithinwhichotherprogramscan
dousefulwork.
To understand more fully the operating system’s role, we next explore
operatingsystemsfromtwoviewpoints:thatoftheuserandthatofthesystem.
1.1.1 User View
Theuser’sviewofthecomputervariesaccordingtotheinterfacebeingused.
Many computer users sit with a laptop or in front of a PC consisting of a
monitor, keyboard, and mouse. Such a system is designed for one user to
monopolizeitsresources.The goalistomaximizethe work(or play)that the
user is performing. In this case, the operating system is designed mostly for
ease of use, with some attention paid to performance and security and none
paid to resource utilization—how various hardware and software resources
areshared.
user
application programs
(compilers, web browsers, development kits, etc.)
operating system
computer hardware
(CPU, memory, I/O devices, etc.)
Figure1.1 Abstractviewofthecomponentsofacomputersystem.1.1 WhatOperatingSystemsDo 5
Increasingly,manyusersinteractwithmobiledevicessuchassmartphones
andtablets—devicesthatarereplacingdesktopandlaptopcomputersystems
for some users. These devices are typically connected to networks through
cellularorotherwirelesstechnologies.Theuserinterfaceformobilecomputers
generallyfeaturesatouchscreen,wheretheuserinteractswiththesystemby
pressing and swiping fingers across the screen rather than using a physical
keyboardandmouse.Manymobiledevicesalsoallowuserstointeractthrough
avoicerecognitioninterface,suchasApple’sSiri.
Somecomputershavelittleornouserview.Forexample,embeddedcom-
putersinhomedevicesandautomobilesmayhavenumerickeypadsandmay
turnindicatorlightsonorofftoshowstatus,buttheyandtheiroperatingsys-
temsandapplicationsaredesignedprimarilytorunwithoutuserintervention.
1.1.2 System View
Fromthecomputer’spointofview,theoperatingsystemistheprogrammost
intimatelyinvolvedwith the hardware. Inthis context, we can viewan oper-
ating system as a resource allocator. Acomputer system has many resources
that may be required to solve a problem: CPU time, memory space, storage
space,I/Odevices,andsoon.Theoperatingsystemactsasthemanagerofthese
resources.Facingnumerousandpossiblyconflictingrequestsforresources,the
operatingsystemmust decidehow toallocate themtospecific programsand
userssothatitcanoperatethecomputersystemefficientlyandfairly.
Aslightly different view of an operating system emphasizes the need to
control the various I/O devices and user programs. An operating system is a
controlprogram.Acontrolprogrammanagestheexecutionofuserprograms
topreventerrorsandimproperuseofthecomputer.Itisespeciallyconcerned
withtheoperationandcontrolofI/Odevices.
1.1.3 Defining Operating Systems
By now, you can probably see that the term operating system covers many
roles and functions. That is the case, at least in part, because of the myriad
designs and uses of computers. Computers are present within toasters, cars,
ships,spacecraft,homes,andbusinesses.Theyarethebasisforgamemachines,
cableTVtuners,andindustrialcontrolsystems.
Toexplainthisdiversity,wecanturntothehistoryofcomputers.Although
computershavearelativelyshorthistory,theyhaveevolvedrapidly.Comput-
ing started as an experiment to determine what could be done and quickly
movedtofixed-purposesystemsformilitaryuses,suchascodebreakingand
trajectory plotting,and governmental uses, such as census calculation. Those
earlycomputersevolvedintogeneral-purpose,multifunctionmainframes,and
that’swhenoperatingsystemswereborn.Inthe1960s,Moore’sLawpredicted
thatthenumberoftransistorsonanintegratedcircuitwoulddoubleevery18
months,andthatpredictionhasheldtrue.Computersgainedinfunctionality
and shrank in size, leading to a vast number of uses and a vast number and
varietyofoperatingsystems.(SeeAppendixAformoredetailsonthehistory
ofoperatingsystems.)
How,then,canwedefinewhatanoperatingsystemis?Ingeneral,wehave
nocompletelyadequatedefinitionofanoperatingsystem.Operatingsystems6 Chapter1 Introduction
exist because they offer a reasonable way to solve the problem of creating
a usable computing system. The fundamental goal of computer systems is
to execute programs and to make solving user problems easier. Computer
hardware is constructed toward this goal. Since bare hardware alone is not
particularlyeasytouse,applicationprogramsaredeveloped.Theseprograms
requirecertaincommonoperations,suchasthosecontrollingtheI/Odevices.
Thecommonfunctionsofcontrollingandallocatingresourcesarethenbrought
togetherintoonepieceofsoftware:theoperatingsystem.
Inaddition,wehavenouniversallyaccepteddefinitionofwhat ispartof
theoperatingsystem.Asimpleviewpointisthatitincludeseverythingaven-
dorshipswhenyouorder“theoperatingsystem.”Thefeaturesincluded,how-
ever,varygreatlyacrosssystems.Somesystemstakeuplessthanamegabyte
of space and lack even a full-screen editor, whereas others require gigabytes
ofspaceandarebasedentirelyongraphicalwindowingsystems.Amorecom-
mondefinition,andtheonethatweusuallyfollow,isthattheoperatingsystem
is the one program running at all times on the computer—usually called the
kernel.Alongwiththekernel,therearetwoothertypesofprograms:system
programs, which are associated with the operating system but are not neces-
sarilypartofthekernel,andapplicationprograms,whichincludeallprograms
notassociatedwiththeoperationofthesystem.
The matter of what constitutes an operating system became increasingly
importantaspersonalcomputersbecamemorewidespreadandoperatingsys-
temsgrewincreasinglysophisticated.In1998,theUnitedStatesDepartmentof
JusticefiledsuitagainstMicrosoft,inessenceclaimingthatMicrosoftincluded
toomuchfunctionalityinitsoperatingsystemsandthuspreventedapplication
vendorsfromcompeting.(Forexample,awebbrowserwasanintegralpartof
Microsoft’soperatingsystems.)Asaresult,Microsoftwasfoundguiltyofusing
itsoperating-systemmonopolytolimitcompetition.
Today, however, if we look at operating systems for mobile devices, we
see that once again the number of features constituting the operating system
is increasing. Mobile operating systems often include not only a core kernel
but also middleware—a set of software frameworks that provide additional
servicestoapplicationdevelopers.For example,eachof thetwo mostpromi-
nentmobileoperatingsystems—Apple’siOSandGoogle’sAndroid—features
WHYSTUDYOPERATINGSYSTEMS?
Althoughtherearemanypractitionersofcomputerscience,onlyasmallper-
centageofthemwillbeinvolvedinthecreationormodificationofanoperat-
ingsystem.Why,then,studyoperatingsystemsandhowtheywork?Simply
because, as almost all code runson top of an operatingsystem, knowledge
of how operating systems work is crucial to proper, efficient, effective, and
secureprogramming.Understandingthefundamentalsofoperatingsystems,
howtheydrivecomputerhardware,andwhattheyprovidetoapplicationsis
notonlyessentialtothosewhoprogramthembutalsohighlyusefultothose
whowriteprogramsonthemandusethem.1.2 Computer-SystemOrganization 7
acorekernelalongwithmiddlewarethatsupportsdatabases,multimedia,and
graphics(tonameonlyafew).
Insummary,for ourpurposes,theoperatingsystemincludesthealways-
running kernel, middleware frameworks that ease application development
and provide features, and system programs that aid in managing the system
while it is running. Most of this text is concerned with the kernel of general-
purposeoperatingsystems,butothercomponentsarediscussedasneededto
fullyexplainoperatingsystemdesignandoperation.
1.2 Computer-System Organization
Amoderngeneral-purposecomputersystemconsistsofoneormoreCPUsand
anumberofdevicecontrollersconnectedthroughacommonbusthatprovides
access between components and shared memory (Figure 1.2). Each device
controller is in charge of a specific type of device (for example, a disk drive,
audiodevice,orgraphicsdisplay).Dependingonthecontroller,morethanone
device may be attached. For instance, one system USB port can connect to a
USB hub, towhich severaldevicescan connect. Adevicecontroller maintains
some local buffer storage and a set of special-purpose registers. The device
controller is responsible for moving the data between the peripheral devices
thatitcontrolsanditslocalbufferstorage.
Typically, operating systems have a device driver for each device con-
troller.Thisdevicedriverunderstandsthedevicecontrollerand providesthe
restoftheoperatingsystemwithauniforminterfacetothedevice.TheCPUand
thedevicecontrollerscanexecuteinparallel,competingformemorycycles.To
ensureorderlyaccesstothesharedmemory,amemorycontrollersynchronizes
accesstothememory.
Inthefollowingsubsections,wedescribesomebasicsofhowsuchasystem
operates,focusingonthreekeyaspectsofthesystem.Westartwithinterrupts,
which alert the CPU to events that require attention. We then discuss storage
structureandI/Ostructure.
mouse keyboard printer monitor
disks
on-line
disk graphics
CPU USB controller
controller adapter
system bus
memory
Figure1.2 AtypicalPCcomputersystem.8 Chapter1 Introduction
1.2.1 Interrupts
Consideratypicalcomputeroperation:aprogramperformingI/O.Tostartan
I/O operation, the device driver loads the appropriate registers in the device
controller. The device controller, in turn, examines the contents of these reg-
isters to determine what action to take (such as “read a character from the
keyboard”).Thecontrollerstartsthetransferofdatafromthedevicetoitslocal
buffer.Oncethetransferofdataiscomplete,thedevicecontrollerinformsthe
device driver that it has finished its operation. The device driver then gives
controltootherpartsoftheoperatingsystem,possiblyreturningthedataora
pointertothedataiftheoperationwasaread.Forotheroperations,thedevice
driver returns status information such as “write completed successfully” or
“devicebusy”.Buthowdoesthecontrollerinformthedevicedriverthatithas
finisheditsoperation?Thisisaccomplishedviaaninterrupt.
1.2.1.1 Overview
Hardware may trigger an interrupt at any time by sending a signal to the
CPU, usually by way of the system bus. (There may be many buses within
a computer system, but the system bus is the main communications path
betweenthemajorcomponents.)Interruptsareusedformanyotherpurposes
aswellandareakeypartofhowoperatingsystemsandhardwareinteract.
When the CPU is interrupted, it stops what it is doing and immediately
transfers execution to a fixed location. The fixed location usually contains
the starting address where the service routine for the interrupt is located.
The interrupt service routine executes; on completion, the CPU resumes the
interrupted computation. Atimeline of this operation is shown in Figure 1.3.
Toruntheanimationassicatedwiththisfigurepleaseclickhere.
Interruptsareanimportantpartofacomputerarchitecture.Eachcomputer
design has its own interrupt mechanism, but several functions are common.
Theinterruptmusttransfercontroltotheappropriateinterruptserviceroutine.
The straightforward method for managing this transfer would be to invoke
a generic routine to examine the interrupt information. The routine, in turn,
Figure1.3 Interrupttimelineforasingleprogramdoingoutput.1.2 Computer-SystemOrganization 9
wouldcalltheinterrupt-specifichandler.However,interruptsmustbehandled
quickly,astheyoccurveryfrequently.Atableofpointerstointerruptroutines
can be used instead to provide the necessary speed. The interrupt routine
is called indirectly through the table, with no intermediate routine needed.
Generally,thetableofpointersisstoredinlowmemory(thefirsthundredorso
locations).Theselocationsholdtheaddressesoftheinterruptserviceroutines
for the various devices. This array, or interrupt vector, of addresses is then
indexedbyauniquenumber,givenwiththeinterruptrequest,toprovidethe
addressoftheinterruptserviceroutinefortheinterruptingdevice.Operating
systemsasdifferentasWindowsandUNIXdispatchinterruptsinthismanner.
Theinterruptarchitecturemustalsosavethestateinformationofwhatever
was interrupted, so that it can restore this information after servicing the
interrupt. If the interrupt routine needs to modify the processor state—for
instance,bymodifyingregistervalues—itmustexplicitlysavethecurrentstate
andthenrestorethatstatebeforereturning.Aftertheinterruptisserviced,the
savedreturnaddressisloadedintotheprogramcounter,andtheinterrupted
computationresumesasthoughtheinterrupthadnotoccurred.
1.2.1.2 Implementation
The basic interrupt mechanism works as follows. The CPU hardware has a
wirecalledtheinterrupt-requestlinethattheCPUsensesafterexecutingevery
instruction. When the CPU detects that a controller has asserted a signal on
the interrupt-request line, it reads the interrupt number and jumps to the
interrupt-handler routine by using that interrupt number as an index into
the interrupt vector. It then starts execution at the address associated with
that index. The interrupt handler saves any state it will be changing during
its operation, determines the cause of the interrupt, performs the necessary
processing,performsastaterestore,and executesareturn from interrupt
instruction to return the CPU to the execution state prior to the interrupt. We
say that the device controller raises an interrupt by asserting a signal on the
interrupt request line, the CPU catches the interrupt and dispatches it to the
interrupthandler,andthehandlerclearstheinterruptbyservicingthedevice.
Figure1.4summarizestheinterrupt-drivenI/Ocycle.
ThebasicinterruptmechanismjustdescribedenablestheCPUtorespondto
anasynchronousevent,aswhenadevicecontrollerbecomesreadyforservice.
Inamodernoperatingsystem,however,weneedmoresophisticatedinterrupt-
handlingfeatures.
1. Weneedtheabilitytodeferinterrupthandlingduringcriticalprocessing.
2. Weneedanefficientwaytodispatchtotheproperinterrupthandlerfor
adevice.
3. We need multilevel interrupts, so that the operating system can distin-
guish between high- and low-priority interrupts and can respond with
theappropriatedegreeofurgency.
In modern computer hardware, these three features are provided by the CPU
andtheinterrupt-controllerhardware.10 Chapter1 Introduction
CPU I/O controller
1
device driver initiates I/O
2
initiates I/O
CPU executing checks for
interrupts between instructions
3
CPU receiving interrupt, 4 input ready, output
transfers control to complete, or error
interrupt handler generates interrupt signal
7
5
interrupt handler
processes data,
returns from interrupt
6
CPU resumes
processing of
interrupted task
Figure1.4 Interrupt-drivenI/Ocycle.
Most CPUs have two interrupt request lines. One is the nonmaskable
interrupt,whichisreservedforeventssuchasunrecoverablememoryerrors.
The second interruptline is maskable: it can be turned off by the CPU before
theexecutionofcriticalinstructionsequencesthatmustnotbeinterrupted.The
maskableinterruptisusedbydevicecontrollerstorequestservice.
Recallthatthepurposeofavectoredinterruptmechanismistoreducethe
needforasingleinterrupthandlertosearchallpossiblesourcesofinterrupts
to determine which one needs service. In practice, however, computers have
moredevices(and,hence,interrupthandlers)thantheyhaveaddresselements
intheinterruptvector.Acommonwaytosolvethisproblemistouseinterrupt
chaining, in which each element in the interrupt vector points to the head of
a list of interrupt handlers. When an interrupt is raised, the handlers on the
corresponding list are called one by one, until one is found that can service
the request. This structure is a compromise between the overhead of a huge
interrupttableandtheinefficiencyofdispatchingtoasingleinterrupthandler.
Figure1.5illustratesthedesignoftheinterruptvectorforIntelprocessors.
The events from 0 to 31, which are nonmaskable, are used to signal various
errorconditions.Theeventsfrom32to255,whicharemaskable,areusedfor
purposessuchasdevice-generatedinterrupts.
The interrupt mechanism also implements a system of interrupt priority
levels.TheselevelsenabletheCPUtodeferthehandlingoflow-priorityinter-1.2 Computer-SystemOrganization 11
vector number description
0 divide error
1 debug exception
2 null interrupt
3 breakpoint
4 INTO-detected overflow
5 bound range exception
6 invalid opcode
7 device not available
8 double fault
9 coprocessor segment overrun (reserved)
10 invalid task state segment
11 segment not present
12 stack fault
13 general protection
14 page fault
15 (Intel reserved, do not use)
16 floating-point error
17 alignment check
18 machine check
19–31 (Intel reserved, do not use)
32–255 maskable interrupts
Figure1.5 Intelprocessorevent-vectortable.
ruptswithoutmaskingallinterruptsandmakesitpossibleforahigh-priority
interrupttopreempttheexecutionofalow-priorityinterrupt.
Insummary,interruptsareusedthroughoutmodernoperatingsystemsto
handleasynchronousevents(andforotherpurposeswewilldiscussthrough-
outthetext).Devicecontrollersandhardwarefaultsraiseinterrupts.Toenable
the most urgent work to be done first, modern computers use a system of
interrupt priorities. Because interrupts are used so heavily for time-sensitive
processing, efficient interrupt handling is required for good system perfor-
mance.
1.2.2 Storage Structure
The CPU can load instructions only from memory, so any programs must
first be loaded into memory to run. General-purpose computers run most
of their programs from rewritable memory, called main memory (also called
random-accessmemory,orRAM).Mainmemorycommonlyisimplementedin
asemiconductortechnologycalleddynamicrandom-accessmemory(DRAM).
Computersuseotherformsofmemoryaswell.Forexample,thefirstpro-
gramtorunoncomputerpower-onisabootstrapprogram,whichthenloads
the operating system. Since RAM is volatile—loses its content when power
is turned off or otherwise lost—we cannot trust it to hold the bootstrap pro-
gram. Instead, for this and some other purposes, the computer uses electri-
callyerasableprogrammableread-onlymemory(EEPROM)andotherformsof
firmwar —storagethatisinfrequentlywrittentoandisnonvolatile.EEPROM12 Chapter1 Introduction
STORAGEDEFINITIONSANDNOTATION
The basic unit of computer storage is the bit. Abit can contain one of two
values,0and1.Allotherstorageinacomputerisbasedoncollectionsofbits.
Givenenoughbits,itisamazinghowmanythingsacomputercanrepresent:
numbers,letters,images,movies,sounds,documents,andprograms,toname
a few. Abyte is 8 bits, and on mostcomputersit is the smallest convenient
chunkofstorage.Forexample,mostcomputersdon’thaveaninstructionto
move a bit but do have one to move a byte. Aless common term is word,
whichisagivencomputerarchitecture’snativeunitofdata.Awordismade
upofoneormorebytes.Forexample,acomputerthathas64-bitregistersand
64-bit memory addressing typically has 64-bit (8-byte) words. Acomputer
executesmanyoperationsinitsnativewordsizeratherthanabyteatatime.
Computer storage, along with most computer throughput, is generally
measuredandmanipulatedinbytesandcollectionsofbytes.Akilobyte,or
KB, is 1,024 bytes; a megabyte, or MB, is 1,0242 bytes; a gigabyte, or GB, is
1,0243bytes;aterabyte,orTB,is1,0244bytes;andapetabyte,orPB,is1,0245
bytes.Computermanufacturersoftenroundoffthesenumbersandsaythat
a megabyte is 1 million bytes and a gigabyte is 1billion bytes. Networking
measurements are an exception to this general rule; they are given in bits
(becausenetworksmovedataabitatatime).
canbechangedbutcannotbechangedfrequently.Inaddition,itislowspeed,
andsoitcontainsmostlystaticprogramsanddatathataren’tfrequentlyused.
For example, the iPhone uses EEPROM to store serial numbers and hardware
informationaboutthedevice.
All forms of memory provide an array of bytes. Each byte has its own
address.Interactionisachievedthroughasequenceofloadorstoreinstruc-
tionstospecificmemoryaddresses.Theloadinstructionmovesabyteorword
frommainmemorytoaninternalregisterwithintheCPU,whereasthestore
instructionmovesthecontentofaregistertomainmemory.Asidefromexplicit
loadsandstores,theCPUautomaticallyloadsinstructionsfrommainmemory
forexecutionfromthelocationstoredintheprogramcounter.
Atypicalinstruction–executioncycle,asexecutedonasystemwithavon
Neumann architecture, first fetches an instruction from memory and stores
that instruction in the instruction register. The instruction is then decoded
and may cause operands to be fetched from memory and stored in some
internalregister.Aftertheinstructionontheoperandshasbeenexecuted,the
result may be stored back in memory. Notice that the memory unit sees only
a stream of memory addresses.It does not know how they are generated(by
the instructioncounter, indexing,indirection,literaladdresses,or someother
means)orwhattheyarefor(instructionsordata).Accordingly,wecanignore
how a memory address is generated by a program. We are interestedonly in
thesequenceofmemoryaddressesgeneratedbytherunningprogram.
Ideally, we want the programs and data to reside in main memory per-
manently. This arrangement usually is not possible on most systems for two
reasons:1.2 Computer-SystemOrganization 13
1. Mainmemoryisusuallytoosmalltostoreallneededprogramsanddata
permanently.
2. Mainmemory,asmentioned,isvolatile—itlosesitscontentswhenpower
isturnedofforotherwiselost.
Thus, most computer systems provide secondary storage as an extension of
mainmemory.Themainrequirementforsecondarystorageisthatitbeableto
holdlargequantitiesofdatapermanently.
Themostcommonsecondary-storagedevicesarehard-diskdrives(HDDs)
and nonvolatile memory (NVM) devices, which provide storage for both
programs and data. Most programs (system and application) are stored in
secondarystorageuntiltheyareloadedintomemory.Manyprogramsthenuse
secondarystorage as both the source and the destination of their processing.
Secondarystorageisalsomuchslowerthanmainmemory.Hence,theproper
managementofsecondarystorageisofcentralimportancetoacomputersys-
tem,aswediscussinChapter11.
In a larger sense, however, the storage structure that we have described
—consisting of registers, main memory, and secondary storage—is only one
ofmanypossiblestoragesystemdesigns.Otherpossiblecomponentsinclude
cache memory, CD-ROM or blu-ray, magnetic tapes, and so on. Those that are
slow enough and large enough that they are used only for special purposes
—to store backup copies of material stored on other devices, for example—
are called tertiary storage. Each storage system provides the basic functions
ofstoringadatumandholdingthatdatumuntilitisretrievedatalatertime.
Themaindifferencesamongthevariousstoragesystemslieinspeed,size,and
volatility.
Thewidevarietyofstoragesystemscanbeorganizedinahierarchy(Figure
1.6)accordingtostoragecapacityandaccesstime.Asageneralrule,thereisa
storage capacity
registers
cache
main memory
nonvolatile memory
hard-disk drives
optical disk
magnetic tapes
rellams
regral
retsaf
rewols
access time
primary
storage
volatile
storage
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
nonvolatile
storage
secondary
storage
tertiary
storage
Figure1.6 Storage-devicehierarchy.14 Chapter1 Introduction
trade-offbetweensizeandspeed,withsmallerandfastermemoryclosertothe
CPU.Asshowninthefigure,inadditiontodifferinginspeedandcapacity,the
various storage systems are either volatile or nonvolatile. Volatile storage, as
mentionedearlier,losesitscontentswhenthepowertothedeviceisremoved,
sodatamustbewrittentononvolatilestorageforsafekeeping.
The top four levels of memory in the figure are constructed using semi-
conductormemory,whichconsistsofsemiconductor-basedelectroniccircuits.
NVMdevices,atthefourthlevel,haveseveralvariantsbutingeneralarefaster
thanharddisks.ThemostcommonformofNVMdeviceisflashmemory,which
is popular in mobile devices such as smartphones and tablets. Increasingly,
flash memory is being used for long-term storage on laptops, desktops, and
serversaswell.
Since storage plays an important role in operating-system structure, we
will refer to it frequently in the text. In general, we will use the following
terminology:
• Volatilestoragewillbereferredtosimplyasmemory.Ifweneedtoempha-
sizeaparticulartypeofstoragedevice(forexample,aregister),wewilldo
soexplicitly.
• Nonvolatile storage retains its contents when power is lost. It will be
referred to as NVS. The vast majority of the time we spend on NVS will
be on secondarystorage. This type of storage can be classified into two
distincttypes:
◦
Mechanical.AfewexamplesofsuchstoragesystemsareHDDs,optical
disks,holographicstorage,andmagnetictape.Ifweneedtoemphasize
a particular typeof mechanical storagedevice(for example,magnetic
tape),wewilldosoexplicitly.
◦
Electrical. Afew examples of such storage systems are flash memory,
FRAM,NRAM,andSSD.ElectricalstoragewillbereferredtoasNVM.If
weneedtoemphasizeaparticulartypeofelectricalstoragedevice(for
example,SSD),wewilldosoexplicitly.
Mechanical storage is generally larger and less expensive per byte than
electricalstorage.Conversely,electricalstorageistypicallycostly,smaller,
andfasterthanmechanicalstorage.
The design of a complete storage system must balance all the factors just
discussed: it must use only as much expensive memory as necessary while
providing as much inexpensive, nonvolatile storage as possible. Caches can
beinstalledtoimproveperformancewherealargedisparityinaccesstimeor
transferrateexistsbetweentwocomponents.
1.2.3 I/O Structure
Alarge portion of operating system code is dedicated to managing I/O, both
because of its importance to the reliability and performance of a system and
becauseofthevaryingnatureofthedevices.
Recallfromthebeginningofthissectionthatageneral-purposecomputer
systemconsistsofmultipledevices,allofwhichexchangedataviaacommon1.3 Computer-SystemArchitecture 15
instruction execution
cycle
instructions
thread of execution and
data movement
data
DMA
memory
I/O
request data
interrupt
cache
CPU (*N)
device
(*M)
Figure1.7 Howamoderncomputersystemworks.
bus. The form of interrupt-driven I/O described in Section 1.2.1 is fine for
movingsmallamountsofdatabutcanproducehighoverheadwhenusedfor
bulk data movement such as NVS I/O. To solve this problem, direct memory
access (DMA) is used. After setting up buffers, pointers, and counters for the
I/O device, the device controller transfers an entire block of data directly to
or from the deviceand main memory,with no interventionby the CPU. Only
oneinterruptisgeneratedperblock,totellthedevicedriverthattheoperation
hascompleted,ratherthantheoneinterruptperbytegeneratedforlow-speed
devices.Whilethedevicecontrollerisperformingtheseoperations,theCPUis
availabletoaccomplishotherwork.
Somehigh-endsystemsuseswitchratherthanbusarchitecture.Onthese
systems, multiple components can talk to other components concurrently,
rather than competing for cycles on a shared bus. In this case, DMA is even
moreeffective.Figure1.7showstheinterplayofallcomponentsofacomputer
system.
1.3 Computer-System Architecture
InSection1.2,we introduced the generalstructureofa typical computersys-
tem. A computer system can be organized in a number of different ways,
whichwecancategorizeroughlyaccordingtothenumberofgeneral-purpose
processorsused.
1.3.1 Single-Processor Systems
Many years ago, most computer systems used a single processor containing
one CPU with a single processing core. The core is the component that exe-
cutesinstructionsandregistersforstoringdatalocally.TheonemainCPUwith
its core is capable of executing a general-purpose instruction set, including
instructionsfromprocesses.Thesesystemshaveotherspecial-purposeproces-16 Chapter1 Introduction
sorsaswell.Theymaycomeintheformofdevice-specificprocessors,suchas
disk,keyboard,andgraphicscontrollers.
All of these special-purpose processors run a limited instruction set and
donotrunprocesses.Sometimes,theyaremanagedbytheoperatingsystem,
inthattheoperatingsystemsendstheminformationabouttheirnexttaskand
monitors their status. For example, a disk-controller microprocessor receives
a sequence of requests from the main CPU core and implements its own disk
queue and scheduling algorithm. This arrangement relieves the main CPU of
theoverheadofdiskscheduling.PCscontainamicroprocessorinthekeyboard
toconvertthekeystrokesintocodestobesenttotheCPU.Inothersystemsor
circumstances,special-purposeprocessorsarelow-levelcomponentsbuiltinto
the hardware. The operating system cannot communicate with these proces-
sors;theydotheirjobsautonomously.Theuseofspecial-purposemicroproces-
sorsiscommonanddoesnotturnasingle-processorsystemintoamultiproces-
sor.Ifthereisonlyonegeneral-purposeCPUwithasingleprocessingcore,then
thesystemisasingle-processorsystem.Accordingtothisdefinition,however,
veryfewcontemporarycomputersystemsaresingle-processorsystems.
1.3.2 Multiprocessor Systems
On modern computers, from mobile devices to servers, multiprocessor sys-
tems now dominate the landscape of computing. Traditionally, such systems
have two (or more) processors, each with a single-core CPU. The proces-
sors share the computer bus and sometimes the clock, memory, and periph-
eral devices. The primary advantage of multiprocessor systems is increased
throughput.Thatis,byincreasingthenumberofprocessors,weexpecttoget
more work done in less time. The speed-up ratio with N processors is not N,
however;itislessthanN.Whenmultipleprocessorscooperateonatask,acer-
tainamountofoverheadisincurredinkeepingallthepartsworkingcorrectly.
Thisoverhead,pluscontentionforsharedresources,lowerstheexpectedgain
fromadditionalprocessors.
The most common multiprocessor systems use symmetric multiprocess-
ing (SMP), in which each peer CPU processor performs all tasks, including
operating-systemfunctionsanduserprocesses.Figure1.8illustratesatypical
SMParchitecturewithtwoprocessors,eachwithitsownCPU.Noticethateach
CPU processor has its own set of registers, as well as a private—or local—
cache.However,allprocessorssharephysicalmemoryoverthesystembus.
The benefit of this model is that many processes can run simultaneously
—N processes can run if there are N CPUs—without causing performance
to deteriorate significantly. However, since the CPUs are separate, one may
be sitting idle while another is overloaded, resulting in inefficiencies. These
inefficienciescanbeavoidediftheprocessorssharecertaindatastructures.A
multiprocessorsystemofthisformwillallowprocessesandresources—such
asmemory—tobeshareddynamicallyamongthevariousprocessorsandcan
lower the workload variance among the processors. Such a system must be
writtencarefully,asweshallseeinChapter5andChapter6.
Thedefinitionofmultiprocessor hasevolvedovertimeandnowincludes
multicoresystems,inwhichmultiplecomputingcoresresideonasinglechip.
Multicoresystemscanbemoreefficientthanmultiplechips withsinglecores
because on-chip communication is faster than between-chip communication.1.3 Computer-SystemArchitecture 17
Figure1.8 Symmetricmultiprocessingarchitecture.
In addition, one chip with multiple cores uses significantly less power than
multiple single-core chips, an important issue for mobile devices as well as
laptops.
InFigure1.9,weshowadual-coredesignwithtwocoresonthesamepro-
cessorchip.Inthisdesign,eachcorehasitsownregisterset,aswellasitsown
localcache,oftenknownasalevel1,orL1,cache.Notice,too,thatalevel2(L2)
cacheislocaltothechipbutissharedbythetwoprocessingcores.Mostarchi-
tecturesadoptthisapproach,combininglocalandsharedcaches,wherelocal,
lower-level caches are generally smaller and faster than higher-level shared
Figure1.9 Adual-coredesignwithtwocoresonthesamechip.18 Chapter1 Introduction
DEFINITIONSOFCOMPUTERSYSTEMCOMPONENTS
• CPU—Thehardwarethatexecutesinstructions.
• Processor—AphysicalchipthatcontainsoneormoreCPUs.
• Core—ThebasiccomputationunitoftheCPU.
• Multicore—IncludingmultiplecomputingcoresonthesameCPU.
• Multiprocessor—Includingmultipleprocessors.
Although virtually all systems are now multicore, we use the general term
CPUwhenreferringtoasinglecomputationalunitofacomputersystemand
coreaswellasmulticorewhenspecificallyreferringtooneormorecoreson
aCPU.
caches. Aside from architectural considerations, such as cache, memory, and
buscontention,amulticoreprocessorwithNcoresappearstotheoperatingsys-
temasNstandardCPUs.Thischaracteristicputspressureonoperating-system
designers—andapplicationprogrammers—tomakeefficientuseofthesepro-
cessingcores,anissuewepursueinChapter4.Virtuallyallmodernoperating
systems—includingWindows,macOS,andLinux,aswellasAndroidandiOS
mobilesystems—supportmulticoreSMPsystems.
AddingadditionalCPUstoamultiprocessorsystemwillincreasecomput-
ingpower;however,assuggestedearlier,theconceptdoesnotscaleverywell,
and once we add too many CPUs, contention for the system bus becomes a
bottleneck and performance begins to degrade. An alternative approach is
instead to provide each CPU (or group of CPUs) with its own local memory
thatisaccessedviaasmall,fastlocalbus.TheCPUsareconnectedbyashared
system interconnect, so that all CPUs share one physical address space. This
approach—known asnon-uniformmemoryaccess, orNUMA—is illustrated
in Figure 1.10. The advantage is that, when a CPU accesses its local memory,
notonlyisitfast,butthereisalsonocontentionoverthesysteminterconnect.
Thus,NUMAsystemscanscalemoreeffectivelyasmoreprocessorsareadded.
ApotentialdrawbackwithaNUMAsystemisincreasedlatencywhenaCPU
mustaccessremotememoryacrossthesysteminterconnect,creatingapossible
performancepenalty.Inotherwords,forexample,CPU cannotaccessthelocal
0
memoryofCPU asquicklyasitcanaccessitsownlocalmemory,slowingdown
3
performance. Operating systems can minimize this NUMA penalty through
carefulCPUschedulingandmemorymanagement,asdiscussedinSection5.5.2
and Section 10.5.4. Because NUMAsystems can scale to accommodate a large
number of processors, they are becoming increasingly popular on servers as
wellashigh-performancecomputingsystems.
Finally,bladeserversaresystemsinwhichmultipleprocessorboards,I/O
boards, and networking boards are placed in the same chassis. The differ-
encebetweentheseandtraditionalmultiprocessorsystemsisthateachblade-
processorboardbootsindependentlyandrunsitsownoperatingsystem.Some
blade-serverboardsaremultiprocessoraswell,whichblursthelinesbetween1.3 Computer-SystemArchitecture 19
memory memory
0 1
interconnect
CPU CPU
0 1
CPU CPU
2 3
memory memory
2 3
Figure1.10 NUMAmultiprocessingarchitecture.
typesofcomputers.Inessence,theseserversconsist ofmultipleindependent
multiprocessorsystems.
1.3.3 Clustered Systems
Another type of multiprocessor system is a clustered system, which gath-
ers together multiple CPUs. Clusteredsystems differ from the multiprocessor
systems described in Section 1.3.2 in that they are composed of two or more
individualsystems—ornodes—joinedtogether;eachnodeistypicallyamul-
ticore system. Such systems are considered loosely coupled. We should note
that the definition of clustered is not concrete; many commercial and open-
source packages wrestle to define what a clustered system is and why one
formisbetterthananother.Thegenerallyaccepteddefinitionisthatclustered
computers share storage and are closely linked via a local-area network LAN
(asdescribedinChapter19)orafasterinterconnect,suchasInfiniBand.
Clustering is usually used to provide high-availability service—that is,
service that will continue even if one or more systems in the cluster fail.
Generally,weobtainhighavailabilitybyaddingalevelofredundancyinthe
system. Alayer of cluster software runs on the cluster nodes. Each node can
monitoroneormoreoftheothers(overthenetwork).Ifthemonitoredmachine
fails,themonitoringmachinecantakeownershipofitsstorageandrestartthe
applicationsthatwererunningonthefailedmachine.Theusersandclientsof
theapplicationsseeonlyabriefinterruptionofservice.
High availability provides increased reliability, which is crucial in many
applications.Theabilitytocontinueprovidingserviceproportionaltothelevel
ofsurvivinghardwareiscalledgracefuldegradation.Somesystemsgobeyond
graceful degradation and are called fault tolerant, because they can suffer a
failure of any single component and still continue operation. Fault tolerance
requires a mechanism to allow the failure to be detected, diagnosed, and, if
possible,corrected.
Clustering can be structured asymmetrically or symmetrically. In asym-
metricclustering,onemachineisinhot-standbymodewhiletheotherisrun-
ningtheapplications.Thehot-standbyhostmachinedoesnothingbutmonitor
the active server. If that server fails, the hot-standby host becomes the active20 Chapter1 Introduction
PCMOTHERBOARD
ConsiderthedesktopPCmotherboardwithaprocessorsocketshownbelow:
This board is a fully functioning computer, once its slots are populated.
It consists of a processor socket containing a CPU, DRAM sockets, PCIe bus
slots, and I/O connectors of various types. Even the lowest-cost general-
purposeCPUcontainsmultiplecores.Somemotherboardscontainmultiple
processor sockets. More advanced computers allow more than one system
board,creatingNUMAsystems.
server. In symmetric clustering, two or more hosts are running applications
andaremonitoringeachother.Thisstructureisobviouslymoreefficient,asit
usesalloftheavailablehardware.However,itdoesrequirethatmorethanone
applicationbeavailabletorun.
Since a cluster consists of several computer systems connected via a net-
work,clusterscanalsobeusedtoprovidehigh-performancecomputingenvi-
ronments.Suchsystemscansupplysignificantlygreatercomputationalpower
thansingle-processororevenSMPsystemsbecausetheycanrunanapplication
concurrently on all computers in the cluster. The application must have been
writtenspecifically totakeadvantage ofthe cluster,however. This involvesa
technique known as parallelization, which divides a program into separate
componentsthatruninparallelonindividualcoresinacomputerorcomput-
ers in a cluster. Typically, these applications are designed so that once each
computingnodeintheclusterhassolveditsportionoftheproblem,theresults
fromallthenodesarecombinedintoafinalsolution.
Other forms of clusters include parallel clusters and clustering over a
wide-areanetwork(WAN)(asdescribedinChapter19).Parallelclustersallow
multiplehoststoaccessthesamedataonsharedstorage.Becausemostoper-1.4 Operating-SystemOperations 21
interconnect interconnect
computer computer computer
storage-area
network
Figure1.11 Generalstructureofaclusteredsystem.
ating systems lack support for simultaneous data access by multiple hosts,
parallel clusters usually require the use of special versions of software and
specialreleasesofapplications.Forexample,OracleRealApplicationCluster
is a version of Oracle’s database that has been designed to run on a parallel
cluster.EachmachinerunsOracle,andalayerofsoftwaretracksaccesstothe
shareddisk.Eachmachinehasfullaccesstoalldatainthedatabase.Toprovide
this shared access, the system must also supply access control and locking to
ensure that no conflicting operations occur. This function, commonly known
asadistributedlockmanager(DLM),isincludedinsomeclustertechnology.
Cluster technology is changing rapidly. Some cluster products support
thousandsofsystemsinacluster,aswellasclusterednodesthatareseparated
by miles. Many of these improvements are made possible by storage-area
networks (SANs), as described in Section 11.7.4, which allow many systems
to attach to a pool of storage. If the applications and their data are stored on
the SAN, then the cluster software can assign the application to run on any
host that isattached totheSAN. If the host fails,then any other host can take
over.Inadatabasecluster,dozensofhostscansharethesamedatabase,greatly
increasingperformanceandreliability.Figure1.11depictsthegeneralstructure
ofaclusteredsystem.
1.4 Operating-System Operations
Nowthatwehavediscussedbasicinformationaboutcomputer-systemorgani-
zationandarchitecture,wearereadytotalkaboutoperatingsystems.Anoper-
atingsystemprovidestheenvironmentwithinwhichprogramsareexecuted.
Internally,operatingsystemsvarygreatly,sincetheyareorganizedalongmany
differentlines.Thereare,however,manycommonalities,whichweconsiderin
thissection.
For a computer to start running—for instance, when it is powered up
or rebooted—it needs to have an initial program to run. As noted earlier,
this initial program, or bootstrap program, tends to be simple. Typically, it is
stored within the computer hardware in firmware. It initializes all aspects of
the system,from CPU registerstodevicecontrollers to memory contents. The
bootstrapprogrammustknowhow toloadtheoperatingsystemand howto22 Chapter1 Introduction
HADOOP
Hadoop is an open-source software framework that is used for distributed
processingoflargedatasets(knownasbigdata)inaclusteredsystemcon-
tainingsimple,low-costhardwarecomponents.Hadoopisdesignedtoscale
fromasinglesystemtoaclustercontainingthousandsofcomputingnodes.
Tasksareassignedtoanodeinthecluster,andHadooparrangescommunica-
tionbetweennodestomanageparallelcomputationstoprocessandcoalesce
results. Hadoop also detects and manages failures in nodes, providing an
efficientandhighlyreliabledistributedcomputingservice.
Hadoopisorganizedaroundthefollowingthreecomponents:
1. Adistributedfilesystemthatmanagesdataandfilesacrossdistributedcom-
putingnodes.
2. TheYARN(“YetAnotherResourceNegotiator”)framework,whichmanages
resources within the cluster as well as scheduling tasks on nodes in the
cluster.
3. The MapReduce system, which allows parallel processing of data across
nodesinthecluster.
Hadoop is designed to run on Linux systems, and Hadoop applications
can be written using several programming languages, including scripting
languages such as PHP, Perl, and Python. Java is a popular choice for
developing Hadoop applications, as Hadoop has several Java libraries that
support MapReduce. More information on MapReduce and Hadoop can
be foundathttps://hadoop.apache.org/docs/r1.2.1/mapred tutorial.html
andhttps://hadoop.apache.org
start executing that system. To accomplish this goal, the bootstrap program
mustlocatetheoperating-systemkernelandloaditintomemory.
Oncethekernelisloadedandexecuting,itcanstartprovidingservicesto
thesystemand itsusers.Someservicesareprovidedoutsideofthe kernelby
systemprogramsthatareloadedintomemoryatboottimetobecomesystem
daemons,which runtheentiretimethekernelisrunning.OnLinux,thefirst
system program is “systemd,” and it starts many other daemons. Once this
phase is complete, the system is fully booted, and the system waits for some
eventtooccur.
Iftherearenoprocessestoexecute,noI/Odevicestoservice,andnousers
towhomtorespond,anoperatingsystemwillsitquietly,waitingforsomething
tohappen.Eventsarealmostalwayssignaledbytheoccurrenceofaninterrupt.
InSection1.2.1wedescribedhardwareinterrupts.Anotherformofinterruptis
atrap(oranexception),whichisasoftware-generatedinterruptcausedeither
by an error (for example, division by zero or invalid memory access) or by
a specific request from a user program that an operating-system service be
performedbyexecutingaspecialoperationcalledasystemcall.1.4 Operating-SystemOperations 23
1.4.1 Multiprogramming and Multitasking
One of the most important aspects of operating systems is the ability to run
multipleprograms,asasingleprogramcannot,ingeneral,keepeithertheCPU
or the I/O devices busy at all times. Furthermore, users typically want to run
more than one program at a time as well. Multiprogramming increases CPU
utilization,aswellaskeepinguserssatisfied,by organizingprogramssothat
theCPUalwayshasonetoexecute.Inamultiprogrammedsystem,aprogram
inexecutionistermedaprocess.
The idea is as follows: The operating system keeps several processes in
memorysimultaneously(Figure1.12).Theoperatingsystempicksandbegins
toexecuteoneoftheseprocesses.Eventually,theprocessmayhavetowaitfor
sometask,suchasanI/Ooperation,tocomplete.Inanon-multiprogrammed
system, the CPU would sit idle. In a multiprogrammed system, the operating
systemsimplyswitchesto,andexecutes,anotherprocess.Whenthat process
needstowait,theCPUswitchestoanotherprocess,andsoon.Eventually,the
first process finishes waiting and gets the CPU back. As long as at least one
processneedstoexecute,theCPUisneveridle.
This idea is common in other life situations. Alawyer does not work for
only one client at a time,for example.While one case is waiting togoto trial
orhavepaperstyped,thelawyercanworkonanothercase.Ifshehasenough
clients, the lawyer will never be idle for lack of work. (Idle lawyers tend to
becomepoliticians,sothereisacertainsocialvalueinkeepinglawyersbusy.)
Multitaskingisalogicalextensionofmultiprogramming.Inmultitasking
systems, the CPU executes multiple processes by switching among them, but
the switches occur frequently, providing the user with a fast response time.
Consider that when a process executes, it typically executes for only a short
time before it either finishes or needs to perform I/O. I/O may be interactive;
that is, output goes to a display for the user, and input comes from a user
keyboard,mouse,ortouchscreen.SinceinteractiveI/Otypicallyrunsat“peo-
ple speeds,” it may take a long time to complete. Input, for example, may be
max
operating system
process 1
process 2
process 3
process 4
0
Figure1.12 Memorylayoutforamultiprogrammingsystem.24 Chapter1 Introduction
bounded by the user’s typing speed; seven characters per second is fast for
people but incredibly slow for computers. Rather than let the CPU sit idle as
thisinteractiveinputtakesplace,theoperatingsystemwillrapidlyswitchthe
CPUtoanotherprocess.
Havingseveralprocessesinmemoryatthesametimerequiressomeform
of memory management, which we cover in Chapter 9 and Chapter 10. In
addition,ifseveralprocessesarereadytorunatthesametime,thesystemmust
choose which process will run next. Making this decision is CPU scheduling,
which is discussed in Chapter 5. Finally, running multiple processes concur-
rentlyrequiresthattheirabilitytoaffectoneanotherbelimitedinallphasesof
theoperatingsystem,includingprocessscheduling,diskstorage,andmemory
management.Wediscusstheseconsiderationsthroughoutthetext.
In a multitasking system, the operating system must ensure reasonable
response time. A common method for doing so is virtual memory, a tech-
niquethatallowstheexecutionofaprocessthatisnotcompletelyinmemory
(Chapter 10). The main advantage of this scheme is that it enables users to
runprogramsthatarelargerthanactualphysicalmemory.Further,itabstracts
mainmemoryintoalarge,uniformarrayofstorage,separatinglogicalmem-
ory as viewed by the user from physical memory. This arrangement frees
programmersfromconcernovermemory-storagelimitations.
Multiprogrammingandmultitaskingsystemsmustalsoprovideafilesys-
tem (Chapter 13, Chapter 14, and Chapter 15). The file system resides on a
secondarystorage;hence,storagemanagementmustbeprovided(Chapter11).
Inaddition,asystemmustprotectresourcesfrominappropriateuse(Chapter
17).Toensureorderlyexecution,thesystemmustalsoprovidemechanismsfor
processsynchronizationandcommunication(Chapter6andChapter7),andit
mayensurethat processesdonotgetstuckinadeadlock,foreverwaitingfor
oneanother(Chapter8).
1.4.2 Dual-Mode and Multimode Operation
Since the operating system and its users share the hardware and software
resourcesofthecomputersystem,aproperlydesignedoperatingsystemmust
ensurethat anincorrect (or malicious)programcannot cause other programs
—or the operating system itself—to execute incorrectly. In order to ensure
the proper execution of the system, we must be able to distinguish between
theexecutionofoperating-systemcodeand user-definedcode.Theapproach
taken by most computer systems is to provide hardware support that allows
differentiationamongvariousmodesofexecution.
At the very least, we need two separate modes of operation: user mode
and kernel mode (also called supervisor mode, system mode, or privileged
mode). Abit, called the mode bit, is added to the hardware of the computer
toindicatethecurrentmode:kernel(0)oruser(1).Withthemodebit,wecan
distinguishbetweenataskthatisexecutedonbehalfoftheoperatingsystem
and one that is executed on behalf of the user. When the computer system is
executingonbehalfofauserapplication,thesystemisinusermode.However,
when a user application requests a service from the operating system (via a
system call), the system must transition from user to kernel mode to fulfill1.4 Operating-SystemOperations 25
user process
user mode
(mode bit = 1)
user process executing calls system call return from system call
trap return
kernel
mode bit = 0 mode bit = 1
kernel mode
(mode bit = 0)
execute system call
Figure1.13 Transitionfromusertokernelmode.
the request. This is shown in Figure 1.13. As we shall see, this architectural
enhancementisusefulformanyotheraspectsofsystemoperationaswell.
At system boot time, the hardware starts in kernel mode. The operating
systemis then loaded and starts user applicationsin user mode.Whenever a
traporinterruptoccurs,thehardwareswitchesfromusermodetokernelmode
(thatis,changesthestateofthemodebitto0).Thus,whenevertheoperating
systemgainscontrolofthecomputer,itisinkernelmode.Thesystemalways
switchestousermode(bysettingthemodebitto1)beforepassingcontrolto
auserprogram.
Thedualmodeofoperationprovidesuswiththemeansforprotectingthe
operating system from errant users—and errant users from one another. We
accomplish this protection by designating some of the machine instructions
that may cause harm as privileged instructions. The hardware allows privi-
legedinstructionstobeexecutedonlyinkernelmode.Ifanattemptismadeto
executeaprivilegedinstructioninusermode,thehardwaredoesnotexecute
theinstructionbutrathertreatsitasillegalandtrapsittotheoperatingsystem.
The instruction to switch to kernel mode is an example of a privileged
instruction.SomeotherexamplesincludeI/Ocontrol,timermanagement,and
interruptmanagement.Manyadditionalprivilegedinstructionsarediscussed
throughoutthetext.
The concept of modes can be extended beyond two modes. For example,
Intel processors have four separate protection rings, where ring 0 is kernel
modeandring3isusermode.(Althoughrings1and2couldbeusedforvari-
ousoperating-systemservices,inpracticetheyarerarelyused.)ARMv8systems
have seven modes. CPUs that support virtualization (Section 18.1) frequently
haveaseparatemodetoindicatewhenthevirtualmachinemanager(VMM)is
incontrolofthesystem.Inthismode,theVMMhasmoreprivilegesthanuser
processes but fewer than the kernel. It needs that level of privilege so it can
createandmanagevirtualmachines,changingtheCPUstatetodoso.
We can now better understand the life cycle of instruction execution in a
computersystem.Initialcontrolresidesintheoperatingsystem,whereinstruc-
tions are executed in kernel mode. When control is given to a user applica-
tion, the mode is set to user mode. Eventually, control is switched back to
the operating system via an interrupt, a trap, or a system call. Most contem-
porary operating systems—such as Microsoft Windows, Unix, and Linux—26 Chapter1 Introduction
take advantage of this dual-mode feature and provide greater protection for
theoperatingsystem.
System calls provide the means for a user program to ask the operating
system to perform tasks reserved for the operating system on the user pro-
gram’s behalf. A system call is invoked in a variety of ways, depending on
the functionality provided by the underlying processor. In all forms, it is the
methodusedbyaprocesstorequestactionbytheoperatingsystem.Asystem
callusuallytakestheformofatraptoaspecificlocationintheinterruptvector.
Thistrapcanbeexecutedbyagenerictrapinstruction,althoughsomesystems
haveaspecificsyscallinstructiontoinvokeasystemcall.
When a system call is executed, it is typically treated by the hardware as
a software interrupt. Control passes through the interrupt vector to a service
routine in the operating system, and the mode bit is set to kernel mode. The
system-callserviceroutineisapartoftheoperatingsystem.Thekernelexam-
ines the interrupting instruction to determine what system call has occurred;
a parameter indicates what type of service the user program is requesting.
Additionalinformationneededfortherequestmaybepassedinregisters,on
thestack,orinmemory(withpointerstothememorylocationspassedinreg-
isters). The kernel verifies that the parameters are correct and legal, executes
therequest,andreturnscontroltotheinstructionfollowingthesystemcall.We
describesystemcallsmorefullyinSection2.3.
Once hardwareprotectionisinplace,itdetectserrorsthatviolatemodes.
Theseerrorsarenormallyhandledbytheoperatingsystem.Ifauserprogram
failsinsomeway—such asbymakinganattempteithertoexecuteanillegal
instructionortoaccessmemorythatisnotintheuser’saddressspace—then
thehardwaretrapstotheoperatingsystem.Thetraptransferscontrolthrough
the interrupt vector to the operating system, just as an interrupt does. When
a program error occurs, the operating system must terminate the program
abnormally. This situation is handled by the same code as a user-requested
abnormaltermination.Anappropriateerrormessageisgiven,andthememory
oftheprogrammaybedumped.Thememorydumpisusuallywrittentoafile
sothattheuserorprogrammercanexamineitandperhapscorrectitandrestart
theprogram.
1.4.3 Timer
We must ensure that the operating system maintains control over the CPU.
We cannot allow a user program to get stuck in an infinite loop or to fail
to call system services and never return control to the operating system. To
accomplish this goal, we can use a timer. A timer can be set to interrupt
the computer after a specified period. The period may be fixed (for example,
1/60 second) or variable (for example, from 1 millisecond to 1 second). A
variable timer is generally implemented by a fixed-rate clock and a counter.
Theoperatingsystemsetsthecounter.Everytimetheclock ticks,thecounter
isdecremented.Whenthecounterreaches0,aninterruptoccurs.Forinstance,
a10-bitcounterwitha1-millisecondclockallowsinterruptsatintervalsfrom
1millisecondto1,024milliseconds,instepsof1millisecond.
Beforeturning overcontrol totheuser,theoperatingsystemensuresthat
thetimerissettointerrupt.Ifthetimerinterrupts,controltransfersautomati-
callytotheoperatingsystem,whichmaytreattheinterruptasafatalerroror1.5 ResourceManagement 27
LINUXTIMERS
OnLinuxsystems,thekernelconfigurationparameterHZspecifiesthefre-
quencyoftimerinterrupts.AnHZvalueof250meansthatthetimergenerates
250 interrupts per second, or one interruptevery 4 milliseconds. The value
ofHZdependsuponhowthekernelisconfigured,aswellthemachinetype
andarchitectureonwhichitisrunning.Arelatedkernelvariableisjiffies,
whichrepresentthenumberoftimerinterruptsthathaveoccurredsincethe
system was booted. A programming project in Chapter 2 further explores
timingintheLinuxkernel.
maygivetheprogrammoretime.Clearly,instructionsthatmodifythecontent
ofthetimerareprivileged.
1.5 Resource Management
Aswehaveseen,anoperatingsystemisaresourcemanager.Thesystem’sCPU,
memoryspace,file-storagespace,andI/Odevicesareamongtheresourcesthat
theoperatingsystemmustmanage.
1.5.1 Process Management
A program can do nothing unless its instructions are executed by a CPU. A
programinexecution,asmentioned,isaprocess.Aprogramsuchasacompiler
isaprocess,andaword-processingprogrambeingrunbyanindividualuser
on a PC is a process. Similarly, a social media app on a mobile device is a
process.Fornow,youcanconsideraprocesstobeaninstanceofaprogramin
execution,butlateryouwillseethattheconceptismoregeneral.Asdescribed
inChapter3,itispossibletoprovidesystemcallsthatallowprocessestocreate
subprocessestoexecuteconcurrently.
Aprocessneedscertainresources—includingCPUtime,memory,files,and
I/Odevices—toaccomplishitstask.Theseresourcesaretypicallyallocatedto
theprocesswhileitisrunning.Inadditiontothevariousphysicalandlogical
resourcesthat a process obtains when it is created, variousinitialization data
(input)may be passedalong. For example,consider aprocess running a web
browser whose function is to display the contents of a web page on a screen.
TheprocesswillbegiventheURLasaninputandwillexecutetheappropriate
instructionsandsystemcallstoobtainanddisplaythedesiredinformationon
thescreen.Whentheprocessterminates,theoperatingsystemwillreclaimany
reusableresources.
We emphasize that a program by itself is not a process. A program is a
passiveentity,likethecontentsofafilestoredondisk,whereasaprocessisan
active entity. Asingle-threaded process has one program counter specifying
the next instruction to execute. (Threads are covered in Chapter 4.) The exe-
cutionofsuchaprocessmustbesequential.TheCPUexecutesoneinstruction
ofthe processafteranother, untilthe processcompletes.Further,at any time,
one instruction at most is executed on behalf of the process. Thus, although28 Chapter1 Introduction
twoprocessesmaybeassociatedwiththesameprogram,theyarenevertheless
considered two separate execution sequences. A multithreaded process has
multiple program counters, each pointing to the next instruction to execute
foragiventhread.
A process is the unit of work in a system. A system consists of a collec-
tion of processes, some of which are operating-system processes (those that
executesystemcode)andtherestofwhichareuserprocesses(thosethatexe-
cuteusercode).Alltheseprocessescanpotentiallyexecuteconcurrently—by
multiplexingonasingleCPUcore—orinparallelacrossmultipleCPUcores.
Theoperatingsystemisresponsibleforthefollowingactivitiesinconnec-
tionwithprocessmanagement:
• Creatinganddeletingbothuserandsystemprocesses
• SchedulingprocessesandthreadsontheCPUs
• Suspendingandresumingprocesses
• Providingmechanismsforprocesssynchronization
• Providingmechanismsforprocesscommunication
Wediscussprocess-managementtechniquesinChapter3throughChapter7.
1.5.2 Memory Management
AsdiscussedinSection1.2.2,themainmemoryiscentraltotheoperationofa
modern computer system. Main memory is a large array of bytes, ranging in
size from hundreds of thousands to billions. Each byte has its own address.
Main memory is a repository of quickly accessible data shared by the CPU
and I/O devices. The CPU reads instructions from main memory during the
instruction-fetch cycle and both reads and writes data from main memory
duringthedata-fetchcycle(onavonNeumannarchitecture).Asnotedearlier,
themainmemoryisgenerallytheonlylargestoragedevicethattheCPUisable
to address and access directly.For example, for the CPU to process data from
disk, those data must first be transferred to main memory by CPU-generated
I/O calls. In the same way, instructions must be in memory for the CPU to
executethem.
Foraprogramtobeexecuted,itmustbemappedtoabsoluteaddressesand
loadedintomemory.Astheprogramexecutes,itaccessesprograminstructions
and data from memory by generating these absolute addresses. Eventually,
the programterminates,itsmemoryspace isdeclaredavailable,and the next
programcanbeloadedandexecuted.
ToimproveboththeutilizationoftheCPUandthespeedofthecomputer’s
responsetoitsusers,general-purposecomputersmustkeepseveralprograms
inmemory,creatinganeedformemorymanagement.Manydifferentmemory-
managementschemesareused.Theseschemesreflectvariousapproaches,and
theeffectivenessofanygivenalgorithmdependsonthesituation.Inselectinga
memory-managementschemeforaspecificsystem,wemusttakeintoaccount
manyfactors—especiallythehardwaredesignofthesystem.Eachalgorithm
requiresitsownhardwaresupport.1.5 ResourceManagement 29
Theoperatingsystemisresponsibleforthefollowingactivitiesinconnec-
tionwithmemorymanagement:
• Keeping track of which parts of memory are currently being used and
whichprocessisusingthem
• Allocatinganddeallocatingmemoryspaceasneeded
• Deciding which processes (or parts of processes) and data to move into
andoutofmemory
Memory-managementtechniquesarediscussedinChapter9andChapter10.
1.5.3 File-System Management
To make the computer system convenient for users, the operating system
providesauniform,logicalviewofinformationstorage.Theoperatingsystem
abstractsfromthephysicalpropertiesofitsstoragedevicestodefinealogical
storageunit,thefil .Theoperatingsystemmapsfilesontophysicalmediaand
accessesthesefilesviathestoragedevices.
File management is one of the most visible components of an operating
system.Computers can store information on severaldifferenttypes of physi-
calmedia.Secondarystorageisthemostcommon,buttertiarystorageisalso
possible. Each of these media has its own characteristics and physical orga-
nization. Most are controlled by a device, such as a disk drive, that also has
itsownuniquecharacteristics.Thesepropertiesincludeaccessspeed,capacity,
data-transferrate,andaccessmethod(sequentialorrandom).
A file is a collection of related information defined by its creator. Com-
monly,filesrepresentprograms(bothsourceandobjectforms)anddata.Data
files may be numeric, alphabetic, alphanumeric, or binary. Files may be free-
form (for example, text files), or they may be formatted rigidly (for example,
fixed fields such as an mp3 music file). Clearly, the concept of a file is an
extremelygeneralone.
Theoperatingsystemimplementstheabstractconceptofafilebymanag-
ingmassstoragemediaandthedevicesthatcontrolthem.Inaddition,filesare
normallyorganizedintodirectoriestomakethemeasiertouse.Finally,when
multiple users have access to files, it may be desirable to control which user
may access a file and how that user may access it (for example, read, write,
append).
Theoperatingsystemisresponsibleforthefollowingactivitiesinconnec-
tionwithfilemanagement:
• Creatinganddeletingfiles
• Creatinganddeletingdirectoriestoorganizefiles
• Supportingprimitivesformanipulatingfilesanddirectories
• Mappingfilesontomassstorage
• Backingupfilesonstable(nonvolatile)storagemedia30 Chapter1 Introduction
File-management techniques are discussed in Chapter 13, Chapter 14, and
Chapter15.
1.5.4 Mass-Storage Management
Aswehavealreadyseen,thecomputersystemmustprovidesecondarystorage
tobackupmainmemory.MostmoderncomputersystemsuseHDDsandNVM
devices as the principal on-line storage media for both programs and data.
Most programs—including compilers, web browsers, word processors, and
games—arestoredonthesedevicesuntilloadedintomemory.Theprograms
thenusethedevicesasboththesourceandthedestinationoftheirprocessing.
Hence,thepropermanagementofsecondarystorageisofcentralimportance
to a computer system. The operating system is responsible for the following
activitiesinconnectionwithsecondarystoragemanagement:
• Mountingandunmounting
• Free-spacemanagement
• Storageallocation
• Diskscheduling
• Partitioning
• Protection
Becausesecondarystorageisusedfrequentlyandextensively,itmustbeused
efficiently.Theentirespeedofoperationofacomputermayhingeonthespeeds
of the secondarystorage subsystem and the algorithms that manipulate that
subsystem.
Atthesametime,therearemanyusesforstoragethatisslowerandlower
in cost (and sometimes higher in capacity) than secondary storage. Backups
ofdiskdata,storage ofseldom-useddata,and long-termarchival storageare
someexamples.MagnetictapedrivesandtheirtapesandCD DVD andBlu-ray
drivesandplattersaretypicaltertiarystoragedevices.
Tertiary storage is not crucial to system performance, but it still must
be managed. Some operating systems take on this task, while others leave
tertiary-storage management to application programs. Some of the functions
thatoperatingsystemscanprovideincludemountingandunmountingmedia
in devices, allocating and freeing the devices for exclusive use by processes,
andmigratingdatafromsecondarytotertiarystorage.
Techniques for secondary storage and tertiary storage management are
discussedinChapter11.
1.5.5 Cache Management
Cachingisanimportantprincipleofcomputersystems.Here’showitworks.
Informationisnormallykeptinsomestoragesystem(suchasmainmemory).
As it is used, it is copied into a faster storage system—the cache—on a tem-
porary basis. When we need a particular piece of information, we first check
whetheritisinthecache.Ifitis,weusetheinformationdirectlyfromthecache.1.5 ResourceManagement 31
Level 1 2 3 4 5
Name registers cache main memory solid-state disk magnetic disk
Typical size < 1 KB < 16MB < 64GB < 1 TB < 10 TB
Implementation custom memory on-chip or CMOS SRAM flash memory magnetic disk
technology with multiple off-chip
ports CMOS CMOS SRAM
Access time (ns) 0.25-0.5 0.5-25 80-250 25,000-50,000 5,000,000
Bandwidth (MB/sec) 20,000-100,000 5,000-10,000 1,000-5,000 500 20-150
Managed by compiler hardware operating system operating system operating system
Backed by cache main memory disk disk disk or tape
Figure1.14 Characteristicsofvarioustypesofstorage.
Ifitisnot,weusetheinformationfromthesource,puttingacopyinthecache
undertheassumptionthatwewillneeditagainsoon.
In addition, internal programmable registers provide a high-speed cache
for main memory. The programmer (or compiler) implements the register-
allocationandregister-replacementalgorithmstodecidewhichinformationto
keepinregistersandwhichtokeepinmainmemory.
Other caches are implemented totally in hardware. For instance, most
systems have an instruction cache to hold the instructions expected to be
executednext. Without this cache, the CPU would have towait severalcycles
whileaninstructionwasfetchedfrommainmemory.Forsimilarreasons,most
systemshaveoneormorehigh-speeddatacachesinthememoryhierarchy.We
arenotconcernedwiththesehardware-onlycachesinthistext,sincetheyare
outsidethecontroloftheoperatingsystem.
Because caches have limited size, cache management is an important
designproblem.Carefulselectionofthecachesizeandofareplacementpolicy
canresultingreatlyincreasedperformance,asyoucanseebyexaminingFigure
1.14. Replacement algorithms for software-controlled caches are discussed in
Chapter10.
Themovementofinformationbetweenlevelsofastoragehierarchymaybe
eitherexplicitorimplicit,dependingonthehardwaredesignandthecontrol-
lingoperating-systemsoftware.Forinstance,datatransferfromcache toCPU
and registersis usually ahardware function, with no operating-systeminter-
vention.Incontrast,transferofdatafromdisktomemoryisusuallycontrolled
bytheoperatingsystem.
In a hierarchical storage structure, the same data may appear in different
levels of the storage system. For example, suppose that an integer A that is
to be incremented by 1 is located in file B, and file B resides on hard disk.
TheincrementoperationproceedsbyfirstissuinganI/Ooperationtocopythe
diskblockonwhichAresidestomainmemory.Thisoperationisfollowedby
copyingAtothecacheandtoaninternalregister.Thus,thecopyofAappears
in several places: on the hard disk, in main memory, in the cache, and in an
internalregister(seeFigure1.15).Oncetheincrementtakesplaceintheinternal
register, the value of Adiffers in the various storage systems. The value of A32 Chapter1 Introduction
magnetic main hardware
A A cache A
disk memory register
Figure1.15 MigrationofintegerAfromdisktoregister.
becomes the same only after the new value of Ais written from the internal
registerbacktotheharddisk.
In a computing environment where only one process executes at a time,
thisarrangementposesnodifficulties,sinceanaccesstointegerAwillalways
betothecopyatthehighestlevelofthehierarchy.However,inamultitasking
environment, where the CPU is switched back and forth among various pro-
cesses,extremecaremustbetakentoensurethat,ifseveralprocesseswishto
access A, then each of these processes will obtain the most recently updated
valueofA.
Thesituationbecomesmorecomplicatedinamultiprocessorenvironment
where, in addition to maintaining internal registers, each of the CPUs also
containsalocalcache(referbacktoFigure1.8).Insuchanenvironment,acopy
of Amay exist simultaneously in several caches. Since the various CPUs can
all execute in parallel, we must make sure that an update to the value of A
inonecacheisimmediatelyreflectedinallothercacheswhereAresides.This
situationiscalledcachecoherency,anditisusuallyahardwareissue(handled
belowtheoperating-systemlevel).
In a distributed environment, the situation becomes even more complex.
Inthisenvironment,severalcopies(orreplicas)ofthesamefilecanbekepton
differentcomputers. Since the various replicasmay be accessed and updated
concurrently,somedistributedsystemsensurethat,whenareplicaisupdated
inoneplace,allotherreplicasarebroughtuptodateassoonaspossible.There
arevariouswaystoachievethisguarantee,aswediscussinChapter19.
1.5.6 I/O System Management
One of the purposes of an operating system is to hide the peculiarities of
specifichardwaredevicesfromtheuser.Forexample,inUNIX,thepeculiarities
of I/O devices are hidden from the bulk of the operating system itself by the
I/Osubsystem.TheI/Osubsystemconsistsofseveralcomponents:
• Amemory-managementcomponentthatincludesbuffering,caching,and
spooling
• Ageneraldevice-driverinterface
• Driversforspecifichardwaredevices
Onlythedevicedriverknowsthepeculiaritiesofthespecificdevicetowhich
itisassigned.
We discussed earlier in this chapter how interrupt handlers and device
driversareusedintheconstructionofefficientI/Osubsystems.InChapter12,
wediscusshowtheI/Osubsysteminterfacestotheothersystemcomponents,
managesdevices,transfersdata,anddetectsI/Ocompletion.1.6 SecurityandProtection 33
1.6 Security and Protection
Ifacomputer systemhas multipleusersand allows the concurrent execution
ofmultipleprocesses,thenaccesstodatamustberegulated.Forthatpurpose,
mechanismsensurethatfiles,memorysegments,CPU,andotherresourcescan
be operated on by only those processes that have gained proper authoriza-
tion from the operating system. For example, memory-addressing hardware
ensures that a process can execute only within its own address space. The
timer ensures that no process can gain control of the CPU without eventually
relinquishingcontrol.Device-controlregistersarenotaccessibletousers,sothe
integrityofthevariousperipheraldevicesisprotected.
Protection,then,isanymechanismforcontrollingtheaccessofprocesses
oruserstotheresourcesdefinedbyacomputersystem.Thismechanismmust
providemeanstospecifythecontrolstobeimposedandtoenforcethecontrols.
Protectioncanimprovereliabilitybydetectinglatenterrorsattheinterfaces
between component subsystems. Early detection of interface errors can often
prevent contamination of a healthy subsystem by another subsystem that is
malfunctioning.Furthermore,anunprotectedresourcecannot defendagainst
use(ormisuse)byanunauthorizedorincompetentuser.Aprotection-oriented
systemprovidesameanstodistinguishbetweenauthorizedandunauthorized
usage,aswediscussinChapter17.
A system can have adequate protection but still be prone to failure and
allowinappropriateaccess.Considerauserwhoseauthenticationinformation
(her means of identifying herself to the system) is stolen. Her data could be
copiedor deleted,eventhough file and memory protectionare working. It is
thejobofsecuritytodefendasystemfromexternalandinternalattacks.Such
attacksspreadacrossahugerangeandincludevirusesandworms,denial-of-
service attacks (which use all of a system’s resources and so keep legitimate
usersoutofthesystem),identitytheft,andtheftofservice(unauthorizeduse
of a system). Prevention of some of these attacks is considered an operating-
system function on some systems, while other systems leave it to policy or
additionalsoftware.Duetothealarmingriseinsecurityincidents,operating-
systemsecurity features are a fast-growing areaof researchand implementa-
tion.WediscusssecurityinChapter16.
Protectionandsecurityrequirethesystemtobeabletodistinguishamong
all its users. Most operating systems maintain a list of user names and asso-
ciated user identifier (user IDs). In Windows parlance, this is a security ID
(SID). These numerical IDs are unique, one per user. When a user logs in to
thesystem,theauthenticationstagedeterminestheappropriateuserIDforthe
user. That user ID is associated with all of the user’s processes and threads.
When an ID needs to be readable by a user, it is translated back to the user
nameviatheusernamelist.
Insomecircumstances,wewishtodistinguishamongsetsofusersrather
thanindividualusers.Forexample,theownerofafileonaUNIXsystemmaybe
allowedtoissuealloperationsonthatfile,whereasaselectedsetofusersmay
beallowedonlytoreadthefile.Toaccomplishthis,weneedtodefineagroup
name and the set of users belonging to that group. Group functionality can
be implementedas a system-widelistof group names and groupidentifier .
Auser can be in one or more groups, dependingon operating-systemdesign34 Chapter1 Introduction
decisions. The user’s group IDs are also included in every associated process
andthread.
In the course of normal system use, the user ID and group ID for a user
aresufficient.However,ausersometimesneedstoescalateprivilegestogain
extrapermissionsforanactivity.Theusermayneedaccesstoadevicethatis
restricted,for example.Operating systemsprovidevariousmethods toallow
privilege escalation. On UNIX, for instance, the setuid attribute on a program
causesthatprogramtorunwiththeuserIDoftheownerofthefile,ratherthan
thecurrentuser’sID.TheprocessrunswiththiseffectiveUIDuntilitturnsoff
theextraprivilegesorterminates.
1.7 Virtualization
Virtualizationisatechnologythatallowsustoabstractthehardwareofasin-
gle computer (the CPU, memory, disk drives, network interface cards, and so
forth)intoseveraldifferentexecutionenvironments,therebycreatingtheillu-
sion that each separate environment is running on its own private computer.
These environments can be viewed as differentindividualoperating systems
(for example,Windows and UNIX) that may be running at the same timeand
may interact with each other. Auser of a virtual machine can switch among
the various operating systems in the same way a user can switch among the
variousprocessesrunningconcurrentlyinasingleoperatingsystem.
Virtualizationallowsoperatingsystemstorunasapplicationswithinother
operatingsystems.Atfirstblush,thereseemstobelittlereasonforsuchfunc-
tionality.Butthevirtualizationindustryisvastandgrowing,whichisatesta-
menttoitsutilityandimportance.
Broadlyspeaking,virtualizationsoftwareisonememberofaclassthatalso
includes emulation. Emulation, which involves simulating computer hard-
wareinsoftware,istypicallyusedwhenthesourceCPUtypeisdifferentfrom
the target CPU type. For example, when Apple switched from the IBM Power
CPUtotheIntelx86CPUforitsdesktopandlaptopcomputers,itincludedan
emulation facility called “Rosetta,” which allowed applications compiled for
theIBMCPUtorunontheIntelCPU.Thatsameconceptcanbeextendedtoallow
anentireoperatingsystemwrittenforoneplatformtorunonanother.Emula-
tioncomesataheavyprice,however.Everymachine-levelinstructionthatruns
natively on the source system must be translated to the equivalent function
on the target system, frequently resulting in several target instructions. If the
source and target CPUs have similar performance levels, the emulated code
mayrunmuchmoreslowlythanthenativecode.
Withvirtualization,incontrast,anoperatingsystemthat isnativelycom-
piled for a particular CPU architecture runs within another operating system
also native to that CPU. Virtualizationfirst came about on IBM mainframes as
a method for multiple users to run tasks concurrently. Running multiple vir-
tual machines allowed (and stillallows)many userstoruntasks ona system
designedforasingleuser.Later,inresponsetoproblemswithrunningmultiple
MicrosoftWindows applications ontheIntelx86CPU, VMwarecreatedanew
virtualizationtechnology in the form of an application that ran on Windows.
That application ran one or more guest copies of Windows or other native
x86 operating systems, each running its own applications. (See Figure 1.16.)1.8 DistributedSystems 35
processes
processes
processes processes
programming
kernel kernel kernel
interface
VM1 VM2 VM3
kernel
virtual machine
manager
hardware
hardware
(a) (b)
Figure1.16 Acomputerrunning(a)asingleoperatingsystemand(b)threevirtual
machines.
Windowswasthehostoperatingsystem,andtheVMwareapplicationwasthe
virtualmachinemanager(VMM).TheVMMrunstheguestoperatingsystems,
managestheirresourceuse,andprotectseachguestfromtheothers.
Eventhoughmodernoperatingsystemsarefullycapableofrunningmulti-
pleapplicationsreliably,theuseofvirtualizationcontinuestogrow.Onlaptops
anddesktops,aVMMallowstheusertoinstallmultipleoperatingsystemsfor
explorationortorunapplicationswrittenforoperatingsystemsotherthanthe
nativehost.Forexample,anApplelaptoprunningmacOSonthex86CPUcan
run a Windows 10 guest to allow execution of Windows applications. Com-
panieswritingsoftwareformultipleoperatingsystemscanusevirtualization
to run all of those operating systems on a single physical server for develop-
ment,testing,anddebugging.Withindatacenters,virtualizationhasbecomea
commonmethodofexecutingandmanagingcomputingenvironments.VMMs
likeVMwareESXandCitrixXenServernolongerrunonhostoperatingsystems
but rather are the host operating systems, providing services and resource
managementtovirtualmachineprocesses.
With this text, we provide a Linux virtual machine that allows you to
runLinux—as wellasthedevelopmenttoolsweprovide—onyourpersonal
system regardless of your host operating system. Full details of the features
andimplementationofvirtualizationcanbefoundinChapter18.
1.8 Distributed Systems
Adistributedsystemis a collection of physically separate,possibly heteroge-
neous computer systems that are networked to provide users with access to
the various resources that the system maintains. Access to a shared resource
increases computation speed, functionality, data availability, and reliability.
Someoperatingsystemsgeneralizenetworkaccessasaformoffileaccess,with
the details of networking contained in the network interface’s device driver.36 Chapter1 Introduction
Others make users specifically invoke network functions. Generally, systems
contain a mix of the two modes—for example FTP and NFS. The protocols
that create a distributed system can greatly affect that system’s utility and
popularity.
Anetwork,inthesimplestterms,isacommunicationpathbetweentwoor
moresystems.Distributedsystemsdependonnetworkingfortheirfunctional-
ity.Networksvarybytheprotocolsused,thedistancesbetweennodes,andthe
transportmedia.TCP/IPisthemostcommonnetworkprotocol,anditprovides
thefundamentalarchitectureoftheInternet.Mostoperatingsystemssupport
TCP/IP,includingallgeneral-purposeones.Somesystemssupportproprietary
protocolstosuittheirneeds.Foranoperatingsystem,itisnecessaryonlythat
anetworkprotocolhaveaninterfacedevice—anetworkadapter,forexample
—withadevicedrivertomanageit,aswellassoftwaretohandledata.These
conceptsarediscussedthroughoutthisbook.
Networks are characterized based on the distances between their nodes.
A local-area network (LAN) connects computers within a room, a building,
or a campus. A wide-area network (WAN) usually links buildings, cities, or
countries.AglobalcompanymayhaveaWANtoconnectitsofficesworldwide,
for example. These networks may run one protocol or several protocols. The
continuing advent of new technologies brings about new forms of networks.
Forexample,ametropolitan-areanetwork(MAN)couldlinkbuildingswithin
a city. BlueTooth and 802.11 devices use wireless technology to communicate
over a distance of several feet, in essence creating a personal-area network
(PAN)betweenaphoneandaheadsetorasmartphoneandadesktopcomputer.
Themediatocarrynetworksareequallyvaried.Theyincludecopperwires,
fiberstrands,andwirelesstransmissionsbetweensatellites,microwavedishes,
and radios. When computing devices are connected to cellular phones, they
createanetwork.Evenveryshort-rangeinfraredcommunicationcanbeused
for networking. At a rudimentary level, whenever computers communicate,
they use or create a network. These networks also vary in their performance
andreliability.
Some operating systems have taken the concept of networks and dis-
tributed systems further than the notion of providing network connectivity.
A network operating system is an operating system that provides features
such as file sharing across the network, along with a communication scheme
that allows differentprocesses on differentcomputers to exchange messages.
Acomputerrunning anetworkoperatingsystemactsautonomouslyfromall
other computers on the network, although it is aware of the network and is
able to communicate with other networked computers. Adistributed operat-
ingsystemprovidesalessautonomousenvironment.Thedifferentcomputers
communicatecloselyenoughtoprovidetheillusionthatonlyasingleoperat-
ingsystemcontrolsthenetwork.Wecovercomputernetworksanddistributed
systemsinChapter19.
1.9 Kernel Data Structures
We turn next to a topic central to operating-system implementation: the way
data are structured in the system. In this section, we briefly describe several
fundamental data structures used extensively in operating systems. Readers1.9 KernelDataStructures 37
data data data null
(cid:129) (cid:129) (cid:129)
Figure1.17 Singlylinkedlist.
whorequirefurtherdetailsonthesestructures,aswellasothers,shouldconsult
thebibliographyattheendofthechapter.
1.9.1 Lists, Stacks, and Queues
An array is a simple data structure in which each element can be accessed
directly.Forexample,mainmemoryisconstructedasanarray.Ifthedataitem
beingstoredislargerthanonebyte,thenmultiplebytescanbeallocatedtothe
item,andtheitemisaddressedas“itemnumber×itemsize.”Butwhatabout
storinganitemwhosesizemayvary?Andwhataboutremovinganitemifthe
relativepositionsoftheremainingitemsmustbepreserved?Insuchsituations,
arraysgivewaytootherdatastructures.
Afterarrays,listsareperhapsthemostfundamentaldatastructuresincom-
puterscience.Whereaseachiteminanarraycanbeaccesseddirectly,theitems
inalistmustbeaccessedinaparticularorder.Thatis,alistrepresentsacollec-
tionofdatavaluesasasequence.Themostcommonmethodforimplementing
thisstructureisalinkedlist,inwhichitemsarelinkedtooneanother.Linked
listsareofseveraltypes:
• In a singly linked list, each item points to its successor, as illustrated in
Figure1.17.
• Inadoublylinkedlist,agivenitemcanrefereithertoitspredecessororto
itssuccessor,asillustratedinFigure1.18.
• In a circularly linked list, the last element in the list refers to the first
element,ratherthantonull,asillustratedinFigure1.19.
Linkedlistsaccommodateitemsofvaryingsizesandalloweasyinsertion
and deletion of items. One potential disadvantage of using a list is that per-
formanceforretrievingaspecifiediteminalistofsizenislinear—O(n),asit
requirespotentiallytraversingallnelementsintheworstcase.Listsaresome-
timesuseddirectlybykernelalgorithms.Frequently,though,theyareusedfor
constructingmorepowerfuldatastructures,suchasstacksandqueues.
Astack is a sequentially ordered data structure that uses the last in, first
out(LIFO)principleforaddingandremovingitems,meaningthatthelastitem
data null data data data null
(cid:129) (cid:129) (cid:129)
Figure1.18 Doublylinkedlist.38 Chapter1 Introduction
data data data data
(cid:129) (cid:129) (cid:129)
Figure1.19 Circularlylinkedlist.
placedontoastackisthefirstitemremoved.Theoperationsforinsertingand
removing items from a stack are known as push and pop, respectively. An
operatingsystemoftenusesastackwheninvokingfunctioncalls.Parameters,
local variables, and the return address are pushed onto the stack when a
function is called; returning from the function call pops those items off the
stack.
Aqueue,incontrast,isasequentiallyordereddatastructurethatusesthe
firstin,firstout(FIFO)principle:itemsareremovedfromaqueueintheorder
in which they were inserted. There are many everyday examples of queues,
includingshopperswaitinginacheckoutlineatastoreandcarswaitinginline
at a traffic signal. Queues are also quite common in operating systems—jobs
thataresenttoaprinteraretypicallyprintedintheorderinwhichtheywere
submitted,forexample.AsweshallseeinChapter5,tasksthatarewaitingto
berunonanavailableCPUareoftenorganizedinqueues.
1.9.2 Trees
Atreeisadatastructurethatcanbeusedtorepresentdatahierarchically.Data
values in a tree structure are linked through parent–child relationships. In a
generaltree,aparentmayhaveanunlimitednumberofchildren.Inabinary
tree, a parent may have at most two children, which we term the left child
and the right child. A binary search tree additionally requires an ordering
betweentheparent’stwochildreninwhichleft child <=right child.Figure1.20
providesanexampleofabinarysearchtree.Whenwesearchforanitemina
binarysearchtree,theworst-caseperformanceisO(n)(considerhowthiscan
occur).Toremedythissituation,wecanuseanalgorithmtocreateabalanced
binarysearchtree.Here,atreecontainingnitemshasatmostlgnlevels,thus
ensuringworst-caseperformanceofO(lg n).WeshallseeinSection5.7.1that
Linux uses a balanced binary search tree (known as a red-black tree) as part
itsCPU-schedulingalgorithm.
1.9.3 Hash Functions and Maps
Ahashfunctiontakesdataasitsinput,performsanumericoperationonthe
data, and returns a numeric value. This numeric value can then be used as
anindexintoatable(typicallyanarray)toquicklyretrievethedata.Whereas
searchingforadataitemthroughalistofsizencanrequireuptoO(n)compar-
isons,usingahashfunctionforretrievingdatafromatablecanbeasgoodas
O(1),dependingonimplementationdetails.Becauseofthisperformance,hash
functionsareusedextensivelyinoperatingsystems.
One potential difficulty with hash functions is that two unique inputs
can result in the same output value—that is, they can link to the same table1.9 KernelDataStructures 39
17
12 35
6 14 40
38
Figure1.20 Binarysearchtree.
location.Wecanaccommodatethishashcollisionbyhavingalinkedlistatthe
tablelocationthatcontainsalloftheitemswiththesamehashvalue.Ofcourse,
themorecollisionsthereare,thelessefficientthehashfunctionis.
Oneuseofahashfunctionistoimplementahashmap,whichassociates
(ormaps)[key:value]pairsusingahashfunction.Oncethemappingisestab-
lished,wecanapplythehashfunctiontothekeytoobtainthevaluefromthe
hashmap(Figure1.21).Forexample,supposethat ausernameismappedto
a password. Password authentication then proceeds as follows: a user enters
her user name and password. The hash function is applied to the user name,
which is then used to retrieve the password. The retrieved password is then
comparedwiththepasswordenteredbytheuserforauthentication.
1.9.4 Bitmaps
Abitmapisastringofnbinarydigitsthatcanbeusedtorepresentthestatusof
nitems.Forexample,supposewehaveseveralresources,andtheavailability
of each resource is indicated by the value of a binary digit: 0 means that the
resourceisavailable,while1indicatesthatitisunavailable(orviceversa).The
hash_function(key)
hash map
0 1 . . n
value
Figure1.21 Hashmap.40 Chapter1 Introduction
LINUXKERNELDATASTRUCTURES
ThedatastructuresusedintheLinuxkernelareavailableinthekernelsource
code. The include file <linux/list.h> provides details of the linked-list
data structure used throughoutthe kernel.Aqueue in Linux is known asa
kfifo,anditsimplementationcanbefoundinthekfifo.cfileinthekernel
directoryofthesourcecode.Linuxalsoprovidesabalancedbinarysearchtree
implementationusingred-blacktrees.Detailscanbefoundintheincludefile
<linux/rbtree.h>.
valueoftheith positioninthebitmapisassociatedwiththeith resource.Asan
example,considerthebitmapshownbelow:
001011101
Resources2,4,5,6,and8areunavailable;resources0,1,3,and7areavailable.
The power of bitmaps becomes apparent when we consider their space
efficiency.Ifwe weretouseaneight-bitBooleanvalueinsteadofasinglebit,
the resulting data structure would be eight times larger. Thus, bitmaps are
commonly used when there is a need to represent the availability of a large
numberofresources.Diskdrivesprovideaniceillustration.Amedium-sized
diskdrivemightbedividedintoseveralthousandindividualunits,calleddisk
blocks.Abitmapcanbeusedtoindicatetheavailabilityofeachdiskblock.
Insummary,datastructuresarepervasiveinoperatingsystemimplemen-
tations. Thus, we will see the structures discussed here, along with others,
throughout this text as we explore kernel algorithms and their implementa-
tions.
1.10 Computing Environments
Sofar,wehavebrieflydescribedseveralaspectsofcomputersystemsandthe
operating systems that manage them. We turn now to a discussion of how
operatingsystemsareusedinavarietyofcomputingenvironments.
1.10.1 Traditional Computing
Ascomputinghasmatured,thelinesseparatingmanyofthetraditionalcom-
putingenvironmentshaveblurred.Considerthe“typicalofficeenvironment.”
Justafewyearsago,thisenvironmentconsistedofPCsconnectedtoanetwork,
with servers providing file and print services. Remote access was awkward,
andportabilitywasachievedbyuseoflaptopcomputers.
Today,webtechnologiesandincreasingWANbandwidtharestretchingthe
boundariesoftraditionalcomputing.Companiesestablishportals,whichpro-
vide web accessibility to their internal servers. Network computers (or thin
clients)—whichareessentiallyterminalsthatunderstandweb-basedcomput-
ing—are used in place of traditional workstations where more security or
easier maintenance is desired. Mobile computers can synchronize with PCs
to allow very portable use of company information. Mobile devices can also1.10 ComputingEnvironments 41
connecttowirelessnetworksandcellulardatanetworkstousethecompany’s
webportal(aswellasthemyriadotherwebresources).
Athome,mostusersoncehadasinglecomputerwithaslowmodemcon-
nection to the office, the Internet, or both. Today, network-connection speeds
once available only at great cost are relatively inexpensive in many places,
giving home users more access to more data. These fast data connections are
allowing home computers to serve up web pages and to run networks that
include printers, client PCs, and servers. Many homes use firewall to pro-
tecttheirnetworksfromsecuritybreaches.Firewallslimitthecommunications
betweendevicesonanetwork.
In the latter half of the 20th century, computing resources were relatively
scarce.(Beforethat,theywerenonexistent!)Foraperiodoftime,systemswere
either batch or interactive. Batch systems processed jobs in bulk, with prede-
terminedinputfromfilesorotherdatasources.Interactivesystemswaitedfor
input from users. To optimize the use of the computing resources, multiple
userssharedtimeonthesesystems.Thesetime-sharingsystemsusedatimer
andschedulingalgorithmstocycleprocessesrapidlythroughtheCPU,giving
eachuserashareoftheresources.
Traditionaltime-sharingsystemsareraretoday.Thesameschedulingtech-
nique is still in use on desktop computers, laptops, servers, and even mobile
computers,but frequentlyall the processesareowned by the sameuser (or a
single user and the operating system). User processes, and system processes
that provide services to the user, are managed so that each frequently gets a
sliceofcomputertime.Considerthewindowscreatedwhileauserisworking
onaPC,forexample,andthefactthattheymaybeperformingdifferenttasks
atthesametime.Evenawebbrowsercanbecomposedofmultipleprocesses,
oneforeachwebsitecurrentlybeingvisited,withtimesharingappliedtoeach
webbrowserprocess.
1.10.2 Mobile Computing
Mobilecomputingreferstocomputing onhandheldsmartphonesand tablet
computers. These devices share the distinguishing physical features of being
portable and lightweight. Historically, compared with desktop and laptop
computers,mobilesystemsgaveupscreensize,memorycapacity,andoverall
functionality in return for handheld mobile access to services such as e-mail
and web browsing. Over the past few years, however, features on mobile
deviceshavebecomesorichthatthedistinctioninfunctionalitybetween,say,
a consumer laptop and a tablet computer may be difficult to discern. In fact,
wemightarguethat thefeaturesofacontemporary mobiledeviceallowitto
providefunctionalitythatiseitherunavailableorimpracticalonadesktopor
laptopcomputer.
Today,mobilesystemsareusednotonlyfore-mailandwebbrowsingbut
also for playing music and video, reading digital books, taking photos, and
recordingandeditinghigh-definitionvideo.Accordingly,tremendousgrowth
continues in the wide range of applications that run on such devices. Many
developersarenowdesigningapplicationsthattakeadvantageoftheunique
features of mobile devices, such as global positioning system (GPS) chips,
accelerometers,andgyroscopes.AnembeddedGPSchipallowsamobiledevice
tousesatellitestodetermineitspreciselocationonEarth.Thatfunctionalityis42 Chapter1 Introduction
especiallyusefulindesigningapplicationsthatprovidenavigation—forexam-
ple, telling users which way to walk or drive or perhaps directing them to
nearbyservices,suchasrestaurants.Anaccelerometerallowsamobiledevice
todetectitsorientationwithrespecttothegroundandtodetectcertainother
forces, such as tilting and shaking. In several computer games that employ
accelerometers, players interface with the system not by using a mouse or a
keyboardbutratherbytilting,rotating,andshakingthemobiledevice!Perhaps
more a practical use of these features is found in augmented-reality appli-
cations, which overlay information on a display of the current environment.
It is difficult to imagine how equivalent applications could be developed on
traditionallaptopordesktopcomputersystems.
To provide access to on-line services, mobile devices typically use either
IEEEstandard802.11wirelessorcellulardatanetworks.Thememorycapacity
andprocessingspeedofmobiledevices,however,aremorelimitedthanthose
of PCs. Whereas a smartphone or tablet may have 256 GB in storage, it is not
uncommon to find 8 TB in storage on a desktop computer. Similarly, because
powerconsumptionissuchaconcern,mobiledevicesoftenuseprocessorsthat
aresmaller,areslower,andofferfewerprocessingcoresthanprocessorsfound
ontraditionaldesktopandlaptopcomputers.
Twooperatingsystemscurrentlydominatemobilecomputing:AppleiOS
and Google Android. iOS was designed to run on Apple iPhone and iPad
mobiledevices.Androidpowerssmartphonesandtabletcomputersavailable
frommanymanufacturers.Weexaminethesetwomobileoperatingsystemsin
furtherdetailinChapter2.
1.10.3 Client–Server Computing
Contemporary network architecture features arrangements in which server
systemssatisfyrequestsgeneratedbyclientsystems.Thisformofspecialized
distributed system, called a client–server system, has the general structure
depictedinFigure1.22.
Server systems can be broadly categorized as compute servers and file
servers:
• The compute-server system provides an interface to which a client can
sendarequesttoperformanaction(forexample,readdata).Inresponse,
theserverexecutestheactionandsendstheresultstotheclient.Aserver
client
desktop
client
server network
laptop
client
smartphone
Figure1.22 Generalstructureofaclient–serversystem.1.10 ComputingEnvironments 43
runningadatabasethatrespondstoclientrequestsfordataisanexample
ofsuchasystem.
• The file-serve system provides a file-system interface where clients can
create, update, read, and delete files. An example of such a system is a
webserverthatdeliversfilestoclientsrunningwebbrowsers.Theactual
contents of the files can vary greatly,ranging from traditional web pages
torichmultimediacontentsuchashigh-definitionvideo.
1.10.4 Peer-to-Peer Computing
Another structure for a distributed system is the peer-to-peer (P2P) system
model. In this model, clients and servers are not distinguished from one
another. Instead, all nodes within the system are considered peers, and each
mayactaseitheraclientoraserver,dependingonwhetheritisrequestingor
providing a service. Peer-to-peer systems offer an advantage over traditional
client–serversystems.Inaclient–serversystem,theserverisabottleneck;but
inapeer-to-peersystem,servicescanbeprovidedbyseveralnodesdistributed
throughoutthenetwork.
Toparticipateinapeer-to-peersystem,anodemustfirstjointhenetwork
ofpeers.Onceanodehas joinedthenetwork,itcanbeginprovidingservices
to—andrequestingservicesfrom—othernodesinthenetwork.Determining
whatservicesareavailableisaccomplishedinoneoftwogeneralways:
• When a node joins a network, it registers its service with a centralized
lookup service on the network. Any node desiring a specific service first
contactsthiscentralizedlookupservicetodeterminewhichnodeprovides
theservice.Theremainderofthecommunicationtakesplacebetweenthe
clientandtheserviceprovider.
• Analternativeschemeusesnocentralizedlookupservice.Instead,apeer
acting as a client must discover what node provides a desiredservice by
broadcasting a request for the service to all other nodes in the network.
The node (or nodes) providing that service responds to the peer making
the request. To support this approach, a discovery protocol must be pro-
videdthatallowspeerstodiscoverservicesprovidedbyotherpeersinthe
network.Figure1.23illustratessuchascenario.
Peer-to-peernetworksgainedwidespreadpopularityinthelate1990swith
severalfile-sharingservices,suchasNapsterandGnutella,thatenabledpeers
toexchangefileswithoneanother.TheNapstersystemusedanapproachsimi-
lartothefirsttypedescribedabove:acentralizedservermaintainedanindexof
allfilesstoredonpeernodesintheNapsternetwork,andtheactualexchange
of files took place between the peer nodes. The Gnutella system used a tech-
niquesimilartothesecondtype:aclientbroadcastfilerequeststoothernodes
inthe system,and nodes that could servicethe requestrespondeddirectlyto
the client. Peer-to-peer networks can be used to exchange copyrighted mate-
rials (music, for example) anonymously, and there are laws governing the
distribution of copyrighted material. Notably, Napster ran into legal trouble
for copyright infringement, and its services were shut down in 2001. For this
reason,thefutureofexchangingfilesremainsuncertain.44 Chapter1 Introduction
client
client client
client client
Figure1.23 Peer-to-peersystemwithnocentralizedservice.
Skype is another example of peer-to-peer computing. It allows clients to
make voice calls and video calls and to send text messages over the Internet
using a technology known as voice over IP (VoIP). Skype uses a hybrid peer-
to-peerapproach.Itincludesacentralizedloginserver,butitalsoincorporates
decentralizedpeersandallowstwopeerstocommunicate.
1.10.5 Cloud Computing
Cloud computing is a type of computing that delivers computing, storage,
and even applications as a service across a network. In some ways, it’s a
logical extension of virtualization, because it uses virtualization as a base for
itsfunctionality.Forexample,theAmazonElasticComputeCloud(ec2)facility
hasthousandsofservers,millionsofvirtualmachines,andpetabytesofstorage
available for use by anyone on the Internet. Users pay per month based on
howmuchofthoseresourcestheyuse.Thereareactuallymanytypesofcloud
computing,includingthefollowing:
• Publiccloud—acloudavailableviatheInternettoanyonewillingtopay
fortheservices
• Privatecloud—acloudrunbyacompanyforthatcompany’sownuse
• Hybridcloud—acloudthatincludesbothpublicandprivatecloudcom-
ponents
• Software as a service (SaaS)—one or more applications (such as word
processorsorspreadsheets)availableviatheInternet
• Platform as a service (PaaS)—a software stack ready for application use
viatheInternet(forexample,adatabaseserver)
• Infrastructure as a service (IaaS)—servers or storage available over the
Internet(forexample,storageavailableformakingbackupcopiesofpro-
ductiondata)1.10 ComputingEnvironments 45
Internet
customer
requests
cloud
firewall customer
interface
load balancer cloud
management
commands
virtual virtual storage cloud
machines machines managment
services
servers servers
Figure1.24 Cloudcomputing.
Thesecloud-computingtypesarenotdiscrete,asacloudcomputingenviron-
mentmay provideacombination ofseveraltypes.For example,an organiza-
tionmayprovidebothSaaSandIaaSaspubliclyavailableservices.
Certainly,therearetraditionaloperatingsystemswithinmanyofthetypes
of cloud infrastructure. Beyond those are the VMMs that manage the virtual
machines inwhich the userprocessesrun.Atahigherlevel,theVMMs them-
selves are managed by cloud management tools, such as VMware vCloud
Director and the open-source Eucalyptus toolset. These tools manage the
resourceswithinagivencloudandprovideinterfacestothecloudcomponents,
makingagoodargumentforconsideringthemanewtypeofoperatingsystem.
Figure 1.24 illustrates a public cloud providing IaaS. Notice that both the
cloudservicesandtheclouduserinterfaceareprotectedbyafirewall.
1.10.6 Real-Time Embedded Systems
Embeddedcomputersarethemostprevalentformofcomputersinexistence.
These devices are found everywhere, from car engines and manufacturing
robotstoopticaldrivesandmicrowaveovens.Theytendtohaveveryspecific
tasks. The systems they run on are usually primitive, and so the operating
systemsprovidelimitedfeatures.Usually,theyhavelittleornouserinterface,
preferring to spend their time monitoring and managing hardware devices,
suchasautomobileenginesandroboticarms.
These embedded systems vary considerably. Some are general-purpose
computers, running standard operating systems—such as Linux—with
special-purpose applications to implement the functionality. Others are
hardware devices with a special-purpose embedded operating system
providing just the functionality desired. Yet others are hardware devices46 Chapter1 Introduction
with application-specific integrated circuits (ASICs) that perform their tasks
withoutanoperatingsystem.
The use of embedded systems continues to expand. The power of these
devices,bothasstandaloneunitsandaselementsofnetworksandtheweb,is
suretoincreaseaswell.Evennow,entirehousescanbecomputerized,sothata
centralcomputer—eitherageneral-purposecomputeroranembeddedsystem
—can control heating and lighting, alarm systems, and even coffee makers.
Web access can enable a home owner to tell the house to heat up before she
arriveshome.Someday,therefrigeratorwillbeabletonotifythegrocerystore
whenitnoticesthemilkisgone.
Embeddedsystemsalmostalwaysrunreal-timeoperatingsystems.Areal-
time system is used when rigid time requirements have been placed on the
operationofaprocessor or the flowofdata; thus, itis oftenusedas acontrol
deviceinadedicatedapplication.Sensorsbringdatatothecomputer.Thecom-
putermustanalyzethedataandpossiblyadjustcontrolstomodifythesensor
inputs.Systemsthatcontrolscientificexperiments,medicalimagingsystems,
industrialcontrolsystems,andcertaindisplaysystemsarereal-timesystems.
Some automobile-engine fuel-injection systems, home-appliance controllers,
andweaponsystemsarealsoreal-timesystems.
A real-time system has well-defined, fixed time constraints. Processing
must be done within the defined constraints, or the system will fail. For
instance, it would not do for a robot arm to be instructed to halt after it had
smashed into the car it was building. Areal-time system functions correctly
onlyifitreturnsthecorrectresultwithinitstimeconstraints.Contrastthissys-
temwithatraditionallaptopsystemwhereitisdesirable(butnotmandatory)
torespondquickly.
InChapter5,weconsidertheschedulingfacilityneededtoimplementreal-
time functionality in an operating system,and in Chapter 20 we describe the
real-timecomponentsofLinux.
1.11 Free and Open-Source Operating Systems
The study of operating systems has been made easier by the avail-
ability of a vast number of free software and open-source releases.
Both free operating systems and open-source operating systems
are available in source-code format rather than as compiled binary
code. Note, though, that free software and open-source software are
two different ideas championed by different groups of people (see
http://gnu.org/philosophy/open-source-misses-the-point.html/ for a
discussion on the topic). Free software (sometimes referred to as free/libre
software) not only makes source code available but also is licensed to allow
no-cost use, redistribution, and modification. Open-source software does
not necessarily offer such licensing. Thus, although all free software is open
source, some open-source software is not “free.” GNU/Linux is the most
famous open-source operating system, with some distributions free and
others open source only (http://www.gnu.org/distros/). Microsoft Windows
is a well-known example of the opposite closed-source approach. Windows
is proprietary software—Microsoft owns it, restricts its use, and carefully
protectsitssourcecode.Apple’smacOSoperatingsystemcomprisesahybrid1.11 FreeandOpen-SourceOperatingSystems 47
approach. It contains an open-source kernel named Darwin but includes
proprietary,closed-sourcecomponentsaswell.
Starting with the source code allows the programmer to produce binary
code that can be executed on a system. Doing the opposite—reverse engi-
neeringthesource codefromthebinaries—is quitealotofwork,and useful
items such as comments are never recovered.Learning operating systems by
examining the source code has other benefits as well. With the source code
in hand, a student can modify the operating system and then compile and
run the code to try out those changes, which is an excellent learning tool.
This text includes projects that involve modifying operating-system source
code,whilealsodescribingalgorithmsatahighleveltobesureallimportant
operating-systemtopicsarecovered.Throughoutthetext,weprovidepointers
toexamplesofopen-sourcecodefordeeperstudy.
There are many benefits to open-source operating systems, including a
communityofinterested(andusuallyunpaid)programmerswhocontributeto
thecodebyhelpingtowriteit,debugit,analyzeit,providesupport,andsug-
gest changes. Arguably, open-source code is more secure than closed-source
code because many more eyes are viewing the code. Certainly, open-source
code has bugs, but open-source advocates argue that bugs tend to be found
and fixed faster owing to the number of people using and viewing the code.
Companies that earn revenue from selling their programs often hesitate to
open-sourcetheircode,butRedHatandamyriadofothercompaniesaredoing
just that and showing that commercial companies benefit, rather than suffer,
whentheyopen-sourcetheircode.Revenuecanbegeneratedthroughsupport
contractsandthesaleofhardwareonwhichthesoftwareruns,forexample.
1.11.1 History
Intheearlydaysofmoderncomputing(thatis,the1950s),softwaregenerally
came with source code. The original hackers (computer enthusiasts) at MIT’s
TechModelRailroadClublefttheirprogramsindrawersforotherstoworkon.
“Homebrew” user groups exchanged code during their meetings. Company-
specificusergroups,suchasDigitalEquipmentCorporation’sDECUS,accepted
contributions of source-code programs, collected them onto tapes, and dis-
tributedthetapestointerestedmembers.In1970,Digital’soperatingsystems
weredistributedassourcecodewithnorestrictionsorcopyrightnotice.
Computer and software companies eventually sought to limit the use of
theirsoftwaretoauthorizedcomputersandpayingcustomers.Releasingonly
the binary files compiled from the source code, rather than the source code
itself,helpedthemtoachievethisgoal,aswellasprotectingtheircodeandtheir
ideasfromtheircompetitors.AlthoughtheHomebrewusergroupsofthe1970s
exchanged code during their meetings, the operating systems for hobbyist
machines(suchasCPM)wereproprietary.By1980,proprietarysoftwarewas
theusualcase.
1.11.2 Free Operating Systems
Tocounterthemovetolimitsoftwareuseandredistribution,RichardStallman
in 1984 started developing a free, UNIX-compatible operating system called
GNU(whichisarecursiveacronymfor“ GNU’sNotUnix!”).ToStallman,“free”
referstofreedomofuse,notprice.Thefree-softwaremovementdoesnotobject48 Chapter1 Introduction
totradingacopyforanamountofmoneybutholdsthatusersareentitledto
four certain freedoms: (1) to freely run the program, (2) to study and change
thesourcecode,andtogiveorsellcopieseither(3)withor(4)withoutchanges.
In1985,StallmanpublishedtheGNUManifesto,whicharguesthatallsoftware
should be free. He also formed the Free Software Foundation (FSF) with the
goalofencouragingtheuseanddevelopmentoffreesoftware.
The FSF uses the copyrights on its programs to implement “copyleft,” a
formoflicensinginventedbyStallman.Copyleftingaworkgivesanyonethat
possessesa copy of the work the four essentialfreedomsthat make the work
free,withtheconditionthatredistributionmustpreservethesefreedoms.The
GNU General Public License (GPL) is a common license under which free
software is released.Fundamentally,the GPLrequiresthat the source code be
distributedwithanybinariesandthatallcopies(includingmodifiedversions)
be releasedunder the same GPLlicense. The CreativeCommons “Attribution
Sharealike” license is also a copyleft license; “sharealike” is another way of
statingtheideaofcopyleft.
1.11.3 GNU/Linux
As an example of a free and open-source operating system, consider
GNU/Linux. By 1991, the GNU operating system was nearly complete. The
GNU Project had developed compilers, editors, utilities, libraries, and games
— whateverpartsitcouldnotfindelsewhere.However,theGNUkernelnever
became ready for prime time. In 1991, a student in Finland, Linus Torvalds,
released a rudimentary UNIX-like kernel using the GNU compilers and tools
and invited contributions worldwide. The advent of the Internet meant that
anyone interested could download the source code, modify it, and submit
changes to Torvalds. Releasing updates once a week allowed this so-called
“Linux” operating system to grow rapidly, enhanced by several thousand
programmers. In 1991, Linux was not free software, as its license permitted
only noncommercial redistribution. In 1992, however, Torvalds rereleased
Linux under the GPL, making it free software (and also, to use a term coined
later,“opensource”).
The resulting GNU/Linux operating system (with the kernel properly
called Linux but the full operating system including GNU tools called
GNU/Linux) has spawned hundreds of unique distributions, or custom
builds, of the system. Major distributions include Red Hat, SUSE, Fedora,
Debian, Slackware, and Ubuntu. Distributions vary in function, utility,
installed applications, hardware support, user interface, and purpose. For
example, Red Hat Enterprise Linux is geared to large commercial use.
PCLinuxOS is a live CD—an operating system that can be booted and run
from a CD-ROM without being installed on a system’s boot disk. Avariant of
PCLinuxOS—calledPCLinuxOSSupergamerDVD—isaliveDVDthatincludes
graphics drivers and games. A gamer can run it on any compatible system
simplyby booting from the DVD.When the gamer isfinished, areboot of the
systemresetsittoitsinstalledoperatingsystem.
You can run Linux on a Windows (or other) system using the following
simple,freeapproach:1.11 FreeandOpen-SourceOperatingSystems 49
1. DownloadthefreeVirtualboxVMMtoolfrom
https://www.virtualbox.org/
andinstallitonyoursystem.
2. Choose to install an operating system from scratch, based on an
installationimagelikeaCD,orchoosepre-builtoperating-systemimages
thatcanbeinstalledandrunmorequicklyfromasitelike
http://virtualboxes.org/images/
These images are preinstalled with operating systems and applications
andincludemanyflavorsofGNU/Linux.
3. BootthevirtualmachinewithinVirtualbox.
An alternative to using Virtualbox is to use the free program Qemu
(http://wiki.qemu.org/Download/), which includes the qemu-img command
forconvertingVirtualboximagestoQemuimagestoeasilyimportthem.
Withthistext,weprovideavirtualmachineimageofGNU/Linuxrunning
theUbunturelease.ThisimagecontainstheGNU/Linuxsourcecodeaswellas
toolsforsoftwaredevelopment.WecoverexamplesinvolvingtheGNU/Linux
imagethroughoutthistext,aswellasinadetailedcasestudyinChapter20.
1.11.4 BSD UNIX
BSDUNIXhasalongerandmorecomplicatedhistorythanLinux.Itstartedin
1978asaderivativeofAT&T’sUNIX.ReleasesfromtheUniversityofCalifornia
at Berkeley (UCB) came in source and binary form, but they were not open
sourcebecausealicensefromAT&Twasrequired.BSDUNIX’sdevelopmentwas
slowed by a lawsuit by AT&T, but eventually a fully functional, open-source
version,4.4BSD-lite,wasreleasedin1994.
Just as with Linux, there are many distributions of BSD UNIX, including
FreeBSD, NetBSD, OpenBSD, and DragonflyBSD. To explore the source code
of FreeBSD, simply download the virtual machine image of the version of
interest and boot it within Virtualbox, as described above for Linux. The
source code comes with the distribution and is stored in /usr/src/. The
kernel source code is in /usr/src/sys. For example, to examine the vir-
tual memory implementation code in the FreeBSD kernel, see the files in
/usr/src/sys/vm.Alternatively,youcansimplyviewthesourcecodeonline
athttps://svnweb.freebsd.org.
As with many open-source projects, this source code is contained in
and controlled by a version control system—in this case, “subversion”
(https://subversion.apache.org/source-code).Versioncontrol systems allow
a user to “pull” an entire source code tree to his computer and “push” any
changes back into the repository for others to then pull. These systems also
provide other features, including an entire history of each file and a conflict
resolution feature in case the same file is changed concurrently. Another50 Chapter1 Introduction
version control system is git, which is used for GNU/Linux, as well as other
programs(http://www.git-scm.com).
Darwin, the core kernel component of macOS, is based on BSD
UNIX and is open-sourced as well. That source code is available from
http://www.opensource.apple.com/.EverymacOSreleasehasitsopen-source
components posted at that site. The name of the package that contains the
kernel begins with “xnu.” Apple also provides extensive developer tools,
documentation,andsupportathttp://developer.apple.com.
THESTUDYOFOPERATINGSYSTEMS
There has never been a more interesting time to study operating systems,
andithasneverbeeneasier.Theopen-sourcemovementhasovertakenoper-
atingsystems,causingmanyofthemtobemadeavailableinbothsourceand
binary (executable) format. The list of operating systems available in both
formatsincludesLinux,BSDUNIX,Solaris,andpartofmacOS.Theavailabil-
ityofsourcecodeallowsustostudyoperatingsystemsfromtheinsideout.
Questions that we could once answer only by looking at documentation or
the behavior of an operating system we can now answer by examining the
codeitself.
Operating systems that are no longer commercially viable have been
open-sourced as well, enabling us to study how systems operated in a
time of fewer CPU, memory, and storage resources. An extensive but
incomplete list of open-source operating-system projects is available from
http://dmoz.org/Computers/Software/Operating Systems/Open Source/.
Inaddition,theriseofvirtualizationasamainstream(andfrequentlyfree)
computerfunctionmakesitpossibletorunmanyoperatingsystemsontop
ofone coresystem. For example,VMware (http://www.vmware.com)pro-
videsafree“player”forWindowsonwhichhundredsoffree“virtualappli-
ances” can run. Virtualbox (http://www.virtualbox.com) provides a free,
open-source virtual machine manager on many operating systems. Using
suchtools,studentscantryouthundredsofoperatingsystemswithoutded-
icatedhardware.
In some cases, simulators of specific hardware are also available, allow-
ing the operating system to run on “native” hardware, all within the con-
fines of a modern computer and modern operating system. For example,
a DECSYSTEM-20 simulator running on macOS can boot TOPS-20, load the
source tapes, and modify and compile a new TOPS-20 kernel.An interested
student can search the Internetto find the original papers that describe the
operatingsystem,aswellastheoriginalmanuals.
The advent of open-source operating systems has also made it easier to
make the move from student to operating-system developer. With some
knowledge,someeffort,andanInternetconnection,astudentcanevencreate
anewoperating-systemdistribution.Notsomanyyearsago,itwasdifficult
orimpossibletogetaccesstosourcecode.Now,such accessislimitedonly
byhowmuchinterest,time,anddiskspaceastudenthas.1.12 Summary 51
1.11.5 Solaris
SolarisisthecommercialUNIX-basedoperatingsystemofSunMicrosystems.
Originally,Sun’sSunOSoperatingsystemwasbasedonBSDUNIX.Sunmoved
to AT&T’s SystemV UNIX as its base in 1991. In 2005, Sun open-sourced most
ofthe Solariscodeas theOpenSolarisproject.The purchase of Sunby Oracle
in2009,however,leftthestateofthisprojectunclear.
SeveralgroupsinterestedinusingOpenSolarishaveexpandeditsfeatures,
andtheirworkingsetisProjectIllumos,whichhasexpandedfromtheOpen-
Solarisbasetoincludemorefeaturesandtobethebasisforseveralproducts.
Illumosisavailableathttp://wiki.illumos.org.
1.11.6 Open-Source Systems as Learning Tools
The free-software movement is driving legions of programmers to create
thousands of open-source projects, including operating systems. Sites like
http://freshmeat.net/andhttp://distrowatch.com/provideportalstomanyof
these projects. As we stated earlier, open-source projects enable students to
usesource code as alearning tool. They can modifyprograms and testthem,
helpfindandfixbugs,andotherwiseexploremature,full-featuredoperating
systems, compilers, tools, user interfaces, and other types of programs. The
availability of source code for historic projects, such as Multics, can help stu-
dentstounderstandthoseprojectsandtobuildknowledgethatwillhelpinthe
implementationofnewprojects.
Anotheradvantageofworkingwithopen-sourceoperatingsystemsistheir
diversity.GNU/Linux and BSDUNIX are both open-source operating systems,
forinstance,buteachhasitsowngoals,utility,licensing,andpurpose.Some-
times,licensesarenotmutuallyexclusiveandcross-pollinationoccurs,allow-
ing rapid improvements in operating-system projects. For example, several
majorcomponentsofOpenSolarishavebeenportedtoBSDUNIX.Theadvan-
tages of free software and open sourcing are likely to increase the number
and quality of open-source projects, leading to an increase in the number of
individualsandcompaniesthatusetheseprojects.
1.12 Summary
• Anoperatingsystemissoftwarethatmanagesthecomputerhardware,as
wellasprovidinganenvironmentforapplicationprogramstorun.
• Interrupts are a key way in which hardware interacts with the operating
system.Ahardwaredevicetriggersaninterruptbysendingasignaltothe
CPU to alert the CPU that some event requires attention. The interrupt is
managedbytheinterrupthandler.
• Foracomputertodoitsjobofexecutingprograms,theprogramsmustbe
in main memory, which is the only large storage area that the processor
canaccessdirectly.
• Themainmemoryisusuallyavolatilestoragedevicethatlosesitscontents
whenpoweristurnedofforlost.52 Chapter1 Introduction
• Nonvolatile storage is an extension of main memory and is capable of
holdinglargequantitiesofdatapermanently.
• The most common nonvolatile storage device is a hard disk, which can
providestorageofbothprogramsanddata.
• Thewidevarietyofstoragesystemsinacomputersystemcanbeorganized
inahierarchyaccordingtospeedandcost.Thehigherlevelsareexpensive,
buttheyarefast.Aswemovedownthehierarchy,thecostperbitgenerally
decreases,whereastheaccesstimegenerallyincreases.
• Moderncomputerarchitecturesaremultiprocessorsystemsinwhicheach
CPUcontainsseveralcomputingcores.
• TobestutilizetheCPU,modernoperatingsystemsemploymultiprogram-
ming, which allows several jobs to be in memory at the same time, thus
ensuringthattheCPUalwayshasajobtoexecute.
• MultitaskingisanextensionofmultiprogrammingwhereinCPUschedul-
ing algorithms rapidlyswitch betweenprocesses,providingusers witha
fastresponsetime.
• To prevent user programs from interfering with the proper operation of
the system, the system hardware has two modes: user mode and kernel
mode.
• Various instructions are privileged and can be executed only in kernel
mode. Examples include the instruction to switch to kernel mode, I/O
control,timermanagement,andinterruptmanagement.
• A process is the fundamental unit of work in an operating system. Pro-
cessmanagementincludescreatinganddeletingprocessesandproviding
mechanisms for processes to communicate and synchronize with each
other.
• Anoperatingsystemmanagesmemorybykeepingtrackofwhatpartsof
memory are being used and by whom. It is also responsible for dynami-
callyallocatingandfreeingmemoryspace.
• Storagespaceismanagedbytheoperatingsystem;thisincludesproviding
filesystemsfor representingfilesanddirectoriesandmanaging spaceon
mass-storagedevices.
• Operating systems provide mechanisms for protecting and securing the
operating system and users. Protection measures control the access of
processesoruserstotheresourcesmadeavailablebythecomputersystem.
• Virtualization involves abstracting a computer’s hardware into several
differentexecutionenvironments.
• Datastructures that are usedin an operating systeminclude lists,stacks,
queues,trees,andmaps.
• Computingtakesplaceinavarietyofenvironments,includingtraditional
computing, mobile computing, client–server systems, peer-to-peer sys-
tems,cloudcomputing,andreal-timeembeddedsystems.PracticeExercises 53
• Freeand open-sourceoperatingsystemsareavailableinsource-codefor-
mat. Free software is licensed to allow no-cost use, redistribution, and
modification. GNU/Linux, FreeBSD, and Solaris are examples of popular
open-sourcesystems.
Practice Exercises
1.1 Whatarethethreemainpurposesofanoperatingsystem?
1.2 Wehavestressedtheneedforanoperatingsystemtomakeefficientuse
of the computing hardware. When is it appropriate for the operating
systemtoforsake thisprincipleand to“waste” resources?Why issuch
asystemnotreallywasteful?
1.3 Whatisthemaindifficultythataprogrammermustovercomeinwriting
anoperatingsystemforareal-timeenvironment?
1.4 Keeping in mind the various definitions of operating system, consider
whethertheoperatingsystemshouldincludeapplicationssuchasweb
browsers and mail programs. Argue both that it should and that it
shouldnot,andsupportyouranswers.
1.5 Howdoesthedistinctionbetweenkernelmodeandusermodefunction
asarudimentaryformofprotection(security)?
1.6 Whichofthefollowinginstructionsshouldbeprivileged?
a. Setvalueoftimer.
b. Readtheclock.
c. Clearmemory.
d. Issueatrapinstruction.
e. Turnoffinterrupts.
f. Modifyentriesindevice-statustable.
g. Switchfromusertokernelmode.
h. AccessI/Odevice.
1.7 Some early computers protected the operating system by placing it in
amemorypartitionthatcouldnotbemodifiedbyeithertheuserjobor
theoperatingsystemitself.Describetwodifficultiesthatyouthinkcould
arisewithsuchascheme.
1.8 SomeCPUsprovideformorethantwomodesofoperation.Whataretwo
possibleusesofthesemultiplemodes?
1.9 Timers could be used to compute the current time. Provide a short
descriptionofhowthiscouldbeaccomplished.
1.10 Givetworeasonswhycachesareuseful.Whatproblemsdotheysolve?
What problems do they cause? If a cache can be made as large as the54 Chapter1 Introduction
device for which it is caching (for instance, a cache as large as a disk),
whynotmakeitthatlargeandeliminatethedevice?
1.11 Distinguish between the client–server and peer-to-peer models of dis-
tributedsystems.
Further Reading
Many generaltextbooks cover operating systems,including [Stallings (2017)]
and[Tanenbaum(2014)].[HennessyandPatterson(2012)]providecoverageof
I/Osystemsandbusesandofsystemarchitectureingeneral.[KuroseandRoss
(2017)]providesageneraloverviewofcomputernetworks.
[Russinovichetal.(2017)]giveanoverviewofMicrosoftWindowsandcov-
ers considerable technical detail about the system internals and components.
[McDougall and Mauro (2007)] cover the internals of the Solaris operating
system. The macOS and iOS internals are discussed in [Levin (2013)]. [Levin
(2015)]coverstheinternalsofAndroid.[Love(2010)]providesanoverviewof
theLinuxoperatingsystemandgreatdetailaboutdatastructuresusedinthe
Linux kernel. The Free Software Foundation has published its philosophy at
http://www.gnu.org/philosophy/free-software-for-freedom.html.
Bibliography
[HennessyandPatterson(2012)] J.HennessyandD.Patterson,ComputerArchi-
tecture:AQuantitativeApproach,FifthEdition,MorganKaufmann(2012).
[KuroseandRoss(2017)] J.KuroseandK.Ross,ComputerNetworking—ATop–
DownApproach,SeventhEdition,Addison-Wesley(2017).
[Levin(2013)] J. Levin, Mac OS X and iOS Internals to the Apple’s Core, Wiley
(2013).
[Levin(2015)] J. Levin, Android Internals–A Confectioner’s Cookbook. Volume I
(2015).
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[McDougallandMauro(2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition,PrenticeHall(2007).
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).
[Stallings(2017)] W.Stallings,OperatingSystems,InternalsandDesignPrinciples
(9thEdition)NinthEdition,PrenticeHall(2017).
[Tanenbaum(2014)] A.S.Tanenbaum,ModernOperatingSystems,PrenticeHall
(2014).Chapter 1 Exercises
1.12 Howdoclusteredsystemsdifferfrommultiprocessorsystems?Whatis
requiredfortwomachinesbelongingtoaclustertocooperatetoprovide
ahighlyavailableservice?
1.13 Consider a computing cluster consisting of two nodes running a
database.Describetwowaysinwhichtheclustersoftwarecanmanage
access to the data on the disk. Discuss the benefits and disadvantages
ofeach.
1.14 Whatisthepurposeofinterrupts?Howdoesaninterruptdifferfroma
trap?Cantrapsbegeneratedintentionallybyauserprogram?Ifso,for
whatpurpose?
1.15 ExplainhowtheLinuxkernelvariablesHZandjiffiescanbeusedto
determinethe number of seconds the system has been running since it
wasbooted.
1.16 Direct memory access is used for high-speed I/O devices in order to
avoidincreasingtheCPU’sexecutionload.
a. How does the CPU interface with the device to coordinate the
transfer?
b. How does the CPU know when the memory operations are com-
plete?
c. The CPU is allowed to execute other programs while the DMA
controller is transferring data. Does this process interfere with
the execution of the user programs? If so, describe what forms of
interferencearecaused.
1.17 Somecomputersystemsdonotprovideaprivilegedmodeofoperation
in hardware. Is it possible to construct a secure operating system for
these computer systems? Give arguments both that it is and that it is
notpossible.
1.18 Many SMP systems have different levels of caches; one level is local to
eachprocessingcore,and another levelisshared amongall processing
cores.Whyarecachingsystemsdesignedthisway?
1.19 Rankthefollowingstoragesystemsfromslowesttofastest:
a. Hard-diskdrives
b. Registers
c. Opticaldisk
d. Mainmemory
e. Nonvolatilememory
f. Magnetictapes
g. Cache
EX-1EX-2 Exercises
1.20 ConsideranSMPsystemsimilartotheoneshowninFigure1.8.Illustrate
with an example how data residing in memory could in fact have a
differentvalueineachofthelocalcaches.
1.21 Discuss, with examples, how the problem of maintaining coherence of
cacheddatamanifestsitselfinthefollowingprocessingenvironments:
a. Single-processorsystems
b. Multiprocessorsystems
c. Distributedsystems
1.22 Describe a mechanism for enforcing memory protection in order to
prevent a program from modifying the memory associated with other
programs.
1.23 Which networkconfiguration—LAN or WAN—would bestsuitthe fol-
lowingenvironments?
a. Acampusstudentunion
b. Severalcampuslocationsacrossastatewideuniversitysystem
c. Aneighborhood
1.24 Describe some of the challenges of designing operating systems for
mobile devices compared with designing operating systems for tradi-
tionalPCs.
1.25 What are some advantages of peer-to-peer systems over client–server
systems?
1.26 Describesomedistributedapplicationsthatwouldbeappropriatefora
peer-to-peersystem.
1.27 Identify several advantages and several disadvantages of open-source
operating systems. Identify the types of people who would find each
aspecttobeanadvantageoradisadvantage.Operating -
2
CHAPTER
System
Structures
An operating system provides the environment within which programs are
executed.Internally,operatingsystemsvarygreatlyintheirmakeup,sincethey
areorganizedalongmanydifferentlines.Thedesignofanewoperatingsystem
is a major task. It is important that the goals of the system be well defined
beforethedesignbegins.Thesegoalsformthebasisforchoicesamongvarious
algorithmsandstrategies.
We can viewan operating system from several vantage points. One view
focusesontheservicesthatthesystemprovides;another,ontheinterfacethat
it makesavailable tousers and programmers;a third,on its components and
theirinterconnections.Inthischapter,weexploreallthreeaspectsofoperating
systems,showingtheviewpointsofusers,programmers,andoperatingsystem
designers.Weconsiderwhatservicesanoperatingsystemprovides,howthey
are provided, how they are debugged, and what the various methodologies
are for designing such systems. Finally, we describe how operating systems
arecreatedandhowacomputerstartsitsoperatingsystem.
CHAPTER OBJECTIVES
• Identifyservicesprovidedbyanoperatingsystem.
(cid:129) Illustratehowsystemcallsareusedtoprovideoperatingsystemservices.
(cid:129) Compare and contrast monolithic, layered, microkernel, modular, and
hybridstrategiesfordesigningoperatingsystems.
(cid:129) Illustratetheprocessforbootinganoperatingsystem.
(cid:129) Applytoolsformonitoringoperatingsystemperformance.
(cid:129) DesignandimplementkernelmodulesforinteractingwithaLinuxkernel.
2.1 Operating-System Services
Anoperatingsystemprovidesanenvironmentfortheexecutionofprograms.
It makes certainservicesavailable to programs and to the users of those pro-
grams. The specific services provided, of course, differ from one operating
5556 Chapter2 Operating-SystemStructures
user and other system programs
GUI touch screen command line
user interfaces
system calls
program I/O file resource
communication accounting
execution operations systems allocation
protection
error
and
detection
security
services
operating system
hardware
Figure2.1 Aviewofoperatingsystemservices.
systemtoanother,butwecanidentifycommonclasses.Figure2.1showsone
viewofthevariousoperating-systemservicesandhowtheyinterrelate.Note
thattheseservicesalsomaketheprogrammingtaskeasierfortheprogrammer.
Onesetofoperatingsystemservicesprovidesfunctionsthatarehelpfulto
theuser.
• User interface. Almost all operating systems have a user interface (UI).
This interface can take several forms. Most commonly, a graphical user
interface (GUI) is used. Here, the interface is a window system with a
mousethat servesas apointing devicetodirectI/O,choose frommenus,
and make selections and a keyboard to enter text. Mobile systems such
asphonesandtabletsprovideatouch-screeninterface,enablingusersto
slidetheirfingersacrossthescreenorpressbuttonsonthescreentoselect
choices.Anotheroptionisacommand-lineinterface(CLI),whichusestext
commands and a method for entering them (say, a keyboard for typing
in commands in a specific format with specific options). Some systems
providetwoorallthreeofthesevariations.
• Programexecution.Thesystemmustbeabletoloadaprogramintomem-
oryandtorunthatprogram.Theprogrammustbeabletoenditsexecu-
tion,eithernormallyorabnormally(indicatingerror).
• I/Ooperations.ArunningprogrammayrequireI/O,whichmayinvolvea
fileoranI/Odevice.Forspecificdevices,specialfunctionsmaybedesired
(suchasreadingfromanetworkinterfaceorwritingtoafilesystem).For
efficiencyandprotection,usersusuallycannotcontrolI/Odevicesdirectly.
Therefore,theoperatingsystemmustprovideameanstodoI/O.
• File-system manipulation.The file systemis of particular interest.Obvi-
ously,programsneedtoreadandwritefilesanddirectories.Theyalsoneed
tocreateanddeletethembyname,searchforagivenfile,andlistfileinfor-
mation.Finally,someoperatingsystemsincludepermissionsmanagement
toallowordenyaccesstofilesordirectoriesbasedonfileownership.Many
operating systems provide a variety of file systems, sometimes to allow2.1 Operating-SystemServices 57
personalchoiceandsometimestoprovidespecificfeaturesorperformance
characteristics.
• Communications. There are many circumstances in which one process
needstoexchangeinformationwithanotherprocess.Suchcommunication
may occur between processes that are executing on the same computer
or between processes that are executing on different computer systems
tied together by a network. Communications may be implemented via
sharedmemory,inwhichtwoormoreprocessesreadandwritetoashared
sectionofmemory,ormessagepassing,inwhichpacketsofinformationin
predefinedformatsaremovedbetweenprocessesbytheoperatingsystem.
• Errordetection.Theoperatingsystemneedstobedetectingandcorrecting
errorsconstantly.ErrorsmayoccurintheCPUandmemoryhardware(such
asamemoryerrororapowerfailure),inI/Odevices(suchasaparityerror
ondisk,aconnectionfailureonanetwork,orlackofpaperintheprinter),
andintheuserprogram(suchasanarithmeticoverfloworanattemptto
access an illegal memory location). For each type of error, the operating
systemshouldtaketheappropriateactiontoensurecorrectandconsistent
computing. Sometimes, it has no choice but to halt the system. At other
times,itmightterminateanerror-causingprocessorreturnanerrorcode
toaprocessfortheprocesstodetectandpossiblycorrect.
Another set of operating-system functions exists not for helping the user
but rather for ensuring the efficient operation of the system itself. Systems
withmultipleprocessescangainefficiencybysharingthecomputerresources
amongthedifferentprocesses.
• Resource allocation. When there are multiple processes running at the
same time, resources must be allocated to each of them. The operating
system manages many different types of resources. Some (such as CPU
cycles, main memory, and file storage) may have special allocation code,
whereasothers(suchasI/Odevices)mayhavemuchmoregeneralrequest
and release code. For instance, in determining how best to use the CPU,
operating systems have CPU-scheduling routines that take into account
the speed of the CPU, the process that must be executed, the number of
processingcoresontheCPU,andotherfactors.Theremayalsoberoutines
toallocateprinters,USBstoragedrives,andotherperipheraldevices.
• Logging. We want to keep track of which programs use how much and
what kinds of computer resources. This record keeping may be used for
accounting(sothatuserscanbebilled)orsimplyforaccumulatingusage
statistics.Usagestatisticsmaybeavaluabletoolforsystemadministrators
whowishtoreconfigurethesystemtoimprovecomputingservices.
• Protectionandsecurity.Theownersofinformationstoredinamultiuser
or networkedcomputer systemmay want tocontrol use of that informa-
tion.Whenseveralseparateprocessesexecuteconcurrently,itshouldnot
be possible for one process to interfere with the others or with the oper-
ating system itself. Protection involves ensuring that all access to system
resourcesiscontrolled.Securityofthesystemfromoutsidersisalsoimpor-
tant.Suchsecuritystartswithrequiringeachusertoauthenticatehimself58 Chapter2 Operating-SystemStructures
or herself to the system, usually by means of a password, to gain access
tosystemresources.ItextendstodefendingexternalI/Odevices,includ-
ingnetworkadapters,frominvalidaccessattemptsandrecordingallsuch
connections for detection of break-ins. If a system is to be protected and
secure, precautions must be instituted throughout it. A chain is only as
strongasitsweakestlink.
2.2 User and Operating-System Interface
We mentioned earlier that there are several ways for users to interface with
the operating system. Here, we discuss three fundamental approaches. One
providesacommand-lineinterface,orcommandinterpreter,thatallowsusers
todirectlyentercommandstobeperformedbytheoperatingsystem.Theother
two allow users to interface with the operating system via a graphical user
interface,orGUI.
2.2.1 Command Interpreters
Mostoperatingsystems,includingLinux,UNIX,andWindows,treatthecom-
mand interpreter as a special program that is running when a process is ini-
tiated or when a user first logs on (on interactive systems). On systems with
multiplecommandinterpreterstochoosefrom,theinterpretersareknownas
shells.Forexample,onUNIXandLinuxsystems,ausermaychooseamongsev-
eraldifferentshells,includingtheCshell,Bourne-Againshell,Kornshell,and
others.Third-partyshellsandfreeuser-writtenshellsarealsoavailable.Most
shells provide similar functionality, and a user’s choice of which shell to use
isgenerallybasedonpersonalpreference.Figure2.2showstheBourne-Again
(orbash)shellcommandinterpreterbeingusedonmacOS.
Themainfunctionofthecommandinterpreteristogetandexecutethenext
user-specifiedcommand. Many of the commands givenat this levelmanipu-
latefiles:create,delete,list,print,copy,execute,andsoon.Thevariousshells
availableonUNIXsystemsoperateinthisway.Thesecommandscanbeimple-
mentedintwogeneralways.
Inoneapproach, thecommandinterpreteritselfcontains thecodetoexe-
cute the command. For example, a command to delete a file may cause the
commandinterpretertojumptoasectionofitscodethatsetsuptheparameters
andmakestheappropriatesystemcall.Inthiscase,thenumberofcommands
that can be given determines the size of the command interpreter, since each
commandrequiresitsownimplementingcode.
Analternativeapproach—used byUNIX,amongotheroperatingsystems
—implements most commands through system programs. In this case, the
commandinterpreterdoesnotunderstandthecommandinanyway;itmerely
uses the command to identify a file to be loaded into memory and executed.
Thus,theUNIXcommandtodeleteafile
rm file.txt
wouldsearchforafilecalledrm,loadthefileintomemory,andexecuteitwith
theparameterfile.txt.Thelogicassociatedwiththermcommandwouldbe2.2 UserandOperating-SystemInterface 59
Figure2.2 ThebashshellcommandinterpreterinmacOS.
defined completely by the code in the file rm. In this way, programmers can
addnewcommandstothesystemeasilybycreatingnewfileswiththeproper
program logic. The command-interpreter program, which can be small, does
nothavetobechangedfornewcommandstobeadded.
2.2.2 Graphical User Interface
Asecondstrategyforinterfacingwiththeoperatingsystemisthroughauser-
friendlygraphicaluserinterface,orGUI.Here,ratherthanenteringcommands
directlyviaacommand-lineinterface,usersemployamouse-basedwindow-
and-menu system characterized by a desktop metaphor. The user moves the
mousetopositionitspointeronimages,oricons,onthescreen(thedesktop)
that represent programs, files, directories, and system functions. Depending
onthemousepointer’slocation,clicking abuttononthemousecaninvokea
program,selectafileordirectory—knownasafolder—orpulldownamenu
thatcontainscommands.
Graphical user interfaces first appeared due in part to research taking
placeintheearly1970satXeroxPARCresearchfacility.ThefirstGUIappeared
on the Xerox Alto computer in 1973. However, graphical interfaces became
morewidespreadwiththeadventofAppleMacintoshcomputersinthe1980s.
TheuserinterfacefortheMacintoshoperatingsystemhasundergonevarious
changes over the years, the most significant being the adoption of the Aqua
interface that appeared with macOS. Microsoft’s first version of Windows—
Version 1.0—was based on the addition of a GUI interface to the MS-DOS
operatingsystem.LaterversionsofWindowshavemadesignificantchangesin
theappearanceoftheGUIalongwithseveralenhancementsinitsfunctionality.60 Chapter2 Operating-SystemStructures
Traditionally,UNIXsystemshavebeendominatedbycommand-lineinter-
faces.VariousGUIinterfacesareavailable,however,withsignificantdevelop-
ment in GUI designs from various open-source projects, such as K Desktop
Environment (or KDE) and the GNOME desktop by the GNU project. Both the
KDE and GNOME desktops run on Linux and various UNIX systems and are
availableunderopen-sourcelicenses,whichmeanstheirsourcecodeisreadily
availableforreadingandformodificationunderspecificlicenseterms.
2.2.3 Touch-Screen Interface
Becauseaeitheracommand-lineinterfaceoramouse-and-keyboardsystemis
impractical for most mobile systems, smartphones and handheld tablet com-
puters typically use a touch-screen interface. Here, users interact by making
gestures on the touch screen—for example, pressing and swiping fingers
acrossthescreen.Althoughearliersmartphonesincludedaphysicalkeyboard,
most smartphones and tablets now simulate a keyboard on the touch screen.
Figure2.3illustratesthetouchscreenoftheAppleiPhone.BoththeiPadand
theiPhoneusetheSpringboardtouch-screeninterface.
2.2.4 Choice of Interface
The choice of whether to use a command-line or GUI interface is mostly
one of personal preference. System administrators who manage computers
and power users who have deep knowledge of a system frequently use the
Figure2.3 TheiPhonetouchscreen.2.2 UserandOperating-SystemInterface 61
command-lineinterface.Forthem,itismoreefficient,givingthemfasteraccess
totheactivitiestheyneedtoperform.Indeed,onsomesystems,onlyasubset
of system functions is available via the GUI, leaving the less common tasks
tothosewhoarecommand-lineknowledgeable.Further,command-lineinter-
facesusuallymakerepetitivetaskseasier,inpartbecausetheyhavetheirown
programmability. For example, if a frequent task requires a set of command-
line steps, those steps can be recorded into a file, and that file can be run
just like a program. The program is not compiled into executable code but
rather is interpreted by the command-line interface. These shell scripts are
very common on systems that are command-line oriented, such as UNIX and
Linux.
Incontrast,mostWindowsusersarehappytousetheWindowsGUIenvi-
ronmentandalmostneverusetheshellinterface.RecentversionsoftheWin-
dows operating system provide both a standard GUI for desktop and tradi-
tional laptops and a touch screenfor tablets.The variouschanges undergone
bytheMacintoshoperatingsystemsalsoprovideanicestudyincontrast.His-
torically,MacOShasnotprovidedacommand-lineinterface,alwaysrequiring
itsuserstointerfacewiththeoperatingsystemusingitsGUI.However,withthe
releaseofmacOS(whichisinpartimplementedusingaUNIXkernel),theoper-
ating system now providesboth an Aqua GUI and a command-line interface.
Figure2.4isascreenshotofthemacOSGUI.
Although there are apps that provide a command-line interface for iOS
and Android mobile systems, they are rarely used. Instead, almost all users
ofmobilesystemsinteractwiththeirdevicesusingthetouch-screeninterface.
The user interface can vary from system to system and even from user
to user within a system; however, it typically is substantially removed from
theactualsystemstructure.Thedesignofausefulandintuitiveuserinterface
is therefore not a direct function of the operating system. In this book, we
concentrate on the fundamental problems of providing adequate service to
Figure2.4 ThemacOSGUI.62 Chapter2 Operating-SystemStructures
user programs. From the point of view of the operating system, we do not
distinguishbetweenuserprogramsandsystemprograms.
2.3 System Calls
Systemcallsprovideaninterfacetotheservicesmadeavailablebyanoperat-
ing system. These calls are generally available as functions written in C and
C++, although certain low-level tasks (for example, tasks where hardware
must be accessed directly) may have to be written using assembly-language
instructions.
2.3.1 Example
Beforewediscusshowanoperatingsystemmakessystemcallsavailable,let’s
first use an example to illustrate how system calls are used: writing a simple
program to read data from one file and copy them to another file. The first
input that the program will need is the names of the two files: the input file
and the output file. These names can be specified in many ways, depending
ontheoperating-systemdesign.Oneapproachistopassthenamesofthetwo
filesaspartofthecommand—forexample,theUNIXcpcommand:
cp in.txt out.txt
Thiscommandcopiestheinputfilein.txttotheoutputfileout.txt.Asec-
ondapproachisfortheprogramtoasktheuserforthenames.Inaninteractive
system, this approach will require a sequence of system calls, first to write
a prompting message on the screen and then to read from the keyboard the
charactersthatdefinethetwofiles.Onmouse-basedandicon-basedsystems,
amenuoffilenamesisusuallydisplayedinawindow.Theusercanthenuse
the mouse to select the source name, and a window can be opened for the
destinationnametobespecified.ThissequencerequiresmanyI/Osystemcalls.
Once the two file names have been obtained, the program must open the
inputfileandcreateandopentheoutputfile.Eachoftheseoperationsrequires
another system call. Possible error conditions for each system call must be
handled. For example, when the program tries to open the input file, it may
findthatthereisnofileofthatnameorthatthefileisprotectedagainstaccess.
Inthesecases,theprogramshouldoutputanerrormessage(anothersequence
of system calls) and then terminate abnormally (another system call). If the
inputfileexists,thenwemustcreateanewoutputfile.Wemayfindthatthere
is already an output file with the same name. This situation may cause the
program to abort (a system call), or we may delete the existing file (another
systemcall)andcreateanewone(yetanothersystemcall).Anotheroption,in
aninteractivesystem,istoasktheuser(viaasequenceofsystemcallstooutput
the prompting message and to read the response from the terminal) whether
toreplacetheexistingfileortoaborttheprogram.
When both files are set up, we enter a loop that reads from the input
file (a system call) and writes to the output file (another system call). Each
readandwritemustreturnstatusinformationregardingvariouspossibleerror
conditions. On input, the program may find that the end of the file has been2.3 SystemCalls 63
source file destination file
Example System-Call Sequence
Acquire input file name
Write prompt to screen
Accept input
Acquire output file name
Write prompt to screen
Accept input
Open the input file
if file doesn't exist, abort
Create output file
if file exists, abort
Loop
Read from input file
Write to output file
Until read fails
Close output file
Write completion message to screen
Terminate normally
Figure2.5 Exampleofhowsystemcallsareused.
reachedorthattherewasahardwarefailureintheread(suchasaparityerror).
The write operation may encounter various errors, depending on the output
device(forexample,nomoreavailablediskspace).
Finally, after the entire file is copied, the program may close both files
(two system calls), write a message to the console or window (more system
calls), and finally terminate normally (the final system call). This system-call
sequenceisshowninFigure2.5.
2.3.2 Application Programming Interface
As you can see, even simple programs may make heavy use of the operat-
ingsystem.Frequently,systemsexecutethousandsofsystemcallspersecond.
Most programmers never see this level of detail, however. Typically, applica-
tion developers design programs according to an application programming
interface(API).TheAPIspecifiesasetoffunctionsthatareavailabletoanappli-
cationprogrammer,includingtheparametersthatarepassedtoeachfunction
andthereturnvaluestheprogrammercanexpect.Threeofthemostcommon
APIsavailabletoapplicationprogrammersaretheWindowsAPIforWindows
systems, the POSIX API for POSIX-based systems (which include virtually all
versions of UNIX, Linux, and macOS), and the Java API for programs that run
ontheJavavirtualmachine.AprogrammeraccessesanAPIviaalibraryofcode
providedbytheoperatingsystem.InthecaseofUNIXandLinuxforprograms
writtenintheClanguage,thelibraryiscalledlibc.Notethat—unlessspecified
—thesystem-callnamesusedthroughoutthistextaregenericexamples.Each
operatingsystemhasitsownnameforeachsystemcall.
Behindthescenes,thefunctionsthatmakeupanAPItypicallyinvokethe
actualsystemcallsonbehalfoftheapplicationprogrammer.Forexample,the
WindowsfunctionCreateProcess()(which,unsurprisingly,isusedtocreate64 Chapter2 Operating-SystemStructures
EXAMPLEOFSTANDARDAPI
AsanexampleofastandardAPI,considertheread()functionthatisavail-
able in UNIX andLinux systems. TheAPI forthis function is obtainedfrom
themanpagebyinvokingthecommand
man read
onthecommandline.AdescriptionofthisAPIappearsbelow:
#include <unistd.h>
ssize_t read(int fd, void *buf, size_t count)
return function parameters
value name
Aprogramthatusestheread()functionmustincludetheunistd.hheader
file, as this file defines the ssize t and size t data types (among other
things).Theparameterspassedtoread()areasfollows:
• int fd—thefiledescriptortoberead
• void *buf—abufferintowhichthedatawillberead
• size t count—the maximum number of bytes to be read into the
buffer
Onasuccessfulread,thenumberofbytesreadisreturned.Areturnvalueof
0indicatesendoffile.Ifanerroroccurs,read()returns−1.
a new process) actually invokes the NTCreateProcess() system call in the
Windowskernel.
Whywouldanapplicationprogrammerpreferprogrammingaccordingto
anAPIratherthaninvokingactualsystemcalls?Thereareseveralreasonsfor
doingso.Onebenefitconcerns programportability.Anapplicationprogram-
merdesigningaprogramusinganAPIcanexpectherprogramtocompileand
runonanysystemthatsupportsthesameAPI(although,inreality,architectural
differences often make this more difficult than it may appear). Furthermore,
actualsystemcallscanoftenbemoredetailedanddifficulttoworkwiththan
theAPIavailabletoanapplicationprogrammer.Nevertheless,thereoftenexists
astrongcorrelationbetweenafunctionintheAPIanditsassociatedsystemcall
withinthekernel.Infact,manyofthePOSIXandWindowsAPIsaresimilarto
thenativesystemcallsprovidedbytheUNIX,Linux,andWindowsoperating
systems.
Another important factor in handling system calls is the run-time envi-
ronment(RTE)—thefullsuiteofsoftwareneededtoexecuteapplicationswrit-
teninagivenprogramminglanguage,including itscompilersorinterpreters
as well as other software, such as libraries and loaders. The RTE provides a2.3 SystemCalls 65
user application
open( )
user
mode
system call interface
kernel
mode
open( )
Implementation
i of open( )
system call
return
Figure2.6 Thehandlingofauserapplicationinvokingtheopen()systemcall.
system-call interface that serves as the link to system calls made available
by theoperating system.The system-callinterfaceinterceptsfunction calls in
the API and invokes the necessary system calls within the operating system.
Typically, a number is associated with each system call, and the system-call
interface maintains a table indexed according to these numbers. The system-
call interface then invokes the intended system call in the operating-system
kernelandreturnsthestatusofthesystemcall.
The caller need know nothing about how the system call is implemented
orwhatitdoesduringexecution.Rather,thecallerneedonlyobeytheAPIand
understand what the operating system will do as a result of the execution of
that system call. Thus, most of the details of the operating-system interface
arehiddenfromtheprogrammerbytheAPIandaremanagedbytheRTE.The
relationshipamonganAPI,thesystem-callinterface,andtheoperatingsystem
is shown in Figure 2.6, which illustrates how the operating system handles a
userapplicationinvokingtheopen()systemcall.
System calls occur in different ways, depending on the computer in use.
Often, more information is required than simply the identity of the desired
system call. The exact type and amount of information vary according to the
particularoperatingsystemandcall.Forexample,togetinput,wemayneed
to specify the file or device to use as the source, as well as the address and
length of the memory buffer into which the input should be read. Of course,
thedeviceorfileandlengthmaybeimplicitinthecall.
Three general methods are used to pass parameters to the operating sys-
tem. The simplest approach is to pass the parameters in registers. In some
cases, however, there may be more parameters than registers. In these cases,
the parameters are generally stored in a block, or table, in memory, and the
addressof the block is passed as a parameter in a register (Figure 2.7). Linux
usesacombinationoftheseapproaches.Iftherearefiveorfewerparameters,66 Chapter2 Operating-SystemStructures
X
register
X: parameters
for call
use parameters code for
load address X from table X system
system call 13 call 13
user program
operating system
Figure2.7 Passingofparametersasatable.
registersareused.Iftherearemorethanfiveparameters,theblockmethodis
used.Parametersalsocanbeplaced,or pushed,ontoastack by theprogram
and popped off the stack by the operating system. Some operating systems
prefer the block or stack method because those approaches do not limit the
numberorlengthofparametersbeingpassed.
2.3.3 Types of System Calls
Systemcallscanbegroupedroughlyintosixmajorcategories:processcontrol,
fil management,devicemanagement,informationmaintenance,communi-
cations,andprotection.Below,webrieflydiscussthetypesofsystemcallsthat
maybeprovidedbyanoperatingsystem.Mostofthesesystemcallssupport,
or are supported by, concepts and functions that are discussed in later chap-
ters.Figure2.8summarizesthetypesofsystemcallsnormallyprovidedbyan
operatingsystem.Asmentioned,inthistext,wenormallyrefertothesystem
calls by generic names. Throughout the text, however, we provide examples
of the actual counterparts to the system calls for UNIX, Linux, and Windows
systems.
2.3.3.1 ProcessControl
A running program needs to be able to halt its execution either normally
(end()) or abnormally (abort()). If a system call is made to terminate the
currentlyrunningprogramabnormally,oriftheprogramrunsintoaproblem
and causes an error trap, a dump of memory is sometimes taken and an
error message generated. The dump is written to a special log file on disk
and may be examined by a debugger—a system program designed to aid
the programmer in finding and correcting errors, or bugs—to determine the
cause of the problem. Under either normal or abnormal circumstances, the
operatingsystemmusttransfercontrol tothe invokingcommand interpreter.
The command interpreter then reads the next command. In an interactive
system, the command interpreter simply continues with the next command;
it is assumed that the user will issue an appropriate command to respond to2.3 SystemCalls 67
• Processcontrol
◦
createprocess,terminateprocess
◦
load,execute
◦
getprocessattributes,setprocessattributes
◦
waitevent,signalevent
◦
allocateandfreememory
• Filemanagement
◦
createfile,deletefile
◦
open,close
◦
read,write,reposition
◦
getfileattributes,setfileattributes
• Devicemanagement
◦
requestdevice,releasedevice
◦
read,write,reposition
◦
getdeviceattributes,setdeviceattributes
◦
logicallyattachordetachdevices
• Informationmaintenance
◦
gettimeordate,settimeordate
◦
getsystemdata,setsystemdata
◦
getprocess,file,ordeviceattributes
◦
setprocess,file,ordeviceattributes
• Communications
◦
create,deletecommunicationconnection
◦
send,receivemessages
◦
transferstatusinformation
◦
attachordetachremotedevices
• Protection
◦
getfilepermissions
◦
setfilepermissions
Figure2.8 Typesofsystemcalls.68 Chapter2 Operating-SystemStructures
EXAMPLESOFWINDOWSANDUNIXSYSTEMCALLS
The following illustrates various equivalent system calls for Windows and
UNIXoperatingsystems.
Windows Unix
Process CreateProcess() fork()
control ExitProcess() exit()
WaitForSingleObject() wait()
File CreateFile() open()
management ReadFile() read()
WriteFile() write()
CloseHandle() close()
Device SetConsoleMode() ioctl()
management ReadConsole() read()
WriteConsole() write()
Information GetCurrentProcessID() getpid()
maintenance SetTimer() alarm()
Sleep() sleep()
Communications CreatePipe() pipe()
CreateFileMapping() shm open()
MapViewOfFile() mmap()
Protection SetFileSecurity() chmod()
InitlializeSecurityDescriptor() umask()
SetSecurityDescriptorGroup() chown()
anyerror.InaGUIsystem,apop-upwindowmightalerttheusertotheerror
andaskforguidance.Somesystemsmayallowforspecialrecoveryactionsin
case an erroroccurs. Ifthe programdiscoversan errorinits input and wants
toterminateabnormally,itmayalsowanttodefineanerrorlevel.Moresevere
errorscanbeindicatedbyahigher-levelerrorparameter.Itisthenpossibleto
combinenormalandabnormalterminationbydefininganormaltermination
asanerroratlevel0.Thecommandinterpreterorafollowingprogramcanuse
thiserrorleveltodeterminethenextactionautomatically.
A process executing one program may want to load() and execute()
another program. This feature allows the command interpreter to execute a
programasdirectedby,forexample,ausercommandortheclickofamouse.
An interesting question is where to return control when the loaded program
terminates. This question is related to whether the existing program is lost,
saved,orallowedtocontinueexecutionconcurrentlywiththenewprogram.
If control returns to the existing program when the new program termi-
nates,wemustsavethememoryimageoftheexistingprogram;thus,wehave2.3 SystemCalls 69
THESTANDARDCLIBRARY
The standard C library provides a portion of the system-call interface for
many versions of UNIX and Linux. As an example, let’s assume a C pro-
graminvokestheprintf()statement.TheClibraryinterceptsthiscalland
invokesthenecessarysystemcall(orcalls)intheoperatingsystem—inthis
instance,thewrite()systemcall.TheClibrarytakesthevaluereturnedby
write()andpassesitbacktotheuserprogram:
#include <stdio.h>
int main( )
{
(cid:129)
(cid:129)
(cid:129)
printf ("Greetings");
(cid:129)
(cid:129)
(cid:129)
return 0;
}
user
mode
standard C library
kernel
mode
write( )
write( )
system call
effectively created a mechanism for one program to call another program. If
both programs continue concurrently, we have created a new process to be
multiprogrammed. Often, there is a system call specifically for this purpose
(create process()).
If we createanewprocess,or perhaps evenasetof processes,we should
be able to control its execution. This control requires the ability to determine
and reset the attributes of a process, including the process’s priority,its max-
imumallowableexecutiontime,andsoon(get process attributes()and
set process attributes()). We may also want to terminate a process that
wecreated(terminate process())ifwefindthatitisincorrectorisnolonger
needed.
Having created new processes, we may need to wait for them to finish
their execution. We may want to wait for a certain amount of time to pass
(wait time()). More probably, we will want to wait for a specific event to
occur(wait event()).Theprocessesshouldthensignalwhenthateventhas
occurred(signal event()).
Quiteoften,twoormoreprocessesmaysharedata.Toensuretheintegrity
ofthedatabeingshared,operatingsystemsoftenprovidesystemcallsallowing70 Chapter2 Operating-SystemStructures
free memory
free memory
user
program
(sketch)
boot loader boot loader
(a) (b)
Figure2.9 Arduinoexecution.(a)Atsystemstartup.(b)Runningasketch.
aprocesstolockshareddata.Then,nootherprocesscanaccessthedatauntil
thelockisreleased.Typically,suchsystemcallsincludeacquire lock()and
release lock().Systemcallsofthesetypes,dealingwiththecoordinationof
concurrentprocesses,arediscussedingreatdetailinChapter6andChapter7.
There are so many facets of and variations in process control that we
nextusetwoexamples—oneinvolvingasingle-taskingsystemandtheother
a multitasking system—to clarify these concepts. The Arduino is a simple
hardware platform consisting of a microcontroller along with input sensors
thatrespondtoavarietyofevents,suchaschangestolight,temperature,and
barometricpressure,tojustnameafew.TowriteaprogramfortheArduino,we
firstwritetheprogramonaPCandthenuploadthecompiledprogram(known
asasketch)fromthePCtotheArduino’sflashmemoryviaaUSBconnection.
ThestandardArduinoplatformdoesnotprovideanoperatingsystem;instead,
asmallpieceofsoftwareknownasabootloaderloadsthesketchintoaspecific
regionintheArduino’smemory(Figure2.9).Oncethesketchhasbeenloaded,
itbeginsrunning,waitingfortheeventsthatitisprogrammedtorespondto.
Forexample,iftheArduino’stemperaturesensordetectsthatthetemperature
has exceeded a certain threshold, the sketch may have the Arduino start the
motor for a fan. An Arduino is considered a single-tasking system, as only
one sketch can be present in memory at a time; if another sketch is loaded,
it replaces the existing sketch. Furthermore, the Arduino provides no user
interfacebeyondhardwareinputsensors.
FreeBSD (derived from Berkeley UNIX) is an example of a multitasking
system. When a user logs on to the system, the shell of the user’s choice is
run, awaiting commands and running programs the user requests.However,
sinceFreeBSDisamultitaskingsystem,thecommandinterpretermaycontinue
running while another programis executed(Figure 2.10). To start a new pro-
cess, the shell executes a fork() system call. Then, the selected program is
loadedintomemoryviaanexec()systemcall,andtheprogramisexecuted.
Dependingonhowthecommandwasissued,theshelltheneitherwaitsforthe
processtofinishorrunstheprocess“inthebackground.”Inthelattercase,the
shellimmediatelywaitsforanothercommandtobeentered.Whenaprocessis
runninginthebackground,itcannotreceiveinputdirectlyfromthekeyboard,
because the shell is using this resource. I/O is therefore done through files or
through a GUI interface. Meanwhile, the user is free to ask the shell to run
otherprograms,tomonitortheprogressoftherunningprocess,tochangethat
program’spriority,andsoon.Whentheprocessisdone,itexecutesanexit()2.3 SystemCalls 71
high
memory kernel
free memory
process C
interpreter
process B
low
process D
memory
Figure2.10 FreeBSDrunningmultipleprograms.
systemcalltoterminate,returningtotheinvokingprocessastatuscodeof0or
anonzeroerrorcode.Thisstatusorerrorcodeisthenavailabletotheshellor
otherprograms.ProcessesarediscussedinChapter3withaprogramexample
usingthefork()andexec()systemcalls.
2.3.3.2 FileManagement
ThefilesystemisdiscussedinmoredetailinChapter13throughChapter15.
Here,weidentifyseveralcommonsystemcallsdealingwithfiles.
Wefirstneedtobeabletocreate()anddelete()files.Eithersystemcall
requires the name of the file and perhaps some of the file’s attributes. Once
the file is created, we need to open() it and to use it. We may also read(),
write(),orreposition()(rewindorskiptotheendofthefile,forexample).
Finally,weneedtoclose()thefile,indicatingthatwearenolongerusingit.
We may need these same sets of operations for directories if we have a
directorystructurefororganizingfilesinthefilesystem.Inaddition,foreither
files or directories, we need to be able to determine the values of various
attributesand perhaps to set them if necessary.File attributes include the file
name, filetype,protectioncodes, accounting information, and so on. At least
twosystemcalls,get file attributes()andset file attributes(),are
requiredfor this function. Some operating systems provide many more calls,
such as calls for file move() and copy(). Others might provide an API that
performsthoseoperationsusingcodeandothersystemcalls,andothersmight
provide system programs to perform the tasks. If the system programs are
callablebyotherprograms,theneachcanbeconsideredanAPIbyothersystem
programs.
2.3.3.3 DeviceManagement
Aprocessmayneedseveralresourcestoexecute—mainmemory,diskdrives,
accesstofiles,andsoon.Iftheresourcesareavailable,theycanbegranted,and
controlcanbereturnedtotheuserprocess.Otherwise,theprocesswillhaveto
waituntilsufficientresourcesareavailable.72 Chapter2 Operating-SystemStructures
The various resources controlled by the operating system can be thought
of as devices. Some of these devices are physical devices (for example, disk
drives), while others can be thought of as abstract or virtual devices (for
example,files).Asystemwithmultipleusersmayrequireustofirstrequest()
adevice,toensureexclusiveuseofit.Afterwearefinishedwiththedevice,we
release()it.Thesefunctions aresimilartothe open()and close()system
callsforfiles.Otheroperatingsystemsallowunmanagedaccesstodevices.The
hazardthenisthepotentialfordevicecontentionandperhapsdeadlock,which
aredescribedinChapter8.
Oncethedevicehasbeenrequested(andallocatedtous),wecanread(),
write(),and(possibly)reposition()thedevice,justaswecanwithfiles.In
fact,thesimilaritybetweenI/Odevicesandfilesissogreatthatmanyoperating
systems,includingUNIX,mergethetwointoacombinedfile–devicestructure.
Inthiscase,asetofsystemcallsisusedonbothfilesanddevices.Sometimes,
I/O devices are identified by special file names, directory placement, or file
attributes.
Theuserinterfacecanalsomakefilesanddevicesappeartobesimilar,even
though theunderlyingsystemcalls aredissimilar.Thisisanother exampleof
themanydesigndecisionsthatgointobuildinganoperatingsystemanduser
interface.
2.3.3.4 InformationMaintenance
Many system calls exist simply for the purpose of transferring information
between the user program and the operating system. For example, most sys-
temshaveasystemcalltoreturnthecurrenttime()anddate().Othersystem
callsmayreturninformationaboutthesystem,suchastheversionnumberof
theoperatingsystem,theamountoffreememoryordiskspace,andsoon.
Another set of system calls is helpful in debugging a program. Many
systems provide system calls to dump() memory. This provision is useful for
debugging. The program strace, which is available on Linux systems, lists
eachsystemcallasitisexecuted.EvenmicroprocessorsprovideaCPUmode,
known as single step, in which a trap is executed by the CPU after every
instruction.Thetrapisusuallycaughtbyadebugger.
Many operating systems provide a time profile of a program to indicate
the amount of time that the program executes at a particular location or set
of locations. A time profile requires either a tracing facility or regular timer
interrupts.Ateveryoccurrenceofthetimerinterrupt,thevalueoftheprogram
counter is recorded. With sufficiently frequent timer interrupts, a statistical
pictureofthetimespentonvariouspartsoftheprogramcanbeobtained.
Inaddition,theoperatingsystemkeepsinformationaboutallitsprocesses,
and system calls are used to access this information. Generally, calls are also
usedtogetandsettheprocessinformation(get process attributes()and
set process attributes()).InSection3.1.3,wediscusswhatinformationis
normallykept.
2.3.3.5 Communication
There are two common models of interprocess communication: the message-
passingmodelandtheshared-memorymodel.Inthemessage-passingmodel,
the communicating processes exchange messages with one another to trans-2.3 SystemCalls 73
fer information. Messages can be exchanged between the processes either
directly or indirectly through a common mailbox. Before communication can
take place, a connection must be opened.The name of the other communica-
tormust be known, be itanother processonthe samesystemor aprocess on
anothercomputerconnectedbyacommunicationsnetwork.Eachcomputerin
anetworkhasahostnamebywhichitiscommonlyknown.Ahostalsohasa
networkidentifier,suchasanIPaddress.Similarly,eachprocesshasaprocess
name, and this name is translated into an identifier by which the operating
system can refer to the process. The get hostid() and get processid()
systemcallsdothistranslation.Theidentifiersarethenpassedtothegeneral-
purpose open() and close() calls provided by the file system or to specific
open connection() and close connection() system calls, depending on
thesystem’smodelofcommunication.Therecipientprocessusuallymustgive
itspermissionforcommunicationtotakeplacewithanaccept connection()
call.Mostprocessesthatwillbereceivingconnectionsarespecial-purposedae-
mons,whicharesystemprogramsprovidedforthatpurpose.Theyexecutea
wait for connection() call and are awakened when a connection is made.
Thesourceofthecommunication,knownastheclient,andthereceivingdae-
mon, known as a server, then exchange messages by using read message()
andwrite message()systemcalls.Theclose connection()callterminates
thecommunication.
In the shared-memory model, processes use shared memory create()
andshared memory attach()systemcallstocreateandgainaccesstoregions
of memory owned by other processes. Recall that, normally, the operating
systemtriestopreventoneprocessfromaccessinganotherprocess’smemory.
Shared memory requires that two or more processes agree to remove this
restriction. They can then exchange information by reading and writing data
in the shared areas. The form of the data is determined by the processes and
isnotundertheoperatingsystem’scontrol.Theprocessesarealsoresponsible
forensuringthattheyarenotwritingtothesamelocationsimultaneously.Such
mechanismsarediscussedinChapter6.InChapter4,welookatavariationof
theprocessscheme—threads—inwhichsomememoryissharedbydefault.
Both of the models just discussed are common in operating systems,
andmostsystemsimplementboth. Messagepassingisusefulforexchanging
smaller amounts of data, because no conflicts need be avoided. It is also eas-
ier to implement than is shared memory for intercomputer communication.
Sharedmemoryallowsmaximumspeedandconvenienceofcommunication,
since it can be done at memory transfer speeds when it takes place within a
computer.Problemsexist,however,intheareasofprotectionandsynchroniza-
tionbetweentheprocessessharingmemory.
2.3.3.6 Protection
Protection provides a mechanism for controlling access to the resources pro-
vided by a computer system. Historically, protection was a concern only on
multiprogrammed computer systems with several users. However, with the
adventofnetworkingandtheInternet,allcomputersystems,fromserversto
mobilehandhelddevices,mustbeconcernedwithprotection.
Typically, system calls providing protection include set permission()
and get permission(), which manipulate the permission settings of74 Chapter2 Operating-SystemStructures
resourcessuchasfilesanddisks.Theallow user()anddeny user()system
calls specify whether particular users can—or cannot—be allowed access
to certain resources. We cover protection in Chapter 17 and the much larger
issueofsecurity—whichinvolvesusingprotectionagainstexternalthreats—
inChapter16.
2.4 System Services
Another aspect of a modernsystem is its collectionof systemservices.Recall
Figure1.1,whichdepictedthelogicalcomputerhierarchy.Atthelowestlevel
ishardware.Nextistheoperatingsystem,thenthesystemservices,andfinally
the application programs. System services, also known as system utilities,
provide a convenient environment for program development and execution.
Some of them are simply user interfaces to system calls. Others are consider-
ablymorecomplex.Theycanbedividedintothesecategories:
• Filemanagement.Theseprogramscreate,delete,copy,rename,print,list,
andgenerallyaccessandmanipulatefilesanddirectories.
• Status information. Some programs simply ask the system for the date,
time, amount of available memory or disk space, number of users, or
similar status information. Others are more complex, providing detailed
performance, logging, and debugging information. Typically, these pro-
gramsformatandprinttheoutputtotheterminalorotheroutputdevices
orfilesordisplayitinawindowoftheGUI.Somesystemsalsosupporta
registry,whichisusedtostoreandretrieveconfigurationinformation.
• Filemodificatio .Severaltexteditorsmaybeavailabletocreateandmod-
ifythecontent offilesstoredondiskorotherstoragedevices.Theremay
also be special commands to search contents of files or perform transfor-
mationsofthetext.
• Programming-languagesupport.Compilers,assemblers,debuggers,and
interpreters for common programming languages (such as C, C++, Java,
andPython)areoftenprovidedwiththeoperatingsystemoravailableas
aseparatedownload.
• Program loading and execution. Once a program is assembled or com-
piled, it must be loaded into memory to be executed. The system may
provideabsoluteloaders,relocatableloaders,linkageeditors,andoverlay
loaders.Debuggingsystemsforeitherhigher-levellanguagesormachine
languageareneededaswell.
• Communications. These programs provide the mechanism for creating
virtualconnectionsamongprocesses,users,andcomputersystems.They
allow users to send messages to one another’s screens, to browse web
pages,tosende-mailmessages,tologinremotely,ortotransferfilesfrom
onemachinetoanother.
• Background services. All general-purpose systems have methods for
launching certain system-program processes at boot time. Some of these
processesterminateaftercompletingtheirtasks,whileotherscontinueto2.5 LinkersandLoaders 75
run until the system is halted. Constantly running system-program pro-
cesses are known as services, subsystems, or daemons. One example is
the network daemon discussed in Section 2.3.3.5. In that example, a sys-
temneededaservicetolistenfornetworkconnectionsinordertoconnect
those requests to the correct processes. Other examples include process
schedulers that start processes according to a specified schedule, system
errormonitoringservices,andprintservers.Typicalsystemshavedozens
ofdaemons.Inaddition,operatingsystemsthatrunimportantactivitiesin
user context rather than in kernel context may use daemons to run these
activities.
Along with system programs, most operating systems are supplied with
programsthatareusefulinsolvingcommonproblemsorperformingcommon
operations. Such application programs include web browsers, word proces-
sors and text formatters, spreadsheets, database systems, compilers, plotting
andstatistical-analysispackages,andgames.
The view of the operating system seen by most users is defined by the
applicationandsystemprograms,ratherthanbytheactualsystemcalls.Con-
sider a user’s PC. When a user’s computer is running the macOS operating
system,theusermightseetheGUI,featuringamouse-and-windowsinterface.
Alternatively,oreveninoneofthewindows,theusermighthaveacommand-
lineUNIXshell.Bothusethesamesetofsystemcalls,butthesystemcallslook
differentand act in differentways. Further confusing the user view, consider
the user dual-booting from macOS into Windows. Now the same user on the
same hardware has two entirely different interfaces and two sets of applica-
tions using the same physical resources. On the same hardware, then, a user
canbeexposedtomultipleuserinterfacessequentiallyorconcurrently.
2.5 Linkers and Loaders
Usually, a program resides on disk as a binary executable file—for example,
a.outorprog.exe.TorunonaCPU,theprogrammustbebroughtintomem-
oryandplacedinthecontextofaprocess.Inthissection,wedescribethesteps
inthisprocedure,fromcompilingaprogramtoplacingitinmemory,whereit
becomeseligibletorunonanavailableCPUcore.Thestepsarehighlightedin
Figure2.11.
Source files are compiled into object files that are designed to be loaded
into any physical memory location, a format known as an relocatable object
fil .Next,thelinkercombinestheserelocatableobjectfilesintoasinglebinary
executablefile.Duringthelinkingphase,otherobjectfilesorlibrariesmaybe
includedaswell,suchasthestandardCormathlibrary(specifiedwiththeflag
-lm).
Aloaderisusedtoloadthebinaryexecutablefileintomemory,whereitis
eligibletorunonaCPUcore.Anactivityassociatedwithlinkingandloading
is relocation, which assigns final addresses to the program parts and adjusts
codeanddataintheprogramtomatchthoseaddressessothat,forexample,the
codecancalllibraryfunctionsandaccessitsvariablesasitexecutes.InFigure
2.11,weseethattoruntheloader,allthatisnecessaryistoenterthenameofthe
executablefileonthecommandline.Whenaprogramnameisenteredonthe76 Chapter2 Operating-SystemStructures
source main.c
program
gcc -c main.c
compiler
generates
object main.o
other file
object
files
gcc -o main main.o -lm
linker
generates
executable main
file
./main
loader
dynamically
linked
libraries
program
in memory
Figure2.11 Theroleofthelinkerandloader.
commandlineonUNIXsystems—forexample,./main—theshellfirstcreates
anewprocesstoruntheprogramusingthefork()systemcall.Theshellthen
invokes the loader with the exec() system call, passing exec() the name of
theexecutablefile.Theloaderthenloadsthespecifiedprogramintomemory
usingtheaddressspaceofthenewlycreatedprocess.(WhenaGUIinterfaceis
used, double-clicking on the icon associated with the executable file invokes
theloaderusingasimilarmechanism.)
The process described thus far assumes that all libraries are linked into
the executable file and loaded into memory. In reality, most systems allow
a program to dynamically link libraries as the program is loaded. Windows,
for instance, supports dynamically linked libraries(DLLs). The benefit of this
approach is that it avoids linking and loading libraries that may end up not
being used into an executable file. Instead, the library is conditionally linked
andisloadedifitisrequiredduringprogramruntime.Forexample,inFigure
2.11, the math library is not linked into the executable file main. Rather, the
linker inserts relocation information that allows it to be dynamically linked
and loaded as the program is loaded. We shall see in Chapter 9 that it is
possibleformultipleprocessestosharedynamicallylinkedlibraries,resulting
inasignificantsavingsinmemoryuse.
Object files and executable files typically have standard formats that
include the compiled machine code and a symbol table containing metadata
about functions and variables that are referenced in the program. For UNIX
and Linux systems, this standard format is known as ELF (for Executable
and Linkable Format). There are separate ELF formats for relocatable and2.6 WhyApplicationsAreOperating-SystemSpecifi 77
ELFFORMAT
Linux provides various commands to identify and evaluate ELF files. For
example, the file command determines a file type. If main.o is an object
file,andmainisanexecutablefile,thecommand
file main.o
willreportthatmain.oisanELFrelocatablefile,whilethecommand
file main
willreportthatmainisanELFexecutable.ELFfilesaredividedintoanumber
ofsectionsandcanbeevaluatedusingthereadelfcommand.
executablefiles.OnepieceofinformationintheELFfileforexecutablefilesis
the program’s entry point, which contains the address of the first instruction
to be executed when the program runs. Windows systems use the Portable
Executable(PE)format,andmacOSusestheMach-Oformat.
2.6 Why Applications Are Operating-System Specific
Fundamentally, applications compiled on one operating system are not exe-
cutableonotheroperatingsystems.Iftheywere,theworldwouldbeabetter
place,andourchoiceofwhatoperatingsystemtousewoulddependonutility
andfeaturesratherthanwhichapplicationswereavailable.
Basedonourearlierdiscussion,wecannowseepartoftheproblem—each
operatingsystemprovidesauniquesetofsystemcalls.Systemcallsarepartof
thesetofservicesprovidedbyoperatingsystemsforusebyapplications.Even
ifsystemcallsweresomehowuniform,otherbarrierswouldmakeitdifficult
for us to execute application programs on different operating systems. But if
you have used multiple operating systems, you may have used some of the
sameapplicationsonthem.Howisthatpossible?
Anapplicationcanbemadeavailabletorunonmultipleoperatingsystems
inoneofthreeways:
1. Theapplicationcanbewritteninaninterpretedlanguage(suchasPython
orRuby)thathasaninterpreteravailableformultipleoperatingsystems.
Theinterpreterreadseachlineofthesourceprogram,executesequivalent
instructionsonthenativeinstructionset,andcallsnativeoperatingsys-
temcalls.Performancesuffersrelativetothatfornativeapplications,and
theinterpreterprovidesonlyasubsetofeachoperatingsystem’sfeatures,
possiblylimitingthefeaturesetsoftheassociatedapplications.
2. The application can be written in a language that includes a virtual
machinecontainingtherunningapplication.Thevirtualmachineispart
ofthelanguage’sfullRTE.OneexampleofthismethodisJava.Javahasan
RTEthatincludesaloader,byte-codeverifier,andothercomponentsthat
loadtheJavaapplicationintotheJavavirtualmachine.ThisRTEhasbeen78 Chapter2 Operating-SystemStructures
ported, or developed,for many operating systems, from mainframes to
smartphones,andintheoryanyJavaappcanrunwithintheRTEwherever
it is available. Systems of this kind have disadvantages similar to those
ofinterpreters,discussedabove.
3. The application developercan use a standard language or API in which
the compiler generates binaries in a machine- and operating-system-
specificlanguage.Theapplicationmustbeportedtoeachoperatingsys-
temonwhichitwillrun.Thisportingcanbequitetimeconsumingand
must be done for each new version of the application, with subsequent
testing and debugging. Perhaps the best-known example is the POSIX
API and its set of standards for maintaining source-code compatibility
betweendifferentvariantsofUNIX-likeoperatingsystems.
In theory, these three approaches seemingly provide simple solutions for
developingapplicationsthatcanrunacrossdifferentoperatingsystems.How-
ever, the general lack of application mobility has several causes, all of which
still make developing cross-platform applications a challenging task. At the
applicationlevel,thelibrariesprovidedwiththeoperatingsystemcontainAPIs
toprovidefeatureslikeGUIinterfaces,andanapplicationdesignedtocallone
setofAPIs(say,thoseavailablefromiOSontheAppleiPhone)willnotworkon
anoperatingsystemthatdoesnotprovidethoseAPIs(suchasAndroid).Other
challengesexistatlowerlevelsinthesystem,includingthefollowing.
• Each operating system has a binary format for applications that dictates
the layout of the header, instructions, and variables. Those components
needtobeatcertainlocationsinspecifiedstructureswithinanexecutable
filesotheoperatingsystemcanopenthefileandloadtheapplicationfor
properexecution.
• CPUs have varying instruction sets, and only applications containing the
appropriateinstructionscanexecutecorrectly.
• Operatingsystemsprovidesystemcallsthatallowapplicationstorequest
various activities, such as creating files and opening network connec-
tions.Thosesystemcallsvaryamongoperatingsystemsinmanyrespects,
includingthespecificoperandsandoperandorderingused,howanappli-
cationinvokesthesystemcalls,theirnumberingandnumber,theirmean-
ings,andtheirreturnofresults.
There are some approaches that have helped address, though not com-
pletelysolve,thesearchitecturaldifferences.Forexample,Linux—andalmost
every UNIX system—has adopted the ELF format for binary executable files.
Although ELF provides a common standard across Linux and UNIX systems,
theELFformatisnottiedtoanyspecificcomputerarchitecture,soitdoesnot
guaranteethatanexecutablefilewillrunacrossdifferenthardwareplatforms.
APIs,asmentionedabove,specifycertainfunctionsattheapplicationlevel.
Atthearchitecturelevel,anapplicationbinaryinterface(ABI)isusedtodefine
how different components of binary code can interface for a given operating
system on a given architecture. An ABI specifies low-level details, including
addresswidth,methodsofpassingparameterstosystemcalls,theorganization2.7 Operating-SystemDesignandImplementation 79
oftherun-timestack,thebinaryformatofsystemlibraries,andthesizeofdata
types,justtonameafew.Typically,anABIisspecifiedforagivenarchitecture
(for example, there is an ABI for the ARMv8 processor). Thus, an ABI is the
architecture-level equivalent of an API. If a binary executable file has been
compiledandlinkedaccordingtoaparticularABI,itshouldbeabletorunon
different systems that support that ABI. However, because a particular ABI is
definedforacertainoperatingsystemrunningonagivenarchitecture,ABIsdo
littletoprovidecross-platformcompatibility.
In sum, all of these differences mean that unless an interpreter, RTE, or
binaryexecutablefileiswrittenforandcompiledonaspecificoperatingsystem
onaspecificCPUtype(suchasIntelx86orARMv8),theapplicationwillfailto
run. Imagine the amount of work that is required for a program such as the
Firefox browser to run on Windows, macOS, various Linux releases, iOS, and
Android,sometimesonvariousCPUarchitectures.
2.7 Operating-System Design and Implementation
Inthissection,wediscussproblemswefaceindesigningandimplementingan
operatingsystem.Thereare,ofcourse,nocompletesolutionstosuchproblems,
butthereareapproachesthathaveprovedsuccessful.
2.7.1 Design Goals
Thefirstproblemindesigningasystemistodefinegoalsandspecifications.At
thehighestlevel,thedesignofthesystemwillbeaffectedbythechoiceofhard-
wareandthetypeofsystem:traditionaldesktop/laptop,mobile,distributed,
orrealtime.
Beyondthishighestdesignlevel,therequirementsmaybemuchharderto
specify.Therequirementscan,however,bedividedintotwobasicgroups:user
goalsandsystemgoals.
Users want certainobvious propertiesin a system.The system should be
convenient to use, easy to learn and to use, reliable,safe, and fast. Of course,
thesespecificationsarenotparticularlyusefulinthesystemdesign,sincethere
isnogeneralagreementonhowtoachievethem.
Asimilarsetofrequirementscanbedefinedbythedeveloperswhomust
design,create,maintain,andoperatethesystem.Thesystemshouldbeeasyto
design,implement,andmaintain;anditshouldbeflexible,reliable,errorfree,
and efficient. Again, theserequirementsare vagueand may be interpretedin
variousways.
Thereis,inshort,nouniquesolutiontotheproblemofdefiningtherequire-
mentsforanoperatingsystem.Thewiderangeofsystemsinexistenceshows
thatdifferentrequirementscanresultinalargevarietyofsolutionsfordifferent
environments.Forexample,therequirementsforWindRiverVxWorks,areal-
time operating system for embedded systems, must have been substantially
differentfromthoseforWindowsServer,alargemultiaccessoperatingsystem
designedforenterpriseapplications.
Specifying and designing an operating system is a highly creative task.
Althoughnotextbookcantellyouhowtodoit,generalprincipleshavebeen80 Chapter2 Operating-SystemStructures
developedinthefieldofsoftwareengineering,andweturnnowtoadiscus-
sionofsomeoftheseprinciples.
2.7.2 Mechanisms and Policies
Oneimportantprincipleistheseparationofpolicyfrommechanism.Mecha-
nismsdeterminehowtodosomething;policiesdeterminewhatwillbedone.
Forexample,thetimerconstruct(seeSection1.4.3)isamechanismforensuring
CPUprotection,butdecidinghowlongthetimeristobesetforaparticularuser
isapolicydecision.
Theseparationofpolicyandmechanismisimportantforflexibility.Policies
arelikelytochangeacrossplacesorovertime.Intheworstcase,eachchange
in policy would require a change in the underlying mechanism. A general
mechanism flexible enough to work across a range of policies is preferable.
Achangeinpolicywouldthenrequireredefinitionofonlycertainparameters
ofthesystem.Forinstance,consideramechanismforgivingprioritytocertain
types of programs over others. If the mechanism is properly separated from
policy, it can be used either to support a policy decision that I/O-intensive
programs should have priority over CPU-intensive ones or to support the
oppositepolicy.
Microkernel-basedoperatingsystems(discussedinSection2.8.3)takethe
separationof mechanism and policy to one extremeby implementinga basic
setofprimitivebuildingblocks.Theseblocksarealmostpolicyfree,allowing
moreadvanced mechanisms and policiestobe addedviauser-createdkernel
modules or user programs themselves. In contrast, consider Windows, an
enormously popular commercial operating system available for over three
decades. Microsoft has closely encoded both mechanism and policy into the
systemtoenforceagloballookandfeelacrossalldevicesthatruntheWindows
operatingsystem.Allapplicationshavesimilarinterfaces,becausetheinterface
itselfisbuiltintothekernelandsystemlibraries.Applehasadoptedasimilar
strategywithitsmacOSandiOSoperatingsystems.
Wecanmakeasimilarcomparisonbetweencommercialandopen-source
operating systems. For instance, contrast Windows, discussed above, with
Linux, an open-source operating system that runs on a wide range of com-
putingdevicesandhasbeenavailableforover25years.The“standard”Linux
kernelhasaspecificCPUschedulingalgorithm(coveredinSection5.7.1),which
is a mechanism that supports a certain policy. However, anyone is free to
modifyorreplacetheschedulertosupportadifferentpolicy.
Policy decisions are important for all resource allocation. Whenever it is
necessarytodecidewhetherornottoallocatearesource,apolicydecisionmust
be made. Whenever the question is how rather than what, it is a mechanism
thatmustbedetermined.
2.7.3 Implementation
Onceanoperatingsystemisdesigned,itmustbeimplemented.Becauseoper-
atingsystemsarecollectionsofmanyprograms,writtenbymanypeopleover
alongperiodoftime,itisdifficulttomakegeneralstatementsabouthowthey
areimplemented.
Early operating systems were written in assembly language. Now, most
are written in higher-level languages such as C or C++, with small amounts2.8 Operating-SystemStructure 81
of the system written in assembly language. In fact, more than one higher-
levellanguage is oftenused.The lowestlevelsofthekernelmight be written
inassemblylanguageandC.Higher-levelroutinesmightbewritteninCand
C++, and system libraries might be written in C++ or even higher-level lan-
guages.Androidprovidesaniceexample:itskerneliswrittenmostlyinCwith
some assembly language. Most Android system libraries are written in C or
C++,anditsapplicationframeworks—whichprovidethedeveloperinterface
tothesystem—arewrittenmostlyinJava.WecoverAndroid’sarchitecturein
moredetailinSection2.8.5.2.
The advantages of using a higher-level language, or at least a systems-
implementation language, for implementing operating systems are the same
asthosegainedwhenthelanguageisusedforapplicationprograms:thecode
canbewrittenfaster,ismorecompact,andiseasiertounderstandanddebug.
In addition, improvements in compiler technology will improve the gener-
ated code for the entire operating system by simple recompilation. Finally,
an operating system is far easier to port to other hardware if it is written in
a higher-level language. This is particularly important for operating systems
thatareintendedtorunonseveraldifferenthardwaresystems,suchassmall
embeddeddevices,Intelx86systems,andARMchipsrunningonphonesand
tablets.
Theonlypossibledisadvantagesofimplementinganoperatingsystemina
higher-levellanguagearereducedspeedandincreasedstoragerequirements.
This, however, is not a major issue in today’s systems. Although an expert
assembly-languageprogrammercanproduceefficientsmallroutines,forlarge
programsamoderncompilercanperformcomplexanalysisandapplysophis-
ticated optimizations that produce excellent code. Modern processors have
deep pipelining and multiple functional units that can handle the details of
complexdependenciesmuchmoreeasilythancanthehumanmind.
Asistrueinothersystems,majorperformanceimprovementsinoperating
systemsaremorelikelytobetheresultofbetterdatastructuresandalgorithms
thanofexcellentassembly-languagecode.Inaddition,althoughoperatingsys-
temsarelarge,onlyasmallamountofthecodeiscriticaltohighperformance;
theinterrupthandlers,I/Omanager,memorymanager,andCPUschedulerare
probablythemostcriticalroutines.Afterthesystemiswrittenandisworking
correctly, bottlenecks can be identified and can be refactored to operate more
efficiently.
2.8 Operating-System Structure
Asystem as large and complex as a modern operating system must be engi-
neeredcarefullyifitistofunctionproperlyandbemodifiedeasily.Acommon
approach is to partition the task into small components, or modules, rather
thanhaveonesinglesystem.Eachofthesemodulesshouldbeawell-defined
portionofthesystem,withcarefullydefinedinterfacesandfunctions.Youmay
useasimilarapproachwhenyoustructureyourprograms:ratherthanplacing
allofyourcodeinthemain()function,youinsteadseparatelogicintoanum-
beroffunctions,clearlyarticulateparametersandreturnvalues,andthencall
thosefunctionsfrommain().82 Chapter2 Operating-SystemStructures
lenrek
(the users)
shells and commands
compilers and interpreters
system libraries
system-call interface to the kernel
signals terminal file system CPU scheduling
handling swapping block I/O page replacement
character I/O system system demand paging
terminal drivers disk and tape drivers virtual memory
kernel interface to the hardware
terminal controllers device controllers memory controllers
terminals disks and tapes physical memory
Figure2.12 TraditionalUNIXsystemstructure.
We briefly discussed the common components of operating systems in
Chapter1.Inthissection,wediscusshowthesecomponentsareinterconnected
andmeldedintoakernel.
2.8.1 Monolithic Structure
Thesimpleststructurefororganizinganoperatingsystemisnostructureatall.
Thatis,placeallofthefunctionalityofthekernelintoasingle,staticbinaryfile
that runs in a single address space. This approach—known as a monolithic
structure—isacommontechniquefordesigningoperatingsystems.
An example of such limited structuring is the original UNIX operating
system, which consists of two separable parts: the kernel and the system
programs.Thekernelisfurtherseparatedintoaseriesofinterfacesanddevice
drivers, which have been added and expanded over the years as UNIX has
evolved.WecanviewthetraditionalUNIXoperatingsystemasbeinglayered
to some extent, as shown in Figure 2.12. Everything below the system-call
interface and above the physical hardware is the kernel. The kernel provides
the file system, CPU scheduling, memory management, and other operating-
system functions through system calls. Taken in sum, that is an enormous
amountoffunctionalitytobecombinedintoonesingleaddressspace.
TheLinuxoperatingsystemisbasedonUNIXandisstructuredsimilarly,as
showninFigure2.13.ApplicationstypicallyusetheglibcstandardClibrary
when communicating with the system call interface to the kernel. The Linux
kernelismonolithicinthatitrunsentirelyinkernelmodeinasingleaddress
space,but as we shallseeinSection2.8.4,itdoeshaveamodular designthat
allowsthekerneltobemodifiedduringruntime.
Despite the apparent simplicity of monolithic kernels, they are difficult
to implementand extend.Monolithic kernels dohave a distinct performance
advantage, however:there is verylittleoverhead inthe system-callinterface,
andcommunicationwithinthekernelisfast.Therefore,despitethedrawbacks2.8 Operating-SystemStructure 83
applications
glibc standard c library
system-call interface
file CPU
systems scheduler
networks memory
(TCP/IP) manager
block character
devices devices
device drivers
hardware
Figure2.13 Linuxsystemstructure.
of monolithic kernels, their speed and efficiency explains why we still see
evidenceofthisstructureintheUNIX,Linux,andWindowsoperatingsystems.
2.8.2 Layered Approach
Themonolithicapproachisoftenknownasatightlycoupledsystembecause
changestoonepartofthesystemcanhavewide-rangingeffectsonotherparts.
Alternatively, we could design a loosely coupled system. Such a system is
dividedintoseparate,smallercomponentsthathavespecificandlimitedfunc-
tionality. All these components together comprise the kernel. The advantage
of this modular approach is that changes in one component affect only that
component, and no others, allowing system implementers more freedom in
creatingandchangingtheinnerworkingsofthesystem.
Asystemcanbemademodularinmanyways.Onemethodisthelayered
approach, in which the operating system is broken into a number of layers
(levels).Thebottomlayer(layer0)isthehardware;thehighest(layerN)isthe
userinterface.ThislayeringstructureisdepictedinFigure2.14.
Anoperating-systemlayerisanimplementationofanabstractobjectmade
up of data and the operations that can manipulate those data. A typical
operating-system layer—say, layer M—consists of data structures and a set
of functions that can be invokedby higher-levellayers.Layer M,in turn, can
invokeoperationsonlower-levellayers.
Themainadvantageofthelayeredapproachissimplicityofconstruction
anddebugging.Thelayersareselectedsothateachusesfunctions(operations)84 Chapter2 Operating-SystemStructures
layer N
user interface
•
•
•
layer 1
layer 0
hardware
Figure2.14 Alayeredoperatingsystem.
and services of only lower-level layers. This approach simplifies debugging
andsystemverification.Thefirstlayercanbedebuggedwithoutanyconcern
fortherestofthesystem,because,bydefinition,itusesonlythebasichardware
(which is assumed correct) to implement its functions. Once the first layer is
debugged, its correct functioning can be assumed while the second layer is
debugged,andsoon.Ifanerrorisfoundduringthedebuggingofaparticular
layer, the error must be on that layer, because the layers below it are already
debugged.Thus,thedesignandimplementationofthesystemaresimplified.
Each layer is implemented only with operations provided by lower-level
layers.Alayerdoesnotneedtoknowhowtheseoperationsareimplemented;
it needs to know only what these operations do. Hence, each layer hides the
existence of certain data structures, operations, and hardware from higher-
levellayers.
Layeredsystemshavebeensuccessfullyusedincomputernetworks(such
as TCP/IP) and web applications. Nevertheless, relatively few operating sys-
tems use a pure layered approach. One reason involves the challenges of
appropriatelydefiningthefunctionality ofeachlayer.Inaddition,theoverall
performance of such systems is poor due to the overhead of requiring a user
programtotraversethroughmultiplelayerstoobtainanoperating-systemser-
vice.Somelayeringiscommonincontemporaryoperatingsystems,however.
Generally,thesesystemshavefewerlayerswithmorefunctionality,providing
most of the advantages of modularized code while avoiding the problems of
layerdefinitionandinteraction.
2.8.3 Microkernels
We have already seen that the original UNIX system had a monolithic struc-
ture. As UNIX expanded, the kernel became large and difficult to manage.
In the mid-1980s, researchers at Carnegie Mellon University developed an
operating system called Mach that modularized the kernel using the micro-
kernel approach. This method structures the operating system by removing2.8 Operating-SystemStructure 85
application file device
program system driver
interprocess
communication
Figure2.15 Architectureofatypicalmicrokernel.
allnonessentialcomponentsfromthekernelandimplementingthemasuser-
level programs that reside in separate address spaces. The result is a smaller
kernel.Thereislittleconsensusregardingwhichservicesshouldremaininthe
kernel and which should be implemented in user space. Typically, however,
microkernelsprovideminimalprocessandmemorymanagement,inaddition
toacommunicationfacility.Figure2.15illustratesthearchitectureofatypical
microkernel.
The main function of the microkernel is to provide communication
between the client program and the various services that are also running in
userspace.Communicationisprovidedthroughmessagepassing,whichwas
describedinSection2.3.3.5.Forexample,iftheclientprogramwishestoaccess
afile,itmustinteractwiththefileserver.Theclientprogramandservicenever
interactdirectly.Rather,theycommunicateindirectlybyexchangingmessages
withthemicrokernel.
One benefit of the microkernel approach is that it makes extending the
operatingsystem easier.All new servicesare addedto user space and conse-
quentlydonotrequiremodificationofthekernel.Whenthekerneldoeshaveto
bemodified,thechangestendtobefewer,becausethemicrokernelisasmaller
kernel. The resulting operating system is easier to port from one hardware
designtoanother.Themicrokernelalsoprovidesmoresecurityandreliability,
since most services are running as user—rather than kernel—processes. If a
servicefails,therestoftheoperatingsystemremainsuntouched.
Perhaps the best-known illustration of a microkernel operating system
is Darwin, the kernel component of the macOS and iOS operating systems.
Darwin,infact,consistsoftwokernels,oneofwhichistheMachmicrokernel.
WewillcoverthemacOSandiOSsystemsinfurtherdetailinSection2.8.5.1.
AnotherexampleisQNX,areal-timeoperatingsystemforembeddedsys-
tems. The QNX Neutrino microkernel provides services for message passing
andprocessscheduling.Italsohandleslow-levelnetworkcommunicationand
hardwareinterrupts.AllotherservicesinQNXareprovidedbystandardpro-
cessesthatrunoutsidethekernelinusermode.
Unfortunately,theperformanceofmicrokernelscansufferduetoincreased
system-function overhead. When two user-level services must communicate,
messages must be copied between the services, which reside in separate86 Chapter2 Operating-SystemStructures
address spaces. In addition, the operating system may have to switch from
one process to the next to exchange the messages. The overhead involved
in copying messages and switching between processes has been the largest
impedimenttothegrowthofmicrokernel-basedoperatingsystems.Consider
thehistoryofWindowsNT:Thefirstreleasehadalayeredmicrokernelorgani-
zation. This version’s performance was low compared with that of Windows
95. Windows NT 4.0 partially corrected the performance problem by moving
layers from user space to kernel space and integrating them more closely.
By the time Windows XP was designed, Windows architecture had become
more monolithic than microkernel. Section 2.8.5.1 will describe how macOS
addressestheperformanceissuesoftheMachmicrokernel.
2.8.4 Modules
Perhaps the best current methodology for operating-system design involves
using loadable kernel modules (LKMs). Here, the kernel has a set of core
componentsandcanlinkinadditionalservicesviamodules,eitheratboottime
orduringruntime.Thistypeofdesigniscommoninmodernimplementations
ofUNIX,suchasLinux,macOS,andSolaris,aswellasWindows.
The idea of the design is for the kernel to provide core services, while
otherservicesareimplementeddynamically,asthekernelisrunning.Linking
servicesdynamicallyispreferabletoaddingnewfeaturesdirectlytothekernel,
which would require recompiling the kernel every time a change was made.
Thus,forexample,wemightbuildCPUschedulingandmemorymanagement
algorithms directly into the kernel and then add support for different file
systemsbywayofloadablemodules.
The overall result resembles a layered system in that each kernel section
hasdefined,protectedinterfaces;butitismoreflexiblethanalayeredsystem,
becauseanymodulecancallanyothermodule.Theapproachisalsosimilarto
themicrokernelapproachinthattheprimarymodulehasonlycorefunctions
and knowledge of how to load and communicate with other modules; but it
is more efficient, because modules do not need to invoke message passing in
ordertocommunicate.
Linux uses loadable kernel modules, primarily for supporting device
drivers and file systems. LKMs can be “inserted” into the kernel as the sys-
tem is started (or booted) or during run time, such as when a USB device is
plugged into a running machine. If the Linux kernel does not have the nec-
essary driver, it can be dynamically loaded. LKMs can be removed from the
kernelduringruntimeaswell.ForLinux,LKMsallowadynamicandmodular
kernel,whilemaintainingtheperformancebenefitsofamonolithicsystem.We
cover creating LKMs in Linux in several programming exercises at the end of
thischapter.
2.8.5 Hybrid Systems
In practice, very few operating systems adopt a single, strictly defined struc-
ture. Instead, they combine different structures, resulting in hybrid systems
that address performance, security, and usability issues. For example, Linux
is monolithic, because having the operating system in a single address space
provides very efficient performance. However, it also modular, so that new
functionality can be dynamically added to the kernel. Windows is largely2.8 Operating-SystemStructure 87
monolithic as well (again primarily for performance reasons), but it retains
some behavior typical of microkernel systems, including providing support
forseparatesubsystems(knownasoperating-systempersonalities)thatrunas
user-modeprocesses.Windowssystemsalsoprovidesupportfordynamically
loadable kernel modules. We provide case studies of Linux and Windows 10
in Chapter 20 and Chapter 21, respectively. In the remainder of this section,
we explore the structure of three hybrid systems: the Apple macOS operat-
ing system and the two most prominent mobile operating systems—iOS and
Android.
2.8.5.1 macOSandiOS
Apple’smacOSoperatingsystemisdesignedtorunprimarilyondesktopand
laptopcomputersystems,whereasiOSisamobileoperatingsystemdesigned
for the iPhone smartphone and iPad tablet computer. Architecturally, macOS
andiOShavemuchincommon,andsowepresentthemtogether,highlighting
whattheyshareaswellashowtheydifferfromeachother.Thegeneralarchi-
tectureofthesetwosystemsisshowninFigure2.16.Highlightsofthevarious
layersincludethefollowing:
• Userexperiencelayer.Thislayerdefinesthesoftwareinterfacethatallows
users to interact with the computing devices. macOS uses the Aqua user
interface,whichisdesignedforamouseortrackpad,whereasiOSusesthe
Springboarduserinterface,whichisdesignedfortouchdevices.
• Applicationframeworkslayer.ThislayerincludestheCocoaandCocoa
Touch frameworks, which provide an API for the Objective-C and Swift
programming languages. The primary difference between Cocoa and
CocoaTouchisthattheformerisusedfordevelopingmacOSapplications,
and the latter by iOS to provide support for hardware features unique to
mobiledevices,suchastouchscreens.
• Core frameworks. This layer defines frameworks that support graphics
andmediaincluding,QuicktimeandOpenGL.
applications
user experience
application frameworks
core frameworks
kernel environment (Darwin)
Figure2.16 ArchitectureofApple’smacOSandiOSoperatingsystems.88 Chapter2 Operating-SystemStructures
• Kernelenvironment.Thisenvironment,alsoknownasDarwin,includes
the Mach microkernel and the BSD UNIX kernel. We will elaborate on
Darwinshortly.
As shown in Figure 2.16, applications can be designed to take advantage of
user-experience features or to bypass them and interact directly with either
theapplicationframeworkorthecoreframework.Additionally,anapplication
can forego frameworks entirely and communicate directly with the kernel
environment.(AnexampleofthislattersituationisaCprogramwrittenwith
nouserinterfacethatmakesPOSIXsystemcalls.)
Some significant distinctions between macOS and iOS include the follow-
ing:
• BecausemacOSisintendedfordesktopandlaptopcomputersystems,itis
compiledtorunonIntelarchitectures.iOSisdesignedformobiledevices
and thus is compiled for ARM-based architectures. Similarly, the iOS ker-
nel has been modified somewhat to address specific features and needs
of mobile systems, such as power management and aggressive memory
management. Additionally, iOS has more stringent security settings than
macOS.
• TheiOSoperatingsystemisgenerallymuchmorerestrictedtodevelopers
than macOS and may even be closed to developers. For example, iOS
restricts access to POSIX and BSD APIs on iOS, whereas they are openly
availabletodevelopersonmacOS.
We now focus on Darwin, which uses a hybrid structure. Darwin is a
layered system that consists primarily of the Mach microkernel and the BSD
UNIXkernel.Darwin’sstructureisshowninFigure2.17.
Whereasmostoperatingsystemsprovideasinglesystem-callinterfaceto
thekernel—suchasthroughthestandardClibraryonUNIXandLinuxsystems
—Darwin provides two system-call interfaces: Mach system calls (known as
applications
library interface
Mach BSD (POSIX)
traps system calls
memory
scheduling IPC
management
iokit
Mach kernel
kexts
Figure2.17 ThestructureofDarwin.2.8 Operating-SystemStructure 89
traps)andBSDsystemcalls(whichprovidePOSIXfunctionality).Theinterface
tothesesystemcallsisarichsetoflibrariesthatincludesnotonlythestandard
Clibrarybutalsolibrariesthatprovidenetworking,security,andprogamming
languagesupport(tonamejustafew).
Beneaththesystem-callinterface,Machprovidesfundamentaloperating-
system services, including memory management, CPU scheduling, and inter-
process communication (IPC) facilities such as message passing and remote
procedurecalls(RPCs).MuchofthefunctionalityprovidedbyMachisavailable
through kernel abstractions, which include tasks (a Mach process), threads,
memoryobjects,andports(usedforIPC).Asanexample,anapplicationmay
create a new process using the BSD POSIX fork() system call. Mach will, in
turn,useataskkernelabstractiontorepresenttheprocessinthekernel.
In additionto Mach and BSD, the kernelenvironment providesan I/O kit
fordevelopmentofdevicedriversanddynamicallyloadablemodules(which
macOSreferstoaskernelextensions,orkexts).
In Section 2.8.3, we described how the overhead of message passing
betweendifferentservicesrunninginuserspacecompromisestheperformance
of microkernels. To address such performance problems, Darwin combines
Mach,BSD,theI/Okit,andanykernelextensionsintoasingleaddressspace.
Thus,Machisnotapuremicrokernelinthesensethatvarioussubsystemsrun
inuserspace.MessagepassingwithinMachstilldoesoccur,butnocopyingis
necessary,astheserviceshaveaccesstothesameaddressspace.
Apple has released the Darwin operating system as open source. As a
result,variousprojectshaveaddedextrafunctionalitytoDarwin,suchastheX-
11windowingsystemandsupportforadditionalfilesystems.UnlikeDarwin,
however,theCocoainterface,aswellasotherproprietaryAppleframeworks
availablefordevelopingmacOSapplications,areclosed.
2.8.5.2 Android
The Android operating system was designed by the Open Handset Alliance
(led primarily by Google) and was developed for Android smartphones and
tabletcomputers.WhereasiOSisdesignedtorunonApplemobiledevicesand
is close-sourced, Android runs on a variety of mobile platforms and is open-
sourced,partlyexplainingitsrapidriseinpopularity.ThestructureofAndroid
appearsinFigure2.18.
Android is similar to iOS in that it is a layered stack of software that
provides a rich set of frameworks supporting graphics, audio, and hardware
features. These features, in turn, provide a platform for developing mobile
applicationsthatrunonamultitudeofAndroid-enableddevices.
Software designers for Android devices develop applications in the Java
language, but they do not generally use the standard Java API. Google has
designedaseparateAndroidAPI for Javadevelopment.Javaapplications are
compiledintoaformthatcanexecuteontheAndroidRunTimeART,avirtual
machinedesignedforAndroidandoptimizedformobiledeviceswithlimited
memoryandCPUprocessingcapabilities.Javaprogramsarefirstcompiledto
a Java bytecode .class file and then translated into an executable .dex file.
WhereasmanyJavavirtualmachinesperformjust-in-time(JIT)compilationto
improve application efficiency, ART performs ahead-of-time (AOT) compila-90 Chapter2 Operating-SystemStructures
applications
Android
ART
frameworks JNI
VM
native libraries
SQLite openGL webkit
surface media
SSL
manager framework
HAL
Bionic
Linux kernel
hardware
Figure2.18 ArchitectureofGoogle’sAndroid.
tion. Here, .dex files are compiled into native machine code when they are
installed on a device, from which they can execute on the ART. AOT compi-
lation allows more efficient application execution as well as reduced power
consumption,featuresthatarecrucialformobilesystems.
AndroiddeveloperscanalsowriteJavaprogramsthatusetheJavanative
interface—or JNI—which allows developers to bypass the virtual machine
and instead write Java programs that can access specific hardware features.
Programs written using JNI are generally not portable from one hardware
devicetoanother.
The set of native libraries available for Android applications includes
frameworksfordevelopingwebbrowsers(webkit),databasesupport(SQLite),
andnetworksupport,suchassecuresockets(SSLs).
Because Android can run on an almost unlimited number of hardware
devices,Googlehaschosentoabstractthephysicalhardwarethroughthehard-
wareabstractionlayer,orHAL.Byabstractingallhardware,suchasthecamera,
GPS chip, and other sensors, the HALprovides applications with a consistent
viewindependentofspecific hardware. This feature,of course, allows devel-
operstowriteprogramsthatareportableacrossdifferenthardwareplatforms.
ThestandardClibraryusedbyLinuxsystemsistheGNUClibrary(glibc).
GoogleinsteaddevelopedtheBionicstandardClibraryforAndroid.Notonly
doesBionichaveasmallermemoryfootprintthanglibc,butitalsohasbeen
designed for the slower CPUs that characterize mobile devices. (In addition,
BionicallowsGoogletobypassGPLlicensingofglibc.)2.8 Operating-SystemStructure 91
AtthebottomofAndroid’ssoftwarestackistheLinuxkernel.Googlehas
modifiedtheLinuxkernelusedinAndroidinavarietyofareastosupportthe
specialneedsofmobilesystems,suchaspowermanagement.Ithasalsomade
changesinmemorymanagementandallocationandhasaddedanewformof
IPCknownasBinder(whichwewillcoverinSection3.8.2.1).
WINDOWSSUBSYSTEMFORLINUX
Windows uses a hybrid architecture that provides subsystems to emu-
latedifferentoperating-systemenvironments.Theseuser-modesubsystems
communicatewiththeWindowskerneltoprovideactualservices.Windows
10adds aWindows subsystem for Linux (WSL), which allows native Linux
applications (specified as ELF binaries) to run on Windows 10. The typical
operation is for a user to start the Windows application bash.exe, which
presentstheuserwithabashshellrunningLinux.Internally,theWSLcreates
a Linux instance consisting of the init process, which in turn creates the
bash shell running the native Linux application /bin/bash. Each of these
processes runs in a Windows Pico process. This special process loads the
nativeLinuxbinaryintotheprocess’sownaddressspace,thusprovidingan
environmentinwhichaLinuxapplicationcanexecute.
Pico processes communicate with the kernel services LXCore and LXSS
to translate Linux system calls, if possible using native Windows system
calls.WhentheLinuxapplicationmakesasystemcallthathasnoWindows
equivalent,theLXSSservicemustprovidetheequivalentfunctionality.When
there is a one-to-one relationship between the Linux and Windows system
calls, LXSS forwards the Linux system call directly to the equivalent call in
the Windows kernel. In some situations, Linux and Windows have system
calls that are similar but not identical. When this occurs, LXSS will provide
some of the functionality and will invoke the similar Windows system call
toprovidetheremainderofthefunctionality.TheLinuxfork()providesan
illustrationofthis:TheWindowsCreateProcess()systemcallissimilarto
fork()butdoesnotprovideexactlythesamefunctionality.Whenfork()
isinvokedinWSL,theLXSSservicedoessomeoftheinitialworkoffork()
andthencallsCreateProcess()todotheremainderofthework.Thefigure
belowillustratesthebasicbehaviorofWSL.
user mode
Linux instance
bash.exe init /bin/bash
kernel mode fork()
CreateProcess()
LXSS/LXCore Windows kernel92 Chapter2 Operating-SystemStructures
2.9 Building and Booting an Operating System
Itispossibletodesign,code,andimplementanoperatingsystemspecifically
for one specific machine configuration. More commonly, however, operating
systems are designed to run on any of a class of machines with a variety of
peripheralconfigurations.
2.9.1 Operating-System Generation
Mostcommonly,acomputersystem,whenpurchased,hasanoperatingsystem
alreadyinstalled.Forexample,youmaypurchaseanewlaptopwithWindows
ormacOSpreinstalled.Butsupposeyouwishtoreplacethepreinstalledoper-
atingsystemoraddadditionaloperatingsystems.Orsupposeyoupurchasea
computer without an operating system. In these latter situations, you have a
fewoptionsforplacingtheappropriateoperatingsystemonthecomputerand
configuringitforuse.
Ifyouaregenerating(orbuilding)anoperatingsystemfromscratch,you
mustfollowthesesteps:
1. Write the operating system source code (or obtain previously written
sourcecode).
2. Configuretheoperatingsystemforthesystemonwhichitwillrun.
3. Compiletheoperatingsystem.
4. Installtheoperatingsystem.
5. Bootthecomputeranditsnewoperatingsystem.
Configuring the system involves specifying which features will be
included,andthisvariesbyoperatingsystem.Typically,parametersdescribing
how the system is configured is stored in a configuration file of some type,
andoncethisfileiscreated,itcanbeusedinseveralways.
At one extreme, a system administrator can use it to modify a copy of
the operating-system source code. Then the operating system is completely
compiled (known as a system build). Data declarations, initializations, and
constants, along with compilation, produce an output-object version of the
operating systemthat is tailoredtothe systemdescribedin the configuration
file.
Ataslightlylesstailoredlevel,thesystemdescriptioncanleadtotheselec-
tionofprecompiledobjectmodulesfromanexistinglibrary.Thesemodulesare
linked together to form the generated operating system. This process allows
thelibrarytocontainthedevicedriversforallsupportedI/Odevices,butonly
those needed are selected and linked into the operating system. Because the
systemisnotrecompiled,systemgenerationisfaster,buttheresultingsystem
maybeoverlygeneralandmaynotsupportdifferenthardwareconfigurations.
Attheotherextreme,itispossibletoconstructasystemthatiscompletely
modular.Here,selectionoccursatexecutiontimeratherthanatcompileorlink
time.Systemgenerationinvolvessimplysettingthe parametersthat describe
thesystemconfiguration.2.9 BuildingandBootinganOperatingSystem 93
Themajordifferencesamongtheseapproachesarethesizeandgenerality
ofthegeneratedsystemandtheeaseofmodifyingitasthehardwareconfigu-
rationchanges. For embeddedsystems,itis not uncommon toadoptthefirst
approachandcreateanoperatingsystemforaspecific,statichardwareconfig-
uration.However,most modernoperatingsystemsthat supportdesktopand
laptopcomputersaswellasmobiledeviceshaveadoptedthesecondapproach.
That is,the operatingsystemis stillgeneratedfor aspecifichardware config-
uration, but the use of techniques such as loadable kernel modules provides
modularsupportfordynamicchangestothesystem.
We now illusrate how to build a Linux system from scratch, where it is
typicallynecessarytoperformthefollowingsteps:
1. DownloadtheLinuxsourcecodefromhttp://www.kernel.org.
2. Configurethekernelusingthe“make menuconfig”command.Thisstep
generatesthe.configconfigurationfile.
3. Compilethemainkernelusingthe“make”command.Themakecommand
compilesthe kernelbased onthe configuration parametersidentifiedin
the.configfile,producingthefilevmlinuz,whichisthekernelimage.
4. Compile the kernel modules using the “make modules” command. Just
as with compiling the kernel, module compilation depends on the con-
figurationparametersspecifiedinthe.configfile.
5. Use the command “make modules install” to install the kernel mod-
ulesintovmlinuz.
6. Install the new kernel on the system by entering the “make install”
command.
Whenthesystemreboots,itwillbeginrunningthisnewoperatingsystem.
Alternatively, it is possible to modify an existing system by installing a
Linux virtual machine. This will allow the host operating system (such as
WindowsormacOS)torunLinux.(WeintroducedvirtualizationinSection1.7
andcoverthetopicmorefullyinChapter18.)
There are a few options for installing Linux as a virtual machine. One
alternative is to build a virtual machine from scratch. This option is similar
tobuildingaLinuxsystemfromscratch;however,theoperatingsystemdoes
notneedtobecompiled.AnotherapproachistouseaLinuxvirtualmachine
appliance, which is an operating system that has already been built and con-
figured.Thisoptionsimplyrequiresdownloadingtheapplianceandinstalling
it using virtualization software such as VirtualBox or VMware. For example,
tobuild the operating systemused inthe virtual machine providedwith this
text,theauthorsdidthefollowing:
1. DownloadedtheUbuntuISOimagefromhttps://www.ubuntu.com/
2. Instructed the virtual machine software VirtualBox to use the ISO as the
bootablemediumandbootedthevirtualmachine
3. Answered the installation questions and then installed and booted the
operatingsystemasavirtualmachine94 Chapter2 Operating-SystemStructures
2.9.2 System Boot
After an operating system is generated, it must be made available for use by
thehardware.Buthowdoesthehardwareknowwherethekernelisorhowto
load that kernel? The process of starting a computer by loading the kernel is
knownasbootingthesystem.Onmostsystems,thebootprocessproceedsas
follows:
1. Asmall piece of code known as the bootstrap program or boot loader
locatesthekernel.
2. Thekernelisloadedintomemoryandstarted.
3. Thekernelinitializeshardware.
4. Therootfilesystemismounted.
Inthissection,webrieflydescribethebootprocessinmoredetail.
Somecomputersystemsuseamultistagebootprocess:Whenthecomputer
isfirstpoweredon,asmallbootloaderlocatedinnonvolatilefirmwareknown
as BIOS is run. This initial boot loader usually does nothing more than load
a second boot loader, which is located at a fixed disk location called the boot
block. The program stored in the boot block may be sophisticated enough to
load the entire operating system into memory and begin its execution. More
typically,itissimplecode(asitmustfitinasinglediskblock)andknowsonly
theaddressondiskandthelengthoftheremainderofthebootstrapprogram.
ManyrecentcomputersystemshavereplacedtheBIOS-basedbootprocess
withUEFI(UnifiedExtensibleFirmwareInterface).UEFIhasseveraladvantages
overBIOS,includingbettersupportfor64-bitsystemsandlargerdisks.Perhaps
the greatest advantage is that UEFI is a single, complete boot manager and
thereforeisfasterthanthemultistageBIOSbootprocess.
WhetherbootingfromBIOSorUEFI,thebootstrapprogramcanperforma
varietyoftasks.Inadditiontoloadingthefile containing the kernelprogram
into memory, it also runs diagnostics to determine the state of the machine
—for example, inspecting memory and the CPUand discovering devices. If
the diagnostics pass, the program can continue with the booting steps. The
bootstrap can also initialize all aspects of the system, from CPU registers to
device controllers and the contents of main memory. Sooner or later, it starts
theoperatingsystemandmountstherootfilesystem.Itisonlyatthispointis
thesystemsaidtoberunning.
GRUB is an open-source bootstrap program for Linux and UNIX systems.
Boot parameters for the system are set in a GRUB configuration file, which is
loadedatstartup.GRUBisflexibleandallowschangestobemadeatboottime,
including modifying kernel parameters and even selecting among different
kernelsthatcanbebooted.Asanexample,thefollowingarekernelparameters
fromthespecialLinuxfile/proc/cmdline,whichisusedatboottime:
BOOT IMAGE=/boot/vmlinuz-4.4.0-59-generic
root=UUID=5f2e2232-4e47-4fe8-ae94-45ea749a5c92
BOOT IMAGE is the name of the kernel image to be loaded into memory, and
rootspecifiesauniqueidentifieroftherootfilesystem.2.10 Operating-SystemDebugging 95
To save space as well as decrease boot time, the Linux kernel image is a
compressedfilethatisextractedafteritisloadedintomemory.Duringtheboot
process,thebootloadertypicallycreatesatemporaryRAMfilesystem,known
asinitramfs.Thisfilesystemcontainsnecessarydriversandkernelmodules
thatmustbeinstalledtosupporttherealrootfilesystem(whichisnotinmain
memory).Oncethekernelhasstartedandthenecessarydriversareinstalled,
the kernel switches the root file system from the temporary RAM location to
the appropriate root file system location. Finally, Linux creates the systemd
process, the initial process in the system, and then starts other services (for
example, a web server and/or database). Ultimately, the system will present
the user with a login prompt. In Section 11.5.2, we describe the boot process
forWindows.
It is worthwhile to note that the booting mechanism is not independent
from the boot loader. Therefore, there are specific versions of the GRUB boot
loaderforBIOSandUEFI,andthefirmwaremustknowaswellwhichspecific
bootloaderistobeused.
The boot process for mobile systems is slightly different from that for
traditionalPCs.Forexample,althoughitskernelisLinux-based,Androiddoes
not use GRUB and instead leaves it up to vendors to provide boot loaders.
The most common Android boot loader is LK (for “little kernel”). Android
systemsusethesamecompressedkernelimageasLinux,aswellasaninitial
RAM file system. However, whereas Linux discards the initramfs once all
necessarydrivershavebeenloaded,Androidmaintainsinitramfsastheroot
file system for the device. Once the kernel has been loaded and the root file
system mounted, Android starts the init process and creates a number of
servicesbeforedisplayingthehomescreen.
Finally, boot loaders for most operating systems—including Windows,
Linux, and macOS, as well as both iOS and Android—provide booting into
recovery mode or single-user mode for diagnosing hardware issues, fixing
corruptfilesystems,andevenreinstallingtheoperatingsystem.Inadditionto
hardwarefailures,computersystemscansufferfromsoftwareerrorsandpoor
operating-systemperformance,whichweconsiderinthefollowingsection.
2.10 Operating-System Debugging
Wehavementioneddebuggingfromtimetotimeinthischapter.Here,wetake
a closer look. Broadly, debugging is the activity of finding and fixing errors
in a system, both in hardware and in software. Performance problems are
considered bugs, so debugging can also include performance tuning, which
seeks to improve performance by removing processing bottlenecks. In this
section, we explore debugging process and kernel errors and performance
problems.Hardwaredebuggingisoutsidethescopeofthistext.
2.10.1 Failure Analysis
Ifa process fails,most operating systemswrite the error information to a log
fil to alert system administrators or users that the problem occurred. The
operatingsystemcanalsotakeacoredump—acaptureofthememoryofthe
process—andstoreitinafileforlateranalysis.(Memorywasreferredtoasthe96 Chapter2 Operating-SystemStructures
“core”intheearlydaysofcomputing.)Runningprogramsandcoredumpscan
beprobedbyadebugger,whichallowsaprogrammertoexplorethecodeand
memoryofaprocessatthetimeoffailure.
Debugginguser-levelprocesscodeisachallenge.Operating-systemkernel
debugging is even more complex because of the size and complexity of the
kernel,itscontrolofthehardware,andthelackofuser-leveldebuggingtools.
Afailureinthekerneliscalledacrash.Whenacrashoccurs,errorinformation
issavedtoalogfile,andthememorystateissavedtoacrashdump.
Operating-system debugging and process debugging frequently use dif-
ferenttoolsandtechniquesduetotheverydifferentnatureofthesetwotasks.
Consider that a kernel failure in the file-systemcode would make it risky for
thekerneltotrytosaveitsstatetoafileonthefilesystembeforerebooting.A
common technique is to save the kernel’s memory state to a section of disk
set aside for this purpose that contains no file system. If the kernel detects
anunrecoverableerror,itwritestheentirecontentsofmemory,oratleastthe
kernel-ownedpartsofthesystemmemory,tothediskarea.Whenthesystem
reboots,aprocessrunstogatherthedatafromthatareaandwriteittoacrash
dump file within a file system for analysis. Obviously, such strategies would
beunnecessaryfordebuggingordinaryuser-levelprocesses.
2.10.2 Performance Monitoring and Tuning
Wementionedearlierthatperformancetuningseekstoimproveperformance
byremovingprocessingbottlenecks.Toidentifybottlenecks,wemustbeable
to monitor system performance. Thus, the operating system must have some
meansofcomputinganddisplayingmeasuresofsystembehavior.Toolsmay
becharacterizedasprovidingeitherper-processorsystem-wideobservations.
Tomaketheseobservations,tools mayuseoneof twoapproaches—counters
ortracing.Weexploreeachoftheseinthefollowingsections.
2.10.2.1 Counters
Operatingsystemskeeptrack of systemactivitythrough aseriesof counters,
such as the number of system calls made or the number of operations
performed to a network device or disk. The following are examples of Linux
toolsthatusecounters:
Per-Process
• ps—reportsinformationforasingleprocessorselectionofprocesses
• top—reportsreal-timestatisticsforcurrentprocesses
System-Wide
• vmstat—reportsmemory-usagestatistics
• netstat—reportsstatisticsfornetworkinterfaces
• iostat—reportsI/Ousagefordisks2.10 Operating-SystemDebugging 97
Figure2.19 TheWindows10taskmanager.
Most of the counter-basedtools on Linux systemsreadstatisticsfrom the
/proc file system. /proc is a “pseudo” file system that exists only in kernel
memory and is used primarily for querying various per-process as well as
kernel statistics. The /proc file system is organized as a directory hierarchy,
withtheprocess (auniqueintegervalueassignedtoeachprocess)appearing
asasubdirectorybelow/proc.Forexample,thedirectoryentry/proc/2155
would contain per-process statistics for the process with an ID of 2155. There
are/procentriesforvariouskernelstatisticsaswell.Inboththischapterand
Chapter3,weprovideprogrammingprojectswhereyouwillcreateandaccess
the/procfilesystem.
Windows systems provide the Windows Task Manager, a tool that
includes information for current applications as well as processes, CPU and
memory usage, and networking statistics. Ascreen shot of the task manager
inWindows10appearsinFigure2.19.
2.10.3 Tracing
Whereas counter-based tools simply inquire on the current value of certain
statistics that are maintained by the kernel, tracing tools collect data for a
specificevent—suchasthestepsinvolvedinasystem-callinvocation.
ThefollowingareexamplesofLinuxtoolsthattraceevents:
Per-Process
• strace—tracessystemcallsinvokedbyaprocess
• gdb—asource-leveldebugger
System-Wide
• perf—acollectionofLinuxperformancetools
• tcpdump—collectsnetworkpackets98 Chapter2 Operating-SystemStructures
Kernighan’sLaw
“Debuggingistwiceashardaswritingthecodeinthefirstplace.Therefore,
ifyouwritethecodeascleverlyaspossible,youare,bydefinition,notsmart
enoughtodebugit.”
Making operating systems easier to understand, debug, and tune as they
run is an active area of research and practice. A new generation of kernel-
enabledperformanceanalysistoolshasmadesignificantimprovementsinhow
this goal can be achieved.Next,we discuss BCC, a toolkit for dynamic kernel
tracinginLinux.
2.10.4 BCC
Debugging the interactions between user-level and kernel code is nearly
impossiblewithoutatoolsetthatunderstandsbothsetsofcodeandcaninstru-
ment their interactions. For that toolset to be truly useful, it must be able to
debuganyareaofasystem,includingareasthatwerenotwrittenwithdebug-
ginginmind,anddosowithoutaffectingsystemreliability.Thistoolsetmust
also have a minimal performance impact—ideally it should have no impact
whennotinuseandaproportionalimpactduringuse.TheBCCtoolkitmeets
these requirements and provides a dynamic, secure, low-impact debugging
environment.
BCC (BPF Compiler Collection) is a rich toolkit that provides tracing fea-
tures for Linux systems. BCC is a front-end interface to the eBPF (extended
Berkeley Packet Filter) tool. The BPF technology was developed in the early
1990sforfilteringtrafficacrossacomputernetwork.The“extended” BPF(eBPF)
addedvariousfeaturestoBPF.eBPFprogramsarewritteninasubsetofCand
arecompiledintoeBPFinstructions,whichcanbedynamicallyinsertedintoa
running Linux system. The eBPF instructions can be used to capture specific
events(suchasacertainsystemcallbeinginvoked)ortomonitorsystemper-
formance(suchasthetimerequiredtoperformdiskI/O).ToensurethateBPF
instructionsarewellbehaved,theyarepassedthroughaverifie beforebeing
inserted into the running Linux kernel. The verifier checks to make sure that
theinstructionsdonotaffectsystemperformanceorsecurity.
AlthougheBPFprovidesarichsetoffeaturesfortracingwithintheLinux
kernel, it traditionally has been very difficult to develop programs using its
Cinterface.BCCwas developedtomakeiteasiertowritetoolsusing eBPFby
providingafront-endinterfaceinPython.ABCCtooliswritteninPythonand
itembedsCcodethatinterfaceswiththeeBPFinstrumentation,whichinturn
interfaceswiththekernel.TheBCCtoolalsocompilestheCprogramintoeBPF
instructions and inserts it into the kernel using either probes or tracepoints,
twotechniquesthatallowtracingeventsintheLinuxkernel.
The specifics of writing custom BCC tools are beyond the scope of this
text, but the BCC package (which is installed on the Linux virtual machine
we provide) provides a number of existing tools that monitor several areas2.10 Operating-SystemDebugging 99
ofactivityinarunningLinuxkernel.Asanexample,theBCCdisksnooptool
tracesdiskI/Oactivity.Enteringthecommand
./disksnoop.py
generatesthefollowingexampleoutput:
TIME(s) T BYTES LAT(ms)
1946.29186700 R 8 0.27
1946.33965000 R 8 0.26
1948.34585000 W 8192 0.96
1950.43251000 R 4096 0.56
1951.74121000 R 4096 0.35
ThisoutputtellsusthetimestampwhentheI/Ooperationoccurred,whether
the I/Owas aRead or Writeoperation, and how many bytes were involvedin
theI/O.Thefinalcolumnreflectstheduration(expressedaslatencyorLAT)in
millisecondsoftheI/O.
Many of the tools provided by BCC can be used for specific applications,
such as MySQL databases, as well as Java and Python programs. Probes can
also be placed to monitor the activity of a specific process. For example, the
command
./opensnoop -p 1225
willtraceopen()systemcallsperformedonlybytheprocesswithanidentifier
of1225.
Figure2.20 TheBCCandeBPFtracingtools.100 Chapter2 Operating-SystemStructures
What makes BCC especially powerful is that its tools can be used on
liveproductionsystemsthatarerunningcriticalapplicationswithoutcausing
harmtothesystem.Thisisparticularlyusefulforsystemadministratorswho
mustmonitorsystemperformancetoidentifypossiblebottlenecksorsecurity
exploits. Figure 2.20 illustrates the wide range of tools currently providedby
BCCandeBPFandtheirabilitytotraceessentiallyanyareaoftheLinuxoperat-
ingsystem.BCCisarapidlychangingtechnologywithnewfeaturesconstantly
beingadded.
2.11 Summary
• An operating system provides an environment for the execution of pro-
gramsbyprovidingservicestousersandprograms.
• The three primary approaches for interacting with an operating system
are(1)commandinterpreters,(2)graphicaluserinterfaces,and(3)touch-
screeninterfaces.
• Systemcallsprovideaninterfacetotheservicesmadeavailablebyanoper-
ating system.Programmers use a systemcall’s application programming
interface(API)foraccessingsystem-callservices.
• System calls can be dividedinto six major categories: (1) process control,
(2)filemanagement,(3)devicemanagement,(4)informationmaintenance,
(5)communications,and(6)protection.
• The standard C library provides the system-call interface for UNIX and
Linuxsystems.
• Operatingsystemsalsoincludeacollectionofsystemprogramsthatpro-
videutilitiestousers.
• Alinkercombines severalrelocatableobjectmodulesintoasinglebinary
executable file. A loader loads the executable file into memory, where it
becomeseligibletorunonanavailableCPU.
• Thereareseveralreasonswhyapplicationsareoperating-systemspecific.
Theseincludedifferentbinaryformatsforprogramexecutables,different
instruction sets for different CPUs, and system calls that vary from one
operatingsystemtoanother.
• Anoperatingsystemisdesignedwithspecificgoalsinmind.Thesegoals
ultimatelydeterminetheoperatingsystem’spolicies.Anoperatingsystem
implementsthesepoliciesthroughspecificmechanisms.
• Amonolithic operating system has no structure; all functionality is pro-
vided in a single, static binary file that runs in a single address space.
Although such systems are difficult to modify, their primary benefit is
efficiency.
• A layered operating system is divided into a number of discrete layers,
wherethe bottom layeristhe hardwareinterface and the highest layeris
theuserinterface.Althoughlayeredsoftwaresystemshavehadsomesuc-FurtherReading 101
cess,thisapproachisgenerallynotidealfordesigningoperatingsystems
duetoperformanceproblems.
• Themicrokernelapproachfordesigningoperatingsystemsusesaminimal
kernel;mostservicesrunasuser-levelapplications.Communicationtakes
placeviamessagepassing.
• Amodularapproachfordesigningoperatingsystemsprovidesoperating-
systemservicesthroughmodulesthatcanbeloadedandremovedduring
runtime.Manycontemporaryoperatingsystemsareconstructedashybrid
systemsusingacombinationofamonolithickernelandmodules.
• Abootloaderloadsanoperatingsystemintomemory,performsinitializa-
tion,andbeginssystemexecution.
• The performance of an operating system can be monitored using either
counters or tracing. Counters are a collection of system-wide or per-
processstatistics,whiletracingfollowstheexecutionofaprogramthrough
theoperatingsystem.
Practice Exercises
2.1 Whatisthepurposeofsystemcalls?
2.2 What is the purpose of the command interpreter? Why is it usually
separatefromthekernel?
2.3 Whatsystemcallshavetobeexecutedbyacommandinterpreterorshell
inordertostartanewprocessonaUNIXsystem?
2.4 Whatisthepurposeofsystemprograms?
2.5 Whatisthemainadvantageofthelayeredapproachtosystemdesign?
Whatarethedisadvantagesofthelayeredapproach?
2.6 Listfiveservicesprovidedbyanoperatingsystem,andexplainhoweach
createsconvenienceforusers.Inwhichcaseswoulditbeimpossiblefor
user-levelprogramstoprovidetheseservices?Explainyouranswer.
2.7 Why do some systems store the operating system in firmware, while
othersstoreitondisk?
2.8 Howcouldasystembedesignedtoallowachoiceofoperatingsystems
fromwhichtoboot?Whatwouldthebootstrapprogramneedtodo?
Further Reading
[Bryant and O’Hallaron (2015)] provide an overview of computer systems,
includingtheroleofthelinkerandloader.[Atlidakisetal.(2016)]discussPOSIX
systemcallsandhowtheyrelatetomodernoperatingsystems.[Levin(2013)]
coverstheinternalsofbothmacOSandiOS,and[Levin(2015)]describesdetails
oftheAndroidsystem.Windows10internalsarecoveredin[Russinovichetal.
(2017)]. BSD UNIX is described in [McKusick et al. (2015)]. [Love (2010)] and102 Chapter2 Operating-SystemStructures
[Mauerer(2008)]thoroughlydiscusstheLinuxkernel.Solarisisfullydescribed
in[McDougallandMauro(2007)].
Linux source code is available at http://www.kernel.org. The Ubuntu ISO
imageisavailablefromhttps://www.ubuntu.com/.
Comprehensive coverage of Linux kernel modules can be found at
http://www.tldp.org/LDP/lkmpg/2.6/lkmpg.pdf.[Ward(2015)]andhttp://www
.ibm.com/developerworks/linux/library/l-linuxboot/ describe the Linux boot
processusingGRUB.Performancetuning—with afocus onLinuxandSolaris
systems—iscoveredin[Gregg(2014)].DetailsfortheBCCtoolkitcanbefound
athttps://github.com/iovisor/bcc/#tools.
Bibliography
[Atlidakisetal.(2016)] V. Atlidakis, J. Andrus, R. Geambasu, D. Mitropoulos,
and J. Nieh,“POSIXAbstractions in ModernOperatingSystems: TheOld, the
New,andtheMissing”(2016),pages19:1–19:17.
[BryantandO’Hallaron(2015)] R.BryantandD.O’Hallaron,ComputerSystems:
AProgrammer’sPerspective,ThirdEdition(2015).
[Gregg(2014)] B.Gregg,SystemsPerformance–EnterpriseandtheCloud,Pearson
(2014).
[Levin(2013)] J. Levin, Mac OS X and iOS Internals to the Apple’s Core, Wiley
(2013).
[Levin(2015)] J. Levin, Android Internals–A Confectioner’s Cookbook. Volume I
(2015).
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[Mauerer(2008)] W.Mauerer,ProfessionalLinux KernelArchitecture,JohnWiley
andSons(2008).
[McDougallandMauro(2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition,PrenticeHall(2007).
[McKusicketal.(2015)] M.K.McKusick,G.V.Neville-Neil,andR.N.M.Wat-
son,TheDesignandImplementationoftheFreeBSDUNIXOperatingSystem–Second
Edition,Pearson(2015).
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).
[Ward(2015)] B. Ward, How LINUX Works–WhatEvery Superuser Should Know,
SecondEdition,NoStarchPress(2015).EX-3
Chapter 2 Exercises
2.9 The services and functions provided by an operating system can be
divided into two main categories. Briefly describe the two categories,
anddiscusshowtheydiffer.
2.10 Describethreegeneralmethodsforpassingparameterstotheoperating
system.
2.11 Describehowyoucouldobtainastatisticalprofileoftheamountoftime
a program spends executing different sections of its code. Discuss the
importanceofobtainingsuchastatisticalprofile.
2.12 Whataretheadvantagesanddisadvantagesofusingthesamesystem-
callinterfaceformanipulatingbothfilesanddevices?
2.13 Woulditbepossiblefortheusertodevelopanewcommandinterpreter
usingthesystem-callinterfaceprovidedbytheoperatingsystem?
2.14 DescribewhyAndroidusesahead-of-time(AOT)ratherthanjust-in-time
(JIT)compilation.
2.15 Whatarethetwomodelsofinterprocesscommunication?Whatarethe
strengthsandweaknessesofthetwoapproaches?
2.16 Contrastandcompareanapplicationprogramminginterface(API)and
anapplicationbinaryinterface(ABI).
2.17 Whyistheseparationofmechanismandpolicydesirable?
2.18 Itissometimesdifficulttoachievealayeredapproachiftwocomponents
oftheoperatingsystemaredependentoneachother.Identifyascenario
inwhichitisunclearhowtolayertwosystemcomponentsthatrequire
tightcouplingoftheirfunctionalities.
2.19 What is the main advantage of the microkernel approach to system
design?Howdouserprogramsandsystemservicesinteractinamicro-
kernelarchitecture?Whatarethedisadvantagesofusingthemicroker-
nelapproach?
2.20 Whataretheadvantagesofusingloadablekernelmodules?
2.21 HowareiOSandAndroidsimilar?Howaretheydifferent?
2.22 ExplainwhyJavaprogramsrunningonAndroidsystemsdonotusethe
standardJavaAPIandvirtualmachine.
2.23 The experimental Synthesis operating system has an assembler incor-
porated in the kernel. To optimize system-call performance, the kernel
assemblesroutineswithinkernelspacetominimizethepaththatthesys-
temcallmusttakethroughthekernel.Thisapproachistheantithesisof
thelayeredapproach,inwhichthepaththroughthekernelisextended
tomakebuildingtheoperatingsystemeasier.Discusstheprosandcons
of the Synthesis approach to kernel design and system-performance
optimization.P-1 Chapter2 Operating-SystemStructures
Programming Problems
2.24 InSection2.3,wedescribedaprogramthatcopiesthecontentsofonefile
toadestinationfile.Thisprogramworksbyfirstpromptingtheuserfor
the name of the source and destination files. Write this program using
eitherthe POSIX orWindows API. Besuretoincludeallnecessaryerror
checking,includingensuringthatthesourcefileexists.
Onceyouhavecorrectlydesignedandtestedtheprogram,ifyouused
asystemthatsupportsit,runtheprogramusingautilitythattracessys-
temcalls.Linuxsystemsprovidethestraceutility,andmacOSsystems
use the dtruss command. (The dtruss command, which actually is a
frontendtodtrace,requiresadminprivileges,soitmustberunusing
sudo.)Thesetoolscanbeusedasfollows(assumethatthenameofthe
executablefileisFileCopy:
Linux:
strace ./FileCopy
macOS:
sudo dtruss ./FileCopy
Since Windows systems do not provide such a tool, you will have to
tracethroughtheWindowsversionofthisprogramusingadebugger.
Programming Projects
Introduction to Linux Kernel Modules
Inthisproject,youwilllearnhowtocreateakernelmoduleandloaditintothe
Linuxkernel.Youwillthenmodifythekernelmodulesothatitcreatesanentry
inthe/procfilesystem.TheprojectcanbecompletedusingtheLinuxvirtual
machinethatisavailablewiththistext.Althoughyoumayuseanytexteditor
to write these C programs, you will have to use the terminal application to
compiletheprograms,andyouwillhavetoentercommandsonthecommand
linetomanagethemodulesinthekernel.
As you’ll discover, the advantage of developing kernel modules is that it
is a relatively easy method of interacting with the kernel, thus allowing you
towriteprogramsthatdirectlyinvokekernelfunctions.Itisimportantforyou
tokeepinmindthatyouareindeedwritingkernelcodethatdirectlyinteracts
withthe kernel.That normally means that any errorsin the codecould crash
the system! However, since you will be using a virtual machine, any failures
willatworstonlyrequirerebootingthesystem.ProgrammingProjects P-2
I.KernelModulesOverview
Thefirstpartofthisprojectinvolvesfollowingaseriesofstepsforcreatingand
insertingamoduleintotheLinuxkernel.
You can list all kernel modules that are currently loaded by entering the
command
lsmod
This command will list the current kernel modules in three columns: name,
size,andwherethemoduleisbeingused.
#include <linux/init.h>
#include <linux/kernel.h>
#include <linux/module.h>
/* This function is called when the module is loaded. */
int simple init(void)
{
printk(KERN INFO "Loading Kernel Module∖n");
return 0;
}
/* This function is called when the module is removed. */
void simple exit(void)
{
printk(KERN INFO "Removing Kernel Module∖n");
}
/* Macros for registering module entry and exit points. */
module init(simple init);
module exit(simple exit);
MODULE LICENSE("GPL");
MODULE DESCRIPTION("Simple Module");
MODULE AUTHOR("SGG");
Figure2.21 Kernelmodulesimple.c.
The program in Figure 2.21 (named simple.c and available with the
source code for this text) illustrates a very basic kernel module that prints
appropriatemessageswhenitisloadedandunloaded.
Thefunctionsimple init()isthemoduleentrypoint,whichrepresents
thefunctionthatisinvokedwhenthemoduleisloadedintothekernel.Simi-
larly,thesimple exit()functionisthemoduleexitpoint—thefunctionthat
iscalledwhenthemoduleisremovedfromthekernel.P-3 Chapter2 Operating-SystemStructures
The module entry point function must return an integer value, with 0
representingsuccessandanyothervaluerepresentingfailure.Themoduleexit
point function returns void. Neither the module entry point nor the module
exit point is passed any parameters. The two following macros are used for
registeringthemoduleentryandexitpointswiththekernel:
module init(simple init)
module exit(simple exit)
Notice in the figure how the module entry and exit point functions make
callstotheprintk()function.printk()isthekernelequivalentofprintf(),
but its output is sent to a kernel log buffer whose contents can be read by
thedmesgcommand.Onedifferencebetweenprintf()andprintk()isthat
printk() allows us to specify a priority flag, whose values are given in the
<linux/printk.h> include file. In this instance, the priority is KERN INFO,
whichisdefinedasaninformationalmessage.
The final lines—MODULE LICENSE(), MODULE DESCRIPTION(), and MOD-
ULE AUTHOR()—represent details regarding the software license, description
of the module, and author. For our purposes, we do not require this infor-
mation,butweincludeitbecauseitisstandardpracticeindevelopingkernel
modules.
This kernel module simple.c is compiled using the Makefile accom-
panying the source code with this project. To compile the module, enter the
followingonthecommandline:
make
The compilation produces several files. The file simple.ko represents the
compiledkernel module.The following step illustratesinserting this module
intotheLinuxkernel.
II.LoadingandRemovingKernelModules
Kernel modules are loaded using the insmod command, which is run as fol-
lows:
sudo insmod simple.ko
Tocheckwhetherthemodulehasloaded,enterthelsmodcommandandsearch
forthemodulesimple.Recallthatthemoduleentrypointisinvokedwhenthe
moduleisinsertedintothekernel.Tocheckthecontentsofthismessageinthe
kernellogbuffer,enterthecommand
dmesg
Youshouldseethemessage"Loading Module."
Removing the kernel module involves invoking the rmmod command
(noticethatthe.kosuffixisunnecessary):
sudo rmmod simpleProgrammingProjects P-4
Be sure to check with the dmesg command to ensure the module has been
removed.
Because the kernel log buffer can fill up quickly, it often makes sense to
clearthebufferperiodically.Thiscanbeaccomplishedasfollows:
sudo dmesg -c
Proceedthroughthestepsdescribedabovetocreatethekernelmoduleand
toloadandunloadthemodule.Besuretocheckthecontentsofthekernellog
bufferusingdmesgtoensurethatyouhavefollowedthestepsproperly.
As kernel modules are running within the kernel, it is possible to obtain
valuesandcallfunctionsthatareavailableonlyinthekernelandnottoregular
userapplications.Forexample,theLinuxincludefile<linux/hash.h>defines
several hashing functions for use within the kernel. This file also defines the
constantvalueGOLDEN RATIO PRIME(whichisdefinedasanunsigned long).
Thisvaluecanbeprintedoutasfollows:
printk(KERN INFO "%lu∖n", GOLDEN RATIO PRIME);
Asanotherexample,theincludefile<linux/gcd.h>definesthefollowing
function
unsigned long gcd(unsigned long a, unsigned b);
whichreturnsthegreatestcommondivisoroftheparametersaandb.
Onceyouareabletocorrectlyloadandunloadyourmodule,completethe
followingadditionalsteps:
1. PrintoutthevalueofGOLDEN RATIO PRIMEinthesimple init()func-
tion.
2. Print out the greatest common divisor of 3,300 and 24 in the sim-
ple exit()function.
Ascompilererrorsarenotoftenhelpfulwhenperformingkerneldevelopment,
it is important to compile your program often by running make regularly. Be
sure to load and remove the kernel module and check the kernel log buffer
usingdmesgtoensurethatyourchangestosimple.careworkingproperly.
In Section 1.4.3, we described the role of the timer as well as the timer
interrupthandler.InLinux,therateatwhichthetimerticks(thetickrate)isthe
valueHZdefinedin<asm/param.h>.ThevalueofHZdeterminesthefrequency
of the timer interrupt, and its value varies by machine type and architecture.
For example, if the value of HZ is 100, a timer interrupt occurs 100 times per
second, or every 10 milliseconds. Additionally, the kernel keeps track of the
globalvariablejiffies,whichmaintainsthenumberoftimerinterruptsthat
haveoccurredsincethesystemwasbooted.Thejiffiesvariableisdeclared
inthefile<linux/jiffies.h>.
1. PrintoutthevaluesofjiffiesandHZinthesimple init()function.
2. Printoutthevalueofjiffiesinthesimple exit()function.P-5 Chapter2 Operating-SystemStructures
Before proceeding to the next set of exercises, consider how you can use
the different values of jiffies in simple init() and simple exit() to
determinethe number of seconds that have elapsedsince the time the kernel
modulewasloadedandthenremoved.
III.The/proc FileSystem
The/procfilesystemisa“pseudo”filesystemthatexistsonlyinkernelmem-
oryandisusedprimarilyforqueryingvariouskernelandper-processstatistics.
#include <linux/init.h>
#include <linux/kernel.h>
#include <linux/module.h>
#include <linux/proc fs.h>
#include <asm/uaccess.h>
#define BUFFER SIZE 128
#define PROC NAME "hello"
ssize t proc read(struct file *file, char user *usr buf,
size t count, loff t *pos);
static struct file operations proc ops = {
.owner = THIS MODULE,
.read = proc read,
};
/* This function is called when the module is loaded. */
int proc init(void)
{
/* creates the /proc/hello entry */
proc create(PROC NAME, 0666, NULL, &proc ops);
return 0;
}
/* This function is called when the module is removed. */
void proc exit(void)
{
/* removes the /proc/hello entry */
remove proc entry(PROC NAME, NULL);
}
Figure2.22 The/procfile-systemkernelmodule,Part1
Thisexerciseinvolvesdesigningkernelmodulesthatcreateadditionalentries
inthe/procfilesysteminvolvingbothkernelstatisticsandinformationrelatedProgrammingProjects P-6
tospecificprocesses.TheentireprogramisincludedinFigure2.22andFigure
2.23.
We begin by describing how to create a new entry in the /proc file sys-
tem.Thefollowingprogramexample(namedhello.candavailablewiththe
sourcecodeforthistext)createsa/procentrynamed/proc/hello.Ifauser
entersthecommand
cat /proc/hello
theinfamousHello Worldmessageisreturned.
/* This function is called each time /proc/hello is read */
ssize t proc read(struct file *file, char user *usr buf,
size t count, loff t *pos)
{
int rv = 0;
char buffer[BUFFER SIZE];
static int completed = 0;
if (completed) {
completed = 0;
return 0;
}
completed = 1;
rv = sprintf(buffer, "Hello World∖n");
/* copies kernel space buffer to user space usr buf */
copy to user(usr buf, buffer, rv);
return rv;
}
module init(proc init);
module exit(proc exit);
MODULE LICENSE("GPL");
MODULE DESCRIPTION("Hello Module");
MODULE AUTHOR("SGG");
Figure2.23 The/procfilesystemkernelmodule,Part2
Inthemoduleentrypointproc init(),wecreatethenew/proc/hello
entry using the proc create() function. This function is passed proc ops,
whichcontainsareferencetoastruct file operations.Thisstructinitial-P-7 Chapter2 Operating-SystemStructures
izes the .owner and .read members. The value of .read is the name of the
functionproc read()thatistobecalledwhenever/proc/helloisread.
Examining this proc read() function, we see that the string "Hello
World∖n"iswrittentothevariablebufferwherebufferexistsinkernelmem-
ory. Since /proc/hello can be accessed from user space, we must copy the
contents of buffer to user space using the kernel function copy to user().
This function copies the contents of kernel memory buffer to the variable
usr buf,whichexistsinuserspace.
Eachtimethe/proc/hellofileisread,theproc read()functioniscalled
repeatedly until it returns 0, so there must be logic to ensure that this func-
tion returns 0 once it has collected the data (in this case, the string "Hello
World∖n")thatistogointothecorresponding/proc/hellofile.
Finally, notice that the /proc/hello file is removed in the module exit
pointproc exit()usingthefunctionremove proc entry().
IV.Assignment
Thisassignmentwillinvolvedesigningtwokernelmodules:
1. Designakernelmodulethatcreatesa/procfilenamed/proc/jiffies
that reportsthe current valueof jiffieswhen the /proc/jiffiesfile
isread,suchaswiththecommand
cat /proc/jiffies
Besuretoremove/proc/jiffieswhenthemoduleisremoved.
2. Design a kernel module that creates a proc file named /proc/seconds
thatreportsthenumberofelapsedsecondssincethekernelmodulewas
loaded. This will involve using the value of jiffies as well as the HZ
rate.Whenauserentersthecommand
cat /proc/seconds
your kernel module will report the number of seconds that have
elapsed since the kernel module was first loaded. Be sure to remove
/proc/secondswhenthemoduleisremoved.Part Two
Process
Management
A process is a program in execution. A process will need certain
resources—such as CPU time, memory, files, and I/O devices—to
accomplish its task. These resources are typically allocated to the
processwhileitisexecuting.
A process is the unit of work in most systems. Systems consist of
a collection of processes: operating-system processes execute system
code, and user processes execute user code. All these processes may
executeconcurrently.
Modern operating systems support processes having multiple
threadsofcontrol.Onsystemswithmultiplehardwareprocessingcores,
thesethreadscanruninparallel.
One of the most important aspects of an operating system is how it
schedules threads onto available processing cores. Several choices for
designingCPUschedulersareavailabletoprogrammers.3
CHAPTER
Processes
Earlycomputersallowedonlyoneprogramtobeexecutedatatime.Thispro-
gram had complete control of the system and had access to all the system’s
resources. In contrast, contemporary computer systems allow multiple pro-
grams to be loaded into memory and executed concurrently. This evolution
required firmer control and more compartmentalization of the various pro-
grams;andtheseneedsresultedinthenotionofaprocess,whichisaprogram
inexecution.Aprocessistheunitofworkinamoderncomputingsystem.
Themorecomplextheoperatingsystemis,themoreitisexpectedtodoon
behalfofitsusers.Althoughitsmainconcernistheexecutionofuserprograms,
italsoneedstotakecareofvarioussystemtasksthatarebestdoneinuserspace,
rather than within the kernel. A system therefore consists of a collection of
processes,someexecutingusercode,othersexecutingoperatingsystemcode.
Potentially,alltheseprocessescanexecuteconcurrently,withtheCPU(orCPUs)
multiplexedamongthem.Inthischapter,youwillreadaboutwhatprocesses
are,howtheyarerepresentedinanoperatingsystem,andhowtheywork.
CHAPTER OBJECTIVES
• Identifytheseparatecomponentsofaprocessandillustratehowtheyare
representedandscheduledinanoperatingsystem.
(cid:129) Describe how processes are created and terminated in an operating sys-
tem, including developing programs using the appropriate system calls
thatperformtheseoperations.
(cid:129) Describeandcontrastinterprocesscommunicationusingsharedmemory
andmessagepassing.
(cid:129) Design programs that use pipes and POSIX shared memory to perform
interprocesscommunication.
(cid:129) Describe client–server communication using sockets and remote proce-
durecalls.
(cid:129) DesignkernelmodulesthatinteractwiththeLinuxoperatingsystem.
105106 Chapter3 Processes
3.1 Process Concept
A question that arises in discussing operating systems involves what to call
alltheCPUactivities.Earlycomputerswerebatchsystemsthatexecutedjobs,
followedbytheemergenceoftime-sharedsystemsthatranuserprograms,or
tasks.Evenonasingle-usersystem,ausermaybeabletorunseveralprograms
atonetime:awordprocessor,awebbrowser,andane-mailpackage.Andeven
ifacomputercanexecuteonlyoneprogramatatime,suchasonanembedded
devicethatdoesnotsupportmultitasking,theoperatingsystemmayneedto
supportitsowninternalprogrammedactivities,suchasmemorymanagement.
Inmanyrespects,alltheseactivitiesaresimilar,sowecallallofthemprocesses.
Although we personally prefer the more contemporary term process, the
term job has historical significance, as much of operating system theory and
terminologywasdevelopedduringatimewhenthemajoractivityofoperating
systems was jobprocessing. Therefore,in some appropriateinstances we use
jobwhendescribingtheroleoftheoperatingsystem.Asanexample,itwould
be misleading to avoid the use of commonly accepted terms that include the
wordjob(suchasjobscheduling)simplybecauseprocesshassupersededjob.
3.1.1 The Process
Informally,asmentionedearlier,aprocessisaprograminexecution.Thestatus
ofthecurrentactivityofaprocessisrepresentedbythevalueoftheprogram
counterandthecontentsoftheprocessor’sregisters.Thememorylayoutofa
processistypicallydividedintomultiplesections,andisshowninFigure3.1.
Thesesectionsinclude:
• Textsection—theexecutablecode
• Datasection—globalvariables
max
stack
heap
data
text
0
Figure3.1 Layoutofaprocessinmemory.3.1 ProcessConcept 107
• Heapsection—memorythatisdynamicallyallocatedduringprogramrun
time
• Stacksection—temporarydatastoragewheninvokingfunctions(suchas
functionparameters,returnaddresses,andlocalvariables)
Noticethatthesizesofthetextanddatasectionsarefixed,astheirsizesdo
notchangeduringprogramruntime.However,thestackandheapsectionscan
shrinkandgrowdynamicallyduringprogramexecution.Eachtimeafunction
iscalled,anactivationrecordcontainingfunctionparameters,localvariables,
andthereturnaddressispushedontothestack;whencontrolisreturnedfrom
thefunction,theactivationrecordispoppedfromthestack.Similarly,theheap
willgrowasmemoryisdynamicallyallocated,andwillshrinkwhenmemory
isreturnedtothesystem.Althoughthestackandheapsectionsgrowtoward
oneanother,theoperatingsystemmustensuretheydonotoverlaponeanother.
We emphasize that a program by itself is not a process. A program is a
passive entity, such as a file containing a list of instructions stored on disk
(often called an executable fil ). In contrast, a process is an active entity,
with a program counter specifying the next instruction to execute and a set
ofassociatedresources.Aprogrambecomesaprocesswhenanexecutablefile
is loaded into memory. Two common techniques for loading executable files
are double-clicking an icon representing the executable file and entering the
nameoftheexecutablefileonthecommandline(asinprog.exeora.out).
Although two processes may be associated with the same program, they
are nevertheless considered two separate execution sequences. For instance,
severalusersmayberunningdifferentcopiesofthemailprogram,orthesame
usermayinvokemanycopiesofthewebbrowserprogram.Eachoftheseisa
separateprocess;andalthoughthetextsectionsareequivalent,thedata,heap,
andstacksectionsvary.Itisalsocommontohaveaprocessthatspawnsmany
processesasitruns.WediscusssuchmattersinSection3.4.
Notethataprocesscanitselfbeanexecutionenvironmentforothercode.
The Java programming environment provides a good example. In most cir-
cumstances, an executable Java program is executed within the Java virtual
machine (JVM). The JVM executes as a process that interprets the loaded Java
codeandtakesactions(vianativemachineinstructions)onbehalfofthatcode.
For example, to run the compiled Java program Program.class, we would
enter
java Program
The command java runs the JVM as an ordinary process, which in turns
executestheJavaprogramPrograminthevirtualmachine.Theconceptisthe
sameassimulation,exceptthatthecode,insteadofbeingwrittenforadifferent
instructionset,iswrittenintheJavalanguage.
3.1.2 Process State
Asaprocessexecutes,itchangesstate.Thestateofaprocessisdefinedinpart
bythecurrentactivityofthatprocess.Aprocessmaybeinoneofthefollowing
states:108 Chapter3 Processes
MEMORYLAYOUTOFACPROGRAM
The figure shown below illustrates the layout of a C program in memory,
highlighting how the different sections of a process relate to an actual C
program.Thisfigureissimilartothegeneralconceptofaprocessinmemory
asshowninFigure3.1,withafewdifferences:
• Theglobaldatasectionisdividedintodifferentsectionsfor(a)initialized
dataand(b)uninitializeddata.
• Aseparatesectionisprovidedfortheargcandargvparameterspassed
tothemain()function.
#include <stdio.h>
high #include <stdlib.h>
argc, agrv
memory
stack int x;
int y = 15;
int main(int argc, char *argv[])
{
int *values;
int i;
heap
uninitialized
values = (int *)malloc(sizeof(int)*5);
data
initialized for(i = 0; i < 5; i++)
data values[i] = i;
low
text return 0;
memory }
TheGNUsize commandcanbe usedto determinethesize (in bytes)of
someofthesesections.Assumingthenameoftheexecutablefileoftheabove
Cprogramismemory,thefollowingistheoutputgeneratedbyenteringthe
commandsize memory:
text data bss dec hex filename
1158 284 8 1450 5aa memory
Thedatafieldreferstouninitializeddata,andbssreferstoinitializeddata.
(bssisahistoricaltermreferringtoblockstartedbysymbol.)Thedecand
hex values are the sum of the three sections represented in decimal and
hexadecimal,respectively.
• New.Theprocessisbeingcreated.
• Running.Instructionsarebeingexecuted.
• Waiting. The process is waiting for some event to occur (such as an I/O
completionorreceptionofasignal).
• Ready.Theprocessiswaitingtobeassignedtoaprocessor.3.1 ProcessConcept 109
new admitted interrupt exit terminated
ready running
scheduler dispatch
I/O or event completion I/O or event wait
waiting
Figure3.2 Diagramofprocessstate.
• Terminated.Theprocesshasfinishedexecution.
Thesenamesarearbitrary,andtheyvaryacrossoperatingsystems.Thestates
thatthey representarefound onall systems,however.Certainoperatingsys-
tems also more finely delineate process states. It is important to realize that
only one process can be running on any processor core at any instant. Many
processesmaybereadyandwaiting,however.Thestatediagramcorresponding
tothesestatesispresentedinFigure3.2.
3.1.3 Process Control Block
Each process is represented in the operating system by a process control
block (PCB)—also called a task control block. APCB is shown in Figure 3.3.
It contains many pieces of information associated with a specific process,
includingthese:
• Processstate.Thestatemaybenew,ready,running,waiting,halted,and
soon.
• Programcounter.Thecounterindicatestheaddressofthenextinstruction
tobeexecutedforthisprocess.
process state
process number
program counter
registers
memory limits
list of open files
• • •
Figure3.3 Processcontrolblock(PCB).110 Chapter3 Processes
• CPU registers. The registers vary in number and type, depending on the
computer architecture. They include accumulators, index registers, stack
pointers,andgeneral-purposeregisters,plusanycondition-codeinforma-
tion.Alongwiththeprogramcounter,thisstateinformationmustbesaved
when an interrupt occurs, to allow the process to be continued correctly
afterwardwhenitisrescheduledtorun.
• CPU-scheduling information. This information includes a process prior-
ity,pointerstoscheduling queues,and any other schedulingparameters.
(Chapter5describesprocessscheduling.)
• Memory-management information. This information may include such
itemsasthevalueofthebaseandlimitregistersandthepagetables,orthe
segmenttables,dependingonthememorysystemusedby theoperating
system(Chapter9).
• Accounting information. This information includes the amount of CPU
andrealtimeused,timelimits,accountnumbers,joborprocessnumbers,
andsoon.
• I/O status information. This information includes the list of I/O devices
allocatedtotheprocess,alistofopenfiles,andsoon.
Inbrief,thePCBsimplyservesastherepositoryforallthedataneededtostart,
orrestart,aprocess,alongwithsomeaccountingdata.
3.1.4 Threads
Theprocessmodeldiscussedsofarhasimpliedthataprocessisaprogramthat
performsasinglethreadofexecution.Forexample,whenaprocessisrunning
a word-processor program, a single thread of instructions is being executed.
This single thread of control allows the process to performonly one task at a
time.Thus,theusercannotsimultaneouslytypeincharactersandrunthespell
checker. Most modern operating systems have extended the process concept
to allow a process to have multiplethreads of execution and thus to perform
morethanonetaskatatime.Thisfeatureisespeciallybeneficialonmulticore
systems, where multiple threads can run in parallel. A multithreaded word
processor could, for example, assign one thread to manage user input while
anotherthreadrunsthespellchecker.Onsystemsthatsupportthreads,thePCB
isexpandedtoincludeinformationforeachthread.Otherchangesthroughout
the system are also needed to support threads. Chapter 4 explores threads in
detail.
3.2 Process Scheduling
Theobjectiveofmultiprogrammingistohavesomeprocessrunningatalltimes
so as to maximize CPU utilization. The objective of time sharing is to switch
a CPU core among processes so frequently that users can interact with each
program while it is running. To meet these objectives, the process scheduler
selectsanavailableprocess(possiblyfromasetofseveralavailableprocesses)
forprogramexecutiononacore.EachCPUcorecanrunoneprocessatatime.3.2 ProcessScheduling 111
PROCESSREPRESENTATIONINLINUX
The process control block in the Linux operating system is rep-
resented by the C structure task struct, which is found in the
<include/linux/sched.h> include file in the kernel source-code
directory. This structure contains all the necessary information for
representing a process, including the state of the process, scheduling
andmemory-managementinformation,listofopenfiles,andpointerstothe
process’s parent and a list of its children and siblings. (Aprocess’s parent
is the process that created it; its children are any processes that it creates.
Itssiblingsarechildrenwiththesameparentprocess.)Someofthesefields
include:
long state; /* state of the process */
struct sched entity se; /* scheduling information */
struct task struct *parent; /* this process’s parent */
struct list head children; /* this process’s children */
struct files struct *files; /* list of open files */
struct mm struct *mm; /* address space */
For example, the state of a process is representedby the field long state
inthisstructure.WithintheLinuxkernel,allactiveprocessesarerepresented
usingadoublylinkedlistoftask struct.Thekernelmaintainsapointer–
current–totheprocesscurrentlyexecutingonthesystem,asshownbelow:
struct task_struct struct task_struct struct task_struct
process information process information (cid:129) (cid:129) (cid:129) process information
(cid:129) (cid:129) (cid:129)
(cid:129) (cid:129) (cid:129)
(cid:129) (cid:129) (cid:129)
current
(currently executing proccess)
Asanillustrationofhowthekernelmightmanipulateoneofthefieldsin
thetask structforaspecifiedprocess,let’sassumethesystemwouldlike
tochangethestateoftheprocesscurrentlyrunningtothevaluenew state.
Ifcurrentisapointertotheprocesscurrentlyexecuting,itsstateischanged
withthefollowing:
current->state = new state;
ForasystemwithasingleCPUcore,therewillneverbemorethanoneprocess
running at a time, whereas a multicore system can run multiple processes at
one time. If there are more processes than cores, excess processes will have112 Chapter3 Processes
queue header PCB PCB
7 2
ready head
queue tail registers registers
• •
• •
• •
PCB PCB PCB
3 14 6
wait head
queue tail
Figure3.4 Thereadyqueueandwaitqueues.
to wait until a core is free and can be rescheduled. The number of processes
currentlyinmemoryisknownasthedegreeofmultiprogramming.
Balancing the objectives of multiprogramming and time sharing also
requirestakingthegeneralbehaviorofaprocessintoaccount.Ingeneral,most
processes can be described as either I/O bound or CPU bound. An I/O-bound
process is one that spends more of its time doing I/O than it spends doing
computations. A CPU-bound process, in contrast, generates I/O requests
infrequently,usingmoreofitstimedoingcomputations.
3.2.1 Scheduling Queues
Asprocessesenterthesystem,theyareputintoareadyqueue,wheretheyare
readyandwaitingtoexecuteonaCPU’scoreThisqueueisgenerallystoredas
alinkedlist;aready-queueheadercontainspointerstothefirstPCBinthelist,
and each PCB includes a pointer field that points to the nextPCB in the ready
queue.
Thesystemalsoincludesotherqueues.WhenaprocessisallocatedaCPU
core,itexecutesforawhileandeventuallyterminates,isinterrupted,orwaits
for the occurrence of a particular event, such as the completion of an I/O
request.SupposetheprocessmakesanI/Orequesttoadevicesuchasadisk.
Since devices run significantly slower than processors, the process will have
towaitfortheI/Otobecomeavailable.Processesthatarewaitingforacertain
event to occur — such as completion of I/O — are placed in a wait queue
(Figure3.4).
Acommon representation of process scheduling is a queueing diagram,
suchasthatinFigure3.5.Twotypesofqueuesarepresent:thereadyqueueand
asetofwaitqueues.Thecirclesrepresenttheresourcesthatservethequeues,
andthearrowsindicatetheflowofprocessesinthesystem.
Anew process is initially put in the ready queue. It waits there until it is
selectedforexecution,ordispatched.OncetheprocessisallocatedaCPUcore
andisexecuting,oneofseveraleventscouldoccur:3.2 ProcessScheduling 113
ready queue CPU
I/O I/O wait queue I/O request
time slice
expired
child
child create child
termination
terminates process
wait queue
interrupt interrupt wait for an
occurs wait queue interrupt
Figure3.5 Queueing-diagramrepresentationofprocessscheduling.
• TheprocesscouldissueanI/OrequestandthenbeplacedinanI/Owait
queue.
• Theprocesscouldcreateanewchildprocessandthenbeplacedinawait
queuewhileitawaitsthechild’stermination.
• The process could be removed forcibly from the core, as a result of an
interruptorhavingitstimesliceexpire,andbeputbackinthereadyqueue.
Inthefirsttwocases,theprocesseventuallyswitchesfromthewaitingstate
tothereadystateandisthenputbackinthereadyqueue.Aprocesscontinues
thiscycleuntilitterminates,atwhich timeitisremovedfromallqueuesand
hasitsPCBandresourcesdeallocated.
3.2.2 CPU Scheduling
Aprocessmigratesamongthereadyqueueandvariouswaitqueuesthrough-
out its lifetime. The role of the CPU scheduler is to select from among the
processesthatareinthereadyqueueandallocateaCPUcoretooneofthem.The
CPUschedulermustselectanewprocessfortheCPUfrequently.AnI/O-bound
process may execute for only a few milliseconds before waiting for an I/O
request.AlthoughaCPU-boundprocesswillrequireaCPUcoreforlongerdura-
tions, the scheduler is unlikely to grant the core to a process for an extended
period.Instead,itislikelydesignedtoforciblyremovetheCPUfromaprocess
andscheduleanotherprocesstorun.Therefore,theCPUschedulerexecutesat
leastonceevery100milliseconds,althoughtypicallymuchmorefrequently.
Someoperatingsystemshaveanintermediateformofscheduling,known
as swapping, whose key idea is that sometimes it can be advantageous to
remove a process from memory (and from active contention for the CPU)
and thus reduce the degree of multiprogramming. Later, the process can be
reintroducedintomemory,anditsexecutioncanbecontinuedwhereitleftoff.
This scheme is known as swapping because a process can be “swapped out”114 Chapter3 Processes
frommemorytodisk,whereitscurrentstatusissaved,andlater“swappedin”
from diskback tomemory,whereits statusisrestored.Swappingistypically
onlynecessarywhenmemoryhasbeenovercommittedandmustbefreedup.
SwappingisdiscussedinChapter9.
3.2.3 Context Switch
AsmentionedinSection1.2.1,interruptscausetheoperatingsystemtochange
a CPU core from its current task and to run a kernel routine. Such operations
happenfrequentlyongeneral-purposesystems.Whenaninterruptoccurs,the
system needs to save the current context of the process running on the CPU
coresothatitcanrestorethatcontextwhenitsprocessingisdone,essentially
suspending the process and then resuming it. The context is represented in
the PCB of the process. It includes the value of the CPU registers, the process
state(seeFigure3.2),andmemory-managementinformation.Generically,we
performastatesaveofthecurrentstateoftheCPUcore,beitinkerneloruser
mode,andthenastaterestoretoresumeoperations.
Switching the CPU core to another process requires performing a state
save of the current process and a state restore of a different process. This
task is known as a context switch and is illustrated in Figure 3.6. When a
context switch occurs, the kernel saves the context of the old process in its
PCBandloadsthesavedcontextofthenewprocessscheduledtorun.Context-
switch time is pure overhead, because the system does no useful work while
switching.Switchingspeedvariesfrommachinetomachine,dependingonthe
process P operating system process P
0 1
interrupt or system call
executing
save state into PCB
0
•
• idle
•
reload state from PCB
1
idle interrupt or system call executing
save state into PCB
1
•
• idle
•
reload state from PCB
0
executing
Figure3.6 Diagramshowingcontextswitchfromprocesstoprocess.3.2 ProcessScheduling 115
MULTITASKINGINMOBILESYSTEMS
Becauseoftheconstraintsimposedonmobiledevices,earlyversionsofiOS
did not provide user-application multitasking; only one application ran in
theforegroundwhileallotheruserapplicationsweresuspended.Operating-
systemtasksweremultitaskedbecausetheywerewrittenbyAppleandwell
behaved.However,beginningwithiOS4,Appleprovidedalimitedformof
multitaskingforuserapplications,thusallowingasingleforegroundappli-
cation to run concurrently with multiple background applications. (On a
mobiledevice,theforegroundapplicationistheapplicationcurrentlyopen
andappearingonthedisplay.Thebackgroundapplicationremainsinmem-
ory, but does not occupy the display screen.) The iOS 4 programming API
providedsupportformultitasking,thusallowingaprocesstorunintheback-
groundwithoutbeingsuspended.However,itwaslimitedandonlyavailable
for a few application types. As hardware for mobile devices began to offer
largermemorycapacities,multipleprocessingcores,andgreaterbatterylife,
subsequent versions of iOS began to support richer functionality for multi-
taskingwithfewerrestrictions.Forexample,thelargerscreenoniPadtablets
allowedrunningtwoforegroundappsatthesametime,atechniqueknown
assplit-screen.
Sinceitsorigins,Androidhassupportedmultitaskinganddoesnotplace
constraints on the types of applications that can run in the background. If
anapplicationrequiresprocessingwhileinthebackground,theapplication
must use a service, a separate application component that runs on behalf
of the background process. Consider a streaming audio application: if the
application moves to the background, the service continues to send audio
data to the audio device driver onbehalfof thebackground application.In
fact, the service will continue to run even if the background application is
suspended.Servicesdonothaveauserinterfaceandhaveasmallmemory
footprint,thusprovidinganefficienttechniqueformultitaskinginamobile
environment.
memoryspeed,thenumberofregistersthatmustbecopied,andtheexistence
ofspecialinstructions(suchasasingleinstructiontoloadorstoreallregisters).
Atypicalspeedisaseveralmicroseconds.
Context-switch times are highly dependent on hardware support. For
instance,someprocessorsprovidemultiplesetsofregisters.Acontextswitch
heresimplyrequireschangingthepointertothecurrentregisterset.Ofcourse,
iftherearemoreactiveprocessesthanthereareregistersets,thesystemresorts
tocopyingregisterdatatoandfrommemory,asbefore.Also,themorecomplex
theoperatingsystem,thegreatertheamountofworkthatmustbedoneduring
acontextswitch.AswewillseeinChapter9,advancedmemory-management
techniques may require that extra data be switched with each context. For
instance, the address space of the current process must be preserved as the
spaceofthenexttaskispreparedforuse.Howtheaddressspaceispreserved,
and what amount of work is needed to preserve it, depend on the memory-
managementmethodoftheoperatingsystem.116 Chapter3 Processes
3.3 Operations on Processes
Theprocessesinmostsystemscanexecuteconcurrently,andtheymaybecre-
atedanddeleteddynamically.Thus,thesesystemsmustprovideamechanism
for process creation and termination. In this section, we explore the mecha-
nisms involved in creating processes and illustrate process creation on UNIX
andWindowssystems.
3.3.1 Process Creation
Duringthecourseofexecution,aprocessmaycreateseveralnewprocesses.As
mentionedearlier,thecreatingprocessiscalledaparentprocess,andthenew
processes are called the childrenof that process. Each of these new processes
mayinturncreateotherprocesses,formingatreeofprocesses.
Most operating systems (including UNIX, Linux, and Windows) identify
processesaccordingtoauniqueprocessidentifie (orpid),whichistypically
an integer number. The pid provides a unique value for each process in the
system,anditcanbeusedasanindextoaccessvariousattributesofaprocess
withinthekernel.
Figure3.7illustratesatypicalprocesstreefortheLinuxoperatingsystem,
showingthenameofeachprocessanditspid.(Weusethetermprocessrather
looselyinthissituation,asLinuxprefersthetermtaskinstead.)Thesystemd
process(which alwayshasapidof1)servesastherootparentprocessforall
user processes, and is the first user process created when the system boots.
Once the system has booted, the systemd process creates processes which
provide additional services such as a web or print server, an ssh server, and
the like. In Figure 3.7, we see two children of systemd—logind and sshd.
The logindprocess is responsiblefor managing clients that directlylog onto
thesystem.Inthisexample,aclienthasloggedonandisusingthebashshell,
which has been assigned pid 8416. Using the bash command-line interface,
thisuserhascreatedtheprocesspsaswellasthevimeditor.Thesshdprocess
is responsible for managing clients that connect to the system by using ssh
(whichisshortforsecureshell).
systemd
pid = 1
logind python sshd
pid = 8415 pid = 2808 pid = 3028
bash sshd
pid = 8416 pid = 3610
ps vim tcsh
pid = 9298 pid = 9204 pid = 4005
Figure3.7 AtreeofprocessesonatypicalLinuxsystem.3.3 OperationsonProcesses 117
THEinitANDsystemdPROCESSES
Traditional UNIX systems identify the process init as the root of all child
processes.init(alsoknownasSystemVinit)isassignedapidof1,andis
thefirstprocesscreatedwhenthesystemisbooted.Onaprocesstreesimilar
towhatisshowninFigure3.7,initisattheroot.
Linux systems initially adoptedtheSystem Vinitapproach,butrecent
distributions have replaced it with systemd. As described in Section 3.3.1,
systemdservesasthesystem’sinitialprocess,muchthesameasSystemV
init;howeveritismuchmoreflexible,andcanprovidemoreservices,than
init.
OnUNIXandLinuxsystems,wecanobtainalistingofprocessesbyusing
thepscommand.Forexample,thecommand
ps -el
willlistcompleteinformationfor allprocessescurrentlyactiveinthe system.
A process tree similar to the one shown in Figure 3.7 can be constructed by
recursively tracing parent processes all the way to the systemd process. (In
addition,Linuxsystemsprovidethepstreecommand,whichdisplaysatree
ofallprocessesinthesystem.)
In general, when a process creates a child process, that child process will
need certain resources (CPU time, memory, files, I/O devices) to accomplish
its task. A child process may be able to obtain its resources directly from
the operating system, or it may be constrained to a subset of the resources
of the parent process. The parent may have to partition its resources among
its children, or it may be able to share some resources (such as memory or
files) among several of its children. Restricting a child process to a subset of
the parent’s resources prevents any process from overloading the system by
creatingtoomanychildprocesses.
Inadditiontosupplyingvariousphysicalandlogicalresources,theparent
process may pass along initialization data (input) to the child process. For
example,consideraprocesswhosefunctionistodisplaythecontentsofafile—
say,hw1.c—onthescreenofaterminal.Whentheprocessiscreated,itwillget,
asaninputfromitsparentprocess,thenameofthefilehw1.c.Usingthatfile
name,itwillopenthefileandwritethecontentsout.Itmayalsogetthename
oftheoutputdevice.Alternatively,someoperatingsystemspassresourcesto
child processes. On such a system, the new process may get two open files,
hw1.c and the terminal device, and may simply transfer the datum between
thetwo.
Whenaprocesscreatesanewprocess,twopossibilitiesforexecutionexist:
1. Theparentcontinuestoexecuteconcurrentlywithitschildren.
2. Theparentwaitsuntilsomeorallofitschildrenhaveterminated.
Therearealsotwoaddress-spacepossibilitiesforthenewprocess:118 Chapter3 Processes
1. The child process is a duplicate of the parent process (it has the same
programanddataastheparent).
2. Thechildprocesshasanewprogramloadedintoit.
Toillustratethesedifferences,let’sfirstconsidertheUNIXoperatingsystem.In
UNIX,aswe’veseen,eachprocessisidentifiedbyitsprocessidentifier,which
is a unique integer. Anew process is created by the fork() system call. The
new process consists of a copy of the address space of the original process.
Thismechanismallowstheparentprocesstocommunicateeasilywithitschild
process. Both processes (the parent and the child) continue execution at the
instructionafterthefork(),withonedifference:thereturncodeforthefork()
iszeroforthenew(child)process,whereasthe(nonzero)processidentifierof
thechildisreturnedtotheparent.
After a fork() system call, one of the two processes typically uses the
exec() system call to replace the process’s memory space with a new pro-
gram.Theexec()systemcallloadsabinaryfileintomemory(destroyingthe
memory image of the program containing the exec() system call) and starts
#include <sys/types.h>
#include <stdio.h>
#include <unistd.h>
int main()
{
pid t pid;
/* fork a child process */
pid = fork();
if (pid < 0) { /* error occurred */
fprintf(stderr, "Fork Failed");
return 1;
}
else if (pid == 0) { /* child process */
execlp("/bin/ls","ls",NULL);
}
else { /* parent process */
/* parent will wait for the child to complete */
wait(NULL);
printf("Child Complete");
}
return 0;
}
Figure3.8 CreatingaseparateprocessusingtheUNIXfork()systemcall.3.3 OperationsonProcesses 119
its execution. In this manner, the two processes are able to communicate and
thengotheirseparateways.Theparentcanthencreatemorechildren;or,ifit
has nothing else to do while the child runs, it can issue a wait() system call
to move itself off the ready queue until the termination of the child. Because
the call to exec() overlays the process’s address space with a new program,
exec()doesnotreturncontrolunlessanerroroccurs.
The C program shown in Figure 3.8 illustrates the UNIX system calls pre-
viouslydescribed.Wenowhavetwodifferentprocessesrunningcopiesofthe
sameprogram.Theonlydifferenceisthatthevalueofthevariablepidforthe
childprocessiszero,whilethatfortheparentisanintegervaluegreaterthan
zero(infact,itistheactualpidofthechildprocess).Thechildprocessinherits
privilegesandschedulingattributesfromtheparent,aswellcertainresources,
such as open files. The child process then overlays its addressspace with the
UNIX command /bin/ls (used to get a directorylisting) using the execlp()
systemcall(execlp()isaversionoftheexec()systemcall).Theparentwaits
forthechildprocesstocompletewiththewait()systemcall.Whenthechild
processcompletes(byeitherimplicitlyorexplicitlyinvokingexit()),thepar-
ent process resumes from the call to wait(), where it completes using the
exit()systemcall.ThisisalsoillustratedinFigure3.9.
Ofcourse,thereisnothingtopreventthechildfromnotinvokingexec()
and instead continuing to execute as a copy of the parent process. In this
scenario,theparentandchildareconcurrentprocessesrunningthesamecode
instructions.Becausethechildisacopyoftheparent,eachprocesshasitsown
copyofanydata.
Asanalternativeexample,wenextconsiderprocesscreationinWindows.
Processes are created in the Windows API using the CreateProcess() func-
tion, which is similar to fork() in that a parent creates a new child process.
However, whereas fork() has the child process inheriting the address space
ofitsparent,CreateProcess()requiresloadingaspecifiedprogramintothe
address space of the child process at process creation. Furthermore, whereas
fork()ispassednoparameters,CreateProcess()expectsnofewerthanten
parameters.
The C program shown in Figure 3.10 illustrates the CreateProcess()
function,whichcreatesachildprocessthatloadstheapplicationmspaint.exe.
We opt for many of the default values of the ten parameters passed to Cre-
ateProcess().Readersinterestedinpursuing thedetailsofprocesscreation
and management in the Windows API are encouraged to consult the biblio-
graphicalnotesattheendofthischapter.
The two parameters passed to the CreateProcess() function are
instances of the STARTUPINFO and PROCESS INFORMATION structures.
STARTUPINFO specifies many properties of the new process, such as window
Figure3.9 Processcreationusingthefork()systemcall.120 Chapter3 Processes
#include <stdio.h>
#include <windows.h>
int main(VOID)
{
STARTUPINFO si;
PROCESS INFORMATION pi;
/* allocate memory */
ZeroMemory(&si, sizeof(si));
si.cb = sizeof(si);
ZeroMemory(&pi, sizeof(pi));
/* create child process */
if (!CreateProcess(NULL, /* use command line */
"C:∖∖WINDOWS∖∖system32∖∖mspaint.exe", /* command */
NULL, /* don’t inherit process handle */
NULL, /* don’t inherit thread handle */
FALSE, /* disable handle inheritance */
0, /* no creation flags */
NULL, /* use parent’s environment block */
NULL, /* use parent’s existing directory */
&si,
&pi))
{
fprintf(stderr, "Create Process Failed");
return -1;
}
/* parent will wait for the child to complete */
WaitForSingleObject(pi.hProcess, INFINITE);
printf("Child Complete");
/* close handles */
CloseHandle(pi.hProcess);
CloseHandle(pi.hThread);
}
Figure3.10 CreatingaseparateprocessusingtheWindowsAPI.
size and appearance and handles to standard input and output files. The
PROCESS INFORMATION structure contains a handle and the identifiers to
the newly created process and its thread. We invoke the ZeroMemory()
function to allocate memory for each of these structures before proceeding
withCreateProcess().
The first twoparameterspassedto CreateProcess()are the application
name and command-line parameters. If the application name is NULL (as it
isinthiscase),thecommand-lineparameterspecifiestheapplicationtoload.3.3 OperationsonProcesses 121
In this instance, we are loading the Microsoft Windows mspaint.exe appli-
cation.Beyondthesetwoinitialparameters,weusethedefaultparametersfor
inheritingprocessandthreadhandlesaswellasspecifyingthattherewillbeno
creationflags.Wealsousetheparent’sexistingenvironmentblockandstarting
directory.Last,weprovidetwopointerstothe STARTUPINFOandPROCESS -
INFORMATION structures created at the beginning of the program. In Figure
3.8,theparentprocesswaitsforthechildtocompletebyinvokingthewait()
system call. The equivalent of this in Windows is WaitForSingleObject(),
whichispassedahandleofthechildprocess—pi.hProcess—andwaitsfor
thisprocesstocomplete.Oncethechildprocessexits,controlreturnsfromthe
WaitForSingleObject()functionintheparentprocess.
3.3.2 Process Termination
A process terminates when it finishes executing its final statement and asks
the operating system to delete it by using the exit() system call. At that
point,theprocessmayreturnastatusvalue(typicallyaninteger)toitswaiting
parent process (via the wait() system call). All the resources of the process
—including physical and virtual memory, open files, and I/O buffers—are
deallocatedandreclaimedbytheoperatingsystem.
Terminationcanoccurinothercircumstancesaswell.Aprocesscancause
theterminationofanotherprocessviaanappropriatesystemcall(forexample,
TerminateProcess()inWindows).Usually,suchasystemcallcanbeinvoked
onlybytheparentoftheprocessthatistobeterminated.Otherwise,auser—
oramisbehavingapplication—couldarbitrarilykillanotheruser’sprocesses.
Notethataparentneedstoknowtheidentitiesofitschildrenifitistoterminate
them.Thus,whenoneprocesscreatesanewprocess,theidentityofthenewly
createdprocessispassedtotheparent.
Aparentmayterminatetheexecutionofoneofitschildrenforavarietyof
reasons,suchasthese:
• Thechildhasexceededitsusageofsomeoftheresourcesthatithasbeen
allocated.(Todeterminewhetherthishasoccurred,theparentmusthave
amechanismtoinspectthestateofitschildren.)
• Thetaskassignedtothechildisnolongerrequired.
• The parent is exiting, and the operating system does not allow a child to
continueifitsparentterminates.
Some systems do not allow a child to exist if its parent has terminated.
Insuchsystems,ifaprocessterminates(eithernormallyorabnormally),then
all its children must also be terminated. This phenomenon, referred to as
cascadingtermination,isnormallyinitiatedbytheoperatingsystem.
Toillustrateprocessexecutionandtermination,considerthat,inLinuxand
UNIX systems, we can terminate a process by using the exit() system call,
providinganexitstatusasaparameter:
/* exit with status 1 */
exit(1);122 Chapter3 Processes
In fact, under normal termination, exit() will be called either directly (as
shownabove)orindirectly,astheCrun-timelibrary(whichisaddedtoUNIX
executablefiles)willincludeacalltoexit()bydefault.
Aparentprocessmaywaitfortheterminationofachildprocessbyusing
the wait() system call. The wait() system call is passed a parameter that
allows the parent to obtain the exit status of the child. This system call also
returnstheprocessidentifieroftheterminatedchildsothattheparentcantell
whichofitschildrenhasterminated:
pid t pid;
int status;
pid = wait(&status);
Whenaprocessterminates,itsresourcesaredeallocatedby theoperating
system. However, its entry in the process table must remain there until the
parentcallswait(),becausetheprocesstablecontainstheprocess’sexitstatus.
Aprocessthathasterminated,butwhoseparenthasnotyetcalledwait(),is
known as a zombie process. All processes transition to this state when they
terminate, but generally they exist as zombies only briefly. Once the parent
calls wait(), the process identifier of the zombie process and its entry in the
processtablearereleased.
Nowconsiderwhatwouldhappenifaparentdidnotinvokewait()and
insteadterminated,therebyleavingitschildprocessesasorphans.Traditional
UNIXsystemsaddressedthisscenariobyassigningtheinitprocessasthenew
parent to orphan processes. (Recall from Section 3.3.1 that init serves as the
rootoftheprocesshierarchyinUNIXsystems.)Theinitprocessperiodically
invokeswait(),therebyallowingtheexitstatusofanyorphanedprocesstobe
collectedandreleasingtheorphan’sprocessidentifierandprocess-tableentry.
AlthoughmostLinuxsystemshavereplacedinitwithsystemd,thelatter
processcanstillservethesamerole,althoughLinuxalsoallowsprocessesother
thansystemdtoinheritorphanprocessesandmanagetheirtermination.
3.3.2.1 AndroidProcessHierarchy
Because of resource constraints such as limited memory, mobile operating
systems may have to terminate existing processes to reclaim limited system
resources.Ratherthanterminatinganarbitraryprocess,Androidhasidentified
an importance hierarchy of processes, and when the system must terminate
a process to make resources available for a new, or more important, process,
it terminates processes in order of increasing importance. From most to least
important,thehierarchyofprocessclassificationsisasfollows:
• Foregroundprocess—Thecurrentprocessvisibleonthescreen,represent-
ingtheapplicationtheuseriscurrentlyinteractingwith
• Visibleprocess—Aprocessthat isnot directlyvisibleon theforeground
butthatisperforminganactivitythattheforegroundprocessisreferring
to (that is, a process performing an activity whose status is displayed on
theforegroundprocess)3.4 InterprocessCommunication 123
• Service process—A process that is similar to a background process but
is performing an activity that is apparent to the user (such as streaming
music)
• Background process—Aprocess that may be performing an activity but
isnotapparenttotheuser.
• Empty process—A process that holds no active components associated
withanyapplication
Ifsystemresourcesmustbereclaimed,Androidwillfirstterminateempty
processes, followed by background processes, and so forth. Processes are
assignedanimportanceranking,andAndroidattemptstoassignaprocessas
higharankingaspossible.Forexample,ifaprocessisprovidingaserviceand
isalsovisible,itwillbeassignedthemore-importantvisibleclassification.
Furthermore,Androiddevelopmentpracticessuggestfollowingtheguide-
linesoftheprocesslifecycle.Whentheseguidelinesarefollowed,thestateof
a process will be saved prior to termination and resumed at its saved state if
theusernavigatesbacktotheapplication.
3.4 Interprocess Communication
Processesexecutingconcurrentlyintheoperatingsystemmaybeeitherinde-
pendentprocessesorcooperatingprocesses.Aprocessisindependentifitdoes
not share data with any other processes executing in the system. A process
is cooperating if it can affect or be affected by the other processes executing
in the system. Clearly, any process that shares data with other processes is a
cooperatingprocess.
Thereareseveralreasonsforprovidinganenvironmentthatallowsprocess
cooperation:
• Information sharing. Since several applications may be interested in the
same piece of information (for instance, copying and pasting), we must
provideanenvironmenttoallowconcurrentaccesstosuchinformation.
• Computationspeedup.Ifwewantaparticulartasktorunfaster,wemust
breakitintosubtasks,eachofwhichwillbeexecutinginparallelwiththe
others. Notice that such a speedup can be achieved only if the computer
hasmultipleprocessingcores.
• Modularity. We may want to construct the system in a modular fashion,
dividing the system functions into separate processes or threads, as we
discussedinChapter2.
Cooperating processes require an interprocess communication (IPC)
mechanism that will allow them to exchange data— that is, send data to
and receive data from each other. There are two fundamental models of
interprocess communication: shared memory and message passing. In the
shared-memorymodel,aregionofmemorythatissharedbythecooperating
processesisestablished.Processescan thenexchangeinformationby reading
and writing data to the shared region. In the message-passing model,124 Chapter3 Processes
MULTIPROCESSARCHITECTURE—CHROMEBROWSER
Manywebsitescontainactivecontent,suchasJavaScript,Flash,andHTML5
to provide a rich and dynamic web-browsing experience. Unfortunately,
thesewebapplicationsmayalsocontainsoftwarebugs,whichcanresultin
sluggish responsetimesandcanevencausethewebbrowsertocrash.This
isn’tabigprobleminawebbrowserthatdisplayscontentfromonlyoneweb-
site.Butmostcontemporarywebbrowsersprovidetabbedbrowsing,which
allowsasingleinstanceofawebbrowserapplicationtoopenseveralwebsites
atthesametime,witheachsiteinaseparatetab.Toswitchbetweenthedif-
ferentsites,auserneedonlyclickontheappropriatetab.Thisarrangement
isillustratedbelow:
Aproblemwiththisapproachisthatifawebapplicationinanytabcrashes,
theentireprocess—includingallothertabsdisplayingadditionalwebsites—
crashesaswell.
Google’s Chrome web browser was designed to address this issue by
usingamultiprocessarchitecture.Chromeidentifiesthreedifferenttypesof
processes:browser,renderers,andplug-ins.
• The browser process is responsible for managing the user interface as
well as disk and network I/O. Anew browser process is created when
Chromeisstarted.Onlyonebrowserprocessiscreated.
• Renderer processes contain logic for rendering web pages. Thus, they
containthelogicforhandlingHTML,Javascript,images,andsoforth.As
ageneralrule,anewrendererprocessiscreatedforeachwebsiteopened
inanewtab,andsoseveralrendererprocessesmaybeactiveatthesame
time.
• Aplug-in process is created for each type of plug-in (such as Flash or
QuickTime)inuse.Plug-inprocessescontainthecodefortheplug-inas
well as additional code that enables the plug-in to communicate with
associatedrendererprocessesandthebrowserprocess.
The advantage of the multiprocess approach is that websites run in iso-
lation from one another.If one website crashes, only its rendererprocess is
affected; all other processes remain unharmed. Furthermore, renderer pro-
cessesruninasandbox,whichmeansthataccesstodiskandnetworkI/Ois
restricted,minimizingtheeffectsofanysecurityexploits.
communication takes place by means of messages exchanged between the
cooperating processes. The two communications models are contrasted in
Figure3.11.3.5 IPCinShared-MemorySystems 125
process A process A
shared memory
process B
process B
message queue
m m m m ... m
0 1 2 3 n
kernel
kernel
(a) (b)
Figure3.11 Communicationsmodels.(a)Sharedmemory.(b)Messagepassing.
Both of the models just mentioned are common in operating systems,
andmanysystemsimplementboth.Messagepassingisusefulforexchanging
smalleramountsofdata,becausenoconflictsneedbeavoided.Messagepass-
ing is also easier to implement in a distributed system than shared memory.
(Although there are systems that provide distributed shared memory, we do
notconsidertheminthistext.)Sharedmemorycanbefasterthanmessagepass-
ing, since message-passing systems are typically implemented using system
calls and thus require the more time-consuming task of kernel intervention.
Inshared-memorysystems,systemcallsarerequiredonlytoestablishshared-
memory regions. Once shared memory is established, all accesses are treated
asroutinememoryaccesses,andnoassistancefromthekernelisrequired.
In Section 3.5 and Section 3.6 we explore shared-memory and message-
passingsystemsinmoredetail.
3.5 IPC in Shared-Memory Systems
Interprocess communication using shared memory requires communicating
processestoestablisharegionofsharedmemory.Typically,ashared-memory
regionresidesintheaddressspaceoftheprocesscreatingtheshared-memory
segment.Otherprocessesthatwishtocommunicateusingthisshared-memory
segmentmustattachittotheiraddressspace.Recallthat,normally,theoper-
ating system tries to prevent one process from accessing another process’s
memory.Sharedmemoryrequiresthattwoormoreprocessesagreetoremove
this restriction. They can then exchange information by reading and writing
datainthesharedareas.Theformofthedataandthelocationaredetermined
bytheseprocessesandarenotundertheoperatingsystem’scontrol.Thepro-
cesses are also responsible for ensuring that they are not writing to the same
locationsimultaneously.126 Chapter3 Processes
To illustrate the concept of cooperating processes, let’s consider the pro-
ducer–consumerproblem,whichisacommonparadigmforcooperatingpro-
cesses. Aproducer process produces information that is consumed by a con-
sumer process. For example, a compiler may produce assembly code that is
consumedbyanassembler.Theassembler,inturn,mayproduceobjectmod-
ules that are consumed by the loader. The producer–consumer problem also
providesausefulmetaphorfortheclient–serverparadigm.Wegenerallythink
ofaserverasaproducerandaclientasaconsumer.Forexample,awebserver
produces(thatis,provides)webcontentsuchasHTMLfilesandimages,which
areconsumed(thatis,read)bytheclientwebbrowserrequestingtheresource.
Onesolutiontotheproducer–consumerproblemusessharedmemory.To
allow producer and consumer processes to run concurrently, we must have
available a buffer of items that can be filled by the producer and emptied by
the consumer. This buffer will residein a regionof memory that is shared by
theproducerandconsumerprocesses.Aproducercanproduceoneitemwhile
theconsumerisconsuminganotheritem.Theproducerandconsumermustbe
synchronized, sothat theconsumer doesnot trytoconsume anitemthat has
notyetbeenproduced.
Twotypesofbufferscanbeused.Theunboundedbufferplacesnoprac-
tical limit on the size of the buffer. The consumer may have to wait for new
items, but the producer can always produce new items. The boundedbuffer
assumesafixedbuffersize.Inthiscase,theconsumer mustwait ifthebuffer
isempty,andtheproducermustwaitifthebufferisfull.
Let’slookmorecloselyathowtheboundedbufferillustratesinterprocess
communication using shared memory. The following variables reside in a
regionofmemorysharedbytheproducerandconsumerprocesses:
#define BUFFER SIZE 10
typedef struct {
. . .
} item;
item buffer[BUFFER SIZE];
int in = 0;
int out = 0;
Thesharedbufferisimplementedasacirculararraywithtwologicalpointers:
inandout.Thevariableinpointstothenextfreepositioninthebuffer;out
points to the first full position in the buffer. The buffer is empty when in ==
out;thebufferisfullwhen((in+1)% BUFFER SIZE)==out.
ThecodefortheproducerprocessisshowninFigure3.12,andthecodefor
theconsumerprocessisshowninFigure3.13.Theproducerprocesshasalocal
variablenext producedinwhichthenewitemtobeproducedisstored.The
consumerprocesshasalocalvariablenext consumedinwhichtheitemtobe
consumedisstored.
This scheme allows at most BUFFER SIZE − 1 items in the buffer at the
same time. We leave it as an exercise for you to provide a solution in which
BUFFER SIZE items can be in the buffer at the same time. In Section 3.7.1, we
illustratethePOSIXAPIforsharedmemory.3.6 IPCinMessage-PassingSystems 127
item next produced;
while (true) {
/* produce an item in next produced */
while (((in + 1) % BUFFER SIZE) == out)
; /* do nothing */
buffer[in] = next produced;
in = (in + 1) % BUFFER SIZE;
}
Figure3.12 Theproducerprocessusingsharedmemory.
Oneissuethisillustrationdoesnotaddressconcernsthesituationinwhich
both the producer process and the consumer process attempt to access the
sharedbuffer concurrently.In Chapter6and Chapter7, wediscuss how syn-
chronization among cooperating processescan be implementedeffectivelyin
ashared-memoryenvironment.
3.6 IPC in Message-Passing Systems
In Section 3.5, we showed how cooperating processes can communicate in a
shared-memoryenvironment.Theschemerequiresthattheseprocessessharea
regionofmemoryandthatthecodeforaccessingandmanipulatingtheshared
memorybewrittenexplicitlybytheapplicationprogrammer.Anotherwayto
achieve the same effect is for the operating system to provide the means for
cooperatingprocessestocommunicatewitheachotherviaamessage-passing
facility.
item next consumed;
while (true) {
while (in == out)
; /* do nothing */
next consumed = buffer[out];
out = (out + 1) % BUFFER SIZE;
/* consume the item in next consumed */
}
Figure3.13 Theconsumerprocessusingsharedmemory.128 Chapter3 Processes
Messagepassingprovidesamechanismtoallowprocessestocommunicate
and to synchronize their actions without sharing the same address space. It
isparticularlyusefulinadistributedenvironment,wherethecommunicating
processes may reside on different computers connected by a network. For
example,anInternetchatprogramcouldbedesignedsothatchatparticipants
communicatewithoneanotherbyexchangingmessages.
Amessage-passingfacilityprovidesatleasttwooperations:
send(message)
and
receive(message)
Messages sent by a process can be either fixed or variable in size. If only
fixed-sizedmessagescanbesent,thesystem-levelimplementationisstraight-
forward.Thisrestriction,however,makesthetaskofprogrammingmorediffi-
cult.Conversely,variable-sizedmessagesrequireamorecomplexsystem-level
implementation,buttheprogrammingtaskbecomessimpler.Thisisacommon
kindoftradeoffseenthroughoutoperating-systemdesign.
IfprocessesPandQwanttocommunicate,theymustsendmessagestoand
receive messages from each other: a communication link must exist between
them.Thislinkcanbeimplementedinavarietyofways.Weareconcernedhere
notwiththelink’sphysicalimplementation(suchassharedmemory,hardware
bus, or network, which are covered in Chapter 19) but rather with its logical
implementation. Here are several methods for logically implementing a link
andthesend()/receive()operations:
• Directorindirectcommunication
• Synchronousorasynchronouscommunication
• Automaticorexplicitbuffering
Welookatissuesrelatedtoeachofthesefeaturesnext.
3.6.1 Naming
Processes that want to communicate must have a way to refer to each other.
Theycanuseeitherdirectorindirectcommunication.
Under direct communication, each process that wants to communicate
must explicitly name the recipient or sender of the communication. In this
scheme,thesend()andreceive()primitivesaredefinedas:
• send(P, message)—SendamessagetoprocessP.
• receive(Q, message)—ReceiveamessagefromprocessQ.
Acommunicationlinkinthisschemehasthefollowingproperties:
• A link is established automatically between every pair of processes that
want to communicate. The processes need to know only each other’s
identitytocommunicate.3.6 IPCinMessage-PassingSystems 129
• Alinkisassociatedwithexactlytwoprocesses.
• Betweeneachpairofprocesses,thereexistsexactlyonelink.
Thisschemeexhibitssymmetryinaddressing;thatis,boththesenderpro-
cessandthereceiverprocessmustnametheothertocommunicate.Avariant
ofthisschemeemploysasymmetryinaddressing.Here,onlythesendernames
therecipient;therecipientisnot requiredtonamethesender.Inthisscheme,
thesend()andreceive()primitivesaredefinedasfollows:
• send(P, message)—SendamessagetoprocessP.
• receive(id, message)—Receiveamessagefromanyprocess.Thevari-
able id is set to the name of the process with which communication has
takenplace.
The disadvantage in both of these schemes (symmetric and asymmetric)
is the limited modularity of the resulting process definitions. Changing the
identifierofaprocessmaynecessitateexaminingallotherprocessdefinitions.
Allreferencestotheoldidentifiermustbefound,sothattheycanbemodified
tothenewidentifier.Ingeneral,anysuchhard-codingtechniques,whereiden-
tifiers must be explicitly stated, are less desirable than techniques involving
indirection,asdescribednext.
Withindirectcommunication,themessagesaresenttoandreceivedfrom
mailboxes, or ports. A mailbox can be viewed abstractly as an object into
which messages can be placed by processes and from which messages can
be removed. Each mailbox has a unique identification. For example, POSIX
messagequeuesuseanintegervaluetoidentifyamailbox.Aprocesscancom-
municate with another process via a number of different mailboxes, but two
processes can communicate only if they have a shared mailbox. The send()
andreceive()primitivesaredefinedasfollows:
• send(A, message)—SendamessagetomailboxA.
• receive(A, message)—ReceiveamessagefrommailboxA.
Inthisscheme,acommunicationlinkhasthefollowingproperties:
• Alinkisestablishedbetweenapairofprocessesonlyifbothmembersof
thepairhaveasharedmailbox.
• Alinkmaybeassociatedwithmorethantwoprocesses.
• Betweeneachpairofcommunicatingprocesses,anumberofdifferentlinks
mayexist,witheachlinkcorrespondingtoonemailbox.
NowsupposethatprocessesP ,P ,andP allsharemailboxA.ProcessP
1 2 3 1
sendsamessagetoA,whilebothP andP executeareceive()fromA.Which
2 3
processwillreceivethemessagesentbyP ?Theanswerdependsonwhichof
1
thefollowingmethodswechoose:
• Allowalinktobeassociatedwithtwoprocessesatmost.130 Chapter3 Processes
• Allowatmostoneprocessatatimetoexecuteareceive()operation.
• Allowthesystemtoselectarbitrarilywhichprocesswillreceivethemes-
sage (that is, either P or P , but not both, will receive the message). The
2 3
system may define an algorithm for selecting which process will receive
themessage(forexample,roundrobin,whereprocessestaketurnsreceiv-
ingmessages).Thesystemmayidentifythereceivertothesender.
Amailbox may be owned eitherby aprocess or by the operating system.
Ifthemailboxisownedbyaprocess(thatis,themailboxispartoftheaddress
space of the process), then we distinguish between the owner (which can
only receive messages through this mailbox) and the user (which can only
sendmessagestothemailbox).Sinceeachmailboxhasauniqueowner,there
can be no confusion about which process should receive a message sent to
this mailbox. When a process that owns a mailbox terminates, the mailbox
disappears. Any process that subsequently sends a message to this mailbox
mustbenotifiedthatthemailboxnolongerexists.
In contrast, a mailbox that is owned by the operating system has an exis-
tenceofitsown.Itisindependentandisnotattachedtoanyparticularprocess.
Theoperatingsystemthenmustprovideamechanismthatallowsaprocessto
dothefollowing:
• Createanewmailbox.
• Sendandreceivemessagesthroughthemailbox.
• Deleteamailbox.
The process that creates a new mailbox is that mailbox’s owner by default.
Initially,theowneristheonlyprocessthatcanreceivemessagesthroughthis
mailbox. However, the ownership and receiving privilege may be passed to
other processes through appropriate system calls. Of course, this provision
couldresultinmultiplereceiversforeachmailbox.
3.6.2 Synchronization
Communication between processes takes place through calls to send() and
receive() primitives. There are different design options for implementing
each primitive. Message passing may be either blocking or nonblocking—
alsoknownassynchronousandasynchronous.(Throughoutthistext,youwill
encountertheconceptsofsynchronousandasynchronousbehaviorinrelation
tovariousoperating-systemalgorithms.)
• Blocking send. The sending process is blocked until the message is
receivedbythereceivingprocessorbythemailbox.
• Nonblockingsend.Thesendingprocesssendsthemessageandresumes
operation.
• Blockingreceive.Thereceiverblocksuntilamessageisavailable.
• Nonblocking receive. The receiver retrieves either a valid message or a
null.3.6 IPCinMessage-PassingSystems 131
message next produced;
while (true) {
/* produce an item in next produced */
send(next produced);
}
Figure3.14 Theproducerprocessusingmessagepassing.
Differentcombinationsofsend()andreceive()arepossible.Whenboth
send() and receive() are blocking, we have a rendezvous between the
sender and the receiver. The solution to the producer–consumer problem
becomestrivialwhenweuseblockingsend()andreceive()statements.The
producermerelyinvokestheblockingsend()callandwaitsuntilthemessage
isdeliveredtoeitherthereceiverorthemailbox.Likewise,whentheconsumer
invokesreceive(),itblocksuntilamessageisavailable.Thisisillustratedin
Figures3.14and3.15.
3.6.3 Buffering
Whethercommunicationisdirectorindirect,messagesexchangedbycommu-
nicatingprocessesresideinatemporaryqueue.Basically,suchqueuescanbe
implementedinthreeways:
• Zero capacity. The queue has a maximum length of zero; thus, the link
cannothaveanymessageswaitinginit.Inthiscase,thesendermustblock
untiltherecipientreceivesthemessage.
• Boundedcapacity.Thequeuehasfinitelengthn;thus,atmostnmessages
can reside in it. If the queue is not full when a new message is sent, the
messageisplacedinthe queue(eitherthemessageiscopiedor apointer
to the message is kept), and the sender can continue execution without
message next consumed;
while (true) {
receive(next consumed);
/* consume the item in next consumed */
}
Figure3.15 Theconsumerprocessusingmessagepassing.132 Chapter3 Processes
waiting.Thelink’scapacityisfinite,however.Ifthelinkisfull,thesender
mustblockuntilspaceisavailableinthequeue.
• Unboundedcapacity.Thequeue’slengthispotentiallyinfinite;thus,any
numberofmessagescanwaitinit.Thesenderneverblocks.
The zero-capacity case is sometimes referred to as a message system with no
buffering.Theothercasesarereferredtoassystemswithautomaticbuffering.
3.7 Examples of IPC Systems
Inthissection,weexplorefourdifferentIPCsystems.WefirstcoverthePOSIX
API for shared memory and then discuss message passing in the Mach oper-
atingsystem.Next,wepresentWindowsIPC,whichinterestinglyusesshared
memory as a mechanism for providing certain types of message passing. We
concludewithpipes,oneoftheearliestIPCmechanismsonUNIXsystems.
3.7.1 POSIX Shared Memory
Several IPC mechanisms are available for POSIX systems, including shared
memory and message passing. Here, we explore the POSIX API for shared
memory.
POSIX shared memory is organized using memory-mapped files, which
associate the regionof shared memory with a file. Aprocess must first create
ashared-memoryobjectusingtheshm open()systemcall,asfollows:
fd = shm open(name, O CREAT | O RDWR, 0666);
Thefirstparameterspecifiesthenameoftheshared-memoryobject.Processes
thatwishtoaccessthissharedmemorymustrefertotheobjectbythisname.
Thesubsequentparametersspecifythattheshared-memoryobjectistobecre-
atedifitdoesnotyetexist(O CREAT)andthattheobjectisopenforreadingand
writing(O RDWR).Thelastparameterestablishesthefile-accesspermissionsof
theshared-memoryobject.Asuccessfulcalltoshm open()returnsaninteger
filedescriptorfortheshared-memoryobject.
Once the object is established, the ftruncate() function is used to
configurethesizeoftheobjectinbytes.Thecall
ftruncate(fd, 4096);
setsthesizeoftheobjectto4,096bytes.
Finally,themmap()functionestablishesamemory-mappedfilecontaining
theshared-memoryobject.Italsoreturnsapointertothememory-mappedfile
thatisusedforaccessingtheshared-memoryobject.
The programs shown in Figure 3.16 and Figure 3.17 use the producer–
consumermodelinimplementingsharedmemory.Theproducerestablishesa
shared-memoryobjectandwritestosharedmemory,andtheconsumerreads
fromsharedmemory.3.7 ExamplesofIPCSystems 133
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <fcntl.h>
#include <sys/shm.h>
#include <sys/stat.h>
#include <sys/mman.h>
int main()
{
/* the size (in bytes) of shared memory object */
const int SIZE = 4096;
/* name of the shared memory object */
const char *name = "OS";
/* strings written to shared memory */
const char *message 0 = "Hello";
const char *message 1 = "World!";
/* shared memory file descriptor */
int fd;
/* pointer to shared memory obect */
char *ptr;
/* create the shared memory object */
fd = shm open(name,O CREAT | O RDWR,0666);
/* configure the size of the shared memory object */
ftruncate(fd, SIZE);
/* memory map the shared memory object */
ptr = (char *)
mmap(0, SIZE, PROT READ | PROT WRITE, MAP SHARED, fd, 0);
/* write to the shared memory object */
sprintf(ptr,"%s",message 0);
ptr += strlen(message 0);
sprintf(ptr,"%s",message 1);
ptr += strlen(message 1);
return 0;
}
Figure3.16 ProducerprocessillustratingPOSIXshared-memoryAPI.134 Chapter3 Processes
Theproducer,showninFigure3.16,createsashared-memoryobjectnamed
OS and writes the infamous string "Hello World!" to shared memory. The
program memory-maps a shared-memory object of the specified size and
allowswritingtotheobject.TheflagMAP SHAREDspecifiesthatchangestothe
shared-memoryobjectwillbevisibletoallprocessessharingtheobject.Notice
thatwewritetotheshared-memoryobjectbycallingthesprintf()function
andwritingtheformattedstringtothepointerptr.Aftereachwrite,wemust
incrementthepointerbythenumberofbyteswritten.
#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <sys/shm.h>
#include <sys/stat.h>
#include <sys/mman.h>
int main()
{
/* the size (in bytes) of shared memory object */
const int SIZE = 4096;
/* name of the shared memory object */
const char *name = "OS";
/* shared memory file descriptor */
int fd;
/* pointer to shared memory obect */
char *ptr;
/* open the shared memory object */
fd = shm open(name, O RDONLY, 0666);
/* memory map the shared memory object */
ptr = (char *)
mmap(0, SIZE, PROT READ | PROT WRITE, MAP SHARED, fd, 0);
/* read from the shared memory object */
printf("%s",(char *)ptr);
/* remove the shared memory object */
shm unlink(name);
return 0;
}
Figure3.17 ConsumerprocessillustratingPOSIXshared-memoryAPI.3.7 ExamplesofIPCSystems 135
The consumer process, shown in Figure 3.17, reads and outputs the con-
tents of the shared memory. The consumer also invokes the shm unlink()
function,whichremovestheshared-memorysegmentaftertheconsumerhas
accessedit.WeprovidefurtherexercisesusingthePOSIXshared-memoryAPIin
theprogrammingexercisesattheendofthischapter.Additionally,weprovide
moredetailedcoverageofmemorymappinginSection13.5.
3.7.2 Mach Message Passing
As an example of message passing, we next consider the Mach operating
system.Machwasespeciallydesignedfordistributedsystems,butwasshown
to be suitable for desktop and mobile systems as well, as evidenced by its
inclusioninthemacOSandiOSoperatingsystems,asdiscussedinChapter2.
TheMachkernelsupportsthecreationanddestructionofmultipletasks,
which are similar to processes but have multiple threads of control and
fewerassociatedresources.MostcommunicationinMach—includingallinter-
task communication—is carried out by messages. Messages are sent to, and
receivedfrom,mailboxes,whicharecalledportsinMach.Portsarefiniteinsize
andunidirectional;fortwo-waycommunication,amessageissenttooneport,
and a response is sent to a separate reply port. Each port may have multiple
senders, but only one receiver. Mach uses ports to represent resources such
as tasks, threads, memory, and processors, while message passing provides
an object-oriented approach for interacting with these system resources and
services.Messagepassingmayoccurbetweenanytwoportsonthesamehost
oronseparatehostsonadistributedsystem.
Associated with each port is a collection of port rights that identify
the capabilities necessary for a task to interact with the port. For example,
for a task to receive a message from a port, it must have the capability
MACH PORT RIGHT RECEIVE for that port. The task that creates a port is that
port’sowner,andtheowneristheonlytaskthatisallowedtoreceivemessages
fromthatport.Aport’sownermayalsomanipulatethecapabilitiesforaport.
Thisismostcommonlydoneinestablishingareplyport.Forexample,assume
thattaskT1ownsportP1,anditsendsamessagetoportP2,whichisowned
by task T2. If T1 expects to receive a reply from T2, it must grant T2 the
right MACH PORT RIGHT SEND for port P1. Ownership of port rights is at the
task level, which means that all threads belonging to the same task share the
same port rights. Thus, two threads belonging to the same task can easily
communicatebyexchangingmessagesthroughtheper-threadportassociated
witheachthread.
When a task is created, two special ports—the Task Self port and the
Notify port—are also created. The kernel has receive rights to the Task Self
port,whichallowsatasktosendmessagestothekernel.Thekernelcansend
notification of event occurrences to a task’s Notify port (to which, of course,
thetaskhasreceiverights).
Themach port allocate()functioncallcreatesanewportandallocates
space for its queue of messages. It also identifies the rights for the port. Each
portrightrepresentsanameforthatport,andaportcanonlybeaccessedvia136 Chapter3 Processes
a right.Port names are simpleinteger valuesand behave much likeUNIX file
descriptors.ThefollowingexampleillustratescreatingaportusingthisAPI:
mach port t port; // the name of the port right
mach port allocate(
mach task self(), // a task referring to itself
MACH PORT RIGHT RECEIVE, // the right for this port
&port); // the name of the port right
Eachtaskalsohasaccesstoabootstrapport,whichallowsatasktoregister
aportithascreatedwithasystem-widebootstrapserver.Onceaporthasbeen
registered with the bootstrap server, other tasks can look up the port in this
registryandobtainrightsforsendingmessagestotheport.
Thequeueassociatedwitheachportisfiniteinsizeandisinitiallyempty.
As messagesaresent tothe port,the messagesare copiedintothe queue.All
messagesare deliveredreliablyand have the same priority.Mach guarantees
that multiple messages from the same sender are queued in first-in, first-
out (FIFO) order but does not guarantee an absolute ordering. For instance,
messagesfromtwosendersmaybequeuedinanyorder.
Machmessagescontainthefollowingtwofields:
• A fixed-size message header containing metadata about the message,
includingthesizeofthemessageaswellassourceanddestinationports.
Commonly, the sending thread expects a reply, so the port name of the
source is passed on to the receiving task, which can use it as a “return
address”insendingareply.
• Avariable-sizedbodycontainingdata.
Messages may be either simple or complex. A simple message contains
ordinary, unstructured user data that are not interpreted by the kernel. A
complex message may contain pointers to memory locations containing data
(knownas“out-of-line”data)ormayalsobeusedfortransferringportrights
toanothertask.Out-of-linedatapointersareespeciallyusefulwhenamessage
mustpasslargechunksofdata.Asimplemessagewouldrequirecopyingand
packagingthedatainthemessage;out-of-linedatatransmissionrequiresonly
apointerthatreferstothememorylocationwherethedataarestored.
The function mach msg() is the standard API for both sending and
receiving messages. The value of one of the function’s parameters—either
MACH SEND MSGorMACH RCV MSG—indicatesifitisasendorreceiveoperation.
Wenowillustratehowitisusedwhenaclienttasksendsasimplemessageto
aservertask.Assumetherearetwoports—client and server—associated
with the client and server tasks, respectively. The code in Figure 3.18 shows
the client task constructing a header and sending a message to the server, as
wellastheservertaskreceivingthemessagesentfromtheclient.
Themach msg()functioncallisinvokedbyuserprogramsforperforming
message passing. mach msg() then invokes the function mach msg trap(),
whichisasystemcalltotheMachkernel.Withinthekernel,mach msg trap()
nextcallsthefunctionmach msg overwrite trap(),whichthenhandlesthe
actualpassingofthemessage.3.7 ExamplesofIPCSystems 137
#include<mach/mach.h>
struct message {
mach msg header t header;
int data;
};
mach port t client;
mach port t server;
/* ClientCode */
struct message message;
// construct the header
message.header.msgh size = sizeof(message);
message.header.msgh remote port = server;
message.header.msgh local port = client;
// send the message
mach msg(&message.header, // message header
MACH SEND MSG, // sending a message
sizeof(message), // size of message sent
0, // maximum size of received message - unnecessary
MACH PORT NULL, // name of receive port - unnecessary
MACH MSG TIMEOUT NONE, // no time outs
MACH PORT NULL // no notify port
);
/* ServerCode */
struct message message;
// receive the message
mach msg(&message.header, // message header
MACH RCV MSG, // sending a message
0, // size of message sent
sizeof(message), // maximum size of received message
server, // name of receive port
MACH MSG TIMEOUT NONE, // no time outs
MACH PORT NULL // no notify port
);
Figure3.18 ExampleprogramillustratingmessagepassinginMach.
Thesendandreceiveoperationsthemselvesareflexible.Forinstance,when
a message is sent to a port, its queue may be full. If the queue is not full,
the message is copied to the queue, and the sending task continues. If the138 Chapter3 Processes
port’s queue is full, the sender has several options (specified via parameters
tomach msg():
1. Waitindefinitelyuntilthereisroominthequeue.
2. Waitatmostnmilliseconds.
3. Donotwaitatallbutratherreturnimmediately.
4. Temporarilycache amessage.Here,amessageisgiventotheoperating
system to keep, even though the queue to which that message is being
sent is full. When the message can be put in the queue, a notification
messageissentbacktothesender.Onlyonemessagetoafullqueuecan
bependingatanytimeforagivensendingthread.
The final option is meant for server tasks. After finishing a request, a server
taskmayneedtosendaone-timereplytothetaskthatrequestedtheservice,
butitmustalsocontinuewithotherservicerequests,evenifthereplyportfor
aclientisfull.
Themajorproblemwithmessagesystemshasgenerallybeenpoorperfor-
mancecausedbycopyingofmessagesfromthesender’sporttothereceiver’s
port. The Mach message system attempts to avoid copy operations by using
virtual-memory-managementtechniques(Chapter10).Essentially,Machmaps
theaddressspacecontainingthesender’smessageintothereceiver’saddress
space.Therefore,themessageitselfisneveractuallycopied,asboththesender
and receiver access the same memory. This message-management technique
providesalargeperformanceboostbutworksonlyforintrasystemmessages.
3.7.3 Windows
TheWindowsoperatingsystemisanexampleofmoderndesignthatemploys
modularity to increase functionality and decrease the time needed to imple-
ment new features. Windows provides support for multiple operating envi-
ronments,orsubsystems.Applicationprogramscommunicatewiththesesub-
systemsviaamessage-passingmechanism.Thus,applicationprogramscanbe
consideredclientsofasubsystemserver.
Themessage-passingfacilityinWindowsiscalledtheadvancedlocalpro-
cedurecall(ALPC)facility.Itisusedforcommunicationbetweentwoprocesses
onthesamemachine.Itissimilartothestandardremoteprocedurecall(RPC)
mechanismthatiswidelyused,butitisoptimizedforandspecifictoWindows.
(RemoteprocedurecallsarecoveredindetailinSection3.8.2.)LikeMach,Win-
dows uses a port object to establish and maintain a connection between two
processes.Windowsusestwotypesofports:connectionportsandcommuni-
cationports.
Serverprocessespublishconnection-portobjectsthatarevisibletoallpro-
cesses.Whenaclientwantsservicesfromasubsystem,itopensahandletothe
server’s connection-port object and sends a connection request to that port.
Theserverthencreatesachannelandreturnsahandletotheclient.Thechan-
nel consists of a pair of private communication ports: one for client–server
messages,theotherforserver–clientmessages.Additionally,communication
channels support a callback mechanism that allows the client and server to
acceptrequestswhentheywouldnormallybeexpectingareply.3.7 ExamplesofIPCSystems 139
Client Server
Connection
request Connection Handle
Port
Handle Client
Communication Port
Server Handle
Communication Port
Shared
Section Object
(> 256 bytes)
Figure3.19 AdvancedlocalprocedurecallsinWindows.
WhenanALPCchanneliscreated,oneofthreemessage-passingtechniques
ischosen:
1. For small messages (up to 256 bytes), the port’s message queue is used
asintermediatestorage,andthemessagesarecopiedfromoneprocessto
theother.
2. Larger messages must be passed through a section object, which is a
regionofsharedmemoryassociatedwiththechannel.
3. Whentheamountofdataistoolargetofitintoasectionobject,anAPIis
availablethatallowsserverprocessestoreadandwritedirectlyintothe
addressspaceofaclient.
The client has to decide when it sets up the channel whether it will need
to send a large message. If the client determines that it does want to send
largemessages,itasksforasectionobjecttobecreated.Similarly,iftheserver
decidesthatreplieswillbelarge,itcreatesasectionobject.Sothatthesection
object can be used, a small message is sent that contains a pointer and size
informationaboutthesectionobject.Thismethodismorecomplicatedthanthe
firstmethodlistedabove,butitavoidsdatacopying.Thestructureofadvanced
localprocedurecallsinWindowsisshowninFigure3.19.
ItisimportanttonotethattheALPCfacilityinWindowsisnotpartofthe
Windows APIandhence isnot visibletotheapplicationprogrammer.Rather,
applications using the Windows API invokestandardremoteprocedurecalls.
When the RPC is being invoked on a process on the same system, the RPC is
handledindirectlythroughanALPCprocedurecall.Additionally,manykernel
servicesuseALPCtocommunicatewithclientprocesses.
3.7.4 Pipes
Apipeacts as a conduit allowing two processes to communicate. Pipes were
one of the first IPC mechanisms in early UNIX systems. They typically pro-
videoneofthesimplerwaysforprocessestocommunicatewithoneanother,
althoughtheyalsohavesomelimitations.Inimplementingapipe,fourissues
mustbeconsidered:140 Chapter3 Processes
1. Does the pipe allow bidirectional communication, or is communication
unidirectional?
2. If two-way communication is allowed, is it half duplex (data can travel
onlyonewayatatime)orfullduplex(datacantravelinbothdirections
atthesametime)?
3. Must a relationship (such as parent–child) exist between the communi-
catingprocesses?
4. Canthepipescommunicateoveranetwork,ormustthecommunicating
processesresideonthesamemachine?
Inthefollowingsections,weexploretwocommontypesofpipesusedonboth
UNIXandWindowssystems:ordinarypipesandnamedpipes.
3.7.4.1 OrdinaryPipes
Ordinary pipes allow two processes to communicate in standard producer–
consumer fashion: theproducerwritestoone endofthepipe(the writeend)
andtheconsumerreadsfromtheotherend(thereadend).Asaresult,ordinary
pipes are unidirectional, allowing only one-way communication. If two-way
communication is required, two pipes must be used, with each pipe sending
data in a different direction. We next illustrate constructing ordinary pipes
onbothUNIX andWindows systems.Inbothprogramexamples,oneprocess
writes the messageGreetings tothe pipe,while the other process reads this
messagefromthepipe.
OnUNIXsystems,ordinarypipesareconstructedusingthefunction
pipe(int fd[])
Thisfunctioncreatesapipethatisaccessedthroughtheint fd[]filedescrip-
tors:fd[0]isthereadendofthepipe,andfd[1]isthewriteend.UNIXtreatsa
pipeasaspecialtypeoffile.Thus,pipescanbeaccessedusingordinaryread()
andwrite()systemcalls.
Anordinarypipecannotbeaccessedfromoutsidetheprocessthatcreated
it. Typically, a parent process creates a pipe and uses it to communicate with
achildprocessthatitcreatesviafork().RecallfromSection3.3.1thatachild
process inherits open files from its parent. Since a pipe is a special type of
file, the child inherits the pipe from its parent process. Figure 3.20 illustrates
Parent Child
fd [0] fd [0]
fd [1] fd [1]
pipe
Figure3.20 Filedescriptorsforanordinarypipe.3.7 ExamplesofIPCSystems 141
#include <sys/types.h>
#include <stdio.h>
#include <string.h>
#include <unistd.h>
#define BUFFER SIZE 25
#define READ END 0
#define WRITE END 1
int main(void)
{
char write msg[BUFFER SIZE] = "Greetings";
char read msg[BUFFER SIZE];
int fd[2];
pid t pid;
/*Programcontinuesin Figure3.22*/
Figure3.21 OrdinarypipeinUNIX.
the relationship of the file descriptors in the fd array to the parent and child
processes. As this illustrates, any writes by the parent to its write end of the
pipe—fd[1]—can be read by the child from its read end—fd[0]—of the
pipe.
In the UNIX program shown in Figure 3.21, the parent process creates a
pipe and then sends a fork() call creating the child process. What occurs
after the fork() call depends on how the data are to flow through the pipe.
Inthisinstance,theparentwritestothepipe,andthechildreadsfromit.Itis
importanttonoticethatboththeparentprocessandthechildprocessinitially
close their unused ends of the pipe. Although the program shown in Figure
3.21doesnotrequirethisaction,itisanimportantsteptoensurethataprocess
readingfromthepipecandetectend-of-file(read()returns0)whenthewriter
hascloseditsendofthepipe.
Ordinary pipes on Windows systems are termed anonymous pipes, and
they behave similarly to their UNIX counterparts: they are unidirectional and
employparent–child relationships betweenthe communicating processes.In
addition,readingand writing tothe pipecan be accomplished with the ordi-
naryReadFile()andWriteFile()functions.TheWindowsAPIforcreating
pipes is the CreatePipe() function, which is passed four parameters. The
parametersprovideseparatehandlesfor(1)readingand(2)writingtothepipe,
aswellas(3)aninstanceoftheSTARTUPINFOstructure,whichisusedtospecify
thatthechildprocessistoinheritthehandlesofthepipe.Furthermore,(4)the
sizeofthepipe(inbytes)maybespecified.
Figure 3.23 illustrates a parent process creating an anonymous pipe for
communicating with its child. Unlike UNIX systems, in which a child pro-
cessautomaticallyinheritsapipecreatedbyitsparent,Windowsrequiresthe
programmer to specify which attributes the child process will inherit. This is142 Chapter3 Processes
/* create the pipe */
if (pipe(fd) == -1) {
fprintf(stderr,"Pipe failed");
return 1;
}
/* fork a child process */
pid = fork();
if (pid < 0) { /* error occurred */
fprintf(stderr, "Fork Failed");
return 1;
}
if (pid > 0) { /* parent process */
/* close the unused end of the pipe */
close(fd[READ END]);
/* write to the pipe */
write(fd[WRITE END], write msg, strlen(write msg)+1);
/* close the write end of the pipe */
close(fd[WRITE END]);
}
else { /* child process */
/* close the unused end of the pipe */
close(fd[WRITE END]);
/* read from the pipe */
read(fd[READ END], read msg, BUFFER SIZE);
printf("read %s",read msg);
/* close the read end of the pipe */
close(fd[READ END]);
}
return 0;
}
Figure3.22 Figure3.21,continued.
accomplishedbyfirstinitializingtheSECURITY ATTRIBUTESstructuretoallow
handles to be inherited and then redirecting the child process’s handles for
standardinputorstandardoutputtothereadorwritehandleofthepipe.Since
the child will be reading from the pipe, the parent must redirect the child’s
standardinputtothereadhandleofthepipe.Furthermore,asthepipesarehalf
duplex,itisnecessarytoprohibitthechildfrominheritingthewriteendofthe3.7 ExamplesofIPCSystems 143
#include <stdio.h>
#include <stdlib.h>
#include <windows.h>
#define BUFFER SIZE 25
int main(VOID)
{
HANDLE ReadHandle, WriteHandle;
STARTUPINFO si;
PROCESS INFORMATION pi;
char message[BUFFER SIZE] = "Greetings";
DWORD written;
/*Programcontinuesin Figure3.24*/
Figure3.23 Windowsanonymouspipe—parentprocess.
pipe.TheprogramtocreatethechildprocessissimilartotheprograminFigure
3.10, except that the fifth parameter is set to TRUE, indicating that the child
process is toinherit designatedhandles from its parent.Beforewriting tothe
pipe,theparentfirstclosesitsunusedreadendofthepipe.Thechildprocess
thatreadsfromthepipeisshowninFigure3.25.Beforereadingfromthepipe,
thisprogramobtainsthereadhandletothepipebyinvokingGetStdHandle().
Notethat ordinarypipesrequireaparent–child relationshipbetweenthe
communicating processes on both UNIX and Windows systems. This means
thatthesepipescanbeusedonlyforcommunicationbetweenprocessesonthe
samemachine.
3.7.4.2 NamedPipes
Ordinary pipes provide a simple mechanism for allowing a pair of processes
to communicate. However, ordinary pipes exist only while the processes are
communicatingwithoneanother.OnbothUNIXandWindows systems,once
theprocesseshavefinishedcommunicatingandhaveterminated,theordinary
pipeceasestoexist.
Named pipes providea much more powerful communication tool. Com-
municationcanbebidirectional,andnoparent–childrelationshipisrequired.
Once a named pipe is established, several processes can use it for communi-
cation. In fact, in a typical scenario, a named pipe has several writers. Addi-
tionally, named pipes continue to exist after communicating processes have
finished.BothUNIXandWindowssystemssupportnamedpipes,althoughthe
detailsofimplementationdiffergreatly.Next,weexplorenamedpipesineach
ofthesesystems.
NamedpipesarereferredtoasFIFOsinUNIXsystems.Oncecreated,they
appear as typical files in the file system. AFIFO is createdwith the mkfifo()
system call and manipulated with the ordinary open(), read(), write(),
andclose()systemcalls.Itwillcontinuetoexistuntilitisexplicitlydeleted144 Chapter3 Processes
/* set up security attributes allowing pipes to be inherited */
SECURITY ATTRIBUTES sa = {sizeof(SECURITY ATTRIBUTES),NULL,TRUE};
/* allocate memory */
ZeroMemory(&pi, sizeof(pi));
/* create the pipe */
if (!CreatePipe(&ReadHandle, &WriteHandle, &sa, 0)) {
fprintf(stderr, "Create Pipe Failed");
return 1;
}
/* establish the START INFO structure for the child process */
GetStartupInfo(&si);
si.hStdOutput = GetStdHandle(STD OUTPUT HANDLE);
/* redirect standard input to the read end of the pipe */
si.hStdInput = ReadHandle;
si.dwFlags = STARTF USESTDHANDLES;
/* don’t allow the child to inherit the write end of pipe */
SetHandleInformation(WriteHandle, HANDLE FLAG INHERIT, 0);
/* create the child process */
CreateProcess(NULL, "child.exe", NULL, NULL,
TRUE, /* inherit handles */
0, NULL, NULL, &si, &pi);
/* close the unused end of the pipe */
CloseHandle(ReadHandle);
/* the parent writes to the pipe */
if (!WriteFile(WriteHandle, message,BUFFER SIZE,&written,NULL))
fprintf(stderr, "Error writing to pipe.");
/* close the write end of the pipe */
CloseHandle(WriteHandle);
/* wait for the child to exit */
WaitForSingleObject(pi.hProcess, INFINITE);
CloseHandle(pi.hProcess);
CloseHandle(pi.hThread);
return 0;
}
Figure3.24 Figure3.23,continued.3.8 CommunicationinClient–ServerSystems 145
#include <stdio.h>
#include <windows.h>
#define BUFFER SIZE 25
int main(VOID)
{
HANDLE Readhandle;
CHAR buffer[BUFFER SIZE];
DWORD read;
/* get the read handle of the pipe */
ReadHandle = GetStdHandle(STD INPUT HANDLE);
/* the child reads from the pipe */
if (ReadFile(ReadHandle, buffer, BUFFER SIZE, &read, NULL))
printf("child read %s",buffer);
else
fprintf(stderr, "Error reading from pipe");
return 0;
}
Figure3.25 Windowsanonymouspipes—childprocess.
fromthefilesystem.AlthoughFIFOsallowbidirectionalcommunication,only
half-duplex transmission is permitted. If data must travel in both directions,
twoFIFOsaretypicallyused.Additionally,thecommunicatingprocessesmust
resideonthesamemachine.Ifintermachinecommunicationisrequired,sock-
ets(Section3.8.1)mustbeused.
NamedpipesonWindowssystemsprovidearichercommunicationmech-
anism than their UNIX counterparts. Full-duplex communication is allowed,
and the communicating processes may reside on either the same or different
machines. Additionally, only byte-oriented data may be transmitted across a
UNIXFIFO,whereasWindowssystemsalloweitherbyte-ormessage-oriented
data. Namedpipes are createdwith the CreateNamedPipe()function, and a
client can connect to a named pipe using ConnectNamedPipe(). Communi-
cation over the named pipe can be accomplished using the ReadFile() and
WriteFile()functions.
3.8 Communication in Client–Server Systems
In Section 3.4, we described how processes can communicate using shared
memoryandmessagepassing.Thesetechniquescanbeusedforcommunica-
tioninclient–serversystems(Section1.10.3)aswell.Inthissection,weexplore
twootherstrategiesforcommunicationinclient–serversystems:socketsand146 Chapter3 Processes
PIPESINPRACTICE
PipesareusedquiteoftenintheUNIXcommand-lineenvironmentforsitu-
ations in which theoutput ofonecommandservesas input to another.For
example,theUNIXlscommandproducesadirectorylisting.Forespecially
long directory listings, the output may scroll through several screens. The
commandlessmanagesoutputbydisplayingonlyonescreenofoutputat
a time where the user may use certain keys to move forward or backward
in the file. Setting up a pipe between the ls and less commands (which
arerunningasindividualprocesses)allowstheoutputoflstobedelivered
as theinputto less,enablingtheuser todisplay alarge directorylisting a
screenatatime.Apipecanbeconstructedonthecommandlineusingthe|
character.Thecompletecommandis
ls | less
In this scenario, the ls command serves as the producer, and its output is
consumedbythelesscommand.
WindowssystemsprovideamorecommandfortheDOSshellwithfunc-
tionality similar to that of its UNIX counterpart less. (UNIX systems also
provideamorecommand,butinthetongue-in-cheekstylecommoninUNIX,
thelesscommandinfactprovidesmorefunctionalitythanmore!)TheDOS
shellalsousesthe|characterforestablishingapipe.Theonlydifferenceis
thattogetadirectorylisting,DOSusesthedircommandratherthanls,as
shownbelow:
dir | more
remote procedure calls (RPCs). As we shall see in our coverage of RPCs, not
onlyaretheyusefulforclient–servercomputing,butAndroidalsousesremote
proceduresasaformofIPCbetweenprocessesrunningonthesamesystem.
3.8.1 Sockets
Asocketisdefinedasanendpointforcommunication.Apairofprocessescom-
municating over a network employs a pair of sockets—one for each process.
A socket is identified by an IP address concatenated with a port number. In
general,socketsuseaclient–serverarchitecture.Theserverwaitsforincoming
client requestsby listening toaspecifiedport.Once arequestis received,the
serveracceptsaconnectionfromtheclientsockettocompletetheconnection.
Servers implementing specific services (such as SSH, FTP, and HTTP) listen to
well-known ports (an SSH server listens to port 22; an FTP server listens to
port 21; and a web, or HTTP, server listens to port 80). All ports below 1024
areconsideredwellknownandareusedtoimplementstandardservices.
When a client process initiates a request for a connection, it is assigned a
port by its host computer. This port has some arbitrary number greater than
1024. For example, if a client on host X with IP address 146.86.5.20 wishes to
establish a connection with a web server (which is listening on port 80) at3.8 CommunicationinClient–ServerSystems 147
host X
(146.86.5.20)
socket
(146.86.5.20:1625)
web server
(161.25.19.8)
socket
(161.25.19.8:80)
Figure3.26 Communicationusingsockets.
address 161.25.19.8, host X may be assigned port 1625. The connection will
consist of a pair of sockets: (146.86.5.20:1625) on host X and (161.25.19.8:80)
on the web server. This situation is illustrated in Figure 3.26. The packets
travelingbetweenthehostsaredeliveredtotheappropriateprocessbasedon
thedestinationportnumber.
Allconnectionsmustbeunique.Therefore,ifanotherprocessalsoonhost
Xwishedtoestablishanotherconnectionwiththesamewebserver,itwouldbe
assignedaportnumbergreaterthan1024andnotequalto1625.Thisensures
thatallconnectionsconsistofauniquepairofsockets.
Although most program examples in this text use C, we will illustrate
sockets using Java, as it provides a much easier interface to sockets and has
arichlibraryfornetworkingutilities.Thoseinterestedinsocketprogramming
inCorC++shouldconsultthebibliographicalnotesattheendofthechapter.
Javaprovidesthreedifferenttypesofsockets.Connection-oriented(TCP)
socketsareimplementedwiththeSocketclass.Connectionless(UDP)sockets
use the DatagramSocket class. Finally, the MulticastSocket class is a sub-
classoftheDatagramSocketclass.Amulticastsocketallowsdatatobesentto
multiplerecipients.
Our example describes a date server that uses connection-oriented TCP
sockets.Theoperationallowsclientstorequestthecurrentdateandtimefrom
the server. The server listens to port 6013, although the port could have any
arbitrary, unused number greater than 1024. When a connection is received,
theserverreturnsthedateandtimetotheclient.
ThedateserverisshowninFigure3.27.TheservercreatesaServerSocket
that specifies that it will listen to port 6013. The server then begins listening
to the port with the accept() method. The server blocks on the accept()
methodwaitingforaclienttorequestaconnection.Whenaconnectionrequest
isreceived,accept()returnsasocketthattheservercanusetocommunicate
withtheclient.
Thedetailsofhowtheservercommunicateswiththesocketareasfollows.
TheserverfirstestablishesaPrintWriterobjectthatitwillusetocommuni-
cate with the client. A PrintWriter object allows the server to write to the
socket using the routine print() and println() methods for output. The148 Chapter3 Processes
import java.net.*;
import java.io.*;
public class DateServer
{
public static void main(String[] args) {
try {
ServerSocket sock = new ServerSocket(6013);
/* now listen for connections */
while (true) {
Socket client = sock.accept();
PrintWriter pout = new
PrintWriter(client.getOutputStream(), true);
/* write the Date to the socket */
pout.println(new java.util.Date().toString());
/* close the socket and resume */
/* listening for connections */
client.close();
}
}
catch (IOException ioe) {
System.err.println(ioe);
}
}
}
Figure3.27 Dateserver.
serverprocesssendsthedatetotheclient,callingthemethodprintln().Once
ithaswrittenthedatetothesocket,theserverclosesthesockettotheclientand
resumeslisteningformorerequests.
Aclientcommunicateswiththeserverbycreatingasocketandconnecting
totheportonwhichtheserverislistening.Weimplementsuchaclientinthe
Java program shown in Figure 3.28. The client creates a Socket and requests
a connection with the server at IP address 127.0.0.1 on port 6013. Once the
connection is made, the client can read from the socket using normal stream
I/Ostatements.Afterithasreceivedthedatefromtheserver,theclientcloses
thesocketandexits.TheIPaddress127.0.0.1isaspecialIPaddressknownasthe
loopback.WhenacomputerreferstoIPaddress127.0.0.1,itisreferringtoitself.
This mechanism allows a client and server on the same host to communicate
usingtheTCP/IPprotocol.TheIPaddress127.0.0.1couldbereplacedwiththe
IPaddressofanotherhostrunningthedateserver.InadditiontoanIPaddress,
anactual host name,such as www.westminstercollege.edu,canbe usedas
well.3.8 CommunicationinClient–ServerSystems 149
import java.net.*;
import java.io.*;
public class DateClient
{
public static void main(String[] args) {
try {
/* make connection to server socket */
Socket sock = new Socket("127.0.0.1",6013);
InputStream in = sock.getInputStream();
BufferedReader bin = new
BufferedReader(new InputStreamReader(in));
/* read the date from the socket */
String line;
while ( (line = bin.readLine()) != null)
System.out.println(line);
/* close the socket connection*/
sock.close();
}
catch (IOException ioe) {
System.err.println(ioe);
}
}
}
Figure3.28 Dateclient.
Communicationusingsockets—althoughcommonandefficient—iscon-
sidered a low-level form of communication between distributed processes.
One reason is that sockets allow only an unstructured stream of bytes to be
exchanged betweenthe communicating threads.Itis the responsibilityofthe
clientorserverapplicationtoimposeastructureonthedata.Inthenextsub-
section, we look a higher-level method of communication: remote procedure
calls(RPCs).
3.8.2 Remote Procedure Calls
OneofthemostcommonformsofremoteserviceistheRPCparadigm,which
was designed as a way to abstract the procedure-call mechanism for use
betweensystemswithnetworkconnections.Itissimilarinmanyrespectstothe
IPCmechanismdescribedinSection3.4,anditisusuallybuiltontopofsucha
system.Here,however,becausewearedealingwithanenvironmentinwhich
theprocessesareexecutingonseparatesystems,wemustuseamessage-based
communicationschemetoprovideremoteservice.150 Chapter3 Processes
In contrast to IPC messages, the messages exchanged in RPC communi-
cation are well structured and are thus no longer just packets of data. Each
messageisaddressedtoanRPCdaemonlisteningtoaportontheremotesys-
tem,andeachcontainsanidentifierspecifyingthefunctiontoexecuteandthe
parameterstopasstothatfunction.Thefunctionisthenexecutedasrequested,
andanyoutputissentbacktotherequesterinaseparatemessage.
Aportinthiscontextissimplyanumberincludedatthestartofamessage
packet. Whereas a system normally has one network address, it can have
many ports within that address to differentiate the many network services it
supports. If a remote process needs a service, it addresses a message to the
proper port. For instance, if a system wished to allow other systems to be
abletolistitscurrent users,itwould haveadaemonsupportingsuchanRPC
attachedtoaport—say,port3027.Anyremotesystemcouldobtaintheneeded
information(thatis,thelistofcurrentusers)bysendinganRPCmessagetoport
3027ontheserver.Thedatawouldbereceivedinareplymessage.
The semantics of RPCs allows a client to invoke a procedure on a remote
host as itwould invokea procedurelocally.TheRPC systemhidesthe details
thatallowcommunicationtotakeplacebyprovidingastubontheclientside.
Typically, a separate stub exists for each separate remote procedure. When
the client invokes a remote procedure, the RPC system calls the appropriate
stub, passing it the parameters provided to the remote procedure. This stub
locates the port on the server and marshals the parameters. The stub then
transmitsamessagetotheserverusingmessagepassing.Asimilarstubonthe
server side receives this message and invokes the procedure on the server. If
necessary,returnvaluesarepassedbacktotheclientusingthesametechnique.
OnWindowssystems,stubcodeiscompiledfromaspecificationwritteninthe
Microsoft Interface Definitio Language (MIDL), which is used for defining
theinterfacesbetweenclientandserverprograms.
Parameter marshaling addresses the issue concerning differences in data
representation on the client and server machines. Consider the representa-
tion of 32-bit integers. Some systems (known as big-endian) store the most
significant byte first, while other systems (known as little-endian) store the
leastsignificantbytefirst.Neitherorderis“better”perse;rather,thechoiceis
arbitrarywithinacomputerarchitecture.Toresolvedifferenceslikethis,many
RPC systems define a machine-independent representation of data. One such
representationis known as external data representation (XDR). On the client
side,parametermarshaling involvesconverting themachine-dependentdata
intoXDRbeforetheyaresenttotheserver.Ontheserverside,theXDRdataare
unmarshaledandconvertedtothemachine-dependentrepresentationforthe
server.
Another important issue involves the semantics of a call. Whereas local
procedure calls fail only under extreme circumstances, RPCs can fail, or be
duplicated and executed more than once, as a result of common network
errors.Onewaytoaddressthisproblemisfortheoperatingsystemtoensure
that messagesareactedonexactly once,ratherthanatmost once.Mostlocal
procedurecallshavethe“exactlyonce”functionality,butitismoredifficultto
implement.
First,consider“atmostonce.”Thissemanticcanbeimplementedbyattach-
ing a timestamp to each message. The server must keep a history of all the
timestamps of messages it has already processed or a history large enough3.8 CommunicationinClient–ServerSystems 151
to ensure that repeated messages are detected. Incoming messages that have
a timestamp already in the history are ignored. The client can then send a
messageoneormoretimesandbeassuredthatitonlyexecutesonce.
For “exactly once,” we need to remove the risk that the server will never
receivetherequest.Toaccomplishthis,theservermustimplementthe“atmost
once” protocol described above but must also acknowledge to the client that
the RPC call was received and executed. These ACK messages are common
throughoutnetworking.TheclientmustresendeachRPCcallperiodicallyuntil
itreceivestheACKforthatcall.
Yetanotherimportantissueconcernsthecommunicationbetweenaserver
andaclient.Withstandardprocedurecalls,someformofbindingtakesplace
duringlink,load,orexecutiontime(Chapter9)sothataprocedurecall’sname
is replaced by the memory address of the procedure call. The RPC scheme
requiresasimilarbindingoftheclientandtheserverport,buthowdoesaclient
know the port numbers on the server? Neither system has full information
abouttheother,becausetheydonotsharememory.
Twoapproachesarecommon.First,thebindinginformationmaybeprede-
termined,intheformoffixedportaddresses.Atcompiletime,anRPCcallhas
afixedportnumberassociatedwithit.Onceaprogramiscompiled,theserver
cannotchangetheportnumberoftherequestedservice.Second,bindingcanbe
donedynamicallybyarendezvousmechanism.Typically,anoperatingsystem
providesarendezvous(alsocalledamatchmaker)daemononafixedRPCport.
AclientthensendsamessagecontainingthenameoftheRPCtotherendezvous
daemon requesting the port address of the RPC it needs to execute. The port
numberisreturned,andtheRPCcallscanbesenttothatportuntiltheprocess
terminates(ortheservercrashes).Thismethodrequirestheextraoverheadof
theinitialrequestbutismoreflexiblethanthefirstapproach.Figure3.29shows
asampleinteraction.
TheRPCschemeisusefulinimplementingadistributedfilesystem(Chap-
ter19).SuchasystemcanbeimplementedasasetofRPCdaemonsandclients.
Themessagesareaddressedtothedistributedfilesystemportonaserveron
whichafileoperationistotakeplace.Themessagecontainsthediskoperation
to be performed. The disk operation might be read(), write(), rename(),
delete(), or status(), corresponding to the usual file-related system calls.
The return message contains any data resulting from that call, which is exe-
cutedbytheDFSdaemononbehalfoftheclient.Forinstance,amessagemight
contain a request to transfer a whole file to a client or be limited to a simple
blockrequest.Inthelattercase,severalrequestsmaybeneededifawholefile
istobetransferred.
3.8.2.1 AndroidRPC
AlthoughRPCsaretypicallyassociatedwithclient-servercomputinginadis-
tributed system, they can also be used as a form of IPC between processes
running on the same system. The Android operating system has a rich set of
IPCmechanismscontainedinitsbinderframework,includingRPCsthatallow
oneprocesstorequestservicesfromanotherprocess.
Androiddefinesanapplicationcomponentasabasicbuildingblockthat
providesutilitytoanAndroidapplication,andanappmaycombinemultiple
applicationcomponentstoprovidefunctionalitytoanapp.Onesuchapplica-152 Chapter3 Processes
client messages server
user calls kernel
to send RPC
message to
procedure X
From: client
kernel sends matchmaker
To: server
message to receives
Port: matchmaker
matchmaker to message, looks
Re: address
find port number for RPC X up answer
From: server
kernel places To: client matchmaker
port P in user Port: kernel replies to client
RPC message Re: RPC X with port P
Port: P
From: client daemon
kernel sends To: server listening to
RPC Port: port P port P receives
<contents> message
From: RPC daemon
kernel receives Port: P processes
reply, passes To: client request and
it to user Port: kernel processes send
<output> output
Figure3.29 Executionofaremoteprocedurecall(RPC).
tion component is a service, which has no user interface but instead runs in
thebackgroundwhileexecutinglong-runningoperationsorperformingwork
forremoteprocesses.Examplesofservicesincludeplayingmusicintheback-
ground and retrieving data over a network connection on behalf of another
process, thereby preventing the other process from blocking as the data are
being downloaded. When a client app invokes the bindService() method
of a service, that service is “bound” and available to provide client-server
communicationusingeithermessagepassingorRPCs.
AboundservicemustextendtheAndroidclassServiceandmustimple-
ment the method onBind(), which is invoked when a client calls bindSer-
vice().Inthecaseofmessagepassing,theonBind()methodreturnsaMes-
senger service, which is used for sending messages from the client to the
service.TheMessengerserviceisonlyone-way;iftheservicemustsendareply
back to the client, the client must also providea Messenger service,which is
contained in the replyTo field of the Message object sent to the service. The
servicecanthensendmessagesbacktotheclient.
To provide RPCs, the onBind() method must return an interface repre-
senting the methods in the remote object that clients use to interact with the3.9 Summary 153
service. This interface is written in regular Java syntax and uses the Android
InterfaceDefinitionLanguage—AIDL—tocreatestubfiles,whichserveasthe
clientinterfacetoremoteservices.
Here, we briefly outline the process requiredto providea genericremote
servicenamedremoteMethod()usingAIDLandthebinderservice.Theinter-
facefortheremoteserviceappearsasfollows:
/* RemoteService.aidl */
interface RemoteService
{
boolean remoteMethod(int x, double y);
{
This file is written as RemoteService.aidl. The Android development kit
will use it togenerate a .java interface from the .aidl file, as well as a stub
thatservesastheRPCinterfaceforthisservice.Theservermustimplementthe
interfacegeneratedbythe.aidlfile,andtheimplementationofthisinterface
willbecalledwhentheclientinvokesremoteMethod().
When a client calls bindService(), the onBind() method is invoked on
the server, and it returns the stub for the RemoteService object to the client.
Theclientcantheninvoketheremotemethodasfollows:
RemoteService service;
. . .
service.remoteMethod(3, 0.14);
Internally,theAndroidbinderframeworkhandlesparametermarshaling,
transferring marshaledparametersbetween processes,and invoking the nec-
essaryimplementationoftheservice,aswellassendinganyreturnvaluesback
totheclientprocess.
3.9 Summary
• Aprocessisaprograminexecution,andthestatusofthecurrentactivityof
aprocessisrepresentedbytheprogramcounter,aswellasotherregisters.
• Thelayoutofaprocessinmemoryisrepresentedbyfourdifferentsections:
(1)text,(2)data,(3)heap,and(4)stack.
• As a process executes, it changes state. There are four general states of a
process:(1)ready,(2)running,(3)waiting,and(4)terminated.
• Aprocesscontrolblock(PCB)isthekerneldatastructurethatrepresentsa
processinanoperatingsystem.
• Theroleoftheprocessscheduleristoselectanavailableprocesstorunon
aCPU.
• An operating system performs a context switch when it switches from
runningoneprocesstorunninganother.154 Chapter3 Processes
• The fork() and CreateProcess() system calls are used to create pro-
cessesonUNIXandWindowssystems,respectively.
• Whensharedmemoryisusedforcommunicationbetweenprocesses,two
(or more) processes share the same region of memory.POSIX providesan
APIforsharedmemory.
• Two processes may communicate by exchanging messages with one
anotherusingmessagepassing.TheMachoperatingsystemusesmessage
passing as its primary form of interprocess communication. Windows
providesaformofmessagepassingaswell.
• A pipe provides a conduit for two processes to communicate. There are
twoformsofpipes,ordinaryandnamed.Ordinarypipesaredesignedfor
communicationbetweenprocessesthathaveaparent–childrelationship.
Namedpipesare moregeneral and allow severalprocessesto communi-
cate.
• UNIX systems provide ordinary pipes through the pipe() system call.
Ordinarypipeshaveareadendandawriteend.Aparentprocesscan,for
example,send data to the pipe using its write end, and the child process
canreaditfromitsreadend.NamedpipesinUNIXaretermedFIFOs.
• Windows systems also provide two forms of pipes—anonymous and
namedpipes.AnonymouspipesaresimilartoUNIXordinarypipes.They
are unidirectional and employ parent–child relationships between the
communicatingprocesses.Namedpipesofferaricherformofinterprocess
communicationthantheUNIXcounterpart,FIFOs.
• Two common forms of client–server communication are sockets and
remote procedure calls (RPCs). Sockets allow two processes on different
machines to communicate over a network. RPCs abstract the concept of
function(procedure)callsinsuchawaythatafunctioncanbeinvokedon
anotherprocessthatmayresideonaseparatecomputer.
• The Android operating system uses RPCs as a form of interprocess com-
municationusingitsbinderframework.
Practice Exercises
3.1 Using the program shown in Figure 3.30, explain what the output will
beatLINE A.
3.2 Includingtheinitialparentprocess,howmanyprocessesarecreatedby
theprogramshowninFigure3.31?
3.3 Original versions of Apple’s mobile iOS operating system provided no
meansofconcurrentprocessing.Discussthreemajorcomplicationsthat
concurrentprocessingaddstoanoperatingsystem.
3.4 Some computer systems provide multiple register sets. Describe what
happens when a context switch occurs if the new context is alreadyPracticeExercises 155
#include <sys/types.h>
#include <stdio.h>
#include <unistd.h>
int value = 5;
int main()
{
pid t pid;
pid = fork();
if (pid == 0) { /* child process */
value += 15;
return 0;
}
else if (pid > 0) { /* parent process */
wait(NULL);
printf("PARENT: value = %d",value); /* LINE A */
return 0;
}
}
Figure3.30 WhatoutputwillbeatLineA?
loaded into one of the register sets. What happens if the new context
isinmemoryratherthaninaregistersetandalltheregistersetsarein
use?
3.5 Whenaprocesscreatesanewprocessusingthefork()operation,which
ofthefollowingstatesissharedbetweentheparentprocessandthechild
process?
a. Stack
b. Heap
c. Sharedmemorysegments
3.6 Considerthe“exactlyonce”semanticwithrespecttotheRPCmechanism.
Does the algorithm for implementing this semantic execute correctly
even if the ACK message sent back to the client is lost due to a net-
workproblem?Describethesequenceofmessages,anddiscusswhether
“exactlyonce”isstillpreserved.
3.7 Assumethat a distributedsystemis susceptibletoserverfailure.What
mechanismswouldberequiredtoguaranteethe“exactlyonce”semantic
forexecutionofRPCs?156 Chapter3 Processes
#include <stdio.h>
#include <unistd.h>
int main()
{
/* fork a child process */
fork();
/* fork another child process */
fork();
/* and fork another */
fork();
return 0;
}
Figure3.31 Howmanyprocessesarecreated?
Further Reading
Process creation, management, and IPC in UNIX and Windows systems,
respectively,arediscussedin[Robbins and Robbins (2003)] and [Russinovich
et al. (2017)]. [Love (2010)] covers support for processes in the Linux
kernel, and [Hart (2005)] covers Windows systems programming in detail.
CoverageofthemultiprocessmodelusedinGoogle’sChromecanbefoundat
http://blog.chromium.org/2008/09/multi-process-architecture.html.
Messagepassingformulticoresystemsisdiscussedin[HollandandSeltzer
(2011)].[Levin(2013)]describesmessagepassingintheMachsystem,particu-
larlywithrespecttomacOSandiOS.
[Harold(2005)]providescoverageofsocketprogramminginJava.Details
onAndroidRPCscanbefoundathttps://developer.android.com/guide/compo
nents/aidl.html.[Hart(2005)]and[RobbinsandRobbins(2003)]coverpipesin
WindowsandUNIXsystems,respectively.
GuidelinesforAndroiddevelopmentcanbefoundathttps://developer.and
roid.com/guide/.
Bibliography
[Harold(2005)] E.R.Harold,JavaNetworkProgramming,ThirdEdition,O’Reilly
&Associates(2005).
[Hart(2005)] J.M.Hart,WindowsSystemProgramming,ThirdEdition,Addison-
Wesley(2005).Bibliography 157
[HollandandSeltzer(2011)] D.HollandandM.Seltzer,“MulticoreOSes:Look-
ingForwardfrom1991,er,2011”,Proceedingsofthe13thUSENIXconferenceonHot
topicsinoperatingsystems(2011),pages33–33.
[Levin(2013)] J. Levin, Mac OS X and iOS Internals to the Apple’s Core, Wiley
(2013).
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[RobbinsandRobbins(2003)] K. Robbins and S. Robbins, Unix Systems Pro-
gramming: Communication, Concurrency and Threads, Second Edition, Prentice
Hall(2003).
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).Exercises EX-4
Chapter 3 Exercises
3.8 Describe the actions taken by a kernel to context-switch between pro-
cesses.
3.9 Construct a process tree similar to Figure 3.7. To obtain process infor-
mation for the UNIX or Linux system, use the command ps -ael.
Use the command man ps to get more information about the ps com-
mand. The task manager on Windows systems does not provide the
parent process ID, but the process monitor tool, available from tech-
net.microsoft.com,providesaprocess-treetool.
3.10 Explain the role of the init (or systemd) process on UNIX and Linux
systemsinregardtoprocesstermination.
3.11 Includingtheinitialparentprocess,howmanyprocessesarecreatedby
theprogramshowninFigure3.32?
3.12 Explain the circumstances under which the line of code marked
printf("LINE J")inFigure3.33willbereached.
3.13 UsingtheprograminFigure3.34,identifythevaluesofpidatlinesA,B,
C, and D. (Assume that the actual pids of the parent and child are 2600
and2603,respectively.)
3.14 Giveanexampleofasituationinwhichordinarypipesaremoresuitable
thannamedpipesandanexampleofasituationinwhichnamedpipes
aremoresuitablethanordinarypipes.
3.15 Consider the RPC mechanism. Describe the undesirable consequences
thatcouldarisefromnotenforcingeitherthe“atmostonce”or“exactly
once”semantic.Describepossibleusesforamechanismthathasneither
oftheseguarantees.
3.16 Using the program shown in Figure 3.35, explain what the output will
beatlinesXandY.
#include <stdio.h>
#include <unistd.h>
int main()
{
int i;
for (i = 0; i < 4; i++)
fork();
return 0;
}
Figure3.21 Howmanyprocessesarecreated?EX-5
3.17 What are the benefits and the disadvantages of each of the following?
Considerboththesystemlevelandtheprogrammerlevel.
a. Synchronousandasynchronouscommunication
b. Automaticandexplicitbuffering
c. Sendbycopyandsendbyreference
d. Fixed-sizedandvariable-sizedmessages
#include <sys/types.h>
#include <stdio.h>
#include <unistd.h>
int main()
{
pid t pid;
/* fork a child process */
pid = fork();
if (pid < 0) { /* error occurred */
fprintf(stderr, "Fork Failed");
return 1;
}
else if (pid == 0) { /* child process */
execlp("/bin/ls","ls",NULL);
printf("LINE J");
}
else { /* parent process */
/* parent will wait for the child to complete */
wait(NULL);
printf("Child Complete");
}
return 0;
}
Figure3.22 WhenwillLINE Jbereached?Exercises EX-6
#include <sys/types.h>
#include <stdio.h>
#include <unistd.h>
int main()
{
pid t pid, pid1;
/* fork a child process */
pid = fork();
if (pid < 0) { /* error occurred */
fprintf(stderr, "Fork Failed");
return 1;
}
else if (pid == 0) { /* child process */
pid1 = getpid();
printf("child: pid = %d",pid); /* A */
printf("child: pid1 = %d",pid1); /* B */
}
else { /* parent process */
pid1 = getpid();
printf("parent: pid = %d",pid); /* C */
printf("parent: pid1 = %d",pid1); /* D */
wait(NULL);
}
return 0;
}
Figure3.23 Whatarethepidvalues?EX-7
#include <sys/types.h>
#include <stdio.h>
#include <unistd.h>
#define SIZE 5
int nums[SIZE] = {0,1,2,3,4};
int main()
{
int i;
pid t pid;
pid = fork();
if (pid == 0) {
for (i = 0; i < SIZE; i++) {
nums[i] *= -i;
printf("CHILD: %d ",nums[i]); /* LINE X */
}
}
else if (pid > 0) {
wait(NULL);
for (i = 0; i < SIZE; i++)
printf("PARENT: %d ",nums[i]); /* LINE Y */
}
return 0;
}
Figure3.24 WhatoutputwillbeatLineXandLineY?ProgrammingProblems P-8
Programming Problems
3.18 Using either a UNIX or a Linux system, write a C program that forks
a child process that ultimatelybecomes a zombie process. This zombie
processmustremaininthesystemforatleast10seconds.Processstates
canbeobtainedfromthecommand
ps -l
TheprocessstatesareshownbelowtheScolumn;processeswithastate
ofZarezombies.Theprocessidentifier(pid)ofthechildprocessislisted
inthePIDcolumn,andthatoftheparentislistedinthePPIDcolumn.
Perhapstheeasiestwaytodeterminethatthechildprocessisindeed
azombieistoruntheprogramthatyouhavewritteninthebackground
(using the &) and then run the command ps -l to determine whether
thechildisazombieprocess.Becauseyoudonotwanttoomanyzombie
processes existing in the system, you will need to remove the one that
you have created.The easiest way to do that is to terminate the parent
processusingthekillcommand.Forexample,ifthepidoftheparent
is4884,youwouldenter
kill -9 4884
3.19 Write a C program called time.c that determines the amount of time
necessarytorunacommandfromthecommandline.Thisprogramwill
be run as "./time <command>" and will report the amount of elapsed
timetorunthespecifiedcommand.Thiswillinvolveusingfork()and
exec() functions, as well as the gettimeofday() function to deter-
mine the elapsed time. It will also require the use of two different IPC
mechanisms.
The general strategy is to fork a child process that will execute the
specifiedcommand. However,before the child executesthe command,
itwillrecordatimestampofthecurrenttime(whichweterm“starting
time”). The parent process will wait for the child process to terminate.
Oncethechildterminates,theparentwillrecordthecurrenttimestamp
for the ending time. The difference between the starting and ending
timesrepresentstheelapsedtimetoexecutethecommand.Theexample
outputbelowreportstheamountoftimetorunthecommandls:
./time ls
time.c
time
Elapsed time: 0.25422
As the parent and child are separate processes, they will need to
arrange how the starting time will be shared between them. You will
writetwoversionsofthisprogram,eachrepresentingadifferentmethod
ofIPC.P-9 Chapter3 Processes
Thefirstversionwillhavethechildprocesswritethestartingtimeto
aregionofsharedmemorybeforeitcallsexec().Afterthechildprocess
terminates,theparentwillreadthestartingtimefromsharedmemory.
Refer to Section 3.7.1 for details using POSIX shared memory. In that
section,thereareseparateprogramsfortheproducerandconsumer.As
the solution to this problem requiresonly a single program, the region
ofsharedmemorycanbeestablishedbeforethechildprocessisforked,
allowing both the parent and child processes access to the region of
sharedmemory.
Thesecondversionwilluseapipe.Thechildwillwritethestarting
timetothepipe,andtheparentwillreadfromitfollowingthetermina-
tionofthechildprocess.
You will use the gettimeofday() function to record the current
timestamp. This function is passed a pointer to a struct timeval
object, which contains two members: tv sec and t usec. These repre-
sentthenumberofelapsedsecondsand microsecondssinceJanuary1,
1970(knownastheUNIXEPOCH).Thefollowingcodesampleillustrates
howthisfunctioncanbeused:
struct timeval current;
gettimeofday(&current,NULL);
// current.tv sec represents seconds
// current.tv usec represents microseconds
For IPC between the child and parent processes, the contents of the
shared memory pointer can be assigned the struct timeval repre-
senting the starting time. When pipes are used, a pointer to a struct
timevalcanbewrittento—andreadfrom—thepipe.
3.20 Anoperatingsystem’spidmanagerisresponsibleformanagingprocess
identifiers. When a process is first created, it is assigned a unique pid
by the pid manager. The pid is returned to the pid manager when the
process completes execution, and the manager may later reassign this
pid. Process identifiers are discussed more fully in Section 3.3.1. What
is most important here is to recognize that process identifiers must be
unique;notwoactiveprocessescanhavethesamepid.
Use the following constants to identify the range of possible pid
values:
#define MIN PID 300
#define MAX PID 5000
You may use any data structure of your choice to represent the avail-
ability of process identifiers. One strategy is to adopt what Linux has
doneanduseabitmapinwhichavalueof0atpositioniindicatesthatProgrammingProblems P-10
a process id of value i is available and a value of 1 indicates that the
processidiscurrentlyinuse.
ImplementthefollowingAPIforobtainingandreleasingapid:
• int allocate map(void)—Creates and initializes a data struc-
tureforrepresentingpids;returns−1ifunsuccessful,1ifsuccessful
• int allocate pid(void)—Allocates and returns a pid; returns
−1ifunabletoallocateapid(allpidsareinuse)
• void release pid(int pid)—Releasesapid
This programmingproblemwillbemodifiedlateroninChapter4and
inChapter6.
3.21 TheCollatzconjectureconcernswhathappenswhenwetakeanyposi-
tiveintegernandapplythefollowingalgorithm:
n∕2, ifniseven
n=
{ 3×n+1, ifnisodd
The conjecture states that when this algorithm is continually applied,
allpositiveintegerswilleventuallyreach1.Forexample,ifn = 35,the
sequenceis
35,106,53,160,80,40,20,10,5,16,8,4,2,1
Write a C program using the fork() system call that generates this
sequence in the child process. The starting number will be provided
from the command line. For example, if 8 is passed as a parameter on
the command line, the child process will output 8,4,2,1. Because the
parentand childprocesseshave theirown copiesofthe data, itwill be
necessaryforthechildtooutputthesequence.Havetheparentinvoke
the wait() call to wait for the child process to complete before exiting
theprogram.Performnecessaryerrorcheckingtoensurethatapositive
integerispassedonthecommandline.
3.22 In Exercise 3.21, the child process must output the sequence of num-
bers generated from the algorithm specified by the Collatz conjecture
becausetheparentandchildhavetheirowncopiesofthedata.Another
approach to designing this program is to establish a shared-memory
object between the parent and child processes. This technique allows
the child to write the contents of the sequence to the shared-memory
object. The parent can then output the sequence when the child com-
pletes.Becausethememoryisshared,anychangesthechildmakeswill
bereflectedintheparentprocessaswell.
This program will be structured using POSIX shared memory as
describedinSection3.7.1.Theparentprocesswillprogressthroughthe
followingsteps:
a. Establish the shared-memory object (shm open(), ftruncate(),
andmmap()).P-11 Chapter3 Processes
b. Createthechildprocessandwaitforittoterminate.
c. Outputthecontentsofsharedmemory.
d. Removetheshared-memoryobject.
One area of concern with cooperating processes involves synchro-
nizationissues.Inthisexercise,theparentandchildprocessesmustbe
coordinated so that the parent does not output the sequence until the
childfinishesexecution.Thesetwoprocesseswillbesynchronizedusing
the wait() system call: the parent process will invoke wait(), which
willsuspendituntilthechildprocessexits.
3.23 Section3.8.1describescertainportnumbersasbeingwellknown—that
is, they providestandard services. Port 17 is known as the quote-of-the-
day service. When a client connects to port 17 on a server, the server
respondswithaquoteforthatday.
ModifythedateservershowninFigure3.27sothatitdeliversaquote
ofthedayratherthanthecurrentdate.Thequotesshouldbeprintable
ASCIIcharactersandshouldcontainfewerthan512characters,although
multiple lines are allowed. Since these well-known ports are reserved
andthereforeunavailable,haveyourserverlistentoport6017.Thedate
client shown in Figure 3.28 can be used to read the quotes returned by
yourserver.
3.24 Ahaikuisathree-linepoeminwhichthefirstlinecontainsfivesyllables,
thesecondlinecontainssevensyllables,andthethirdlinecontainsfive
syllables. Write a haiku server that listens to port 5575. When a client
connects to this port, the server responds with a haiku. The date client
shown in Figure 3.28 can be used to read the quotes returned by your
haikuserver.
3.25 Anechoserverechoesbackwhateveritreceivesfromaclient.Forexam-
ple,ifaclientsendstheserverthestringHello there!,theserverwill
respondwithHello there!
Write an echo server using the Java networking API described in
Section 3.8.1. This server will wait for a client connection using the
accept()method.Whenaclientconnectionisreceived,theserverwill
loop,performingthefollowingsteps:
• Readdatafromthesocketintoabuffer.
• Writethecontentsofthebufferbacktotheclient.
The serverwillbreak outofthe loop only whenithas determinedthat
theclienthasclosedtheconnection.
The date server of Figure 3.27 uses the java.io.BufferedReader
class. BufferedReader extends the java.io.Reader class, which is
used for reading character streams. However, the echo server cannot
guaranteethatitwillreadcharactersfromclients;itmayreceivebinary
dataaswell.Theclassjava.io.InputStreamdealswithdataatthebyte
levelratherthanthecharacterlevel.Thus,yourechoservermustusean
object that extends java.io.InputStream.The read() method in theProgrammingProblems P-12
java.io.InputStream class returns −1 when the client has closed its
endofthesocketconnection.
3.26 Design a program using ordinary pipes in which one process sends a
string message to a second process, and the second process reverses
the case of each character in the message and sends it back to the first
process. For example, if the first process sends the message Hi There,
the second process will return hI tHERE. This will require using two
pipes,oneforsendingtheoriginalmessagefromthefirsttothesecond
processandtheotherforsendingthemodifiedmessagefromthesecond
to the first process. You can write this program using either UNIX or
Windowspipes.
3.27 Design a file-copying program named filecopy.c using ordinary
pipes.Thisprogramwillbepassedtwoparameters:thenameofthefile
tobecopiedandthenameofthedestinationfile.Theprogramwillthen
createanordinarypipeandwritethecontentsofthefiletobecopiedto
thepipe.Thechildprocesswillreadthisfilefromthepipeandwriteit
tothedestinationfile.Forexample,ifweinvoketheprogramasfollows:
./filecopy input.txt copy.txt
thefileinput.txtwillbewrittentothepipe.Thechildprocesswillread
thecontentsofthisfileandwriteittothedestinationfilecopy.txt.You
maywritethisprogramusingeitherUNIXorWindowspipes.
Programming Projects
Project 1—UNIX Shell
This project consists of designing a C program to serve as a shell interface
that accepts user commands and then executes each command in a separate
process. Your implementation will support input and output redirection, as
well as pipes as a form of IPC between a pair of commands. Completing this
project will involve using the UNIX fork(), exec(), wait(), dup2(), and
pipe() system calls and can be completed on any Linux, UNIX, or macOS
system.
I.Overview
A shell interface gives the user a prompt, after which the next command
is entered. The example below illustrates the prompt osh> and the user’s
next command: cat prog.c. (This command displays the file prog.c on the
terminalusingtheUNIXcatcommand.)
osh>cat prog.cP-13 Chapter3 Processes
Onetechniqueforimplementingashellinterfaceistohavetheparentprocess
firstreadwhattheuserentersonthecommandline(inthiscase,cat prog.c)
and then create a separate child process that performs the command. Unless
otherwisespecified,theparentprocesswaitsforthechildtoexitbeforecontin-
uing.Thisissimilarinfunctionalitytothenewprocesscreationillustratedin
Figure3.9. However,UNIX shells typicallyalso allowthe child process to run
inthebackground,orconcurrently.Toaccomplishthis,weaddanampersand
(&)attheendofthecommand.Thus,ifwerewritetheabovecommandas
osh>cat prog.c &
theparentandchildprocesseswillrunconcurrently.
Theseparatechildprocessiscreatedusingthefork()systemcall,andthe
user’scommandisexecutedusingoneofthesystemcallsintheexec()family
(asdescribedinSection3.3.1).
ACprogramthatprovidesthegeneraloperationsofacommand-lineshell
is supplied in Figure 3.36. The main() function presents the prompt osh->
andoutlinesthestepstobetakenafterinputfromtheuserhasbeenread.The
main() function continually loops as long as should run equals 1; when the
user enters exit at the prompt, your program will set should run to 0 and
terminate.
#include <stdio.h>
#include <unistd.h>
#define MAX LINE 80 /* The maximum length command */
int main(void)
{
char *args[MAX LINE/2 + 1]; /* command line arguments */
int should run = 1; /* flag to determine when to exit program */
while (should run) {
printf("osh>");
fflush(stdout);
/**
* After reading user input, the steps are:
* (1) fork a child process using fork()
* (2) the child process will invoke execvp()
* (3) parent will invoke wait() unless command included &
*/
}
return 0;
}
Figure3.36 Outlineofsimpleshell.ProgrammingProjects P-14
Thisprojectisorganizedintoseveralparts:
1. Creatingthechildprocessandexecutingthecommandinthechild
2. Providingahistoryfeature
3. Addingsupportofinputandoutputredirection
4. Allowingtheparentandchildprocessestocommunicateviaapipe
II.ExecutingCommandin a Child Process
The first task is to modify the main() function in Figure 3.36 so that a child
process is forked and executes the command specified by the user. This will
requireparsingwhattheuserhasenteredintoseparatetokensandstoringthe
tokensinanarrayofcharacterstrings(argsinFigure3.36).Forexample,ifthe
userentersthecommandps -aelattheosh>prompt,thevaluesstoredinthe
argsarrayare:
args[0] = "ps"
args[1] = "-ael"
args[2] = NULL
Thisargsarraywillbepassedtotheexecvp()function,whichhasthefollow-
ingprototype:
execvp(char *command, char *params[])
Here,commandrepresentsthecommandtobeperformedandparamsstoresthe
parameters to this command. For this project, the execvp() function should
be invoked as execvp(args[0], args). Be sure to check whether the user
included & to determine whether or not the parent process is to wait for the
childtoexit.
III.CreatingaHistory Feature
The next task is to modify the shell interface program so that it provides a
historyfeaturetoallowausertoexecutethemostrecentcommandbyentering
!!.Forexample,ifauserentersthecommandls -l,shecanthenexecutethat
commandagainbyentering!!attheprompt.Anycommandexecutedinthis
fashionshouldbeechoedontheuser’sscreen,andthecommandshouldalso
beplacedinthehistorybufferasthenextcommand.
Yourprogramshouldalsomanagebasicerrorhandling.Ifthereisnorecent
commandinthehistory,entering!!shouldresultinamessage“No commands
in history.”
IV. RedirectingInputandOutput
Your shell should then be modified to support the ‘>’ and ‘<’ redirectionP-15 Chapter3 Processes
operators,where‘>’redirectstheoutputofacommandtoafileand‘<’redirects
theinputtoacommandfromafile.Forexample,ifauserenters
osh>ls > out.txt
theoutputfromthelscommandwillberedirectedtothefileout.txt.Simi-
larly,inputcanberedirectedaswell.Forexample,iftheuserenters
osh>sort < in.txt
thefilein.txtwillserveasinputtothesortcommand.
Managingtheredirectionofbothinputandoutputwillinvolveusingthe
dup2() function, which duplicates an existing file descriptor to another file
descriptor.Forexample,iffdisafiledescriptortothefileout.txt,thecall
dup2(fd, STDOUT FILENO);
duplicatesfdtostandardoutput(theterminal).Thismeansthatanywritesto
standardoutputwillinfactbesenttotheout.txtfile.
Youcanassumethatcommandswillcontaineitheroneinputoroneoutput
redirection and will not contain both. In other words, you do not have to be
concernedwithcommandsequencessuchassort < in.txt > out.txt.
V. Communicationvia aPipe
Thefinalmodificationtoyourshellistoallowtheoutputofonecommandto
serve as input to another using a pipe. For example, the following command
sequence
osh>ls -l | less
has the output of the command ls -l serve as the input to the less com-
mand. Both the ls and less commands will run as separate processes and
will communicate using the UNIX pipe() function describedin Section3.7.4.
Perhapstheeasiestwaytocreatetheseseparateprocessesistohavetheparent
processcreatethechildprocess(whichwillexecutels -l).Thischildwillalso
createanotherchildprocess(whichwillexecuteless)andwillestablishapipe
betweenitselfandthechildprocessitcreates.Implementingpipefunctionality
willalsorequireusingthedup2()functionasdescribedintheprevioussection.
Finally, although several commands can be chained together using multiple
pipes, you can assume that commands will contain only one pipe character
andwillnotbecombinedwithanyredirectionoperators.
Project 2 —Linux Kernel Module for Task Information
In this project, you will write a Linux kernel module that uses the /proc file
systemfordisplayingatask’sinformationbasedonitsprocessidentifiervalue
pid.Beforebeginningthisproject,besureyouhavecompletedtheLinuxkernel
module programming project in Chapter 2, which involves creating an entry
inthe/procfilesystem.ThisprojectwillinvolvewritingaprocessidentifiertoProgrammingProjects P-16
thefile/proc/pid.Onceapidhasbeenwrittentothe/procfile,subsequent
readsfrom/proc/pidwillreport(1)thecommandthetaskisrunning,(2)the
valueofthetask’spid,and(3)thecurrentstateofthetask.Anexampleofhow
yourkernelmodulewillbeaccessedonceloadedintothesystemisasfollows:
echo "1395" > /proc/pid
cat /proc/pid
command = [bash] pid = [1395] state = [1]
Theechocommandwritesthecharacters "1395"tothe/proc/pidfile.Your
kernel module will read this value and store its integer equivalent as it rep-
resentsa process identifier.The cat command reads from /proc/pid, where
yourkernelmodulewillretrievethethreefieldsfromthetask structassoci-
atedwiththetaskwhosepidvalueis1395.
ssize t proc write(struct file *file, char user *usr buf,
size t count, loff t *pos)
{
int rv = 0;
char *k mem;
/* allocate kernel memory */
k mem = kmalloc(count, GFP KERNEL);
/* copies user space usr buf to kernel memory */
copy from user(k mem, usr buf, count);
printk(KERN INFO "%s∖n", k mem);
/* return kernel memory */
kfree(k mem);
return count;
}
Figure3.37 Theproc write()function.
I.Writing to the/procFile System
In the kernel module project in Chapter 2, you learned how to read from the
/proc file system. We now cover how to write to /proc. Setting the field
.writeinstruct file operationsto
.write = proc write
causes the proc write() function of Figure 3.37 to be called when a write
operationismadeto/proc/pidP-17 Chapter3 Processes
The kmalloc() function is the kernel equivalent of the user-level mal-
loc() function for allocating memory, except that kernel memory is being
allocated. The GFP KERNEL flag indicates routine kernel memory allocation.
The copy from user() function copies the contents of usr buf (which con-
tains what has been written to /proc/pid) to the recently allocated kernel
memory.Yourkernelmodulewillhavetoobtaintheintegerequivalentofthis
valueusingthekernelfunctionkstrtol(),whichhasthesignature
int kstrtol(const char *str, unsigned int base, long *res)
Thisstoresthecharacter equivalentof str,which isexpressedas abaseinto
res.
Finally, note that we return memory that was previously allocated with
kmalloc()backtothekernelwiththecalltokfree().Carefulmemoryman-
agement—which includes releasing memory to prevent memory leaks—is
crucialwhendevelopingkernel-levelcode.
II.Readingfromthe/procFile System
Once the process identifier has been stored, any reads from /proc/pid
will return the name of the command, its process identifier, and its state.
As illustrated in Section 3.1, the PCB in Linux is represented by the
structure task struct, which is found in the <linux/sched.h> include
file.Givenaprocessidentifier,thefunctionpid task()returnstheassociated
task struct.Thesignatureofthisfunctionappearsasfollows:
struct task struct pid task(struct pid *pid,
enum pid type type)
The kernel function find vpid(int pid) can be used to obtain the struct
pid,andPIDTYPE PIDcanbeusedasthepid type.
For a validpid inthe system,pid task willreturnitstask struct.You
canthendisplaythevaluesofthecommand,pid,andstate.(Youwillprobably
havetoreadthroughthetask structstructurein<linux/sched.h>toobtain
thenamesofthesefields.)
Ifpid task()isnotpassedavalidpid,itreturnsNULL.Besuretoperform
appropriateerrorcheckingtocheckforthiscondition.Ifthissituationoccurs,
the kernel module function associated with reading from /proc/pid should
return0.
In the source code download, we give the C program pid.c, which pro-
videssomeofthebasicbuildingblocksforbeginningthisproject.
Project 3—Linux Kernel Module for Listing Tasks
In this project, you will write a kernel module that lists all current tasks in a
Linuxsystem.Youwilliteratethroughthetasksbothlinearlyanddepthfirst.
PartI—IteratingoverTasksLinearly
In the Linux kernel, the for each process() macro easily allows iteration
overallcurrenttasksinthesystem:ProgrammingProjects P-18
#include <linux/sched.h>
struct task struct *task;
for each process(task){
/* on each iteration task points to the next task */
}
Thevariousfieldsintask structcanthenbedisplayedastheprogramloops
throughthefor each process()macro.
Assignment
Designakernelmodulethatiteratesthroughalltasksinthesystemusingthe
for each process() macro. In particular, output the task command, state,
and process id of each task. (You will probably have to read through the
task struct structure in <linux/sched.h> to obtain the names of these
fields.)Writethiscodeinthemoduleentrypointsothatitscontentswillappear
in the kernel log buffer, which can be viewed using the dmesg command. To
verifythatyourcodeisworkingcorrectly,comparethecontentsofthekernel
log buffer with the output of the following command, which lists all tasks in
thesystem:
ps -el
Thetwovaluesshouldbeverysimilar.Becausetasksaredynamic,however,it
ispossiblethatafewtasksmayappearinonelistingbutnottheother.
PartII—IteratingoverTaskswith aDepth-FirstSearchTree
Thesecondportionofthisprojectinvolvesiteratingoveralltasksinthesystem
using a depth-first search (DFS) tree. (As an example: the DFS iteration of the
processesinFigure3.7is1,8415,8416,9298,9204,2808,3028,3610,4005.)
Linux maintains its process tree as a series of lists. Examining the
task structin<linux/sched.h>,weseetwostruct list headobjects:
children
and
sibling
Theseobjectsarepointerstoalistofthetask’schildren,aswellasitssiblings.
Linuxalsomaintainsareferencetotheinitialtaskinthesystem — init task
— which is of type task struct. Using this information as well as macro
operationsonlists,wecaniterateoverthechildrenofinit taskasfollows:
struct task struct *task;
struct list head *list;P-19 Chapter3 Processes
list for each(list, &init task->children) {
task = list entry(list, struct task struct, sibling);
/* task points to the next child in the list */
}
The list for each() macro is passed two parameters, both of type struct
list head:
• Apointertotheheadofthelisttobetraversed
• Apointertotheheadnodeofthelisttobetraversed
At each iteration of list for each(), the first parameter is set to the list
structure of the next child. We then use this value to obtain each structure in
thelistusingthelist entry()macro.
Assignment
Beginningfrominit tasktask,designakernelmodulethat iteratesoverall
tasksinthesystemusingaDFStree.Justasinthefirstpartofthisproject,output
thename,state,andpidofeachtask.Performthisiterationinthekernelentry
modulesothatitsoutputappearsinthekernellogbuffer.
If you output all tasks in the system, you may see many more tasks than
appear with the ps -ael command. This is because some threads appear as
children but do not show up as ordinary processes. Therefore, to check the
outputoftheDFStree,usethecommand
ps -eLf
Thiscommandlistsalltasks—includingthreads—inthesystem.Toverifythat
you have indeed performed an appropriate DFS iteration, you will have to
examinetherelationshipsamongthevarioustasksoutputbythepscommand.
Project 4—Kernel Data Structures
In Section 1.9, we covered various data structures that are common in oper-
ating systems. The Linux kernel provides several of these structures. Here,
we explore using the circular, doubly linked list that is available to kernel
developers.MuchofwhatwediscussisavailableintheLinuxsourcecode—
in this instance, the include file <linux/list.h>—and we recommend that
youexaminethisfileasyouproceedthroughthefollowingsteps.
Initially,youmust define a structcontaining the elementsthat aretobe
insertedinthelinkedlist.ThefollowingCstructdefinesacolorasamixture
ofred,blue,andgreen:
struct color {
int red;
int blue;
int green;ProgrammingProjects P-20
struct list head list;
};
Notice the member struct list head list. The list head structure is
definedintheincludefile<linux/types.h>,anditsintentionistoembedthe
linkedlistwithinthenodesthatcomprisethelist.Thislist headstructureis
quitesimple—itmerelyholdstwomembers,nextandprev,thatpointtothe
next and previous entries in the list. By embedding the linked list within the
structure,Linuxmakesitpossibletomanagethedatastructurewithaseriesof
macrofunctions.
I.InsertingElementsinto theLinkedList
Wecandeclarealist headobject,whichweuseasareferencetotheheadof
thelistbyusingtheLIST HEAD()macro:
static LIST HEAD(color list);
This macro defines and initializes the variable color list, which is of type
struct list head.
Wecreateandinitializeinstancesofstruct colorasfollows:
struct color *violet;
violet = kmalloc(sizeof(*violet), GFP KERNEL);
violet->red = 138;
violet->blue = 43;
violet->green = 226;
INIT LIST HEAD(&violet->list);
The kmalloc() function is the kernel equivalent of the user-level malloc()
functionforallocatingmemory,exceptthatkernelmemoryisbeingallocated.
The GFP KERNEL flag indicates routine kernel memory allocation. The macro
INIT LIST HEAD()initializesthelistmemberinstruct color.Wecanthen
addthisinstancetotheendofthelinkedlistusingthelist add tail()macro:
list add tail(&violet->list, &color list);
II.TraversingtheLinkedList
Traversing the list involves using the list for each entry() macro, which
acceptsthreeparameters:
• Apointertothestructurebeingiteratedover
• Apointertotheheadofthelistbeingiteratedover
• Thenameofthevariablecontainingthelist headstructure
Thefollowingcodeillustratesthismacro:P-21 Chapter3 Processes
struct color *ptr;
list for each entry(ptr, &color list, list) {
/* on each iteration ptr points */
/* to the next struct color */
}
III.RemovingElementsfromtheLinkedList
Removingelementsfromthelistinvolvesusingthelist del()macro,which
ispassedapointertostruct list head:
list del(struct list head *element);
This removes element from the list while maintaining the structure of the
remainderofthelist.
Perhaps the simplest approach for removing all elements from a
linked list is to remove each element as you traverse the list. The macro
list for each entry safe() behaves much like list for each entry()
exceptthatitispassedanadditionalargumentthatmaintainsthevalueofthe
next pointer of the item being deleted. (This is necessary for preserving the
structureofthelist.)Thefollowingcodeexampleillustratesthismacro:
struct color *ptr, *next;
list for each entry safe(ptr,next,&color list,list) {
/* on each iteration ptr points */
/* to the next struct color */
list del(&ptr->list);
kfree(ptr);
}
Noticethatafterdeletingeachelement,wereturnmemorythatwaspreviously
allocatedwithkmalloc()backtothekernelwiththecalltokfree().
PartI—Assignment
In the module entry point, create a linked list containing four struct color
elements. Traverse the linked list and output its contents to the kernel log
buffer. Invoke the dmesg command to ensure that the list is properly con-
structedoncethekernelmodulehasbeenloaded.
Inthemoduleexitpoint,deletetheelementsfromthelinkedlistandreturn
thefreememorybacktothekernel.Again,invokethedmesgcommandtocheck
thatthelisthasbeenremovedoncethekernelmodulehasbeenunloaded.
PartII—ParameterPassing
Thisportionoftheprojectwillinvolvepassingaparametertoakernelmodule.
ThemodulewillusethisparameterasaninitialvalueandgeneratetheCollatz
sequenceasdescribedinExercise3.21.ProgrammingProjects P-22
PassingaParametertoaKernelModule
Parametersmaybepassedtokernelmoduleswhentheyareloaded.Forexam-
ple,ifthenameofthekernelmoduleiscollatz,wecanpasstheinitialvalue
of15tothekernelparameterstartasfollows:
sudo insmod collatz.ko start=15
Withinthekernelmodule,wedeclarestartasaparameterusingthefollowing
code:
#include<linux/moduleparam.h>
static int start = 25;
module param(start, int, 0);
The module param() macro is used to establish variables as parameters to
kernel modules. module param() is provided three arguments: (1) the name
oftheparameter,(2)itstype,and(3)filepermissions.Sincewearenotusinga
filesystemforaccessingtheparameter,wearenotconcernedwithpermissions
and use a default value of 0. Note that the name of the parameter used with
theinsmodcommandmustmatchthenameoftheassociatedkernelparameter.
Finally,ifwedonotprovideavaluetothemoduleparameterduringloading
withinsmod,thedefaultvalue(whichinthiscaseis25)isused.
PartII—Assignment
Design a kernel module named collatz that is passed an initial value as a
moduleparameter.Yourmodulewillthengenerateandstorethesequencein
a kernel linked list when the module is loaded. Once the sequence has been
stored,yourmodulewilltraversethelistandoutputitscontentstothekernel
log buffer. Use the dmesg command to ensure that the sequence is properly
generatedoncethemodulehasbeenloaded.
Inthemoduleexitpoint,deletethecontentsofthelistandreturnthefree
memory back to the kernel. Again, use dmesg to check that the list has been
removedoncethekernelmodulehasbeenunloaded.4
CHAPTER
Threads &
Concurrency
The process model introduced in Chapter 3 assumed that a process was an
executingprogramwithasinglethreadofcontrol.Virtuallyallmodernoperat-
ingsystems,however,providefeaturesenablingaprocesstocontainmultiple
threadsofcontrol.Identifyingopportunitiesforparallelismthroughtheuseof
threadsisbecomingincreasinglyimportantformodernmulticoresystemsthat
providemultipleCPUs.
Inthischapter,weintroducemanyconcepts,aswellaschallenges,associ-
atedwithmultithreadedcomputersystems,includingadiscussionoftheAPIs
forthePthreads,Windows,andJavathreadlibraries.Additionally,weexplore
several new features that abstract the concept of creating threads, allowing
developers to focus on identifying opportunities for parallelism and letting
language features and API frameworks manage the details of thread creation
andmanagement.Welookatanumberofissuesrelatedtomultithreadedpro-
gramminganditseffectonthedesignofoperatingsystems.Finally,weexplore
howtheWindowsandLinuxoperatingsystemssupportthreadsatthekernel
level.
CHAPTER OBJECTIVES
• Identify the basic components of a thread, and contrast threads and
processes.
• Describethemajorbenefitsandsignificantchallengesofdesigningmulti-
threadedprocesses.
• Illustratedifferentapproachestoimplicitthreading,includingthreadpools,
fork-join,andGrandCentralDispatch.
• Describe how the Windows and Linux operating systems represent
threads.
• DesignmultithreadedapplicationsusingthePthreads,Java,andWindows
threadingAPIs.
159160 Chapter4 Threads&Concurrency
4.1 Overview
AthreadisabasicunitofCPUutilization;itcomprisesathreadID,aprogram
counter(PC),aregisterset,andastack.Itshareswithotherthreadsbelonging
tothesameprocessitscodesection,datasection,andotheroperating-system
resources, such as open files and signals. A traditional process has a single
thread of control. If a process has multiple threads of control, it can perform
more than one task at a time. Figure 4.1 illustrates the difference between a
traditionalsingle-threadedprocessandamultithreadedprocess.
4.1.1 Motivation
Mostsoftwareapplicationsthatrunonmoderncomputersandmobiledevices
aremultithreaded.Anapplicationtypicallyisimplementedasaseparatepro-
cess with several threads of control. Below we highlight a few examples of
multithreadedapplications:
• Anapplicationthatcreatesphotothumbnails fromacollectionofimages
may use a separate thread to generate a thumbnail from each separate
image.
• Awebbrowsermighthaveonethreaddisplayimagesortextwhileanother
threadretrievesdatafromthenetwork.
• A word processor may have a thread for displaying graphics, another
thread for responding to keystrokesfrom the user, and a third thread for
performingspellingandgrammarcheckinginthebackground.
code data files code data files
registers PC stack registers registers registers
stack stack stackk
PC PC PC
thread
thread
single-threaded process multithreaded process
Figure4.1 Single-threadedandmultithreadedprocesses.4.1 Overview 161
Applicationscanalsobedesignedtoleverageprocessingcapabilitiesonmul-
ticore systems. Such applications can perform several CPU-intensive tasks in
parallelacrossthemultiplecomputingcores.
Incertainsituations,asingleapplicationmayberequiredtoperformsev-
eral similar tasks. For example, a web server accepts client requests for web
pages,images,sound,andsoforth.Abusywebservermayhaveseveral(per-
hapsthousandsof)clientsconcurrentlyaccessingit.Ifthewebserverranasa
traditionalsingle-threadedprocess,itwouldbeabletoserviceonlyoneclient
atatime,andaclientmighthavetowaitaverylongtimeforitsrequesttobe
serviced.
One solution is to have the server run as a single process that accepts
requests. When the server receives a request, it creates a separate process
to service that request. In fact, this process-creation method was in common
use before threads became popular. Process creation is time consuming and
resourceintensive,however.Ifthenewprocesswillperformthesametasksas
theexistingprocess,whyincurallthatoverhead?Itisgenerallymoreefficient
touseoneprocessthatcontainsmultiplethreads.Iftheweb-serverprocessis
multithreaded, the server will create a separate thread that listens for client
requests. When a request is made, rather than creating another process, the
server creates a new thread to service the request and resumes listening for
additionalrequests.ThisisillustratedinFigure4.2.
Most operating system kernels are also typically multithreaded. As an
example, during system boot time on Linux systems, several kernel threads
are created. Each thread performs a specific task, such as managing devices,
memory management, or interrupt handling. The command ps -ef can be
usedtodisplaythekernelthreadsonarunningLinuxsystem.Examiningthe
outputofthiscommandwillshowthekernelthreadkthreadd(withpid=2),
whichservesastheparentofallotherkernelthreads.
Manyapplicationscanalsotakeadvantageofmultiplethreads,including
basicsorting,trees,andgraphalgorithms.Inaddition,programmerswhomust
solve contemporary CPU-intensive problems in data mining, graphics, and
artificialintelligencecanleveragethepowerofmodernmulticoresystemsby
designingsolutionsthatruninparallel.
(2) create new
(1) request thread to service
the request
client server thread
(3) resume listening
for additional
client requests
Figure4.2 Multithreadedserverarchitecture.162 Chapter4 Threads&Concurrency
4.1.2 Benefits
The benefits of multithreaded programming can be broken down into four
majorcategories:
1. Responsiveness. Multithreadinganinteractiveapplicationmayallowa
program to continue running even if part of it is blocked or is perform-
ing a lengthy operation, thereby increasing responsiveness to the user.
Thisqualityisespeciallyusefulindesigninguserinterfaces.Forinstance,
consider what happens when a user clicks a button that results in the
performance of a time-consuming operation. A single-threaded appli-
cation would be unresponsive to the user until the operation had been
completed.Incontrast,ifthetime-consumingoperationisperformedin
a separate, asynchronous thread, the application remains responsive to
theuser.
2. Resourcesharing.Processescanshareresourcesonlythroughtechniques
such as shared memory and message passing. Such techniques must
be explicitly arranged by the programmer. However, threads share the
memoryandtheresourcesoftheprocesstowhichtheybelongbydefault.
The benefit of sharing code and data is that it allows an application to
haveseveraldifferentthreadsofactivitywithinthesameaddressspace.
3. Economy. Allocating memory and resources for process creation is
costly. Because threads share the resources of the process to which they
belong, it is more economical to create and context-switch threads.
Empirically gauging the difference in overhead can be difficult, but in
general thread creation consumes less time and memory than process
creation. Additionally, context switching is typically faster between
threadsthanbetweenprocesses.
4. Scalability.Thebenefitsofmultithreadingcanbeevengreaterinamul-
tiprocessor architecture, where threads may be running in parallel on
different processing cores. A single-threaded process can run on only
oneprocessor,regardlesshowmany areavailable.Weexplorethisissue
furtherinthefollowingsection.
4.2 Multicore Programming
Earlier in the history of computer design, in response to the need for more
computingperformance,single-CPUsystemsevolvedintomulti-CPUsystems.
A later, yet similar, trend in system design is to place multiple computing
cores on a single processing chip where each core appears as a separate CPU
totheoperatingsystem(Section1.3.2).Werefertosuchsystemsasmulticore,
and multithreaded programming provides a mechanism for more efficient
use of these multiple computing cores and improved concurrency. Consider
an application with four threads. On a system with a single computing core,
concurrencymerelymeansthattheexecutionofthethreadswillbeinterleaved
overtime(Figure4.3),becausetheprocessingcoreiscapableofexecutingonly
one threadat a time.On asystem withmultiplecores, however,concurrency4.2 MulticoreProgramming 163
single core T 1 T 2 T 3 T 4 T 1 T 2 T 3 T 4 T 1 ...
time
Figure4.3 Concurrentexecutiononasingle-coresystem.
means that somethreadscan runinparallel,because the systemcan assigna
separatethreadtoeachcore(Figure4.4).
Noticethedistinctionbetweenconcurrencyandparallelisminthisdiscus-
sion.Aconcurrentsystemsupportsmorethanonetaskbyallowingallthetasks
tomakeprogress.Incontrast,aparallelsystemcanperformmorethanonetask
simultaneously. Thus, it is possible to have concurrency without parallelism.
Before the advent of multiprocessor and multicore architectures, most com-
putersystemshadonlyasingleprocessor,andCPUschedulersweredesigned
toprovidetheillusionofparallelismbyrapidlyswitchingbetweenprocesses,
therebyallowingeachprocesstomakeprogress.Suchprocesseswererunning
concurrently,butnotinparallel.
4.2.1 Programming Challenges
The trend toward multicore systems continues to place pressure on system
designers and application programmers to make better use of the multiple
computingcores.Designersofoperatingsystemsmustwriteschedulingalgo-
rithmsthatusemultipleprocessingcorestoallowtheparallelexecutionshown
inFigure4.4.Forapplicationprogrammers,thechallengeistomodifyexisting
programsaswellasdesignnewprogramsthataremultithreaded.
In general, five areas present challenges in programming for multicore
systems:
1. Identifying tasks. This involves examining applications to find areas
that can be divided into separate, concurrent tasks. Ideally, tasks are
independent of one another and thus can run in parallel on individual
cores.
2. Balance. While identifying tasks that can run in parallel, programmers
must also ensure that the tasks perform equal work of equal value. In
some instances, a certain task may not contribute as much value to the
overallprocessasothertasks.Usingaseparateexecutioncoretorunthat
taskmaynotbeworththecost.
core 1 T 1 T 3 T 1 T 3 T 1 ...
core 2 T T T T T
2 4 2 4 2 ...
time
Figure4.4 Parallelexecutiononamulticoresystem.164 Chapter4 Threads&Concurrency
AMDAHL’SLAW
Amdahl’sLawisaformulathatidentifiespotentialperformancegainsfrom
adding additional computing cores to an application that has both serial
(nonparallel)andparallelcomponents.If Sis theportionofthe application
that must be performed serially on a system with N processing cores, the
formulaappearsasfollows:
1
speedup≤
S+
(1−S)
N
Asanexample,assumewehaveanapplicationthatis75percentparalleland
25percentserial.Ifwerunthisapplicationonasystemwithtwoprocessing
cores, we can get a speedup of 1.6 times. If we add two additional cores
(for a total of four), the speedup is 2.28 times. Below is a graph illustrating
Amdahl’sLawinseveraldifferentscenarios.
16
14
12
10
8
6
4
2
0
0 2 4 6 8 10 12 14 16
pudeepS
Ideal Speedup
S = 0.05
S = 0.10
S = 0.50
Number of Processing Cores
One interesting fact about Amdahl’s Law is that as N approaches infinity,
the speedup converges to 1∕S. For example, if 50 percent of an application
is performed serially, the maximum speedup is 2.0 times, regardless of the
numberofprocessingcoresweadd.Thisisthefundamentalprinciplebehind
Amdahl’s Law: the serial portion of an application can have a dispropor-
tionate effect on the performancewe gain by adding additional computing
cores.
3. Data splitting. Just as applications are divided into separate tasks, the
data accessed and manipulated by the tasks must be divided to run on
separatecores.
4. Datadependency.Thedataaccessedbythetasksmustbeexaminedfor
dependencies between two or more tasks. When one task depends on
data from another, programmers must ensure that the execution of the
tasksissynchronizedtoaccommodatethedatadependency.Weexamine
suchstrategiesinChapter6.4.2 MulticoreProgramming 165
data
data
parallelism
core0 core1 core2 core3
data
task
parallelism
core0 core1 core2 core3
Figure4.5 Dataandtaskparallelism.
5. Testinganddebugging.Whenaprogramisrunninginparallelonmulti-
plecores,manydifferentexecutionpathsarepossible.Testinganddebug-
ging such concurrent programs is inherently more difficult than testing
anddebuggingsingle-threadedapplications.
Becauseofthesechallenges,manysoftwaredevelopersarguethattheadventof
multicoresystemswillrequireanentirelynewapproachtodesigningsoftware
systemsinthefuture.(Similarly,manycomputerscienceeducatorsbelievethat
software development must be taught with increased emphasis on parallel
programming.)
4.2.2 Types of Parallelism
In general, there are two types of parallelism: data parallelism and task par-
allelism. Data parallelism focuses on distributing subsets of the same data
across multiplecomputing cores and performingthe same operationon each
core.Consider,forexample,summingthecontentsofanarrayofsizeN.Ona
single-coresystem,onethreadwouldsimplysumtheelements[0] ...[N−1].
On a dual-core system, however, thread A, running on core 0, could sum the
elements [0] ...[N∕2 − 1] while thread B, running on core 1, could sum the
elements [N∕2] ...[N − 1]. The two threads would be running in parallel on
separatecomputingcores.
Taskparallelism involvesdistributingnotdatabuttasks(threads)across
multiplecomputingcores.Eachthreadisperformingauniqueoperation.Dif-
ferentthreadsmaybeoperatingonthesamedata,ortheymaybeoperatingon
differentdata.Consideragainourexampleabove.Incontrasttothatsituation,
an example of task parallelism might involve two threads, each performing
a unique statistical operation on the array of elements. The threads again are
operating in parallel on separate computing cores, but each is performing a
uniqueoperation.
Fundamentally, then, data parallelism involves the distribution of data
across multiple cores, and task parallelism involves the distribution of tasks
across multiple cores, as shown in Figure 4.5. However, data and task paral-166 Chapter4 Threads&Concurrency
user threads
user
space
kernel
space
kernel threads
Figure4.6 Userandkernelthreads.
lelismarenotmutuallyexclusive,andanapplicationmayinfactuseahybrid
ofthesetwostrategies.
4.3 Multithreading Models
Ourdiscussionsofarhastreatedthreadsinagenericsense.However,support
forthreadsmaybeprovidedeitherattheuserlevel,foruserthreads,orbythe
kernel, for kernel threads. User threads are supported above the kernel and
are managed without kernel support, whereas kernel threads are supported
and managed directly by the operating system. Virtually all contemporary
operatingsystems—includingWindows,Linux,andmacOS— supportkernel
threads.
Ultimately, a relationship must exist between user threads and kernel
threads, as illustrated in Figure 4.6. In this section, we look at three common
ways of establishing such a relationship: the many-to-one model, the one-to-
onemodel,andthemany-to-manymodel.
4.3.1 Many-to-One Model
The many-to-one model (Figure 4.7) maps many user-level threads to one
kernelthread.Threadmanagementisdonebythethreadlibraryinuserspace,
soitisefficient(wediscussthreadlibrariesinSection4.4).However,theentire
processwillblockifathreadmakesablockingsystemcall.Also,becauseonly
user threads
user
space
kernel
space
kernel threads
Figure4.7 Many-to-onemodel.4.3 MultithreadingModels 167
user threads
user
space
kernel
space
kernel threads
Figure4.8 One-to-onemodel.
onethreadcanaccess thekernelatatime,multiplethreadsareunable torun
in parallel on multicore systems. Green threads—a thread library available
forSolarissystemsandadoptedinearlyversionsofJava—usedthemany-to-
onemodel.However,veryfewsystemscontinue tousethemodelbecauseof
its inability to take advantage of multiple processing cores, which have now
becomestandardonmostcomputersystems.
4.3.2 One-to-One Model
Theone-to-onemodel(Figure4.8)mapseachuserthreadtoakernelthread.It
providesmoreconcurrencythanthemany-to-onemodelbyallowinganother
threadtorunwhenathreadmakesablockingsystemcall.Italsoallowsmul-
tiplethreadstoruninparallelonmultiprocessors.Theonly drawbacktothis
modelisthatcreatingauserthreadrequirescreatingthecorrespondingkernel
thread,andalargenumberofkernelthreadsmayburdentheperformanceof
asystem.Linux,alongwiththefamilyofWindowsoperatingsystems,imple-
menttheone-to-onemodel.
4.3.3 Many-to-Many Model
Themany-to-manymodel(Figure4.9)multiplexesmanyuser-levelthreadsto
a smaller or equal number of kernel threads. The number of kernel threads
may be specific to either a particular application or a particular machine (an
application may be allocated more kernel threads on a system with eight
processingcoresthanasystemwithfourcores).
user threads
user
space
kernel
space
kernel threads
Figure4.9 Many-to-manymodel.168 Chapter4 Threads&Concurrency
user threads
user
space
kernel
space
kernel threads
Figure4.10 Two-levelmodel.
Let’sconsidertheeffectofthisdesignonconcurrency.Whereasthemany-
to-one model allows the developer to create as many user threads as she
wishes,itdoesnotresultinparallelism,becausethekernelcanscheduleonly
onekernelthreadatatime.Theone-to-onemodelallowsgreaterconcurrency,
but the developer has to be careful not to create too many threads within an
application. (In fact, on some systems, she may be limited in the number of
threadsshecancreate.)Themany-to-manymodelsuffersfromneitherofthese
shortcomings: developers can create as many user threads as necessary, and
thecorrespondingkernelthreadscanruninparallelonamultiprocessor.Also,
whenathreadperformsablockingsystemcall,thekernelcanscheduleanother
threadforexecution.
One variation on the many-to-many model still multiplexes many user-
levelthreadstoasmallerorequalnumberofkernelthreadsbutalsoallowsa
user-level thread to be bound to a kernel thread. This variation is sometimes
referredtoasthetwo-levelmodel(Figure4.10).
Althoughthemany-to-many modelappearstobethemostflexibleofthe
modelsdiscussed,inpracticeitisdifficulttoimplement.Inaddition,withan
increasing number of processing cores appearing on most systems, limiting
the number of kernel threads has become less important. As a result, most
operatingsystemsnowusetheone-to-onemodel.However,asweshallseein
Section4.5,somecontemporaryconcurrencylibrarieshavedevelopersidentify
tasksthatarethenmappedtothreadsusingthemany-to-manymodel.
4.4 Thread Libraries
AthreadlibraryprovidestheprogrammerwithanAPIforcreatingandman-
aging threads.Therearetwoprimarywaysofimplementingathreadlibrary.
Thefirstapproachistoprovidealibraryentirelyinuserspacewithnokernel
support. All code and data structures for the library exist in user space. This
meansthatinvokingafunctioninthelibraryresultsinalocalfunctioncallin
userspaceandnotasystemcall.
The second approach is to implement a kernel-level library supported
directly by the operating system. In this case, code and data structures for
thelibraryexistinkernelspace.InvokingafunctionintheAPIforthelibrary
typicallyresultsinasystemcalltothekernel.4.4 ThreadLibraries 169
Threemainthreadlibrariesareinusetoday:POSIXPthreads,Windows,and
Java.Pthreads,thethreadsextensionofthePOSIX standard,maybeprovided
as either a user-level or a kernel-level library. The Windows thread library
is a kernel-level library available on Windows systems. The Java thread API
allowsthreadstobecreatedandmanageddirectlyinJavaprograms.However,
becauseinmostinstancestheJVMisrunningontopofahostoperatingsystem,
theJavathread APIisgenerallyimplementedusingathreadlibraryavailable
onthehostsystem.ThismeansthatonWindowssystems,Javathreadsaretyp-
icallyimplementedusingtheWindowsAPI;UNIX,Linux,andmacOSsystems
typicallyusePthreads.
For POSIX and Windows threading, any data declared globally—that is,
declaredoutsideofanyfunction—aresharedamongallthreadsbelongingto
thesameprocess.BecauseJavahasnoequivalentnotionofglobaldata,access
toshareddatamustbeexplicitlyarrangedbetweenthreads.
In the remainder of this section, we describe basic thread creation using
these three thread libraries. As an illustrative example, we design a multi-
threadedprogramthatperformsthesummationofanon-negativeintegerina
separatethreadusingthewell-knownsummationfunction:
N
sum=∑i
i=1
For example, if N were 5, this function would represent the summation of
integersfrom1to5,whichis15. Eachof thethreeprogramswillberunwith
theupperboundsofthesummationenteredonthecommandline.Thus,ifthe
userenters8,thesummationoftheintegervaluesfrom1to8willbeoutput.
Before we proceed with our examples of thread creation, we introduce
twogeneralstrategiesforcreatingmultiplethreads:asynchronousthreading
and synchronous threading. With asynchronous threading, once the parent
creates a child thread, the parent resumes its execution, so that the parent
and child execute concurrently and independently of one another. Because
the threads are independent, there is typically little data sharing between
them.Asynchronousthreadingisthestrategyusedinthemultithreadedserver
illustrated in Figure 4.2 and is also commonly used for designing responsive
userinterfaces.
Synchronousthreadingoccurswhentheparentthreadcreatesoneormore
childrenandthenmustwaitforallofitschildrentoterminatebeforeitresumes.
Here, the threads created by the parent perform work concurrently, but the
parentcannotcontinueuntilthisworkhasbeencompleted.Onceeachthread
hasfinisheditswork,itterminatesandjoinswithitsparent.Onlyafterallofthe
childrenhavejoinedcantheparentresumeexecution.Typically,synchronous
threading involves significant data sharing among threads. For example, the
parent thread may combine the results calculated by its various children. All
ofthefollowingexamplesusesynchronousthreading.
4.4.1 Pthreads
PthreadsreferstothePOSIXstandard(IEEE1003.1c)defininganAPIforthread
creationandsynchronization.Thisisaspecificationforthreadbehavior,notan
implementation.Operating-systemdesignersmayimplementthespecification170 Chapter4 Threads&Concurrency
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
int sum; /* this data is shared by the thread(s) */
void *runner(void *param); /* threads call this function */
int main(int argc, char *argv[])
{
pthread t tid; /* the thread identifier */
pthread attr t attr; /* set of thread attributes */
/* set the default attributes of the thread */
pthread attr init(&attr);
/* create the thread */
pthread create(&tid, &attr, runner, argv[1]);
/* wait for the thread to exit */
pthread join(tid,NULL);
printf("sum = %d∖n",sum);
}
/* The thread will execute in this function */
void *runner(void *param)
{
int i, upper = atoi(param);
sum = 0;
for (i = 1; i <= upper; i++)
sum += i;
pthread exit(0);
}
Figure4.11 MultithreadedCprogramusingthePthreadsAPI.
in any way they wish. Numerous systems implement the Pthreads specifica-
tion;mostareUNIX-typesystems,includingLinuxandmacOS.AlthoughWin-
dowsdoesn’tsupportPthreadsnatively,somethird-partyimplementationsfor
Windowsareavailable.
TheCprogramshowninFigure4.11demonstratesthebasicPthreadsAPI
for constructing a multithreaded program that calculates the summation of
a non-negative integer in a separate thread. In a Pthreads program, separate
threadsbeginexecutioninaspecifiedfunction.InFigure4.11,thisistherun-
ner()function.Whenthisprogrambegins,asinglethreadofcontrolbeginsin4.4 ThreadLibraries 171
#define NUM THREADS 10
/* an array of threads to be joined upon */
pthread t workers[NUM THREADS];
for (int i = 0; i < NUM THREADS; i++)
pthread join(workers[i], NULL);
Figure4.12 Pthreadcodeforjoiningtenthreads.
main().Aftersomeinitialization,main()createsasecondthreadthatbegins
controlintherunner()function.Boththreadssharetheglobaldatasum.
Let’s look more closely at this program. All Pthreads programs must
includethepthread.hheaderfile.Thestatementpthread t tiddeclaresthe
identifier for the thread we will create. Each thread has a set of attributes,
including stack size and scheduling information. The pthread attr t attr
declaration represents the attributes for the thread. We set the attributes in
the function call pthread attr init(&attr). Because we did not explicitly
set any attributes, we use the default attributes provided. (In Chapter 5, we
discuss some of the scheduling attributes provided by the Pthreads API.) A
separate thread is created with the pthread create() function call. In addi-
tion to passing the thread identifier and the attributes for the thread, we also
passthenameofthefunctionwherethenewthreadwillbeginexecution—in
thiscase,therunner()function.Last,wepasstheintegerparameterthatwas
providedonthecommandline,argv[1].
Atthispoint,theprogramhastwothreads:theinitial(orparent)threadin
main()andthesummation(orchild)threadperformingthesummationoper-
ation in the runner() function. This program follows the thread create/join
strategy,wherebyaftercreatingthesummationthread,theparentthreadwill
waitforittoterminatebycallingthepthread join()function. Thesumma-
tionthreadwillterminatewhenitcallsthefunctionpthread exit().Oncethe
summationthreadhasreturned,theparentthreadwilloutputthevalueofthe
shareddatasum.
This example program creates only a single thread. With the growing
dominanceofmulticoresystems,writingprogramscontainingseveralthreads
has become increasingly common. A simple method for waiting on several
threadsusingthepthread join()functionistoenclosetheoperationwithin
asimpleforloop.Forexample,youcanjoinontenthreadsusingthePthread
codeshowninFigure4.12.
4.4.2 Windows Threads
ThetechniqueforcreatingthreadsusingtheWindowsthreadlibraryissimilar
to the Pthreads technique in several ways. We illustrate the Windows thread
API in the C program shown in Figure 4.13. Notice that we must include the
windows.hheaderfilewhenusingtheWindowsAPI.172 Chapter4 Threads&Concurrency
#include <windows.h>
#include <stdio.h>
DWORD Sum; /* data is shared by the thread(s) */
/* The thread will execute in this function */
DWORD WINAPI Summation(LPVOID Param)
{
DWORD Upper = *(DWORD*)Param;
for (DWORD i = 1; i <= Upper; i++)
Sum += i;
return 0;
}
int main(int argc, char *argv[])
{
DWORD ThreadId;
HANDLE ThreadHandle;
int Param;
Param = atoi(argv[1]);
/* create the thread */
ThreadHandle = CreateThread(
NULL, /* default security attributes */
0, /* default stack size */
Summation, /* thread function */
&Param, /* parameter to thread function */
0, /* default creation flags */
&ThreadId); /* returns the thread identifier */
/* now wait for the thread to finish */
WaitForSingleObject(ThreadHandle,INFINITE);
/* close the thread handle */
CloseHandle(ThreadHandle);
printf("sum = %d∖n",Sum);
}
Figure4.13 MultithreadedCprogramusingtheWindowsAPI.
Just as in the Pthreads version shown in Figure 4.11, data shared by the
separate threads—in this case, Sum—are declared globally (the DWORD data
typeis an unsigned32-bit integer).We alsodefine the Summation()function
thatistobeperformedinaseparatethread.Thisfunctionispassedapointer
to a void, which Windows defines as LPVOID. The thread performing this
function setsthe global data Sum tothe valueof the summationfrom 0 tothe
parameterpassedtoSummation().4.4 ThreadLibraries 173
ThreadsarecreatedintheWindowsAPIusingtheCreateThread()func-
tion, and—just as in Pthreads—a set of attributes for the thread is passed
to this function. These attributes include security information, the size of the
stack,andaflagthatcanbesettoindicateifthethreadistostartinasuspended
state. In this program, we use the default values for these attributes. (The
defaultvaluesdonotinitiallysetthethreadtoasuspendedstateandinstead
make it eligible to be run by the CPU scheduler.) Once the summation thread
iscreated,theparentmustwaitforittocompletebeforeoutputtingthevalue
of Sum, as the value is set by the summation thread. Recall that the Pthread
program (Figure 4.11) had the parent thread wait for the summation thread
usingthepthread join()statement.Weperformtheequivalentofthisinthe
WindowsAPIusingtheWaitForSingleObject()function,which causesthe
creatingthreadtoblockuntilthesummationthreadhasexited.
In situations that require waiting for multiple threads to complete, the
WaitForMultipleObjects() function is used. This function is passed four
parameters:
1. Thenumberofobjectstowaitfor
2. Apointertothearrayofobjects
3. Aflagindicatingwhetherallobjectshavebeensignaled
4. Atimeoutduration(orINFINITE)
For example, if THandles is an array of thread HANDLE objects of size N, the
parentthreadcanwaitforallitschildthreadstocompletewiththisstatement:
WaitForMultipleObjects(N, THandles, TRUE, INFINITE);
4.4.3 Java Threads
ThreadsarethefundamentalmodelofprogramexecutioninaJavaprogram,
andtheJavalanguageanditsAPIprovidearichsetoffeaturesforthecreation
and management of threads. All Java programs comprise at least a single
thread of control—even a simple Java program consisting of only a main()
method runs as a single thread in the JVM. Java threads are available on any
systemthat providesaJVM including Windows, Linux,and macOS. TheJava
threadAPIisavailableforAndroidapplicationsaswell.
TherearetwotechniquesforexplicitlycreatingthreadsinaJavaprogram.
One approach is to create a new class that is derived from the Thread class
andtooverrideitsrun()method.Analternative—andmorecommonlyused
—technique is todefine aclass that implementsthe Runnableinterface.This
interface defines a single abstract method with the signature public void
run(). The code in the run() method of a class that implements Runnable
iswhatexecutesinaseparatethread.Anexampleisshownbelow:
class Task implements Runnable
{
public void run() {
System.out.println("I am a thread.");
}
}174 Chapter4 Threads&Concurrency
LAMBDAEXPRESSIONSINJAVA
BeginningwithVersion1.8ofthelanguage,JavaintroducedLambdaexpres-
sions, which allow a much cleaner syntax for creating threads. Rather than
defining a separate class that implements Runnable, a Lambda expression
canbeusedinstead:
Runnable task = () -> {
System.out.println("I am a thread.");
};
Thread worker = new Thread(task);
worker.start();
Lambdaexpressions—aswellassimilar functionsknownasclosures—are
a prominent feature of functional programming languages and have been
availableinseveralnonfunctionallanguagesaswellincludingPython,C++,
andC#.Asweshallseeinlaterexamplesinthischapter,Lamdbaexpressions
oftenprovideasimplesyntaxfordevelopingparallelapplications.
Thread creation in Java involves creating a Thread object and passing it
an instance of a class that implements Runnable, followed by invoking the
start()methodontheThreadobject.Thisappearsinthefollowingexample:
Thread worker = new Thread(new Task());
worker.start();
Invokingthestart()methodforthenewThreadobjectdoestwothings:
1. ItallocatesmemoryandinitializesanewthreadintheJVM.
2. Itcallstherun()method,makingthethreadeligibletoberunbytheJVM.
(Noteagainthatwenevercalltherun()methoddirectly.Rather,wecall
thestart()method,anditcallstherun()methodonourbehalf.)
Recall that the parent threads in the Pthreads and Windows libraries use
pthread join() and WaitForSingleObject()(respectively)to wait for the
summation threads to finish before proceeding. The join() method in Java
providessimilarfunctionality.(Noticethatjoin()canthrowanInterrupt-
edException,whichwechoosetoignore.)
try {
worker.join();
}
catch (InterruptedException ie) { }
Iftheparentmustwaitforseveralthreadstofinish,thejoin()methodcanbe
enclosedinaforloopsimilartothatshownforPthreadsinFigure4.12.4.4 ThreadLibraries 175
4.4.3.1 JavaExecutorFramework
Javahassupportedthreadcreationusingtheapproachwehavedescribedthus
far since its origins. However, beginning with Version 1.5 and its API, Java
introduced several new concurrency features that provide developers with
muchgreatercontroloverthreadcreationandcommunication.Thesetoolsare
availableinthejava.util.concurrentpackage.
Rather than explicitly creating Thread objects, thread creation is instead
organizedaroundtheExecutorinterface:
public interface Executor
{
void execute(Runnable command);
}
Classesimplementingthisinterfacemustdefinetheexecute()method,which
ispassedaRunnableobject.ForJavadevelopers,thismeansusingtheExecu-
tor rather than creating a separate Thread object and invoking its start()
method.TheExecutorisusedasfollows:
Executor service = new Executor;
service.execute(new Task());
TheExecutorframeworkisbasedontheproducer-consumermodel;tasks
implementingtheRunnableinterfaceareproduced,andthethreadsthatexe-
cute these tasks consume them. The advantage of this approach is that it not
onlydividesthreadcreationfromexecutionbutalsoprovidesamechanismfor
communicationbetweenconcurrenttasks.
Datasharingbetweenthreadsbelongingtothesameprocessoccurseasily
inWindows andPthreads,sinceshareddataaresimplydeclaredglobally.As
a pure object-oriented language, Java has no such notion of global data. We
can pass parameters to a class that implements Runnable, but Java threads
cannotreturnresults.Toaddressthisneed,thejava.util.concurrentpack-
age additionally defines the Callable interface, which behaves similarly to
Runnableexceptthataresultcanbereturned.ResultsreturnedfromCallable
tasks are known as Future objects. Aresult can be retrieved from the get()
method defined in the Future interface. The program shown in Figure 4.14
illustratesthesummationprogramusingtheseJavafeatures.
The Summationclass implementsthe Callableinterface,which specifies
the method V call()—it is the code inthis call()method that is executed
in a separate thread. To execute this code, we create a newSingleThreadEx-
ecutor object (providedas a static method in the Executors class), which is
of type ExecutorService, and pass it a Callable task using its submit()
method.(Theprimarydifferencebetweentheexecute()andsubmit()meth-
ods is that the former returns no result, whereas the latter returns a result as
a Future.) Once we submit the callable task to the thread, we wait for its
resultbycallingtheget()methodoftheFutureobjectitreturns.
Itisquiteeasytonoticeatfirstthatthismodelofthreadcreationappears
morecomplicatedthansimplycreatingathreadandjoiningonitstermination.
However,incurringthismodestdegreeofcomplicationconfersbenefits.Aswe
have seen, using Callable and Future allows for threads to return results.176 Chapter4 Threads&Concurrency
import java.util.concurrent.*;
class Summation implements Callable<Integer>
{
private int upper;
public Summation(int upper) {
this.upper = upper;
}
/* The thread will execute in this method */
public Integer call() {
int sum = 0;
for (int i = 1; i <= upper; i++)
sum += i;
return new Integer(sum);
}
}
public class Driver
{
public static void main(String[] args) {
int upper = Integer.parseInt(args[0]);
ExecutorService pool = Executors.newSingleThreadExecutor();
Future<Integer> result = pool.submit(new Summation(upper));
try {
System.out.println("sum = " + result.get());
} catch (InterruptedException | ExecutionException ie) { }
}
}
Figure4.14 IllustrationofJavaExecutorframeworkAPI.
Additionally, this approach separates the creation of threads from the results
they produce: rather than waiting for a thread to terminate before retrieving
results,theparentinsteadonlywaitsfortheresultstobecomeavailable.Finally,
as we shall see in Section 4.5.1, this framework can be combined with other
featurestocreaterobusttoolsformanagingalargenumberofthreads.
4.5 Implicit Threading
With the continued growth of multicore processing, applications contain-
ing hundreds—or even thousands—of threads are looming on the horizon.
Designing such applications is not a trivial undertaking: programmers must4.5 ImplicitThreading 177
THEJVMANDTHEHOSTOPERATINGSYSTEM
The JVM is typically implemented on top of a host operating system (see
Figure 18.10).Thissetup allows the JVMto hidetheimplementationdetails
of the underlying operating system and to provide a consistent, abstract
environment that allows Java programs to operate on any platform that
supports a JVM. The specification for the JVM does not indicate how Java
threadsaretobemappedtotheunderlyingoperatingsystem,insteadleaving
thatdecision to theparticular implementationofthe JVM.For example,the
Windows operatingsystem uses the one-to-onemodel; therefore,each Java
threadforaJVMrunningonWindowsmapstoakernelthread.Inaddition,
there may be a relationship between the Java thread library and the thread
libraryonthehostoperatingsystem.Forexample,implementationsofaJVM
for the Windows family of operating systems might use the Windows API
whencreatingJavathreads;LinuxandmacOSsystemsmightusethePthreads
API.
addressnotonlythechallengesoutlinedinSection4.2butadditionaldifficul-
tiesaswell.Thesedifficulties,whichrelatetoprogramcorrectness,arecovered
inChapter6andChapter8.
Onewaytoaddressthesedifficultiesandbettersupportthedesignofcon-
current and parallel applications is to transfer the creation and management
ofthreadingfromapplicationdeveloperstocompilersandrun-timelibraries.
This strategy, termedimplicit threading, is an increasingly popular trend. In
thissection,weexplorefouralternativeapproachestodesigningapplications
that can take advantage of multicore processors through implicit threading.
As we shall see, these strategies generally require application developers to
identify tasks—not threads—that can run in parallel. Atask is usually writ-
ten as a function, which the run-time library then maps to a separate thread,
typically using the many-to-many model (Section 4.3.3). The advantage of
this approach is that developers only need to identify parallel tasks, and the
librariesdeterminethespecificdetailsofthreadcreationandmanagement.
4.5.1 Thread Pools
In Section 4.1, we described a multithreaded web server. In this situation,
whenever the server receivesa request, it creates a separate thread to service
therequest.Whereascreatingaseparatethreadiscertainlysuperiortocreating
aseparateprocess,amultithreadedservernonethelesshaspotentialproblems.
The first issue concerns the amount of time required to create the thread,
togetherwiththefact thatthethreadwillbediscardedonce ithascompleted
its work. The second issue is more troublesome. If we allow each concurrent
request to be serviced in a new thread, we have not placed a bound on the
numberofthreadsconcurrentlyactiveinthesystem.Unlimitedthreadscould
exhaust system resources, such as CPU time or memory. One solution to this
problemistouseathreadpool.178 Chapter4 Threads&Concurrency
ANDROIDTHREADPOOLS
In Section 3.8.2.1, we covered RPCs in the Android operating system. You
may recall from that section that Android uses the Android Interface Defi-
nitionLanguage(AIDL),atoolthatspecifiestheremoteinterfacethatclients
interactwithontheserver.AIDLalsoprovidesathreadpool.Aremoteservice
usingthethreadpoolcanhandlemultipleconcurrentrequests,servicingeach
requestusingaseparatethreadfromthepool.
The general ideabehind a thread pool is to create a number of threads at
start-upandplacethemintoapool,wheretheysitandwaitforwork.Whena
serverreceivesarequest,rather than creating athread,it insteadsubmits the
requesttothethreadpoolandresumeswaitingforadditionalrequests.Ifthere
is an available thread in the pool, it is awakened, and the request is serviced
immediately.Ifthepoolcontainsnoavailablethread,thetaskisqueueduntil
one becomes free. Once a thread completes its service, it returns to the pool
and awaits more work. Thread pools work well when the tasks submitted to
thepoolcanbeexecutedasynchronously.
Threadpoolsofferthesebenefits:
1. Servicingarequestwithanexistingthreadisoftenfasterthanwaitingto
createathread.
2. Athreadpoollimitsthenumberofthreadsthatexistatanyonepoint.This
isparticularlyimportantonsystemsthatcannotsupportalargenumber
ofconcurrentthreads.
3. Separating the task to be performed from the mechanics of creating the
taskallowsustousedifferentstrategiesforrunningthetask.Forexample,
the task could be scheduled to execute after a time delay or to execute
periodically.
Thenumberofthreadsinthepoolcanbesetheuristicallybasedonfactors
suchasthenumberofCPUsinthesystem,theamountofphysicalmemory,and
theexpectednumberofconcurrentclientrequests.Moresophisticatedthread-
pool architectures can dynamically adjust the number of threads in the pool
according to usage patterns. Such architectures providethe further benefit of
havingasmallerpool—therebyconsuminglessmemory—whentheloadon
the system is low. We discuss one such architecture, Apple’s Grand Central
Dispatch,laterinthissection.
TheWindowsAPIprovidesseveralfunctionsrelatedtothreadpools.Using
the thread pool API is similartocreating a threadwith the Thread Create()
function, as described in Section 4.4.2. Here, a function that is to run as a
separatethreadisdefined.Suchafunctionmayappearasfollows:
DWORD WINAPI PoolFunction(PVOID Param) {
/* this function runs as a separate thread. */
}4.5 ImplicitThreading 179
Apointer to PoolFunction() is passed to one of the functions in the thread
poolAPI,andathreadfromthepoolexecutesthisfunction.Onesuchmember
inthethreadpoolAPIistheQueueUserWorkItem()function,whichispassed
threeparameters:
• LPTHREAD START ROUTINE Function—apointertothefunctionthatisto
runasaseparatethread
• PVOID Param—theparameterpassedtoFunction
• ULONG Flags—flagsindicatinghowthethreadpoolistocreateandman-
ageexecutionofthethread
Anexampleofinvokingafunctionisthefollowing:
QueueUserWorkItem(&PoolFunction, NULL, 0);
ThiscausesathreadfromthethreadpooltoinvokePoolFunction()onbehalf
of the programmer. In this instance, we pass no parameters to PoolFunc-
tion(). Because we specify 0 as a flag, we provide the thread pool with no
specialinstructionsforthreadcreation.
Other members in the Windows thread pool API include utilities that
invoke functions at periodic intervals or when an asynchronous I/O request
completes.
4.5.1.1 JavaThreadPools
The java.util.concurrentpackage includes an API for several varietiesof
thread-poolarchitectures.Here,wefocusonthefollowingthreemodels:
1. Singlethreadexecutor—newSingleThreadExecutor()—createsapool
ofsize1.
2. Fixed thread executor—newFixedThreadPool(int size)—creates a
threadpoolwithaspecifiednumberofthreads.
3. Cached thread executor—newCachedThreadPool()—creates an
unboundedthreadpool,reusingthreadsinmanyinstances.
We have, in fact, already seen the use of a Java thread pool in Section
4.4.3,wherewecreatedanewSingleThreadExecutorintheprogramexample
shown in Figure 4.14. In that section, we noted that the Java executor frame-
work can be usedto construct more robust threading tools. We now describe
howitcanbeusedtocreatethreadpools.
AthreadpooliscreatedusingoneofthefactorymethodsintheExecutors
class:
• static ExecutorService newSingleThreadExecutor()
• static ExecutorService newFixedThreadPool(int size)
• static ExecutorService newCachedThreadPool()
Eachofthesefactorymethodscreatesandreturnsanobjectinstancethatimple-
mentstheExecutorServiceinterface.ExecutorServiceextendstheExecu-180 Chapter4 Threads&Concurrency
import java.util.concurrent.*;
public class ThreadPoolExample
{
public static void main(String[] args) {
int numTasks = Integer.parseInt(args[0].trim());
/* Create the thread pool */
ExecutorService pool = Executors.newCachedThreadPool();
/* Run each task using a thread in the pool */
for (int i = 0; i < numTasks; i++)
pool.execute(new Task());
/* Shut down the pool once all threads have completed */
pool.shutdown();
}
Figure4.15 CreatingathreadpoolinJava.
tor interface, allowing us toinvoke the execute()method on this object. In
addition, ExecutorService provides methods for managing termination of
thethreadpool.
TheexampleshowninFigure4.15createsacachedthreadpoolandsubmits
taskstobeexecutedbyathreadinthepoolusingtheexecute()method.When
theshutdown()methodisinvoked,thethreadpoolrejectsadditionaltasksand
shutsdownonceallexistingtaskshavecompletedexecution.
4.5.2 Fork Join
The strategy for thread creation covered in Section 4.4 is often known as the
fork-joinmodel.Recallthatwiththismethod,themainparentthreadcreates
(forks)oneormorechildthreadsandthenwaitsforthechildrentoterminate
andjoinwithit,atwhichpointitcanretrieveandcombinetheirresults.This
synchronous model is often characterized as explicit thread creation, but it
is also an excellent candidate for implicit threading. In the latter situation,
threadsarenotconstructeddirectlyduringtheforkstage;rather,paralleltasks
aredesignated.ThismodelisillustratedinFigure4.16.Alibrarymanagesthe
numberofthreadsthatarecreatedandisalsoresponsibleforassigningtasksto
threads.Insomeways,thisfork-joinmodelisasynchronousversionofthread
pools in which a library determinesthe actual number of threads to create—
forexample,byusingtheheuristicsdescribedinSection4.5.1.
4.5.2.1 ForkJoininJava
Java introduced a fork-join library in Version 1.7 of the API that is designed
to be used with recursive divide-and-conquer algorithms such as Quicksort
andMergesort.Whenimplementingdivide-and-conqueralgorithmsusingthis4.5 ImplicitThreading 181
fo r k task join
main thread main thread
fork
task
join
Figure4.16 Fork-joinparallelism.
library,separatetasksareforkedduringthedividestepandassignedsmaller
subsets of the original problem. Algorithms must be designed so that these
separatetaskscanexecuteconcurrently.Atsomepoint,thesizeoftheproblem
assigned to a task is small enough that it can be solved directly and requires
creating no additional tasks. The general recursive algorithm behind Java’s
fork-joinmodelisshownbelow:
Task(problem)
if problem is small enough
solve the problem directly
else
subtask1 = fork(new Task(subset of problem)
subtask2 = fork(new Task(subset of problem)
result1 = join(subtask1)
result2 = join(subtask2)
return combined results
Figure4.17depictsthemodelgraphically.
We now illustrate Java’s fork-join strategy by designing a divide-and-
conqueralgorithmthatsumsallelementsinanarrayofintegers.InVersion1.7
oftheAPI Javaintroducedanewthreadpool—theForkJoinPool—thatcan
beassignedtasksthatinherittheabstractbaseclassForkJoinTask(whichfor
nowwewillassumeistheSumTaskclass).ThefollowingcreatesaForkJoin-
Poolobjectandsubmitstheinitialtaskviaitsinvoke()method:
ForkJoinPool pool = new ForkJoinPool();
// array contains the integers to be summed
int[] array = new int[SIZE];
SumTask task = new SumTask(0, SIZE - 1, array);
int sum = pool.invoke(task);
Uponcompletion,theinitialcalltoinvoke()returnsthesummationofarray.
The class SumTask—shown in Figure 4.18—implements a divide-and-
conquer algorithm that sums the contents of the array using fork-join. New
tasksarecreatedusingthefork()method,andthecompute()methodspeci-
fiesthecomputationthatisperformedbyeachtask.Themethodcompute()is
invokeduntilitcandirectlycalculatethesumofthesubsetitisassigned.The182 Chapter4 Threads&Concurrency
fork task
join
task
fork join
task
join fork
task
join fork
task
fork
join
task
join
task
fork
Figure4.17 Fork-joininJava.
calltojoin()blocksuntilthetaskcompletes,uponwhichjoin()returnsthe
resultscalculatedincompute().
NoticethatSumTaskinFigure4.18extendsRecursiveTask.TheJavafork-
join strategy is organized around the abstract base class ForkJoinTask, and
theRecursiveTaskandRecursiveActionclassesextendthisclass.Thefun-
damentaldifferencebetweenthesetwoclassesisthatRecursiveTaskreturns
aresult(viathereturnvaluespecifiedincompute()),andRecursiveAction
doesnotreturnaresult.Therelationshipbetweenthethreeclassesisillustrated
intheUMLclassdiagraminFigure4.19.
Animportantissuetoconsiderisdeterminingwhentheproblemis“small
enough”tobesolveddirectlyandnolongerrequirescreatingadditionaltasks.
In SumTask, this occurs when the number of elements being summed is less
thanthevalueTHRESHOLD,whichinFigure4.18wehavearbitrarilysetto1,000.
Inpractice,determiningwhenaproblemcanbesolveddirectlyrequirescareful
timingtrials,asthevaluecanvaryaccordingtoimplementation.
What is interesting in Java’s fork-join model is the management of tasks
whereinthelibraryconstructsapoolofworkerthreadsandbalancestheload
oftasksamongtheavailableworkers.Insomesituations,therearethousands
of tasks, yet only a handful of threads performing the work (for example, a
separate thread for each CPU). Additionally, each thread in a ForkJoinPool
maintainsaqueueoftasksthatithasforked,andifathread’squeueisempty,
itcanstealataskfromanotherthread’squeueusingaworkstealingalgorithm,
thusbalancingtheworkloadoftasksamongallthreads.4.5 ImplicitThreading 183
import java.util.concurrent.*;
public class SumTask extends RecursiveTask<Integer>
{
static final int THRESHOLD = 1000;
private int begin;
private int end;
private int[] array;
public SumTask(int begin, int end, int[] array) {
this.begin = begin;
this.end = end;
this.array = array;
}
protected Integer compute() {
if (end - begin < THRESHOLD) {
int sum = 0;
for (int i = begin; i <= end; i++)
sum += array[i];
return sum;
}
else {
int mid = (begin + end) / 2;
SumTask leftTask = new SumTask(begin, mid, array);
SumTask rightTask = new SumTask(mid + 1, end, array);
leftTask.fork();
rightTask.fork();
return rightTask.join() + leftTask.join();
}
}
}
Figure4.18 Fork-joincalculationusingtheJavaAPI.
4.5.3 OpenMP
OpenMPisasetofcompilerdirectivesaswellasanAPIforprogramswrittenin
C,C++,orFORTRANthatprovidessupportforparallelprogramminginshared-
memory environments. OpenMP identifies parallel regions as blocks of code
thatmayruninparallel.Applicationdevelopersinsertcompilerdirectivesinto
their code at parallel regions, and these directives instruct the OpenMP run-184 Chapter4 Threads&Concurrency
ForkJoinTask <V>
<abstract>
RecursiveTask <V> RecursiveAction
<abstract> <abstract>
V compute() void compute()
Figure4.19 UMLclassdiagramforJava’sfork-join.
time library to execute the region in parallel. The following C program illus-
tratesacompilerdirectiveabovetheparallelregioncontaining the printf()
statement:
#include <omp.h>
#include <stdio.h>
int main(int argc, char *argv[])
{
/* sequential code */
#pragma omp parallel
{
printf("I am a parallel region.");
}
/* sequential code */
return 0;
}
WhenOpenMPencountersthedirective
#pragma omp parallel
itcreatesasmanythreadsasthereareprocessingcoresinthesystem.Thus,for
a dual-core system, two threads are created; for a quad-core system, four are
created;andsoforth.Allthethreadsthensimultaneouslyexecutetheparallel
region.Aseachthreadexitstheparallelregion,itisterminated.
OpenMP provides several additional directives for running code regions
in parallel, including parallelizing loops. For example, assume we have two
arrays,aandb,ofsizeN.Wewishtosumtheircontents andplacetheresults4.5 ImplicitThreading 185
in array c. We can have this task run in parallel by using the following code
segment,whichcontainsthecompilerdirectiveforparallelizingforloops:
#pragma omp parallel for
for (i = 0; i < N; i++) {
c[i] = a[i] + b[i];
}
OpenMPdividestheworkcontainedintheforloopamongthethreadsithas
createdinresponsetothedirective
#pragma omp parallel for
In addition to providing directives for parallelization, OpenMP allows
developers to choose among several levels of parallelism. For example, they
can set the number of threads manually. It also allows developersto identify
whether data are shared between threads or are private to a thread. OpenMP
isavailableonseveralopen-sourceandcommercialcompilersforLinux,Win-
dows,andmacOSsystems.Weencouragereadersinterestedinlearningmore
aboutOpenMPtoconsultthebibliographyattheendofthechapter.
4.5.4 Grand Central Dispatch
Grand Central Dispatch (GCD) is a technology developed by Apple for its
macOS and iOS operating systems. It is a combination of a run-time library,
an API, and language extensions that allow developersto identify sections of
code(tasks)toruninparallel.LikeOpenMP,GCDmanagesmostofthedetails
ofthreading.
GCDschedulestasksforrun-timeexecutionbyplacingthemonadispatch
queue.Whenitremovesataskfromaqueue,itassignsthetasktoanavailable
thread from a pool of threads that it manages. GCD identifies two types of
dispatchqueues:serialandconcurrent.
TasksplacedonaserialqueueareremovedinFIFOorder.Onceataskhas
beenremovedfromthequeue,itmustcompleteexecutionbeforeanothertask
isremoved.Eachprocesshasitsownserialqueue(knownasitsmainqueue),
anddeveloperscancreateadditionalserialqueuesthatarelocaltoaparticular
process.(Thisiswhyserialqueuesarealsoknownasprivatedispatchqueues.)
Serialqueuesareusefulforensuringthesequentialexecutionofseveraltasks.
Tasks placed on a concurrent queue are also removed in FIFO order, but
severaltasksmayberemovedatatime,thusallowingmultipletaskstoexecute
in parallel. There are several system-wide concurrent queues (also known as
globaldispatchqueues),whicharedividedintofourprimaryquality-of-service
classes:
• QOS CLASS USER INTERACTIVE—The user-interactive class represents
tasks that interact with the user, such as the user interface and event
handling, to ensure a responsive user interface. Completing a task
belongingtothisclassshouldrequireonlyasmallamountofwork.
• QOS CLASS USER INITIATED—The user-initiated class is similar to the
user-interactive class in that tasks are associated with a responsive user
interface; however, user-initiated tasks may require longer processing186 Chapter4 Threads&Concurrency
times. Opening a file or a URLis a user-initiated task, for example. Tasks
belonging to this class must be completed for the user to continue inter-
acting withthe system,but they donot needto be servicedas quickly as
tasksintheuser-interactivequeue.
• QOS CLASS UTILITY —The utility class represents tasks that require a
longertimetocompletebutdonotdemandimmediateresults.Thisclass
includesworksuchasimportingdata.
• QOS CLASS BACKGROUND —Tasks belonging to the background class are
notvisibletotheuserandarenottimesensitive.Examplesincludeindex-
ingamailboxsystemandperformingbackups.
Tasks submitted to dispatch queues may be expressed in one of two
differentways:
1. For the C, C++, and Objective-C languages, GCD identifies a language
extension known as a block, which is simply a self-contained unit of
work.Ablockisspecifiedbyacaretˆinsertedinfrontofapairofbraces
{}.Codewithinthebracesidentifiestheunitofworktobeperformed.A
simpleexampleofablockisshownbelow:
^{ printf("I am a block"); }
2. For the Swift programming language, a task is defined using a closure,
which is similar to a block in that it expresses a self-contained unit of
functionality.Syntactically,aSwiftclosureiswritteninthesamewayas
ablock,minustheleadingcaret.
The following Swift code segment illustrates obtaining a concurrent
queuefortheuser-initiatedclassandsubmittingatasktothequeueusing
thedispatch async()function:
let queue = dispatch get global queue
(QOS CLASS USER INITIATED, 0)
dispatch async(queue,{ print("I am a closure.") })
Internally, GCD’s thread pool is composed of POSIX threads. GCD actively
managesthepool,allowingthenumberofthreadstogrowandshrinkaccord-
ing to application demand and system capacity. GCD is implemented by the
libdispatchlibrary,whichApplehasreleasedundertheApacheCommons
license.IthassincebeenportedtotheFreeBSDoperatingsystem.
4.5.5 Intel Thread Building Blocks
Intelthreadingbuildingblocks(TBB)isatemplatelibrarythatsupportsdesign-
ing parallel applications in C++. As this is a library, it requires no special
compiler or language support. Developers specify tasks that can run in par-4.5 ImplicitThreading 187
allel, and the TBB task scheduler maps these tasks onto underlying threads.
Furthermore, the task scheduler provides load balancing and is cache aware,
meaningthatitwillgiveprecedencetotasksthatlikelyhavetheirdatastored
in cache memory and thus will execute more quickly. TBB provides a rich set
offeatures,includingtemplatesforparallelloopstructures,atomicoperations,
and mutual exclusion locking. In addition, it providesconcurrent data struc-
tures,includingahashmap,queue,andvector,whichcanserveasequivalent
thread-safeversionsoftheC++standardtemplatelibrarydatastructures.
Let’suseparallelforloopsasanexample.Initially,assumethereisafunc-
tionnamedapply(float value)thatperformsanoperationontheparameter
value.Ifwehadanarrayvofsizencontainingfloatvalues,wecouldusethe
followingserialforlooptopasseachvalueinvtotheapply()function:
for (int i = 0; i < n; i++) {
apply(v[i]);
}
A developer could manually apply data parallelism (Section 4.2.2) on a
multicore system by assigning different regions of the array v to each pro-
cessingcore;however,thistiesthetechniqueforachievingparallelismclosely
to the physical hardware, and the algorithm would have to be modified and
recompiledforthenumberofprocessingcoresoneachspecificarchitecture.
Alternatively,adevelopercoulduseTBB,whichprovidesaparallel for
templatethatexpectstwovalues:
parallel for (range body)
whererangereferstotherangeofelementsthatwillbeiterated(knownasthe
iteration space) and body specifies an operation that will be performed on a
subrangeofelements.
WecannowrewritetheaboveserialforloopusingtheTBBparallel for
templateasfollows:
parallel for (size t(0), n, [=](size t i) {apply(v[i]);});
Thefirsttwoparametersspecifythattheiterationspaceisfrom0ton−1(which
correspondstothenumberofelementsinthearrayv).Thesecondparameter
is a C++ lambda function that requires a bit of explanation. The expression
[=](size t i)istheparameteri,whichassumeseachofthevaluesoverthe
iterationspace(inthiscasefrom0to𝚗−1).Eachvalueofiisusedtoidentify
which array element in v is to be passed as a parameter to the apply(v[i])
function.
TheTBBlibrarywilldividetheloopiterationsintoseparate“chunks”and
create a number of tasks that operate on those chunks. (The parallel for
function allows developersto manually specify the size of the chunks ifthey
wishto.)TBBwillalsocreateanumberofthreadsandassigntaskstoavailable
threads.Thisisquitesimilartothefork-joinlibraryinJava.Theadvantageof
thisapproachisthatitrequiresonlythatdevelopersidentifywhatoperations
canruninparallel(byspecifyingaparallel forloop),andthelibraryman-188 Chapter4 Threads&Concurrency
ages the details involved in dividingthe work into separate tasks that run in
parallel.Intel TBB has both commercial and open-source versionsthat run on
Windows, Linux, and macOS. Refer to the bibliography for further details on
howtodevelopparallelapplicationsusingTBB.
4.6 Threading Issues
In this section, we discuss some of the issues to consider in designing multi-
threadedprograms.
4.6.1 The fork() and exec() System Calls
In Chapter 3, we described how the fork() system call is used to create a
separate, duplicate process. The semantics of the fork() and exec() system
callschangeinamultithreadedprogram.
If one thread in a program calls fork(), does the new process duplicate
all threads, or is the new process single-threaded? Some UNIX systems have
chosen to have two versions of fork(), one that duplicates all threads and
anotherthatduplicatesonlythethreadthatinvokedthefork()systemcall.
The exec() system call typically works in the same way as described in
Chapter 3. That is, if a thread invokes the exec() system call, the program
specifiedintheparametertoexec()willreplacetheentireprocess—including
allthreads.
Which of the two versions of fork() to use depends on the application.
If exec() is called immediately after forking, then duplicating all threads is
unnecessary,astheprogramspecifiedintheparameterstoexec()willreplace
the process. In this instance, duplicating only the calling thread is appropri-
ate. If, however, the separate process does not call exec() after forking, the
separateprocessshouldduplicateallthreads.
4.6.2 Signal Handling
AsignalisusedinUNIXsystemstonotifyaprocessthataparticulareventhas
occurred. Asignal may be received either synchronously or asynchronously,
depending on the source of and the reason for the event being signaled. All
signals,whethersynchronousorasynchronous,followthesamepattern:
1. Asignalisgeneratedbytheoccurrenceofaparticularevent.
2. Thesignalisdeliveredtoaprocess.
3. Oncedelivered,thesignalmustbehandled.
Examplesofsynchronoussignalsincludeillegalmemoryaccessanddivi-
sionby0.Ifarunningprogramperformseitheroftheseactions,asignalisgen-
erated.Synchronoussignalsaredeliveredtothesameprocessthatperformed
the operation that caused the signal (that is the reason they are considered
synchronous).
Whenasignalisgeneratedbyaneventexternaltoarunningprocess,that
process receives the signal asynchronously. Examples of such signals include
terminating a process with specific keystrokes (such as <control><C>) and4.6 ThreadingIssues 189
having a timer expire. Typically, an asynchronous signal is sent to another
process.
Asignalmaybehandledbyoneoftwopossiblehandlers:
1. Adefaultsignalhandler
2. Auser-definedsignalhandler
Everysignalhasadefaultsignalhandlerthatthekernelrunswhenhan-
dling that signal. This default action can be overridden by a user-define
signalhandlerthatiscalledtohandlethesignal.Signalsarehandledindiffer-
ent ways. Some signals may be ignored, while others (for example, an illegal
memoryaccess)arehandledbyterminatingtheprogram.
Handling signals in single-threaded programs is straightforward: signals
arealwaysdeliveredtoaprocess.However,deliveringsignalsismorecompli-
catedinmultithreadedprograms,where aprocessmay haveseveralthreads.
Where,then,shouldasignalbedelivered?
Ingeneral,thefollowingoptionsexist:
1. Deliverthesignaltothethreadtowhichthesignalapplies.
2. Deliverthesignaltoeverythreadintheprocess.
3. Deliverthesignaltocertainthreadsintheprocess.
4. Assignaspecificthreadtoreceiveallsignalsfortheprocess.
Themethodfordeliveringasignaldependsonthetypeofsignalgenerated.
For example, synchronous signals need to be deliveredto the thread causing
thesignalandnottootherthreadsintheprocess.However,thesituationwith
asynchronous signals is not as clear. Some asynchronous signals—such as a
signal that terminates a process (<control><C>, for example)—should be
senttoallthreads.
ThestandardUNIXfunctionfordeliveringasignalis
kill(pid t pid, int signal)
Thisfunctionspecifiestheprocess(pid)towhichaparticularsignal(signal)is
tobedelivered.MostmultithreadedversionsofUNIXallowathreadtospecify
which signals it will accept and which itwill block. Therefore,insome cases,
an asynchronous signal may be delivered only to those threads that are not
blockingit.However,becausesignalsneedtobehandledonlyonce,asignalis
typicallydeliveredonlytothefirstthreadfoundthatisnotblockingit.POSIX
Pthreadsprovidesthefollowingfunction,whichallowsasignaltobedelivered
toaspecifiedthread(tid):
pthread kill(pthread t tid, int signal)
Although Windows does not explicitly provide support for signals, it
allows us to emulate them using asynchronous procedure calls (APCs). The
APC facility enables a user thread to specify a function that is to be called
when the user thread receives notification of a particular event. As indicated190 Chapter4 Threads&Concurrency
byitsname,anAPCisroughlyequivalenttoanasynchronoussignalinUNIX.
However,whereasUNIXmustcontendwithhowtodealwithsignalsinamul-
tithreadedenvironment,theAPCfacilityismorestraightforward,sinceanAPC
isdeliveredtoaparticularthreadratherthanaprocess.
4.6.3 Thread Cancellation
Threadcancellationinvolvesterminatingathreadbeforeithascompleted.For
example, if multiple threads are concurrently searching through a database
and one thread returns the result, the remaining threads might be canceled.
Anothersituationmightoccurwhenauserpressesabuttononawebbrowser
that stops a web page from loading any further. Often, a web page loads
using several threads—each image is loaded in a separate thread. When a
userpressesthestop buttonon the browser,all threadsloadingthe pageare
canceled.
A thread that is to be canceled is often referred to as the target thread.
Cancellationofatargetthreadmayoccurintwodifferentscenarios:
1. Asynchronouscancellation.Onethreadimmediatelyterminatesthetar-
getthread.
2. Deferred cancellation. The target thread periodically checks whether it
should terminate, allowing it an opportunity to terminate itself in an
orderlyfashion.
Thedifficultywithcancellationoccursinsituationswhereresourceshave
been allocated to a canceled thread or where a thread is canceled while in
the midst of updating data it is sharing with other threads. This becomes
especially troublesome with asynchronous cancellation. Often, the operating
system will reclaim system resources from a canceled thread but will not
reclaim all resources. Therefore, canceling a thread asynchronously may not
freeanecessarysystem-wideresource.
With deferred cancellation, in contrast, one thread indicates that a target
threadistobecanceled,butcancellationoccursonlyafterthetargetthreadhas
checked aflag todeterminewhether or not it should becanceled. Thethread
canperformthischeckatapointatwhichitcanbecanceledsafely.
In Pthreads, thread cancellation is initiated using the pthread cancel()
function.Theidentifierofthetargetthreadispassedasaparametertothefunc-
tion.Thefollowingcodeillustratescreating—andthencanceling—athread:
pthread t tid;
/* create the thread */
pthread create(&tid, 0, worker, NULL);
. . .
/* cancel the thread */
pthread cancel(tid);
/* wait for the thread to terminate */
pthread join(tid,NULL);4.6 ThreadingIssues 191
Invoking pthread cancel()indicates only a request to cancel the target
thread, however; actual cancellation depends on how the target thread is set
up to handle the request. When the target thread is finally canceled, the call
to pthread join() in the canceling thread returns. Pthreads supports three
cancellation modes.Each modeis definedas astate and atype,as illustrated
inthetablebelow.AthreadmaysetitscancellationstateandtypeusinganAPI.
Mode State Type
Off Disabled –
Deferred Enabled Deferred
Asynchronous Enabled Asynchronous
As the table illustrates, Pthreads allows threads to disable or enable can-
cellation. Obviously, a thread cannot be canceled if cancellation is disabled.
However,cancellationrequestsremainpending,sothethreadcanlaterenable
cancellationandrespondtotherequest.
The default cancellation type is deferredcancellation. However, cancella-
tionoccursonlywhenathreadreachesacancellationpoint.Mostoftheblock-
ingsystemcallsinthePOSIXandstandardClibraryaredefinedascancellation
points,andthesearelistedwheninvokingthecommandman pthreadsona
Linuxsystem.Forexample,theread()systemcallisacancellationpointthat
allowscancellingathreadthatisblockedwhileawaitinginputfromread().
One technique for establishing a cancellation point is to invoke the
pthread testcancel() function. If a cancellation request is found to be
pending, the call to pthread testcancel() will not return, and the thread
will terminate; otherwise, the call to the function will return, and the thread
will continue to run. Additionally, Pthreads allows a function known as a
cleanup handler to be invoked if a thread is canceled. This function allows
any resources a thread may have acquired to be released before the thread is
terminated.
Thefollowingcodeillustrateshowathreadmayrespondtoacancellation
requestusingdeferredcancellation:
while (1) {
/* do some work for awhile */
. . .
/* check if there is a cancellation request */
pthread testcancel();
}
Because of the issues described earlier, asynchronous cancellation is not
recommended in Pthreads documentation. Thus, we do not cover it here.
An interesting note is that on Linux systems, thread cancellation using the
PthreadsAPIishandledthroughsignals(Section4.6.2).
ThreadcancellationinJavausesapolicysimilartodeferredcancellationin
Pthreads.TocancelaJavathread,youinvoketheinterrupt()method,which
setstheinterruptionstatusofthetargetthreadtotrue:192 Chapter4 Threads&Concurrency
Thread worker;
. . .
/* set the interruption status of the thread */
worker.interrupt()
A thread can check its interruption status by invoking the isInter-
rupted() method, which returns a boolean value of a thread’s interruption
status:
while (!Thread.currentThread().isInterrupted()) {
. . .
}
4.6.4 Thread-Local Storage
Threads belonging to a process share the data of the process. Indeed, this
data sharing provides one of the benefits of multithreaded programming.
However, in some circumstances, each thread might need its own copy of
certaindata.Wewillcallsuchdatathread-localstorage(orTLS).Forexample,
in a transaction-processing system, we might service each transaction in a
separate thread. Furthermore, each transaction might be assigned a unique
identifier. To associate each thread with its unique transaction identifier, we
couldusethread-localstorage.
It is easy to confuse TLS with local variables. However, local variables
are visible only during a single function invocation, whereas TLS data are
visible across function invocations. Additionally, when the developer has no
controloverthethreadcreationprocess—forexample,whenusinganimplicit
techniquesuchasathreadpool—thenanalternativeapproachisnecessary.
In some ways, TLS is similar to static data; the difference is that TLS
data are unique to each thread. (In fact, TLS is usually declared as static.)
Most thread libraries and compilers provide support for TLS. For example,
Java provides a ThreadLocal<T> class with set() and get() methods for
ThreadLocal<T> objects. Pthreads includes the type pthread key t, which
providesakeythatisspecifictoeachthread.Thiskeycanthenbeusedtoaccess
TLSdata.Microsoft’sC#languagesimplyrequiresaddingthestorageattribute
[ThreadStatic]todeclarethread-localdata.The gcccompilerprovidesthe
storage class keyword thread for declaring TLS data. For example, if we
wished to assign a unique identifier for each thread, we would declare it as
follows:
static thread int threadID;
4.6.5 Scheduler Activations
Afinalissuetobeconsideredwithmultithreadedprogramsconcernscommu-
nication between the kernel and the thread library, which may be required4.6 ThreadingIssues 193
by the many-to-many and two-level models discussed in Section 4.3.3. Such
coordinationallowsthenumberofkernelthreadstobedynamicallyadjusted
tohelpensurethebestperformance.
Many systems implementing either the many-to-many or the two-level
model place an intermediate data structure between the user and kernel
threads. This data structure—typically known as a lightweight process, or
LWP—is shown in Figure 4.20. To the user-thread library, the LWP appears to
be avirtualprocessor on which the applicationcan scheduleauser threadto
run. Each LWP is attached to a kernel thread, and it is kernel threads that the
operating system schedules to run on physical processors. If a kernel thread
blocks(suchaswhilewaitingforanI/Ooperationtocomplete),theLWPblocks
aswell.Upthechain,theuser-levelthreadattachedtotheLWPalsoblocks.
AnapplicationmayrequireanynumberofLWPstorunefficiently.Consider
aCPU-bound applicationrunning on asingleprocessor.Inthis scenario,only
onethreadcanrunatatime,sooneLWPissufficient.AnapplicationthatisI/O-
intensivemayrequiremultipleLWPstoexecute,however.Typically,anLWPis
requiredforeachconcurrentblockingsystemcall.Suppose,forexample,that
five different file-read requests occur simultaneously. Five LWPs are needed,
becauseallcouldbewaitingforI/Ocompletioninthekernel.Ifaprocesshas
only fourLWPs, thenthe fifthrequestmust wait for oneofthe LWPs toreturn
fromthekernel.
One scheme for communication between the user-thread library and the
kernelisknown asscheduleractivation.Itworks asfollows: Thekernelpro-
videsanapplicationwithasetofvirtualprocessors(LWPs),andtheapplication
can schedule user threads onto an available virtual processor. Furthermore,
thekernelmustinformanapplicationaboutcertainevents.Thisprocedureis
knownasanupcall.Upcallsarehandledbythethreadlibrarywithanupcall
handler,andupcallhandlersmustrunonavirtualprocessor.
One event that triggers an upcall occurs when an application thread is
about to block. Inthis scenario, the kernel makesan upcall tothe application
informingitthatathreadisabouttoblockandidentifyingthespecificthread.
Thekernelthenallocatesanewvirtualprocessortotheapplication.Theappli-
cation runs an upcall handler on this new virtual processor, which saves the
user thread
LWP lightweight process
kernel thread
Figure4.20 Lightweightprocess(LWP).194 Chapter4 Threads&Concurrency
stateoftheblockingthreadandrelinquishesthevirtualprocessoronwhichthe
blockingthreadisrunning.Theupcallhandlerthenschedulesanotherthread
that is eligible to run on the new virtual processor. When the event that the
blockingthreadwaswaitingforoccurs,thekernelmakesanotherupcalltothe
thread library informing it that the previouslyblocked thread is now eligible
torun.Theupcallhandlerforthiseventalsorequiresavirtualprocessor,and
the kernel may allocate a new virtual processor or preempt one of the user
threadsandruntheupcallhandleronitsvirtualprocessor.Aftermarkingthe
unblockedthreadaseligibletorun,theapplicationschedulesaneligiblethread
torunonanavailablevirtualprocessor.
4.7 Operating-System Examples
At this point, we have examined a number of concepts and issues related to
threads.Weconcludethechapterbyexploringhowthreadsareimplemented
inWindowsandLinuxsystems.
4.7.1 Windows Threads
A Windows application runs as a separate process, and each process may
containoneormorethreads.TheWindowsAPIforcreatingthreadsiscovered
inSection4.4.2.Additionally,Windowsusestheone-to-onemappingdescribed
in Section 4.3.2, where each user-level thread maps to an associated kernel
thread.
Thegeneralcomponentsofathreadinclude:
• AthreadIDuniquelyidentifyingthethread
• Aregistersetrepresentingthestatusoftheprocessor
• Aprogramcounter
• Auser stack, employed when the thread is running in user mode, and a
kernelstack,employedwhenthethreadisrunninginkernelmode
• Aprivatestorageareausedbyvariousrun-timelibrariesanddynamiclink
libraries(DLLs)
The register set, stacks, and private storage area are known as the context of
thethread.
Theprimarydatastructuresofathreadinclude:
• ETHREAD—executivethreadblock
• KTHREAD—kernelthreadblock
• TEB—threadenvironmentblock
The key components of the ETHREAD include a pointer to the process
to which the thread belongs and the address of the routine in which the
threadstartscontrol.TheETHREADalsocontainsapointertothecorresponding
KTHREAD.4.7 Operating-SystemExamples 195
ETHREAD
thread start
address
pointer to
parent process KTHREAD
scheduling
and
synchronization
(cid:129) information
(cid:129)
(cid:129)
kernel TEB
stack
thread identifier
(cid:129) user
(cid:129) stack
(cid:129)
thread-local
storage
(cid:129)
(cid:129)
(cid:129)
kernel space user space
Figure4.21 DatastructuresofaWindowsthread.
The KTHREAD includes scheduling and synchronization information for
thethread.Inaddition,theKTHREADincludesthekernelstack(usedwhenthe
threadisrunninginkernelmode)andapointertotheTEB.
TheETHREADandtheKTHREADexistentirelyinkernelspace;thismeans
that only the kernel can access them. The TEB is a user-space data structure
thatisaccessedwhenthethreadisrunninginusermode.Amongotherfields,
the TEB contains the thread identifier, a user-mode stack, and an array for
thread-localstorage.ThestructureofaWindowsthreadisillustratedinFigure
4.21.
4.7.2 Linux Threads
Linux provides the fork() system call with the traditional functionality of
duplicatingaprocess,asdescribedinChapter3.Linuxalsoprovidestheability
to create threads using the clone() system call. However, Linux does not
distinguish between processes and threads. In fact, Linux uses the term task
—ratherthanprocessorthread— whenreferringtoaflowofcontrolwithina
program.
When clone() is invoked, it is passed a set of flags that determine how
muchsharingistotakeplacebetweentheparentandchildtasks.Someofthese
flags are listed in Figure 4.22. For example, suppose that clone() is passed
theflagsCLONE FS,CLONE VM,CLONE SIGHAND,andCLONE FILES.Theparent
and child tasks will then share the same file-system information (such as the
currentworkingdirectory),thesamememoryspace,thesamesignalhandlers,196 Chapter4 Threads&Concurrency
flag meaning
CLONE_FS File-system information is shared.
CLONE_VM The same memory space is shared.
CLONE_SIGHAND Signal handlers are shared.
CLONE_FILES The set of open files is shared.
Figure4.22 Someoftheflagspassedwhenclone()isinvoked.
and the same set of openfiles. Using clone() in this fashion is equivalentto
creatingathreadasdescribedinthischapter,sincetheparenttasksharesmost
ofitsresourceswithitschildtask.However,ifnoneoftheseflagsissetwhen
clone() is invoked, no sharing takes place, resulting in functionality similar
tothatprovidedbythefork()systemcall.
Thevaryinglevelofsharingispossiblebecauseofthewayataskisrepre-
sentedintheLinuxkernel.Auniquekerneldatastructure(specifically,struct
task struct) exists for each task in the system. This data structure, instead
of storing data for the task, contains pointers to other data structures where
these data are stored—for example, data structures that represent the list of
openfiles,signal-handlinginformation,andvirtualmemory.Whenfork()is
invoked, a new task is created, along with a copy of all the associated data
structuresoftheparentprocess.Anewtaskisalsocreatedwhentheclone()
systemcallismade.However,ratherthancopyingalldatastructures,thenew
task points to the data structures of the parent task, depending on the set of
flagspassedtoclone().
Finally, the flexibility of the clone() system call can be extended to the
conceptofcontainers,avirtualizationtopicwhichwasintroducedinChapter
1. Recall from that chapter that a container is a virtualization technique pro-
vided by the operating system that allows creating multiple Linux systems
(containers) under a single Linux kernel that run in isolation to one another.
Justascertainflagspassedtoclone()candistinguishbetweencreatingatask
thatbehavesmorelikeaprocessorathreadbasedupontheamountofsharing
betweentheparentandchildtasks,thereareotherflagsthatcanbepassedto
clone()thatallowaLinuxcontainertobecreated.Containerswillbecovered
morefullyinChapter18.
4.8 Summary
• AthreadrepresentsabasicunitofCPUutilization,andthreadsbelonging
to the same process share many of the process resources, including code
anddata.
• Therearefourprimarybenefitstomultithreadedapplications:(1)respon-
siveness,(2)resourcesharing,(3)economy,and(4)scalability.
• Concurrency existswhenmultiplethreadsaremaking progress,whereas
parallelism exists when multiple threads are making progress simulta-PracticeExercises 197
neously. On a system with a single CPU, only concurrency is possible;
parallelismrequiresamulticoresystemthatprovidesmultipleCPUs.
• There are several challenges in designing multithreaded applications.
Theyincludedividingandbalancingthework,dividingthedatabetween
thedifferentthreads,andidentifyinganydatadependencies.Finally,mul-
tithreadedprogramsareespeciallychallengingtotestanddebug.
• Dataparallelismdistributessubsetsofthesamedataacrossdifferentcom-
puting cores and performs the same operation on each core. Task paral-
lelism distributes not data but tasks across multiple cores. Each task is
runningauniqueoperation.
• User applications create user-level threads, which must ultimately be
mapped to kernel threads to execute on a CPU. The many-to-one model
maps many user-level threads to one kernel thread. Other approaches
includetheone-to-oneandmany-to-manymodels.
• AthreadlibraryprovidesanAPIforcreatingandmanagingthreads.Three
commonthreadlibrariesincludeWindows,Pthreads,andJavathreading.
Windows isfortheWindowssystemonly,whilePthreadsisavailablefor
POSIX-compatible systems such as UNIX, Linux, and macOS. Java threads
willrunonanysystemthatsupportsaJavavirtualmachine.
• Implicitthreadinginvolvesidentifyingtasks—notthreads—andallowing
languages or API frameworks to create and manage threads. There are
severalapproachestoimplicitthreading,includingthreadpools,fork-join
frameworks,andGrandCentralDispatch.Implicitthreadingisbecoming
anincreasinglycommontechniqueforprogrammerstouseindeveloping
concurrentandparallelapplications.
• Threadsmaybeterminatedusingeitherasynchronousordeferredcancel-
lation. Asynchronous cancellation stops a thread immediately, even if it
is in the middle of performing an update. Deferred cancellation informs
athreadthat itshould terminatebutallowsthethreadtoterminateinan
orderlyfashion.Inmostcircumstances,deferredcancellationispreferred
toasynchronoustermination.
• Unlikemanyotheroperatingsystems,Linuxdoesnotdistinguishbetween
processes and threads; instead, it refers to each as a task. The Linux
clone() system call can be used to create tasks that behave either more
likeprocessesormorelikethreads.
Practice Exercises
4.1 Providethreeprogrammingexamplesinwhichmultithreadingprovides
betterperformancethanasingle-threadedsolution.
4.2 UsingAmdahl’sLaw,calculatethespeedupgainofanapplicationthat
hasa60percentparallelcomponentfor(a)twoprocessingcoresand(b)
fourprocessingcores.198 Chapter4 Threads&Concurrency
4.3 DoesthemultithreadedwebserverdescribedinSection4.1exhibittask
ordataparallelism?
4.4 What are two differences between user-level threads and kernel-level
threads?Underwhatcircumstancesisonetypebetterthantheother?
4.5 Describetheactionstakenbyakerneltocontext-switchbetweenkernel-
levelthreads.
4.6 What resourcesare usedwhen athread is created?How dothey differ
fromthoseusedwhenaprocessiscreated?
4.7 Assumethatanoperatingsystemmapsuser-levelthreadstothekernel
using the many-to-many model and that the mapping is done through
LWPs. Furthermore, the system allows developers to create real-time
threads for use in real-time systems. Is it necessary to bind a real-time
threadtoanLWP?Explain.
Further Reading
[Vahalia(1996)]coversthreadinginseveralversionsofUNIX.[McDougalland
Mauro(2007)]describesdevelopmentsinthreadingtheSolariskernel.[Russi-
novichetal.(2017)]discussthreadingintheWindowsoperatingsystemfamily.
[Mauerer(2008)]and[Love(2010)]explainhowLinuxhandlesthreading,and
[Levin (2013)] covers threads in macOS and iOS. [Herlihy and Shavit (2012)]
coversparallelismissuesonmulticoresystems.[Aubanel(2017)]coversparal-
lelismofseveraldifferentalgorithms.
Bibliography
[Aubanel(2017)] E.Aubanel,ElementsofParallelComputing,CRCPress(2017).
[HerlihyandShavit(2012)] M.HerlihyandN.Shavit,TheArtofMultiprocessor
Programming,RevisedFirstEdition,MorganKaufmannPublishersInc.(2012).
[Levin(2013)] J. Levin, Mac OS X and iOS Internals to the Apple’s Core, Wiley
(2013).
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[Mauerer(2008)] W.Mauerer,ProfessionalLinux KernelArchitecture,JohnWiley
andSons(2008).
[McDougallandMauro(2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition,PrenticeHall(2007).
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).
[Vahalia(1996)] U. Vahalia, Unix Internals: The New Frontiers, Prentice Hall
(1996).Exercises EX-8
Chapter 4 Exercises
4.8 Providetwoprogrammingexamplesinwhichmultithreadingdoesnot
providebetterperformancethanasingle-threadedsolution.
4.9 Under what circumstances does a multithreaded solution using multi-
ple kernel threads provide better performance than a single-threaded
solutiononasingle-processorsystem?
4.10 Whichofthefollowingcomponentsofprogramstatearesharedacross
threadsinamultithreadedprocess?
a. Registervalues
b. Heapmemory
c. Globalvariables
d. Stackmemory
4.11 Can a multithreaded solution using multiple user-level threads
achieve better performance on a multiprocessor system than on a
single-processorsystem?Explain.
4.12 In Chapter 3, we discussed Google’s Chrome browser and its practice
ofopeningeachnewtabinaseparateprocess.Wouldthesamebenefits
havebeenachievedif,instead,Chromehadbeendesignedtoopeneach
newtabinaseparatethread?Explain.
4.13 Isitpossibletohaveconcurrencybutnotparallelism?Explain.
4.14 UsingAmdahl’sLaw,calculatethespeedupgainforthefollowingappli-
cations:
• 40 percent parallel with (a) eight processing cores and (b) sixteen
processingcores
• 67 percent parallel with (a) two processing cores and (b) four pro-
cessingcores
• 90percentparallelwith(a)fourprocessingcoresand(b)eightpro-
cessingcores
4.15 Determineifthefollowingproblemsexhibittaskordataparallelism:
• Usingaseparatethreadtogenerateathumbnailforeachphotoina
collection
• Transposingamatrixinparallel
• Anetworkedapplicationwhereonethreadreadsfromthenetwork
andanotherwritestothenetwork
• Thefork-joinarraysummationapplicationdescribedinSection4.5.2
• TheGrandCentralDispatchsystem
4.16 Asystem with two dual-core processors has four processors available
for scheduling. ACPU-intensive application is running on this system.
All input is performed at program start-up, when a single file must beEX-9
opened.Similarly,alloutputisperformedjustbeforetheprogramtermi-
nates,whentheprogramresultsmustbewrittentoasinglefile.Between
start-upandtermination,theprogramisentirelyCPU-bound.Yourtask
is to improve the performance of this application by multithreading it.
The application runs on a system that uses the one-to-one threading
model(eachuserthreadmapstoakernelthread).
• Howmanythreadswillyoucreatetoperformtheinputandoutput?
Explain.
• HowmanythreadswillyoucreatefortheCPU-intensiveportionof
theapplication?Explain.
4.17 Considerthefollowingcodesegment:
pid t pid;
pid = fork();
if (pid == 0) { /* child process */
fork();
thread create( . . .);
}
fork();
a. Howmanyuniqueprocessesarecreated?
b. Howmanyuniquethreadsarecreated?
4.18 As described in Section 4.7.2, Linux does not distinguish between pro-
cessesandthreads.Instead,Linuxtreatsbothinthesameway,allowinga
tasktobemoreakintoaprocessorathreaddependingonthesetofflags
passed to the clone() system call. However, other operating systems,
suchasWindows,treatprocessesandthreadsdifferently.Typically,such
systemsuseanotationinwhichthedatastructureforaprocesscontains
pointerstotheseparatethreadsbelongingtotheprocess.Contrastthese
twoapproachesformodelingprocessesandthreadswithinthekernel.
4.19 The program shown in Figure 4.23 uses the Pthreads API. What would
betheoutputfromtheprogramatLINE CandLINE P?
4.20 Consider a multicore system and a multithreaded program written
usingthemany-to-manythreadingmodel.Letthenumberofuser-level
threadsinthe programbegreaterthan the number ofprocessing cores
in the system. Discuss the performance implications of the following
scenarios.
a. Thenumberofkernelthreadsallocatedtotheprogramislessthan
thenumberofprocessingcores.
b. Thenumberofkernelthreadsallocatedtotheprogramisequalto
thenumberofprocessingcores.
c. The number of kernel threads allocated to the program is greater
than the number of processing cores but less than the number of
user-levelthreads.Exercises EX-10
#include <pthread.h>
#include <stdio.h>
int value = 0;
void *runner(void *param); /* the thread */
int main(int argc, char *argv[])
{
pid t pid;
pthread t tid;
pthread attr t attr;
pid = fork();
if (pid == 0) { /* child process */
pthread attr init(&attr);
pthread create(&tid,&attr,runner,NULL);
pthread join(tid,NULL);
printf("CHILD: value = %d",value); /* LINE C */
}
else if (pid > 0) { /* parent process */
wait(NULL);
printf("PARENT: value = %d",value); /* LINE P */
}
}
void *runner(void *param) {
value = 5;
pthread exit(0);
}
Figure4.22 CprogramforExercise4.19.
4.21 Pthreads provides an API for managing thread cancellation. The
pthread setcancelstate() function is used to set the cancellation
state.Itsprototypeappearsasfollows:
pthread setcancelstate(int state, int *oldstate)
The twopossible valuesfor the state are PTHREAD CANCEL ENABLE and
PTHREAD CANCEL DISABLE.
Using the code segment shown in Figure 4.24, provide examples of
two operations that would be suitable to perform between the calls to
disableandenablethreadcancellation.EX-11
int oldstate;
pthread setcancelstate(PTHREAD CANCEL DISABLE, &oldstate);
/* What operations would be performed here? */
pthread setcancelstate(PTHREAD CANCEL ENABLE, &oldstate);
Figure4.23 CprogramforExercise4.21.ProgrammingProblems P-23
Programming Problems
4.22 Writeamultithreadedprogramthatcalculatesvariousstatisticalvalues
for a list of numbers. This program will be passed a series of numbers
onthecommandlineandwillthencreatethreeseparateworkerthreads.
Onethreadwilldeterminetheaverageofthenumbers,thesecondwill
determine the maximum value, and the third will determine the mini-
mumvalue.Forexample,supposeyourprogramispassedtheintegers
90817895797285
Theprogramwillreport
The average value is 82
The minimum value is 72
The maximum value is 95
Thevariablesrepresentingtheaverage,minimum,andmaximumvalues
will be stored globally. The worker threads will set these values, and
the parent thread will output the values once the workers have exited.
(Wecouldobviouslyexpandthisprogrambycreatingadditionalthreads
that determine other statistical values, such as median and standard
deviation.)
4.23 Writeamultithreadedprogramthat outputsprimenumbers. This pro-
gram should work as follows: The user will run the program and will
enter a number on the command line. The program will then create a
separatethreadthatoutputsalltheprimenumberslessthanorequalto
thenumberenteredbytheuser.
4.24 AninterestingwayofcalculatingπistouseatechniqueknownasMonte
Carlo,whichinvolvesrandomization.Thistechniqueworksasfollows:
Suppose you have a circle inscribed within a square, as shown in
Figure4.25.(Assumethattheradiusofthiscircleis1.)
• First,generateaseriesofrandompointsassimple(x,y)coordinates.
ThesepointsmustfallwithintheCartesiancoordinatesthatbound
thesquare.Ofthetotalnumberofrandompointsthataregenerated,
somewilloccurwithinthecircle.
• Next,estimateπbyperformingthefollowingcalculation:
π=4×(numberofpointsincircle)/(totalnumberofpoints)
Write a multithreaded version of this algorithm that creates a separate
thread to generate a number of random points. The thread will count
the number of points that occur within the circle and store that result
inaglobalvariable.Whenthisthreadhasexited,theparentthreadwill
calculateandoutputtheestimatedvalueofπ.Itisworthexperimenting
with the number of random points generated. As a general rule, the
greaterthenumberofpoints,theclosertheapproximationtoπ.P-24 Chapter4 Threads&Concurrency
(−1, 1) (1, 1)
(0, 0)
(−1, −1) (1, −1)
Figure4.25 MonteCarlotechniqueforcalculatingπ.
In the source-code download for this text, you will find a sample
programthatprovidesatechniqueforgeneratingrandomnumbers,as
wellasdeterminingiftherandom(x,y)pointoccurswithinthecircle.
Readers interested in the details of the Monte Carlo method for
estimatingπshouldconsultthebibliographyattheendofthischapter.
InChapter6,wemodifythisexerciseusingrelevantmaterialfromthat
chapter.
4.25 RepeatExercise4.24,butinsteadofusingaseparatethreadtogenerate
random points,useOpenMPtoparallelizethegenerationofpoints.Be
carefulnottoplacethecalculationofπintheparallelregion,sinceyou
wanttocalculateπonlyonce.
4.26 Modify the socket-based date server (Figure 3.27) in Chapter 3 so that
theserverserviceseachclientrequestinaseparatethread.
4.27 The Fibonacci sequence is the series of numbers 0,1,1,2,3,5,8,.... For-
mally,itcanbeexpressedas:
fib =0
0
fib =1
1
fib =fib +fib
n n−1 n−2
Write a multithreaded program that generates the Fibonacci sequence.
This program should work as follows: On the command line, the user
willenterthenumberofFibonaccinumbersthattheprogramistogen-
erate.Theprogramwillthencreateaseparatethreadthatwillgenerate
theFibonaccinumbers,placingthesequenceindatathatcanbeshared
by the threads (an array is probably the most convenient data struc-
ture).Whenthethreadfinishesexecution,theparentthreadwilloutput
the sequence generated by the child thread. Because the parent thread
cannot begin outputting the Fibonacci sequence until the child thread
finishes,theparentthreadwillhavetowaitforthechildthreadtofinish.
UsethetechniquesdescribedinSection4.4tomeetthisrequirement.
4.28 ModifyprogrammingproblemExercise3.20fromChapter3,whichasks
youtodesignapidmanager.ThismodificationwillconsistofwritingaProgrammingProblems P-25
multithreadedprogramthattestsyoursolutiontoExercise3.20.Youwill
create a number of threads—for example, 100—and each thread will
request a pid, sleep for a random period of time, and then release the
pid.(Sleepingforarandomperiodoftimeapproximatesthetypicalpid
usageinwhichapidisassignedtoanewprocess,theprocessexecutes
and then terminates, and the pid is released on the process’s termina-
tion.) On UNIX and Linux systems, sleeping is accomplished through
thesleep()function,whichispassedanintegervaluerepresentingthe
numberofsecondstosleep.ThisproblemwillbemodifiedinChapter7.
4.29 Exercise 3.25 in Chapter 3 involves designing an echo server using the
Java threading API. This server is single-threaded, meaning that the
servercannotrespondtoconcurrentechoclientsuntilthecurrentclient
exits.ModifythesolutiontoExercise3.25sothattheechoserverservices
eachclientinaseparaterequest.
Programming Projects
Project 1—Sudoku Solution Validator
ASudoku puzzle uses a 9×9 grid in which each column and row, as well as
each of the nine 3 × 3 subgrids, must contain all of the digits 1 ⋅ ⋅ ⋅ 9. Figure
4.26 presents an example of a valid Sudoku puzzle. This project consists of
designing a multithreaded application that determines whether the solution
toaSudokupuzzleisvalid.
There are several different ways of multithreading this application. One
suggestedstrategyistocreatethreadsthatcheckthefollowingcriteria:
• Athreadtocheckthateachcolumncontainsthedigits1through9
• Athreadtocheckthateachrowcontainsthedigits1through9
6 2 4 5 3 9 1 8 7
5 1 9 7 2 8 6 3 4
8 3 7 6 1 4 2 9 5
1 4 3 8 6 5 7 2 9
9 5 8 2 4 7 3 6 1
7 6 2 3 9 1 4 5 8
3 7 1 9 5 6 8 4 2
4 9 6 1 8 2 5 7 3
2 8 5 4 7 3 9 1 6
Figure4.26 Solutiontoa9×9Sudokupuzzle.P-26 Chapter4 Threads&Concurrency
• Ninethreadstocheckthateachofthe3×3subgridscontainsthedigits1
through9
This would result in a total of eleven separate threads for validating a
Sudoku puzzle. However, you are welcome to create even more threads for
this project. For example,rather than creating one thread that checks all nine
columns,youcouldcreatenineseparatethreadsandhaveeachofthemcheck
onecolumn.
I.Passing Parametersto Each Thread
The parent thread will create the worker threads, passing each worker the
location that it must check in the Sudoku grid. This step will require passing
several parameters to each thread. The easiest approach is to create a data
structureusingastruct.Forexample,astructuretopasstherowandcolumn
whereathreadmustbeginvalidatingwouldappearasfollows:
/* structure for passing data to threads */
typedef struct
{
int row;
int column;
} parameters;
BothPthreadsandWindowsprogramswillcreateworkerthreadsusinga
strategysimilartothatshownbelow:
parameters *data = (parameters *) malloc(sizeof(parameters));
data->row = 1;
data->column = 1;
/* Now create the thread passing it data as a parameter */
The data pointer will be passed to either the pthread create() (Pthreads)
functionortheCreateThread()(Windows)function,whichinturnwillpass
itasaparametertothefunctionthatistorunasaseparatethread.
II.ReturningResultsto the ParentThread
Eachworkerthreadisassignedthetaskofdeterminingthevalidityofapartic-
ularregionoftheSudokupuzzle.Onceaworkerhasperformedthischeck,it
mustpassitsresultsbacktotheparent.Onegoodwaytohandlethisistocreate
an array of integer values that is visible to each thread. The ith index in this
array corresponds to the ith worker thread. If a worker sets its corresponding
valueto1,itisindicatingthatitsregionoftheSudokupuzzleisvalid.Avalue
of0indicatesotherwise.Whenallworkerthreadshavecompleted,theparent
threadcheckseachentryintheresultarraytodetermineiftheSudokupuzzle
isvalid.
Project 2—Multithreaded Sorting Application
Writeamultithreadedsortingprogramthatworksasfollows:Alistofintegers
isdividedintotwosmallerlistsofequalsize.Twoseparatethreads(whichweProgrammingProjects P-27
will term sorting threads) sort each sublist using a sorting algorithm of your
choice.Thetwosublistsarethenmergedbyathirdthread—amergingthread
—whichmergesthetwosublistsintoasinglesortedlist.
Becauseglobaldataaresharedacrossallthreads,perhapstheeasiestway
tosetupthedataistocreateaglobalarray.Eachsortingthreadwillworkon
one half of this array. Asecond global array of the same size as the unsorted
integerarraywillalsobeestablished.Themergingthreadwillthenmergethe
two sublists into this second array. Graphically, this program is structured as
inFigure4.27.
This programming project will require passing parameters to each of the
sortingthreads.Inparticular,itwillbenecessarytoidentifythestartingindex
fromwhicheachthreadistobeginsorting.RefertotheinstructionsinProject
1fordetailsonpassingparameterstoathread.
Theparentthreadwilloutputthesortedarrayonceallsortingthreadshave
exited.
Project 3—Fork-Join Sorting Application
Implement the preceding project (Multithreaded Sorting Application) using
Java’sfork-joinparallelismAPI.Thisprojectwillbedevelopedintwodifferent
versions.Eachversionwillimplementadifferentdivide-and-conquersorting
algorithm:
1. Quicksort
2. Mergesort
The Quicksort implementation will use the Quicksort algorithm for dividing
the list of elements to be sorted into a left half and a right half based on the
original list
7, 12, 19, 3, 18, 4, 2, 6, 15, 8
sorting sorting
thread shread
0 1
7, 12, 19, 3, 18 4, 2, 6, 15, 8
merge thread
2, 3, 4, 6, 7, 8, 12, 15, 18, 19
sorted list
Figure4.27 Multithreadedsorting.P-28 Chapter4 Threads&Concurrency
position of the pivot value. The Mergesort algorithm will divide the list into
two evenly sized halves. For both the Quicksort and Mergesort algorithms,
whenthelisttobe sortedfallswithinsomethresholdvalue(forexample,the
listissize100orfewer),directlyapplyasimplealgorithmsuchastheSelection
or Insertion sort. Most data structures texts describe these two well-known,
divide-and-conquersortingalgorithms.
TheclassSumTaskshowninSection4.5.2.1extendsRecursiveTask,which
is a result-bearing ForkJoinTask. As this assignment will involve sorting
the array that is passed to the task, but not returning any values, you will
instead create a class that extends RecursiveAction, a non result-bearing
ForkJoinTask(seeFigure4.19).
The objects passed to each sorting algorithm are required to implement
Java’s Comparable interface, and this will need to be reflected in the class
definition for each sorting algorithm. The source code download for this text
includesJavacodethatprovidesthefoundationsforbeginningthisproject.5
CHAPTER
CPU
Scheduling
CPUschedulingisthebasisofmultiprogrammedoperatingsystems.Byswitch-
ing the CPU among processes, the operating system can make the computer
moreproductive.Inthischapter,weintroducebasicCPU-schedulingconcepts
and present several CPU-scheduling algorithms, including real-time systems.
Wealsoconsidertheproblemofselectinganalgorithmforaparticularsystem.
InChapter4,weintroducedthreadstotheprocessmodel.Onmodernoper-
atingsystemsitiskernel-levelthreads—notprocesses—thatareinfactbeing
scheduledbythe operatingsystem.However,theterms"processscheduling"
and"threadscheduling"areoftenusedinterchangeably.Inthischapter,weuse
process scheduling when discussing general scheduling concepts and thread
schedulingtorefertothread-specificideas.
Similarly,inChapter1wedescribehow a coreis thebasic computational
unitofaCPU,andthataprocessexecutesonaCPU’s core.However,inmany
instancesinthischapter,whenweusethegeneralterminologyofscheduling
aprocessto"runon aCPU",we areimplyingthat theprocess isrunning ona
CPU’score.
CHAPTER OBJECTIVES
• DescribevariousCPUschedulingalgorithms.
• AssessCPUschedulingalgorithmsbasedonschedulingcriteria.
• Explaintheissuesrelatedtomultiprocessorandmulticorescheduling.
• Describevariousreal-timeschedulingalgorithms.
• Describe the scheduling algorithms used in the Windows, Linux, and
Solarisoperatingsystems.
• ApplymodelingandsimulationstoevaluateCPUschedulingalgorithms.
• DesignaprogramthatimplementsseveraldifferentCPUschedulingalgo-
rithms.
199200 Chapter5 CPUScheduling
5.1 Basic Concepts
InasystemwithasingleCPUcore,onlyoneprocesscanrunatatime.Others
mustwaituntiltheCPU’scoreisfreeandcanberescheduled.Theobjectiveof
multiprogrammingistohavesomeprocessrunningatalltimes,tomaximize
CPUutilization.Theideaisrelativelysimple.Aprocessisexecuteduntilitmust
wait, typically for the completion of some I/O request. In a simple computer
system, the CPU then just sits idle. All this waiting time is wasted; no useful
workisaccomplished.Withmultiprogramming,wetrytousethistimeproduc-
tively.Severalprocessesarekeptinmemoryatonetime.Whenoneprocesshas
towait,theoperatingsystemtakestheCPUawayfromthatprocessandgives
theCPUtoanotherprocess.Thispatterncontinues.Everytimeoneprocesshas
towait,anotherprocesscantakeoveruseoftheCPU.Onamulticoresystem,
thisconceptofkeepingtheCPUbusyisextendedtoallprocessingcoresonthe
system.
Scheduling of this kind is a fundamental operating-system function.
Almostallcomputerresourcesarescheduledbeforeuse.TheCPUis,ofcourse,
one of the primary computer resources. Thus, its scheduling is central to
operating-systemdesign.
(cid:129)
(cid:129)
(cid:129)
load store
add store CPU burst
read from file
wait for I/O I/O burst
store increment
index CPU burst
write to file
wait for I/O I/O burst
load store
add store CPU burst
read from file
wait for I/O I/O burst
(cid:129)
(cid:129)
(cid:129)
Figure5.1 AlternatingsequenceofCPUandI/Obursts.5.1 BasicConcepts 201
5.1.1 CPU–I/O Burst Cycle
ThesuccessofCPUschedulingdependsonanobservedpropertyofprocesses:
processexecutionconsistsofacycleofCPUexecutionandI/Owait.Processes
alternatebetweenthesetwostates.ProcessexecutionbeginswithaCPUburst.
ThatisfollowedbyanI/Oburst,whichisfollowedbyanotherCPUburst,then
anotherI/Oburst,andsoon.Eventually,thefinalCPUburstendswithasystem
requesttoterminateexecution(Figure5.1).
The durations of CPU bursts have been measured extensively. Although
they vary greatly from process to process and from computer to computer,
they tend to have a frequency curve similar to that shown in Figure 5.2. The
curve is generally characterized as exponential or hyperexponential, with a
large number of short CPU bursts and a small number of long CPU bursts.
An I/O-bound program typically has many short CPU bursts. A CPU-bound
programmighthaveafewlongCPUbursts.Thisdistributioncanbeimportant
whenimplementingaCPU-schedulingalgorithm.
5.1.2 CPU Scheduler
Whenever the CPU becomes idle,the operating system must select one of the
processesinthereadyqueuetobeexecuted.Theselectionprocessiscarriedout
by the CPU scheduler, which selects a process from the processes in memory
thatarereadytoexecuteandallocatestheCPUtothatprocess.
Notethatthereadyqueueisnotnecessarilyafirst-in,first-out(FIFO)queue.
Asweshallseewhenweconsiderthevariousschedulingalgorithms,aready
queuecanbeimplementedasaFIFOqueue,apriorityqueue,atree,orsimply
anunorderedlinkedlist.Conceptually,however,alltheprocessesintheready
queuearelinedupwaitingforachancetorunontheCPU.Therecordsinthe
queuesaregenerallyprocesscontrolblocks(PCBs)oftheprocesses.
burst duration
ycneuqerf
Figure5.2 HistogramofCPU-burstdurations.202 Chapter5 CPUScheduling
5.1.3 Preemptive and Nonpreemptive Scheduling
CPU-scheduling decisions may take place under the following four circum-
stances:
1. Whenaprocessswitchesfromtherunningstatetothewaitingstate(for
example,astheresultofanI/Orequestoraninvocationofwait()forthe
terminationofachildprocess)
2. When a process switches from the running state to the ready state (for
example,whenaninterruptoccurs)
3. When a process switches from the waiting state to the ready state (for
example,atcompletionofI/O)
4. Whenaprocessterminates
Forsituations1and4,thereisnochoiceintermsofscheduling.Anewprocess
(if one exists in the ready queue) must be selected for execution. There is a
choice,however,forsituations2and3.
Whenschedulingtakesplaceonlyundercircumstances1and4,wesaythat
theschedulingschemeisnonpreemptiveorcooperative.Otherwise,itispre-
emptive. Under nonpreemptive scheduling, once the CPU has been allocated
toaprocess,theprocesskeepstheCPUuntilitreleasesiteitherbyterminating
or by switching to the waiting state. Virtually all modern operating systems
includingWindows,macOS,Linux,andUNIXusepreemptiveschedulingalgo-
rithms.
Unfortunately, preemptivescheduling can result in race conditions when
data are shared among several processes. Consider the case of two processes
that share data. While one process is updating the data, it is preempted so
that the second process can run. The second process then tries to read the
data, which are in an inconsistent state. This issue will be explored in detail
inChapter6.
Preemptionalsoaffectsthedesignoftheoperating-systemkernel.During
the processing of a system call, the kernel may be busy with an activity on
behalf of a process. Such activities may involve changing important kernel
data (for instance, I/O queues). What happens if the process is preempted
in the middle of these changes and the kernel (or the device driver) needs
to read or modify the same structure? Chaos ensues. As will be discussed in
Section6.2,operating-systemkernelscanbedesignedaseithernonpreemptive
orpreemptive.Anonpreemptivekernelwillwaitforasystemcalltocomplete
orforaprocesstoblockwhilewaitingforI/Otocompletetotakeplacebefore
doingacontextswitch.Thisschemeensuresthatthekernelstructureissimple,
sincethekernelwillnotpreemptaprocesswhilethekerneldatastructuresare
in an inconsistent state. Unfortunately, this kernel-execution model is a poor
oneforsupportingreal-timecomputing,wheretasksmustcompleteexecution
within a giventime frame. In Section 5.6, we explore scheduling demands of
real-time systems. A preemptive kernel requires mechanisms such as mutex
lockstopreventraceconditionswhenaccessingsharedkerneldatastructures.
Most modern operating systems are now fully preemptive when running in
kernelmode.5.1 BasicConcepts 203
P
0
executing
save state
into PCB
0
dispatch
latency
restore state
from PCB
1
P
1
executing
Figure5.3 Theroleofthedispatcher.
Becauseinterruptscan,bydefinition,occuratanytime,andbecausethey
cannotalwaysbeignoredbythekernel,thesectionsofcodeaffectedbyinter-
ruptsmustbeguardedfromsimultaneoususe.Theoperatingsystemneedsto
acceptinterruptsatalmostalltimes.Otherwise,inputmightbelostoroutput
overwritten. So that these sections of code are not accessed concurrently by
several processes, they disable interrupts at entry and reenable interrupts at
exit.Itisimportanttonotethatsectionsofcodethatdisableinterruptsdonot
occurveryoftenandtypicallycontainfewinstructions.
5.1.4 Dispatcher
AnothercomponentinvolvedintheCPU-schedulingfunctionisthedispatcher.
ThedispatcheristhemodulethatgivescontroloftheCPU’scoretotheprocess
selectedbytheCPUscheduler.Thisfunctioninvolvesthefollowing:
• Switchingcontextfromoneprocesstoanother
• Switchingtousermode
• Jumpingtotheproperlocationintheuserprogramtoresumethatprogram
Thedispatchershouldbeasfastaspossible,sinceitisinvokedduringevery
contextswitch.Thetimeittakesforthedispatchertostoponeprocessandstart
anotherrunningisknownasthedispatchlatencyandisillustratedinFigure
5.3.
An interesting question to consider is, how often do context switches
occur?Onasystem-widelevel,thenumberofcontextswitchescanbeobtained
byusingthevmstatcommandthatisavailableonLinuxsystems.Belowisthe
output(whichhasbeentrimmed)fromthecommand
vmstat 1 3204 Chapter5 CPUScheduling
Thiscommandprovides3linesofoutputovera1-seconddelay:
------cpu-----
24
225
339
Thefirstlinegivestheaveragenumber ofcontextswitchesover1second
since the system booted, and the next two lines give the number of context
switches over two 1-second intervals. Since this machine booted, it has aver-
aged 24 context switches per second. And in the past second, 225 context
switchesweremade,with339contextswitchesinthesecondpriortothat.
We can also use the /proc file system to determine the number of
context switches for a given process. For example, the contents of the file
/proc/2166/status will list various statistics for the process with pid =
2166.Thecommand
cat /proc/2166/status
providesthefollowingtrimmedoutput:
voluntary ctxt switches 150
nonvoluntary ctxt switches 8
This output shows the number of context switches over the lifetime of the
process. Notice the distinction between voluntary and nonvoluntary context
switches. A voluntary context switch occurs when a process has given up
control of the CPU because it requires a resource that is currently unavailable
(suchasblockingforI/O.)AnonvoluntarycontextswitchoccurswhentheCPU
hasbeentakenawayfromaprocess,suchaswhenitstimeslicehasexpiredor
ithasbeenpreemptedbyahigher-priorityprocess.
5.2 Scheduling Criteria
DifferentCPU-schedulingalgorithmshavedifferentproperties,andthechoice
of a particular algorithm may favor one class of processes over another. In
choosing which algorithm to use in a particular situation, we must consider
thepropertiesofthevariousalgorithms.
Many criteria have been suggested for comparing CPU-scheduling algo-
rithms.Whichcharacteristicsareusedforcomparisoncanmakeasubstantial
difference in which algorithm is judged to be best. The criteria include the
following:
• CPU utilization. We want to keep the CPU as busy as possible. Concep-
tually,CPUutilizationcanrangefrom0to100percent.Inarealsystem,it
should range from 40 percent (for a lightly loaded system) to 90 percent
(for a heavily loaded system). (CPU utilization can be obtained by using
thetopcommandonLinux,macOS,andUNIXsystems.)
• Throughput. If the CPU is busy executing processes, then work is being
done.Onemeasureofworkisthenumberofprocessesthatarecompleted5.3 SchedulingAlgorithms 205
per time unit, called throughput. For long processes, this rate may be
oneprocessoverseveralseconds;forshorttransactions,itmaybetensof
processespersecond.
• Turnaround time. From the point of view of a particular process, the
importantcriterionishowlongittakestoexecutethatprocess.Theinterval
from the time of submission of a process to the time of completion is the
turnaroundtime.Turnaroundtimeisthesumoftheperiodsspentwaiting
inthereadyqueue,executingontheCPU,anddoingI/O.
• Waiting time. The CPU-scheduling algorithm does not affect the amount
of time during which a process executes or does I/O. It affects only the
amountoftimethataprocessspendswaitinginthereadyqueue.Waiting
timeisthesumoftheperiodsspentwaitinginthereadyqueue.
• Response time. In an interactive system, turnaround time may not be
the best criterion. Often, a process can produce some output fairly early
andcancontinuecomputingnewresultswhilepreviousresultsarebeing
outputtotheuser.Thus,anothermeasureisthetimefromthesubmission
of a request until the first response is produced. This measure, called
responsetime,isthetimeittakestostartresponding,notthetimeittakes
tooutputtheresponse.
ItisdesirabletomaximizeCPUutilizationandthroughputandtominimize
turnaroundtime,waitingtime,andresponsetime.Inmostcases,weoptimize
theaveragemeasure.However,undersomecircumstances,weprefertoopti-
mizetheminimumormaximumvaluesratherthantheaverage.Forexample,
to guarantee that all users get good service, we may want to minimize the
maximumresponsetime.
Investigators have suggested that, for interactive systems (such as a PC
desktop or laptop system), it is more important to minimize the variance in
theresponsetimethantominimizetheaverageresponsetime.Asystemwith
reasonable and predictable response time may be considered more desirable
thanasystemthatisfasterontheaveragebutishighlyvariable.However,little
workhasbeendoneonCPU-schedulingalgorithmsthatminimizevariance.
AswediscussvariousCPU-schedulingalgorithmsinthefollowingsection,
we illustrate their operation. An accurate illustration should involve many
processes, each a sequence of several hundred CPU bursts and I/O bursts.
For simplicity, though, we consider only one CPU burst (in milliseconds) per
process in our examples. Our measure of comparison is the average waiting
time.MoreelaborateevaluationmechanismsarediscussedinSection5.8.
5.3 Scheduling Algorithms
CPUschedulingdealswiththeproblemofdecidingwhichoftheprocessesin
thereadyqueueistobeallocatedtheCPU’score.TherearemanydifferentCPU-
schedulingalgorithms.Inthissection,wedescribeseveralofthem.Although
most modern CPU architectures have multiple processing cores, we describe
these scheduling algorithms in the context of only one processing core avail-
able.Thatis,asingleCPUthathasasingleprocessingcore,thusthesystemis206 Chapter5 CPUScheduling
capable of only running one process at a time. In Section 5.5 we discuss CPU
schedulinginthecontextofmultiprocessorsystems.
5.3.1 First-Come, First-Served Scheduling
By far the simplest CPU-scheduling algorithm is the first-come first-serve
(FCFS) scheduling algorithm. With this scheme, the process that requests the
CPU first is allocated the CPU first. The implementation of the FCFS policy is
easilymanagedwithaFIFOqueue.Whenaprocessentersthereadyqueue,its
PCBislinkedontothetailofthequeue.WhentheCPUisfree,itisallocatedto
theprocessattheheadofthequeue.Therunningprocessisthenremovedfrom
thequeue.ThecodeforFCFSschedulingissimpletowriteandunderstand.
On the negative side, the average waiting time under the FCFS policy is
oftenquitelong.Considerthefollowingsetofprocessesthatarriveattime0,
withthelengthoftheCPUburstgiveninmilliseconds:
Process BurstTime
P 24
1
P 3
2
P 3
3
IftheprocessesarriveintheorderP ,P ,P ,andareservedinFCFSorder,
1 2 3
wegettheresultshowninthefollowingGanttchart,whichisabarchartthat
illustratesaparticularschedule,includingthestartandfinishtimesofeachof
theparticipatingprocesses:
P P P
1 2 3
0 24 27 30
The waiting time is 0 milliseconds for process P , 24 milliseconds for process
1
P , and 27 milliseconds for process P . Thus, the average waiting time is (0
2 3
+ 24 + 27)/3 = 17 milliseconds. If the processes arrive in the order P , P , P ,
2 3 1
however,theresultswillbeasshowninthefollowingGanttchart:
P P P
2 3 1
0 3 6 30
Theaveragewaitingtimeisnow(6+0+3)/3=3milliseconds.Thisreduction
issubstantial.Thus,theaveragewaitingtimeunderanFCFSpolicyisgenerally
notminimalandmayvarysubstantiallyiftheprocesses’CPUbursttimesvary
greatly.
In addition, consider the performance of FCFS scheduling in a dynamic
situation.AssumewehaveoneCPU-boundprocessandmanyI/O-boundpro-
cesses. As the processes flow around the system, the following scenario may
result.TheCPU-boundprocesswillgetandholdtheCPU.Duringthistime,all
the other processes will finish their I/O and will move into the ready queue,
waiting for the CPU. While the processes wait in the ready queue, the I/O5.3 SchedulingAlgorithms 207
devicesareidle.Eventually,theCPU-boundprocessfinishesitsCPUburstand
moves to an I/O device. All the I/O-bound processes, which have short CPU
bursts, execute quickly and move back to the I/O queues. At this point, the
CPUsitsidle.TheCPU-boundprocesswillthenmovebacktothereadyqueue
and be allocated the CPU. Again, all the I/O processes end up waiting in the
readyqueueuntiltheCPU-boundprocessisdone.Thereisaconvoyeffectas
alltheotherprocesseswaitfortheonebigprocesstogetofftheCPU.Thiseffect
resultsinlowerCPUanddeviceutilizationthanmightbepossibleiftheshorter
processeswereallowedtogofirst.
NotealsothattheFCFSschedulingalgorithm isnonpreemptive.Oncethe
CPUhasbeenallocatedtoaprocess,thatprocesskeepstheCPUuntilitreleases
theCPU,eitherbyterminatingorbyrequestingI/O.TheFCFSalgorithmisthus
particularly troublesome for interactive systems, where it is important that
eachprocessgetashareoftheCPUatregularintervals.Itwouldbedisastrous
toallowoneprocesstokeeptheCPUforanextendedperiod.
5.3.2 Shortest-Job-First Scheduling
AdifferentapproachtoCPUschedulingistheshortest-job-firs (SJF)schedul-
ing algorithm. This algorithm associates with each process the length of the
process’snextCPUburst.WhentheCPUisavailable,itisassignedtotheprocess
thathasthesmallestnextCPUburst.IfthenextCPUburstsoftwoprocessesare
the same, FCFS scheduling is used to break the tie. Note that a more appro-
priatetermforthisschedulingmethodwouldbetheshortest-next-CPU-burst
algorithm,becauseschedulingdependsonthelengthofthenextCPUburstof
aprocess,ratherthanitstotallength.WeusethetermSJFbecausemostpeople
andtextbooksusethistermtorefertothistypeofscheduling.
As an example of SJF scheduling, consider the following set of processes,
withthelengthoftheCPUburstgiveninmilliseconds:
Process BurstTime
P 6
1
P 8
2
P 7
3
P 3
4
Using SJF scheduling, we would schedule these processes according to the
followingGanttchart:
P P P P
4 1 3 2
0 3 9 16 24
The waiting time is 3 milliseconds for process P , 16 milliseconds for process
1
P , 9millisecondsfor processP ,and 0millisecondsforprocess P . Thus,the
2 3 4
averagewaitingtimeis(3+16+9+0)/4=7milliseconds.Bycomparison,if
we were using the FCFS scheduling scheme, the average waiting time would
be10.25milliseconds.
TheSJFschedulingalgorithmisprovablyoptimal,inthatitgivesthemini-
mumaveragewaitingtimeforagivensetofprocesses.Movingashortprocess208 Chapter5 CPUScheduling
before a long one decreases the waiting time of the short process more than
it increases the waiting time of the long process. Consequently, the average
waitingtimedecreases.
AlthoughtheSJFalgorithmisoptimal,itcannotbeimplementedatthelevel
ofCPUscheduling,asthereisnowaytoknowthelengthofthenextCPUburst.
OneapproachtothisproblemistotrytoapproximateSJFscheduling.Wemay
not know the length of the next CPU burst, but we may be able to predict its
value.WeexpectthatthenextCPUburstwillbesimilarinlengthtotheprevious
ones.BycomputinganapproximationofthelengthofthenextCPUburst,we
canpicktheprocesswiththeshortestpredictedCPUburst.
The next CPU burst is generally predicted as an exponential average of
the measured lengths of previous CPU bursts. We can define the exponential
averagewiththefollowingformula.Lett bethelengthofthenthCPUburst,
n
andletτ beourpredictedvalueforthenextCPUburst.Then,forα,0≤α≤
n+1
1,define
τ =αt +(1−α)τ .
n+1 n n
Thevalueof t contains our mostrecentinformation, whileτ storesthepast
n n
history.Theparameterαcontrolstherelativeweightofrecentandpasthistory
in our prediction. If α = 0, then τ = τ , and recent history has no effect
n+1 n
(current conditions are assumed to be transient). If α = 1, then τ = t , and
n+1 n
only the most recent CPU burst matters (history is assumed to be old and
irrelevant). More commonly, α = 1/2, so recent history and past history are
equally weighted. The initial τ can be defined as a constant or as an overall
0
system average. Figure 5.4 shows an exponential average with α = 1/2 and
τ =10.
0
12
τ 10
i
8
t 6
i
4
2
time
…
CPU burst (t) 6 4 6 4 13 13 13
i
"guess" (τ) 10 8 6 6 5 9 11 12 …
i
Figure5.4 PredictionofthelengthofthenextCPUburst.5.3 SchedulingAlgorithms 209
Tounderstandthebehavioroftheexponentialaverage,wecanexpandthe
formulaforτ bysubstitutingforτ tofind
n+1 n
τ =αt +(1 − α)αt +···+(1−α)jαt +···+(1−α)n+1τ .
n+1 n n−1 n−j 0
Typically, α is less than 1. As a result, (1 − α) is also less than 1, and each
successivetermhaslessweightthanitspredecessor.
TheSJFalgorithmcanbeeitherpreemptiveornonpreemptive.Thechoice
arises when a new process arrives at the ready queue while a previous pro-
cess is still executing. The next CPU burst of the newly arrived process may
be shorter than what is left of the currently executing process. Apreemptive
SJF algorithm will preempt the currently executing process, whereas a non-
preemptiveSJFalgorithmwillallowthecurrentlyrunningprocesstofinishits
CPUburst.PreemptiveSJFschedulingissometimescalledshortest-remaining-
time-firs scheduling.
As an example, consider the following four processes, with the length of
theCPUburstgiveninmilliseconds:
Process ArrivalTime BurstTime
P 0 8
1
P 1 4
2
P 2 9
3
P 3 5
4
If the processes arrive at the ready queue at the times shown and need the
indicatedbursttimes,thentheresultingpreemptiveSJFscheduleisasdepicted
inthefollowingGanttchart:
P P P P P
1 2 4 1 3
0 1 5 10 17 26
ProcessP isstartedattime0,sinceitistheonlyprocessinthequeue.Process
1
P arrives at time 1. The remaining time for process P (7 milliseconds) is
2 1
larger than the time required by process P (4 milliseconds), so process P is
2 1
preempted, and process P is scheduled. The average waiting time for this
2
exampleis[(10−1)+(1−1)+(17−2)+(5−3)]/4=26/4=6.5milliseconds.
NonpreemptiveSJFschedulingwouldresultinanaveragewaitingtimeof7.75
milliseconds.
5.3.3 Round-Robin Scheduling
Theround-robin(RR)schedulingalgorithmissimilartoFCFSscheduling,but
preemptionisaddedtoenablethesystemtoswitchbetweenprocesses.Asmall
unitoftime,calledatimequantumortimeslice,isdefined.Atimequantum
isgenerallyfrom10to100millisecondsinlength.Thereadyqueueistreatedas
a circular queue. The CPU scheduler goes around the ready queue, allocating
theCPUtoeachprocessforatimeintervalofupto1timequantum.
To implement RR scheduling, we again treat the ready queue as a FIFO
queue of processes. New processes are added to the tail of the ready queue.210 Chapter5 CPUScheduling
TheCPUschedulerpicksthefirstprocessfromthereadyqueue,setsatimerto
interruptafter1timequantum,anddispatchestheprocess.
Oneoftwothingswillthenhappen.TheprocessmayhaveaCPUburstof
less than 1 time quantum. In this case, the process itself will release the CPU
voluntarily. The scheduler will then proceed to the next process in the ready
queue.IftheCPUburstofthecurrentlyrunning processislongerthan1time
quantum, the timer will go off and will cause an interrupt to the operating
system. Acontext switch will be executed, and the process will be put at the
tailofthereadyqueue.TheCPUschedulerwillthenselectthenextprocessin
thereadyqueue.
The averagewaiting time under the RR policy is often long. Consider the
followingsetofprocessesthatarriveattime0,withthelengthoftheCPUburst
giveninmilliseconds:
Process BurstTime
P 24
1
P 3
2
P 3
3
If we use a time quantum of 4 milliseconds, then process P gets the first 4
1
milliseconds. Since it requires another 20 milliseconds, it is preempted after
thefirsttimequantum,andtheCPUisgiventothenextprocessinthequeue,
processP .ProcessP doesnotneed4milliseconds,soitquitsbeforeitstime
2 2
quantumexpires.TheCPUisthengiventothenextprocess,processP .Once
3
each process has received 1 time quantum, the CPU is returned to process P
1
foranadditionaltimequantum.TheresultingRRscheduleisasfollows:
P P P P P P P P
1 2 3 1 1 1 1 1
0 4 7 10 14 18 22 26 30
Let’s calculate the average waiting time for this schedule. P waits for 6 mil-
1
liseconds(10−4),P waitsfor4milliseconds,andP waitsfor7milliseconds.
2 3
Thus,theaveragewaitingtimeis17/3=5.66milliseconds.
In the RR scheduling algorithm, no process is allocated the CPU for more
than 1 time quantum in a row (unless it is the only runnable process). If a
process’sCPUburstexceeds1timequantum,thatprocessispreemptedandis
putbackinthereadyqueue.TheRRschedulingalgorithmisthuspreemptive.
Iftherearenprocessesinthereadyqueueandthetimequantumisq,then
eachprocessgets1/noftheCPUtimeinchunksofatmostqtimeunits.Each
processmustwaitnolongerthan(n−1)×q timeunitsuntilitsnexttimequan-
tum.Forexample,withfiveprocessesandatimequantumof20milliseconds,
eachprocesswillgetupto20millisecondsevery100milliseconds.
The performance of the RR algorithm depends heavily on the size of the
time quantum. At one extreme, if the time quantum is extremely large, the
RR policy is the same as the FCFS policy. In contrast, if the time quantum is
extremely small (say, 1 millisecond), the RR approach can result in a large5.3 SchedulingAlgorithms 211
process time = 10 quantum context
switches
12 0
0 10
6 1
0 10
6
1 9
0 1 2 3 4 5 6 7 8 9 10
Figure5.5 Howasmallertimequantumincreasescontextswitches.
number of context switches. Assume, for example, that we have only one
process of 10 time units. If the quantum is 12 time units, the process finishes
inlessthan1timequantum,withnooverhead.Ifthequantumis6timeunits,
however, the process requires 2 quanta, resulting in a context switch. If the
timequantumis1timeunit,thenninecontextswitcheswilloccur,slowingthe
executionoftheprocessaccordingly(Figure5.5).
Thus, we want the time quantum to be large with respect to the context-
switch time. If the context-switch time is approximately 10 percent of the
timequantum,thenabout 10percentoftheCPUtimewillbespentincontext
switching. In practice, most modern systems have time quanta ranging from
10to100milliseconds.Thetimerequiredforacontextswitchistypicallyless
than 10 microseconds; thus, the context-switch time is a small fraction of the
timequantum.
Turnaround time also depends on the size of the time quantum. As we
can see from Figure 5.6, the average turnaround time of a set of processes
does not necessarily improve as the time-quantum size increases. In general,
the average turnaround time can be improved if most processes finish their
next CPU burst in a single time quantum. For example, given three processes
of 10 time units each and a quantum of 1 time unit, the average turnaround
time is 29. If the time quantum is 10, however, the average turnaround time
drops to 20. If context-switch time is added in, the average turnaround time
increasesevenmoreforasmallertimequantum,sincemorecontextswitches
arerequired.
Although the time quantum should be large compared with the context-
switch time, it should not be too large. As we pointed out earlier, if the time
quantum is too large, RR scheduling degenerates to an FCFS policy. Arule of
thumb is that 80 percent of the CPU bursts should be shorter than the time
quantum.
5.3.4 Priority Scheduling
TheSJFalgorithmisaspecialcaseofthegeneralpriority-schedulingalgorithm.
A priority is associated with each process, and the CPU is allocated to the212 Chapter5 CPUScheduling
emit
dnuoranrut
egareva
process time
12.5
P 6
1
P 3
12.0 2
P 1
3
11.5 P 7
4
11.0
10.5
10.0
9.5
9.0
1 2 3 4 5 6 7
time quantum
Figure5.6 Howturnaroundtimevarieswiththetimequantum.
process with the highest priority. Equal-priority processes are scheduled in
FCFSorder.AnSJFalgorithmissimplyapriorityalgorithmwherethepriority
(p) is the inverse of the (predicted) next CPU burst. The larger the CPU burst,
thelowerthepriority,andviceversa.
Notethatwediscussschedulingintermsofhighpriorityandlowpriority.
Priorities are generally indicated by some fixed range of numbers, such as 0
to7or0to4,095.However,thereisnogeneralagreementonwhether0isthe
highest or lowest priority. Some systems use low numbers to represent low
priority;othersuselownumbersfor highpriority.Thisdifferencecan leadto
confusion.Inthistext,weassumethatlownumbersrepresenthighpriority.
As an example, consider the following set of processes, assumed to have
arrived at time 0 in the order P , P , ···, P , with the length of the CPU burst
1 2 5
giveninmilliseconds:
Process BurstTime Priority
P 10 3
1
P 1 1
2
P 2 4
3
P 1 5
4
P 5 2
5
Usingpriorityscheduling,wewouldscheduletheseprocessesaccordingtothe
followingGanttchart:5.3 SchedulingAlgorithms 213
P P P P P
2 5 1 3 4
0 1 6 16 18 19
Theaveragewaitingtimeis8.2milliseconds.
Prioritiescanbe definedeitherinternallyor externally.Internallydefined
prioritiesusesomemeasurablequantityorquantitiestocomputethepriority
of a process. For example, time limits, memory requirements, the number of
open files, and the ratio of average I/O burst to average CPU burst have been
usedincomputingpriorities.Externalprioritiesaresetbycriteriaoutsidethe
operatingsystem,suchastheimportanceoftheprocess,thetypeandamount
of funds being paid for computer use, the department sponsoring the work,
andother,oftenpolitical,factors.
Priority scheduling can be either preemptive or nonpreemptive. When a
processarrivesatthereadyqueue,itspriorityiscomparedwiththepriorityof
thecurrentlyrunningprocess.Apreemptivepriorityschedulingalgorithmwill
preempttheCPUifthepriorityofthenewlyarrivedprocessishigherthanthe
priorityofthecurrentlyrunningprocess.Anonpreemptivepriorityscheduling
algorithmwillsimplyputthenewprocessattheheadofthereadyqueue.
Amajorproblemwithpriorityschedulingalgorithmsisindefinit block-
ing, or starvation. Aprocess that is ready to run but waiting for the CPU can
be considered blocked. Apriority scheduling algorithm can leave some low-
priorityprocesseswaitingindefinitely.Inaheavilyloadedcomputersystem,a
steadystreamof higher-priorityprocessescan preventalow-priority process
from ever getting the CPU. Generally, one of two things will happen. Either
theprocesswilleventuallyberun(at2A.M.Sunday,whenthesystemisfinally
lightlyloaded),orthecomputersystemwilleventuallycrashandloseallunfin-
ishedlow-priorityprocesses.(RumorhasitthatwhentheyshutdowntheIBM
7094atMITin1973,theyfoundalow-priorityprocessthathadbeensubmitted
in1967andhadnotyetbeenrun.)
Asolutiontotheproblemofindefiniteblockageoflow-priorityprocessesis
aging.Aginginvolvesgraduallyincreasingthepriorityofprocessesthatwait
in the system for a long time. For example, if priorities range from 127 (low)
to 0 (high), we could periodically (say, every second) increase the priority of
a waiting process by 1. Eventually, even a process with an initial priority of
127would havethehighestpriorityinthesystemandwouldbe executed.In
fact,itwouldtakealittleover2minutesforapriority-127processtoagetoa
priority-0process.
Anotheroptionistocombineround-robinandpriorityschedulinginsuch
awaythatthesystemexecutesthehighest-priorityprocessandrunsprocesses
with the same priority using round-robin scheduling. Let’s illustrate with an
example using the following set of processes, with the burst time in millisec-
onds:
Process BurstTime Priority
P 4 3
1
P 5 2
2
P 8 2
3
P 7 1
4
P 3 3
5214 Chapter5 CPUScheduling
Usingpriorityschedulingwithround-robinforprocesseswithequalpriority,
we would schedule these processes according to the following Gantt chart
usingatimequantumof2milliseconds:
P P P P P P P P P P P
4 2 3 2 3 2 3 1 5 1 5
0 7 9 11 13 15 16 20 22 24 26 27
Inthisexample,processP hasthehighestpriority,soitwillruntocomple-
4
tion.ProcessesP andP havethenext-highestpriority,andtheywillexecutein
2 3
around-robinfashion.NoticethatwhenprocessP finishesattime16,process
2
P is the highest-priority process, so it will run until it completes execution.
3
Now, only processes P and P remain, and as they have equal priority, they
1 5
willexecuteinround-robinorderuntiltheycomplete.
5.3.5 Multilevel Queue Scheduling
With both priority and round-robin scheduling, all processes may be placed
in asingle queue,and the schedulerthen selectsthe process with the highest
priority to run. Depending on how the queues are managed, an O(n) search
may be necessary to determine the highest-priority process. In practice, it is
often easier to have separate queues for each distinct priority, and priority
scheduling simply schedules the process in the highest-priority queue. This
is illustrated in Figure 5.7. This approach—known as multilevel queue—
also works well when priority scheduling is combined with round-robin: if
therearemultipleprocessesinthehighest-priorityqueue,theyareexecutedin
round-robinorder.Inthemostgeneralizedformofthisapproach,apriorityis
assigned statically to each process, and a process remains in the same queue
forthedurationofitsruntime.
priority = 0 T T T T T
0 1 2 3 4
priority = 1 T T T
5 6 7
priority = 2 T T T T
8 9 10 11
priority = n T T T
x y z
Figure5.7 Separatequeuesforeachpriority.5.3 SchedulingAlgorithms 215
highest priority
real-time processes
system processes
interactive processes
batch processes
lowest priority
Figure5.8 Multilevelqueuescheduling.
A multilevel queue scheduling algorithm can also be used to partition
processes into several separate queues based on the process type (Figure
5.8). For example, a common division is made between foreground (interac-
tive) processes and background (batch) processes. These two types of pro-
cesses have different response-time requirements and so may have different
schedulingneeds.Inaddition,foregroundprocessesmayhavepriority(exter-
nallydefined)overbackgroundprocesses.Separatequeuesmightbeusedfor
foreground and background processes, and each queue might have its own
scheduling algorithm. The foreground queue might be scheduled by an RR
algorithm,forexample,whilethebackgroundqueueisscheduledbyanFCFS
algorithm.
In addition, there must be scheduling among the queues, which is com-
monlyimplementedasfixed-prioritypreemptivescheduling.Forexample,the
real-timequeuemayhaveabsolutepriorityovertheinteractivequeue.
Let’slookatanexampleofamultilevelqueueschedulingalgorithmwith
fourqueues,listedbelowinorderofpriority:
1. Real-timeprocesses
2. Systemprocesses
3. Interactiveprocesses
4. Batchprocesses
Eachqueuehasabsolutepriorityoverlower-priorityqueues.Noprocessinthe
batchqueue,forexample,couldrununlessthequeuesforreal-timeprocesses,
system processes, and interactive processes were all empty. If an interactive
processenteredthereadyqueuewhileabatchprocesswasrunning,thebatch
processwouldbepreempted.
Another possibility is to time-slice among the queues. Here, each queue
getsacertainportionoftheCPUtime,whichitcanthenscheduleamongitsvar-
ious processes. For instance, in the foreground–background queue example,
theforegroundqueuecanbegiven80percentoftheCPUtimeforRRscheduling216 Chapter5 CPUScheduling
among its processes, while the background queue receives 20 percent of the
CPUtogivetoitsprocessesonanFCFSbasis.
5.3.6 Multilevel Feedback Queue Scheduling
Normally,whenthemultilevelqueueschedulingalgorithmisused,processes
are permanently assigned to a queue when they enter the system. If there
are separate queues for foreground and background processes, for example,
processes do not move from one queue to the other, since processes do not
change theirforegroundor background nature.Thissetuphastheadvantage
oflowschedulingoverhead,butitisinflexible.
Themultilevelfeedbackqueueschedulingalgorithm,incontrast,allows
aprocesstomovebetweenqueues.Theideaistoseparateprocessesaccording
tothecharacteristicsoftheirCPUbursts.IfaprocessusestoomuchCPUtime,
itwillbemovedtoalower-priorityqueue.ThisschemeleavesI/O-boundand
interactive processes—which are typically characterized by short CPU bursts
—inthehigher-priorityqueues.Inaddition,aprocessthatwaitstoolongina
lower-priority queue may be moved to a higher-priority queue. This form of
agingpreventsstarvation.
For example, consider a multilevel feedback queue scheduler with three
queues, numbered from 0 to 2 (Figure 5.9). The scheduler first executes all
processes in queue 0. Only when queue 0 is empty will it execute processes
in queue 1. Similarly, processes in queue 2 will be executed only if queues 0
and 1are empty.Aprocess that arrivesfor queue1 will preempta processin
queue2.Aprocessinqueue1willinturnbepreemptedbyaprocessarriving
forqueue0.
Anenteringprocessisputinqueue0.Aprocessinqueue0isgivenatime
quantum of 8 milliseconds. If it does not finish within this time, it is moved
tothetailofqueue1.Ifqueue0isempty,theprocessattheheadofqueue1is
givenaquantumof16milliseconds.Ifitdoesnotcomplete,itispreemptedand
isputintoqueue2.Processesinqueue2arerunonanFCFSbasisbutarerun
onlywhenqueues0and1areempty.Topreventstarvation,aprocessthatwaits
toolonginalower-priorityqueuemaygraduallybemovedtoahigher-priority
queue.
quantum = 8
quantum = 16
FCFS
Figure5.9 Multilevelfeedbackqueues.5.4 ThreadScheduling 217
ThisschedulingalgorithmgiveshighestprioritytoanyprocesswithaCPU
burst of8millisecondsor less.Such aprocesswill quicklygetthe CPU, finish
its CPU burst, and go off to its next I/O burst. Processes that need more than
8 but less than 24 milliseconds are also served quickly, although with lower
priority than shorter processes. Long processes automatically sink to queue
2 and are served in FCFS order with any CPU cycles left over from queues 0
and1.
Ingeneral,amultilevelfeedbackqueueschedulerisdefinedbythefollow-
ingparameters:
• Thenumberofqueues
• Theschedulingalgorithmforeachqueue
• The method used to determine when to upgrade a process to a higher-
priorityqueue
• The method used to determine when to demote a process to a lower-
priorityqueue
• Themethodusedtodeterminewhichqueueaprocesswillenterwhenthat
processneedsservice
The definition of a multilevel feedback queue scheduler makes it the most
general CPU-scheduling algorithm. It can be configured to match a specific
system under design. Unfortunately, it is also the most complex algorithm,
sincedefiningthebestschedulerrequiressomemeansbywhichtoselectvalues
foralltheparameters.
5.4 Thread Scheduling
In Chapter 4, we introduced threads to the process model, distinguishing
between user-level and kernel-level threads. On most modern operating sys-
tems it is kernel-level threads—not processes—that are being scheduled by
theoperatingsystem.User-levelthreadsaremanagedbyathreadlibrary,and
the kernel is unaware of them. To run on a CPU, user-levelthreads must ulti-
matelybemappedtoanassociatedkernel-levelthread,althoughthismapping
may be indirect and may use a lightweight process (LWP). In this section, we
explore scheduling issues involving user-level and kernel-level threads and
offerspecificexamplesofschedulingforPthreads.
5.4.1 Contention Scope
One distinction between user-level and kernel-level threads lies in how they
are scheduled. On systems implementing the many-to-one (Section 4.3.1)
and many-to-many (Section 4.3.3) models, the thread library schedules user-
level threads to run on an available LWP. This scheme is known as process-
contention scope (PCS), since competition for the CPU takes place among
threadsbelongingtothesameprocess.(Whenwesaythethreadlibrarysched-
ules user threads onto available LWPs, we do not mean that the threads are
actually running on a CPU as that further requires the operating system to
schedule the LWP’s kernel thread onto a physical CPU core.) To decide which218 Chapter5 CPUScheduling
kernel-levelthreadtoscheduleontoaCPU,thekernelusessystem-contention
scope(SCS).CompetitionfortheCPUwithSCSschedulingtakesplaceamong
all threadsin the system.Systemsusing the one-to-one model(Section4.3.2),
suchasWindowsandLinuxschedulethreadsusingonlySCS.
Typically, PCS is done according to priority—the scheduler selects the
runnable thread with the highest priority to run. User-level thread priorities
aresetbytheprogrammerandarenotadjustedbythethreadlibrary,although
some thread libraries may allow the programmer to change the priority of
a thread. It is important to note that PCS will typically preempt the thread
currently running in favor of a higher-priority thread; however, there is no
guaranteeoftimeslicing(Section5.3.3)amongthreadsofequalpriority.
5.4.2 Pthread Scheduling
WeprovidedasamplePOSIX PthreadprograminSection4.4.1,along withan
introduction to thread creation with Pthreads. Now, we highlight the POSIX
PthreadAPIthatallowsspecifyingPCSorSCSduringthreadcreation.Pthreads
identifiesthefollowingcontentionscopevalues:
• PTHREAD SCOPE PROCESSschedulesthreadsusingPCSscheduling.
• PTHREAD SCOPE SYSTEMschedulesthreadsusingSCSscheduling.
On systems implementing the many-to-many model, the
PTHREAD SCOPE PROCESS policy schedules user-level threads onto available
LWPs.ThenumberofLWPsismaintainedbythethreadlibrary,perhapsusing
scheduleractivations(Section4.6.5).ThePTHREAD SCOPE SYSTEMscheduling
policywillcreateandbindanLWPforeachuser-levelthreadonmany-to-many
systems,effectivelymappingthreadsusingtheone-to-onepolicy.
ThePthreadIPC(InterprocessCommunication)providestwofunctionsfor
setting—andgetting—thecontentionscopepolicy:
• pthread attr setscope(pthread attr t *attr, int scope)
• pthread attr getscope(pthread attr t *attr, int *scope)
Thefirstparameterforbothfunctionscontainsapointertotheattributesetfor
thethread.Thesecondparameterforthepthread attr setscope()function
ispassedeitherthe PTHREAD SCOPE SYSTEM orthe PTHREAD SCOPE PROCESS
value, indicating how the contention scope is to be set. In the case of
pthread attr getscope(), this second parameter contains a pointer to an
int value that is set to the current value of the contention scope. If an error
occurs,eachofthesefunctionsreturnsanonzerovalue.
In Figure 5.10, we illustrate a Pthread scheduling API. The pro-
gram first determines the existing contention scope and sets it to
PTHREAD SCOPE SYSTEM. It then creates five separate threads that will
run using the SCS scheduling policy. Note that on some systems,only certain
contentionscopevaluesareallowed.Forexample,LinuxandmacOS systems
allowonlyPTHREAD SCOPE SYSTEM.5.4 ThreadScheduling 219
#include <pthread.h>
#include <stdio.h>
#define NUM THREADS 5
int main(int argc, char *argv[])
{
int i, scope;
pthread t tid[NUM THREADS];
pthread attr t attr;
/* get the default attributes */
pthread attr init(&attr);
/* first inquire on the current scope */
if (pthread attr getscope(&attr, &scope) != 0)
fprintf(stderr, "Unable to get scheduling scope∖n");
else {
if (scope == PTHREAD SCOPE PROCESS)
printf("PTHREAD SCOPE PROCESS");
else if (scope == PTHREAD SCOPE SYSTEM)
printf("PTHREAD SCOPE SYSTEM");
else
fprintf(stderr, "Illegal scope value.∖n");
}
/* set the scheduling algorithm to PCS or SCS */
pthread attr setscope(&attr, PTHREAD SCOPE SYSTEM);
/* create the threads */
for (i = 0; i < NUM THREADS; i++)
pthread create(&tid[i],&attr,runner,NULL);
/* now join on each thread */
for (i = 0; i < NUM THREADS; i++)
pthread join(tid[i], NULL);
}
/* Each thread will begin control in this function */
void *runner(void *param)
{
/* do some work ... */
pthread exit(0);
}
Figure5.10 PthreadschedulingAPI.220 Chapter5 CPUScheduling
5.5 Multi-Processor Scheduling
OurdiscussionthusfarhasfocusedontheproblemsofschedulingtheCPUina
systemwithasingleprocessingcore.IfmultipleCPUsareavailable,loadshar-
ing, where multiple threads may run in parallel, becomes possible, however
scheduling issuesbecome correspondinglymorecomplex.Many possibilities
have been tried; and as we saw with CPU scheduling with a single-core CPU,
thereisnoonebestsolution.
Traditionally, the term multiprocessor referred to systems that provided
multiplephysicalprocessors,whereeachprocessorcontainedonesingle-core
CPU.However,thedefinitionofmultiprocessorhasevolvedsignificantly,and
on modern computing systems, multiprocessor now applies to the following
systemarchitectures:
• MulticoreCPUs
• Multithreadedcores
• NUMAsystems
• Heterogeneousmultiprocessing
Here,wediscussseveralconcernsinmultiprocessorschedulinginthecon-
textofthesedifferentarchitectures.Inthefirstthreeexamplesweconcentrate
onsystemsinwhichtheprocessorsareidentical—homogeneous—intermsof
theirfunctionality.WecanthenuseanyavailableCPUtorunanyprocessinthe
queue. In the last example we explore a system where the processors are not
identicalintheircapabilities.
5.5.1 Approaches to Multiple-Processor Scheduling
OneapproachtoCPUschedulinginamultiprocessorsystemhasallscheduling
decisions, I/O processing, and other system activities handled by a single
processor — the master server. The other processors execute only user code.
Thisasymmetricmultiprocessingissimplebecauseonlyonecoreaccessesthe
system data structures, reducing the need for data sharing. The downfall of
thisapproachisthemasterserverbecomesapotentialbottleneckwhereoverall
systemperformancemaybereduced.
Thestandardapproachforsupportingmultiprocessorsissymmetricmul-
tiprocessing (SMP), where each processor is self-scheduling. Scheduling pro-
ceeds by having the scheduler for each processor examine the ready queue
and select a thread to run. Note that this providestwo possible strategies for
organizingthethreadseligibletobescheduled:
1. Allthreadsmaybeinacommonreadyqueue.
2. Eachprocessormayhaveitsownprivatequeueofthreads.
These two strategies are contrasted in Figure 5.11. If we select the first
option, we have a possible race condition on the shared ready queue and
thereforemustensurethattwoseparateprocessorsdonotchoosetoschedule
thesamethreadandthatthreadsarenotlostfromthequeue.Asdiscussedin5.5 Multi-ProcessorScheduling 221
T
0
T T
1 0
... T T T
T T T T 2 0 1
0 1 2 n
T T T
3 1 2
... ...
core core core core core core
0 1 n 0 1 n
common ready queue per-core run queues
(a) (b)
Figure5.11 Organizationofreadyqueues.
Chapter 6, we could use some form of locking to protect the common ready
queuefromthisracecondition.Lockingwouldbehighlycontended,however,
as all accesses to the queue would require lock ownership, and accessing the
shared queue would likely be a performance bottleneck. The second option
permits each processor to schedule threads from its private run queue and
therefore does not suffer from the possible performance problems associated
with a shared run queue. Thus, it is the most common approach on systems
supportingSMP.Additionally,asdescribedinSection5.5.4,havingprivate,per-
processorrunqueuesinfactmayleadtomoreefficientuseofcache memory.
Thereareissueswithper-processorrunqueues—mostnotably,workloadsof
varying sizes. However, as we shall see, balancing algorithms can be used to
equalizeworkloadsamongallprocessors.
VirtuallyallmodernoperatingsystemssupportSMP,includingWindows,
Linux, and macOS as well as mobile systems including Android and iOS. In
theremainderofthissection,wediscussissuesconcerningSMPsystemswhen
designingCPUschedulingalgorithms.
5.5.2 Multicore Processors
Traditionally,SMPsystemshaveallowedseveralprocessestoruninparallelby
providing multiple physical processors. However, most contemporary com-
puter hardware now places multiple computing cores on the same physical
chip, resultingin a multicoreprocessor. Each core maintains its architectural
state and thus appears to the operating system to be a separate logical CPU.
SMPsystemsthatusemulticoreprocessorsarefasterandconsumelesspower
thansystemsinwhicheachCPUhasitsownphysicalchip.
Multicore processors may complicate scheduling issues. Let’s consider
how this can happen. Researchers have discovered that when a processor
accessesmemory,itspendsasignificantamountoftimewaitingforthedatato
become available. This situation, known as a memory stall, occurs primarily
becausemodernprocessorsoperateatmuchfasterspeedsthanmemory.How-
ever, a memory stall can also occur because of a cache miss (accessing data
that are not in cache memory). Figure 5.12 illustrates a memory stall. In this
scenario,theprocessorcanspendupto50percentofitstimewaitingfordata
tobecomeavailablefrommemory.222 Chapter5 CPUScheduling
C compute cycle M memory stall cycle
thread
C M C M C M C M
time
Figure5.12 Memorystall.
To remedy this situation, many recent hardware designs have imple-
mented multithreaded processing cores in which two (or more) hardware
threadsareassignedtoeachcore.Thatway,ifonehardwarethreadstallswhile
waiting for memory, the core can switch to another thread. Figure 5.13 illus-
tratesadual-threadedprocessingcoreonwhichtheexecutionofthread0and
the executionof thread 1 are interleaved.From an operating system perspec-
tive,eachhardwarethreadmaintainsitsarchitecturalstate,suchasinstruction
pointerand registerset,and thus appearsas alogical CPU that isavailable to
runasoftwarethread.Thistechnique—knownaschipmultithreading(CMT)
—is illustrated in Figure 5.14. Here, the processor contains four computing
cores,witheachcorecontaining twohardwarethreads.Fromtheperspective
oftheoperatingsystem,thereareeightlogicalCPUs.
Intelprocessorsusethetermhyper-threading(alsoknownassimultane-
ousmultithreadingorSMT)todescribeassigningmultiplehardwarethreadsto
asingleprocessingcore.ContemporaryIntelprocessors—suchasthei7—sup-
porttwothreadspercore,whiletheOracleSparcM7processorsupportseight
threadspercore,witheightcoresperprocessor,thusprovidingtheoperating
systemwith64logicalCPUs.
In general, there are two ways to multithread a processing core: coarse-
grained and fine-graine multithreading. With coarse-grained multithread-
ing, a thread executes on a core until a long-latency event such as a memory
stall occurs. Because of the delay caused by the long-latency event, the core
mustswitchtoanotherthreadtobeginexecution.However,thecostofswitch-
ing between threads is high, since the instruction pipeline must be flushed
before the other thread can begin execution on the processor core. Once this
newthreadbeginsexecution,itbeginsfillingthepipelinewithitsinstructions.
Fine-grained (or interleaved) multithreading switches between threads at a
much finer level of granularity—typically at the boundary of an instruction
thread
1 C M C M C M C
thread
0 C M C M C M C
time
Figure5.13 Multithreadedmulticoresystem.5.5 Multi-ProcessorScheduling 223
processor
core 0 core 1
hardware thread hardware thread
hardware thread hardware thread
core core
2 3
hardware thread hardware thread
hardware thread hardware thread
operating system view
CPU 0 CPU 1 CPU 2 CPU 3
CPU CPU CPU CPU
4 5 6 7
Figure5.14 Chipmultithreading.
cycle.However,thearchitecturaldesignoffine-grainedsystemsincludeslogic
forthreadswitching.Asaresult,thecostofswitchingbetweenthreadsissmall.
Itisimportanttonotethattheresourcesofthephysicalcore(suchascaches
and pipelines) must be shared among its hardware threads, and therefore a
processingcorecanonlyexecuteonehardwarethreadatatime.Consequently,
a multithreaded,multicore processor actually requires two different levels of
scheduling,asshowninFigure5.15,whichillustratesadual-threadedprocess-
ingcore.
Ononelevelaretheschedulingdecisionsthatmustbemadebytheoper-
ating system as it chooses which software thread to run on each hardware
thread (logical CPU). For all practical purposes, such decisions have been the
primaryfocusofthischapter.Therefore,forthislevelofscheduling,theoper-
atingsystemmaychooseanyschedulingalgorithm,includingthosedescribed
inSection5.3.
Asecondlevelofschedulingspecifieshoweachcoredecideswhichhard-
warethreadtorun.Thereareseveralstrategiestoadoptinthissituation.One
approach is to use a simple round-robin algorithm to schedule a hardware
threadtotheprocessingcore.ThisistheapproachadoptedbytheUltraSPARC
T3.AnotherapproachisusedbytheIntelItanium,adual-coreprocessorwith
twohardware-managedthreadspercore.Assignedtoeachhardwarethreadis
a dynamic urgency value ranging from 0 to 7, with 0 representing the lowest
urgencyand7thehighest.TheItaniumidentifiesfivedifferenteventsthatmay224 Chapter5 CPUScheduling
software threads
level 1
hardware threads
(logical processors)
level 2
processing
core
Figure5.15 Twolevelsofscheduling.
triggerathreadswitch.Whenoneoftheseeventsoccurs,thethread-switching
logiccomparestheurgencyofthetwothreadsandselectsthethreadwiththe
highesturgencyvaluetoexecuteontheprocessorcore.
Note that the two different levels of scheduling shown in Figure 5.15 are
not necessarily mutually exclusive. In fact, if the operating system scheduler
(thefirstlevel)ismadeawareofthesharingofprocessorresources,itcanmake
more effective scheduling decisions. As an example, assume that a CPU has
twoprocessingcores,andeachcorehastwohardwarethreads.Iftwosoftware
threadsarerunningonthissystem,theycanberunningeitheronthesamecore
oronseparatecores.Iftheyarebothscheduledtorunonthesamecore,they
have toshare processor resourcesand thus arelikelytoproceedmore slowly
thaniftheywerescheduledonseparatecores.Iftheoperatingsystemisaware
ofthelevelofprocessorresourcesharing,itcanschedulesoftwarethreadsonto
logicalprocessorsthatdonotshareresources.
5.5.3 Load Balancing
On SMP systems, it is important to keep the workload balanced among all
processorstofullyutilizethebenefitsofhavingmorethanoneprocessor.Oth-
erwise,oneormoreprocessorsmaysitidlewhileother processorshavehigh
workloads,alongwithreadyqueuesofthreadsawaitingtheCPU.Loadbalanc-
ingattemptstokeeptheworkloadevenlydistributedacrossallprocessorsin
anSMPsystem.Itisimportanttonotethatloadbalancingistypicallynecessary
onlyonsystemswhereeachprocessorhasitsownprivatereadyqueueofeligi-
blethreadstoexecute.Onsystemswithacommonrunqueue,loadbalancing
isunnecessary,becauseonceaprocessorbecomesidle,itimmediatelyextracts
arunnablethreadfromthecommonreadyqueue.
There are two general approaches to load balancing: push migration and
pull migration. With push migration, a specific task periodically checks the
loadoneachprocessorand—ifitfindsanimbalance—evenlydistributesthe
load by moving (or pushing) threads from overloaded to idle or less-busy
processors.Pullmigrationoccurswhenanidleprocessorpullsawaitingtask
fromabusyprocessor.Pushandpullmigrationneednotbemutuallyexclusive
andare,infact,oftenimplementedinparallelonload-balancingsystems.For5.5 Multi-ProcessorScheduling 225
example, the Linux CFS scheduler (described in Section 5.7.1) and the ULE
scheduleravailableforFreeBSDsystemsimplementbothtechniques.
Theconceptofa“balancedload”mayhavedifferentmeanings.Oneview
ofabalancedloadmayrequiresimplythatallqueueshaveapproximatelythe
same number of threads. Alternatively, balance may require an equal distri-
butionofthreadprioritiesacrossallqueues.Inaddition,incertainsituations,
neitherofthesestrategiesmaybesufficient.Indeed,theymayworkagainstthe
goalsoftheschedulingalgorithm.(Weleavefurtherconsiderationofthisasan
exercise.)
5.5.4 Processor Affinity
Considerwhathappenstocachememorywhenathreadhasbeenrunningona
specificprocessor.Thedatamostrecentlyaccessedbythethreadpopulatethe
cachefortheprocessor.Asaresult,successivememoryaccessesbythethread
areoftensatisfiedincachememory(knownasa“warmcache”).Nowconsider
what happens if the thread migrates to another processor—say, due to load
balancing.Thecontentsofcachememorymustbeinvalidatedforthefirstpro-
cessor,andthecacheforthesecondprocessormustberepopulated.Becauseof
thehighcostofinvalidatingandrepopulatingcaches,mostoperatingsystems
withSMPsupporttrytoavoidmigratingathreadfromoneprocessortoanother
andinsteadattempttokeepathreadrunningonthesameprocessorandtake
advantage of a warm cache. This is known as processor affinit —that is, a
processhasanaffinityfortheprocessoronwhichitiscurrentlyrunning.
The two strategies described in Section 5.5.1 for organizing the queue of
threadsavailableforschedulinghaveimplicationsforprocessoraffinity.Ifwe
adopt the approach of a common ready queue, a thread may be selected for
executionbyanyprocessor.Thus,ifathreadisscheduledonanewprocessor,
thatprocessor’scachemustberepopulated.Withprivate,per-processorready
queues,athreadisalwaysscheduledonthesameprocessorandcantherefore
benefit from the contents of a warm cache. Essentially, per-processor ready
queuesprovideprocessoraffinityforfree!
Processor affinity takes several forms. When an operating system has a
policy of attempting to keep a process running on the same processor—but
notguaranteeingthatitwilldoso—wehaveasituationknownassoftaffinit .
Here,theoperatingsystemwillattempttokeepaprocessonasingleprocessor,
but it is possible for a process to migrate between processors during load
balancing. In contrast, some systems provide system calls that support hard
affinit ,therebyallowingaprocesstospecifyasubsetofprocessorsonwhichit
canrun.Manysystemsprovidebothsoftandhardaffinity.Forexample,Linux
implementssoftaffinity,butitalsoprovidesthesched setaffinity()system
call,whichsupportshardaffinitybyallowingathreadtospecifythesetofCPUs
onwhichitiseligibletorun.
The main-memory architecture of a system can affect processor affinity
issues as well. Figure 5.16 illustrates an architecture featuring non-uniform
memoryaccess(NUMA)wheretherearetwophysicalprocessorchipseachwith
their own CPU and local memory. Although a system interconnect allows all
CPUsinaNUMAsystemtoshareonephysicaladdressspace,aCPUhasfaster
accesstoitslocalmemorythantomemorylocaltoanotherCPU.Iftheoperating
system’sCPU scheduler and memory-placementalgorithms are NUMA-aware226 Chapter5 CPUScheduling
CPU CPU
fast access
slow
access fast access
memory memory
interconnect
Figure5.16 NUMAandCPUscheduling.
andworktogether,thenathreadthathasbeenscheduledontoaparticularCPU
canbeallocatedmemoryclosesttowheretheCPUresides,thusprovidingthe
threadthefastestpossiblememoryaccess.
Interestingly, load balancing often counteracts the benefits of processor
affinity.Thatis,thebenefitofkeepingathreadrunningonthesameprocessor
isthatthethreadcantakeadvantageofitsdatabeinginthatprocessor’scache
memory. Balancing loads by moving a thread from one processor to another
removes this benefit. Similarly, migrating a thread between processors may
incurapenaltyonNUMAsystems,whereathreadmaybemovedtoaprocessor
that requires longer memory access times. In other words, there is a natural
tension between load balancing and minimizing memory access times. Thus,
schedulingalgorithmsformodernmulticoreNUMAsystemshavebecomequite
complex.InSection5.7.1,weexaminetheLinuxCFSschedulingalgorithmand
explorehowitbalancesthesecompetinggoals.
5.5.5 Heterogeneous Multiprocessing
Intheexampleswehavediscussedsofar,allprocessorsareidenticalinterms
of their capabilities, thus allowing any thread to run on any processing core.
Theonlydifferencebeingthatmemoryaccesstimesmayvarybaseduponload
balancingandprocessoraffinitypolicies,aswellasonNUMAsystems.
Althoughmobilesystemsnowincludemulticorearchitectures,somesys-
temsarenowdesignedusingcoresthatrunthesameinstructionset,yetvary
intermsoftheirclockspeedandpowermanagement,includingtheabilityto
adjust the power consumption of a core to the point of idling the core. Such
systemsareknownasheterogeneousmultiprocessing(HMP).Notethisisnot
a form of asymmetric multiprocessing as described in Section 5.5.1 as both
systemandusertaskscanrunonanycore.Rather,theintentionbehindHMPis
tobettermanagepowerconsumptionbyassigningtaskstocertaincoresbased
uponthespecificdemandsofthetask.
For ARM processors that support it, this type of architecture is known
as big.LITTLE where higher-peformance big cores are combined with energy
efficientLITTLEcores.Big coresconsumegreaterenergyandthereforeshould5.6 Real-TimeCPUScheduling 227
only be used for short periods of time. Likewise, little cores use less energy
andcanthereforebeusedforlongerperiods.
Thereareseveraladvantagestothisapproach.Bycombininganumberof
slower cores with faster ones, a CPU scheduler can assign tasks that do not
require high performance, but may need to run for longer periods, (such as
backgroundtasks)tolittlecores,therebyhelpingtopreserveabatterycharge.
Similarly, interactive applications which require more processing power, but
may run for shorter durations, can be assigned to big cores. Additionally, if
the mobile device is in a power-saving mode, energy-intensive big cores can
bedisabledandthesystemcanrelysolelyonenergy-efficientlittlecores.Win-
dows10supportsHMPschedulingbyallowingathreadtoselectascheduling
policythatbestsupportsitspowermanagementdemands.
5.6 Real-Time CPU Scheduling
CPU scheduling for real-time operating systems involves special issues. In
general,wecandistinguishbetweensoftreal-timesystemsandhardreal-time
systems. Soft real-time systems provide no guarantee as to when a critical
real-timeprocesswillbescheduled.Theyguaranteeonlythattheprocesswill
be given preference over noncritical processes. Hard real-time systems have
stricterrequirements.Ataskmustbeservicedbyitsdeadline;serviceafterthe
deadlinehasexpiredisthesameasnoserviceatall.Inthissection,weexplore
several issues related to process scheduling in both soft and hard real-time
operatingsystems.
5.6.1 Minimizing Latency
Considertheevent-drivennatureofareal-timesystem.Thesystemistypically
waitingforaneventinrealtimetooccur.Eventsmayariseeitherinsoftware
—as when a timer expires—or in hardware—as when a remote-controlled
vehicle detects that it is approaching an obstruction. When an event occurs,
the system must respond to and service it as quickly as possible. We refer to
eventlatencyastheamountoftimethatelapsesfromwhenaneventoccursto
whenitisserviced(Figure5.17).
event E first occurs
event latency
t t
0 1
real-time system responds to E
Time
Figure5.17 Eventlatency.228 Chapter5 CPUScheduling
Usually,differenteventshavedifferentlatencyrequirements.Forexample,
thelatencyrequirementforanantilockbrakesystemmightbe3to5millisec-
onds. That is, from the time a wheel first detects that it is sliding, the system
controllingtheantilockbrakeshas3to5millisecondstorespondtoandcontrol
thesituation.Anyresponsethattakeslongermightresultintheautomobile’s
veeringoutofcontrol.Incontrast,anembeddedsystemcontrollingradarinan
airlinermighttoleratealatencyperiodofseveralseconds.
Twotypesoflatenciesaffecttheperformanceofreal-timesystems:
1. Interruptlatency
2. Dispatchlatency
Interruptlatencyreferstotheperiodoftimefromthearrivalofaninterrupt
at the CPU to the start of the routine that services the interrupt. When an
interruptoccurs,theoperatingsystemmustfirstcompletetheinstructionitis
executinganddeterminethetypeofinterruptthatoccurred.Itmustthensave
thestateofthecurrentprocessbeforeservicingtheinterruptusingthespecific
interruptserviceroutine(ISR).Thetotaltimerequiredtoperformthesetasksis
theinterruptlatency(Figure5.18).
Obviously, it is crucial for real-time operating systems to minimize inter-
ruptlatencytoensurethatreal-timetasksreceiveimmediateattention.Indeed,
forhardreal-timesystems,interruptlatencymustnotsimplybeminimized,it
mustbeboundedtomeetthestrictrequirementsofthesesystems.
One important factor contributing to interrupt latency is the amount
of time interrupts may be disabled while kernel data structures are being
updated. Real-time operating systems require that interrupts be disabled for
onlyveryshortperiodsoftime.
The amount of time required for the scheduling dispatcher to stop one
process and start another is known as dispatch latency. Providing real-time
interrupt
determine
task T running interrupt
type
context
switch
ISR
interrupt
latency
time
Figure5.18 Interruptlatency.5.6 Real-TimeCPUScheduling 229
event response to event
response interval
process made
interrupt available
processing
dispatch latency
real-time
process
execution
conflicts dispatch
time
Figure5.19 Dispatchlatency.
tasks with immediate access to the CPU mandates that real-time operating
systemsminimizethislatencyaswell.Themosteffectivetechniqueforkeeping
dispatch latency low is to provide preemptive kernels. For hard real-time
systems,dispatchlatencyistypicallymeasuredinseveralmicroseconds.
In Figure 5.19, we diagram the makeup of dispatch latency. The conflic
phaseofdispatchlatencyhastwocomponents:
1. Preemptionofanyprocessrunninginthekernel
2. Releasebylow-priorityprocessesofresourcesneededbyahigh-priority
process
Following the conflict phase, the dispatch phase schedules the high-priority
processontoanavailableCPU.
5.6.2 Priority-Based Scheduling
Themostimportantfeatureofareal-timeoperatingsystemistorespondimme-
diately to a real-time process as soon as that process requires the CPU. As a
result,theschedulerforareal-timeoperatingsystemmustsupportapriority-
basedalgorithmwithpreemption.Recallthatpriority-basedschedulingalgo-
rithmsassigneachprocessaprioritybasedonitsimportance;moreimportant
tasks are assigned higher priorities than those deemed less important. If the
scheduler also supports preemption, a process currently running on the CPU
willbepreemptedifahigher-priorityprocessbecomesavailabletorun.
Preemptive,priority-basedschedulingalgorithmsarediscussedindetailin
Section5.3.4, and Section 5.7 presentsexamples of the soft real-timeschedul-
ing features of the Linux, Windows, and Solaris operating systems. Each of
thesesystemsassigns real-timeprocessesthe highest scheduling priority.For230 Chapter5 CPUScheduling
p p p
d d d
t t t
Time
period period period
1 2 3
Figure5.20 Periodictask.
example,Windowshas32differentprioritylevels.Thehighestlevels—priority
values16to31—are reservedfor real-timeprocesses.Solarisand Linuxhave
similarprioritizationschemes.
Note that providing a preemptive,priority-based scheduler only guaran-
teessoftreal-timefunctionality.Hardreal-timesystemsmustfurtherguarantee
thatreal-timetaskswillbeservicedinaccordwiththeirdeadlinerequirements,
and making such guarantees requires additional scheduling features. In the
remainderofthissection,wecoverschedulingalgorithmsappropriateforhard
real-timesystems.
Beforeweproceedwiththedetailsoftheindividualschedulers,however,
wemustdefinecertaincharacteristicsoftheprocessesthataretobescheduled.
First, the processes are considered periodic. That is, they require the CPU at
constant intervals (periods). Once a periodic process has acquired the CPU, it
hasafixedprocessingtimet,adeadlinedbywhichitmustbeservicedbythe
CPU,andaperiodp.Therelationshipoftheprocessingtime,thedeadline,and
theperiodcanbeexpressedas0 ≤t≤d≤p.Therateofaperiodictaskis1∕p.
Figure5.20illustratestheexecutionofaperiodicprocessovertime.Schedulers
cantakeadvantageofthesecharacteristicsandassignprioritiesaccordingtoa
process’sdeadlineorraterequirements.
Whatisunusualaboutthisformofschedulingisthataprocessmayhaveto
announceitsdeadlinerequirementstothescheduler.Then,usingatechnique
known as an admission-control algorithm, the scheduler does one of two
things.Iteitheradmitstheprocess,guaranteeingthattheprocesswillcomplete
ontime,orrejectstherequestasimpossibleifitcannotguaranteethatthetask
willbeservicedbyitsdeadline.
5.6.3 Rate-Monotonic Scheduling
The rate-monotonic scheduling algorithm schedules periodic tasks using a
static priority policy with preemption. If a lower-priority process is run-
ning and a higher-priority process becomes available to run, it will preempt
the lower-priority process. Upon entering the system, each periodic task is
assigned a priority inversely based on its period. The shorter the period, the
higherthepriority;thelongertheperiod,thelowerthepriority.Therationale
behind this policy is to assign a higher priority to tasks that require the CPU
moreoften.Furthermore,rate-monotonicschedulingassumesthattheprocess-5.6 Real-TimeCPUScheduling 231
deadlines P P , P
1 1 2
P P
2 1
0 10 20 30 40 50 60 70 80 90 100 110 120
Figure5.21 SchedulingoftaskswhenP hasahigherprioritythanP .
2 1
ingtimeofaperiodicprocessisthesameforeachCPUburst.Thatis,everytime
aprocessacquirestheCPU,thedurationofitsCPUburstisthesame.
Let’sconsideranexample.Wehavetwoprocesses,P andP .Theperiods
1 2
forP andP are50and100,respectively—thatis,p = 50andp = 100.The
1 2 1 2
processing times are t = 20 for P and t = 35 for P . The deadline for each
1 1 2 2
processrequiresthatitcompleteitsCPUburstbythestartofitsnextperiod.
We must first ask ourselves whether it is possible to schedule these tasks
sothateachmeetsitsdeadlines.IfwemeasuretheCPUutilizationofaprocess
P as the ratio of its burst to its period—t∕p —the CPU utilization of P is
i i i 1
20∕50 = 0.40 and that of P is 35∕100 = 0.35, for a total CPU utilization of
2
75percent.Therefore,itseemswecanschedulethesetasksinsuchawaythat
bothmeettheirdeadlinesandstillleavetheCPUwithavailablecycles.
SupposeweassignP ahigherprioritythanP .TheexecutionofP andP
2 1 1 2
inthissituationisshowninFigure5.21.Aswecansee,P startsexecutionfirst
2
andcompletesattime35.Atthispoint,P starts;itcompletesitsCPUburstat
1
time55.However,thefirstdeadlineforP wasattime50,sotheschedulerhas
1
causedP tomissitsdeadline.
1
Now suppose we use rate-monotonic scheduling, in which we assign P
1
a higher priority than P because the period of P is shorter than that of P .
2 1 2
The execution of these processes in this situation is shown in Figure 5.22. P
1
starts first and completes its CPU burst at time 20, thereby meeting its first
deadline.P startsrunningatthispointandrunsuntiltime50.Atthistime,itis
2
preemptedbyP ,althoughitstillhas5millisecondsremaininginitsCPUburst.
1
P completesitsCPUburstattime70,atwhichpointtheschedulerresumesP .
1 2
P completesitsCPUburstattime75,alsomeetingitsfirstdeadline.Thesystem
2
isidleuntiltime100,whenP isscheduledagain.
1
Rate-monotonic scheduling is considered optimal in that if a set of pro-
cesses cannot be scheduled by this algorithm, it cannot be scheduled by any
other algorithm that assigns static priorities. Let’s next examine a set of pro-
cessesthatcannotbescheduledusingtherate-monotonicalgorithm.
AssumethatprocessP hasaperiodofp = 50andaCPUburstoft =25.
1 1 1
For P , the corresponding values are p = 80 and t = 35. Rate-monotonic
2 2 2
deadlines P P , P P P , P
1 1 2 1 1 2
P P P P P P P P
1 2 1 2 1 2 1 2
0 10 20 30 40 50 60 70 80 90 100 110 120130140150160170180190200
Figure5.22 Rate-monotonicscheduling.232 Chapter5 CPUScheduling
deadlines P P P P , P
1 2 1 1 2
P P P P
1 2 1 2
0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160
Figure5.23 Missingdeadlineswithrate-monotonicscheduling.
scheduling would assign process P a higher priority, as it has the shorter
1
period. The total CPU utilization of the two processes is (25∕50) + (35∕80) =
0.94,anditthereforeseemslogicalthatthetwoprocessescouldbescheduled
and still leave the CPU with 6 percent available time. Figure 5.23 shows the
scheduling of processesP and P . Initially,P runs until it completesits CPU
1 2 1
burstattime25.ProcessP thenbeginsrunningandrunsuntiltime50,when
2
itispreemptedbyP .Atthispoint,P stillhas10millisecondsremaininginits
1 2
CPUburst.ProcessP runsuntiltime75;consequently,P2finishesitsburstat
1
time85,afterthedeadlineforcompletionofitsCPUburstattime80.
Despite being optimal, then, rate-monotonic scheduling has a limitation:
CPU utilization is bounded, and it is not always possible to maximize CPU
resourcesfully.Theworst-caseCPUutilizationforschedulingNprocessesis
N(21∕N−1).
With one process in the system, CPU utilization is 100 percent, but it falls to
approximately69percentasthenumberofprocessesapproachesinfinity.With
twoprocesses,CPUutilizationisboundedatabout83percent.CombinedCPU
utilization for the two processes scheduled in Figure 5.21 and Figure 5.22 is
75 percent; therefore, the rate-monotonic scheduling algorithm is guaranteed
toschedulethemsothattheycanmeettheirdeadlines.Forthetwoprocesses
scheduled in Figure 5.23, combined CPU utilization is approximately 94 per-
cent; therefore, rate-monotonic scheduling cannot guarantee that they can be
scheduledsothattheymeettheirdeadlines.
5.6.4 Earliest-Deadline-First Scheduling
Earliest-deadline-firs (EDF)schedulingassignsprioritiesdynamicallyaccord-
ing to deadline.The earlier the deadline,the higher the priority; the later the
deadline,thelowerthepriority.UndertheEDFpolicy,whenaprocessbecomes
runnable,itmustannounceitsdeadlinerequirementstothesystem.Priorities
mayhavetobeadjustedtoreflectthedeadlineofthenewlyrunnableprocess.
Note how this differs from rate-monotonic scheduling, where priorities are
fixed.
To illustrate EDF scheduling, we again schedule the processes shown in
Figure5.23,whichfailedtomeetdeadlinerequirementsunderrate-monotonic
scheduling. Recall that P has values of p = 50 and t = 25 and that P has
1 1 1 2
valuesofp = 80andt = 35.TheEDFschedulingoftheseprocessesisshown
2 2
inFigure5.24.ProcessP hastheearliestdeadline,soitsinitialpriorityishigher
1
thanthatofprocessP .ProcessP beginsrunningattheendoftheCPUburst
2 2
forP .However,whereasrate-monotonicschedulingallowsP topreemptP
1 1 25.6 Real-TimeCPUScheduling 233
deadlines P P P P P
1 2 1 1 2
P P P P P P
1 2 1 2 1 2
0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160
Figure5.24 Earliest-deadline-firstscheduling.
at the beginning of its next period at time 50, EDF scheduling allows process
P tocontinue running. P now has a higher prioritythan P because itsnext
2 2 1
deadline(attime80)isearlierthanthatofP (attime100).Thus,bothP and
1 1
P meet their first deadlines. Process P again begins running at time 60 and
2 1
completesitssecondCPUburstattime85,alsomeetingitsseconddeadlineat
time 100. P begins running at this point, only to be preempted by P at the
2 1
start of its next period at time 100. P is preempted because P has an earlier
2 1
deadline(time150)thanP (time160).Attime125,P completesitsCPUburst
2 1
and P resumes execution, finishing at time 145 and meeting its deadline as
2
well.Thesystemisidleuntiltime150,whenP isscheduledtorunonceagain.
1
Unliketherate-monotonicalgorithm,EDFschedulingdoesnotrequirethat
processes be periodic, nor must a process require a constant amount of CPU
time per burst. The only requirement is that a process announce its deadline
to the scheduler when it becomes runnable. The appeal of EDF scheduling is
thatitistheoreticallyoptimal—theoretically,itcanscheduleprocessessothat
each process can meet its deadline requirements and CPU utilization will be
100 percent. In practice, however, it is impossible to achieve this levelof CPU
utilizationduetothecostofcontextswitchingbetweenprocessesandinterrupt
handling.
5.6.5 Proportional Share Scheduling
ProportionalshareschedulersoperatebyallocatingTsharesamongallappli-
cations. An application can receive N shares of time, thus ensuring that the
applicationwillhaveN∕T ofthetotalprocessortime.Asanexample,assume
thatatotalofT =100sharesistobedividedamongthreeprocesses,A,B,and
C.Aisassigned50shares,Bisassigned15shares,andCisassigned20shares.
ThisschemeensuresthatAwillhave50percentoftotalprocessortime,Bwill
have15percent,andCwillhave20percent.
Proportional share schedulers must work in conjunction with an
admission-controlpolicytoguaranteethatanapplicationreceivesitsallocated
shares of time. An admission-control policy will admit a client requesting
a particular number of shares only if sufficient shares are available. In our
current example, we have allocated 50 + 15 + 20 = 85 shares of the total of
100 shares. If a new process D requested 30 shares, the admission controller
woulddenyDentryintothesystem.
5.6.6 POSIX Real-Time Scheduling
The POSIX standard also provides extensions for real-time computing—
POSIX.1b.Here,wecoversomeofthePOSIXAPIrelatedtoschedulingreal-time
threads.POSIXdefinestwoschedulingclassesforreal-timethreads:234 Chapter5 CPUScheduling
• SCHED FIFO
• SCHED RR
SCHED FIFOschedulesthreadsaccordingtoafirst-come,first-servedpolicy
usingaFIFOqueueasoutlinedinSection5.3.1.However,thereisnotimeslic-
ing among threads of equal priority. Therefore, the highest-priority real-time
thread at the front of the FIFO queue will be granted the CPU until it termi-
natesorblocks.SCHED RRusesaround-robinpolicy.ItissimilartoSCHED FIFO
except that it provides time slicing among threads of equal priority. POSIX
provides an additional scheduling class—SCHED OTHER—but its implemen-
tationisundefinedandsystemspecific;itmaybehavedifferentlyondifferent
systems.
ThePOSIXAPIspecifiesthefollowingtwofunctionsforgettingandsetting
theschedulingpolicy:
• pthread attr getschedpolicy(pthread attr t *attr, int
*policy)
• pthread attr setschedpolicy(pthread attr t *attr, int
policy)
The first parameter to both functions is a pointer to the set of attributes for
the thread. The second parameter is either (1) a pointer to an integer that is
set tothe current scheduling policy (for pthread attr getsched policy())
or (2) an integer value (SCHED FIFO, SCHED RR, or SCHED OTHER) for the
pthread attr setsched policy() function. Both functions return nonzero
valuesifanerroroccurs.
In Figure 5.25, we illustratea POSIX Pthread program using this API. This
program first determines the current scheduling policy and then sets the
schedulingalgorithmtoSCHED FIFO.
5.7 Operating-System Examples
We turn next to a description of the scheduling policies of the Linux, Win-
dows, and Solaris operating systems. It is important to note that we use the
termprocessscheduling inageneralsensehere.Infact,wearedescribingthe
schedulingofkernel threadswithSolarisandWindows systemsandoftasks
withtheLinuxscheduler.
5.7.1 Example: Linux Scheduling
ProcessschedulinginLinuxhashadaninterestinghistory.PriortoVersion2.5,
theLinuxkernelranavariationofthetraditionalUNIXschedulingalgorithm.
However, as this algorithm was not designed with SMP systems in mind, it
did not adequately support systems with multiple processors. In addition, it
resultedinpoorperformanceforsystemswithalargenumberofrunnablepro-
cesses.WithVersion2.5ofthekernel,theschedulerwasoverhauledtoinclude
a scheduling algorithm—known as O(1)—that ran in constant time regard-
less of the number of tasks in the system. The O(1) scheduler also provided5.7 Operating-SystemExamples 235
#include <pthread.h>
#include <stdio.h>
#define NUM THREADS 5
int main(int argc, char *argv[])
{
int i, policy;
pthread t tid[NUM THREADS];
pthread attr t attr;
/* get the default attributes */
pthread attr init(&attr);
/* get the current scheduling policy */
if (pthread attr getschedpolicy(&attr, &policy) != 0)
fprintf(stderr, "Unable to get policy.∖n");
else {
if (policy == SCHED OTHER)
printf("SCHED OTHER∖n");
else if (policy == SCHED RR)
printf("SCHED RR∖n");
else if (policy == SCHED FIFO)
printf("SCHED FIFO∖n");
}
/* set the scheduling policy - FIFO, RR, or OTHER */
if (pthread attr setschedpolicy(&attr, SCHED FIFO) != 0)
fprintf(stderr, "Unable to set policy.∖n");
/* create the threads */
for (i = 0; i < NUM THREADS; i++)
pthread create(&tid[i],&attr,runner,NULL);
/* now join on each thread */
for (i = 0; i < NUM THREADS; i++)
pthread join(tid[i], NULL);
}
/* Each thread will begin control in this function */
void *runner(void *param)
{
/* do some work ... */
pthread exit(0);
}
Figure5.25 POSIXreal-timeschedulingAPI.236 Chapter5 CPUScheduling
increasedsupportforSMPsystems,including processoraffinity andloadbal-
ancingbetweenprocessors.However,inpractice,althoughtheO(1)scheduler
deliveredexcellentperformanceonSMPsystems,itledtopoorresponsetimes
fortheinteractiveprocessesthatarecommononmanydesktopcomputersys-
tems.Duringdevelopmentofthe2.6kernel,theschedulerwasagainrevised;
andinrelease2.6.23ofthekernel,theCompletelyFairScheduler(CFS)became
thedefaultLinuxschedulingalgorithm.
SchedulingintheLinuxsystemisbasedonschedulingclasses.Eachclass
isassignedaspecificpriority.Byusingdifferentschedulingclasses,thekernel
can accommodate different scheduling algorithms based on the needs of the
systemanditsprocesses.TheschedulingcriteriaforaLinuxserver,forexam-
ple,maybedifferentfromthoseforamobiledevicerunningLinux.Todecide
whichtasktorunnext,theschedulerselectsthehighest-prioritytaskbelong-
ingtothehighest-priorityschedulingclass.StandardLinuxkernelsimplement
twoschedulingclasses:(1)adefaultschedulingclassusingtheCFSscheduling
algorithmand(2)areal-timeschedulingclass.Wediscusseachoftheseclasses
here.Newschedulingclassescan,ofcourse,beadded.
Rather than using strict rules that associate a relative priority value with
the length of a time quantum, the CFS scheduler assigns a proportion of CPU
processing time to each task. This proportion is calculated based on the nice
value assigned to each task. Nice values range from −20 to +19, where a
numerically lower nice value indicates a higher relative priority. Tasks with
lowernicevaluesreceiveahigherproportionofCPUprocessingtimethantasks
withhighernicevalues.Thedefaultnicevalueis0.(Thetermnicecomesfrom
theideathatifataskincreasesitsnicevaluefrom,say,0to+10,itisbeingnice
toothertasksinthesystembyloweringitsrelativepriority.Inotherwords,nice
processesfinishlast!)CFSdoesn’tusediscretevaluesoftimeslicesandinstead
identifiesatargetedlatency, whichisanintervaloftimeduringwhichevery
runnable task should runat least once. Proportions of CPU time are allocated
fromthevalueoftargetedlatency.Inadditiontohavingdefaultandminimum
values,targetedlatencycanincreaseifthenumberofactivetasksinthesystem
growsbeyondacertainthreshold.
TheCFSschedulerdoesn’tdirectlyassignpriorities.Rather,itrecordshow
longeachtaskhasrunbymaintainingthevirtualruntimeofeachtaskusing
theper-taskvariablevruntime.Thevirtualruntimeisassociatedwithadecay
factor based on the priority of a task: lower-priority tasks have higher rates
of decay than higher-priority tasks. For tasks at normal priority (nice values
of 0), virtual run time is identical to actual physical run time. Thus, if a task
with default priority runs for 200 milliseconds, its vruntime will also be 200
milliseconds. However, if a lower-priority task runs for 200 milliseconds, its
vruntime will be higher than 200 milliseconds. Similarly, if a higher-priority
taskrunsfor200milliseconds,itsvruntimewillbelessthan200milliseconds.
Todecidewhichtasktorunnext,theschedulersimplyselectsthetaskthathas
thesmallestvruntimevalue.Inaddition,ahigher-prioritytaskthat becomes
availabletoruncanpreemptalower-prioritytask.
Let’s examine the CFS scheduler in action: Assume that two tasks have
the same nice values. One task is I/O-bound, and the other is CPU-bound.
Typically,theI/O-boundtaskwillrunonlyforshortperiodsbeforeblockingfor
additionalI/O,andtheCPU-boundtaskwillexhaustitstimeperiodwheneverit
hasanopportunitytorunonaprocessor.Therefore,thevalueofvruntimewill5.7 Operating-SystemExamples 237
CFSPERFORMANCE
TheLinuxCFSschedulerprovidesanefficientalgorithmforselectingwhich
task to run next. Rather than using a standard queue data structure, each
runnable task is placed in a red-black tree—a balanced binary search tree
whosekeyisbasedonthevalueofvruntime.Thistreeisshownbelow.
T
0
task with the smallest
T T
value of vruntime 1 2
T T T T
3 4 5 6
T T T
7 8 9
smaller larger
value of vruntime
When a task becomes runnable, it is added to the tree. If a task on the
treeisnotrunnable(forexample,ifitisblockedwhilewaitingforI/O),itis
removed.Generallyspeaking,tasksthathavebeengivenlessprocessingtime
(smaller values of vruntime) are toward the left side of the tree, and tasks
thathavebeengivenmoreprocessingtimeareontherightside.According
to the properties of a binary search tree, the leftmost node has the smallest
key value, which for the sake of the CFS scheduler meansthat it is the task
with thehighestpriority.Because thered-blacktreeis balanced,navigating
it to discover the leftmost node will require O(log N) operations (where N
is the number of nodes in the tree). However, for efficiency reasons, the
Linux scheduler caches this value in the variable rb leftmost, and thus
determiningwhichtasktorunnextrequiresonlyretrievingthecachedvalue.
eventuallybelowerfortheI/O-boundtaskthanfortheCPU-boundtask,giving
the I/O-bound task higher priority than the CPU-bound task. At that point, if
the CPU-bound task is executing when the I/O-bound task becomes eligible
to run (for example, when I/O the task is waiting for becomes available), the
I/O-boundtaskwillpreempttheCPU-boundtask.
Linux also implements real-time scheduling using the POSIX standard as
describedinSection5.6.6.AnytaskscheduledusingeithertheSCHED FIFOor
theSCHED RRreal-timepolicyrunsatahigherprioritythannormal(non-real-
time)tasks.Linuxusestwoseparatepriorityranges,oneforreal-timetasksand
asecondfornormaltasks.Real-timetasksareassignedstaticprioritieswithin
therangeof 0to99, andnormal tasksareassignedprioritiesfrom100to139.
Thesetworangesmapintoaglobalpriorityschemewhereinnumericallylower
valuesindicatehigherrelativepriorities.Normaltasksareassignedapriority238 Chapter5 CPUScheduling
real-time normal
0 99 100 139
higher lower
priority
Figure5.26 SchedulingprioritiesonaLinuxsystem.
basedontheirnicevalues,whereavalueof−20mapstopriority100andanice
valueof+19mapsto139.ThisschemeisshowninFigure5.26.
The CFS scheduler also supports load balancing, using a sophisticated
technique that equalizes the load among processing cores yet is also NUMA-
aware and minimizes the migration of threads. CFS defines the load of each
thread as a combination of the thread’s priority and its average rate of CPU
utilization.Therefore,athreadthathasahighpriority,yetismostlyI/O-bound
and requires little CPU usage, has a generally low load, similar to the load of
alow-prioritythreadthathashighCPUutilization.Usingthismetric,theload
ofaqueueisthesumoftheloadsofallthreadsinthequeue,andbalancingis
simplyensuringthatallqueueshaveapproximatelythesameload.
As highlighted in Section 5.5.4, however, migrating a thread may result
in a memory access penalty due to either having to invalidate cache con-
tentsor,onNUMAsystems,incurringlongermemoryaccesstimes.Toaddress
this problem, Linux identifies a hierarchical system of scheduling domains.
Ascheduling domain is a set of CPU cores that can be balanced against one
another. This idea is illustrated in Figure 5.27. The cores in each scheduling
domainaregroupedaccordingtohowtheysharetheresourcesofthesystem.
Forexample,althougheachcoreshowninFigure5.27mayhaveitsownlevel
1 (L1) cache, pairs of cores share a level 2 (L2) cache and are thus organized
into separate domain and domain . Likewise,these two domains may share a
0 1
level 3 (L3) cache, and are therefore organized into a processor-level domain
(alsoknownasaNUMAnode).Takingthisone-stepfurther,onaNUMAsystem,
physical processor domain
(NUMA node)
domain 0 domain 1
core 0 core 2
L2 L2
core 1 core 3
L3
Figure5.27 NUMA-awareloadbalancingwithLinuxCFSscheduler.5.7 Operating-SystemExamples 239
a larger system-level domain would combine separate processor-level NUMA
nodes.
ThegeneralstrategybehindCFSistobalanceloadswithindomains,begin-
ning at the lowest level of the hierarchy. Using Figure 5.27 as an example,
initially a thread would only migrate between cores on the same domain
(i.e.withindomain ordomain .)Loadbalancing atthenextlevelwouldoccur
0 1
betweendomain anddomain .CFSisreluctanttomigratethreadsbetweensep-
0 1
arateNUMAnodesifathreadwouldbemovedfartherfromitslocalmemory,
and such migration would only occur under severe load imbalances. As a
general rule, if the overall system is busy, CFS will not load-balance beyond
thedomainlocaltoeachcoretoavoidthememorylatencypenaltiesofNUMA
systems.
5.7.2 Example: Windows Scheduling
Windows schedules threads using a priority-based, preemptive scheduling
algorithm. The Windows scheduler ensures that the highest-priority thread
will always run. The portion of the Windows kernel that handles scheduling
is called the dispatcher. A thread selected to run by the dispatcher will run
until it is preempted by a higher-priority thread, until it terminates, until its
timequantumends,oruntilitcallsablockingsystemcall,suchasforI/O.Ifa
higher-priority real-time thread becomes ready while a lower-priority thread
isrunning,thelower-prioritythreadwillbepreempted.Thispreemptiongives
a real-time thread preferential access to the CPU when the thread needs such
access.
The dispatcher uses a 32-level priority scheme to determine the order of
thread execution. Priorities are divided into two classes. The variable class
containsthreadshavingprioritiesfrom1to15,andthereal-timeclasscontains
threadswithprioritiesrangingfrom16to31.(Thereisalsoathreadrunningat
priority0thatisusedformemorymanagement.)Thedispatcherusesaqueue
for each scheduling priority and traverses the set of queues from highest to
lowestuntil itfinds athreadthat isreadytorun. Ifno readythreadisfound,
thedispatcherwillexecuteaspecialthreadcalledtheidlethread.
There is a relationship between the numeric priorities of the Windows
kernel and the Windows API. The Windows API identifies the following six
priorityclassestowhichaprocesscanbelong:
• IDLE PRIORITY CLASS
• BELOW NORMALPRIORITY CLASS
• NORMALPRIORITY CLASS
• ABOVE NORMALPRIORITY CLASS
• HIGH PRIORITY CLASS
• REALTIME PRIORITY CLASS
Processes are typically members of the NORMALPRIORITY CLASS. A process
belongs to this class unless the parent of the process was a member of the
IDLE PRIORITY CLASS or unless another class was specified when the process
was created. Additionally, the priority class of a process can be altered with240 Chapter5 CPUScheduling
theSetPriorityClass()functionintheWindowsAPI.Prioritiesinallclasses
excepttheREALTIME PRIORITY CLASSarevariable,meaningthatthepriorityof
athreadbelongingtooneoftheseclassescanchange.
Athreadwithinagivenpriorityclassalsohasarelativepriority.Thevalues
forrelativeprioritiesinclude:
• IDLE
• LOWEST
• BELOW NORMAL
• NORMAL
• ABOVE NORMAL
• HIGHEST
• TIME CRITICAL
The priority of each thread is based on both the priority class it belongs
to and its relative priority within that class. This relationship is shown in
Figure 5.28. The values of the priority classes appear in the top row. The
left column contains the values for the relative priorities. For example, if the
relativepriorityofathreadintheABOVE NORMALPRIORITY CLASSisNORMAL,
thenumericpriorityofthatthreadis10.
Furthermore, each thread has a base priority representing a value in the
priority range for the class to which the thread belongs. By default, the base
priority is the value of the NORMAL relative priority for that class. The base
prioritiesforeachpriorityclassareasfollows:
• REALTIME PRIORITY CLASS—24
• HIGH PRIORITY CLASS—13
• ABOVE NORMALPRIORITY CLASS—10
• NORMALPRIORITY CLASS—8
real- above below idle
high normal
time normal normal priority
time-critical 31 15 15 15 15 15
highest 26 15 12 10 8 6
above normal 25 14 11 9 7 5
normal 24 13 10 8 6 4
below normal 23 12 9 7 5 3
lowest 22 11 8 6 4 2
idle 16 1 1 1 1 1
Figure5.28 Windowsthreadpriorities.5.7 Operating-SystemExamples 241
• BELOW NORMALPRIORITY CLASS—6
• IDLE PRIORITY CLASS—4
The initial priority of a thread is typically the base priority of the process
the thread belongs to, although the SetThreadPriority() function in the
WindowsAPIcanalsobeusedtomodifyathread’sbasepriority.
Whenathread’stimequantumrunsout,that threadisinterrupted.Ifthe
thread is in the variable-priority class, its priority is lowered. The priority is
never lowered below the base priority, however. Lowering the priority tends
to limit the CPU consumption of compute-bound threads. When a variable-
priority thread is released from a wait operation, the dispatcher boosts the
priority.Theamountoftheboostdependsonwhatthethreadwaswaitingfor.
For example, a thread waiting for keyboard I/O would get a large increase,
whereas a thread waiting for a disk operation would get a moderate one.
Thisstrategytendstogivegoodresponsetimestointeractivethreadsthatare
usingthemouseandwindows.ItalsoenablesI/O-boundthreadstokeepthe
I/O devices busy while permitting compute-bound threads to use spare CPU
cycles in the background. This strategy is used by severaloperating systems,
including UNIX. In addition, the window with which the user is currently
interactingreceivesapriorityboosttoenhanceitsresponsetime.
When a user is running an interactive program, the system needs to pro-
vide especially good performance. For this reason, Windows has a special
schedulingruleforprocessesintheNORMALPRIORITY CLASS.Windowsdistin-
guishesbetweentheforegroundprocessthatiscurrentlyselectedonthescreen
andthebackgroundprocessesthatarenotcurrentlyselected.Whenaprocess
moves into the foreground, Windows increases the scheduling quantum by
somefactor—typicallyby3.Thisincreasegivestheforegroundprocessthree
timeslongertorunbeforeatime-sharingpreemptionoccurs.
Windows7introduceduser-modescheduling(UMS),whichallowsappli-
cations to create and manage threads independently of the kernel. Thus, an
application can create and schedule multiple threads without involving the
Windows kernel scheduler. For applications that create a large number of
threads,scheduling threadsinusermodeis muchmore efficientthan kernel-
modethreadscheduling,asnokernelinterventionisnecessary.
Earlier versions of Windows provided a similar feature known as fiber ,
which allowed several user-mode threads (fibers) to be mapped to a single
kernelthread.However,fiberswereoflimitedpracticaluse.Afiberwasunable
to make calls to the Windows API because all fibers had to share the thread
environmentblock(TEB)ofthethreadonwhichtheywererunning.Thispre-
sentedaproblemifaWindowsAPIfunctionplacedstateinformationintothe
TEBforonefiber,onlytohavetheinformationoverwrittenbyadifferentfiber.
UMSovercomesthisobstaclebyprovidingeachuser-modethreadwithitsown
threadcontext.
In addition, unlike fibers, UMS is not intended to be used directly by the
programmer. The details of writing user-mode schedulers can be very chal-
lenging, and UMS does not include such a scheduler. Rather, the schedulers
come from programming language libraries that build on top of UMS. For
example, Microsoft provides Concurrency Runtime (ConcRT), a concurrent
programming framework for C++that is designedfor task-based parallelism242 Chapter5 CPUScheduling
(Section4.2)onmulticoreprocessors.ConcRTprovidesauser-modescheduler
together with facilitiesfor decomposing programsinto tasks, which can then
bescheduledontheavailableprocessingcores.
Windows also supports scheduling on multiprocessor systems as
described in Section 5.5 by attempting to schedule a thread on the most
optimalprocessingcoreforthatthread,whichincludesmaintainingathread’s
preferredaswellasmostrecentprocessor.OnetechniqueusedbyWindowsis
tocreatesetsoflogicalprocessors(knownasSMTsets).Onahyper-threaded
SMT system, hardware threads belonging to the same CPU core would also
belongtothesameSMTset.Logicalprocessorsarenumbered,beginningfrom
0. As an example, a dual-threaded/quad-core system would contain eight
logicalprocessors,consistingofthefourSMTsets:{0,1},{2,3},{4,5},and{6,
7}. To avoid cache memory access penalites highlighted in Section 5.5.4, the
schedulerattemptstomaintainathreadrunningonlogicalprocessorswithin
thesameSMTset.
To distribute loads across different logical processors, each thread is
assigned an ideal processor, which is a number representing a thread’s
preferred processor. Each process has an initial seed value identifying the
idealCPUfor athreadbelonging tothatprocess.Thisseedisincrementedfor
each new thread created by that process, thereby distributing the load across
differentlogical processors.On SMT systems,the increment for the next ideal
processor is in the next SMT set. For example, on a dual-threaded/quad-core
system,theidealprocessorsforthreadsinaspecificprocesswouldbeassigned
0,2,4,6,0,2,....Toavoidthesituationwherbythefirstthreadforeachprocess
is assigned processor 0, processes are assigned different seed values, thereby
distributing the load of threads across all physical processing cores in the
system.Continuing ourexamplefromabove,iftheseedforasecondprocess
were1,theidealprocessorswouldbeassignedintheorder1,3,5,7,1,3,and
soforth.
5.7.3 Example: Solaris Scheduling
Solaris uses priority-based thread scheduling. Each thread belongs to one of
sixclasses:
1. Timesharing(TS)
2. Interactive(IA)
3. Realtime(RT)
4. System(SYS)
5. Fairshare(FSS)
6. Fixedpriority(FP)
Within each class there are different priorities and different scheduling algo-
rithms.
Thedefaultschedulingclassforaprocessistimesharing.Thescheduling
policyforthetime-sharingclassdynamicallyaltersprioritiesandassignstime
slicesofdifferentlengthsusingamultilevelfeedbackqueue.Bydefault,there
is an inverse relationship between priorities and time slices. The higher the5.7 Operating-SystemExamples 243
time return
time quantum from
priority quantum expired sleep
0 200 0 50
5 200 0 50
10 160 0 51
15 160 5 51
20 120 10 52
25 120 15 52
30 80 20 53
35 80 25 54
40 40 30 55
45 40 35 56
50 40 40 58
55 40 45 58
59 20 49 59
Figure5.29 Solarisdispatchtablefortime-sharingandinteractivethreads.
priority, the smaller the time slice; and the lower the priority, the larger the
time slice. Interactive processes typically have a higher priority; CPU-bound
processes, a lower priority. This scheduling policy gives good response time
for interactive processes and good throughput for CPU-bound processes. The
interactiveclassusesthesameschedulingpolicyasthetime-sharingclass,but
itgiveswindowingapplications—suchasthosecreatedbytheKDEorGNOME
windowmanagers—ahigherpriorityforbetterperformance.
Figure5.29showsthesimplifieddispatchtableforschedulingtime-sharing
andinteractivethreads.Thesetwoschedulingclassesinclude60prioritylevels,
butforbrevity,wedisplayonlyahandful.(Toseethefulldispatchtableona
SolarissystemorVM,rundispadmin -c TS -g.)Thedispatchtableshownin
Figure5.29containsthefollowingfields:
• Priority.Theclass-dependentpriorityforthetime-sharingandinteractive
classes.Ahighernumberindicatesahigherpriority.
• Time quantum. The time quantum for the associated priority. This illus-
trates the inverse relationship between priorities and time quanta: the
lowest priority (priority 0) has the highest time quantum (200 millisec-
onds),andthehighestpriority(priority59)has thelowesttimequantum
(20milliseconds).
• Time quantum expired. The new priority of a thread that has used its
entiretimequantumwithoutblocking.SuchthreadsareconsideredCPU-
intensive. As shown in the table, these threads have their priorities low-
ered.244 Chapter5 CPUScheduling
• Returnfromsleep.Thepriorityofathreadthatisreturningfromsleeping
(suchasfromwaitingforI/O).Asthetableillustrates,whenI/Oisavailable
forawaitingthread,itspriorityisboostedtobetween50and59,support-
ingtheschedulingpolicyofprovidinggoodresponsetimeforinteractive
processes.
Threads in the real-time class are given the highest priority. A real-time
process will run before a process in any other class. This assignment allows
a real-time process to have a guaranteed response from the system within
a bounded period of time. In general, however, few processes belong to the
real-timeclass.
Solaris uses the system class to run kernel threads, such as the scheduler
andpagingdaemon.Oncethepriorityofasystemthreadisestablished,itdoes
notchange.Thesystemclassisreservedforkerneluse(userprocessesrunning
inkernelmodearenotinthesystemclass).
The fixed-priority and fair-share classes were introduced with Solaris 9.
Threads in the fixed-priority class have the same priority range as those in
thetime-sharingclass;however,theirprioritiesarenotdynamicallyadjusted.
The fair-share class uses CPU shares instead of priorities to make scheduling
decisions. CPU shares indicate entitlement to available CPU resources and are
allocatedtoasetofprocesses(knownasaproject).
Eachscheduling class includes asetofpriorities.However,the scheduler
convertstheclass-specificprioritiesintoglobalprioritiesandselectsthethread
with the highest global priority to run. The selected thread runs on the CPU
untilit(1)blocks,(2)usesitstimeslice,or(3)ispreemptedbyahigher-priority
thread.Iftherearemultiplethreadswiththesamepriority,thescheduleruses
a round-robin queue. Figure 5.30 illustrates how the six scheduling classes
relate to one another and how they map to global priorities. Notice that the
kernel maintains ten threads for servicing interrupts. These threads do not
belong to any scheduling class and execute at the highest priority (160–169).
Asmentioned,Solarishastraditionallyusedthemany-to-manymodel(Section
4.3.3) but switched to the one-to-one model (Section 4.3.2) beginning with
Solaris9.
5.8 Algorithm Evaluation
HowdoweselectaCPU-schedulingalgorithmforaparticularsystem?Aswe
saw in Section 5.3, there are many scheduling algorithms, each with its own
parameters.Asaresult,selectinganalgorithmcanbedifficult.
The first problem is defining the criteria to be used in selecting an algo-
rithm. As we saw in Section 5.2, criteria are often defined in terms of CPU
utilization, response time, or throughput. To select an algorithm, we must
firstdefinetherelativeimportanceoftheseelements.Ourcriteriamayinclude
severalmeasures,suchasthese:
• Maximizing CPU utilization under the constraint that the maximum
responsetimeis300milliseconds5.8 AlgorithmEvaluation 245
global scheduling
priority order
169
highest first
interrupt threads
160
159
realtime (RT) threads
100
99
system (SYS) threads
60
59
fair share (FSS) threads
fixed priority (FX) threads
timeshare (TS) threads
interactive (IA) threads
lowest 0 last
Figure5.30 Solarisscheduling.
• Maximizingthroughputsuchthatturnaroundtimeis(onaverage)linearly
proportionaltototalexecutiontime
Oncetheselectioncriteriahavebeendefined,wewanttoevaluatethealgo-
rithmsunderconsideration.Wenextdescribethevariousevaluationmethods
wecanuse.
5.8.1 Deterministic Modeling
Onemajorclassofevaluationmethodsisanalyticevaluation.Analyticevalu-
ationusesthegivenalgorithmandthesystemworkloadtoproduceaformula
ornumbertoevaluatetheperformanceofthealgorithmforthatworkload.
Deterministic modeling is one type of analytic evaluation. This method
takes a particular predetermined workload and defines the performance of
each algorithm for that workload. For example, assume that we have the
workloadshownbelow.Allfiveprocessesarriveattime0,intheordergiven,
withthelengthoftheCPUburstgiveninmilliseconds:246 Chapter5 CPUScheduling
Process BurstTime
P 10
1
P 29
2
P 3
3
P 7
4
P 12
5
Consider the FCFS, SJF, and RR (quantum = 10 milliseconds) scheduling algo-
rithms for this set of processes. Which algorithm would give the minimum
averagewaitingtime?
FortheFCFSalgorithm,wewouldexecutetheprocessesas
P P P P P
1 2 3 4 5
0 10 39 42 49 61
The waiting time is 0 milliseconds for process P , 10 milliseconds for process
1
P , 39 milliseconds for process P , 42 milliseconds for process P , and 49
2 3 4
milliseconds for process P . Thus, the average waiting time is (0 + 10 + 39 +
5
42+49)/5=28milliseconds.
WithnonpreemptiveSJFscheduling,weexecutetheprocessesas
P P P P P
3 4 1 5 2
0 3 10 20 32 61
Thewaitingtimeis10millisecondsforprocessP ,32millisecondsforprocess
1
P ,0millisecondsforprocessP ,3millisecondsforprocessP ,and20millisec-
2 3 4
ondsforprocessP .Thus,theaveragewaitingtimeis(10+32+0+3+20)/5
5
=13milliseconds.
WiththeRRalgorithm,weexecutetheprocessesas
P P P P P P P P
1 2 3 4 5 2 5 2
0 10 20 23 30 40 50 52 61
The waiting time is 0 milliseconds for process P , 32 milliseconds for process
1
P , 20 milliseconds for process P , 23 milliseconds for process P , and 40
2 3 4
milliseconds for process P . Thus, the average waiting time is (0 + 32 + 20 +
5
23+40)/5=23milliseconds.
Wecanseethat,inthiscase,theaveragewaitingtimeobtainedwiththeSJF
policy is less than half that obtained with FCFS scheduling; the RR algorithm
givesusanintermediatevalue.
Deterministicmodelingissimpleandfast.Itgivesusexactnumbers,allow-
ingustocomparethealgorithms.However,itrequiresexactnumbersforinput,
and its answers apply only to those cases. The main uses of deterministic
modeling are in describing scheduling algorithms and providing examples.
Incaseswherewearerunningthesameprogramoverandoveragainandcan5.8 AlgorithmEvaluation 247
measuretheprogram’sprocessingrequirementsexactly,wemaybeabletouse
deterministicmodelingtoselectaschedulingalgorithm. Furthermore,overa
setof examples,deterministicmodeling may indicate trendsthat can thenbe
analyzed and proved separately. For example, it can be shown that, for the
environment described (all processes and their times available at time 0), the
SJFpolicywillalwaysresultintheminimumwaitingtime.
5.8.2 Queueing Models
Onmanysystems,theprocessesthatarerunvaryfromdaytoday,sothereis
nostaticsetofprocesses(ortimes)tousefordeterministicmodeling.Whatcan
bedetermined,however,is thedistributionof CPUand I/Obursts.Thesedis-
tributions can be measuredand then approximatedor simply estimated.The
resultisamathematicalformuladescribingtheprobabilityofaparticularCPU
burst.Commonly,thisdistributionisexponentialandisdescribedbyitsmean.
Similarly, we can describe the distribution of times when processes arrive in
the system (the arrival-time distribution). From these two distributions, it is
possibletocomputetheaveragethroughput,utilization,waitingtime,andso
onformostalgorithms.
Thecomputersystemisdescribedasanetworkofservers.Eachserverhas
aqueueofwaitingprocesses.TheCPUisaserverwithitsreadyqueue,asisthe
I/Osystemwithitsdevicequeues.Knowingarrivalratesandservicerates,we
cancomputeutilization,averagequeuelength,averagewait time,andsoon.
Thisareaofstudyiscalledqueueing-networkanalysis.
Asanexample,letnbetheaveragelong-termqueuelength(excludingthe
process being serviced), let W be the average waiting time in the queue, and
letλbe theaveragearrivalratefornewprocessesinthe queue(such asthree
processespersecond).WeexpectthatduringthetimeWthataprocesswaits,
λ×Wnewprocesseswillarriveinthequeue.Ifthesystemisinasteadystate,
thenthenumberofprocessesleavingthequeuemustbeequaltothenumber
ofprocessesthatarrive.Thus,
n=λ×W.
This equation, known as Little’s formula, is particularly useful because it is
valid for any scheduling algorithm and arrival distribution. For example n
couldbethenumberofcustomersinastore.
We can use Little’s formula to compute one of the three variables if we
know the other two. For example, if we know that 7 processes arrive every
second (on average) and that there are normally 14 processes in the queue,
thenwecancomputetheaveragewaitingtimeperprocessas2seconds.
Queueinganalysiscanbeusefulincomparingschedulingalgorithms,but
italsohas limitations.Atthemoment,theclassesofalgorithmsand distribu-
tions that can be handled are fairly limited. The mathematics of complicated
algorithms and distributions can be difficult to work with. Thus, arrival and
servicedistributionsareoftendefinedinmathematicallytractable—butunre-
alistic—ways. It is also generally necessary to make a number of indepen-
dentassumptions,whichmaynotbeaccurate.Asaresultofthesedifficulties,
queueingmodelsareoftenonlyapproximationsofrealsystems,andtheaccu-
racyofthecomputedresultsmaybequestionable.248 Chapter5 CPUScheduling
5.8.3 Simulations
Togetamoreaccurateevaluationofschedulingalgorithms,wecanusesimu-
lations.Runningsimulationsinvolvesprogrammingamodelofthecomputer
system. Software data structures represent the major components of the sys-
tem.Thesimulatorhasavariablerepresentingaclock.Asthisvariable’svalue
is increased, the simulator modifies the system state to reflect the activities
of the devices, the processes, and the scheduler. As the simulation executes,
statisticsthatindicatealgorithmperformancearegatheredandprinted.
Thedatatodrivethesimulationcanbegeneratedinseveralways.Themost
common method uses a random-number generator that is programmed to
generateprocesses,CPUbursttimes,arrivals,departures,andsoon,according
to probability distributions. The distributions can be defined mathematically
(uniform,exponential,Poisson)orempirically.Ifadistributionistobedefined
empirically, measurements of the actual system under study are taken. The
resultsdefinethedistributionofeventsintherealsystem;thisdistributioncan
thenbeusedtodrivethesimulation.
Adistribution-drivensimulation may be inaccurate, however, because of
relationships between successive events in the real system. The frequency
distributionindicatesonlyhowmanyinstancesofeacheventoccur;itdoesnot
indicateanythingabouttheorderoftheiroccurrence.Tocorrectthisproblem,
we can use trace files. We create a trace by monitoring the real system and
recordingthesequenceofactualevents(Figure5.31).Wethenusethissequence
to drive the simulation. Trace files provide an excellent way to compare two
algorithms on exactly the same set of real inputs. This method can produce
accurateresultsforitsinputs.
Simulations can be expensive, often requiring many hours of computer
time. A more detailed simulation provides more accurate results, but it also
performance
simulation statistics
for FCFS
FCFS
(cid:129) (cid:129) (cid:129)
CPU 10
I/O 213
actual CPU 12 performance
process I/O 112 simulation statistics
execution CPU 2 for SJF
I/O 147
SJF
CPU 173
(cid:129) (cid:129) (cid:129)
trace tape
performance
simulation statistics
for RR (q = 14)
RR (q = 14)
Figure5.31 EvaluationofCPUschedulersbysimulation.5.8 AlgorithmEvaluation 249
takesmorecomputertime.Inaddition,tracefilescanrequirelargeamountsof
storagespace.Finally,thedesign,coding,anddebuggingofthesimulatorcan
beamajortask.
5.8.4 Implementation
Even a simulation is of limited accuracy. The only completely accurate way
to evaluate a scheduling algorithm is to code it up, put it in the operating
system,andseehowitworks.Thisapproachputstheactualalgorithminthe
realsystemforevaluationunderrealoperatingconditions.
Thismethodisnotwithoutexpense.Theexpenseisincurredincodingthe
algorithm and modifying the operating system to support it (along with its
required data structures). There is also cost in testing the changes, usually in
virtualmachinesratherthanondedicatedhardware.Regressiontestingcon-
firmsthatthechangeshaven’tmadeanythingworse,andhaven’tcausednew
bugs or caused old bugs to be recreated (for example because the algorithm
beingreplacedsolvedsomebugandchangingitcausedthatbugtoreoccur).
Another difficultyisthat theenvironmentinwhichthe algorithmisused
will change. The environment will change not only in the usual way, as new
programs are written and the types of problems change, but also as a result
oftheperformanceofthescheduler.Ifshortprocessesaregivenpriority,then
users may break larger processes into sets of smaller processes. If interactive
processes are given priority over noninteractive processes, then users may
switchtointeractiveuse.Thisproblemisusuallyaddressedbyusingtoolsor
scriptsthatencapsulatecompletesetsofactions,repeatedlyusingthosetools,
andusingthosetoolswhilemeasuringtheresults(anddetectinganyproblems
theycauseinthenewenvironment).
Ofcoursehumanorprogrambehaviorcanattempttocircumventschedul-
ing algorithms. For example, researchers designed one system that classi-
fied interactive and noninteractive processes automatically by looking at the
amount of terminal I/O. If a process did not input or output to the terminal
in a 1-second interval, the process was classified as noninteractive and was
movedtoa lower-priorityqueue.In response tothis policy, one programmer
modifiedhisprogramstowriteanarbitrarycharactertotheterminalatregular
intervalsoflessthan1second.Thesystemgavehisprogramsahighpriority,
eventhoughtheterminaloutputwascompletelymeaningless.
Ingeneral,mostflexibleschedulingalgorithmsarethosethatcanbealtered
by the system managers or by the users so that they can be tuned for a spe-
cific application or set of applications. Aworkstation that performs high-end
graphicalapplications,forinstance,mayhaveschedulingneedsdifferentfrom
thoseofawebserverorfileserver.Someoperatingsystems—particularlysev-
eralversionsofUNIX—allowthesystemmanagertofine-tunethescheduling
parameters for a particular system configuration. For example, Solaris pro-
vides the dispadmin command to allow the system administrator to modify
theparametersoftheschedulingclassesdescribedinSection5.7.3.
Another approach is to use APIs that can modify the priority of a process
or thread. The Java, POSIX, and Windows APIs provide such functions. The
downfallofthisapproachisthatperformance-tuningasystemorapplication
mostoftendoesnotresultinimprovedperformanceinmoregeneralsituations.250 Chapter5 CPUScheduling
5.9 Summary
• CPU scheduling is the task of selecting a waiting process from the ready
queue and allocating the CPU to it. The CPU is allocated to the selected
processbythedispatcher.
• Scheduling algorithms may be either preemptive (where the CPU can be
taken away from a process) or nonpreemptive (where a process must
voluntarily relinquish control of the CPU). Almost all modern operating
systemsarepreemptive.
• Scheduling algorithms can be evaluated according to the following five
criteria:(1)CPUutilization,(2)throughput,(3)turnaroundtime,(4)waiting
time,and(5)responsetime.
• First-come,first-served(FCFS)schedulingisthesimplestschedulingalgo-
rithm,butitcancauseshortprocessestowaitforverylongprocesses.
• Shortest-job-first(SJF)schedulingisprovablyoptimal,providingtheshort-
est average waiting time. Implementing SJF scheduling is difficult, how-
ever,becausepredictingthelengthofthenextCPUburstisdifficult.
• Round-robin (RR) scheduling allocates the CPUtoeach processfor a time
quantum.IftheprocessdoesnotrelinquishtheCPUbeforeitstimequan-
tum expires, the process is preempted, and another process is scheduled
torunforatimequantum.
• Priorityschedulingassignseachprocessapriority,andtheCPUisallocated
to the process with the highest priority. Processes with the same priority
canbescheduledinFCFSorderorusingRRscheduling.
• Multilevel queue scheduling partitions processes into several separate
queues arranged by priority, and the scheduler executes the processes in
the highest-priority queue. Different scheduling algorithms may be used
ineachqueue.
• Multilevelfeedbackqueuesaresimilartomultilevelqueues,exceptthata
processmaymigratebetweendifferentqueues.
• Multicore processors place one or more CPUs on the same physical chip,
and each CPU may have more than one hardware thread. From the per-
spective of the operating system, each hardware thread appears to be a
logicalCPU.
• LoadbalancingonmulticoresystemsequalizesloadsbetweenCPUcores,
althoughmigratingthreadsbetweencorestobalanceloadsmayinvalidate
cachecontentsandthereforemayincreasememoryaccesstimes.
• Soft real-time scheduling gives priority to real-time tasks over non-real-
timetasks.Hardreal-timeschedulingprovidestimingguaranteesforreal-
timetasks,
• Rate-monotonic real-time scheduling schedules periodic tasks using a
staticprioritypolicywithpreemption.PracticeExercises 251
• Earliest-deadline-first (EDF) scheduling assigns priorities according to
deadline. The earlier the deadline, the higher the priority; the later the
deadline,thelowerthepriority.
• ProportionalshareschedulingallocatesTsharesamongallapplications.If
anapplicationisallocatedNsharesoftime,itisensuredofhavingN∕Tof
thetotalprocessortime.
• Linuxusesthecompletelyfairscheduler(CFS),whichassignsaproportion
ofCPUprocessingtimetoeachtask.Theproportionisbasedonthevirtual
runtime(vruntime)valueassociatedwitheachtask.
• Windowsschedulingusesapreemptive,32-levelpriorityschemetodeter-
minetheorderofthreadscheduling.
• Solarisidentifiessixuniqueschedulingclassesthataremappedtoaglobal
priority. CPU-intensive threads are generally assigned lower priorities
(andlongertimequantums),andI/O-boundthreadsareusuallyassigned
higherpriorities(withshortertimequantums.)
• ModelingandsimulationscanbeusedtoevaluateaCPUschedulingalgo-
rithm.
Practice Exercises
5.1 ACPU-schedulingalgorithmdeterminesanorderfortheexecutionofits
scheduledprocesses.Givennprocessestobescheduledononeproces-
sor,howmanydifferentschedulesarepossible?Giveaformulainterms
ofn.
5.2 Explainthedifferencebetweenpreemptiveandnonpreemptiveschedul-
ing.
5.3 Suppose that the following processes arrive for execution at the times
indicated.Eachprocesswillrunfortheamountoftimelisted.Inanswer-
ingthequestions,usenonpreemptivescheduling,andbasealldecisions
ontheinformationyouhaveatthetimethedecisionmustbemade.
Process ArrivalTime BurstTime
P 0.0 8
1
P 0.4 4
2
P 1.0 1
3
a. Whatistheaverageturnaroundtimefortheseprocesseswiththe
FCFSschedulingalgorithm?
b. Whatistheaverageturnaroundtimefortheseprocesseswiththe
SJFschedulingalgorithm?
c. TheSJFalgorithmissupposedtoimproveperformance,butnotice
thatwechosetorunprocessP attime0becausewedidnotknow
1
that two shorter processeswould arrivesoon. Compute what the252 Chapter5 CPUScheduling
averageturnaround timewillbe iftheCPUisleftidleforthe first
1 unit and then SJF scheduling is used. Remember that processes
P and P are waiting during this idle time, so their waiting time
1 2
mayincrease.Thisalgorithmcouldbeknownasfuture-knowledge
scheduling.
5.4 Considerthefollowingsetofprocesses,withthelengthoftheCPUburst
timegiveninmilliseconds:
Process BurstTime Priority
P 2 2
1
P 1 1
2
P 8 4
3
P 4 2
4
P 5 3
5
TheprocessesareassumedtohavearrivedintheorderP ,P ,P ,P ,P ,
1 2 3 4 5
allattime0.
a. Draw four Gantt charts that illustrate the execution of these pro-
cesses using the following scheduling algorithms: FCFS, SJF, non-
preemptive priority (a larger priority number implies a higher
priority),andRR(quantum=2).
b. What is the turnaround time of each process for each of the
schedulingalgorithmsinparta?
c. Whatisthewaitingtimeofeachprocessforeachoftheseschedul-
ingalgorithms?
d. Which of the algorithms results in the minimum averagewaiting
time(overallprocesses)?
5.5 Thefollowingprocessesarebeingscheduledusingapreemptive,round-
robinschedulingalgorithm.
Process Priority Burst Arrival
P 40 20 0
1
P 30 25 25
2
P 30 25 30
3
P 35 15 60
4
P 5 10 100
5
P 10 10 105
6
Eachprocessisassignedanumericalpriority,withahighernumberindi-
catingahigherrelativepriority.Inadditiontotheprocesseslistedbelow,
thesystemalsohasanidletask(whichconsumesnoCPUresourcesand
is identified as P ). This task has priority 0 and is scheduled when-
idle
everthesystemhasnootheravailableprocessestorun.ThelengthofaPracticeExercises 253
timequantumis10units.Ifaprocessispreemptedbyahigher-priority
process,thepreemptedprocessisplacedattheendofthequeue.
a. ShowtheschedulingorderoftheprocessesusingaGanttchart.
b. Whatistheturnaroundtimeforeachprocess?
c. Whatisthewaitingtimeforeachprocess?
d. WhatistheCPUutilizationrate?
5.6 What advantageisthereinhaving differenttime-quantumsizesat dif-
ferentlevelsofamultilevelqueueingsystem?
5.7 Many CPU-scheduling algorithms are parameterized. For example, the
RRalgorithmrequiresaparametertoindicatethetimeslice.Multilevel
feedback queues require parameters to define the number of queues,
the scheduling algorithms for each queue, the criteria used to move
processesbetweenqueues,andsoon.
Thesealgorithmsarethusreallysetsofalgorithms(forexample,theset
ofRRalgorithmsforalltimeslices,andsoon).Onesetofalgorithmsmay
include another (for example, the FCFS algorithm is the RR algorithm
with an infinite time quantum). What (if any) relation holds between
thefollowingpairsofalgorithmsets?
a. PriorityandSJF
b. MultilevelfeedbackqueuesandFCFS
c. PriorityandFCFS
d. RRandSJF
5.8 Suppose that a CPU scheduling algorithm favors those processes that
have used the least processor time in the recent past. Why will this
algorithm favor I/O-bound programs and yet not permanently starve
CPU-boundprograms?
5.9 DistinguishbetweenPCSandSCSscheduling.
5.10 ThetraditionalUNIXschedulerenforcesaninverserelationshipbetween
priority numbers and priorities: the higher the number, the lower the
priority. The scheduler recalculates process priorities once per second
usingthefollowingfunction:
Priority=(recentCPUusage/2)+base
where base = 60 and recent CPU usage refers to a value indicating how
oftenaprocesshasusedtheCPUsinceprioritieswerelastrecalculated.
AssumethatrecentCPUusageforprocessP is40,forprocessP is18,
1 2
and forprocessP is10. What willbethenewprioritiesfor thesethree
3
processes when priorities are recalculated? Based on this information,
does the traditional UNIX scheduler raise or lower the relative priority
ofaCPU-boundprocess?254 Chapter5 CPUScheduling
Further Reading
Scheduling policies used in the UNIX FreeBSD 5.2 are presented by
[McKusick et al. (2015)]; The Linux CFS scheduler is further described in
https://www.ibm.com/developerworks/library/l-completely-fair-scheduler/.
Solaris scheduling is described by [Mauro and McDougall (2007)]. [Russi-
novich et al. (2017)] discusses scheduling in Windows internals. [Butenhof
(1997)]and [LewisandBerg(1998)] describeschedulinginPthreadssystems.
Multicoreschedulingisexaminedin[McNairyandBhatia(2005)],[Kongetira
etal.(2005)],and[Siddhaetal.(2007)].
Bibliography
[Butenhof(1997)] D. Butenhof, Programming with POSIX Threads, Addison-
Wesley(1997).
[Kongetiraetal.(2005)] P.Kongetira,K.Aingaran,andK.Olukotun,“Niagara:
A32-Way MultithreadedSPARC Processor”,IEEE MicroMagazine,Volume25,
Number2(2005),pages21–29.
[LewisandBerg(1998)] B. Lewis and D. Berg, MultithreadedProgramming with
Pthreads,SunMicrosystemsPress(1998).
[MauroandMcDougall(2007)] J. Mauro and R. McDougall, Solaris Internals:
CoreKernelArchitecture,PrenticeHall(2007).
[McKusicketal.(2015)] M.K.McKusick,G.V.Neville-Neil,andR.N.M.Wat-
son,TheDesignandImplementationoftheFreeBSDUNIXOperatingSystem–Second
Edition,Pearson(2015).
[McNairyandBhatia(2005)] C. McNairy and R. Bhatia, “Montecito: A Dual–
Core, Dual-Threaded Itanium Processor”, IEEE Micro Magazine, Volume 25,
Number2(2005),pages10–20.
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).
[Siddhaetal.(2007)] S.Siddha,V.Pallipadi,andA.Mallick,“ProcessSchedul-
ing Challenges in the Era of Multi-Core Processors”, Intel Technology Journal,
Volume11,Number4(2007).Exercises EX-12
Chapter 5 Exercises
5.11 Ofthesetwotypesofprograms:
a. I/O-bound
b. CPU-bound
which is more likely to have voluntary context switches, and which
is more likely to have nonvoluntary context switches? Explain your
answer.
5.12 Discusshowthefollowingpairsofschedulingcriteriaconflictincertain
settings.
a. CPUutilizationandresponsetime
b. Averageturnaroundtimeandmaximumwaitingtime
c. I/OdeviceutilizationandCPUutilization
5.13 Onetechniqueforimplementinglotteryschedulingworksbyassigning
processeslotterytickets,whichareusedforallocatingCPUtime.When-
ever a scheduling decision has to be made, a lottery ticket is chosen at
random,andtheprocessholdingthatticketgetstheCPU.TheBTVoper-
atingsystemimplementslotteryschedulingbyholdingalottery50times
each second, with each lottery winner getting 20 milliseconds of CPU
time(20milliseconds×50=1second).DescribehowtheBTVscheduler
canensurethathigher-prioritythreadsreceivemoreattentionfromthe
CPUthanlower-prioritythreads.
5.14 Mostschedulingalgorithmsmaintainarunqueue,whichlistsprocesses
eligible to run on a processor. On multicore systems, there are two
general options: (1) each processing core has its own run queue, or
(2) a single run queue is shared by all processing cores. What are the
advantagesanddisadvantagesofeachoftheseapproaches?
5.15 Considertheexponentialaverageformulausedtopredictthelengthof
thenextCPUburst.Whataretheimplicationsofassigningthefollowing
valuestotheparametersusedbythealgorithm?
a. α=0andτ =100milliseconds
0
b. α=0.99andτ =10milliseconds
0
5.16 Avariationoftheround-robinscheduleristheregressiveround-robin
scheduler. This scheduler assigns each process a time quantum and a
priority.Theinitialvalueofatimequantumis50milliseconds.However,
everytimeaprocesshasbeenallocatedtheCPUandusesitsentiretime
quantum (does not block for I/O), 10 milliseconds is added to its time
quantum, and its priority level is boosted. (The time quantum for a
process can be increased to a maximum of 100 milliseconds.) When a
processblocksbeforeusingitsentiretimequantum,itstimequantumis
reducedby5milliseconds,butitspriorityremainsthesame.Whattype
of process (CPU-bound or I/O-bound) does the regressive round-robin
schedulerfavor?Explain.EX-13
5.17 Considerthefollowingsetofprocesses,withthelengthoftheCPUburst
giveninmilliseconds:
Process BurstTime Priority
P 5 4
1
P 3 1
2
P 1 2
3
P 7 2
4
P 4 3
5
TheprocessesareassumedtohavearrivedintheorderP ,P ,P ,P ,P ,
1 2 3 4 5
allattime0.
a. Draw four Gantt charts that illustrate the execution of these pro-
cesses using the following scheduling algorithms: FCFS, SJF, non-
preemptive priority (a larger priority number implies a higher
priority),andRR(quantum=2).
b. What is the turnaround time of each process for each of the
schedulingalgorithmsinparta?
c. Whatisthewaitingtimeofeachprocessforeachoftheseschedul-
ingalgorithms?
d. Which of the algorithms results in the minimum averagewaiting
time(overallprocesses)?
5.18 The following processes are being scheduled using a preemptive,
priority-based,round-robinschedulingalgorithm.
Process Priority Burst Arrival
P 8 15 0
1
P 3 20 0
2
P 4 20 20
3
P 4 20 25
4
P 5 5 45
5
P 5 15 55
6
Eachprocessisassignedanumericalpriority,withahighernumberindi-
catingahigherrelativepriority.Theschedulerwillexecutethehighest-
priority process. For processes with the same priority, a round-robin
scheduler will be used with a time quantum of 10 units. If a process is
preemptedbyahigher-priorityprocess,thepreemptedprocessisplaced
attheendofthequeue.
a. ShowtheschedulingorderoftheprocessesusingaGanttchart.
b. Whatistheturnaroundtimeforeachprocess?
c. Whatisthewaitingtimeforeachprocess?
nice
5.19 The command isusedtosetthenicevalueofaprocessonLinux,
aswellasonotherUNIXsystems.Explainwhysomesystemsmayallow
anyusertoassignaprocessanicevalue>=0yetallowonlytheroot(or
administrator)usertoassignnicevalues<0.Exercises EX-14
5.20 Whichofthefollowingschedulingalgorithmscouldresultinstarvation?
a. First-come,first-served
b. Shortestjobfirst
c. Roundrobin
d. Priority
5.21 Consideravariant ofthe RRscheduling algorithm inwhich theentries
inthereadyqueuearepointerstothePCBs.
a. What would be the effect of putting two pointers to the same
processinthereadyqueue?
b. What would be two major advantages and two disadvantages of
thisscheme?
c. HowwouldyoumodifythebasicRRalgorithmtoachievethesame
effectwithouttheduplicatepointers?
5.22 Consider a system running ten I/O-bound tasks and one CPU-bound
task. Assume that the I/O-bound tasks issue an I/O operation once for
everymillisecondof CPUcomputing and that each I/O operationtakes
10 milliseconds to complete. Also assume that the context-switching
overheadis0.1millisecondandthatallprocessesarelong-runningtasks.
DescribetheCPUutilizationforaround-robinschedulerwhen:
a. Thetimequantumis1millisecond
b. Thetimequantumis10milliseconds
5.23 Consider a system implementing multilevel queue scheduling. What
strategy can a computer user employ to maximize the amount of CPU
timeallocatedtotheuser’sprocess?
5.24 Considerapreemptivepriorityschedulingalgorithmbasedondynami-
callychangingpriorities.Largerprioritynumbersimplyhigherpriority.
WhenaprocessiswaitingfortheCPU(inthereadyqueue,butnotrun-
ning), its priority changes at a rate α. When it is running, its priority
changes at a rate β. All processes are given a priority of 0 when they
enterthereadyqueue.Theparametersαandβcanbesettogivemany
differentschedulingalgorithms.
a. Whatisthealgorithmthatresultsfromβ > α >0?
b. Whatisthealgorithmthatresultsfromα < β <0?
5.25 Explainthehowthefollowingschedulingalgorithmsdiscriminateeither
infavoroforagainstshortprocesses:
a. FCFS
b. RR
c. MultilevelfeedbackqueuesEX-15
5.26 Describe why a shared ready queue might suffer from performance
problemsinanSMPenvironment.
5.27 Consider a load-balancing algorithm that ensures that each queue has
approximately the same number of threads, independent of priority.
How effectively would a priority-based scheduling algorithm handle
thissituationifonerunqueuehadallhigh-prioritythreadsandasecond
queuehadalllow-prioritythreads?
5.28 Assume that an SMP system has private, per-processor run queues.
Whenanewprocessiscreated,itcanbeplacedineitherthesamequeue
astheparentprocessoraseparatequeue.
a. Whatarethebenefitsofplacingthenewprocessinthesamequeue
asitsparent?
b. What are the benefits of placing the new process in a different
queue?
5.29 Assume that a thread has blocked for network I/O and is eligible to
run again. Describe why a NUMA-aware scheduling algorithm should
reschedulethethreadonthesameCPUonwhichitpreviouslyran.
5.30 Using the Windows scheduling algorithm, determine the numeric pri-
orityofeachofthefollowingthreads.
a. AthreadintheREALTIME PRIORITY CLASSwitharelativepriority
ofNORMAL
b. A thread in the ABOVE NORMALPRIORITY CLASS with a relative
priorityofHIGHEST
c. A thread in the BELOW NORMALPRIORITY CLASS with a relative
priorityofABOVE NORMAL
5.31 AssumingthatnothreadsbelongtotheREALTIME PRIORITY CLASSand
thatnonemaybeassignedaTIME CRITICALpriority,whatcombination
ofpriorityclassandprioritycorrespondstothehighestpossiblerelative
priorityinWindowsscheduling?
5.32 Consider the scheduling algorithm in the Solaris operating system for
time-sharingthreads.
a. Whatisthetimequantum(inmilliseconds)forathreadwithpri-
ority15?Withpriority40?
b. Assume that a thread with priority 50 has used its entire time
quantum without blocking. What newprioritywill the scheduler
assignthisthread?
c. Assumethatathreadwithpriority20blocksforI/Obeforeitstime
quantumhasexpired.Whatnewprioritywilltheschedulerassign
thisthread?Exercises EX-16
5.33 Assumethattwotasks,AandB,arerunningonaLinuxsystem.Thenice
valuesofAandBare−5and+5,respectively.UsingtheCFSscheduleras
vruntime
aguide,describehowtherespectivevaluesof varybetween
thetwoprocessesgiveneachofthefollowingscenarios:
• BothAandBareCPU-bound.
• AisI/O-bound,andBisCPU-bound.
• AisCPU-bound,andBisI/O-bound.
5.34 Provide a specific circumstance that illustrates where rate-monotonic
scheduling is inferior to earliest-deadline-first scheduling in meeting
real-timeprocessdeadlines?
5.35 Considertwoprocesses,P andP ,wherep = 50,t = 25,p = 75,and
1 2 1 1 2
t =30.
2
a. Can these two processes be scheduled using rate-monotonic
scheduling?IllustrateyouranswerusingaGanttchartsuchasthe
onesinFigure5.21–Figure5.24.
b. Illustrate the scheduling of these two processes using earliest-
deadline-first(EDF)scheduling.
5.36 Explainwhyinterruptanddispatchlatencytimesmustbeboundedina
hardreal-timesystem.
5.37 Describe the advantages of using heterogeneous multiprocessing in a
mobilesystem.P-29 Chapter5 CPUScheduling
Programming Projects
Scheduling Algorithms
Thisprojectinvolvesimplementingseveraldifferentprocessschedulingalgo-
rithms. The scheduler will be assigned a predefined set of tasks and will
schedule the tasks based on the selected scheduling algorithm. Each task is
assigned a priority and CPU burst. The following scheduling algorithms will
beimplemented:
• First-come,first-served(FCFS),whichschedulestasksintheorderinwhich
theyrequesttheCPU.
• Shortest-job-first(SJF),whichschedulestasksinorderofthelengthofthe
tasks’nextCPUburst.
• Priorityscheduling,whichschedulestasksbasedonpriority.
• Round-robin (RR)scheduling,where each taskis runfor atimequantum
(orfortheremainderofitsCPUburst).
• Prioritywithround-robin,whichschedulestasksinorderofpriorityand
usesround-robinschedulingfortaskswithequalpriority.
Prioritiesrangefrom1to10,whereahighernumericvalueindicatesahigher
relativepriority.Forround-robinscheduling,thelengthofatimequantum is
10milliseconds.
I.Implementation
TheimplementationofthisprojectmaybecompletedineitherCorJava,and
program files supporting both of these languages are provided in the source
codedownloadforthetext.Thesesupportingfilesreadinthescheduleoftasks,
insertthetasksintoalist,andinvokethescheduler.
Thescheduleoftaskshastheform[taskname][priority][CPUburst],with
thefollowingexampleformat:
T1, 4, 20
T2, 2, 25
T3, 3, 25
T4, 3, 15
T5, 10, 10
Thus,taskT1haspriority4andaCPUburstof20milliseconds,andsoforth.It
isassumedthatalltasksarriveatthesametime,soyourscheduleralgorithms
do not have to support higher-priority processes preempting processes with
lowerpriorities.Inaddition,tasksdonothavetobeplacedintoaqueueorlist
inanyparticularorder.
There are a few different strategies for organizing the list of tasks, as
first presented in Section 5.1.2. One approach is to place all tasks in a single
unorderedlist,wherethestrategyfortaskselectiondependsontheschedulingProgrammingProjects P-30
algorithm. For example, SJF scheduling would search the list to find the task
withtheshortestnextCPUburst.Alternatively,alistcouldbeorderedaccord-
ing to scheduling criteria (that is, by priority). One other strategy involves
havingaseparatequeueforeachuniquepriority,asshowninFigure5.7.These
approaches are briefly discussed in Section 5.3.6. It is also worth highlight-
ing that we are using the terms list and queue somewhat interchangeably.
However,aqueuehasveryspecificFIFOfunctionality,whereasalistdoesnot
havesuchstrictinsertionanddeletionrequirements.Youarelikelytofindthe
functionalityofagenerallisttobemoresuitablewhencompletingthisproject.
II.C ImplementationDetails
Thefiledriver.creadsinthescheduleoftasks,insertseachtaskintoalinked
list,andinvokestheprocessschedulerbycallingtheschedule()function.The
schedule()functionexecuteseachtaskaccordingtothespecifiedscheduling
algorithm.TasksselectedforexecutionontheCPUaredeterminedbythepick-
NextTask()functionandareexecutedbyinvokingtherun()functiondefined
intheCPU.cfile.AMakefileisusedtodeterminethespecificschedulingalgo-
rithmthatwillbeinvokedbydriver.Forexample,tobuildtheFCFSscheduler,
wewouldenter
make fcfs
andwouldexecutethescheduler(usingthescheduleoftasksschedule.txt)
asfollows:
./fcfs schedule.txt
RefertotheREADMEfileinthesourcecodedownloadforfurtherdetails.Before
proceeding, be sure to familiarize yourself with the source code provided as
wellastheMakefile.
III.JavaImplementationDetails
The file Driver.java reads in the schedule of tasks, inserts each task into a
JavaArrayList,andinvokestheprocessschedulerbycallingtheschedule()
method. The following interface identifies a generic scheduling algorithm,
whichthefivedifferentschedulingalgorithmswillimplement:
public interface Algorithm
{
// Implementation of scheduling algorithm
public void schedule();
// Selects the next task to be scheduled
public Task pickNetTask();
}
Theschedule()methodobtainsthenexttasktoberunontheCPUbyinvok-
ing the pickNextTask() method and then executes this Task by calling the
staticrun()methodintheCPU.javaclass.
Theprogramisrunasfollows:
java Driver fcfs schedule.txtP-31 Chapter5 CPUScheduling
RefertotheREADMEfileinthesourcecodedownloadforfurtherdetails.Before
proceeding,be suretofamiliarizeyourselfwithall Javasource filesprovided
inthesourcecodedownload.
IV. FurtherChallenges
Twoadditionalchallengesarepresentedforthisproject:
1. Each task provided to the scheduler is assigned a unique task (tid).
If a scheduler is running in an SMP environment where each CPU is
separatelyrunningitsownscheduler,thereisapossibleraceconditionon
thevariablethatisusedtoassigntaskidentifiers.Fixthisracecondition
usinganatomicinteger.
On Linux and macOS systems, the sync fetch and add() function
canbeusedtoatomicallyincrementanintegervalue.Asanexample,the
followingcodesampleatomicallyincrementsvalueby1:
int value = 0;
sync fetch and add(&value,1);
RefertotheJavaAPIfordetailsonhowtousetheAtomicIntegerclass
forJavaprograms.
2. Calculatetheaverageturnaroundtime,waitingtime,andresponsetime
foreachoftheschedulingalgorithms.Part Three
Process
Synchronization
A system typically consists of several (perhaps hundreds or even thou-
sands)ofthreadsrunningeitherconcurrentlyorinparallel.Threadsoften
shareuserdata.Meanwhile,theoperatingsystemcontinuouslyupdates
various data structures to support multiple threads. A race condition
exists when access to shared data is not controlled, possibly resulting
incorruptdatavalues.
Process synchronization involves using tools that control access to
shareddatatoavoidraceconditions.Thesetoolsmustbeusedcarefully,
as their incorrect use can result in poor system performance, including
deadlock.6
CHAPTER
Synchronization
Tools
Acooperatingprocess is one that can affector be affectedby otherprocesses
executing in the system. Cooperating processes can either directly share a
logicaladdressspace(thatis,bothcodeanddata)orbeallowedtosharedata
onlythroughsharedmemoryormessagepassing.Concurrentaccesstoshared
data may result in data inconsistency, however. In this chapter, we discuss
variousmechanismstoensuretheorderlyexecutionofcooperatingprocesses
thatsharealogicaladdressspace,sothatdataconsistencyismaintained.
CHAPTER OBJECTIVES
• Describethecritical-sectionproblemandillustratearacecondition.
• Illustratehardwaresolutionstothecritical-sectionproblemusingmemory
barriers,compare-and-swapoperations,andatomicvariables.
• Demonstratehowmutexlocks,semaphores,monitors,andconditionvari-
ablescanbeusedtosolvethecritical-sectionproblem.
• Evaluate tools that solve the critical-section problem in low-, moderate-,
andhigh-contentionscenarios.
6.1 Background
We’vealreadyseenthatprocessescanexecuteconcurrentlyorinparallel.Sec-
tion 3.2.2 introduced the role of process scheduling and described how the
CPUschedulerswitchesrapidlybetweenprocessestoprovideconcurrentexe-
cution. This means that one process may only partially complete execution
before another process is scheduled. In fact, a process may be interrupted at
anypointinitsinstructionstream,andtheprocessingcoremaybeassignedto
execute instructions of another process. Additionally, Section 4.2 introduced
parallel execution, in which two instruction streams (representing different
processes)executesimultaneouslyonseparateprocessingcores.Inthischap-
ter, we explain how concurrent or parallel execution can contribute to issues
involvingtheintegrityofdatasharedbyseveralprocesses.
257258 Chapter6 SynchronizationTools
Let’sconsideranexampleofhowthiscanhappen.InChapter3,wedevel-
oped a model of a system consisting of cooperating sequential processes or
threads,allrunningasynchronouslyandpossiblysharingdata.Weillustrated
this model with the producer–consumer problem, which is a representative
paradigmofmanyoperatingsystemfunctions.Specifically,inSection3.5,we
described how a bounded buffer could be used to enable processes to share
memory.
Wenowreturntoourconsiderationoftheboundedbuffer.Aswepointed
out,ouroriginalsolutionallowedatmostBUFFER SIZE−1itemsinthebuffer
at the same time. Suppose we want to modify the algorithm to remedy this
deficiency. One possibility is to add an integer variable, count, initialized to
0. count is incremented every time we add a new item to the buffer and is
decrementedeverytimeweremoveoneitemfromthebuffer.Thecodeforthe
producerprocesscanbemodifiedasfollows:
while (true) {
/* produce an item in next produced */
while (count == BUFFER SIZE)
; /* do nothing */
buffer[in] = next produced;
in = (in + 1) % BUFFER SIZE;
count++;
}
Thecodefortheconsumerprocesscanbemodifiedasfollows:
while (true) {
while (count == 0)
; /* do nothing */
next consumed = buffer[out];
out = (out + 1) % BUFFER SIZE;
count--;
/* consume the item in next consumed */
}
Although the producer and consumer routines shown above are correct
separately, they may not function correctly when executed concurrently. As
anillustration,supposethatthevalueofthevariablecountiscurrently5and
thattheproducerandconsumerprocessesconcurrentlyexecutethestatements
“count++” and “count--”. Following the execution of these two statements,
thevalueofthevariablecountmaybe4,5,or6!Theonlycorrectresult,though,
is count == 5, which is generated correctly if the producer and consumer
executeseparately.6.1 Background 259
We can show that the value of count may be incorrect as follows. Note
thatthestatement“count++”maybeimplementedinmachinelanguage(ona
typicalmachine)asfollows:
register =count
1
register =register +1
1 1
count=register
1
whereregister isoneofthelocalCPUregisters.Similarly,thestatement“count-
1
-”isimplementedasfollows:
register =count
2
register =register −1
2 2
count=register
2
whereagainregister isoneofthelocalCPUregisters.Eventhoughregister and
2 1
register maybethesamephysicalregister,rememberthatthecontentsofthis
2
registerwillbesavedandrestoredbytheinterrupthandler(Section1.2.3).
The concurrent execution of “count++” and “count--” is equivalent to a
sequentialexecutioninwhichthelower-levelstatementspresentedpreviously
are interleaved in some arbitrary order (but the order within each high-level
statementispreserved).Onesuchinterleavingisthefollowing:
T : producer execute register =count {register =5}
0 1 1
T : producer execute register =register +1 {register =6}
1 1 1 1
T : consumer execute register =count {register =5}
2 2 2
T : consumer execute register =register −1 {register =4}
3 2 2 2
T : producer execute count=register {count=6}
4 1
T : consumer execute count=register {count=4}
5 2
Noticethatwehavearrivedattheincorrectstate“count==4”,indicatingthat
fourbuffersarefull,when,infact,fivebuffersarefull.Ifwereversedtheorder
of the statements at T and T , we would arrive at the incorrect state “count
4 5
==6”.
Wewouldarriveatthisincorrectstatebecauseweallowedbothprocesses
to manipulate the variable count concurrently. A situation like this, where
several processes access and manipulate the same data concurrently and the
outcomeoftheexecutiondependsontheparticularorderinwhichtheaccess
takes place, is called a race condition. To guard against the race condition
above,weneedtoensurethatonlyoneprocessatatimecanbemanipulating
thevariablecount.Tomakesuchaguarantee,werequirethattheprocessesbe
synchronizedinsomeway.
Situations such as the one just described occur frequently in operating
systems as different parts of the system manipulate resources. Furthermore,
as we have emphasized in earlier chapters, the prominence of multicore sys-
temshas brought an increasedemphasis ondevelopingmultithreadedappli-
cations.Insuchapplications,severalthreads—whicharequitepossiblyshar-
ing data—are running in parallel on different processing cores. Clearly, we
want any changes that result from such activities not to interfere with one260 Chapter6 SynchronizationTools
another.Becauseoftheimportanceofthisissue,wedevoteamajorportionof
thischaptertoprocesssynchronizationandcoordinationamongcooperating
processes.
6.2 The Critical-Section Problem
We begin our consideration of process synchronization by discussing the so-
called critical-section problem. Consider a system consisting of n processes
{P ,P ,...,P }. Each process has a segment of code, called a critical section,
0 1 n−1
inwhichtheprocessmaybeaccessing — andupdating — datathatisshared
with at least one other process. The important feature of the system is that,
whenoneprocessisexecutinginitscriticalsection,nootherprocessisallowed
toexecuteinitscriticalsection.Thatis,notwoprocessesareexecutingintheir
critical sections at the same time. The critical-section problem is to design
a protocol that the processes can use to synchronize their activity so as to
cooperatively share data. Each process must request permission to enter its
critical section. The section of code implementing this request is the entry
section.Thecriticalsectionmaybefollowedbyanexitsection.Theremaining
code is the remainder section. The general structure of a typical process is
showninFigure6.1.Theentrysectionandexitsectionareenclosedinboxesto
highlighttheseimportantsegmentsofcode.
Asolutiontothe critical-sectionproblemmustsatisfy thefollowing three
requirements:
1. Mutualexclusion.IfprocessP isexecutinginitscriticalsection,thenno
i
otherprocessescanbeexecutingintheircriticalsections.
2. Progress. If no process is executing in its critical section and some pro-
cesseswishtoentertheircriticalsections,thenonlythoseprocessesthat
are not executing in their remainder sections can participate in decid-
ingwhichwillenteritscriticalsectionnext,andthisselectioncannot be
postponedindefinitely.
while (true) {
entrysection
criticalsection
exitsection
remaindersection
}
Figure6.1 Generalstructureofatypicalprocess.6.2 TheCritical-SectionProblem 261
3. Boundedwaiting.Thereexistsabound,orlimit,onthenumberoftimes
that other processes are allowed to enter their critical sections after a
process has made a request to enter its critical section and before that
requestisgranted.
Weassumethateachprocessisexecutingatanonzerospeed.However,wecan
makenoassumptionconcerningtherelativespeedofthenprocesses.
At a given point in time, many kernel-mode processes may be active in
theoperatingsystem.Asaresult,thecodeimplementinganoperatingsystem
(kernel code) is subject to several possible race conditions. Consider as an
example a kernel data structure that maintains a list of all open files in the
system.Thislistmustbemodifiedwhenanewfileisopenedorclosed(adding
thefiletothelistorremovingitfromthelist).Iftwoprocessesweretoopenfiles
simultaneously,theseparateupdatestothislistcouldresultinaracecondition.
Another example is illustrated in Figure 6.2. In this situation, two pro-
cesses, P and P , are creating child processes using the fork() system call.
0 1
RecallfromSection3.3.1thatfork()returnstheprocessidentifierofthenewly
created process to the parent process. In this example, there is a race condi-
tion on the variable kernel variable next available pid which represents
the value of the next available process identifier. Unless mutual exclusion is
provided,itispossiblethesameprocessidentifiernumber couldbeassigned
totwoseparateprocesses.
Other kernel data structures that are prone to possible race conditions
includestructuresformaintainingmemoryallocation,formaintainingprocess
lists,andforinterrupthandling.Itisuptokerneldeveloperstoensurethatthe
operatingsystemisfreefromsuchraceconditions.
The critical-sectionproblemcouldbe solvedsimplyinasingle-coreenvi-
ronmentifwecouldpreventinterruptsfromoccurringwhileasharedvariable
was being modified. In this way, we could be sure that the current sequence
P P
0 1
pid_t child = fork (); pid_t child = fork ();
request request
pid pid
next_available_pid = 2615
return return
2615 2615
child = 2615 child = 2615
emit
Figure6.2 Raceconditionwhenassigningapid.262 Chapter6 SynchronizationTools
ofinstructionswouldbeallowedtoexecuteinorderwithoutpreemption.No
other instructions would be run, so no unexpected modifications could be
madetothesharedvariable.
Unfortunately,thissolutionisnotasfeasibleinamultiprocessorenviron-
ment. Disabling interruptson a multiprocessor can be time consuming, since
themessageispassedtoalltheprocessors.Thismessagepassingdelaysentry
into each critical section, and system efficiency decreases. Also consider the
effectonasystem’sclockiftheclockiskeptupdatedbyinterrupts.
Two general approaches are used to handle critical sections in operating
systems:preemptivekernelsandnonpreemptivekernels.Apreemptiveker-
nel allows a process to be preempted while it is running in kernel mode. A
nonpreemptivekerneldoesnotallowaprocessrunninginkernelmodetobe
preempted;akernel-modeprocesswillrununtil itexitskernelmode,blocks,
orvoluntarilyyieldscontroloftheCPU.
Obviously,anonpreemptivekernelisessentiallyfreefromraceconditions
onkerneldatastructures,asonlyoneprocessisactiveinthekernelatatime.
We cannot say the same about preemptive kernels, so they must be carefully
designedtoensurethatsharedkerneldataarefreefromraceconditions.Pre-
emptive kernels are especially difficult to design for SMP architectures, since
in these environments it is possible for two kernel-mode processes to run
simultaneouslyondifferentCPUcores.
Why, then, would anyone favor a preemptive kernel over a nonpreemp-
tiveone?Apreemptivekernelmaybemoreresponsive,sincethereislessrisk
thatakernel-modeprocesswillrunforanarbitrarilylongperiodbeforerelin-
quishing the processor to waiting processes. (Of course, this risk can also be
minimized by designing kernel code that does not behave in this way.) Fur-
thermore,apreemptivekernelismoresuitableforreal-timeprogramming,as
itwillallowareal-timeprocesstopreemptaprocesscurrentlyrunninginthe
kernel.
6.3 Peterson’s Solution
Next,weillustrateaclassicsoftware-basedsolutiontothecritical-sectionprob-
lem known as Peterson’s solution. Because of the way modern computer
architecturesperformbasic machine-language instructions, suchasloadand
store, there are no guarantees that Peterson’s solution will work correctly
onsucharchitectures.However,wepresentthesolutionbecauseitprovidesa
goodalgorithmicdescriptionofsolvingthecritical-sectionproblemandillus-
tratessomeofthecomplexitiesinvolvedindesigningsoftwarethataddresses
therequirementsofmutualexclusion,progress,andboundedwaiting.
Peterson’s solution is restricted to two processes that alternate execution
betweentheircriticalsectionsandremaindersections.Theprocessesarenum-
beredP andP .Forconvenience,whenpresentingP,weuseP todenotethe
0 1 i j
otherprocess;thatis,jequals1−i.
Peterson’ssolutionrequiresthetwoprocessestosharetwodataitems:
int turn;
boolean flag[2];6.3 Peterson’sSolution 263
while (true) {
flag[i] = true;
turn = j;
while (flag[j] && turn == j)
;
/* critical section */
flag[i] = false;
/*remainder section */
}
Figure6.3 ThestructureofprocessP inPeterson’ssolution.
i
Thevariableturnindicateswhoseturnitistoenteritscriticalsection.Thatis,
if turn == i, then process P is allowed to execute in its critical section. The
i
flag array is usedto indicate if aprocess is readyto enter its critical section.
Forexample,ifflag[i]istrue,P isreadytoenteritscriticalsection.Withan
i
explanation of these data structures complete, we are now ready to describe
thealgorithmshowninFigure6.3.
To enter the critical section, process P first sets flag[i] to be true and
i
thensetsturntothevaluej,therebyassertingthatiftheotherprocesswishes
toenterthecriticalsection,itcandoso.Ifbothprocessestrytoenteratthesame
time, turn will be set to both i and j at roughly the same time. Only one of
theseassignmentswilllast;theotherwilloccurbutwillbeoverwrittenimme-
diately.The eventual value of turn determineswhich of the two processes is
allowedtoenteritscriticalsectionfirst.
Wenowprovethatthissolutioniscorrect.Weneedtoshowthat:
1. Mutualexclusionispreserved.
2. Theprogressrequirementissatisfied.
3. Thebounded-waitingrequirementismet.
To prove property 1, we note that each P enters its critical section only
i
if either flag[j] == false or turn == i. Also note that, if both processes
can be executing in their critical sections at the same time, then flag[0] ==
flag[1] == true. These two observations imply that P and P could not
0 1
have successfully executed their while statements at about the same time,
sincethevalueof turncanbeeither0or 1but cannot beboth. Hence,one of
theprocesses—say,P —musthavesuccessfullyexecutedthewhilestatement,
j
whereas P had to execute at least one additional statement (“turn == j”).
i
However, at that time, flag[j] == true and turn == j, and this condition
willpersistaslongasP isinitscriticalsection;asaresult,mutualexclusionis
j
preserved.264 Chapter6 SynchronizationTools
Toproveproperties2and3,wenotethataprocessP canbepreventedfrom
i
enteringthecriticalsectiononlyifitisstuckinthewhileloopwiththecondition
flag[j]==trueandturn==j;thisloopistheonlyonepossible.IfP isnot
j
readytoenterthecriticalsection,thenflag[j]==false,andP canenterits
i
criticalsection.IfP hassetflag[j]totrueandisalsoexecutinginitswhile
j
statement,theneitherturn==iorturn==j.Ifturn==i,thenP willenter
i
thecriticalsection.Ifturn==j,thenP willenterthecriticalsection.However,
j
once P exits its critical section, it will reset flag[j] to false, allowing P to
j i
enteritscriticalsection.IfP resetsflag[j]totrue,itmustalsosetturntoi.
j
Thus,sinceP doesnotchangethevalueofthevariableturnwhileexecuting
i
the while statement, P will enter the critical section (progress) after at most
i
oneentrybyP (boundedwaiting).
j
As mentioned at the beginning of this section, Peterson’s solution is not
guaranteed to work on modern computer architectures for the primary rea-
son that, to improve system performance, processors and/or compilers may
reorder read and write operations that have no dependencies. For a single-
threaded application, this reordering is immaterial as far as program correct-
nessisconcerned,asthefinalvaluesareconsistentwithwhatisexpected.(This
issimilartobalancingacheckbook—theactualorderinwhichcreditanddebit
operationsareperformedisunimportant,becausethefinalbalancewillstillbe
thesame.)Butforamultithreadedapplicationwithshareddata,thereordering
ofinstructionsmayrenderinconsistentorunexpectedresults.
As an example, consider the following data that are shared between two
threads:
boolean flag = false;
int x = 0;
whereThread1performsthestatements
while (!flag)
;
print x;
andThread2performs
x = 100;
flag = true;
Theexpectedbehavioris,ofcourse,thatThread1outputsthevalue100for
variablex.However,astherearenodatadependenciesbetweenthevariables
flag and x, it is possible that a processor may reorder the instructions for
Thread 2 so that flag is assigned true before assignment of x = 100. In
this situation, it is possible that Thread 1 would output 0 for variable x. Less
obviousisthattheprocessormayalsoreorderthestatementsissuedbyThread
1andloadthevariablexbeforeloadingthevalueofflag.Ifthisweretooccur,
Thread1wouldoutput0forvariablexeveniftheinstructionsissuedbyThread
2werenotreordered.6.4 HardwareSupportforSynchronization 265
process turn = 1 flag[0] = true cs
0
process turn = 0 , flag[1] = true cs
1
time
Figure6.4 TheeffectsofinstructionreorderinginPeterson’ssolution.
How does this affect Peterson’s solution? Consider what happens if the
assignments of the first two statements that appear in the entry section of
Peterson’ssolutioninFigure6.3arereordered;itispossiblethatboththreads
maybeactiveintheircriticalsectionsatthesametime,asshowninFigure6.4.
Asyouwillseeinthefollowingsections,theonlywaytopreservemutual
exclusion is by using proper synchronization tools. Our discussion of these
tools begins with primitive support in hardware and proceeds through
abstract, high-level, software-based APIs available to both kernel developers
andapplicationprogrammers.
6.4 Hardware Support for Synchronization
Wehavejustdescribedonesoftware-basedsolutiontothecritical-sectionprob-
lem.(Werefertoitasasoftware-basedsolutionbecausethealgorithminvolves
nospecialsupportfromtheoperatingsystemorspecifichardwareinstructions
toensuremutualexclusion.)However,asdiscussed,software-basedsolutions
arenotguaranteedtoworkonmoderncomputerarchitectures.Inthissection,
we present three hardware instructions that provide support for solving the
critical-section problem. These primitive operations can be used directly as
synchronization tools, or they can be used to form the foundation of more
abstractsynchronizationmechanisms.
6.4.1 Memory Barriers
InSection6.3,wesawthatasystemmayreorderinstructions,apolicythatcan
lead to unreliable data states. How a computer architecture determines what
memoryguaranteesitwillprovidetoanapplicationprogramisknownasits
memorymodel.Ingeneral,amemorymodelfallsintooneoftwocategories:
1. Strongly ordered, where a memory modification on one processor is
immediatelyvisibletoallotherprocessors.
2. Weaklyordered,wheremodificationstomemoryononeprocessormay
notbeimmediatelyvisibletootherprocessors.
Memorymodelsvarybyprocessortype,sokerneldeveloperscannotmake
any assumptions regarding the visibility of modifications to memory on a
shared-memorymultiprocessor.Toaddressthisissue,computerarchitectures
provideinstructionsthatcanforceanychangesinmemorytobepropagatedto
allotherprocessors,therebyensuringthatmemorymodificationsarevisibleto266 Chapter6 SynchronizationTools
threadsrunningonotherprocessors.Suchinstructionsareknownasmemory
barriersormemoryfences.Whenamemorybarrierinstructionisperformed,
the system ensures that all loads and stores are completed before any subse-
quent load or store operations are performed. Therefore, even if instructions
werereordered,thememorybarrierensuresthatthestoreoperationsarecom-
pleted in memory and visible to other processors before future load or store
operationsareperformed.
Let’sreturntoourmostrecentexample,inwhichreorderingofinstructions
couldhaveresultedinthewrongoutput,anduseamemorybarriertoensure
thatweobtaintheexpectedoutput.
IfweaddamemorybarrieroperationtoThread1
while (!flag)
memory barrier();
print x;
weguaranteethatthevalueofflagisloadedbeforethevalueofx.
Similarly, if we place a memory barrier between the assignments per-
formedbyThread2
x = 100;
memory barrier();
flag = true;
weensurethattheassignmenttoxoccursbeforetheassignmenttoflag.
With respect to Peterson’s solution, we could place a memory barrier
betweenthe first two assignment statementsinthe entry sectionto avoidthe
reordering of operations shown in Figure 6.4. Note that memory barriers are
considered very low-level operations and are typically only used by kernel
developerswhenwritingspecializedcodethatensuresmutualexclusion.
6.4.2 Hardware Instructions
Many modern computer systems provide special hardware instructions that
allowuseithertotestandmodifythecontentofawordortoswapthecontents
of two words atomically—that is, as one uninterruptible unit. We can use
these special instructions to solve the critical-section problem in a relatively
simplemanner.Ratherthandiscussingonespecificinstructionforonespecific
machine,weabstractthemainconceptsbehindthesetypesofinstructionsby
describingthetest and set()andcompare and swap()instructions.
boolean test and set(boolean *target) {
boolean rv = *target;
*target = true;
return rv;
}
Figure6.5 Thedefinitionoftheatomictest and set()instruction.6.4 HardwareSupportforSynchronization 267
do {
while (test and set(&lock))
; /* do nothing */
/* critical section */
lock = false;
/* remainder section */
} while (true);
Figure6.6 Mutual-exclusionimplementationwithtest and set().
The test and set() instruction can be defined as shown in Figure 6.5.
The important characteristic of this instruction is that it is executed atomi-
cally. Thus, if two test and set() instructions are executed simultaneously
(eachonadifferentcore),theywillbeexecutedsequentiallyinsomearbitrary
order. If the machine supports the test and set() instruction, then we can
implementmutualexclusionbydeclaringabooleanvariablelock,initialized
tofalse.ThestructureofprocessP isshowninFigure6.6.
i
Thecompare and swap()instruction(CAS),justlikethetest and set()
instruction,operatesontwowordsatomically,butusesadifferentmechanism
thatisbasedonswappingthecontentoftwowords.
The CAS instruction operates on three operands and is defined in Figure
6.7. The operand value is set to new value only if the expression (*value
== expected) is true. Regardless, CAS always returns the original value of
thevariablevalue.Theimportantcharacteristicofthisinstructionisthatitis
executedatomically.Thus,iftwoCASinstructionsareexecutedsimultaneously
(eachonadifferentcore),theywillbeexecutedsequentiallyinsomearbitrary
order.
Mutual exclusion using CAS can be provided as follows: A global vari-
able (lock) is declared and is initialized to 0. The first process that invokes
compare and swap() will set lock to 1. It will then enter its critical section,
int compare and swap(int *value, int expected, int new value) {
int temp = *value;
if (*value == expected)
*value = new value;
return temp;
}
Figure6.7 Thedefinitionoftheatomiccompare and swap()instruction.268 Chapter6 SynchronizationTools
while (true) {
while (compare and swap(&lock, 0, 1) != 0)
; /* do nothing */
/* critical section */
lock = 0;
/* remainder section */
}
Figure6.8 Mutualexclusionwiththecompare and swap()instruction.
becausetheoriginalvalueoflockwasequaltotheexpectedvalueof0.Subse-
quentcallstocompare and swap()willnotsucceed,becauselocknowisnot
equaltotheexpectedvalueof0.Whenaprocessexitsitscriticalsection,itsets
lock back to 0, which allows another process to enter its critical section. The
structureofprocessP isshowninFigure6.8.
i
Although this algorithm satisfies the mutual-exclusion requirement, it
does not satisfy the bounded-waiting requirement. In Figure 6.9, we present
while (true) {
waiting[i] = true;
key = 1;
while (waiting[i] && key == 1)
key = compare and swap(&lock,0,1);
waiting[i] = false;
/* critical section */
j = (i + 1) % n;
while ((j != i) && !waiting[j])
j = (j + 1) % n;
if (j == i)
lock = 0;
else
waiting[j] = false;
/* remainder section */
}
Figure6.9 Bounded-waitingmutualexclusionwithcompare and swap().6.4 HardwareSupportforSynchronization 269
MAKINGCOMPARE-AND-SWAPATOMIC
On Intel x86 architectures, the assembly language statement cmpxchg is
usedtoimplementthecompare and swap()instruction.Toenforceatomic
execution, the lock prefix is used to lock the bus while the destination
operandisbeingupdated.Thegeneralformofthisinstructionappearsas:
lock cmpxchg <destination operand>, <source operand>
anotheralgorithmusingthecompare and swap()instructionthatsatisfiesall
thecritical-sectionrequirements.Thecommondatastructuresare
boolean waiting[n];
int lock;
Theelementsinthewaitingarrayareinitializedtofalse,andlockisinitial-
izedto0.Toprovethatthemutual-exclusionrequirementismet,wenotethat
processP canenteritscritical sectiononly ifeitherwaiting[i]==falseor
i
key == 0. The value of key can become 0 only if the compare and swap() is
executed. The first process to execute the compare and swap() will find key
==0;allothersmustwait.Thevariablewaiting[i]canbecomefalseonlyif
anotherprocessleavesitscriticalsection;onlyonewaiting[i]issettofalse,
maintainingthemutual-exclusionrequirement.
Toprovethattheprogressrequirementismet,wenotethatthearguments
presented for mutual exclusion also apply here, since a process exiting the
criticalsectioneithersetslockto0orsetswaiting[j]tofalse.Bothallowa
processthatiswaitingtoenteritscriticalsectiontoproceed.
Toprovethatthebounded-waitingrequirementismet,wenotethat,when
a process leaves its critical section, it scans the array waiting in the cyclic
ordering (i + 1, i + 2, ..., n − 1, 0, ..., i − 1). It designates the first process in
thisorderingthatisintheentrysection(waiting[j]==true)asthenextone
toenterthecriticalsection.Anyprocesswaitingtoenteritscriticalsectionwill
thusdosowithinn−1turns.
Detailsdescribingtheimplementationoftheatomictest and set()and
compare and swap()instructions are discussedmore fully in books on com-
puterarchitecture.
6.4.3 Atomic Variables
Typically,thecompare and swap()instructionisnotuseddirectlytoprovide
mutual exclusion. Rather, it is used as abasic building block for constructing
other tools that solve the critical-section problem. One such tool is an atomic
variable,whichprovidesatomicoperationsonbasicdatatypessuchasintegers
andbooleans.WeknowfromSection6.1thatincrementingordecrementingan
integer value may produce a race condition. Atomic variables can be used in
toensure mutual exclusion in situations where there may be adatarace on a
singlevariablewhileitisbeingupdated,aswhenacounterisincremented.
Most systems that support atomic variables provide special atomic data
types as well as functions for accessing and manipulating atomic variables.270 Chapter6 SynchronizationTools
These functions are often implemented using compare and swap() opera-
tions.Asanexample,thefollowingincrementstheatomicintegersequence:
increment(&sequence);
wheretheincrement()functionisimplementedusingtheCASinstruction:
void increment(atomic int *v)
{
int temp;
do {
temp = *v;
}
while (temp != compare and swap(v, temp, temp+1));
}
It is important to note that although atomic variables provide atomic
updates, they do not entirely solve race conditions in all circumstances. For
example,inthebounded-bufferproblemdescribedinSection6.1,wecoulduse
anatomicintegerforcount.Thiswouldensurethattheupdatestocountwere
atomic.However,theproducerandconsumerprocessesalsohavewhileloops
whoseconditiondependsonthevalueofcount.Considerasituationinwhich
thebufferiscurrentlyemptyandtwoconsumersareloopingwhilewaitingfor
count>0.Ifaproducerenteredoneiteminthebuffer,bothconsumerscould
exittheirwhileloops(ascountwouldnolongerbeequalto0)andproceedto
consume,eventhoughthevalueofcountwasonlysetto1.
Atomicvariablesarecommonlyusedinoperatingsystemsaswellascon-
current applications, although their use is often limited to single updates of
shared data such as counters and sequence generators. In the following sec-
tions,weexploremorerobusttoolsthataddressraceconditionsinmoregen-
eralizedsituations.
6.5 Mutex Locks
Thehardware-basedsolutionstothecritical-sectionproblempresentedinSec-
tion 6.4 are complicated as well as generally inaccessible to application pro-
grammers. Instead, operating-system designers build higher-level software
tools to solve the critical-section problem. The simplest of these tools is the
mutexlock.(Infact,thetermmutexisshortformutualexclusion.)Weusethe
mutex lock to protect critical sections and thus prevent race conditions. That
is,aprocessmustacquirethelockbeforeenteringacriticalsection;itreleases
thelockwhenitexitsthecriticalsection.Theacquire()functionacquiresthe
lock,andtherelease()functionreleasesthelock,asillustratedinFigure6.10.
Amutex lock has a boolean variable available whose value indicates if
thelockisavailableornot.Ifthelockisavailable,acalltoacquire()succeeds,
andthelockisthenconsideredunavailable.Aprocessthatattemptstoacquire
anunavailablelockisblockeduntilthelockisreleased.6.5 MutexLocks 271
while (true) {
acquirelock
criticalsection
releaselock
remaindersection
}
Figure6.10 Solutiontothecritical-sectionproblemusingmutexlocks.
Thedefinitionofacquire()isasfollows:
acquire() {
while (!available)
; /* busy wait */
available = false;
}
Thedefinitionofrelease()isasfollows:
release() {
available = true;
}
Calls to either acquire() or release() must be performed atomically.
Thus, mutex locks can be implementedusing the CAS operation described in
Section6.4,andweleavethedescriptionofthistechniqueasanexercise.
LOCKCONTENTION
Locksareeithercontendedoruncontended.Alockisconsideredcontended
ifathreadblockswhiletryingtoacquirethelock.Ifalockisavailablewhen
a thread attempts to acquire it, the lock is considered uncontended. Con-
tendedlockscanexperienceeitherhighcontention(arelativelylargenumber
of threads attempting to acquire the lock) or low contention (a relatively
small number of threads attempting to acquire the lock.) Unsurprisingly,
highly contendedlocks tend to decrease overallperformanceof concurrent
applications.272 Chapter6 SynchronizationTools
WHATISMEANTBY“SHORTDURATION”?
Spinlocksareoftenidentifiedasthelockingmechanismofchoiceonmulti-
processorsystemswhenthelockistobeheldforashortduration.Butwhat
exactly constitutes a short duration? Given that waiting on a lock requires
two context switches—a context switch to move the thread to the waiting
stateandasecondcontextswitchtorestorethewaitingthreadoncethelock
becomes available—the general rule is to use a spinlock if the lock will be
heldforadurationoflessthantwocontextswitches.
Themaindisadvantageoftheimplementationgivenhereisthatitrequires
busy waiting. While a process is in its critical section, any other process that
triestoenteritscriticalsectionmustloopcontinuouslyinthecalltoacquire().
Thiscontinualloopingisclearlyaprobleminarealmultiprogrammingsystem,
where a single CPU core is shared among many processes. Busy waiting also
wastes CPU cycles that some other process might be able touse productively.
(InSection6.6,weexamineastrategythatavoidsbusywaitingbytemporarily
putting the waiting process to sleep and then awakening it once the lock
becomesavailable.)
The type of mutex lock we have been describing is also called a spin-
lock because the process “spins” while waiting for the lock to become avail-
able. (We see the same issue with the code examples illustrating the com-
pare and swap() instruction.) Spinlocks do have an advantage, however, in
that no context switch is requiredwhen a process must wait on a lock, and a
contextswitchmaytakeconsiderabletime.Incertaincircumstancesonmulti-
coresystems,spinlocksareinfactthepreferablechoiceforlocking.Ifalockis
to be held for a short duration, one thread can “spin” on one processing core
whileanotherthreadperformsitscriticalsectiononanothercore.Onmodern
multicore computing systems, spinlocks are widely used in many operating
systems.
In Chapter 7 we examine how mutex locks can be used to solve classical
synchronizationproblems.Wealsodiscusshowmutexlocksandspinlocksare
usedinseveraloperatingsystems,aswellasinPthreads.
6.6 Semaphores
Mutexlocks,aswementionedearlier,aregenerallyconsideredthesimplestof
synchronizationtools.Inthissection,weexamineamorerobusttoolthatcan
behavesimilarlytoamutexlockbutcanalsoprovidemoresophisticatedways
forprocessestosynchronizetheiractivities.
A semaphore S is an integer variable that, apart from initialization, is
accessedonlythroughtwostandardatomicoperations:wait()andsignal().
Semaphores were introduced by the Dutch computer scientist Edsger Dijk-
stra,andsuch,thewait()operationwasoriginallytermedP(fromtheDutch6.6 Semaphores 273
proberen,“totest”);signal()wasoriginallycalledV(fromverhogen,“toincre-
ment”).Thedefinitionofwait()isasfollows:
wait(S) {
while (S <=0)
; // busy wait
S--;
}
Thedefinitionofsignal()isasfollows:
signal(S) {
S++;
}
Allmodificationstotheintegervalueofthesemaphoreinthewait()and
signal()operationsmust be executedatomically.That is,when one process
modifies the semaphore value, no other process can simultaneously modify
thatsamesemaphorevalue.Inaddition,inthecaseofwait(S),thetestingof
the integer value of S (S ≤ 0), as well as its possible modification (S--), must
be executed without interruption. We shall see how these operations can be
implementedinSection6.6.2.First,let’sseehowsemaphorescanbeused.
6.6.1 Semaphore Usage
Operating systems often distinguish between counting and binary
semaphores. The value of a counting semaphore can range over an
unrestricted domain. The value of a binary semaphore can range only
between0and1.Thus,binarysemaphoresbehavesimilarlytomutexlocks.In
fact, on systems that do not provide mutex locks, binary semaphores can be
usedinsteadforprovidingmutualexclusion.
Counting semaphores can be used to control access to a given resource
consisting of a finite number of instances. The semaphore is initializedto the
number of resources available. Each process that wishes to use a resource
performs a wait() operation on the semaphore (thereby decrementing the
count). When a process releasesa resource,it performs a signal()operation
(incrementing the count). When the count for the semaphore goes to 0, all
resourcesarebeingused.Afterthat,processesthatwishtousearesourcewill
blockuntilthecountbecomesgreaterthan0.
We can also use semaphores to solve various synchronization problems.
Forexample,considertwoconcurrentlyrunningprocesses:P withastatement
1
S andP withastatementS .SupposewerequirethatS beexecutedonlyafter
1 2 2 2
S hascompleted.WecanimplementthisschemereadilybylettingP andP
1 1 2
shareacommonsemaphoresynch,initializedto0.InprocessP ,weinsertthe
1
statements
S ;
1
signal(synch);274 Chapter6 SynchronizationTools
InprocessP ,weinsertthestatements
2
wait(synch);
S ;
2
Because synch isinitializedto0, P will execute S only afterP has invoked
2 2 1
signal(synch),whichisafterstatementS hasbeenexecuted.
1
6.6.2 Semaphore Implementation
RecallthattheimplementationofmutexlocksdiscussedinSection6.5suffers
from busy waiting. The definitions of the wait() and signal() semaphore
operations just described present the same problem. To overcome this prob-
lem, we can modify the definition of the wait() and signal() operations
as follows: When a process executes the wait() operation and finds that the
semaphorevalueisnotpositive,itmustwait.However,ratherthanengaging
inbusywaiting,theprocesscansuspenditself.Thesuspendoperationplaces
aprocessintoawaitingqueueassociatedwiththesemaphore,andthestateof
the processisswitched tothewaiting state.Thencontrol is transferredtothe
CPUscheduler,whichselectsanotherprocesstoexecute.
Aprocessthatissuspended,waitingonasemaphoreS,shouldberestarted
when some other process executes a signal() operation. The process is
restartedbyawakeup()operation,whichchangestheprocessfromthewaiting
state to the ready state. The process is then placed in the ready queue. (The
CPUmayormaynotbeswitchedfromtherunningprocesstothenewlyready
process,dependingontheCPU-schedulingalgorithm.)
Toimplementsemaphoresunderthisdefinition,wedefineasemaphoreas
follows:
typedef struct{
int value;
struct process *list;
}semaphore;
Each semaphore has an integer value and a list of processes list. When
a process must wait on a semaphore, it is added to the list of processes. A
signal() operation removes one process from the list of waiting processes
andawakensthatprocess.
Now,thewait()semaphoreoperationcanbedefinedas
wait(semaphore *S) {
S->value--;
if (S->value < 0) {
addthisprocesstoS->list;
sleep();
}
}6.6 Semaphores 275
andthesignal()semaphoreoperationcanbedefinedas
signal(semaphore *S) {
S->value++;
if (S->value <= 0) {
removeaprocessPfromS->list;
wakeup(P);
}
}
The sleep() operation suspends the process that invokes it. The wakeup(P)
operation resumes the execution of a suspended process P. These two opera-
tionsareprovidedbytheoperatingsystemasbasicsystemcalls.
Note that in this implementation, semaphore values may be negative,
whereassemaphorevaluesarenevernegativeundertheclassicaldefinitionof
semaphoreswithbusywaiting.Ifasemaphorevalueisnegative,itsmagnitude
is the number of processes waiting on that semaphore. This fact results from
switchingtheorderofthedecrementandthetestintheimplementationofthe
wait()operation.
The list of waiting processes can be easily implemented by a link field in
eachprocesscontrolblock(PCB).Eachsemaphorecontainsanintegervalueand
apointertoalistofPCBs.Onewaytoaddandremoveprocessesfromthelist
soastoensureboundedwaitingistouseaFIFOqueue,wherethesemaphore
containsbothheadandtailpointerstothequeue.Ingeneral,however,thelist
can use any queuing strategy. Correct usage of semaphores does not depend
onaparticularqueuingstrategyforthesemaphorelists.
As mentioned,it is critical that semaphoreoperations be executedatomi-
cally.Wemustguaranteethatnotwoprocessescanexecutewait()andsig-
nal() operations on the same semaphore at the same time. This is a critical-
sectionproblem,andinasingle-processorenvironment,wecansolveitbysim-
plyinhibitinginterruptsduringthetimethewait()andsignal()operations
areexecuting.Thisschemeworksinasingle-processorenvironmentbecause,
once interrupts are inhibited, instructions from different processes cannot be
interleaved. Only the currently running process executes until interrupts are
reenabledandtheschedulercanregaincontrol.
In a multicore environment, interrupts must be disabled on every pro-
cessingcore.Otherwise,instructionsfromdifferentprocesses(runningondif-
ferent cores) may be interleaved in some arbitrary way. Disabling interrupts
oneverycorecan be adifficulttaskand can seriouslydiminishperformance.
Therefore, SMP systems must provide alternative techniques—such as com-
pare and swap()orspinlocks—toensurethatwait()andsignal()areper-
formedatomically.
It is important to admit that we have not completely eliminated busy
waiting with this definition of the wait() and signal() operations. Rather,
we have moved busy waiting from the entry section to the critical sections
of application programs. Furthermore, we have limited busy waiting to the
criticalsectionsofthewait()andsignal()operations,andthesesectionsare
short(ifproperlycoded,theyshouldbenomorethanaboutteninstructions).
Thus, the critical section is almost never occupied, and busy waiting occurs276 Chapter6 SynchronizationTools
rarely, and then for only a short time. An entirely different situation exists
with application programs whose critical sections may be long (minutes or
even hours) or may almost always be occupied. In such cases, busy waiting
isextremelyinefficient.
6.7 Monitors
Althoughsemaphoresprovideaconvenientandeffectivemechanismforpro-
cess synchronization, using them incorrectly can result in timing errors that
are difficult to detect, since these errors happen only if particular execution
sequencestakeplace,andthesesequencesdonotalwaysoccur.
Wehaveseenanexampleofsucherrorsintheuseofacountinoursolution
tothe producer–consumer problem(Section6.1).Inthat example,the timing
problem happened only rarely, and even then the count value appeared to
be reasonable—off by only 1. Nevertheless, the solution is obviously not an
acceptable one. It is for this reason that mutex locks and semaphores were
introducedinthefirstplace.
Unfortunately,such timingerrorscan stilloccur wheneithermutexlocks
orsemaphoresareused.Toillustratehow,wereviewthesemaphoresolution
tothecritical-sectionproblem.Allprocessesshareabinarysemaphorevariable
mutex,whichisinitializedto1.Eachprocessmustexecutewait(mutex)before
enteringthecriticalsectionandsignal(mutex)afterward.Ifthissequenceis
not observed, two processes may be in their critical sections simultaneously.
Next,welistseveraldifficultiesthatmayresult.Notethatthesedifficultieswill
ariseevenifasingleprocessisnotwellbehaved.Thissituationmaybecaused
byanhonestprogrammingerrororanuncooperativeprogrammer.
• Supposethat aprogram interchanges the orderinwhich thewait()and
signal() operations on the semaphore mutex are executed, resulting in
thefollowingexecution:
signal(mutex);
...
criticalsection
...
wait(mutex);
In this situation, several processes may be executing in their critical sec-
tions simultaneously, violating the mutual-exclusion requirement. This
errormaybediscoveredonlyifseveralprocessesaresimultaneouslyactive
intheircriticalsections.Notethatthissituationmaynotalwaysberepro-
ducible.
• Supposethataprogramreplacessignal(mutex)withwait(mutex).That
is,itexecutes
wait(mutex);
...
criticalsection
...
wait(mutex);6.7 Monitors 277
In this case, the process will permanently block on the second call to
wait(),asthesemaphoreisnowunavailable.
• Supposethataprocessomitsthewait(mutex),orthesignal(mutex),or
both. In this case, either mutual exclusion is violated or the process will
permanentlyblock.
Theseexamplesillustratethat various typesof errorscan be generatedeasily
when programmers use semaphores or mutex locks incorrectly to solve the
critical-sectionproblem.Onestrategyfordealingwithsucherrorsistoincor-
poratesimplesynchronizationtoolsashigh-levellanguageconstructs.Inthis
section,wedescribeonefundamentalhigh-levelsynchronizationconstruct—
themonitortype.
6.7.1 Monitor Usage
Anabstractdatatype—orADT—encapsulatesdatawithasetoffunctionsto
operate on that data that are independent of any specific implementation of
theADT.AmonitortypeisanADTthatincludesasetofprogrammer-defined
operations that are provided with mutual exclusion within the monitor. The
monitor type also declares the variables whose values define the state of an
monitor monitorname
{
/* shared variable declarations */
function P1 ( . . . ) {
. . .
}
function P2 ( . . . ) {
. . .
}
.
.
.
function Pn ( . . . ) {
. . .
}
initialization code ( . . . ) {
. . .
}
}
Figure6.11 Pseudocodesyntaxofamonitor.278 Chapter6 SynchronizationTools
instanceofthattype,alongwiththebodiesoffunctionsthatoperateonthose
variables. The syntax of a monitor type is shown in Figure 6.11. The repre-
sentation of a monitor type cannot be used directlyby the various processes.
Thus, a function defined within a monitor can access only those variables
declared locally within the monitor and its formal parameters. Similarly, the
localvariablesofamonitorcanbeaccessedbyonlythelocalfunctions.
The monitor construct ensures that only one process at a time is active
within the monitor. Consequently, the programmer does not need to code
thissynchronization constraintexplicitly(Figure6.12).However,themonitor
construct, as defined so far, is not sufficiently powerful for modeling some
synchronizationschemes.Forthispurpose,weneedtodefineadditionalsyn-
chronizationmechanisms.Thesemechanismsareprovidedbythecondition
construct. A programmer who needs to write a tailor-made synchronization
schemecandefineoneormorevariablesoftypecondition:
condition x, y;
Theonlyoperationsthatcanbeinvokedonaconditionvariablearewait()
andsignal().Theoperation
x.wait();
means that the process invoking this operation is suspended until another
processinvokes
x.signal();
entry queue
shared data
. . .
operations
initialization
code
Figure6.12 Schematicviewofamonitor.6.7 Monitors 279
The x.signal()operationresumesexactly one suspendedprocess. Ifno
process is suspended, then the signal() operation has no effect; that is, the
state of x is the same as if the operation had never been executed (Figure
6.13). Contrast this operation with the signal() operation associated with
semaphores,whichalwaysaffectsthestateofthesemaphore.
Now suppose that, when the x.signal() operation is invoked by a pro-
cessP,thereexistsasuspendedprocessQassociatedwithconditionx.Clearly,
if the suspended process Q is allowed to resume its execution, the signaling
process P must wait. Otherwise, both P and Q would be active simultane-
ouslywithinthemonitor.Note,however,thatconceptuallybothprocessescan
continuewiththeirexecution.Twopossibilitiesexist:
1. Signal and wait. P either waits until Q leaves the monitor or waits for
anothercondition.
2. Signal and continue. Q either waits until P leaves the monitor or waits
foranothercondition.
There are reasonable arguments in favor of adopting either option. On
the one hand, since P was already executing in the monitor, the signal-and-
continuemethodseemsmorereasonable.Ontheother,ifweallowthreadPto
continue,thenbythetimeQisresumed,thelogicalconditionforwhichQwas
waitingmay nolongerhold.Acompromisebetweenthesetwochoices exists
aswell:whenthreadPexecutesthesignaloperation,itimmediatelyleavesthe
monitor.Hence,Qisimmediatelyresumed.
entry queue
shared data
queues associated with x
x, y conditions y
(cid:129) (cid:129) (cid:129)
operations
initialization
code
Figure6.13 Monitorwithconditionvariables.280 Chapter6 SynchronizationTools
Manyprogramminglanguageshaveincorporatedtheideaofthemonitor
asdescribedinthissection,includingJavaandC#.Otherlanguages—suchas
Erlang—provideconcurrencysupportusingasimilarmechanism.
6.7.2 Implementing a Monitor Using Semaphores
Wenowconsiderapossibleimplementationofthemonitormechanismusing
semaphores. For each monitor, a binary semaphore mutex (initialized to 1) is
provided to ensure mutual exclusion. A process must execute wait(mutex)
before entering the monitor and must execute signal(mutex) after leaving
themonitor.
We will use the signal-and-wait scheme in our implementation. Since a
signaling process must wait until the resumed process either leaves or waits,
an additional binary semaphore, next, is introduced, initialized to 0. The
signaling processes can use next to suspend themselves.An integer variable
next countisalsoprovidedtocount thenumber ofprocessessuspendedon
next.Thus,eachexternalfunctionFisreplacedby
wait(mutex);
...
bodyofF
...
if (next count > 0)
signal(next);
else
signal(mutex);
Mutualexclusionwithinamonitorisensured.
We can now describe how condition variables are implemented as well.
For each condition x, we introduce a binary semaphorex sem and an integer
variable x count, both initialized to 0. The operation x.wait() can now be
implementedas
x count++;
if (next count > 0)
signal(next);
else
signal(mutex);
wait(x sem);
x count--;
Theoperationx.signal()canbeimplementedas
if (x count > 0) {
next count++;
signal(x sem);
wait(next);
next count--;
}
This implementationis applicable to the definitions ofmonitors givenby
both Hoare and Brinch-Hansen (see the bibliographical notes at the end of
the chapter). In some cases, however, the generality of the implementation is6.7 Monitors 281
monitor ResourceAllocator
{
boolean busy;
condition x;
void acquire(int time) {
if (busy)
x.wait(time);
busy = true;
}
void release() {
busy = false;
x.signal();
}
initialization code() {
busy = false;
}
}
Figure6.14 Amonitortoallocateasingleresource.
unnecessary,andasignificantimprovementinefficiencyispossible.Weleave
thisproblemtoyouinExercise6.27.
6.7.3 Resuming Processes within a Monitor
We turn now to the subject of process-resumption order within a monitor. If
several processes are suspended on condition x, and an x.signal() opera-
tion is executed by some process, then how do we determine which of the
suspendedprocessesshouldberesumednext?Onesimplesolutionistousea
first-come,first-served(FCFS)ordering,sothattheprocessthathasbeenwait-
ingthelongestisresumedfirst.Inmanycircumstances,however,suchasimple
scheduling scheme is not adequate. In these circumstances, the conditional-
waitconstructcanbeused.Thisconstructhastheform
x.wait(c);
wherecisanintegerexpressionthatisevaluatedwhenthewait()operation
is executed. The value of c, which is called a priority number, is then stored
withthenameoftheprocessthatissuspended.Whenx.signal()isexecuted,
theprocesswiththesmallestprioritynumberisresumednext.
Toillustratethisnewmechanism,considertheResourceAllocatormon-
itor shown in Figure 6.14, which controls the allocation of a single resource
among competing processes. Each process, when requesting an allocation of
thisresource,specifiesthemaximumtimeitplanstousetheresource.Themon-
itor allocates the resource to the process that has the shortest time-allocation282 Chapter6 SynchronizationTools
request.Aprocessthat needstoaccess theresourceinquestionmustobserve
thefollowingsequence:
R.acquire(t);
...
accesstheresource;
...
R.release();
whereRisaninstanceoftypeResourceAllocator.
Unfortunately, the monitor concept cannot guarantee that the preceding
access sequence will be observed. In particular, the following problems can
occur:
• Aprocessmightaccessaresourcewithoutfirstgainingaccesspermission
totheresource.
• Aprocess might never release a resource once it has been granted access
totheresource.
• Aprocessmightattempttoreleasearesourcethatitneverrequested.
• Aprocess might request the same resource twice (without first releasing
theresource).
The same difficulties are encountered with the use of semaphores, and
these difficulties are similar in nature to those that encouraged us to develop
the monitor constructs in the first place. Previously, we had to worry about
thecorrectuseofsemaphores.Now,wehavetoworryaboutthecorrectuseof
higher-levelprogrammer-definedoperations,withwhichthecompilercanno
longerassistus.
One possible solution to the current problem is to include the resource-
access operations within the ResourceAllocator monitor. However, using
this solution will mean that scheduling is done according to the built-in
monitor-schedulingalgorithmratherthantheonewehavecoded.
To ensure that the processes observe the appropriatesequences, we must
inspectalltheprogramsthatmakeuseoftheResourceAllocatormonitorand
its managed resource.We must check two conditions to establishthe correct-
ness of this system. First, user processes must always make their calls on the
monitorinacorrectsequence.Second,wemustbesurethatanuncooperative
processdoesnotsimplyignorethemutual-exclusiongatewayprovidedbythe
monitorandtrytoaccessthesharedresourcedirectly,withoutusingtheaccess
protocols.Onlyifthesetwoconditionscanbeensuredcanweguaranteethat
notime-dependenterrorswilloccurandthattheschedulingalgorithmwillnot
bedefeated.
Although this inspection may be possible for a small, static system, it is
not reasonable for a large system or a dynamic system. This access-control
problemcanbesolvedonlythroughtheuseoftheadditionalmechanismsthat
aredescribedinChapter17.6.8 Liveness 283
6.8 Liveness
Oneconsequenceofusingsynchronizationtoolstocoordinateaccesstocritical
sectionsis thepossibilitythat aprocessattemptingtoenteritscritical section
willwaitindefinitely.RecallthatinSection6.2,weoutlinedthreecriteriathat
solutionstothecritical-sectionproblemmustsatisfy.Indefinitewaitingviolates
twoofthese—theprogressandbounded-waitingcriteria.
Liveness refers to a set of properties that a systemmust satisfy to ensure
thatprocessesmakeprogressduringtheirexecutionlifecycle.Aprocesswait-
ing indefinitely under the circumstances just described is an example of a
“livenessfailure.”
There are many different forms of liveness failure; however, all are gen-
erally characterized by poor performance and responsiveness. Avery simple
exampleofalivenessfailureisaninfiniteloop.Abusywaitlooppresentsthe
possibility of a liveness failure, especially if a process may loop an arbitrarily
longperiodoftime.Effortsatprovidingmutualexclusionusingtoolssuchas
mutexlocksandsemaphorescanoftenleadtosuchfailuresinconcurrentpro-
gramming.Inthissection,weexploretwosituationsthatcanleadtoliveness
failures.
6.8.1 Deadlock
The implementation of a semaphore with a waiting queue may result in a
situation where two or more processes are waiting indefinitely for an event
thatcanbecausedonlybyoneofthewaitingprocesses.Theeventinquestion
istheexecutionof asignal()operation.Whensuchastateisreached,these
processesaresaidtobedeadlocked.
Toillustratethis,considerasystemconsistingoftwoprocesses,P andP ,
0 1
eachaccessingtwosemaphores,SandQ,settothevalue1:
P P
0 1
wait(S); wait(Q);
wait(Q); wait(S);
. .
. .
. .
signal(S); signal(Q);
signal(Q); signal(S);
SupposethatP executeswait(S)andthenP executeswait(Q).WhenP
0 1 0
executeswait(Q), it must wait until P executes signal(Q).Similarly,when
1
P executes wait(S), it must wait until P executes signal(S). Since these
1 0
signal()operationscannotbeexecuted,P andP aredeadlocked.
0 1
We say that a set of processes is in a deadlocked state when every process
in the set is waiting for an event that can be caused only by another process in the
set.The“events”withwhichwearemainlyconcernedherearetheacquisition
andreleaseofresourcessuchas mutexlocks and semaphores.Othertypesof
events may result in deadlocks, as we show in more detail in Chapter 8. In284 Chapter6 SynchronizationTools
that chapter, we describe various mechanisms for dealing with the deadlock
problem,aswellasotherformsoflivenessfailures.
6.8.2 Priority Inversion
A scheduling challenge arises when a higher-priority process needs to read
or modify kernel data that are currently being accessed by a lower-priority
process—or a chain of lower-priority processes. Since kernel data are typi-
cally protected with a lock, the higher-priority process will have to wait for
a lower-priority one to finish with the resource. The situation becomes more
complicated if the lower-priority process is preempted in favor of another
processwithahigherpriority.
As an example, assume we have three processes—L, M, and H—whose
priorities follow the order L < M < H. Assume that process H requires
a semaphore S, which is currently being accessed by process L. Ordinarily,
processHwouldwaitforLtofinishusingresourceS.However,nowsuppose
thatprocessMbecomesrunnable,therebypreemptingprocessL.Indirectly,a
processwithalowerpriority—process M—has affectedhow long processH
mustwaitforLtorelinquishresourceS.
This liveness problem is known as priority inversion, and it can occur
only in systemswithmore thantwo priorities.Typically,priorityinversionis
avoided by implementing a priority-inheritance protocol. According to this
protocol,allprocessesthatareaccessingresourcesneededbyahigher-priority
processinheritthehigherpriorityuntiltheyarefinishedwiththeresourcesin
question.Whentheyarefinished,theirprioritiesreverttotheiroriginalvalues.
In the example above, a priority-inheritance protocol would allow process L
totemporarilyinheritthepriorityofprocessH,therebypreventingprocessM
frompreemptingitsexecution.WhenprocessLhadfinishedusingresourceS,it
wouldrelinquishitsinheritedpriorityfromHandassumeitsoriginalpriority.
Because resource S would now be available, process H—not M—would run
next.
6.9 Evaluation
Wehavedescribedseveraldifferentsynchronizationtoolsthatcanbeusedto
solve the critical-section problem. Given correct implementation and usage,
thesetoolscanbeusedeffectivelytoensuremutualexclusionaswellasaddress
liveness issues. With the growth of concurrent programs that leverage the
power of modern multicore computer systems, increasing attention is being
paid to the performance of synchronization tools. Trying to identify when
to use which tool, however, can be a daunting challenge. In this section, we
presentsomesimplestrategiesfordeterminingwhentousespecificsynchro-
nizationtools.
The hardware solutions outlined in Section 6.4 are considered very low
levelandaretypicallyusedasthefoundationsforconstructingothersynchro-
nization tools, such as mutex locks. However, there has been a recent focus
on using the CAS instruction to construct lock-free algorithms that provide
protection from race conditions without requiring the overhead of locking.
Althoughtheselock-freesolutionsaregainingpopularityduetolowoverhead6.9 Evaluation 285
PRIORITYINVERSIONANDTHEMARSPATHFINDER
Priorityinversioncanbemorethanaschedulinginconvenience.Onsystems
with tight time constraints—such as real-time systems—priority inversion
cancauseaprocesstotakelongerthanitshouldtoaccomplishatask.When
thathappens,otherfailurescancascade,resultinginsystemfailure.
ConsidertheMarsPathfinder,aNASAspaceprobethatlandedarobot,the
Sojourner rover, on Mars in 1997 to conduct experiments. Shortly after the
Sojournerbeganoperating,itstartedtoexperiencefrequentcomputerresets.
Each reset reinitialized all hardware and software, including communica-
tions. If the problem had not been solved, the Sojourner would have failed
initsmission.
Theproblemwascausedbythefactthatonehigh-prioritytask,“bc dist,”
was taking longer than expected to complete its work. This task was being
forced to wait for a shared resource that was held by the lower-priority
“ ASI/MET”task,whichinturnwaspreemptedbymultiplemedium-priority
tasks. The “bc dist” task would stall waiting for the shared resource, and
ultimatelythe“bc sched”taskwoulddiscovertheproblemandperformthe
reset.TheSojournerwassufferingfromatypicalcaseofpriorityinversion.
TheoperatingsystemontheSojournerwastheVxWorksreal-timeoperat-
ingsystem,whichhadaglobalvariabletoenablepriorityinheritanceonall
semaphores.Aftertesting,thevariablewassetontheSojourner(onMars!),
andtheproblemwassolved.
A full description of the problem, its detection, and its solu-
tion was written by the software team lead and is available at
http://research.microsoft.com/en-us/um/people/mbj/mars pathfinder/
authoritative account.html.
and ability to scale, the algorithms themselves are often difficult to develop
andtest.(Intheexercisesattheendofthischapter,weaskyoutoevaluatethe
correctnessofalock-freestack.)
CAS-based approaches are considered an optimistic approach—you opti-
mistically first update a variable and then use collision detection to see if
another thread is updating the variable concurrently. If so, you repeatedly
retry the operation until it is successfully updated without conflict. Mutual-
exclusionlocking,incontrast,isconsideredapessimisticstrategy;youassume
another thread is concurrently updating the variable, so you pessimistically
acquirethelockbeforemakinganyupdates.
The following guidelines identify general rules concerning performance
differences between CAS-based synchronization and traditional synchroniza-
tion(suchasmutexlocksandsemaphores)undervaryingcontentionloads:
• Uncontended. Although both options are generally fast, CAS protection
willbesomewhatfasterthantraditionalsynchronization.
• Moderatecontention.CASprotectionwillbefaster—possiblymuchfaster
—thantraditionalsynchronization.286 Chapter6 SynchronizationTools
• Highcontention.Underveryhighlycontendedloads,traditionalsynchro-
nizationwillultimatelybefasterthanCAS-basedsynchronization.
Moderatecontentionisparticularlyinterestingtoexamine.Inthisscenario,
the CAS operation succeeds most of the time, and when it fails, it will iterate
through the loop shown in Figure6.8only afewtimes beforeultimatelysuc-
ceeding.Bycomparison,withmutual-exclusionlocking,anyattempttoacquire
acontendedlockwillresultinamorecomplicated—andtime-intensive—code
paththatsuspendsathreadandplacesitonawaitqueue,requiringacontext
switchtoanotherthread.
Thechoiceofamechanismthataddressesraceconditionscanalsogreatly
affect system performance. For example, atomic integers are much lighter
weightthantraditionallocks,andaregenerallymoreappropriatethanmutex
locks or semaphores for single updates to shared variables such as counters.
We also see this in the design of operating systems where spinlocks are used
onmultiprocessorsystemswhenlocksareheldforshortdurations.Ingeneral,
mutex locks are simpler and require less overhead than semaphores and are
preferable to binary semaphores for protecting access to a critical section.
However, for some uses—such as controlling access to a finite number of
resources—acountingsemaphoreisgenerallymoreappropriatethanamutex
lock.Similarly,insomeinstances,areader–writerlockmaybepreferredover
a mutex lock, as it allows a higher degree of concurrency (that is, multiple
readers).
Theappealofhigher-leveltoolssuchasmonitorsandconditionvariables
is based on their simplicity and ease of use. However, such tools may have
significant overhead and, depending on their implementation, may be less
likelytoscaleinhighlycontendedsituations.
Fortunately, there is much ongoing research toward developing scalable,
efficient tools that address the demands of concurrent programming. Some
examplesinclude:
• Designingcompilersthatgeneratemoreefficientcode.
• Developinglanguagesthatprovidesupportforconcurrentprogramming.
• ImprovingtheperformanceofexistinglibrariesandAPIs.
Inthe nextchapter, we examinehow variousoperating systemsand APIs
availabletodevelopersimplementthesynchronizationtoolspresentedinthis
chapter.
6.10 Summary
• Araceconditionoccurswhenprocesseshaveconcurrentaccesstoshared
data and the final result depends on the particular order in which con-
current accesses occur. Race conditions can result in corrupted values of
shareddata.
• Acritical section is a section of code where shared data may be manipu-
latedandapossibleraceconditionmayoccur.Thecritical-sectionproblemPracticeExercises 287
istodesignaprotocolwherebyprocessescansynchronizetheiractivityto
cooperativelysharedata.
• Asolutiontothecritical-sectionproblemmustsatisfythefollowingthree
requirements:(1)mutualexclusion,(2)progress,and(3)boundedwaiting.
Mutualexclusionensuresthatonlyoneprocessatatimeisactiveinitscrit-
icalsection.Progressensuresthatprogramswillcooperativelydetermine
what process will next enter its critical section. Bounded waiting limits
howmuchtimeaprogramwillwaitbeforeitcanenteritscriticalsection.
• Softwaresolutionstothecritical-sectionproblem,suchasPeterson’ssolu-
tion,donotworkwellonmoderncomputerarchitectures.
• Hardwaresupportforthecritical-sectionproblemincludesmemorybarri-
ers;hardwareinstructions,suchasthecompare-and-swapinstruction;and
atomicvariables.
• A mutex lock provides mutual exclusion by requiring that a process
acquire a lock before entering a critical section and release the lock on
exitingthecriticalsection.
• Semaphores, like mutex locks, can be used to provide mutual exclusion.
However,whereasamutexlockhasabinaryvaluethatindicatesifthelock
isavailableornot,asemaphorehasanintegervalueandcanthereforebe
usedtosolveavarietyofsynchronizationproblems.
• A monitor is an abstract data type that provides a high-level form of
process synchronization. A monitor uses condition variables that allow
processes to wait for certain conditions to become true and to signal one
anotherwhenconditionshavebeensettotrue.
• Solutions to the critical-section problem may suffer from liveness prob-
lems,includingdeadlock.
• Thevarioustoolsthatcanbeusedtosolvethecritical-sectionproblemas
well as to synchronize the activity of processes can be evaluated under
varying levels of contention. Some tools work better under certain con-
tentionloadsthanothers.
Practice Exercises
6.1 In Section 6.4, we mentioned that disabling interrupts frequently can
affect the system’s clock. Explain why this can occur and how such
effectscanbeminimized.
6.2 What is the meaning of the term busy waiting? What other kinds of
waitingarethereinanoperatingsystem?Canbusywaitingbeavoided
altogether?Explainyouranswer.
6.3 Explainwhyspinlocksarenotappropriateforsingle-processorsystems
yetareoftenusedinmultiprocessorsystems.
6.4 Show that, if the wait() and signal() semaphore operations are not
executedatomically,thenmutualexclusionmaybeviolated.288 Chapter6 SynchronizationTools
6.5 Illustrate how a binary semaphore can be used to implement mutual
exclusionamongnprocesses.
6.6 Race conditions are possible in many computer systems. Consider a
banking system that maintains an account balance with two functions:
deposit(amount) and withdraw(amount). These two functions are
passedthe amountthat istobedepositedor withdrawnfromthe bank
accountbalance.Assumethatahusbandandwifeshareabankaccount.
Concurrently,thehusbandcallsthewithdraw()function,andthewife
calls deposit(). Describe how a race condition is possible and what
mightbedonetopreventtheraceconditionfromoccurring.
Further Reading
Themutual-exclusionproblemwasfirstdiscussedinaclassicpaperby[Dijk-
stra (1965)]. The semaphore concept was suggested by [Dijkstra (1965)]. The
monitor concept was developed by [Brinch-Hansen (1973)]. [Hoare (1974)]
gaveacompletedescriptionofthemonitor.
FormoreontheMarsPathfinderproblemseehttp://research.microsoft.co
m/en-us/um/people/mbj/mars pathfinder/authoritative account.html
Athoroughdiscussionofmemorybarriersandcachememoryispresented
in [Mckenney (2010)]. [Herlihy and Shavit (2012)] presents details on several
issuesrelatedtomultiprocessorprogramming,includingmemorymodelsand
compare-and-swap instructions. [Bahra (2013)] examines nonblocking algo-
rithmsonmodernmulticoresystems.
Bibliography
[Bahra(2013)] S. A. Bahra, “Nonblocking Algorithms and Scalable Multicore
Programming”,ACMqueue,Volume11,Number5(2013).
[Brinch-Hansen(1973)] P.Brinch-Hansen,OperatingSystemPrinciples,Prentice
Hall(1973).
[Dijkstra(1965)] E. W.Dijkstra,“CooperatingSequentialProcesses”,Technical
report,TechnologicalUniversity,Eindhoven,theNetherlands(1965).
[HerlihyandShavit(2012)] M.HerlihyandN.Shavit,TheArtofMultiprocessor
Programming,RevisedFirstEdition,MorganKaufmannPublishersInc.(2012).
[Hoare(1974)] C. A. R. Hoare, “Monitors: An Operating System Structuring
Concept”, Communications of the ACM, Volume 17, Number 10 (1974), pages
549–557.
[Mckenney(2010)] P. E. Mckenney, “Memory Barriers: a Hardware View for
SoftwareHackers”(2010).EX-17
Chapter 6 Exercises
6.7 The pseudocode of Figure 6.15 illustrates the basic push() and pop()
operationsofanarray-basedstack.Assumingthatthisalgorithmcould
beusedinaconcurrentenvironment,answerthefollowingquestions:
a. Whatdatahavearacecondition?
b. Howcouldtheraceconditionbefixed?
6.8 Race conditions are possible in many computer systems. Consider an
online auction system where the current highest bid for each item
must be maintained. Aperson who wishes to bid on an item calls the
bid(amount) function, which compares the amount being bid to the
current highest bid. If the amount exceeds the current highest bid, the
highestbidissettothenewamount.Thisisillustratedbelow:
void bid(double amount) {
if (amount > highestBid)
highestBid = amount;
}
push(item) {
if (top < SIZE) {
stack[top] = item;
top++;
}
else
ERROR
}
pop() {
if (!is empty()) {
top--;
return stack[top];
}
else
ERROR
}
is empty() {
if (top == 0)
return true;
else
return false;
}
Figure6.16 Array-basedstackforExercise6.12.Exercises EX-18
5 10 15 20 25 30 35 40
0 1 2 3 4 5 6 7
+ + + +
5 15 15 35 25 55 35 75
0 1 2 3 4 5 6 7
+ +
5 15 15 50 25 55 35 130
0 1 2 3 4 5 6 7
+
5 15 15 50 25 55 35 180
0 1 2 3 4 5 6 7
Figure6.17 SumminganarrayasaseriesofpartialsumsforExercise6.14.
Describe how a race condition is possible in this situation and what
mightbedonetopreventtheraceconditionfromoccurring.
6.9 The following program example can be used to sum the array values
ofsizeNelementsinparallelonasystemcontainingNcomputingcores
(thereisaseparateprocessorforeacharrayelement):
for j = 1 to log 2(N) {
for k = 1 to N {
if ((k + 1) % pow(2,j) == 0) {
values[k] += values[k - pow(2,(j-1))]
}
}
}
This has the effect of summing the elements in the array as a series
of partial sums, as shown in Figure 6.16. After the code has executed,
the sum of all elements in the array is stored in the last array location.
Arethereanyraceconditionsintheabovecodeexample?Ifso,identify
where they occur and illustrate with an example. If not, demonstrate
whythisalgorithmisfreefromraceconditions.
6.10 The compare and swap() instruction can be used to design lock-free
datastructuressuch as stacks,queues,and lists.Theprogram example
shown in Figure 6.17 presents a possible solution to a lock-free stack
using CAS instructions, where the stack is represented as a linked list
of Node elements with top representing the top of the stack. Is this
implementationfreefromraceconditions?EX-19
typedef struct node {
value t data;
struct node *next;
} Node;
Node *top; // top of stack
void push(value t item) {
Node *old node;
Node *new node;
new node = malloc(sizeof(Node));
new node->data = item;
do {
old node = top;
new node->next = old node;
}
while (compare and swap(top,old node,new node) != old node);
}
value t pop() {
Node *old node;
Node *new node;
do {
old node = top;
if (old node == NULL)
return NULL;
new node = old node->next;
}
while (compare and swap(top,old node,new node) != old node);
return old node->data;
}
Figure6.18 Lock-freestackforExercise6.15.
6.11 Oneapproachforusingcompare and swap()forimplementingaspin-
lockisasfollows:
void lock spinlock(int *lock) {
while (compare and swap(lock, 0, 1) != 0)
; /* spin */
}
Asuggestedalternativeapproachistousethe“compareandcompare-
and-swap”idiom,whichchecksthestatusofthelockbeforeinvokingtheExercises EX-20
compare and swap()operation.(Therationalebehindthisapproachis
to invoke compare and swap()only if the lock is currently available.)
Thisstrategyisshownbelow:
void lock spinlock(int *lock) {
{
while (true) {
if (*lock == 0) {
/* lock appears to be available */
if (!compare and swap(lock, 0, 1))
break;
}
}
}
Doesthis“compareandcompare-and-swap”idiomworkappropriately
for implementing spinlocks? If so, explain. If not, illustrate how the
integrityofthelockiscompromised.
6.12 SomesemaphoreimplementationsprovideafunctiongetValue()that
returnsthecurrentvalueofasemaphore.Thisfunctionmay,forinstance,
beinvokedpriortocallingwait()sothataprocesswillonlycallwait()
ifthevalueofthesemaphoreis> 0,therebypreventingblockingwhile
waitingforthesemaphore.Forexample:
if (getValue(&sem) > 0)
wait(&sem);
Manydevelopersargueagainstsuchafunctionanddiscourageitsuse.
Describeapotentialproblemthatcouldoccur whenusingthefunction
getValue()inthisscenario.
6.13 Thefirstknowncorrectsoftwaresolutiontothecritical-sectionproblem
fortwoprocesseswasdevelopedbyDekker.Thetwoprocesses,P and
0
P ,sharethefollowingvariables:
1
boolean flag[2]; /* initially false */
int turn;
The structure of process P (i == 0 or 1) is shown in Figure 6.18. The
i
other process is P (j == 1 or 0). Prove that the algorithm satisfies all
j
threerequirementsforthecritical-sectionproblem.
6.14 Thefirstknowncorrectsoftwaresolutiontothecritical-sectionproblem
for n processes with a lower bound on waiting of n − 1 turns was
presentedbyEisenbergandMcGuire.Theprocessessharethefollowing
variables:
enum pstate{idle, want in, in cs};
pstate flag[n];
int turn;EX-21
while (true) {
flag[i] = true;
while (flag[j]) {
if (turn == j) {
flag[i] = false;
while (turn == j)
; /* do nothing */
flag[i] = true;
}
}
/* critical section */
turn = j;
flag[i] = false;
/* remainder section */
}
Figure6.19 ThestructureofprocessP inDekker’salgorithm.
i
All the elements of flag are initially idle. The initial value of turn is
immaterial(between0andn-1).ThestructureofprocessP isshownin
i
Figure6.19.Provethatthealgorithmsatisfiesallthreerequirementsfor
thecritical-sectionproblem.
6.15 Explain why implementing synchronization primitives by disabling
interruptsisnotappropriateinasingle-processorsystemifthesynchro-
nizationprimitivesaretobeusedinuser-levelprograms.
6.16 Consider how to implement a mutex lock using the com-
pare and swap() instruction. Assume that the following structure
definingthemutexlockisavailable:
typedef struct{
int available;
}lock;
The value (available == 0) indicates that the lock is available, and
a value of 1 indicates that the lock is unavailable. Using this struct,
illustrate how the following functions can be implemented using the
compare and swap()instruction:
• void acquire(lock *mutex)
• void release(lock *mutex)
Besuretoincludeanyinitializationthatmaybenecessary.Exercises EX-22
while (true) {
while (true) {
flag[i] = want in;
j = turn;
while (j != i) {
if (flag[j] != idle) {
j = turn;
else
j = (j + 1) % n;
}
flag[i] = in cs;
j = 0;
while ( (j < n) && (j == i || flag[j] != in cs))
j++;
if ( (j >= n) && (turn == i || flag[turn] == idle))
break;
}
/* critical section */
j = (turn + 1) % n;
while (flag[j] == idle)
j = (j + 1) % n;
turn = j;
flag[i] = idle;
/* remainder section */
}
Figure6.20 ThestructureofprocessP inEisenbergandMcGuire’salgorithm.
i
6.17 Explainwhy interruptsarenot appropriatefor implementingsynchro-
nizationprimitivesinmultiprocessorsystems.
6.18 TheimplementationofmutexlocksprovidedinSection6.5suffersfrom
busy waiting. Describe what changes would be necessary so that a
process waiting to acquire a mutex lock would be blocked and placed
intoawaitingqueueuntilthelockbecameavailable.
6.19 Assume that a system has multiple processing cores. For each of the
following scenarios, describe which is a better locking mechanism—aEX-23
spinlock or a mutex lock where waiting processes sleep while waiting
forthelocktobecomeavailable:
• Thelockistobeheldforashortduration.
• Thelockistobeheldforalongduration.
• Athreadmaybeputtosleepwhileholdingthelock.
6.20 Assume that a context switch takes T time. Suggest an upper bound
(in terms of T) for holding a spinlock. If the spinlock is held for any
longer,amutexlock(wherewaitingthreadsareputtosleep)isabetter
alternative.
6.21 A multithreaded web server wishes to keep track of the number of
requestsitservices(knownas hits).Considerthetwofollowingstrate-
giestopreventaraceconditiononthevariablehits.Thefirststrategy
istouseabasicmutexlockwhenupdatinghits:
int hits;
mutex lock hit lock;
hit lock.acquire();
hits++;
hit lock.release();
Asecondstrategyistouseanatomicinteger:
atomic t hits;
atomic inc(&hits);
Explainwhichofthesetwostrategiesismoreefficient.
6.22 Considerthecodeexampleforallocatingandreleasingprocessesshown
inFigure6.20.
a. Identifytheracecondition(s).
b. Assumeyouhaveamutexlocknamedmutexwiththeoperations
acquire()andrelease().Indicatewherethelockingneedstobe
placedtopreventtheracecondition(s).
c. Couldwereplacetheintegervariable
int number of processes = 0
withtheatomicinteger
atomic t number of processes = 0
topreventtheracecondition(s)?
6.23 Servers can be designed to limit the number of open connections. For
example, a server may wish to have only N socket connections at any
point in time. As soon as N connections are made, the server will
not accept another incoming connection until an existing connection isExercises EX-24
#define MAX PROCESSES 255
int number of processes = 0;
/* the implementation of fork() calls this function */
int allocate process() {
int new pid;
if (number of processes == MAX PROCESSES)
return -1;
else {
/* allocate necessary process resources */
++number of processes;
return new pid;
}
}
/* the implementation of exit() calls this function */
void release process() {
/* release process resources */
--number of processes;
}
Figure6.21 AllocatingandreleasingprocessesforExercise6.27.
released.Illustratehowsemaphorescanbeusedbyaservertolimitthe
numberofconcurrentconnections.
6.24 In Section 6.7, we use the following illustration as an incorrect use of
semaphorestosolvethecritical-sectionproblem:
wait(mutex);
...
criticalsection
...
wait(mutex);
Explainwhythisisanexampleofalivenessfailure.
6.25 Demonstratethatmonitorsandsemaphoresareequivalenttothedegree
that theycan beusedtoimplementsolutionstothesametypesofsyn-
chronizationproblems.
6.26 Describehowthesignal() operationassociatedwithmonitorsdiffers
fromthecorrespondingoperationdefinedforsemaphores.
6.27 Supposethesignal() statementcan appearonlyas thelaststatement
in a monitor function. Suggest how the implementation described in
Section6.7canbesimplifiedinthissituation.EX-25
6.28 ConsiderasystemconsistingofprocessesP ,P ,...,P ,eachofwhichhas
1 2 n
auniqueprioritynumber.Writeamonitorthatallocatesthreeidentical
printerstotheseprocesses,usingtheprioritynumbersfordecidingthe
orderofallocation.
6.29 A file is to be shared among different processes, each of which has
a unique number. The file can be accessed simultaneously by several
processes, subject to the following constraint: the sum of all unique
numbers associated with all the processes currently accessing the file
mustbelessthann.Writeamonitortocoordinateaccesstothefile.
6.30 Whenasignalisperformedonaconditioninsideamonitor,thesignaling
processcaneithercontinueitsexecutionortransfercontroltotheprocess
thatissignaled.Howwouldthesolutiontotheprecedingexercisediffer
withthesetwodifferentwaysinwhichsignalingcanbeperformed?
6.31 Designanalgorithmforamonitorthatimplementsanalarmclockthat
enablesacallingprogramtodelayitselfforaspecifiednumberoftime
units(ticks).Youmayassumetheexistenceofarealhardwareclockthat
invokesafunctiontick()inyourmonitoratregularintervals.
6.32 Discuss ways in which the priority inversion problem could be
addressed in a real-time system. Also discuss whether the solutions
could be implemented within the context of a proportional share
scheduler.P-32 Chapter6 SynchronizationTools
Programming Problems
6.33 Assumethatafinitenumberofresourcesofasingleresourcetypemust
bemanaged.Processesmayaskforanumberoftheseresourcesandwill
return them once finished. As an example, many commercial software
packagesprovideagivennumberoflicenses,indicatingthenumberof
applicationsthatmayrunconcurrently.Whentheapplicationisstarted,
the license count is decremented. When the application is terminated,
the license count is incremented. If all licenses are in use, requests to
start the application are denied. Such a request will be granted only
whenanexistinglicenseholderterminatestheapplicationandalicense
isreturned.
Thefollowingprogramsegmentisusedtomanageafinitenumberof
instances of an available resource. The maximum number of resources
andthenumberofavailableresourcesaredeclaredasfollows:
#define MAX RESOURCES 5
int available resources = MAX RESOURCES;
When a process wishes to obtain a number of resources, it invokes the
decrease count()function:
/* decrease available resources by count resources */
/* return 0 if sufficient resources available, */
/* otherwise return -1 */
int decrease count(int count) {
if (available resources < count)
return -1;
else {
available resources -= count;
return 0;
}
}
When a process wants to return a number of resources, it calls the
increase count()function:
/* increase available resources by count */
int increase count(int count) {
available resources += count;
return 0;
}
Theprecedingprogramsegmentproducesaracecondition.Dothefol-
lowing:
a. Identifythedatainvolvedintheracecondition.ProgrammingProblems P-33
b. Identifythelocation(orlocations)inthecodewheretheracecon-
ditionoccurs.
c. Using a semaphore or mutex lock, fix the race condition. It is
permissibletomodifythedecrease count()functionsothatthe
callingprocessisblockeduntilsufficientresourcesareavailable.
6.34 The decrease count() function in the previous exercise currently
returns 0 if sufficient resources are available and −1 otherwise. This
leads to awkward programming for a process that wishes to obtain a
numberofresources:
while (decrease count(count) == -1)
;
Rewrite the resource-manager code segment using a monitor and con-
dition variables so that the decrease count() function suspends the
processuntilsufficientresourcesareavailable.Thiswillallowaprocess
toinvokedecrease count()bysimplycalling
decrease count(count);
The process will return from this function call only when sufficient
resourcesareavailable.7
CHAPTER
Synchronization
Examples
In Chapter 6, we presented the critical-section problem and focused on how
raceconditionscanoccurwhenmultipleconcurrentprocessessharedata.We
went on to examine several tools that address the critical-section problem by
preventingraceconditionsfromoccurring.Thesetoolsrangedfromlow-level
hardwaresolutions(suchasmemorybarriersandthecompare-and-swapoper-
ation) to increasingly higher-level tools (from mutex locks to semaphores to
monitors).Wealsodiscussedvariouschallengesindesigningapplicationsthat
are free from race conditions, including liveness hazards such as deadlocks.
In this chapter, we apply the tools presented in Chapter 6 to several classic
synchronization problems. We also explore the synchronization mechanisms
used by the Linux, UNIX, and Windows operating systems, and we describe
APIdetailsforbothJavaandPOSIXsystems.
CHAPTER OBJECTIVES
• Explain the bounded-buffer, readers–writers, and dining–philosophers
synchronizationproblems.
• Describe specific tools used by Linux and Windows to solve process
synchronizationproblems.
• IllustratehowPOSIXandJavacanbeusedtosolveprocesssynchroniza-
tionproblems.
• Designanddevelop solutionstoprocess synchronization problemsusing
POSIXandJavaAPIs.
7.1 Classic Problems of Synchronization
Inthissection,wepresentanumberofsynchronizationproblemsasexamples
ofalargeclassofconcurrency-controlproblems.Theseproblemsareusedfor
testingnearlyeverynewlyproposedsynchronizationscheme.Inoursolutions
to the problems, we use semaphores for synchronization, since that is the
289290 Chapter7 SynchronizationExamples
while (true) {
. . .
/* produce an item in next produced */
. . .
wait(empty);
wait(mutex);
. . .
/* add next produced to the buffer */
. . .
signal(mutex);
signal(full);
}
Figure7.1 Thestructureoftheproducerprocess.
traditional way to present such solutions. However, actual implementations
ofthesesolutionscouldusemutexlocksinplaceofbinarysemaphores.
7.1.1 The Bounded-Buffer Problem
Thebounded-bufferproblemwasintroducedinSection6.1;itiscommonlyused
toillustratethepowerofsynchronizationprimitives.Here,wepresentagen-
eral structure of this scheme without committing ourselves to any particular
implementation.Weprovidearelatedprogrammingprojectintheexercisesat
theendofthechapter.
Inourproblem,theproducerandconsumerprocessessharethefollowing
datastructures:
int n;
semaphore mutex = 1;
semaphore empty = n;
semaphore full = 0
Weassumethatthepoolconsistsofnbuffers,eachcapableofholdingoneitem.
The mutex binary semaphore provides mutual exclusion for accesses to the
buffer pooland isinitializedtothe value1. Theemptyand fullsemaphores
countthenumberofemptyandfullbuffers.Thesemaphoreemptyisinitialized
tothevaluen;thesemaphorefullisinitializedtothevalue0.
The code for the producer process is shown in Figure 7.1, and the code
fortheconsumerprocessisshowninFigure7.2.Notethesymmetrybetween
the producer and the consumer. We can interpret this code as the producer
producingfullbuffersfortheconsumerorastheconsumerproducingempty
buffersfortheproducer.
7.1.2 The Readers–Writers Problem
Suppose that a database is to be shared among several concurrent processes.
Some of these processes may want only to read the database, whereas others
may want to update (that is, read and write) the database. We distinguish7.1 ClassicProblemsofSynchronization 291
while (true) {
wait(full);
wait(mutex);
. . .
/* remove an item from buffer to next consumed */
. . .
signal(mutex);
signal(empty);
. . .
/* consume the item in next consumed */
. . .
}
Figure7.2 Thestructureoftheconsumerprocess.
between these two types of processes by referring to the former as readers
and to the latter as writers. Obviously, if two readers access the shared data
simultaneously, no adverse effects will result. However, if a writer and some
otherprocess(eitherareaderorawriter)accessthedatabasesimultaneously,
chaosmayensue.
To ensure that these difficulties do not arise, we require that the writers
haveexclusiveaccesstotheshareddatabasewhilewritingtothedatabase.This
synchronizationproblemisreferredtoasthereaders–writersproblem.Sinceit
wasoriginallystated,ithasbeenusedtotestnearlyeverynewsynchronization
primitive.
The readers–writers problem has several variations, all involving priori-
ties.Thesimplestone,referredtoasthefirstreaders–writersproblem,requires
thatnoreaderbekeptwaitingunlessawriterhasalreadyobtainedpermission
tousethesharedobject.Inotherwords,noreadershouldwaitforotherread-
ers to finish simply because a writer is waiting. The second readers–writers
problem requires that, once a writer is ready, that writer perform its write as
soonaspossible.Inotherwords,ifawriteriswaitingtoaccesstheobject, no
newreadersmaystartreading.
A solution to either problem may result in starvation. In the first case,
writers may starve; in the second case, readers may starve. For this reason,
othervariantsoftheproblemhavebeenproposed.Next,wepresentasolution
to the first readers–writers problem. See the bibliographical notes at the end
ofthechapterforreferencesdescribingstarvation-freesolutionstothesecond
readers–writersproblem.
In the solution to the first readers–writers problem, the reader processes
sharethefollowingdatastructures:
semaphore rw mutex = 1;
semaphore mutex = 1;
int read count = 0;
The binary semaphores mutex and rw mutex are initialized to 1;
read countisacountingsemaphoreinitializedto0.Thesemaphorerw mutex292 Chapter7 SynchronizationExamples
while (true) {
wait(rw mutex);
. . .
/* writing is performed */
. . .
signal(rw mutex);
}
Figure7.3 Thestructureofawriterprocess.
iscommontobothreaderandwriterprocesses.Themutexsemaphoreisused
to ensure mutual exclusion when the variable read count is updated.
The read count variable keeps track of how many processes are currently
reading the object. The semaphore rw mutex functions as a mutual exclusion
semaphoreforthewriters.Itisalsousedbythefirstorlastreaderthatenters
or exits the critical section. It is not used by readers that enter or exit while
otherreadersareintheircriticalsections.
ThecodeforawriterprocessisshowninFigure7.3;thecodeforareader
process is shown in Figure 7.4. Note that, if a writer is in the critical section
and nreadersarewaiting,thenone readerisqueuedonrw mutex,and n −1
readersarequeuedonmutex.Alsoobservethat,whenawriterexecutessig-
nal(rw mutex),wemayresumetheexecutionofeitherthewaitingreadersor
asinglewaitingwriter.Theselectionismadebythescheduler.
The readers–writers problem and its solutions have been generalized to
providereader–writerlocksonsomesystems.Acquiringareader–writerlock
requires specifying the mode of the lock: either read or write access. When a
while (true) {
wait(mutex);
read count++;
if (read count == 1)
wait(rw mutex);
signal(mutex);
. . .
/* reading is performed */
. . .
wait(mutex);
read count--;
if (read count == 0)
signal(rw mutex);
signal(mutex);
}
Figure7.4 Thestructureofareaderprocess.7.1 ClassicProblemsofSynchronization 293
process wishes only to read shared data, it requests the reader–writer lock
in read mode. Aprocess wishing to modify the shared data must requestthe
lock in write mode. Multiple processes are permittedto concurrently acquire
areader–writerlockinreadmode,butonlyoneprocessmayacquirethelock
forwriting,asexclusiveaccessisrequiredforwriters.
Reader–writerlocksaremostusefulinthefollowingsituations:
• In applications where it is easy to identify which processes only read
shareddataandwhichprocessesonlywriteshareddata.
• In applications that have more readers than writers. This is because
reader–writer locks generally require more overhead to establish than
semaphores or mutual-exclusion locks. The increased concurrency of
allowing multiple readers compensates for the overhead involved in
settingupthereader–writerlock.
7.1.3 The Dining-Philosophers Problem
Consider five philosophers who spend their lives thinking and eating. The
philosophersshareacirculartablesurroundedbyfivechairs,eachbelongingto
onephilosopher.Inthecenterofthetableisabowlofrice,andthetableislaid
with five single chopsticks (Figure 7.5). When a philosopher thinks, she does
notinteractwithhercolleagues.Fromtimetotime,aphilosophergetshungry
and tries to pick up the two chopsticks that are closest to her (the chopsticks
thatarebetweenherandherleftandrightneighbors).Aphilosophermaypick
uponlyonechopstickatatime.Obviously,shecannotpickupachopstickthat
isalreadyinthehandofaneighbor.Whenahungryphilosopherhasbothher
chopsticks at the same time, she eats without releasing the chopsticks. When
sheisfinishedeating,sheputsdownbothchopsticksandstartsthinkingagain.
Thedining-philosophersproblemisconsideredaclassicsynchronization
problem neither because of its practical importance nor because computer
scientists dislike philosophers but because it is an example of a large class
of concurrency-control problems. It is a simple representation of the need
RICE
Figure7.5 Thesituationofthediningphilosophers.294 Chapter7 SynchronizationExamples
while (true) {
wait(chopstick[i]);
wait(chopstick[(i+1) % 5]);
. . .
/* eat for a while */
. . .
signal(chopstick[i]);
signal(chopstick[(i+1) % 5]);
. . .
/* think for awhile */
. . .
}
Figure7.6 Thestructureofphilosopheri.
to allocate several resources among several processes in a deadlock-free and
starvation-freemanner.
7.1.3.1 SemaphoreSolution
One simple solution is to represent each chopstick with a semaphore. A
philosophertriestograbachopstickbyexecutingawait()operationonthat
semaphore.She releasesher chopsticks by executingthe signal()operation
ontheappropriatesemaphores.Thus,theshareddataare
semaphore chopstick[5];
where all the elements of chopstick are initialized to 1. The structure of
philosopheriisshowninFigure7.6.
Althoughthissolutionguaranteesthatnotwoneighborsareeatingsimul-
taneously,itneverthelessmustberejectedbecauseitcouldcreateadeadlock.
Supposethat all five philosophersbecome hungry at the same timeand each
grabs her left chopstick. All the elements of chopstick will now be equal to
0.Wheneachphilosophertriestograbherrightchopstick,shewillbedelayed
forever.
Severalpossibleremediestothedeadlockproblemarethefollowing:
• Allowatmostfourphilosopherstobesittingsimultaneouslyatthetable.
• Allowaphilosophertopickupherchopsticksonlyifbothchopsticksare
available(todothis,shemustpickthemupinacriticalsection).
• Useanasymmetricsolution—thatis,anodd-numberedphilosopherpicks
up first her leftchopstick and then her right chopstick, whereas an even-
numbered philosopher picks up her right chopstick and then her left
chopstick.
In Section 6.7, we present a solution to the dining-philosophers problem
that ensures freedom from deadlocks. Note, however, that any satisfactory
solutiontothedining-philosophersproblemmustguardagainstthepossibility7.2 SynchronizationwithintheKernel 295
thatoneofthephilosopherswillstarvetodeath.Adeadlock-freesolutiondoes
notnecessarilyeliminatethepossibilityofstarvation.
7.1.3.2 MonitorSolution
Next,weillustratemonitorconceptsbypresentingadeadlock-freesolutionto
the dining-philosophers problem. This solution imposes the restriction that a
philosophermaypickupherchopsticksonlyifbothofthemareavailable.To
codethissolution,weneedtodistinguishamongthreestatesinwhichwemay
findaphilosopher.Forthispurpose,weintroducethefollowingdatastructure:
enum{THINKING, HUNGRY, EATING}state[5];
Philosophericansetthevariablestate[i] = EATINGonlyifhertwoneigh-
bors are not eating: (state[(i+4) % 5] != EATING) and (state[(i+1) %
5] != EATING).
Wealsoneedtodeclare
condition self[5];
Thisallowsphilosopheritodelayherselfwhensheishungrybutisunableto
obtainthechopstickssheneeds.
We are now in a position to describe our solution to the dining-
philosophers problem. The distribution of the chopsticks is controlled by
the monitor DiningPhilosophers, whose definition is shown in Figure 7.7.
Eachphilosopher,beforestartingtoeat,mustinvoketheoperationpickup().
This act may result in the suspension of the philosopher process. After the
successful completion of the operation, the philosopher may eat. Following
this, the philosopher invokes the putdown() operation. Thus, philosopher
i must invoke the operations pickup() and putdown() in the following
sequence:
DiningPhilosophers.pickup(i);
...
eat
...
DiningPhilosophers.putdown(i);
It is easy to show that this solution ensures that no two neighbors are
eatingsimultaneouslyandthatnodeadlockswilloccur.Aswealreadynoted,
however,itispossibleforaphilosophertostarvetodeath.Wedonotpresent
asolutiontothisproblembutratherleaveitasanexerciseforyou.
7.2 Synchronization within the Kernel
WenextdescribethesynchronizationmechanismsprovidedbytheWindows
and Linux operating systems. These two operating systems provide good
examplesofdifferentapproachestosynchronizingthekernel,andasyouwill296 Chapter7 SynchronizationExamples
monitor DiningPhilosophers
{
enum {THINKING, HUNGRY, EATING} state[5];
condition self[5];
void pickup(int i) {
state[i] = HUNGRY;
test(i);
if (state[i] != EATING)
self[i].wait();
}
void putdown(int i) {
state[i] = THINKING;
test((i + 4) % 5);
test((i + 1) % 5);
}
void test(int i) {
if ((state[(i + 4) % 5] != EATING) &&
(state[i] == HUNGRY) &&
(state[(i + 1) % 5] != EATING)) {
state[i] = EATING;
self[i].signal();
}
}
initialization code() {
for (int i = 0; i < 5; i++)
state[i] = THINKING;
}
}
Figure7.7 Amonitorsolutiontothedining-philosophersproblem.
see,thesynchronizationmechanismsavailableinthesesystemsdifferinsubtle
yetsignificantways.
7.2.1 Synchronization in Windows
The Windows operating system is a multithreaded kernel that provides sup-
port for real-time applications and multiple processors. When the Windows
kernel accesses a global resource on a single-processor system, it temporar-
ily masks interruptsfor all interrupthandlers that may also access the global
resource. On a multiprocessor system, Windows protects access to global
resources using spinlocks, although the kernel uses spinlocks only to protect
shortcodesegments.Furthermore,forreasonsofefficiency,thekernelensures
thatathreadwillneverbepreemptedwhileholdingaspinlock.7.2 SynchronizationwithintheKernel 297
For thread synchronization outside the kernel, Windows provides dis-
patcher objects. Using a dispatcher object, threads synchronize according to
severaldifferentmechanisms,includingmutexlocks,semaphores,events,and
timers.The systemprotects shareddata by requiringa thread togain owner-
shipofamutextoaccessthedataandtoreleaseownershipwhenitisfinished.
SemaphoresbehaveasdescribedinSection6.6.Eventsaresimilartocondition
variables; that is, they may notify a waiting thread when a desired condition
occurs. Finally,timersareusedtonotify one (ormorethan one) threadthat a
specifiedamountoftimehasexpired.
Dispatcherobjectsmaybeineitherasignaledstateoranonsignaledstate.
An object in a signaled state is available, and a thread will not block when
acquiring the object. An object in a nonsignaled state is not available, and a
threadwillblockwhenattemptingtoacquiretheobject.Weillustratethestate
transitionsofamutexlockdispatcherobjectinFigure7.8.
Arelationshipexistsbetweenthestateofadispatcherobjectandthestate
ofathread.Whenathreadblocksonanonsignaleddispatcherobject,itsstate
changes from ready to waiting, and the thread is placed in a waiting queue
forthatobject.Whenthestateforthedispatcherobjectmovestosignaled,the
kernel checks whether any threads are waiting on the object. If so, the kernel
moves one thread—or possibly more—from the waiting state to the ready
state, where they can resume executing. The number of threads the kernel
selects from the waiting queue depends on the type of dispatcher object for
which each threadis waiting. The kernelwill selectonly one threadfrom the
waiting queue for a mutex, since a mutex object may be “owned” by only a
single thread. For an event object, the kernel will select all threads that are
waitingfortheevent.
We can use a mutex lock as an illustration of dispatcher objects and
threadstates.Ifathreadtriestoacquireamutexdispatcherobjectthat isina
nonsignaledstate,thatthreadwillbesuspendedandplacedinawaitingqueue
for the mutex object. When the mutex moves to the signaled state (because
another thread has releasedthe lock on the mutex), the thread waiting at the
frontofthequeuewillbemovedfromthewaitingstatetothereadystateand
willacquirethemutexlock.
Acritical-section object is a user-mode mutexthat can often be acquired
and released without kernel intervention. On a multiprocessor system, a
critical-sectionobjectfirstusesaspinlockwhilewaitingfortheotherthreadto
releasetheobject.Ifitspinstoolong,theacquiringthreadwillthenallocatea
kernelmutexandyielditsCPU.Critical-sectionobjectsareparticularlyefficient
because the kernel mutex is allocated only when there is contention for the
object.Inpractice,thereisverylittlecontention,sothesavingsaresignificant.
owner thread releases mutex lock
nonsignaled signaled
thread acquires mutex lock
Figure7.8 Mutexdispatcherobject.298 Chapter7 SynchronizationExamples
We provide a programming project at the end of this chapter that uses
mutexlocksandsemaphoresintheWindowsAPI.
7.2.2 Synchronization in Linux
PriortoVersion2.6,Linuxwasanonpreemptivekernel,meaningthataprocess
running in kernel mode could not be preempted—even if a higher-priority
process became available to run. Now, however, the Linux kernel is fully
preemptive,soataskcanbepreemptedwhenitisrunninginthekernel.
Linux provides several different mechanisms for synchronization in
the kernel. As most computer architectures provide instructions for atomic
versions of simple math operations, the simplest synchronization technique
within the Linux kernel is an atomic integer, which is represented using the
opaque data type atomic t. As the name implies, all math operations using
atomic integers are performed without interruption. To illustrate, consider a
programthatconsistsofanatomicintegercounterandanintegervalue.
atomic t counter;
int value;
The following code illustrates the effect of performing various atomic opera-
tions:
AtomicOperation Effect
atomic set(&counter,5); counter = 5
atomic add(10,&counter); counter = counter + 10
atomic sub(4,&counter); counter = counter - 4
atomic inc(&counter); counter = counter + 1
value = atomic read(&counter); value = 12
Atomic integers are particularly efficient in situations where an integer
variable—suchasacounter—needstobeupdated,sinceatomicoperationsdo
notrequiretheoverheadoflockingmechanisms.However,theiruseislimited
to these sorts of scenarios. In situations where there are several variables
contributingtoapossibleracecondition,moresophisticatedlockingtoolsmust
beused.
MutexlocksareavailableinLinuxforprotectingcriticalsectionswithinthe
kernel.Here,ataskmustinvokethemutex lock()functionpriortoentering
a critical section and the mutex unlock() function after exiting the critical
section.Ifthemutexlockisunavailable,ataskcallingmutex lock()isputinto
asleepstateandisawakenedwhenthelock’sownerinvokesmutex unlock().
Linux also provides spinlocks and semaphores (as well as reader–writer
versionsofthesetwolocks)forlockinginthekernel.OnSMPmachines,thefun-
damentallockingmechanismisaspinlock,andthekernelisdesignedsothat
the spinlock is held only for short durations. On single-processor machines,
such as embedded systems with only a single processing core, spinlocks are
inappropriate for use and are replaced by enabling and disabling kernel pre-
emption.Thatis,onsystemswithasingleprocessingcore,ratherthanholding
aspinlock,thekerneldisableskernelpreemption;andratherthanreleasingthe
spinlock,itenableskernelpreemption.Thisissummarizedbelow:7.3 POSIXSynchronization 299
Single Processor Multiple Processors
Disable kernel preemption Acquire spin lock
Enable kernel preemption Release spin lock
In the Linux kernel, both spinlocks and mutex locks are nonrecursive,
whichmeansthatifathreadhasacquiredoneoftheselocks,itcannotacquire
the same lock a second time without first releasing the lock. Otherwise, the
secondattemptatacquiringthelockwillblock.
Linux uses an interesting approach to disable and enable kernel preemp-
tion. It provides two simple system calls—preempt disable() and pre-
empt enable()—fordisablingandenablingkernelpreemption.Thekernelis
notpreemptible,however,ifataskrunninginthekernelisholdingalock.To
enforcethisrule,eachtaskinthesystemhasathread-infostructurecontain-
ing a counter, preempt count, to indicate the number of locks being held by
thetask. When alock isacquired,preempt countis incremented.It isdecre-
mented when a lock is released. If the value of preempt count for the task
currentlyrunninginthekernelisgreaterthan0,itisnotsafetopreempttheker-
nel,asthistaskcurrentlyholdsalock.Ifthecountis0,thekernelcansafelybe
interrupted(assumingtherearenooutstandingcallstopreempt disable()).
Spinlocks—along with enabling and disabling kernel preemption—are
used in the kernel only when a lock (or disabling kernel preemption) is held
forashortduration.Whenalockmustbeheldforalongerperiod,semaphores
ormutexlocksareappropriateforuse.
7.3 POSIX Synchronization
The synchronization methods discussed in the preceding section pertain to
synchronization within the kernel and are therefore available only to kernel
developers.Incontrast,thePOSIXAPIisavailableforprogrammersattheuser
level and is not part of any particular operating-system kernel. (Of course, it
must ultimately be implemented using tools provided by the host operating
system.)
Inthissection,wecovermutexlocks,semaphores,andconditionvariables
that areavailableinthePthreads and POSIX APIs. TheseAPIs arewidelyused
for thread creation and synchronization by developers on UNIX, Linux, and
macOSsystems.
7.3.1 POSIX Mutex Locks
Mutexlocks representthe fundamental synchronization technique used with
Pthreads. Amutex lock is used to protect critical sections of code—that is, a
threadacquiresthelock beforeenteringacriticalsectionand releasesitupon
exiting the critical section. Pthreads uses the pthread mutex t data type for
mutex locks. A mutex is created with the pthread mutex init() function.
The first parameter is a pointer to the mutex. By passing NULL as a second
parameter, we initialize the mutex to its default attributes. This is illustrated
below:300 Chapter7 SynchronizationExamples
#include <pthread.h>
pthread mutex t mutex;
/* create and initialize the mutex lock */
pthread mutex init(&mutex,NULL);
Themutexisacquiredandreleasedwiththepthread mutex lock()and
pthread mutex unlock() functions. If the mutex lock is unavailable when
pthread mutex lock() is invoked, the calling thread is blocked until the
ownerinvokespthread mutex unlock().Thefollowingcodeillustratespro-
tectingacriticalsectionwithmutexlocks:
/* acquire the mutex lock */
pthread mutex lock(&mutex);
/* critical section */
/* release the mutex lock */
pthread mutex unlock(&mutex);
Allmutexfunctionsreturnavalueof0withcorrectoperation;ifanerroroccurs,
thesefunctionsreturnanonzeroerrorcode.
7.3.2 POSIX Semaphores
Many systems that implement Pthreads also provide semaphores, although
semaphores are not part of the POSIX standard and instead belong to the
POSIX SEM extension. POSIX specifies two types of semaphores—named and
unnamed.Fundamentally,thetwoarequitesimilar,buttheydifferintermsof
howtheyarecreatedandsharedbetweenprocesses.Becausebothtechniques
are common, we discuss both here. Beginning with Version 2.6 of the kernel,
Linuxsystemsprovidesupportforbothnamedandunnamedsemaphores.
7.3.2.1 POSIXNamedSemaphores
Thefunctionsem open()isusedtocreateandopenaPOSIXnamedsempahore:
#include <semaphore.h>
sem t *sem;
/* Create the semaphore and initialize it to 1 */
sem = sem open("SEM", O CREAT, 0666, 1);
Inthisinstance,wearenamingthesemaphoreSEM.TheO CREATflagindicates
thatthesemaphorewillbecreatedifitdoesnotalreadyexist.Additionally,the
semaphore has read and write access for other processes (via the parameter
0666)andisinitializedto1.
Theadvantageofnamedsemaphoresisthatmultipleunrelatedprocesses
can easily use a common semaphore as a synchronization mechanism by7.3 POSIXSynchronization 301
simply referring to the semaphore’s name. In the example above, once the
semaphore SEM has been created, subsequent calls to sem open() (with
the same parameters) by other processes return a descriptor to the existing
semaphore.
In Section6.6, we describedthe classic wait() and signal() semaphore
operations. POSIX declares these operations sem wait() and sem post(),
respectively.Thefollowingcodesampleillustratesprotectingacriticalsection
usingthenamedsemaphorecreatedabove:
/* acquire the semaphore */
sem wait(sem);
/* critical section */
/* release the semaphore */
sem post(sem);
BothLinuxandmacOSsystemsprovidePOSIXnamedsemaphores.
7.3.2.2 POSIXUnnamedSemaphores
Anunnamedsemaphoreiscreatedandinitializedusingthesem init()func-
tion,whichispassedthreeparameters:
1. Apointertothesemaphore
2. Aflagindicatingthelevelofsharing
3. Thesemaphore’sinitialvalue
andisillusratedinthefollowingprogrammingexample:
#include <semaphore.h>
sem t sem;
/* Create the semaphore and initialize it to 1 */
sem init(&sem, 0, 1);
Inthisexample,bypassingtheflag0,weareindicatingthatthissemaphorecan
besharedonlybythreadsbelongingtotheprocessthatcreatedthesemaphore.
(If we supplied a nonzero value, we could allow the semaphore to be shared
between separate processes by placing it in a region of shared memory.) In
addition,weinitializethesemaphoretothevalue1.
POSIX unnamed semaphores use the same sem wait() and sem post()
operations as named semaphores. The following code sample illustrates pro-
tectingacriticalsectionusingtheunnamedsemaphorecreatedabove:302 Chapter7 SynchronizationExamples
/* acquire the semaphore */
sem wait(&sem);
/* critical section */
/* release the semaphore */
sem post(&sem);
Just like mutex locks, all semaphore functions return 0 when successful and
nonzerowhenanerrorconditionoccurs.
7.3.3 POSIX Condition Variables
ConditionvariablesinPthreadsbehavesimilarlytothosedescribedinSection
6.7. However, in that section, condition variables are used within the context
of a monitor, which provides a locking mechanism to ensure data integrity.
SincePthreadsistypicallyusedinCprograms—andsinceCdoesnothavea
monitor— we accomplish locking by associating a condition variable with a
mutexlock.
Condition variables in Pthreads use the pthread cond t data type and
are initialized using the pthread cond init() function. The following code
createsandinitializesaconditionvariableaswellasitsassociatedmutexlock:
pthread mutex t mutex;
pthread cond t cond var;
pthread mutex init(&mutex,NULL);
pthread cond init(&cond var,NULL);
The pthread cond wait() function is used for waiting on a condition
variable.Thefollowingcodeillustrateshowathreadcanwaitforthecondition
a == btobecometrueusingaPthreadconditionvariable:
pthread mutex lock(&mutex);
while (a != b)
pthread cond wait(&cond var, &mutex);
pthread mutex unlock(&mutex);
The mutex lock associated with the condition variable must be locked
beforethepthread cond wait()functioniscalled,sinceitisusedtoprotect
thedataintheconditionalclausefromapossibleracecondition.Oncethislock
is acquired, the thread can check the condition. If the condition is not true,
the thread then invokes pthread cond wait(), passing the mutex lock and
the condition variable as parameters. Calling pthread cond wait() releases
themutexlock,therebyallowinganotherthreadtoaccesstheshareddataand
possibly update its value so that the condition clause evaluates to true. (To
protect against program errors,it is important to place the conditional clause
withinaloopsothattheconditionisrecheckedafterbeingsignaled.)7.4 SynchronizationinJava 303
Athreadthatmodifiestheshareddatacaninvokethepthread cond signal()
function,therebysignalingonethreadwaitingontheconditionvariable.This
isillustratedbelow:
pthread mutex lock(&mutex);
a = b;
pthread cond signal(&cond var);
pthread mutex unlock(&mutex);
It is important to note that the call to pthread cond signal() does not
release the mutex lock. It is the subsequent call to pthread mutex unlock()
that releases the mutex. Once the mutex lock is released, the signaled thread
becomes the owner of the mutex lock and returns control from the call to
pthread cond wait().
Weprovideseveralprogrammingproblemsandprojectsattheendofthis
chapterthatusePthreadsmutexlocksandconditionvariables,aswellasPOSIX
semaphores.
7.4 Synchronization in Java
The Java language and its API have provided rich support for thread syn-
chronization since the origins of the language. In this section, we first cover
Javamonitors,Java’soriginalsynchronizationmechanism.Wethencoverthree
additional mechanisms that were introduced in Release 1.5: reentrant locks,
semaphores,andconditionvariables.Weincludethesebecausetheyrepresent
the most common locking and synchronization mechanisms. However, the
JavaAPIprovidesmanyfeaturesthatwedonotcoverinthistext—forexam-
ple,supportforatomicvariablesandtheCASinstruction—andweencourage
interestedreaderstoconsultthebibliographyformoreinformation.
7.4.1 Java Monitors
Javaprovidesamonitor-likeconcurrencymechanismforthreadsynchroniza-
tion.WeillustratethismechanismwiththeBoundedBufferclass(Figure7.9),
whichimplementsasolutiontothebounded-bufferproblemwhereinthepro-
ducer and consumer invoke the insert() and remove() methods, respec-
tively.
EveryobjectinJavahasassociatedwithitasinglelock.Whenamethodis
declaredtobesynchronized,callingthemethodrequiresowningthelockfor
theobject.Wedeclareasynchronizedmethodbyplacingthesynchronized
keywordin the method definition, such as with the insert()and remove()
methodsintheBoundedBufferclass.
Invoking a synchronized method requires owning the lock on an object
instance of BoundedBuffer. If the lock is already owned by another thread,
thethreadcallingthesynchronizedmethodblocksandisplacedintheentry
setfortheobject’slock.Theentrysetrepresentsthesetofthreadswaitingfor
the lock to become available. If the lock is available when a synchronized
methodiscalled,thecallingthreadbecomestheowneroftheobject’slockand
can enterthe method.The lock is releasedwhen the threadexitsthe method.
If the entry set for the lock is not empty when the lock is released, the JVM304 Chapter7 SynchronizationExamples
public class BoundedBuffer<E>
{
private static final int BUFFER SIZE = 5;
private int count, in, out;
private E[] buffer;
public BoundedBuffer() {
count = 0;
in = 0;
out = 0;
buffer = (E[]) new Object[BUFFER SIZE];
}
/* Producers call this method */
public synchronized void insert(E item) {
/* See Figure 7.11 */
}
/* Consumers call this method */
public synchronized E remove() {
/* See Figure 7.11 */
}
}
Figure7.9 BoundedbufferusingJavasynchronization.
arbitrarilyselectsathreadfromthissettobetheownerofthelock.(Whenwe
say“arbitrarily,”wemeanthatthespecificationdoesnotrequirethatthreadsin
thissetbeorganizedinanyparticularorder.However,inpractice,mostvirtual
machinesorderthreadsintheentrysetaccordingtoaFIFOpolicy.)Figure7.10
illustrateshowtheentrysetoperates.
Inadditiontohavingalock,everyobjectalsohasassociatedwithitawait
setconsistingofasetofthreads.Thiswaitsetisinitiallyempty.Whenathread
entersasynchronizedmethod,itownsthelockfortheobject.However,this
threadmaydeterminethatitisunabletocontinuebecauseacertaincondition
acquire lock
object
lock
owner
entry set
Figure7.10 Entrysetforalock.7.4 SynchronizationinJava 305
BLOCKSYNCHRONIZATION
Theamountoftimebetweenwhenalockisacquiredandwhenitisreleased
is defined as the scope of the lock. Asynchronizedmethodthat has only
a small percentage of its code manipulating shared data may yield a scope
that is too large. In such an instance, it may be better to synchronize only
theblockofcodethatmanipulatesshareddatathantosynchronizetheentire
method. Such a design results in a smaller lock scope. Thus, in addition to
declaring synchronizedmethods,Javaalso allows blocksynchronization,
as illustrated below. Only the access to the critical-section code requires
ownershipoftheobjectlockforthethisobject.
public void someMethod() {
/* non-critical section */
synchronized(this) {
/* critical section */
}
/* remainder section */
}
has not been met. That will happen, for example, if the producer calls the
insert()method and the buffer isfull.The threadthen will releasethe lock
andwaituntiltheconditionthatwillallowittocontinueismet.
Whenathreadcallsthewait()method,thefollowinghappens:
1. Thethreadreleasesthelockfortheobject.
2. Thestateofthethreadissettoblocked.
3. Thethreadisplacedinthewaitsetfortheobject.
Consider the example in Figure 7.11. If the producer calls the insert()
method and sees that the buffer is full, it calls the wait() method. This call
releasesthelock,blockstheproducer,andputstheproducerinthewaitsetfor
theobject.Becausetheproducerhasreleasedthelock,theconsumerultimately
enterstheremove()method,whereitfreesspaceinthebufferfortheproducer.
Figure 7.12 illustrates the entry and wait sets for a lock. (Note that although
wait()canthrowanInterruptedException,wechoosetoignoreitforcode
clarityandsimplicity.)
Howdoestheconsumerthreadsignalthattheproducermaynowproceed?
Ordinarily,whenathreadexitsasynchronizedmethod,thedepartingthread
releases only the lock associated with the object, possibly removing a thread
fromtheentrysetandgivingitownershipofthelock.However,attheendof
theinsert()andremove()methods,wehaveacalltothemethodnotify().
Thecalltonotify():
1. PicksanarbitrarythreadTfromthelistofthreadsinthewaitset306 Chapter7 SynchronizationExamples
/* Producers call this method */
public synchronized void insert(E item) {
while (count == BUFFER SIZE) {
try {
wait();
}
catch (InterruptedException ie) { }
}
buffer[in] = item;
in = (in + 1) % BUFFER SIZE;
count++;
notify();
}
/* Consumers call this method */
public synchronized E remove() {
E item;
while (count == 0) {
try {
wait();
}
catch (InterruptedException ie) { }
}
item = buffer[out];
out = (out + 1) % BUFFER SIZE;
count--;
notify();
return item;
}
Figure7.11 insert()andremove()methodsusingwait()andnotify().
2. MovesTfromthewaitsettotheentryset
3. SetsthestateofTfromblockedtorunnable
T is now eligible to compete for the lock with the other threads. Once T has
regained control of the lock, it returns from calling wait(), where it may
check the value of count again. (Again, the selection of an arbitrary thread
is according to the Java specification; in practice, most Java virtual machines
orderthreadsinthewaitsetaccordingtoaFIFOpolicy.)7.4 SynchronizationinJava 307
acquire lock wait
object
lock
owner
entry set wait set
Figure7.12 Entryandwaitsets.
Next, we describe the wait() and notify() methods in terms of the
methods shown in Figure 7.11. We assume that the buffer is full and the lock
fortheobjectisavailable.
• The producer calls the insert() method, sees that the lock is available,
andentersthemethod.Onceinthemethod,theproducerdeterminesthat
thebufferisfullandcallswait().Thecalltowait()releasesthelockfor
theobject,setsthestateoftheproducertoblocked,andputstheproducer
inthewaitsetfortheobject.
• The consumer ultimately calls and enters the remove() method, as the
lock for the object isnow available.The consumer removesan itemfrom
thebufferandcallsnotify().Notethattheconsumerstillownsthelock
fortheobject.
• The call to notify() removes the producer from the wait set for the
object, moves the producer to the entry set, and sets the producer’s state
torunnable.
• Theconsumerexitstheremove()method.Exitingthismethodreleasesthe
lockfortheobject.
• Theproducertriestoreacquirethelockandissuccessful.Itresumesexecu-
tionfromthecalltowait().Theproducerteststhewhileloop,determines
thatroomisavailableinthebuffer,andproceedswiththeremainderofthe
insert()method.Ifnothreadisinthewaitsetfortheobject, thecallto
notify()isignored.Whentheproducerexitsthemethod,itreleasesthe
lockfortheobject.
Thesynchronized,wait(),andnotify()mechanismshavebeenpartof
Javasinceitsorigins.However,laterrevisionsoftheJavaAPIintroducedmuch
more flexible and robust locking mechanisms, some of which we examine in
thefollowingsections.
7.4.2 Reentrant Locks
PerhapsthesimplestlockingmechanismavailableintheAPIistheReentrant-
Lock.Inmanyways,aReentrantLockactslikethesynchronizedstatement
describedinSection7.4.1:aReentrantLockisownedbyasinglethreadandis
usedtoprovidemutuallyexclusiveaccesstoasharedresource.However,the
ReentrantLockprovidesseveraladditionalfeatures,suchassettingafairness
parameter,whichfavorsgrantingthelocktothelongest-waitingthread.(Recall308 Chapter7 SynchronizationExamples
thatthespecificationfortheJVMdoesnotindicatethatthreadsinthewaitset
foranobjectlockaretobeorderedinanyspecificfashion.)
AthreadacquiresaReentrantLocklockbyinvokingitslock()method.
If the lock is available—or if the thread invoking lock() already owns it,
which is why it is termed reentrant—lock() assigns the invoking thread
lock ownership and returns control. If the lock is unavailable, the invoking
thread blocks until it is ultimately assigned the lock when its owner invokes
unlock().ReentrantLockimplementstheLockinterface;itisusedasfollows:
Lock key = new ReentrantLock();
key.lock();
try {
/* critical section */
}
finally {
key.unlock();
}
Theprogrammingidiomofusingtryandfinallyrequiresabitofexpla-
nation. If the lock is acquired via the lock() method, it is important that the
lock be similarly released. By enclosing unlock() in a finally clause, we
ensurethatthelockisreleasedoncethecriticalsectioncompletesorifanexcep-
tionoccurswithinthetryblock.Noticethatwedonotplacethecalltolock()
withinthetryclause,aslock()doesnotthrowanycheckedexceptions.Con-
siderwhathappensifweplacelock()withinthetryclauseandanunchecked
exception occurs when lock() is invoked (such as OutofMemoryError): The
finallyclausetriggersthecalltounlock(),whichthenthrowstheunchecked
IllegalMonitorStateException,asthelockwasneveracquired.ThisIlle-
galMonitorStateExceptionreplacestheuncheckedexceptionthatoccurred
when lock() was invoked, thereby obscuring the reason why the program
initiallyfailed.
WhereasaReentrantLockprovidesmutualexclusion,itmaybetoocon-
servative a strategy if multiple threads only read, but do not write, shared
data. (We described this scenario in Section 7.1.2.) To address this need, the
JavaAPIalsoprovidesaReentrantReadWriteLock,whichisalockthatallows
multipleconcurrentreadersbutonlyonewriter.
7.4.3 Semaphores
TheJavaAPIalsoprovidesacountingsemaphore,asdescribedinSection6.6.
Theconstructorforthesemaphoreappearsas
Semaphore(int value);
where value specifies the initial value of the semaphore (a negative value
is allowed). The acquire() method throws an InterruptedException if
the acquiring thread is interrupted. The following example illustrates using
asemaphoreformutualexclusion:7.4 SynchronizationinJava 309
Semaphore sem = new Semaphore(1);
try {
sem.acquire();
/* critical section */
}
catch (InterruptedException ie) { }
finally {
sem.release();
}
Noticethatweplacethecalltorelease()inthefinallyclausetoensurethat
thesemaphoreisreleased.
7.4.4 Condition Variables
The last utility we cover in the Java API is the condition variable. Just as
the ReentrantLock is similar to Java’s synchronized statement, condition
variablesprovidefunctionalitysimilartothewait()andnotify()methods.
Therefore,toprovidemutualexclusion,aconditionvariablemustbeassociated
withareentrantlock.
We create a condition variable by first creating a ReentrantLock and
invokingitsnewCondition()method,whichreturnsaConditionobjectrep-
resenting the condition variable for the associated ReentrantLock. This is
illustratedinthefollowingstatements:
Lock key = new ReentrantLock();
Condition condVar = key.newCondition();
Once the condition variable has been obtained, we can invoke its await()
and signal() methods, which function in the same way as the wait() and
signal()commandsdescribedinSection6.7.
Recall that with monitors as described in Section 6.7, the wait() and
signal()operationscanbeappliedtonamedconditionvariables,allowinga
threadtowaitforaspecificconditionortobenotifiedwhenaspecificcondition
hasbeenmet.Atthelanguagelevel,Javadoesnotprovidesupportfornamed
condition variables. Each Java monitor is associated with just one unnamed
condition variable, and the wait() and notify() operations described in
Section7.4.1applyonlytothissingleconditionvariable.WhenaJavathreadis
awakenedvianotify(),itreceivesnoinformationastowhyitwasawakened;
it is up to the reactivated thread to check for itself whether the condition
for which it was waiting has been met. Condition variables remedy this by
allowingaspecificthreadtobenotified.
We illustrate with the following example: Suppose we have five threads,
numbered0 through 4, and a sharedvariable turnindicating which thread’s
turn it is. When a thread wishes to do work, it calls the doWork() method
in Figure 7.13, passing its thread number. Only the thread whose value of
threadNumbermatchesthevalueofturncanproceed;otherthreadsmustwait
theirturn.310 Chapter7 SynchronizationExamples
/* threadNumber is the thread that wishes to do some work */
public void doWork(int threadNumber)
{
lock.lock();
try {
/**
* If it’s not my turn, then wait
* until I’m signaled.
*/
if (threadNumber != turn)
condVars[threadNumber].await();
/**
* Do some work for awhile ...
*/
/**
* Now signal to the next thread.
*/
turn = (turn + 1) % 5;
condVars[turn].signal();
}
catch (InterruptedException ie) { }
finally {
lock.unlock();
}
}
Figure7.13 ExampleusingJavaconditionvariables.
WealsomustcreateaReentrantLockandfiveconditionvariables(repre-
sentingtheconditionsthethreadsarewaitingfor)tosignalthethreadwhose
turnisnext.Thisisshownbelow:
Lock lock = new ReentrantLock();
Condition[] condVars = new Condition[5];
for (int i = 0; i < 5; i++)
condVars[i] = lock.newCondition();
When a thread enters doWork(), it invokes the await() method on its
associated condition variable if its threadNumber is not equal to turn, only
toresumewhenitissignaledbyanotherthread.Afterathreadhascompleted
itswork,itsignalstheconditionvariableassociatedwiththethreadwhoseturn
follows.
It is important to note that doWork() does not need to be declared syn-
chronized,astheReentrantLockprovidesmutualexclusion.Whenathread7.5 AlternativeApproaches 311
invokes await() on the condition variable, it releases the associated Reen-
trantLock, allowing another thread to acquire the mutual exclusion lock.
Similarly,whensignal()isinvoked,onlytheconditionvariableissignaled;
thelockisreleasedbyinvokingunlock().
7.5 Alternative Approaches
With the emergence of multicore systems has come increased pressure to
develop concurrent applications that take advantage of multiple processing
cores.However,concurrentapplicationspresentanincreasedriskofracecon-
ditionsandlivenesshazards such as deadlock.Traditionally,techniquessuch
as mutex locks, semaphores, and monitors have been used to address these
issues,butasthenumberofprocessingcoresincreases,itbecomesincreasingly
difficulttodesignmultithreadedapplicationsthatarefreefromraceconditions
and deadlock. In this section, we explore various features provided in both
programminglanguagesandhardwarethatsupportthedesignofthread-safe
concurrentapplications.
7.5.1 Transactional Memory
Quite often in computer science, ideas from one area of study can be used
to solve problems in other areas. The concept of transactional memory orig-
inated in database theory, for example, yet it provides a strategy for process
synchronization.Amemorytransactionisasequenceofmemoryread–write
operationsthatareatomic.Ifalloperationsinatransactionarecompleted,the
memorytransactioniscommitted.Otherwise,theoperationsmustbeaborted
androlledback.Thebenefitsoftransactionalmemorycanbeobtainedthrough
featuresaddedtoaprogramminglanguage.
Consideranexample.Supposewehaveafunctionupdate()thatmodifies
shareddata.Traditionally,thisfunctionwouldbewrittenusingmutexlocks(or
semaphores)suchasthefollowing:
void update ()
{
acquire();
/* modify shared data */
release();
}
However, using synchronization mechanisms such as mutex locks and
semaphores involves many potential problems, including deadlock.
Additionally, as the number of threads increases, traditional locking doesn’t
scaleaswell,becausethelevelofcontentionamongthreadsforlockownership
becomesveryhigh.
As an alternative to traditional locking methods, new features that take
advantageoftransactionalmemorycanbeaddedtoaprogramminglanguage.
Inourexample,supposeweaddtheconstructatomic{S},whichensuresthat312 Chapter7 SynchronizationExamples
the operations in S execute as a transaction. This allows us to rewrite the
update()functionasfollows:
void update ()
{
atomic {
/* modify shared data */
}
}
The advantage of using such a mechanism rather than locks is that the
transactional memory system—not the developer—is responsible for guar-
anteeing atomicity. Additionally, because no locks are involved, deadlock is
notpossible.Furthermore,atransactionalmemorysystemcanidentifywhich
statementsinatomicblocks canbe executedconcurrently,such as concurrent
read access to a shared variable. It is, of course, possible for a programmer
toidentifythesesituationsandusereader–writerlocks,butthetaskbecomes
increasinglydifficultasthenumberofthreadswithinanapplicationgrows.
Transactionalmemorycanbeimplementedineithersoftwareorhardware.
Software transactional memory (STM), as the name suggests, implements
transactionalmemoryexclusivelyinsoftware—nospecialhardwareisneeded.
STM works by inserting instrumentation code inside transaction blocks. The
code is inserted by a compiler and manages each transaction by examining
wherestatementsmayrunconcurrentlyandwherespecificlow-levellockingis
required.Hardwaretransactionalmemory(HTM)useshardwarecachehierar-
chiesandcachecoherencyprotocolstomanageandresolveconflictsinvolving
shared data residing in separate processors’ caches. HTM requires no special
code instrumentation and thus has less overhead than STM. However, HTM
doesrequirethatexistingcache hierarchiesandcache coherency protocolsbe
modifiedtosupporttransactionalmemory.
Transactional memory has existed for several years without widespread
implementation. However, the growth of multicore systems and the associ-
ated emphasis on concurrent and parallel programming have prompted a
significant amount of research in this area on the part of both academics and
commercialsoftwareandhardwarevendors.
7.5.2 OpenMP
InSection4.5.2,weprovidedanoverviewofOpenMPanditssupportofparallel
programminginashared-memoryenvironment.RecallthatOpenMPincludes
asetofcompilerdirectivesandanAPI.Anycodefollowingthecompilerdirec-
tive#pragma omp parallelisidentifiedasaparallelregionandisperformed
byanumberofthreadsequaltothenumberofprocessingcoresinthesystem.
TheadvantageofOpenMP(andsimilartools)isthatthreadcreationandman-
agementare handledby the OpenMPlibraryand arenot the responsibilityof
applicationdevelopers.
Along with its #pragma omp parallel compiler directive,OpenMPpro-
videsthecompilerdirective#pragma omp critical,whichspecifiesthecode
regionfollowingthedirectiveasacriticalsectioninwhichonlyonethreadmay
be active at a time. In this way, OpenMP provides support for ensuring that
threadsdonotgenerateraceconditions.7.5 AlternativeApproaches 313
As an example of the use of the critical-section compiler directive, first
assume that the shared variable counter can be modified in the update()
functionasfollows:
void update(int value)
{
counter += value;
}
Iftheupdate()functioncanbepartof—orinvokedfrom—aparallelregion,
araceconditionispossibleonthevariablecounter.
The critical-section compiler directive can be used to remedy this race
conditionandiscodedasfollows:
void update(int value)
{
#pragmaompcritical
{
counter += value;
}
}
Thecritical-sectioncompilerdirectivebehavesmuchlikeabinarysemaphore
or mutex lock, ensuring that only one thread at a time is active in the critical
section. If a thread attempts to enter a critical section when another thread is
currentlyactiveinthatsection(thatis,ownsthesection),thecallingthreadis
blockeduntiltheownerthreadexits.Ifmultiplecriticalsectionsmustbeused,
each critical section can be assigned a separate name, and a rule can specify
that no more than one thread may be active in a critical section of the same
namesimultaneously.
An advantage of using the critical-section compiler directive in OpenMP
is that it is generally considered easier to use than standard mutex locks.
However, a disadvantage is that application developers must still identify
possibleraceconditionsandadequatelyprotectshareddatausingthecompiler
directive.Additionally,becausethecritical-sectioncompilerdirectivebehaves
much like a mutex lock, deadlock is still possible when two or more critical
sectionsareidentified.
7.5.3 Functional Programming Languages
Most well-known programming languages—such as C,C++,Java, and C#—
areknownasimperative(orprocedural)languages.Imperativelanguagesare
usedforimplementingalgorithmsthatarestate-based.Intheselanguages,the
flowofthealgorithmiscrucialtoitscorrectoperation,andstateisrepresented
withvariablesandotherdatastructures.Ofcourse,programstateismutable,
asvariablesmaybeassigneddifferentvaluesovertime.
With the current emphasis on concurrent and parallel programming for
multicore systems, there has been greater focus on functional programming
languages, which follow a programming paradigm much different from that
offeredbyimperativelanguages.Thefundamentaldifferencebetweenimper-
ative and functional languages is that functional languages do not maintain
state.Thatis,onceavariablehasbeendefinedandassignedavalue,itsvalue314 Chapter7 SynchronizationExamples
isimmutable—itcannotchange.Becausefunctionallanguagesdisallowmuta-
blestate,theyneednot be concerned withissuessuch as raceconditions and
deadlocks. Essentially, most of the problems addressed in this chapter are
nonexistentinfunctionallanguages.
Severalfunctionallanguagesarepresentlyinuse,andwebrieflymention
twoofthemhere:ErlangandScala.TheErlanglanguagehasgainedsignificant
attentionbecauseofitssupportforconcurrencyandtheeasewithwhichitcan
be used to develop applications that run on parallel systems. Scala is a func-
tionallanguagethatisalsoobject-oriented.Infact,muchofthesyntaxofScala
issimilartothepopularobject-orientedlanguagesJavaandC#.Readersinter-
estedinErlangandScala,andinfurtherdetailsaboutfunctionallanguagesin
general,areencouragedtoconsultthebibliographyattheendofthischapter
foradditionalreferences.
7.6 Summary
• Classicproblems ofprocess synchronization include the bounded-buffer,
readers–writers, and dining-philosophers problems. Solutions to these
problemscanbedevelopedusingthetoolspresentedinChapter6,includ-
ingmutexlocks,semaphores,monitors,andconditionvariables.
• Windows uses dispatcher objects as well as events to implement process
synchronizationtools.
• Linux uses a variety of approaches to protect against race conditions,
includingatomicvariables,spinlocks,andmutexlocks.
• ThePOSIXAPIprovidesmutexlocks,semaphores,andconditionvariables.
POSIX provides two forms of semaphores: named and unnamed. Several
unrelatedprocessescaneasilyaccessthesamenamedsemaphorebysim-
plyreferringtoitsname.Unnamedsemaphorescannotbesharedaseasily,
andrequireplacingthesemaphoreinaregionofsharedmemory.
• JavahasarichlibraryandAPIforsynchronization.Availabletoolsinclude
monitors (which are provided at the language level) as well as reentrant
locks, semaphores, and condition variables (which are supported by the
API).
• Alternative approaches to solving the critical-section problem include
transactionalmemory,OpenMP,andfunctionallanguages.Functionallan-
guages are particularly intriguing, as they offer a different programming
paradigmfromprocedurallanguages.Unlikeprocedurallanguages,func-
tionallanguagesdonotmaintainstateandthereforearegenerallyimmune
fromraceconditionsandcriticalsections.
Practice Exercises
7.1 Explain why Windows and Linux implement multiple locking mech-
anisms. Describe the circumstances under which they use spinlocks,
mutexlocks,semaphores,andconditionvariables.Ineachcase,explain
whythemechanismisneeded.Bibliography 315
7.2 Windowsprovidesalightweightsynchronizationtoolcalledslimreader
–writer locks. Whereas most implementations of reader–writer locks
favoreitherreadersorwriters,orperhapsorderwaitingthreadsusinga
FIFO policy,slim reader–writerlocks favor neither readersnor writers,
norarewaitingthreadsorderedinaFIFOqueue.Explainthebenefitsof
providingsuchasynchronizationtool.
7.3 Describe what changes would be necessary to the producer and con-
sumerprocessesinFigure7.1andFigure7.2sothatamutexlockcould
beusedinsteadofabinarysemaphore.
7.4 Describe how deadlock is possible with the dining-philosophers prob-
lem.
7.5 Explain the difference between signaled and non-signaled states with
Windowsdispatcherobjects.
7.6 AssumevalisanatomicintegerinaLinuxsystem.Whatisthevalueof
valafterthefollowingoperationshavebeencompleted?
atomic set(&val,10);
atomic sub(8,&val);
atomic inc(&val);
atomic inc(&val);
atomic add(6,&val);
atomic sub(3,&val);
Further Reading
Details of Windows synchronization can be found in [Solomon and Russi-
novich (2000)]. [Love (2010)] describes synchronization in the Linux kernel.
[Hart (2005)] describes thread synchronization using Windows. [Breshears
(2009)] and [Pacheco (2011)] provide detailed coverage of synchronization
issues in relation to parallel programming. Details on using OpenMP can be
found at http://openmp.org. Both[Oaks(2014)] and [Goetzet al.(2006)] con-
trasttraditionalsynchronizationandCAS-basedstrategiesinJava.
Bibliography
[Breshears(2009)] C. Breshears, The Art of Concurrency, O’Reilly & Associates
(2009).
[Goetzetal.(2006)] B. Goetz, T. Peirls, J. Bloch, J. Bowbeer, D. Holmes, and
D.Lea,JavaConcurrencyinPractice,Addison-Wesley(2006).
[Hart(2005)] J.M.Hart,WindowsSystemProgramming,ThirdEdition,Addison-
Wesley(2005).
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).316 Chapter7 SynchronizationExamples
[Oaks(2014)] S.Oaks,JavaPerformance—TheDefinitiveGuide,O’Reilly&Asso-
ciates(2014).
[Pacheco(2011)] P.S.Pacheco,AnIntroductiontoParallelProgramming,Morgan
Kaufmann(2011).
[SolomonandRussinovich(2000)] D. A. Solomon and M. E. Russinovich,
InsideMicrosoftWindows2000,ThirdEdition,MicrosoftPress(2000).Exercises EX-26
Chapter 7 Exercises
7.7 Describetwokerneldatastructuresinwhichraceconditionsarepossi-
ble.Besuretoincludeadescriptionofhowaraceconditioncanoccur.
7.8 TheLinuxkernelhasapolicythataprocesscannotholdaspinlockwhile
attemptingtoacquireasemaphore.Explainwhythispolicyisinplace.
7.9 Designanalgorithmforabounded-buffermonitorinwhichthebuffers
(portions)areembeddedwithinthemonitoritself.
7.10 Thestrictmutualexclusionwithinamonitormakesthebounded-buffer
monitorofExercise7.14mainlysuitableforsmallportions.
a. Explainwhythisistrue.
b. Designanewschemethatissuitableforlargerportions.
7.11 Discuss the tradeoff between fairness and throughput of operations
in the readers–writers problem. Propose a method for solving the
readers–writersproblemwithoutcausingstarvation.
7.12 Explainwhythecalltothelock()methodinaJavaReentrantLockis
not placed in the try clause for exception handling, yet the call to the
unlock()methodisplacedinafinallyclause.
7.13 Explain the difference between software and hardware transactional
memory.P-34 Chapter7 SynchronizationExamples
Programming Problems
7.14 Exercise 3.20 required you to design a PID manager that allocated a
uniqueprocessidentifiertoeachprocess.Exercise4.28requiredyouto
modifyyoursolutiontoExercise3.20bywritingaprogramthatcreateda
numberofthreadsthatrequestedandreleasedprocessidentifiers.Using
mutexlocks,modifyyoursolutiontoExercise4.28byensuringthatthe
datastructureusedtorepresenttheavailabilityofprocessidentifiersis
safefromraceconditions.
7.15 In Exercise 4.27, you wrote a program to generate the Fibonacci
sequence.Theprogramrequiredtheparentthreadtowaitforthechild
thread to finish its execution before printing out the computed values.
IfwelettheparentthreadaccesstheFibonaccinumbersassoonasthey
were computed by the child thread—rather than waiting for the child
threadtoterminate—whatchangeswouldbenecessarytothesolution
forthisexercise?Implementyourmodifiedsolution.
7.16 The C program stack-ptr.c (available in the source-code download)
containsanimplementationofastackusingalinkedlist.Anexampleof
itsuseisasfollows:
StackNode *top = NULL;
push(5, &top);
push(10, &top);
push(15, &top);
int value = pop(&top);
value = pop(&top);
value = pop(&top);
This program currently has a race condition and is not appropriate for
a concurrent environment. Using Pthreads mutex locks (described in
Section7.3.1),fixtheracecondition.
7.17 Exercise 4.24 asked you to design a multithreaded program that esti-
mated π using the Monte Carlo technique. In that exercise, you were
asked to create a single thread that generated random points, storing
theresultinaglobalvariable.Oncethatthreadexited,theparentthread
performedthecalculationthatestimatedthevalueofπ.Modifythatpro-
gramsothatyoucreateseveralthreads,eachofwhichgeneratesrandom
pointsanddeterminesifthepointsfallwithinthecircle.Eachthreadwill
have to update the global count of all points that fall within the circle.
Protectagainstraceconditionsonupdatestothesharedglobalvariable
byusingmutexlocks.
7.18 Exercise 4.25 asked you to design a program using OpenMP that esti-
matedπusingtheMonteCarlotechnique.Examineyoursolutiontothat
programlookingforanypossibleraceconditions.Ifyouidentifyarace
condition,protectagainstitusingthestrategyoutlinedinSection7.5.2.
7.19 Abarrierisatoolforsynchronizingtheactivityofanumberofthreads.
Whenathreadreachesabarrierpoint,itcannotproceeduntilallotherProgrammingProjects P-35
threads have reached this point as well. When the last thread reaches
the barrier point, all threads are released and can resume concurrent
execution.
Assume that the barrier is initialized to N—the number of threads
thatmustwaitatthebarrierpoint:
init(N);
Eachthreadthenperformssomeworkuntilitreachesthebarrierpoint:
/* do some work for awhile */
barrier point();
/* do some work for awhile */
UsingeitherthePOSIXorJavasynchronizationtoolsdescribedinthis
chapter,constructabarrierthatimplementsthefollowingAPI:
• int init(int n)—Initializesthebarriertothespecifiedsize.
• int barrier point(void)—Identifies the barrier point. All
threads are released from the barrier when the last thread reaches
thispoint.
Thereturnvalueofeachfunctionisusedtoidentifyerrorconditions.
Each function will return 0 under normal operation and will return
−1 if an error occurs. Atesting harness is provided in the source-code
downloadtotestyourimplementationofthebarrier.
Programming Projects
Project 1—Designing a Thread Pool
ThreadpoolswereintroducedinSection4.5.1.Whenthreadpoolsareused,a
taskissubmittedtothepoolandexecutedbyathreadfromthepool.Workis
submitted to the pool using a queue, and an available thread removes work
from the queue. If there are no available threads, the work remains queued
untilonebecomesavailable.Ifthereisnowork,threadsawaitnotificationuntil
ataskbecomesavailable.
Thisprojectinvolvescreatingandmanagingathreadpool,anditmaybe
completedusingeitherPthredsandPOSIXsynchronizationorJava.Belowwe
providethedetailsrelevanttoeachspecifictechnology.
I.POSIX
The POSIX version of this project will involve creating a number of threads
using the Pthreads API as well as using POSIX mutex locks and semaphores
forsynchronization.P-36 Chapter7 SynchronizationExamples
TheClient
UsersofthethreadpoolwillutilizethefollowingAPI:
• void pool init()—Initializesthethreadpool.
• int pool submit(void (*somefunction)(void *p), void *p)—
wheresomefunctionisapointertothefunctionthatwillbeexecutedby
athreadfromthepoolandpisaparameterpassedtothefunction.
• void pool shutdown(void)—Shutsdownthethreadpooloncealltasks
havecompleted.
Weprovideanexampleprogramclient.cinthesourcecodedownloadthat
illustrateshowtousethethreadpoolusingthesefunctions.
ImplementationoftheThreadPool
In the source code download we provide the C source file threadpool.c as
a partial implementation of the thread pool. You will need to implement the
functionsthatarecalledbyclientusers,aswellasseveraladditionalfunctions
thatsupporttheinternalsofthethreadpool.Implementationwillinvolvethe
followingactivities:
1. The pool init() function will create the threads at startup as well as
initializemutual-exclusionlocksandsemaphores.
2. The pool submit() function is partially implemented and currently
places the function to be executed—as well as its data— into a task
struct.Thetaskstructrepresentsworkthatwillbecompletedbyathread
in the pool. pool submit() will add these tasks tothe queue by invok-
ing the enqueue() function, and worker threads will call dequeue() to
retrieveworkfromthequeue.Thequeuemaybeimplementedstatically
(usingarrays)ordynamically(usingalinkedlist).
The pool init() function has an int return value that is used to
indicate if the task was successfully submitted to the pool (0 indicates
success, 1 indicates failure). If the queue is implemented using arrays,
pool init()willreturn1ifthereisanattempttosubmitworkandthe
queue is full. If the queue is implemented as a linked list, pool init()
shouldalwaysreturn0unlessamemoryallocationerroroccurs.
3. Theworker()functionisexecutedbyeachthreadinthepool,whereeach
thread will wait for available work. Once work becomes available, the
thread will remove it from the queue and invoke execute() to run the
specifiedfunction.
Asemaphore can be used for notifying a waiting thread when work
is submitted to the thread pool. Either named or unnamed semaphores
may be used. Refer to Section 7.3.2 for further details on using POSIX
semaphores.ProgrammingProjects P-37
4. A mutex lock is necessary to avoid race conditions when accessing or
modifying the queue. (Section 7.3.1 provides details on Pthreads mutex
locks.)
5. Thepool shutdown()functionwillcanceleachworkerthreadandthen
wait for each thread to terminate by calling pthread join(). Refer to
Section 4.6.3 for details on POSIX thread cancellation. (The semaphore
operationsem wait()isacancellationpointthatallowsathreadwaiting
onasemaphoretobecancelled.)
Refertothesource-codedownloadforadditionaldetailsonthisproject.In
particular,theREADMEfiledescribesthesourceandheaderfiles,aswellasthe
Makefileforbuildingtheproject.
II.Java
The Java version of this project may be completed using Java synchroniza-
tion tools as described in Section 7.4. Synchronization may depend on either
(a) monitors using synchronized/wait()/notify() (Section 7.4.1) or (b)
semaphoresandreentrantlocks(Section7.4.2andSection7.4.3).Javathreads
aredescribedinSection4.4.3.
ImplementationoftheThreadPool
YourthreadpoolwillimplementthefollowingAPI:
• ThreadPool()—Createadefault-sizedthreadpool.
• ThreadPool(int size)—Createathreadpoolofsizesize.
• void add(Runnable task)—Addatasktobeperformedbyathreadin
thepool.
• void shutdown()—Stopallthreadsinthepool.
WeprovidetheJavasourcefileThreadPool.javaasapartialimplemen-
tationofthethreadpoolinthesourcecodedownload.Youwillneedtoimple-
mentthemethodsthatarecalledbyclientusers,aswellasseveraladditional
methods that support the internals of the thread pool. Implementation will
involvethefollowingactivities:
1. Theconstructorwillfirstcreateanumberofidlethreadsthatawaitwork.
2. Workwillbesubmittedtothepoolviatheadd()method,whichaddsa
taskimplementingtheRunnableinterface.Theadd()methodwillplace
theRunnabletaskintoaqueue(youmayuseanavailablestructurefrom
theJavaAPI suchasjava.util.List).
3. Once a thread in the pool becomes available for work, it will check the
queue for any Runnable tasks. If there is such a task, the idle thread
will remove the task from the queue and invoke its run() method. If
the queue is empty, the idle thread will wait to be notified when workP-38 Chapter7 SynchronizationExamples
becomesavailable.(Theadd()methodmayimplementnotificationusing
eithernotify()orsemaphoreoperationswhenitplacesaRunnabletask
intothequeuetopossiblyawakenanidlethreadawaitingwork.)
4. The shutdown() method will stop all threads in the pool by invoking
theirinterrupt()method.This,ofcourse,requiresthatRunnabletasks
beingexecutedbythethreadpoolchecktheirinterruptionstatus(Section
4.6.3).
Refertothesource-codedownloadforadditionaldetailsonthisproject.In
particular, the READMEfile describestheJava source files,as well as further
detailsonJavathreadinterruption.
Project 2—The Sleeping Teaching Assistant
Auniversity computer science department has a teaching assistant (TA) who
helps undergraduate students with their programming assignments during
regularofficehours.TheTA’sofficeisrathersmallandhasroomforonlyone
deskwithachairandcomputer.Therearethreechairsinthehallwayoutside
theofficewherestudentscansitandwaitiftheTAiscurrentlyhelpinganother
student. When there are no students who need help during office hours, the
TA sits at the desk and takes a nap. If a student arrives during office hours
andfindstheTAsleeping,thestudentmustawakentheTAtoaskforhelp.Ifa
studentarrivesandfindstheTAcurrentlyhelpinganotherstudent,thestudent
sitsononeofthechairsinthehallwayandwaits.Ifnochairsareavailable,the
studentwillcomebackatalatertime.
Using POSIX threads, mutex locks, and semaphores, implement a solu-
tion that coordinates the activities of the TAand the students. Details for this
assignmentareprovidedbelow.
TheStudentsandtheTA
UsingPthreads(Section4.4.1),beginbycreatingnstudentswhereeachstudent
will run as a separate thread. The TA will run as a separate thread as well.
Studentthreadswillalternatebetweenprogrammingforaperiodoftimeand
seekinghelpfromtheTA.IftheTAisavailable,theywillobtainhelp.Otherwise,
they will either sit in a chair in the hallway or, if no chairs are available, will
resume programming and will seek help at a later time. If a student arrives
and notices that the TA is sleeping, the student must notify the TA using a
semaphore.Whenthe TAfinishes helping astudent,the TAmust check tosee
if there are students waiting for help in the hallway. If so, the TA must help
eachofthesestudentsinturn.Ifnostudentsarepresent,theTAmayreturnto
napping.
Perhapsthebestoptionforsimulatingstudentsprogramming—aswellas
the TAproviding help to a student—is to have the appropriate threads sleep
forarandomperiodoftime.
CoverageofPOSIXmutexlocksandsemaphoresisprovidedinSection7.3.
Consultthatsectionfordetails.ProgrammingProjects P-39
Project 3—The Dining-Philosophers Problem
InSection7.1.3,weprovideanoutlineofasolutiontothedining-philosophers
problem using monitors. This project involves implementing a solution to
this problem using either POSIX mutex locks and condition variables or Java
condition variables. Solutions will be based on the algorithm illustrated in
Figure7.7.
Bothimplementationswillrequirecreatingfivephilosophers,eachidenti-
fiedbyanumber0..4.Eachphilosopherwillrunasaseparatethread.Philoso-
phersalternatebetweenthinkingandeating.Tosimulatebothactivities,have
eachthreadsleepforarandomperiodbetweenoneandthreeseconds.
I.POSIX
ThreadcreationusingPthreadsiscoveredinSection4.4.1.Whenaphilosopher
wishestoeat,sheinvokesthefunction
pickup forks(int philosopher number)
wherephilosopher numberidentifiesthenumberofthephilosopherwishing
toeat.Whenaphilosopherfinisheseating,sheinvokes
return forks(int philosopher number)
YourimplementationwillrequiretheuseofPOSIXconditionvariables,which
arecoveredinSection7.3.
II.Java
When a philosopher wishes to eat, she invokes the method take-
Forks(philosopherNumber), where philosopherNumber identifies the
numberofthephilosopherwishingtoeat.Whenaphilosopherfinisheseating,
sheinvokesreturnForks(philosopherNumber).
Yoursolutionwillimplementthefollowinginterface:
public interface DiningServer
{
/* Called by a philosopher when it wishes to eat */
public void takeForks(int philosopherNumber);
/* Called by a philosopher when it is finished eating */
public void returnForks(int philosopherNumber);
}
ItwillrequiretheuseofJavaconditionvariables,whicharecoveredinSection
7.4.4.P-40 Chapter7 SynchronizationExamples
Project 4—The Producer–Consumer Problem
In Section 7.1.1, we presented a semaphore-based solution to the producer–
consumer problem using a bounded buffer. In this project, you will design a
programmingsolutiontothebounded-bufferproblemusingtheproducerand
consumer processesshown inFigures5.9and 5.10. The solutionpresentedin
Section7.1.1usesthreesemaphores:emptyandfull,whichcountthenumber
ofemptyandfullslotsinthebuffer,andmutex,whichisabinary(ormutual-
exclusion) semaphore that protects the actual insertion or removal of items
in the buffer. For this project, you will use standard counting semaphores
for empty and full and a mutex lock, rather than a binary semaphore, to
represent mutex. The producer and consumer—running as separate threads
—will move items to and from a buffer that is synchronized with the empty,
full,andmutexstructures.YoucansolvethisproblemusingeitherPthreads
ortheWindowsAPI.
TheBuffer
Internally, the buffer will consist of a fixed-size array of type buffer item
(which will be defined using a typedef). The array of buffer item objects
willbemanipulatedasacircularqueue.Thedefinitionofbuffer item,along
withthesizeofthebuffer,canbestoredinaheaderfilesuchasthefollowing:
/* buffer.h */
typedef int buffer item;
#define BUFFER SIZE 5
The buffer will be manipulated with two functions, insert item() and
remove item(), which are called by the producer and consumer threads,
respectively.AskeletonoutliningthesefunctionsappearsinFigure7.14.
The insert item() and remove item() functions will synchronize the
producerandconsumerusingthealgorithmsoutlinedinFigure7.1andFigure
7.2. The buffer will also require an initialization function that initializes the
mutual-exclusionobjectmutexalongwiththeemptyandfullsemaphores.
Themain()functionwillinitializethebufferandcreatetheseparatepro-
ducerandconsumerthreads.Onceithascreatedtheproducerandconsumer
threads,themain()functionwillsleepforaperiodoftimeand,uponawaken-
ing, will terminate the application. The main() function will be passed three
parametersonthecommandline:
1. Howlongtosleepbeforeterminating
2. Thenumberofproducerthreads
3. Thenumberofconsumerthreads
AskeletonforthisfunctionappearsinFigure7.15.ProgrammingProjects P-41
#include "buffer.h"
/* the buffer */
buffer item buffer[BUFFER SIZE];
int insert item(buffer item item) {
/* insert item into buffer
return 0 if successful, otherwise
return -1 indicating an error condition */
}
int remove item(buffer item *item) {
/* remove an object from buffer
placing it in item
return 0 if successful, otherwise
return -1 indicating an error condition */
}
Figure7.14 Outlineofbufferoperations.
TheProducerandConsumerThreads
The producer thread will alternate between sleeping for a random period of
time and inserting a random integer into the buffer. Random numbers will
be produced using the rand() function, which produces random integers
between0andRAND MAX.Theconsumerwillalsosleepforarandomperiod
oftimeand,uponawakening,willattempttoremoveanitemfromthebuffer.
AnoutlineoftheproducerandconsumerthreadsappearsinFigure7.16.
#include "buffer.h"
int main(int argc, char *argv[]) {
/* 1. Get command line arguments argv[1],argv[2],argv[3] */
/* 2. Initialize buffer */
/* 3. Create producer thread(s) */
/* 4. Create consumer thread(s) */
/* 5. Sleep */
/* 6. Exit */
}
Figure7.15 Outlineofskeletonprogram.P-42 Chapter7 SynchronizationExamples
#include <stdlib.h> /* required for rand() */
#include "buffer.h"
void *producer(void *param) {
buffer item item;
while (true) {
/* sleep for a random period of time */
sleep(...);
/* generate a random number */
item = rand();
if (insert item(item))
fprintf("report error condition");
else
printf("producer produced %d∖n",item);
}
void *consumer(void *param) {
buffer item item;
while (true) {
/* sleep for a random period of time */
sleep(...);
if (remove item(&item))
fprintf("report error condition");
else
printf("consumer consumed %d∖n",item);
}
Figure7.16 Anoutlineoftheproducerandconsumerthreads.
As noted earlier, you can solve this problem using either Pthreads or the
WindowsAPI.Inthefollowingsections,wesupplymoreinformationoneach
ofthesechoices.
PthreadsThreadCreationandSynchronization
CreatingthreadsusingthePthreadsAPIisdiscussedinSection4.4.1.Coverage
of mutex locks and semaphores using Pthreads is provided in Section 7.3.
RefertothosesectionsforspecificinstructionsonPthreadsthreadcreationand
synchronization.
WindowsThreads
Section 4.4.2 discusses thread creation using the Windows API. Refer to that
sectionforspecificinstructionsoncreatingthreads.ProgrammingProjects P-43
WindowsMutexLocks
Mutex locks are a type of dispatcherobject, as describedin Section7.2.1. The
following illustrates how to create a mutex lock using the CreateMutex()
function:
#include <windows.h>
HANDLE Mutex;
Mutex = CreateMutex(NULL, FALSE, NULL);
Thefirstparameterreferstoasecurityattributeforthemutexlock.Bysetting
thisattributetoNULL,wepreventanychildrenoftheprocessfromcreatingthis
mutex lock to inherit the handle of the lock. The second parameter indicates
whetherthecreatorofthemutexlockisthelock’sinitialowner.Passingavalue
of FALSE indicates that the thread creating the mutex is not the initial owner.
(Weshallsoonseehowmutexlocksareacquired.)Thethirdparameterallows
ustonamethemutex.However,becauseweprovideavalueofNULL,wedonot
namethemutex.Ifsuccessful,CreateMutex()returnsaHANDLEtothemutex
lock;otherwise,itreturnsNULL.
InSection7.2.1,weidentifieddispatcherobjectsasbeingeithersignaledor
nonsignaled. Asignaled dispatcher object (such as a mutex lock) is available
forownership.Onceitisacquired,itmovestothenonsignaledstate.Whenit
isreleased,itreturnstosignaled.
MutexlocksareacquiredbyinvokingtheWaitForSingleObject()func-
tion.ThefunctionispassedtheHANDLEtothelockalongwithaflagindicating
howlongtowait.Thefollowingcodedemonstrateshowthemutexlockcreated
abovecanbeacquired:
WaitForSingleObject(Mutex, INFINITE);
TheparametervalueINFINITEindicatesthatwewillwaitaninfiniteamount
oftimeforthelocktobecomeavailable.Othervaluescouldbeusedthatwould
allowthecallingthreadtotimeoutifthelockdidnotbecomeavailablewithin
a specified time. If the lock is in a signaled state, WaitForSingleObject()
returns immediately, and the lock becomes nonsignaled. A lock is released
(movestothesignaledstate)byinvokingReleaseMutex()—forexample,as
follows:
ReleaseMutex(Mutex);
WindowsSemaphores
SemaphoresintheWindowsAPIaredispatcherobjectsandthususethesame
signalingmechanismasmutexlocks.Semaphoresarecreatedasfollows:
#include <windows.h>
HANDLE Sem;
Sem = CreateSemaphore(NULL, 1, 5, NULL);P-44 Chapter7 SynchronizationExamples
The first and last parameters identify a security attribute and a name for the
semaphore,similartowhatwedescribedformutexlocks.Thesecondandthird
parametersindicatetheinitialvalueandmaximumvalueofthesemaphore.In
this instance, the initial value of the semaphore is 1, and its maximum value
is 5. If successful, CreateSemaphore() returns a HANDLE to the mutex lock;
otherwise,itreturnsNULL.
Semaphores are acquired with the same WaitForSingleObject() func-
tionasmutexlocks.WeacquirethesemaphoreSemcreatedinthisexampleby
usingthefollowingstatement:
WaitForSingleObject(Sem, INFINITE);
If the value of the semaphore is > 0, the semaphore is in the signaled state
andthusisacquiredbythecallingthread.Otherwise,thecallingthreadblocks
indefinitely—aswearespecifyingINFINITE—untilthesemaphorereturnsto
thesignaledstate.
Theequivalentofthesignal()operationforWindowssemaphoresisthe
ReleaseSemaphore()function.Thisfunctionispassedthreeparameters:
1. TheHANDLEofthesemaphore
2. Howmuchtoincreasethevalueofthesemaphore
3. Apointertothepreviousvalueofthesemaphore
WecanusethefollowingstatementtoincreaseSemby1:
ReleaseSemaphore(Sem, 1, NULL);
Both ReleaseSemaphore() and ReleaseMutex() return a nonzero value if
successfuland0otherwise.8
CHAPTER
Deadlocks
Inamultiprogrammingenvironment,severalthreadsmaycompeteforafinite
number of resources. A thread requests resources; if the resources are not
availableatthat time,the threadentersawaiting state.Sometimes,awaiting
threadcanneveragainchangestate,becausetheresourcesithasrequestedare
heldbyotherwaitingthreads.Thissituationiscalledadeadlock.Wediscussed
this issuebrieflyinChapter 6as aform of livenessfailure.There,we defined
deadlockasasituationinwhicheveryprocessinasetofprocessesiswaitingforan
eventthatcanbecausedonlybyanotherprocessintheset.
Perhapsthebestillustrationofadeadlockcanbedrawnfromalawpassed
bytheKansaslegislatureearlyinthe20thcentury.Itsaid,inpart:“Whentwo
trains approach each other at a crossing, both shall come to a full stop and
neithershallstartupagainuntiltheotherhasgone.”
In this chapter, we describe methods that application developers as well
as operating-system programmers can use to prevent or deal with dead-
locks. Although some applications can identify programs that may dead-
lock, operating systems typically do not provide deadlock-prevention facil-
ities, and it remains the responsibility of programmers to ensure that they
designdeadlock-freeprograms.Deadlockproblems—aswellasotherliveness
failures—are becoming more challenging as demand continues for increased
concurrencyandparallelismonmulticoresystems.
CHAPTER OBJECTIVES
• Illustratehowdeadlockcanoccurwhenmutexlocksareused.
• Definethefournecessaryconditionsthatcharacterizedeadlock.
• Identifyadeadlocksituationinaresourceallocationgraph.
• Evaluatethefourdifferentapproachesforpreventingdeadlocks.
• Applythebanker’salgorithmfordeadlockavoidance.
• Applythedeadlockdetectionalgorithm.
• Evaluateapproachesforrecoveringfromdeadlock.
317318 Chapter8 Deadlocks
8.1 System Model
A system consists of a finite number of resources to be distributed among a
number of competing threads. The resources may be partitioned into several
types(orclasses),eachconsisting ofsomenumber ofidenticalinstances.CPU
cycles, files, and I/O devices(such as network interfaces and DVD drives)are
examplesofresourcetypes.Ifasystemhas four CPUs, thenthe resourcetype
CPU has four instances. Similarly, the resource type network may have two
instances. If a thread requests an instance of a resource type, the allocation
of any instance of the type should satisfy the request. If it does not, then the
instancesarenotidentical,andtheresourcetypeclasseshavenotbeendefined
properly.
The various synchronization tools discussed in Chapter 6, such as mutex
locks and semaphores, arealso system resources;and on contemporary com-
putersystems,theyarethemostcommonsourcesofdeadlock.However,def-
initionisnotaproblemhere.Alockistypicallyassociatedwithaspecificdata
structure—thatis,onelockmaybeusedtoprotectaccesstoaqueue,another
toprotectaccesstoalinkedlist,andsoforth.Forthatreason,eachinstanceof
alockistypicallyassigneditsownresourceclass.
Notethatthroughoutthischapterwediscusskernelresources,butthreads
mayuseresourcesfromotherprocesses(forexample,viainterprocesscommu-
nication),andthoseresourceusescanalsoresultindeadlock.Suchdeadlocks
arenottheconcernofthekernelandthusnotdescribedhere.
A thread must request a resource before using it and must release the
resourceafterusingit.Athreadmayrequestas many resourcesas itrequires
tocarryoutitsdesignatedtask.Obviously,thenumberofresourcesrequested
maynotexceedthetotalnumberofresourcesavailableinthesystem.Inother
words,athreadcannot requesttwonetworkinterfacesifthesystemhasonly
one.
Under the normal mode of operation, a thread may utilize a resource in
onlythefollowingsequence:
1. Request. The thread requests the resource. If the request cannot be
granted immediately (for example, if a mutex lock is currently held by
anotherthread),thentherequestingthreadmustwaituntilitcanacquire
theresource.
2. Use.Thethreadcanoperateontheresource(forexample,iftheresource
isamutexlock,thethreadcanaccessitscriticalsection).
3. Release.Thethreadreleasestheresource.
The requestand releaseof resourcesmay be systemcalls, as explainedin
Chapter 2. Examples are the request() and release() of a device, open()
and close() of a file, and allocate() and free() memory system calls.
Similarly, as we saw in Chapter 6, request and release can be accomplished
through the wait() and signal() operations on semaphores and through
acquire()andrelease()ofamutexlock.Foreachuseofakernel-managed
resourcebyathread,theoperatingsystemcheckstomakesurethatthethread
has requested and has been allocated the resource. A system table records
whethereachresourceisfreeorallocated.For eachresourcethat isallocated,8.2 DeadlockinMultithreadedApplications 319
the table also records the thread to which it is allocated. If a thread requests
a resource that is currently allocated to another thread, it can be added to a
queueofthreadswaitingforthisresource.
Asetofthreadsisinadeadlockedstatewheneverythreadinthesetiswait-
ingforaneventthatcanbecausedonlybyanotherthreadintheset.Theevents
withwhichwearemainlyconcernedhereareresourceacquisitionandrelease.
Theresourcesaretypicallylogical(forexample,mutexlocks,semaphores,and
files);however,othertypesofeventsmayresultindeadlocks,includingread-
ingfromanetworkinterfaceortheIPC(interprocesscommunication)facilities
discussedinChapter3.
To illustrate a deadlocked state, we refer back to the dining-philosophers
problem from Section 7.1.3. In this situation, resources are represented by
chopsticks. If all the philosophers get hungry at the same time, and each
philosopher grabs the chopstick on her left,there are no longer any available
chopsticks.Eachphilosopheristhenblockedwaitingforherrightchopstickto
becomeavailable.
Developersof multithreaded applications must remain aware of the pos-
sibility of deadlocks. The locking tools presented in Chapter 6 are designed
toavoidraceconditions. However,inusingthesetools,developersmustpay
carefulattentiontohowlocksareacquiredandreleased.Otherwise,deadlock
canoccur,asdescribednext.
8.2 Deadlock in Multithreaded Applications
Prior to examining how deadlock issues can be identified and man-
aged, we first illustrate how deadlock can occur in a multithreaded
Pthread program using POSIX mutex locks. The pthread mutex init()
function initializes an unlocked mutex. Mutex locks are acquired and
released using pthread mutex lock() and pthread mutex unlock(),
respectively. If a thread attempts to acquire a locked mutex, the call to
pthread mutex lock() blocks the thread until the owner of the mutex lock
invokespthread mutex unlock().
Twomutexlocksarecreatedandinitializedinthefollowingcodeexample:
pthread mutex t first mutex;
pthread mutex t second mutex;
pthread mutex init(&first mutex,NULL);
pthread mutex init(&second mutex,NULL);
Next, two threads—thread one and thread two—are created, and both
these threads have access to both mutex locks. thread one and thread two
run in the functions do work one() and do work two(), respectively, as
showninFigure8.1.
In this example, thread one attempts to acquire the mutex locks in the
order (1) first mutex, (2) second mutex. At the same time, thread two
attempts to acquire the mutex locks in the order (1) second mutex, (2)
first mutex. Deadlock is possible if thread one acquires first mutex
whilethread twoacquiressecond mutex.320 Chapter8 Deadlocks
/* thread one runs in this function */
void *do work one(void *param)
{
pthread mutex lock(&first mutex);
pthread mutex lock(&second mutex);
/**
* Do some work
*/
pthread mutex unlock(&second mutex);
pthread mutex unlock(&first mutex);
pthread exit(0);
}
/* thread two runs in this function */
void *do work two(void *param)
{
pthread mutex lock(&second mutex);
pthread mutex lock(&first mutex);
/**
* Do some work
*/
pthread mutex unlock(&first mutex);
pthread mutex unlock(&second mutex);
pthread exit(0);
}
Figure8.1 Deadlockexample.
Notethat,eventhoughdeadlockispossible,itwillnotoccurifthread one
can acquire and release the mutex locks for first mutex and second mutex
before thread two attempts to acquire the locks. And, of course, the order
in which the threads run depends on how they are scheduled by the CPU
scheduler. This example illustrates a problem with handling deadlocks: it is
difficult to identify and test for deadlocks that may occur only under certain
schedulingcircumstances.
8.2.1 Livelock
Livelock is another form of liveness failure. It is similar to deadlock; both
prevent two or more threads from proceeding, but the threads are unable to
proceed for different reasons. Whereas deadlock occurs when every thread
in a set is blocked waiting for an event that can be caused only by another
threadintheset,livelockoccurswhenathreadcontinuouslyattemptsanaction
that fails. Livelock is similar to what sometimes happens when two people
attempttopassinahallway:Onemovestohisright,theothertoherleft,still
obstructing each other’s progress. Then he moves to his left, and she moves8.3 DeadlockCharacterization 321
to her right, and so forth. They aren’t blocked, but they aren’t making any
progress.
Livelock can be illustratedwith the Pthreads pthread mutex trylock()
function, which attemptstoacquireamutexlockwithout blocking. The code
exampleinFigure8.2rewritestheexamplefromFigure8.1sothatitnowuses
pthread mutex trylock().Thissituationcanleadtolivelockifthread one
acquires first mutex, followed by thread two acquiring second mutex.
Each thread then invokes pthread mutex trylock(), which fails, releases
theirrespectivelocks,andrepeatsthesameactionsindefinitely.
Livelocktypicallyoccurswhenthreadsretryfailingoperationsatthesame
time.It thus can generallybe avoidedby having each threadretrythe failing
operation at random times. This is precisely the approach taken by Ethernet
networkswhenanetworkcollisionoccurs.Ratherthantryingtoretransmita
packetimmediatelyafteracollisionoccurs,ahostinvolvedinacollisionwill
backoff arandomperiodoftimebeforeattemptingtotransmitagain.
Livelock is less common than deadlock but nonetheless is a challenging
issueindesigningconcurrentapplications,andlikedeadlock,itmayonlyoccur
underspecificschedulingcircumstances.
8.3 Deadlock Characterization
In the previous section we illustrated how deadlock could occur in multi-
threadedprogrammingusingmutexlocks.Wenowlookmorecloselyatcon-
ditionsthatcharacterizedeadlock.
8.3.1 Necessary Conditions
Adeadlocksituationcanariseifthefollowingfourconditionsholdsimultane-
ouslyinasystem:
1. Mutual exclusion. At least one resource must be held in a nonsharable
mode; that is, only one thread at a time can use the resource. If another
threadrequeststhatresource,therequestingthreadmustbedelayeduntil
theresourcehasbeenreleased.
2. Hold and wait. A thread must be holding at least one resource and
waiting to acquire additional resources that are currently being held by
otherthreads.
3. No preemption. Resources cannot be preempted;that is, a resource can
bereleasedonlyvoluntarilybythethreadholdingit,afterthatthreadhas
completeditstask.
4. Circularwait.Aset{T ,T ,...,T }ofwaitingthreadsmustexistsuchthat
0 1 n
T is waiting for a resource held by T , T is waiting for a resource held
0 1 1
byT ,...,T iswaitingforaresourceheldbyT ,andT iswaitingfora
2 n−1 n n
resourceheldbyT .
0
We emphasize that all four conditions must hold for a deadlock to occur.
The circular-wait condition implies the hold-and-wait condition, so the four322 Chapter8 Deadlocks
/* thread one runs in this function */
void *do work one(void *param)
{
int done = 0;
while (!done) {
pthread mutex lock(&first mutex);
if (pthread mutex trylock(&second mutex)) {
/**
* Do some work
*/
pthread mutex unlock(&second mutex);
pthread mutex unlock(&first mutex);
done = 1;
}
else
pthread mutex unlock(&first mutex);
}
pthread exit(0);
}
/* thread two runs in this function */
void *do work two(void *param)
{
int done = 0;
while (!done) {
pthread mutex lock(&second mutex);
if (pthread mutex trylock(&first mutex)) {
/**
* Do some work
*/
pthread mutex unlock(&first mutex);
pthread mutex unlock(&second mutex);
done = 1;
}
else
pthread mutex unlock(&second mutex);
}
pthread exit(0);
}
Figure8.2 Livelockexample.8.3 DeadlockCharacterization 323
. .
first_mutex second_mutex
thread_one thread_two
Figure8.3 Resource-allocationgraphforprograminFigure8.1.
conditions are not completely independent. We shall see in Section 8.5, how-
ever,thatitisusefultoconsidereachconditionseparately.
8.3.2 Resource-Allocation Graph
Deadlockscanbedescribedmorepreciselyintermsofadirectedgraphcalled
asystem resource-allocation graph.This graphconsists of asetof verticesV
andasetofedgesE.ThesetofverticesVispartitionedintotwodifferenttypes
ofnodes:T = {T ,T ,...,T },thesetconsistingofalltheactivethreadsinthe
1 2 n
system,andR = {R ,R ,...,R },thesetconsistingofallresourcetypesinthe
1 2 m
system.
AdirectededgefromthreadT toresourcetypeR isdenotedby T → R;
i j i j
it signifies that threadT has requestedan instance of resource type R and is
i j
currently waiting for that resource. Adirected edge from resource type R to
j
thread T is denoted by R → T; it signifies that an instance of resource type
i j i
R hasbeenallocatedtothreadT.AdirectededgeT → R iscalledarequest
j i i j
edge;adirectededgeR → T iscalledanassignmentedge.
j i
Pictorially, we represent each thread T as a circle and each resource type
i
R as a rectangle. As a simple example, the resource allocation graph shown
j
inFigure8.3illustratesthedeadlocksituationfromtheprograminFigure8.1.
Since resource type R may have more than one instance, we represent each
j
such instance as a dot within the rectangle. Note that a request edge points
onlytotherectangleR,whereasanassignmentedgemustalsodesignateone
j
ofthedotsintherectangle.
WhenthreadT requestsaninstanceofresourcetypeR,arequestedgeis
i j
inserted in the resource-allocation graph. When this request can be fulfilled,
therequestedgeisinstantaneouslytransformedtoanassignmentedge.When
thethreadnolongerneedsaccesstotheresource,itreleasestheresource.Asa
result,theassignmentedgeisdeleted.
The resource-allocation graph shown in Figure 8.4 depicts the following
situation.
• ThesetsT,R,andE:
◦
T={T ,T ,T }
1 2 3
◦
R={R ,R ,R ,R }
1 2 3 4324 Chapter8 Deadlocks
R R
1 3
T T T
1 2 3
R
2
R
4
Figure8.4 Resource-allocationgraph.
◦ E={T → R ,T → R ,R → T ,R → T ,R → T ,R → T }
1 1 2 3 1 2 2 2 2 1 3 3
• Resourceinstances:
◦
OneinstanceofresourcetypeR
1
◦
TwoinstancesofresourcetypeR
2
◦
OneinstanceofresourcetypeR
3
◦
ThreeinstancesofresourcetypeR
4
• Threadstates:
◦
ThreadT isholdinganinstanceofresourcetypeR andiswaitingfor
1 2
aninstanceofresourcetypeR .
1
◦
Thread T is holding an instance of R and an instance of R and is
2 1 2
waitingforaninstanceofR .
3
◦
ThreadT isholdinganinstanceofR .
3 3
Giventhedefinitionofaresource-allocationgraph,itcanbeshownthat,if
thegraphcontainsnocycles,thennothreadinthesystemisdeadlocked.Ifthe
graphdoescontainacycle,thenadeadlockmayexist.
If each resource type has exactly one instance, then a cycle implies that a
deadlockhasoccurred.Ifthecycleinvolvesonlyasetofresourcetypes,each
ofwhichhasonlyasingleinstance,thenadeadlockhasoccurred.Eachthread
involvedinthecycleisdeadlocked.Inthiscase,acycleinthegraphisbotha
necessaryandasufficientconditionfortheexistenceofdeadlock.
Ifeachresourcetypehasseveralinstances,thenacycledoesnotnecessarily
imply that a deadlock has occurred. In this case, a cycle in the graph is a
necessarybutnotasufficientconditionfortheexistenceofdeadlock.
To illustrate this concept, we return to the resource-allocation graph
depictedinFigure8.4.SupposethatthreadT requestsaninstanceofresource
3
type R . Since no resource instance is currently available, we add a request
28.3 DeadlockCharacterization 325
R R
1 3
T T T
1 2 3
R
2
R
4
Figure8.5 Resource-allocationgraphwithadeadlock.
edgeT →R tothegraph(Figure8.5).Atthispoint,twominimalcyclesexist
3 2
inthesystem:
T → R → T → R → T → R → T
1 1 2 3 3 2 1
T → R → T → R → T
2 3 3 2 2
Threads T , T , and T are deadlocked. Thread T is waiting for the resource
1 2 3 2
R , which is held by thread T . Thread T is waiting for either thread T or
3 3 3 1
threadT toreleaseresourceR .Inaddition,threadT iswaitingforthreadT
2 2 1 2
toreleaseresourceR .
1
Nowconsidertheresource-allocationgraphinFigure8.6.Inthisexample,
wealsohaveacycle:
T → R → T → R → T
1 1 3 2 1
T
2
R
1
T
3
T
1
R
2
T
4
Figure8.6 Resource-allocationgraphwithacyclebutnodeadlock.326 Chapter8 Deadlocks
However,thereisnodeadlock.ObservethatthreadT mayreleaseitsinstance
4
of resource type R . That resource can then be allocated to T , breaking the
2 3
cycle.
Insummary,ifaresource-allocationgraphdoesnothaveacycle,thenthe
systemisnotinadeadlockedstate.Ifthereisacycle,thenthesystemmayor
maynotbeinadeadlockedstate.Thisobservationisimportantwhenwedeal
withthedeadlockproblem.
8.4 Methods for Handling Deadlocks
Generally speaking, we can deal with the deadlock problem in one of three
ways:
• We can ignore the problem altogether and pretend that deadlocks never
occurinthesystem.
• We can use a protocol to prevent or avoid deadlocks, ensuring that the
systemwillneverenteradeadlockedstate.
• Wecanallowthesystemtoenteradeadlockedstate,detectit,andrecover.
Thefirstsolutionistheoneusedbymostoperatingsystems,includingLinux
and Windows. It is then up to kernel and application developers to write
programs that handle deadlocks, typically using approaches outlined in the
secondsolution.Somesystems—suchasdatabases—adoptthethirdsolution,
allowingdeadlockstooccurandthenmanagingtherecovery.
Next, we elaborate briefly on the three methods for handling deadlocks.
Then,inSection8.5throughSection8.8,wepresentdetailedalgorithms.Before
proceeding,weshouldmentionthatsomeresearchershavearguedthatnoneof
thebasicapproachesaloneisappropriatefortheentirespectrumofresource-
allocation problems in operating systems. The basic approaches can be com-
bined, however, allowing us to select an optimal approach for each class of
resourcesinasystem.
Toensurethatdeadlocksneveroccur,thesystemcanuseeitheradeadlock-
preventionoradeadlock-avoidancescheme.Deadlockpreventionprovidesa
setofmethodstoensurethatatleastoneofthenecessaryconditions(Section
8.3.1) cannot hold. These methods prevent deadlocks by constraining how
requestsforresourcescanbemade.WediscussthesemethodsinSection8.5.
Deadlock avoidance requires that the operating system be given addi-
tionalinformationinadvanceconcerningwhichresourcesathreadwillrequest
anduseduringitslifetime.Withthisadditionalknowledge,theoperatingsys-
tem can decide for each request whether or not the thread should wait. To
decide whether the current request can be satisfied or must be delayed, the
systemmustconsidertheresourcescurrentlyavailable,theresourcescurrently
allocated to each thread, and the future requests and releases of each thread.
WediscusstheseschemesinSection8.6.
If a system does not employ either a deadlock-prevention or a deadlock-
avoidancealgorithm,thenadeadlocksituationmayarise.Inthisenvironment,
the system can providean algorithm that examines the state of the system to
determinewhetheradeadlockhasoccurredandanalgorithmtorecoverfrom8.5 DeadlockPrevention 327
the deadlock (if a deadlock has indeed occurred). We discuss these issues in
Section8.7andSection8.8.
Intheabsenceofalgorithmstodetectandrecoverfromdeadlocks,wemay
arrive at a situation in which the system is in a deadlocked state yet has no
wayofrecognizingwhathashappened.Inthiscase,theundetecteddeadlock
willcausethesystem’sperformancetodeteriorate,becauseresourcesarebeing
heldby threadsthat cannot run and because more and more threads, asthey
make requests for resources, will enter a deadlocked state. Eventually, the
systemwillstopfunctioningandwillneedtoberestartedmanually.
Althoughthismethodmaynotseemtobeaviableapproachtothedead-
lockproblem,itisneverthelessusedinmostoperatingsystems,asmentioned
earlier. Expense is one important consideration. Ignoring the possibility of
deadlocksischeaperthantheotherapproaches.Sinceinmanysystems,dead-
locksoccur infrequently(say,once permonth), theextraexpenseoftheother
methodsmaynotseemworthwhile.
Inaddition,methodsusedtorecoverfromotherlivenessconditions,such
as livelock, may be used to recover from deadlock. In some circumstances, a
system is suffering from a liveness failure but is not in a deadlocked state.
We see this situation, for example, with a real-time thread running at the
highest priority (or any thread running on a nonpreemptive scheduler) and
neverreturningcontroltotheoperatingsystem.Thesystemmusthavemanual
recoverymethodsforsuchconditionsandmaysimplyusethosetechniquesfor
deadlockrecovery.
8.5 Deadlock Prevention
As we noted in Section 8.3.1, for a deadlock to occur, each of the four neces-
sary conditions must hold. By ensuring that at least one of these conditions
cannothold,wecanpreventtheoccurrenceofadeadlock.Weelaborateonthis
approachbyexaminingeachofthefournecessaryconditionsseparately.
8.5.1 Mutual Exclusion
Themutual-exclusionconditionmusthold.Thatis,atleastoneresourcemust
be nonsharable. Sharable resources do not require mutually exclusive access
andthuscannotbeinvolvedinadeadlock.Read-onlyfilesareagoodexample
of a sharable resource. If several threads attempt to open a read-only file at
the same time, they can be granted simultaneous access to the file. Athread
never needs to wait for a sharable resource. In general, however, we cannot
preventdeadlocksbydenyingthemutual-exclusioncondition,because some
resources are intrinsically nonsharable. For example, a mutex lock cannot be
simultaneouslysharedbyseveralthreads.
8.5.2 Hold and Wait
Toensurethatthehold-and-waitconditionneveroccursinthesystem,wemust
guarantee that, whenever a thread requests a resource, it does not hold any
otherresources.Oneprotocolthatwecanuserequireseachthreadtorequest
andbeallocatedallitsresourcesbeforeitbeginsexecution.Thisis,ofcourse,328 Chapter8 Deadlocks
impractical for most applications due to the dynamic nature of requesting
resources.
An alternativeprotocol allows a thread to requestresources only when it
has none. Athread may request some resources and use them. Before it can
request any additional resources, it must release all the resources that it is
currentlyallocated.
Boththeseprotocolshavetwomaindisadvantages.First,resourceutiliza-
tionmaybelow,sinceresourcesmaybeallocatedbutunusedforalongperiod.
For example, a thread may be allocated a mutex lock for its entire execution,
yetonlyrequireitforashortduration.Second,starvationispossible.Athread
thatneedsseveralpopularresourcesmayhavetowaitindefinitely,becauseat
leastoneoftheresourcesthatitneedsisalwaysallocatedtosomeotherthread.
8.5.3 No Preemption
The third necessary condition for deadlocks is that there be no preemption
of resources that have already been allocated. To ensure that this condition
doesnot hold,we can use thefollowing protocol.If athreadisholding some
resourcesandrequestsanotherresourcethatcannotbeimmediatelyallocated
to it (that is, the thread must wait), then all resources the thread is currently
holdingarepreempted.Inotherwords,theseresourcesareimplicitlyreleased.
Thepreemptedresourcesareaddedtothelistofresourcesforwhichthethread
iswaiting.Thethreadwillberestartedonlywhenitcanregainitsoldresources,
aswellasthenewonesthatitisrequesting.
Alternatively,ifa thread requestssome resources, we first check whether
they are available. If they are, we allocate them. If they are not, we check
whethertheyareallocatedtosomeotherthreadthatiswaitingforadditional
resources.Ifso,wepreemptthedesiredresourcesfromthewaitingthreadand
allocatethemtotherequestingthread.Iftheresourcesareneitheravailablenor
heldbyawaitingthread,therequestingthreadmustwait.Whileitiswaiting,
some of its resources may be preempted, but only if another thread requests
them. A thread can be restarted only when it is allocated the new resources
it is requestingand recoversany resourcesthat were preemptedwhile it was
waiting.
Thisprotocolisoftenappliedtoresourceswhosestatecanbeeasilysaved
and restored later, such as CPU registers and database transactions. It can-
not generally be applied to such resources as mutex locks and semaphores,
preciselythetypeofresourceswheredeadlockoccursmostcommonly.
8.5.4 Circular Wait
The three options presented thus far for deadlock prevention are generally
impractical in most situations. However, the fourth and final condition for
deadlocks — the circular-wait condition — presents an opportunity for a
practical solution by invalidating one of the necessary conditions. One way
to ensure that this condition never holds is to impose a total ordering of
all resource types and to require that each thread requests resources in an
increasingorderofenumeration.
To illustrate, we let R = {R , R , ..., R } be the set of resource types. We
1 2 m
assign to each resource type a unique integer number, which allows us to8.5 DeadlockPrevention 329
comparetworesourcesandtodeterminewhetheroneprecedesanotherinour
ordering.Formally,wedefineaone-to-onefunctionF:R→N,whereNistheset
ofnaturalnumbers.Wecanaccomplishthisschemeinanapplicationprogram
by developing an ordering among all synchronization objects in the system.
For example, the lock ordering in the Pthread program shown in Figure 8.1
couldbe
F(first mutex)=1
F(second mutex)=5
We can now consider the following protocol to prevent deadlocks: Each
threadcanrequestresourcesonlyinanincreasingorderofenumeration.That
is,athreadcaninitiallyrequestaninstance ofaresource—say, R.Afterthat,
i
the thread can request an instance of resource R if and only if F(R) > F(R).
j j i
For example, using the function defined above, a thread that wants to use
both first mutex and second mutex at the same time must first request
first mutex and then second mutex. Alternatively, we can require that a
threadrequestinganinstanceofresourceR musthavereleasedanyresources
j
R suchthatF(R)≥F(R).Notealsothatifseveralinstancesofthesameresource
i i j
typeareneeded,asinglerequestforallofthemmustbeissued.
If these two protocols are used, then the circular-wait condition cannot
hold. We can demonstrate this fact by assuming that a circular wait exists
(proofbycontradiction).Letthesetofthreadsinvolvedinthecircularwaitbe
{T , T , ..., T }, where T is waiting for a resource R, which is held by thread
0 1 n i i
T . (Modulo arithmetic is used on the indexes, so that T is waiting for a
i+1 n
resource R held by T .) Then, since thread T is holding resource R while
n 0 i+1 i
requestingresourceR ,wemusthaveF(R)<F(R )foralli.Butthiscondi-
i+1 i i+1
tionmeansthatF(R )<F(R )<...<F(R )<F(R ).Bytransitivity,F(R ) < F(R ),
0 1 n 0 0 0
whichisimpossible.Therefore,therecanbenocircularwait.
Keepinmindthatdevelopinganordering,orhierarchy,doesnotinitself
prevent deadlock. It is up to application developers to write programs that
follow the ordering. However, establishing a lock ordering can be difficult,
especially on a system with hundreds—or thousands—of locks. To address
this challenge, many Java developers have adopted the strategy of using
themethodSystem.identityHashCode(Object)(whichreturnsthedefault
hash code value of the Object parameter it has been passed) as the function
fororderinglockacquisition.
It is also important to note that imposing a lock ordering does not guar-
antee deadlock prevention if locks can be acquired dynamically. For exam-
ple, assume we have a function that transfers funds between two accounts.
To prevent a race condition, each account has an associated mutex lock that
is obtained from a get lock() function such as that shown in Figure 8.7.
Deadlockispossibleiftwothreadssimultaneouslyinvokethetransaction()
function,transposingdifferentaccounts.Thatis,onethreadmightinvoke
transaction(checking account, savings account, 25.0)
andanothermightinvoke
transaction(savings account, checking account, 50.0)330 Chapter8 Deadlocks
void transaction(Account from, Account to, double amount)
{
mutex lock1, lock2;
lock1 = get lock(from);
lock2 = get lock(to);
acquire(lock1);
acquire(lock2);
withdraw(from, amount);
deposit(to, amount);
release(lock2);
release(lock1);
}
Figure8.7 Deadlockexamplewithlockordering.
8.6 Deadlock Avoidance
Deadlock-prevention algorithms, as discussed in Section 8.5, prevent dead-
locks by limiting how requests can be made. The limits ensure that at least
oneofthenecessaryconditionsfordeadlockcannotoccur.Possiblesideeffects
of preventing deadlocks by this method, however, are low device utilization
andreducedsystemthroughput.
An alternative method for avoiding deadlocks is to require additional
informationabouthowresourcesaretoberequested.Forexample,inasystem
with resources R1 and R2, the system might need to know that thread P
will request first R1 and then R2 before releasing both resources, whereas
thread Q will request R2 and then R1. With this knowledge of the complete
sequence of requests and releases for each thread, the system can decide for
eachrequestwhetherornotthethreadshouldwaitinordertoavoidapossible
futuredeadlock.Eachrequestrequiresthatinmakingthisdecisionthesystem
considertheresourcescurrentlyavailable,theresourcescurrentlyallocatedto
eachthread,andthefuturerequestsandreleasesofeachthread.
The various algorithms that use this approach differ in the amount and
typeofinformationrequired.Thesimplestandmostusefulmodelrequiresthat
eachthreaddeclarethemaximumnumberofresourcesofeachtypethatitmay
need. Given this a priori information, it is possible to construct an algorithm
that ensures that the systemwill never entera deadlockedstate.Adeadlock-
avoidance algorithm dynamically examines the resource-allocation state to
ensure that a circular-wait condition can never exist. The resource-allocation
state is defined by the number of available and allocated resources and the
maximum demands ofthe threads.In the following sections, we exploretwo
deadlock-avoidancealgorithms.8.6 DeadlockAvoidance 331
LINUXLOCKDEPTOOL
Although ensuring that resources are acquired in the proper order is the
responsibility ofkerneland application developers,certainsoftware can be
usedtoverifythatlocksareacquiredintheproperorder.Todetectpossible
deadlocks,Linuxprovideslockdep,atoolwithrichfunctionalitythatcanbe
usedtoverifylockingorderinthekernel.lockdepisdesignedtobeenabled
on a running kernel as it monitors usage patterns of lock acquisitions and
releasesagainstasetofrulesforacquiringandreleasinglocks.Twoexamples
follow,butnotethatlockdepprovidessignificantlymorefunctionalitythan
whatisdescribedhere:
• Theorderinwhichlocksareacquiredisdynamicallymaintainedbythe
system.Iflockdepdetectslocksbeingacquiredoutoforder,itreportsa
possibledeadlockcondition.
• InLinux,spinlockscanbeusedininterrupthandlers.Apossiblesource
ofdeadlockoccurswhenthekernelacquiresaspinlockthatisalsoused
in an interrupt handler. If the interrupt occurs while the lock is being
held, the interrupthandler preemptsthe kernelcode currentlyholding
the lock and then spins while attempting to acquire the lock, resulting
indeadlock.Thegeneralstrategyforavoidingthissituationistodisable
interrupts on the current processor before acquiring a spinlock that is
alsousedinaninterrupthandler.Iflockdepdetectsthatinterruptsare
enabledwhilekernelcodeacquiresalockthatisalsousedinaninterrupt
handler,itwillreportapossibledeadlockscenario.
lockdep was developed to be used as a tool in developing or modifying
code in the kernel and not to be used on production systems, as it can
significantly slow down a system. Its purpose is to test whether software
such as a new device driver or kernel module provides a possible source
of deadlock. The designers of lockdep have reported that within a few
years of its development in 2006, the number of deadlocks from system
reportshadbeenreducedbyanorderofmagnitude.âŁžAlthoughlockdep
was originally designed only for use in the kernel, recent revisions of this
tool can now be used for detecting deadlocks in user applications using
Pthreads mutex locks. Further details on the lockdep tool can be found at
https://www.kernel.org/doc/Documentation/locking/lockdep-design.txt.
8.6.1 Safe State
A state is safe if the system can allocate resources to each thread (up to its
maximum)insomeorderandstillavoidadeadlock.Moreformally,asystem
is in a safe state only if there exists a safe sequence. A sequence of threads
<T , T , ..., T > is a safe sequence for the current allocation state if, for each
1 2 n
T,theresourcerequeststhatT canstillmakecanbesatisfiedbythecurrently
i i
availableresourcesplustheresourcesheldbyallT,withj<i.Inthissituation,
j
if the resources that T needs are not immediately available, then T can wait
i i
until all T have finished. When they have finished, T can obtain all of its
j i332 Chapter8 Deadlocks
unsafe
deadlock
safe
Figure8.8 Safe,unsafe,anddeadlockedstatespaces.
neededresources,completeitsdesignatedtask,returnitsallocatedresources,
and terminate. When T terminates, T can obtain its needed resources, and
i i+1
soon.Ifnosuchsequenceexists,thenthesystemstateissaidtobeunsafe.
A safe state is not a deadlocked state. Conversely, a deadlocked state is
an unsafe state. Not all unsafe states are deadlocks, however (Figure 8.8).
An unsafe state may lead to a deadlock. As long as the state is safe, the
operatingsystemcanavoidunsafe(anddeadlocked)states.Inanunsafestate,
theoperatingsystemcannotpreventthreadsfromrequestingresourcesinsuch
awaythatadeadlockoccurs.Thebehaviorofthethreadscontrolsunsafestates.
To illustrate, consider a system with twelve resources and three threads:
T ,T ,andT .ThreadT requirestenresources,threadT mayneedasmany
0 1 2 0 1
as four, and thread T may need up to nine resources. Suppose that, at time
2
t ,threadT isholdingfiveresources,threadT isholdingtworesources,and
0 0 1
threadT isholdingtworesources.(Thus,therearethreefreeresources.)
2
MaximumNeeds CurrentNeeds
T 10 5
0
T 4 2
1
T 9 2
2
Attimet ,thesystemisinasafestate.Thesequence<T ,T ,T >satisfies
0 1 0 2
the safety condition. Thread T can immediatelybe allocated all its resources
1
andthenreturnthem(thesystemwillthenhavefiveavailableresources);then
threadT cangetallitsresourcesandreturnthem(thesystemwillthenhaveten
0
available resources); and finally thread T can get all its resources and return
2
them(thesystemwillthenhavealltwelveresourcesavailable).
Asystemcangofromasafestatetoanunsafestate.Supposethat,attimet ,
1
threadT requestsandisallocatedonemoreresource.Thesystemisnolonger
2
in a safe state. At this point, only thread T can be allocated all its resources.
1
When it returns them, the system will have only four available resources.
Since thread T is allocated five resources but has a maximum of ten, it may
0
requestfivemoreresources.Ifitdoesso,itwillhavetowait,becausetheyare
unavailable.Similarly,threadT mayrequestsixadditionalresourcesandhave
2
towait,resultinginadeadlock.Ourmistakewasingrantingtherequestfrom
threadT foronemoreresource.IfwehadmadeT waituntileitheroftheother
2 28.6 DeadlockAvoidance 333
threads had finished and released its resources, then we could have avoided
thedeadlock.
Giventheconceptofasafestate,wecandefineavoidancealgorithmsthat
ensurethatthesystemwillneverdeadlock.Theideaissimplytoensurethatthe
systemwillalwaysremaininasafestate.Initially,thesystemisinasafestate.
Whenever a thread requestsa resource that is currently available, the system
mustdecidewhethertheresourcecanbeallocatedimmediatelyorthethread
mustwait.Therequestisgrantedonlyiftheallocationleavesthesystemina
safestate.
Inthisscheme,ifathreadrequestsaresourcethatiscurrentlyavailable,it
may still have towait. Thus, resource utilizationmay be lower than it would
otherwisebe.
8.6.2 Resource-Allocation-Graph Algorithm
Ifwehavearesource-allocationsystemwithonlyoneinstanceofeachresource
type,wecanuseavariantoftheresource-allocationgraphdefinedinSection
8.3.2fordeadlockavoidance.Inadditiontotherequestandassignmentedges
already described, we introduce a new type of edge, called a claim edge. A
claimedgeT →R indicatesthatthreadT mayrequestresourceR atsometime
i j i j
inthefuture.Thisedgeresemblesarequestedgeindirectionbutisrepresented
inthegraphbyadashedline.WhenthreadT requestsresourceR,theclaim
i j
edge T → R is converted to a request edge. Similarly, when a resource R is
i j j
releasedbyT,theassignmentedgeR →T isreconvertedtoaclaimedgeT →
i j i i
R.
j
Note that the resources must be claimed a priori in the system. That is,
beforethreadT startsexecuting,allitsclaimedgesmustalreadyappearinthe
i
resource-allocationgraph.Wecanrelaxthisconditionbyallowingaclaimedge
T →R tobeaddedtothegraphonlyifalltheedgesassociatedwiththreadT
i j i
areclaimedges.
Now suppose that thread T requests resource R. The request can be
i j
granted only if converting the request edge T → R to an assignment edge
i j
R → T does not result in the formation of a cycle in the resource-allocation
j i
graph.Wecheckforsafetybyusingacycle-detectionalgorithm.Analgorithm
fordetectingacycleinthisgraphrequiresanorderofn2 operations,wheren
isthenumberofthreadsinthesystem.
Ifnocycleexists,thentheallocationofthe resourcewillleavethesystem
in a safe state. If a cycle is found, then the allocation will put the system in
an unsafe state. In that case, thread T will have to wait for its requests to be
i
satisfied.
To illustrate this algorithm, we consider the resource-allocation graph of
Figure 8.9. Suppose that T requests R . Although R is currently free, we
2 2 2
cannotallocateittoT ,sincethisactionwillcreateacycleinthegraph(Figure
2
8.10). Acycle, as mentioned,indicates that the system is in an unsafe state.If
T requestsR ,andT requestsR ,thenadeadlockwilloccur.
1 2 2 1
8.6.3 Banker’s Algorithm
The resource-allocation-graph algorithm is not applicable to a resource-
allocation system with multiple instances of each resource type. The334 Chapter8 Deadlocks
R
1
T T
1 2
R
2
Figure8.9 Resource-allocationgraphfordeadlockavoidance.
deadlock-avoidance algorithm that we describe next is applicable to such a
system but is less efficient than the resource-allocation graph scheme. This
algorithm is commonly known as the banker’s algorithm. The name was
chosen because the algorithm could be used in a banking system to ensure
that thebank neverallocateditsavailablecashinsuchawaythat itcouldno
longersatisfytheneedsofallitscustomers.
Whenanewthreadentersthesystem,itmustdeclarethemaximumnum-
berofinstancesofeachresourcetypethatitmayneed.Thisnumbermaynot
exceed the total number of resources in the system. When a user requests a
set of resources, the system must determine whether the allocation of these
resourceswillleavethesysteminasafestate.Ifitwill,theresourcesareallo-
cated;otherwise,thethreadmustwaituntilsomeotherthreadreleasesenough
resources.
Several data structures must be maintained to implement the banker’s
algorithm. These data structures encode the state of the resource-allocation
system. We need the following data structures, where n is the number of
threadsinthesystemandmisthenumberofresourcetypes:
• Available.Avectoroflengthmindicatesthenumberofavailableresources
of each type. If Available[j] equals k, then k instances of resource type R
j
areavailable.
R
1
T T
1 2
R
2
Figure8.10 Anunsafestateinaresource-allocationgraph.8.6 DeadlockAvoidance 335
• Max. An n × m matrix defines the maximum demand of each thread.
If Max[i][j] equals k, then thread T may request at most k instances of
i
resourcetypeR.
j
• Allocation.Ann×mmatrixdefinesthenumberofresourcesofeachtype
currentlyallocatedtoeachthread.IfAllocation[i][j]equalsk,thenthread
T iscurrentlyallocatedkinstancesofresourcetypeR.
i j
• Need. An n × m matrix indicates the remaining resource need of each
thread.IfNeed[i][j]equalsk,thenthreadT mayneedkmoreinstancesof
i
resourcetypeR tocompleteitstask.NotethatNeed[i][j]equalsMax[i][j]
j
−Allocation[i][j].
Thesedatastructuresvaryovertimeinbothsizeandvalue.
To simplify the presentation of the banker’s algorithm, we next establish
somenotation.LetXandYbevectorsoflengthn.WesaythatX≤Yifandonly
ifX[i]≤Y[i]foralli=1,2,...,n.Forexample,ifX=(1,7,3,2)andY=(0,3,2,1),
thenY≤X.Inaddition,Y<XifY≤XandY≠X.
We can treat each row in the matrices Allocation and Need as vectors
and refer to them as Allocation and Need. The vector Allocation specifies
i i i
the resources currently allocated to thread T; the vector Need specifies the
i i
additionalresourcesthatthreadT maystillrequesttocompleteitstask.
i
8.6.3.1 SafetyAlgorithm
We can now presentthe algorithm for finding out whether or not asystem is
inasafestate.Thisalgorithmcanbedescribedasfollows:
1. LetWorkandFinishbevectorsoflengthmandn,respectively.Initialize
Work=AvailableandFinish[i]=falsefori=0,1,...,n−1.
2. Findanindexisuchthatboth
a. Finish[i]==false
b. Need ≤Work
i
Ifnosuchiexists,gotostep4.
3. Work=Work+Allocation
i
Finish[i]=true
Gotostep2.
4. IfFinish[i]==trueforalli,thenthesystemisinasafestate.
Thisalgorithmmayrequireanorderofm×n2operationstodeterminewhether
astateissafe.
8.6.3.2 Resource-RequestAlgorithm
Next, we describe the algorithm for determining whether requests can be
safely granted. Let Request be the request vector for thread T. If Request
i i i
[j] == k,thenthreadT wantskinstancesofresourcetypeR.Whenarequest
i j
forresourcesismadebythreadT,thefollowingactionsaretaken:
i336 Chapter8 Deadlocks
1. IfRequest ≤Need,gotostep2.Otherwise,raiseanerrorcondition,since
i i
thethreadhasexceededitsmaximumclaim.
2. If Request ≤ Available, go to step 3. Otherwise, T must wait, since the
i i
resourcesarenotavailable.
3. Have the system pretend to have allocated the requested resources to
threadT bymodifyingthestateasfollows:
i
Available=Available–Request
i
Allocation =Allocation +Request
i i i
Need =Need –Request
i i i
If the resulting resource-allocation state is safe, the transaction is com-
pleted,andthreadT isallocateditsresources.However,ifthenewstate
i
isunsafe,thenT mustwaitforRequest,andtheoldresource-allocation
i i
stateisrestored.
8.6.3.3 AnIllustrativeExample
To illustrate the use of the banker’s algorithm, consider a system with five
threads T through T and three resource types A, B, and C. Resource type A
0 4
has ten instances, resource typeB has five instances, and resourcetypeC has
seven instances. Suppose that the following snapshot represents the current
stateofthesystem:
Allocation Max Available
ABC ABC ABC
T 010 753 332
0
T 200 322
1
T 302 902
2
T 211 222
3
T 002 433
4
The content of the matrix Need is defined to be Max − Allocation and is as
follows:
Need
ABC
T 743
0
T 122
1
T 600
2
T 011
3
T 431
4
Weclaimthatthesystemiscurrentlyinasafestate.Indeed,thesequence
<T , T , T , T , T > satisfies the safety criteria. Suppose now that thread
1 3 4 2 0
T requests one additional instance of resource type A and two instances of
1
resource type C, so Request = (1,0,2). To decide whether this request can be
1
immediately granted, we first check that Request ≤ Available—that is, that
18.7 DeadlockDetection 337
(1,0,2) ≤ (3,3,2), which is true. We then pretend that this request has been
fulfilled,andwearriveatthefollowingnewstate:
Allocation Need Available
ABC ABC ABC
T 010 743 230
0
T 302 020
1
T 302 600
2
T 211 011
3
T 002 431
4
We must determine whether this new system state is safe. To do so, we
execute our safety algorithm and find that the sequence <T , T , T , T , T >
1 3 4 0 2
satisfiesthesafetyrequirement.Hence,wecanimmediatelygranttherequest
ofthreadT .
1
Youshouldbeabletosee,however,thatwhenthesystemisinthisstate,a
requestfor(3,3,0)byT cannotbegranted,sincetheresourcesarenotavailable.
4
Furthermore, a request for (0,2,0) by T cannot be granted, even though the
0
resourcesareavailable,sincetheresultingstateisunsafe.
We leave it as a programming exercise for students to implement the
banker’salgorithm.
8.7 Deadlock Detection
If a system does not employ either a deadlock-prevention or a deadlock-
avoidancealgorithm,thenadeadlocksituationmayoccur.Inthisenvironment,
thesystemmayprovide:
• Analgorithmthatexaminesthestateofthesystemtodeterminewhether
adeadlockhasoccurred
• Analgorithmtorecoverfromthedeadlock
Next, we discuss these two requirements as they pertain to systems with
only a single instance of each resource type, as well as to systems with sev-
eral instances of each resource type. At this point, however, we note that a
detection-and-recovery scheme requires overhead that includes not only the
run-time costs of maintaining the necessary information and executing the
detection algorithm but also the potential losses inherent in recovering from
adeadlock.
8.7.1 Single Instance of Each Resource Type
If all resources have only a single instance, then we can define a deadlock-
detectionalgorithmthatusesavariantoftheresource-allocationgraph,called
await-for graph.We obtain thisgraph fromthe resource-allocationgraphby
removingtheresourcenodesandcollapsingtheappropriateedges.
Moreprecisely,anedgefromT toT inawait-forgraphimpliesthatthread
i j
T iswaitingforthreadT toreleasearesourcethatT needs.AnedgeT →T
i j i i j338 Chapter8 Deadlocks
T
5
R R R
1 3 4
T
5
T T T
1 2 3
T T T
1 2 3
T
4
T
R R 4
2 5
(a) (b)
Figure8.11 (a)Resource-allocationgraph.(b)Correspondingwait-forgraph.
existsinawait-for graphifand only ifthecorresponding resource-allocation
graphcontainstwoedgesT →R andR →T forsomeresourceR .InFigure
i q q j q
8.11, we present a resource-allocation graph and the corresponding wait-for
graph.
Asbefore,adeadlockexistsinthesystemifandonlyifthewait-forgraph
contains acycle. To detectdeadlocks,the system needsto maintain the wait-
forgraphandperiodicallyinvokeanalgorithmthatsearchesforacycleinthe
graph. An algorithm to detect a cycle in a graph requires O(n2) operations,
wherenisthenumberofverticesinthegraph.
The BCC toolkit described in Section 2.10.4 provides a tool that can
detect potential deadlocks with Pthreads mutex locks in a user process
running on a Linux system. The BCC tool deadlock detector operates
by inserting probes which trace calls to the pthread mutex lock() and
pthread mutex unlock()functions.Whenthespecifiedprocessmakesacall
to either function, deadlock detector constructs a wait-for graph of mutex
locksinthatprocess,andreportsthepossibilityofdeadlockifitdetectsacycle
inthegraph.
8.7.2 Several Instances of a Resource Type
The wait-for graph scheme is not applicable to a resource-allocation system
with multiple instances of each resource type. We turn now to a deadlock-
detectionalgorithmthatisapplicabletosuchasystem.Thealgorithmemploys
several time-varying data structures that are similar to those used in the
banker’salgorithm(Section8.6.3):
• Available.Avectoroflengthmindicatesthenumberofavailableresources
ofeachtype.8.7 DeadlockDetection 339
DEADLOCKDETECTIONUSINGJAVATHREADDUMPS
Although Java does not provide explicit support for deadlock detection, a
thread dump can be used to analyze a running program to determine if
thereisadeadlock.Athreaddumpisausefuldebuggingtoolthatdisplaysa
snapshotofthestatesofallthreadsinaJavaapplication.Javathreaddumps
also show locking information, including which locks a blocked thread is
waitingtoacquire.Whenathreaddumpisgenerated,theJVMsearchesthe
wait-forgraphtodetectcycles,reportinganydeadlocksitdetects.Togenerate
athreaddumpofarunningapplication,fromthecommandlineenter:
Ctrl-L(UNIX,Linux,ormacOS)
Ctrl-Break(Windows)
Inthesource-codedownloadforthistext,weprovideaJavaexampleofthe
program shown in Figure 8.1 and describe how to generate a thread dump
thatreportsthedeadlockedJavathreads.
• Allocation.Ann×mmatrixdefinesthenumberofresourcesofeachtype
currentlyallocatedtoeachthread.
• Request. An n × m matrix indicates the current request of each thread.
If Request[i][j] equals k, then thread T is requesting k more instances of
i
resourcetypeR.
j
The ≤ relation between two vectors is defined as in Section 8.6.3. To sim-
plifynotation,weagaintreattherowsinthematricesAllocationandRequest
as vectors; we refer to them as Allocation and Request. The detection algo-
i i
rithm described here simply investigates every possible allocation sequence
forthethreadsthatremaintobecompleted.Comparethisalgorithmwiththe
banker’salgorithmofSection8.6.3.
1. LetWorkandFinishbevectorsoflengthmandn,respectively.Initialize
Work=Available.Fori=0,1,...,n–1,ifAllocation ≠0,thenFinish[i]=
i
false.Otherwise,Finish[i]=true.
2. Findanindexisuchthatboth
a. Finish[i]==false
b. Request ≤Work
i
Ifnosuchiexists,gotostep4.
3. Work=Work+Allocation
i
Finish[i]=true
Gotostep2.
4. IfFinish[i]==falseforsomei,0≤i<n,thenthesystemisinadeadlocked
state.Moreover,ifFinish[i]==false,thenthreadT isdeadlocked.
i
This algorithm requires an order of m × n2 operations to detect whether the
systemisinadeadlockedstate.340 Chapter8 Deadlocks
Youmaywonder why we reclaimthe resourcesof threadT (instep3)as
i
soon as we determine that Request ≤ Work (in step 2b). We know that T is
i i
currently not involved in a deadlock (since Request ≤ Work). Thus, we take
i
an optimistic attitude and assume that T will require no more resources to
i
complete its task; it will thus soon return all currently allocated resources to
the system. If our assumption is incorrect, a deadlock may occur later. That
deadlock will be detected the next time the deadlock-detection algorithm is
invoked.
To illustrate this algorithm, we consider a system with five threads T
0
through T and three resource types A, B, and C. Resource type A has seven
4
instances, resource type B has two instances, and resource type C has six
instances.Thefollowingsnapshotrepresentsthecurrentstateofthesystem:
Allocation Request Available
ABC ABC ABC
T 010 000 000
0
T 200 202
1
T 303 000
2
T 211 100
3
T 002 002
4
Weclaimthatthesystemisnotinadeadlockedstate.Indeed,ifweexecute
our algorithm, we will find that the sequence <T , T , T , T , T > results in
0 2 3 1 4
Finish[i]==trueforalli.
SupposenowthatthreadT makesoneadditionalrequestforaninstance
2
oftypeC.TheRequestmatrixismodifiedasfollows:
Request
ABC
T 000
0
T 202
1
T 001
2
T 100
3
T 002
4
Weclaimthatthesystemisnowdeadlocked.Althoughwecanreclaimthe
resourcesheldbythreadT ,thenumberofavailableresourcesisnotsufficient
0
to fulfill the requests of the other threads. Thus, a deadlock exists, consisting
ofthreadsT ,T ,T ,andT .
1 2 3 4
8.7.3 Detection-Algorithm Usage
Whenshouldweinvokethedetectionalgorithm?Theanswerdependsontwo
factors:
1. Howoftenisadeadlocklikelytooccur?
2. Howmanythreadswillbeaffectedbydeadlockwhenithappens?8.8 RecoveryfromDeadlock 341
MANAGINGDEADLOCKINDATABASES
Database systems provide a useful illustration of how both open-source
and commercial software manage deadlock. Updates to a database may be
performed as transactions, and to ensure data integrity, locks are typically
used. A transaction may involve several locks, so it comes as no surprise
that deadlocks are possible in a database with multiple concurrenttransac-
tions. To manage deadlock, most transactional database systems include a
deadlockdetectionandrecoverymechanism.Thedatabaseserverwillperi-
odically search for cycles in the wait-for graph to detect deadlock among a
set of transactions. When deadlock is detected, a victim is selected and the
transactionisabortedandrolledback,releasingthelocksheldbythevictim
transactionandfreeingtheremainingtransactionsfromdeadlock.Oncethe
remaining transactions have resumed, the aborted transaction is reissued.
Choiceofavictimtransactiondependsonthedatabasesystem;forinstance,
MySQL attempts to select transactions that minimize the number of rows
beinginserted,updated,ordeleted.
Ifdeadlocksoccurfrequently,thenthedetectionalgorithmshouldbeinvoked
frequently. Resources allocated to deadlocked threads will be idle until the
deadlock can be broken. In addition, the number of threads involved in the
deadlockcyclemaygrow.
Deadlocks occur only when some thread makes a request that cannot be
granted immediately. This request may be the final request that completes a
chain of waiting threads. In the extreme, then, we can invoke the deadlock-
detection algorithm every time a request for allocation cannot be granted
immediately.Inthiscase,wecanidentifynotonlythedeadlockedsetofthreads
butalsothespecificthreadthat “caused”thedeadlock.(Inreality,eachofthe
deadlockedthreadsisalinkinthecycleintheresourcegraph,soallofthem,
jointly, caused the deadlock.) If there are many different resource types, one
request may create many cycles in the resource graph, each cycle completed
bythemostrecentrequestand“caused”bytheoneidentifiablethread.
Of course, invoking the deadlock-detection algorithm for every resource
request will incur considerable overhead in computation time. Aless expen-
sive alternative is simply to invoke the algorithm at defined intervals—for
example,once perhour or wheneverCPU utilizationdrops below40percent.
(AdeadlockeventuallycripplessystemthroughputandcausesCPUutilization
to drop.) If the detection algorithm is invoked at arbitrary points in time, the
resourcegraphmaycontainmanycycles.Inthiscase,wegenerallycannottell
whichofthemanydeadlockedthreads“caused”thedeadlock.
8.8 Recovery from Deadlock
When a detection algorithm determines that a deadlock exists, several alter-
nativesareavailable.Onepossibilityistoinformtheoperatorthatadeadlock
hasoccurredandtolettheoperatordealwiththedeadlockmanually.Another
possibilityistoletthesystemrecoverfromthedeadlockautomatically.There342 Chapter8 Deadlocks
are two options for breaking a deadlock. One is simply to abort one or more
threadstobreakthecircularwait.Theotheristopreemptsomeresourcesfrom
oneormoreofthedeadlockedthreads.
8.8.1 Process and Thread Termination
To eliminate deadlocks by aborting a process or thread, we use one of two
methods. In both methods, the system reclaims all resources allocated to the
terminatedprocesses.
• Abortalldeadlockedprocesses.Thismethodclearlywillbreakthedead-
lockcycle,butatgreatexpense.Thedeadlockedprocessesmayhavecom-
putedfor along time,and the resultsofthese partialcomputations must
bediscardedandprobablywillhavetoberecomputedlater.
• Abortoneprocessatatimeuntilthedeadlockcycleiseliminated.This
methodincursconsiderableoverhead,sinceaftereachprocessisaborted,a
deadlock-detectionalgorithmmustbeinvokedtodeterminewhetherany
processesarestilldeadlocked.
Aborting a process may not be easy. If the process was in the midst of
updatingafile,terminatingitmayleavethatfileinanincorrectstate.Similarly,
iftheprocesswasinthemidstofupdatingshareddatawhileholdingamutex
lock,thesystemmustrestorethestatusofthelockasbeingavailable,although
noguaranteescanbemaderegardingtheintegrityoftheshareddata.
Ifthe partialterminationmethodisused,thenwemust determinewhich
deadlockedprocess(orprocesses)shouldbeterminated.Thisdeterminationis
apolicydecision,similartoCPU-schedulingdecisions.Thequestionisbasically
an economic one; we should abort those processes whose termination will
incurtheminimumcost.Unfortunately,thetermminimumcostisnotaprecise
one.Manyfactorsmayaffectwhichprocessischosen,including:
1. Whatthepriorityoftheprocessis
2. How long the process has computed and how much longer the process
willcomputebeforecompletingitsdesignatedtask
3. Howmanyandwhattypesofresourcestheprocesshasused(forexam-
ple,whethertheresourcesaresimpletopreempt)
4. Howmanymoreresourcestheprocessneedsinordertocomplete
5. Howmanyprocesseswillneedtobeterminated
8.8.2 Resource Preemption
To eliminate deadlocks using resource preemption, we successively preempt
someresourcesfromprocessesandgivetheseresourcestootherprocessesuntil
thedeadlockcycleisbroken.
Ifpreemptionisrequiredtodealwithdeadlocks,thenthreeissuesneedto
beaddressed:8.9 Summary 343
1. Selecting a victim. Which resources and which processes are to be pre-
empted?Asinprocesstermination,wemustdeterminetheorderofpre-
emption to minimize cost. Cost factors may include such parameters as
thenumberofresourcesadeadlockedprocessisholdingandtheamount
oftimetheprocesshasthusfarconsumed.
2. Rollback.Ifwepreemptaresourcefromaprocess,whatshouldbedone
withthatprocess?Clearly,itcannotcontinuewithitsnormalexecution;it
ismissingsomeneededresource.Wemustrollbacktheprocesstosome
safestateandrestartitfromthatstate.
Since, in general, it is difficult to determine what a safe state is, the
simplest solution is a total rollback: abort the process and then restart
it. Although it is more effective to roll back the process only as far as
necessarytobreakthedeadlock,thismethodrequiresthesystemtokeep
moreinformationaboutthestateofallrunningprocesses.
3. Starvation.Howdoweensurethatstarvationwillnotoccur?Thatis,how
canweguaranteethat resourceswillnot alwaysbepreemptedfromthe
sameprocess?
Inasystemwherevictimselectionisbasedprimarilyoncostfactors,
it may happen that the same process is always picked as a victim. As
a result, this process never completes its designated task, a starvation
situationanypracticalsystemmustaddress.Clearly,wemustensurethat
aprocesscanbepickedasavictimonlya(small)finitenumberoftimes.
The most common solution is to include the number of rollbacks in the
costfactor.
8.9 Summary
• Deadlock occurs in a set of processes when every process in the set is
waitingforaneventthatcanonlybecausedbyanotherprocessintheset.
• Therearefournecessaryconditionsfordeadlock:(1)mutualexclusion,(2)
hold and wait, (3) no preemption,and (4) circular wait. Deadlock is only
possiblewhenallfourconditionsarepresent.
• Deadlockscanbemodeledwithresource-allocationgraphs,whereacycle
indicatesdeadlock.
• Deadlocks can be prevented by ensuring that one of the four necessary
conditions for deadlock cannot occur. Of the four necessary conditions,
eliminatingthecircularwaitistheonlypracticalapproach.
• Deadlock can be avoided by using the banker’s algorithm, which does
notgrantresourcesifdoingsowouldleadthesystemintoanunsafestate
wheredeadlockwouldbepossible.
• Adeadlock-detectionalgorithmcanevaluateprocessesandresourcesona
runningsystemtodetermineifasetofprocessesisinadeadlockedstate.
• Ifdeadlockdoesoccur,asystemcanattempttorecoverfromthedeadlock
byeitherabortingoneoftheprocessesinthecircularwaitorpreempting
resourcesthathavebeenassignedtoadeadlockedprocess.344 Chapter8 Deadlocks
Practice Exercises
8.1 List three examples of deadlocks that are not related to a computer-
systemenvironment.
8.2 Supposethat asystem isin anunsafe state.Showthat itis possible for
the threads to complete their execution without entering a deadlocked
state.
8.3 Considerthefollowingsnapshotofasystem:
Allocation Max Available
ABCD ABCD ABCD
T 0012 0012 1520
0
T 1000 1750
1
T 1354 2356
2
T 0632 0652
3
T 0014 0656
4
Answerthefollowingquestionsusingthebanker’salgorithm:
a. WhatisthecontentofthematrixNeed?
b. Isthesysteminasafestate?
c. IfarequestfromthreadT arrivesfor (0,4,2,0),can therequestbe
1
grantedimmediately?
8.4 A possible method for preventing deadlocks is to have a single,
higher-orderresourcethatmustberequestedbeforeanyotherresource.
For example, if multiple threads attempt to access the synchronization
objectsA···E,deadlockispossible.(Suchsynchronizationobjectsmay
includemutexes,semaphores,conditionvariables,andthelike.)Wecan
preventdeadlockby addingasixthobject F.Wheneverathreadwants
to acquire the synchronization lock for any object A ···E, it must first
acquire the lock for object F. This solution is known as containment:
the locks for objects A ··· E are contained within the lock for object F.
Comparethisschemewiththecircular-waitschemeofSection8.5.4.
8.5 Prove that the safety algorithm presented in Section 8.6.3 requires an
orderofm×n2 operations.
8.6 Consideracomputersystemthatruns5,000jobspermonthandhasno
deadlock-prevention or deadlock-avoidance scheme. Deadlocks occur
about twice per month, and the operator must terminate and rerun
abouttenjobsperdeadlock.Eachjobisworthabouttwodollars(inCPU
time),andthejobsterminatedtendtobeabouthalfdonewhentheyare
aborted.
A systems programmer has estimated that a deadlock-avoidance
algorithm(likethebanker’salgorithm)couldbeinstalledinthesystem
with an increase of about 10 percent in the average execution time perPracticeExercises 345
job. Since the machine currently has 30 percent idle time, all 5,000 jobs
permonthcouldstillberun,althoughturnaroundtimewouldincrease
byabout20percentonaverage.
a. What are the arguments for installing the deadlock-avoidance
algorithm?
b. Whataretheargumentsagainstinstallingthedeadlock-avoidance
algorithm?
8.7 Canasystemdetectthatsomeofitsthreadsarestarving?Ifyouanswer
“yes,” explain how it can. If you answer “no,” explain how the system
candealwiththestarvationproblem.
8.8 Consider the following resource-allocation policy. Requests for and
releases of resources are allowed at any time. If a request for resources
cannotbesatisfiedbecausetheresourcesarenotavailable,thenwecheck
any threads that are blocked waiting for resources. If a blocked thread
has the desired resources, then these resources are taken away from it
andaregiventotherequestingthread.Thevectorofresourcesforwhich
the blocked thread is waiting is increased to include the resources that
weretakenaway.
Forexample,asystemhasthreeresourcetypes,andthevectorAvail-
able is initialized to (4,2,2). If thread T asks for (2,2,1), it gets them. If
0
T asks for (1,0,1), it gets them. Then, if T asks for (0,0,1), it is blocked
1 0
(resource not available). If T now asks for (2,0,0), it gets the available
2
one(1,0,0),aswellasonethatwasallocatedtoT (sinceT isblocked).
0 0
T ’sAllocationvectorgoesdownto(1,2,1),anditsNeedvectorgoesup
0
to(1,0,1).
a. Candeadlockoccur?Ifyouanswer“yes,”giveanexample.Ifyou
answer“no,”specifywhichnecessaryconditioncannotoccur.
b. Canindefiniteblockingoccur?Explainyouranswer.
8.9 Considerthefollowingsnapshotofasystem:
Allocation Max
ABCD ABCD
T 3014 5117
0
T 2210 3211
1
T 3121 3321
2
T 0510 4612
3
T 4212 6325
4
Using the banker’s algorithm, determine whether or not each of the
followingstatesisunsafe.Ifthestateissafe,illustratetheorderinwhich
thethreadsmaycomplete.Otherwise,illustratewhythestateisunsafe.
a. Available=(0,3,0,1)
b. Available=(1,0,0,2)346 Chapter8 Deadlocks
8.10 Supposethatyouhavecodedthedeadlock-avoidancesafetyalgorithm
thatdeterminesifasystemisinasafestateornot,andnowhavebeen
askedtoimplementthedeadlock-detectionalgorithm.Canyoudosoby
simplyusingthesafetyalgorithmcodeandredefiningMax =Waiting
i i
+ Allocation, where Waiting is a vector specifying the resources for
i i
which thread i is waiting and Allocation is as defined in Section 8.6?
i
Explainyouranswer.
8.11 Is it possible to have a deadlock involving only one single-threaded
process?Explainyouranswer.
Further Reading
Most research involving deadlock was conducted many years ago. [Dijkstra
(1965)] was one of the first and most influential contributors in the deadlock
area.
Details of how the MySQL database manages deadlock can be found at
http://dev.mysql.com/.
Detailsonthelockdeptoolcan befound athttps://www.kernel.org/doc/
Documentation/locking/lockdep-design.txt.
Bibliography
[Dijkstra(1965)] E. W.Dijkstra,“CooperatingSequentialProcesses”,Technical
report,TechnologicalUniversity,Eindhoven,theNetherlands(1965).Chapter 8 Exercises
8.12 ConsiderthetrafficdeadlockdepictedinFigure8.12.
a. Showthatthefournecessaryconditionsfordeadlockholdinthis
example.
b. Stateasimpleruleforavoidingdeadlocksinthissystem.
8.13 Draw the resource-allocation graph that illustrates deadlock from the
programexampleshowninFigure8.1inSection8.2.
8.14 In Section 6.8.1, we described a potential deadlock scenario involv-
ing processes P and P and semaphores S and Q. Draw the resource-
0 1
allocation graphthat illustratesdeadlockunder the scenario presented
inthatsection.
8.15 Assumethatamultithreadedapplicationusesonlyreader–writerlocks
for synchronization. Applying the four necessary conditions for dead-
lock,isdeadlockstillpossibleifmultiplereader–writerlocksareused?
8.16 TheprogramexampleshowninFigure8.1doesn’talwaysleadtodead-
lock. Describe what role the CPU scheduler plays and how it can con-
tributetodeadlockinthisprogram.
8.17 InSection8.5.4,wedescribedasituationinwhichwepreventdeadlock
by ensuring that all locks are acquired in a certain order. However, we
also point out that deadlock is possible in this situation if two threads
simultaneouslyinvokethe transaction()function. Fixthe transac-
tion()functiontopreventdeadlocks.
•
•
•
•
•
•
• • •
• • •
EX-27
Figure8.11 TrafficdeadlockforExercise8.12.Exercises EX-28
8.18 Which of the six resource-allocation graphs shown in Figure 8.12 illus-
trate deadlock? For those situations that are deadlocked, provide the
cycleofthreadsandresources.Wherethereisnotadeadlocksituation,
illustratetheorderinwhichthethreadsmaycompleteexecution.
8.19 Comparethecircular-waitschemewiththevariousdeadlock-avoidance
schemes (like the banker’s algorithm) with respect to the following
issues:
a. Runtimeoverhead
b. Systemthroughput
8.20 In a real computer system, neither the resources available nor the
demands of threads for resources are consistent over long periods
(months). Resources break or are replaced, new processes and threads
come and go, and new resources are bought and added to the system.
If deadlock is controlled by the banker’s algorithm, which of the
(a) (b)
T T
1 3
R R
1 2
• •
R R R
1 2 3
••• ••• •••
T 1 T 2 T 3
T
2
(c) (d)
R 1 R 2 T 1 T 2
•• ••
R 1 R 2
•• ••
T T T
1 2 3
T T
3 4
(e) (f )
T 1 T 2 T 1 T 2
•R •1 •R • 2 R •1 •R •2 •R • 3
T 3 T 4 T 3 T 4
Figure8.12 Resource-allocationgraphsforExercise8.18.EX-29
following changes can be made safely (without introducing the
possibilityofdeadlock),andunderwhatcircumstances?
a. IncreaseAvailable(newresourcesadded).
b. DecreaseAvailable(resourcepermanentlyremovedfromsystem).
c. Increase Max for one thread (the thread needs or wants more
resourcesthanallowed).
d. DecreaseMaxforonethread(thethreaddecidesitdoesnot need
thatmanyresources).
e. Increasethenumberofthreads.
f. Decreasethenumberofthreads.
8.21 Considerthefollowingsnapshotofasystem:
Allocation Max
ABCD ABCD
T 2106 6327
0
T 3313 5415
1
T 2312 6614
2
T 1234 4345
3
T 3030 7261
4
WhatarethecontentsoftheNeedmatrix?
8.22 Consider a system consisting of four resources of the same type that
aresharedbythreethreads,eachofwhichneedsatmosttworesources.
Showthatthesystemisdeadlockfree.
8.23 Consider a system consisting of m resources of the same type being
shared by n threads. Athread can request or release only one resource
at a time. Show that the system is deadlock free if the following two
conditionshold:
a. Themaximumneedofeachthreadisbetweenoneresourceandm
resources.
b. Thesumofallmaximumneedsislessthanm+n.
8.24 Consider the version of the dining-philosophers problem in which the
chopsticks are placed at the center of the table and any two of them
can be used by a philosopher. Assume that requests for chopsticks are
made one at a time. Describe a simple rule for determining whether a
particular request can be satisfied without causing deadlock given the
currentallocationofchopstickstophilosophers.
8.25 Consideragain the setting in the preceding exercise.Assume now that
eachphilosopherrequiresthreechopstickstoeat.Resourcerequestsare
still issued one at a time. Describe some simple rules for determining
whetheraparticularrequestcanbesatisfiedwithout causing deadlock
giventhecurrentallocationofchopstickstophilosophers.Exercises EX-30
8.26 We can obtain the banker’s algorithm for a single resource type from
the general banker’s algorithm simply by reducing the dimensionality
ofthevariousarraysby1.
Show through an example that we cannot implement the multiple-
resource-type banker’s scheme by applying the single-resource-type
schemetoeachresourcetypeindividually.
8.27 Considerthefollowingsnapshotofasystem:
Allocation Max
ABCD ABCD
T 1202 4316
0
T 0112 2424
1
T 1240 3651
2
T 1201 2623
3
T 1001 3112
4
Using the banker’s algorithm, determine whether or not each of the
followingstatesisunsafe.Ifthestateissafe,illustratetheorderinwhich
thethreadsmaycomplete.Otherwise,illustratewhythestateisunsafe.
a. Available=(2,2,2,3)
b. Available=(4,4,1,1)
c. Available=(3,0,1,4)
d. Available=(1,5,2,2)
8.28 Considerthefollowingsnapshotofasystem:
Allocation Max Available
ABCD ABCD ABCD
T 3141 6473 2224
0
T 2102 4232
1
T 2413 2533
2
T 4110 6332
3
T 2221 5675
4
Answerthefollowingquestionsusingthebanker’salgorithm:
a. Illustrate that the system is in a safe state by demonstrating an
orderinwhichthethreadsmaycomplete.
b. IfarequestfromthreadT arrivesfor(2,2,2,4),cantherequestbe
4
grantedimmediately?
c. IfarequestfromthreadT arrivesfor(0,1,1,0),cantherequestbe
2
grantedimmediately?
d. IfarequestfromthreadT arrivesfor(2,2,1,2),cantherequestbe
3
grantedimmediately?EX-31
8.29 Whatistheoptimisticassumptionmadeinthedeadlock-detectionalgo-
rithm?Howcanthisassumptionbeviolated?
8.30 Asingle-lane bridge connects the two Vermont villages of North Tun-
bridgeandSouthTunbridge.Farmersinthetwovillagesusethisbridge
todelivertheirproducetotheneighboringtown.Thebridgecanbecome
deadlockedifanorthboundandasouthboundfarmergetonthebridge
at the same time. (Vermont farmers are stubborn and are unable to
back up.) Using semaphores and/or mutex locks, design an algorithm
in pseudocode that prevents deadlock. Initially, do not be concerned
about starvation (the situation in which northbound farmers prevent
southboundfarmersfromusingthebridge,orviceversa).
8.31 ModifyyoursolutiontoExercise8.30sothatitisstarvation-free.P-45 Chapter8 Deadlocks
Programming Problems
8.32 Implementyour solution toExercise8.30using POSIX synchronization.
Inparticular,representnorthboundandsouthboundfarmersasseparate
threads.Onceafarmerisonthebridge,theassociatedthreadwillsleep
for a random period of time, representing traveling across the bridge.
Designyourprogramsothatyoucancreateseveralthreadsrepresenting
thenorthboundandsouthboundfarmers.
8.33 InFigure8.7,weillustrateatransaction()functionthatdynamically
acquires locks. In the text, we describe how this function presents
difficulties for acquiring locks in a way that avoids deadlock. Using
the Java implementation of transaction() that is provided in
the source-code download for this text, modify it using the Sys-
tem.identityHashCode() method so that the locks are acquired in
order.
Programming Projects
Banker’s Algorithm
Forthisproject,youwillwriteaprogramthat implementsthebanker’s algo-
rithmdiscussedinSection8.6.3.Customersrequestandreleaseresourcesfrom
the bank. The banker will grant a request only if it leaves the system in a
safe state. Arequest that leaves the system in an unsafe state will be denied.
AlthoughthecodeexamplesthatdescribethisprojectareillustratedinC,you
mayalsodevelopasolutionusingJava.
TheBanker
Thebanker willconsiderrequestsfromncustomersfor mresourcestypes,as
outlinedinSection8.6.3.Thebankerwillkeeptrackoftheresourcesusingthe
followingdatastructures:
#define NUMBER OF CUSTOMERS 5
#define NUMBER OF RESOURCES 4
/* the available amount of each resource */
int available[NUMBER OF RESOURCES];
/*the maximum demand of each customer */
int maximum[NUMBER OF CUSTOMERS][NUMBER OF RESOURCES];
/* the amount currently allocated to each customer */
int allocation[NUMBER OF CUSTOMERS][NUMBER OF RESOURCES];
/* the remaining need of each customer */
int need[NUMBER OF CUSTOMERS][NUMBER OF RESOURCES];ProgrammingProjects P-46
The banker will grant a request if it satisfies the safety algorithm outlined in
Section8.6.3.1.Ifarequestdoesnotleavethesysteminasafestate,thebanker
willdenyit.Functionprototypesforrequestingandreleasingresourcesareas
follows:
int request resources(int customer num, int request[]);
void release resources(int customer num, int release[]);
The request resources() function should return 0 if successful and –1 if
unsuccessful.
Testing YourImplementation
Design a program that allows the user to interactively enter a request for
resources, to release resources, or to output the values of the different data
structures (available, maximum, allocation, and need) used with the
banker’salgorithm.
You should invoke your program by passing the number of resources of
eachtypeonthecommandline.Forexample,iftherewerefourresourcetypes,
with ten instances of the first type,five of the second type, sevenof the third
type,andeightofthefourthtype,youwouldinvokeyourprogramasfollows:
./a.out 10 5 7 8
Theavailablearraywouldbeinitializedtothesevalues.
Yourprogramwillinitiallyreadinafilecontainingthemaximumnumber
ofrequestsforeachcustomer.Forexample,iftherearefivecustomersandfour
resources,theinputfilewouldappearasfollows:
6,4,7,3
4,2,3,2
2,5,3,3
6,3,3,2
5,6,7,5
where each line in the input file represents the maximum request of each
resourcetypeforeachcustomer.Yourprogramwillinitializethemaximumarray
tothesevalues.
Your program will then have the user enter commands responding to a
requestofresources,areleaseofresources,orthecurrentvaluesofthedifferent
datastructures.Usethecommand‘RQ’forrequestingresources,‘RL’forreleas-
ingresources,and‘*’tooutputthevaluesofthedifferentdatastructures.For
example, if customer 0 were to request the resources (3,1,2,1), the following
commandwouldbeentered:
RQ 0 3 1 2 1
Your program would then output whether the request would be satisfied or
deniedusingthesafetyalgorithmoutlinedinSection8.6.3.1.P-47 Chapter8 Deadlocks
Similarly,ifcustomer4weretoreleasetheresources(1,2,3,1),theuserwould
enterthefollowingcommand:
RL 4 1 2 3 1
Finally,ifthecommand‘*’isentered,yourprogramwouldoutputthevalues
oftheavailable,maximum,allocation,andneedarrays.Part Four
Memory
Management
Themainpurposeofacomputersystemistoexecuteprograms.These
programs, together with the data they access, must be at least partially
inmainmemoryduringexecution.
Modern computer systems maintain several processes in memory
during system execution. Many memory-management schemes exist,
reflecting various approaches, and the effectiveness of each algorithm
varieswiththesituation.Selectionofamemory-managementschemefor
asystemdependsonmanyfactors,especiallyonthesystem’shardware
design.Mostalgorithmsrequiresomeformofhardwaresupport.9
CHAPTER
Main Memory
InChapter5,weshowedhowtheCPUcanbesharedbyasetofprocesses.As
aresultofCPUscheduling,wecanimproveboththeutilizationoftheCPUand
the speed of the computer’s response to its users. To realize this increase in
performance,however,wemustkeepmanyprocessesinmemory—thatis,we
mustsharememory.
Inthischapter,wediscussvariouswaystomanagememory.Thememory-
management algorithms vary from a primitive bare-machine approach to a
strategy that uses paging. Each approach has its own advantages and disad-
vantages. Selection of a memory-management method for a specific system
depends on many factors, especially on the hardware design of the system.
As we shall see, most algorithms require hardware support, leading many
systems to have closely integrated hardware and operating-system memory
management.
CHAPTER OBJECTIVES
• Explain the difference between a logical and a physical address and the
roleofthememorymanagementunit(MMU)intranslatingaddresses.
• Applyfirst-,best-,andworst-fitstrategiesforallocatingmemorycontigu-
ously.
• Explainthedistinctionbetweeninternalandexternalfragmentation.
• Translatelogicaltophysicaladdressesinapagingsystemthatincludesa
translationlook-asidebuffer(TLB).
• Describehierarchicalpaging,hashedpaging,andinvertedpagetables.
• DescribeaddresstranslationforIA-32,x86-64,andARMv8architectures.
9.1 Background
As we saw in Chapter 1, memory is central to the operation of a modern
computersystem.Memoryconsistsofalargearrayofbytes,eachwithitsown
address.TheCPUfetchesinstructionsfrommemoryaccordingtothevalueof
349350 Chapter9 MainMemory
the program counter. These instructions may cause additional loading from
andstoringtospecificmemoryaddresses.
Atypicalinstruction-executioncycle,forexample,firstfetchesaninstruc-
tion from memory. The instruction is then decoded and may cause operands
to be fetched from memory. After the instruction has been executed on the
operands,resultsmaybestoredbackinmemory.Thememoryunitseesonlya
streamofmemoryaddresses;itdoesnotknowhowtheyaregenerated(bythe
instructioncounter,indexing,indirection,literaladdresses,andsoon)orwhat
theyarefor(instructionsordata).Accordingly,wecanignorehowaprogram
generatesamemoryaddress.Weareinterestedonlyinthesequenceofmemory
addressesgeneratedbytherunningprogram.
We begin our discussion by covering several issues that are pertinent to
managingmemory:basichardware,thebindingofsymbolic(orvirtual)mem-
oryaddressestoactualphysicaladdresses,andthedistinctionbetweenlogical
andphysicaladdresses.Weconcludethesectionwithadiscussionofdynamic
linkingandsharedlibraries.
9.1.1 Basic Hardware
Main memory and the registers built into each processing core are the only
general-purpose storage that the CPU can access directly. There are machine
instructionsthattakememoryaddressesasarguments,butnonethattakedisk
addresses. Therefore, any instructions in execution, and any data being used
bytheinstructions,mustbeinoneofthesedirect-accessstoragedevices.Ifthe
dataarenotinmemory,theymustbemovedtherebeforetheCPUcanoperate
onthem.
Registers that are built into each CPU core are generallyaccessible within
one cycle of the CPU clock. Some CPU cores can decode instructions and per-
form simple operations on register contents at the rate of one or more opera-
tionsperclocktick.Thesamecannotbesaidofmainmemory,whichisaccessed
viaatransactiononthe memorybus.Completingamemoryaccess maytake
many cycles of the CPU clock. In such cases, the processor normally needs to
stall,sinceitdoesnothavethedatarequiredtocompletetheinstructionthatit
isexecuting.Thissituationisintolerablebecauseofthefrequencyofmemory
accesses.TheremedyistoaddfastmemorybetweentheCPUandmainmem-
ory, typically on the CPU chip for fast access. Such a cache was described in
Section1.5.5.TomanageacachebuiltintotheCPU,thehardwareautomatically
speedsupmemoryaccesswithoutanyoperating-systemcontrol.(Recallfrom
Section5.5.2thatduringamemorystall,amultithreadedcorecanswitchfrom
thestalledhardwarethreadtoanotherhardwarethread.)
Not only are we concerned with the relative speed of accessing physi-
cal memory, but we also must ensure correct operation. For proper system
operation, we must protect the operating system from access by user pro-
cesses,aswellasprotectuserprocessesfromoneanother.Thisprotectionmust
be provided by the hardware, because the operating system doesn’t usually
intervenebetweentheCPUand itsmemoryaccesses(because oftheresulting
performancepenalty).Hardwareimplementsthisproductioninseveraldiffer-
ent ways, as we show throughout the chapter. Here, we outline one possible
implementation.9.1 Background 351
1024000
operating
system
880000
process
420940 base + limit
process
300040
base
process
256000
0
Figure9.1 Abaseandalimitregisterdefinealogicaladdressspace.
Wefirstneedtomakesurethateachprocesshasaseparatememoryspace.
Separateper-processmemoryspaceprotectstheprocessesfromeachotherand
isfundamentaltohavingmultipleprocessesloadedinmemoryforconcurrent
execution. To separate memory spaces, we need the ability to determine the
range of legal addresses that the process may access and to ensure that the
process can access only these legal addresses.We can provide this protection
by using two registers,usually a base and alimit, as illustratedin Figure 9.1.
Thebaseregisterholdsthesmallestlegalphysicalmemoryaddress;thelimit
register specifies the sizeof the range.For example,ifthe base registerholds
300040andthelimitregisteris120900,thentheprogramcanlegallyaccessall
addressesfrom300040through420939(inclusive).
ProtectionofmemoryspaceisaccomplishedbyhavingtheCPUhardware
compareeveryaddressgeneratedinusermodewiththeregisters.Anyattempt
by a program executing in user mode to access operating-system memory or
otherusers’memoryresultsinatraptotheoperatingsystem,whichtreatsthe
attemptasafatalerror(Figure9.2).Thisschemepreventsauserprogramfrom
(accidentally or deliberately) modifying the code or data structures of either
theoperatingsystemorotherusers.
The base and limit registers can be loaded only by the operating system,
which uses a special privileged instruction. Since privileged instructions can
beexecutedonlyinkernelmode,andsinceonlytheoperatingsystemexecutes
inkernelmode,onlytheoperatingsystemcanloadthebaseandlimitregisters.
This scheme allows the operating system to change the value of the registers
butpreventsuserprogramsfromchangingtheregisters’contents.
The operating system, executing in kernel mode, is given unrestricted
access to both operating-system memory and users’ memory. This provision
allows the operating system to load users’ programs into users’ memory, to
dump out those programs in case of errors, to access and modify parameters
of system calls, to perform I/O to and from user memory, and to provide
many other services. Consider, for example, that an operating system for a352 Chapter9 MainMemory
base base + limit
address yes yes
CPU ≥ <
no no
trap to operating system
illegal addressing error memory
Figure9.2 Hardwareaddressprotectionwithbaseandlimitregisters.
multiprocessingsystemmustexecutecontextswitches,storingthestateofone
processfromtheregistersintomainmemorybeforeloadingthenextprocess’s
contextfrommainmemoryintotheregisters.
9.1.2 Address Binding
Usually, a program resides on a disk as a binary executable file. To run, the
program must be brought into memory and placed within the context of a
process (as described in Section 2.5), where it becomes eligible for execution
onanavailableCPU.Astheprocessexecutes,itaccessesinstructionsanddata
frommemory.Eventually,theprocessterminates,anditsmemoryisreclaimed
forusebyotherprocesses.
Most systems allow a user process to reside in any part of the physical
memory.Thus,althoughtheaddressspaceofthecomputermaystartat00000,
thefirstaddressoftheuserprocessneednotbe00000.Youwillseelaterhow
theoperatingsystemactuallyplacesaprocessinphysicalmemory.
Inmostcases,auserprogramgoesthroughseveralsteps—someofwhich
maybeoptional—beforebeingexecuted(Figure9.3).Addressesmayberepre-
sentedindifferentwaysduringthesesteps.Addressesinthesourceprogram
aregenerallysymbolic(suchasthevariablecount).Acompilertypicallybinds
thesesymbolicaddressestorelocatableaddresses(suchas“14bytesfromthe
beginningofthismodule”).Thelinkerorloader(seeSection2.5)inturnbinds
the relocatableaddressestoabsolute addresses(such as 74014). Eachbinding
isamappingfromoneaddressspacetoanother.
Classically,thebindingofinstructionsanddatatomemoryaddressescan
bedoneatanystepalongtheway:
• Compiletime.Ifyouknowatcompiletimewheretheprocesswillresidein
memory,thenabsolutecodecanbegenerated.Forexample,ifyouknow
that a user process will reside starting at location R, then the generated
compiler code will start at that location and extend up from there. If, at
somelatertime,thestartinglocationchanges,thenitwillbenecessaryto
recompilethiscode.9.1 Background 353
source
program
compiler compile
time
object
file
other
object
files
linker
load
executable time
file
loader
dynamically
linked
libraries
execution
program
time
in memory
(run time)
Figure9.3 Multistepprocessingofauserprogram.
• Loadtime.Ifitisnotknownatcompiletimewheretheprocesswillreside
inmemory,thenthecompilermustgeneraterelocatablecode.Inthiscase,
finalbindingisdelayeduntilloadtime.Ifthestartingaddresschanges,we
needonlyreloadtheusercodetoincorporatethischangedvalue.
• Executiontime.Iftheprocesscanbemovedduringitsexecutionfromone
memorysegmenttoanother,thenbindingmustbedelayeduntilruntime.
Special hardware must be available for this scheme to work, as will be
discussedinSection9.1.3.Mostoperatingsystemsusethismethod.
Amajorportionofthischapterisdevotedtoshowinghowthesevariousbind-
ings can be implemented effectively in a computer system and to discussing
appropriatehardwaresupport.
9.1.3 Logical Versus Physical Address Space
AnaddressgeneratedbytheCPUiscommonlyreferredtoasalogicaladdress,
whereas an address seen by the memory unit—that is, the one loaded into354 Chapter9 MainMemory
logical physical
address address
physical
CPU MMU memory
Figure9.4 Memorymanagementunit(MMU).
the memory-address register of the memory—is commonly referred to as a
physicaladdress.
Bindingaddressesateithercompileorloadtimegeneratesidenticallogical
andphysicaladdresses.However,theexecution-timeaddress-bindingscheme
resultsindifferinglogicalandphysicaladdresses.Inthiscase,weusuallyrefer
tothelogicaladdressasavirtualaddress.Weuselogicaladdressandvirtual
addressinterchangeablyinthistext.Thesetofalllogicaladdressesgenerated
by a program is a logical address space. The set of all physical addresses
correspondingtotheselogicaladdressesisaphysicaladdressspace.Thus,in
the execution-time address-binding scheme, the logical and physical address
spacesdiffer.
The run-time mapping from virtual to physical addresses is done by a
hardware device called the memory-management unit (MMU) (Figure 9.4).
Wecanchoosefrommanydifferentmethodstoaccomplishsuchmapping,as
wediscussinSection9.2throughSection9.3.Forthetimebeing,weillustrate
this mapping with asimpleMMU scheme that is ageneralizationof the base-
register scheme described in Section 9.1.1. The base register is now called
a relocation register. The value in the relocation register is added to every
addressgeneratedbyauserprocessatthetimetheaddressissenttomemory
(see Figure 9.5). For example, if the base is at 14000, then an attempt by the
usertoaddresslocation0isdynamicallyrelocatedtolocation14000;anaccess
tolocation346ismappedtolocation14346.
Theuserprogramneveraccessestherealphysicaladdresses.Theprogram
cancreateapointertolocation346,storeitinmemory,manipulateit,andcom-
pareitwithotheraddresses—allasthenumber346.Onlywhenitisusedasa
memoryaddress(inanindirectloadorstore,perhaps)isitrelocatedrelativeto
thebaseregister.Theuserprogramdealswithlogicaladdresses.Thememory-
mapping hardware converts logical addresses into physical addresses. This
formofexecution-timebindingwasdiscussedinSection9.1.2.Thefinalloca-
tion of a referenced memory address is not determined until the reference is
made.
We now have two different types of addresses: logical addresses (in the
range0tomax)andphysicaladdresses(intherangeR+0toR+maxforabase
value R). The user program generates only logical addresses and thinks that
the process runs in memory locations from 0 to max. However, these logical
addresses must be mapped to physical addresses before they are used. The9.1 Background 355
relocation
register
14000
logical physical
address address
CPU ≶ memory
346 14346
MMU
Figure9.5 Dynamicrelocationusingarelocationregister.
conceptofalogicaladdressspacethatisboundtoaseparatephysicaladdress
spaceiscentraltopropermemorymanagement.
9.1.4 Dynamic Loading
In our discussion so far, it has been necessary for the entire program and all
dataofaprocesstobeinphysicalmemoryfortheprocesstoexecute.Thesize
of a process has thus been limited to the size of physical memory. To obtain
bettermemory-spaceutilization,wecanusedynamicloading.Withdynamic
loading,aroutineisnotloadeduntilitiscalled.Allroutinesarekeptondisk
in a relocatable load format. The main program is loaded into memory and
is executed. When a routine needs to call another routine, the calling routine
firstcheckstoseewhethertheotherroutinehasbeenloaded.Ifithasnot,the
relocatablelinkingloaderiscalledtoloadthedesiredroutineintomemoryand
to update the program’s address tables to reflect this change. Then control is
passedtothenewlyloadedroutine.
Theadvantageofdynamicloadingisthataroutineisloadedonlywhenit
isneeded.Thismethodisparticularlyusefulwhenlargeamountsofcodeare
neededtohandleinfrequentlyoccurringcases,suchaserrorroutines.Insuch
a situation, although the total program size may be large, the portion that is
used(andhenceloaded)maybemuchsmaller.
Dynamic loading does not require special support from the operating
system. It is the responsibility of the users to design their programs to take
advantage of such a method. Operating systems may help the programmer,
however,byprovidinglibraryroutinestoimplementdynamicloading.
9.1.5 Dynamic Linking and Shared Libraries
Dynamicallylinkedlibraries(DLLs)aresystemlibrariesthatarelinkedtouser
programswhentheprogramsarerun(referbacktoFigure9.3).Someoperating
systems support only static linking, in which system libraries are treated356 Chapter9 MainMemory
like any other object module and are combined by the loader into the binary
program image. Dynamic linking, in contrast, is similar to dynamic loading.
Here,though,linking,ratherthanloading,ispostponeduntilexecutiontime.
This feature is usually used with system libraries, such as the standard C
languagelibrary.Withoutthisfacility,eachprogramonasystemmustincludea
copyofitslanguagelibrary(oratleasttheroutinesreferencedbytheprogram)
in the executable image. This requirement not only increases the size of an
executable image but also may waste main memory. Asecond advantage of
DLLs is that these libraries can be shared among multiple processes, so that
only one instance of the DLL in main memory. For this reason, DLLs are also
known as shared libraries, and are used extensively in Windows and Linux
systems.
Whenaprogramreferencesaroutinethatisinadynamiclibrary,theloader
locatestheDLL,loadingitintomemoryifnecessary.Itthenadjustsaddresses
thatreferencefunctionsinthedynamiclibrarytothelocationinmemorywhere
theDLLisstored.
Dynamically linked libraries can be extended to library updates (such as
bug fixes). In addition, a library may be replaced by a new version, and all
programs that reference the library will automatically use the new version.
Withoutdynamiclinking,allsuchprogramswouldneedtoberelinkedtogain
accesstothenewlibrary.Sothatprogramswillnot accidentallyexecutenew,
incompatibleversionsoflibraries,versioninformationisincludedinboththe
program and the library. More than one version of a library may be loaded
intomemory,andeachprogramusesitsversioninformationtodecidewhich
copyofthelibrarytouse.Versionswithminorchangesretainthesameversion
number, whereas versions with major changes increment the number. Thus,
onlyprogramsthatarecompiledwiththenewlibraryversionareaffectedby
anyincompatiblechangesincorporatedinit.Otherprogramslinkedbeforethe
newlibrarywasinstalledwillcontinueusingtheolderlibrary.
Unlike dynamic loading, dynamic linking and shared libraries generally
require help from the operating system. If the processes in memory are pro-
tectedfromoneanother, thentheoperatingsystemistheonly entitythat can
checktoseewhethertheneededroutineisinanotherprocess’smemoryspace
or that can allow multiple processes to access the same memory addresses.
We elaborate on this concept, as well as how DLLs can be shared by multiple
processes,whenwediscusspaginginSection9.3.4.
9.2 Contiguous Memory Allocation
The main memory must accommodate both the operating system and the
various user processes. We therefore need to allocate main memory in the
mostefficientwaypossible.Thissectionexplainsoneearlymethod,contiguous
memoryallocation.
The memory is usually dividedinto two partitions: one for the operating
system and one for the user processes. We can place the operating system
in either low memory addresses or high memory addresses. This decision
dependsonmanyfactors,suchasthelocationoftheinterruptvector.However,
many operatingsystems(including Linuxand Windows)placetheoperating
systeminhighmemory,andthereforewediscussonlythatsituation.9.2 ContiguousMemoryAllocation 357
We usually want several user processes to reside in memory at the same
time. We therefore need to consider how to allocate available memory to the
processes that are waiting to be brought into memory. In contiguous mem-
ory allocation, each process is contained in a single section of memory that
is contiguous to the section containing the next process. Before discussing
thismemoryallocationschemefurther,though, wemustaddresstheissueof
memoryprotection.
9.2.1 Memory Protection
We can prevent a process from accessing memory that it does not own by
combining two ideas previously discussed. If we have a system with a relo-
cationregister(Section9.1.3),togetherwithalimitregister(Section9.1.1),we
accomplishourgoal.Therelocationregistercontainsthevalueofthesmallest
physicaladdress;thelimitregistercontainstherangeoflogicaladdresses(for
example, relocation = 100040 and limit = 74600). Each logical address must
fall within the range specified by the limit register. The MMU maps the log-
ical address dynamically by adding the value in the relocation register. This
mappedaddressissenttomemory(Figure9.6).
When the CPU scheduler selects a process for execution, the dispatcher
loads the relocation and limit registers with the correct values as part of the
context switch. Becauseeveryaddressgeneratedby a CPU is checked against
theseregisters,wecanprotectboththeoperatingsystemandtheotherusers’
programsanddatafrombeingmodifiedbythisrunningprocess.
Therelocation-registerschemeprovidesaneffectivewaytoallowtheoper-
atingsystem’ssizetochangedynamically.Thisflexibilityisdesirableinmany
situations.For example,the operating systemcontains code and buffer space
for device drivers. If a device driver is not currently in use, it makes little
sensetokeepitinmemory;instead,itcanbeloadedintomemoryonlywhen
it is needed. Likewise, when the device driver is no longer needed, it can be
removedanditsmemoryallocatedforotherneeds.
limit relocation
register register
logical physical
address yes address
CPU < + memory
no
trap: addressing error
Figure9.6 Hardwaresupportforrelocationandlimitregisters.358 Chapter9 MainMemory
9.2.2 Memory Allocation
Nowwearereadytoturntomemoryallocation.Oneofthesimplestmethodsof
allocatingmemoryistoassignprocessestovariablysizedpartitionsinmem-
ory, where each partition may contain exactly one process. In this variable-
partitionscheme,theoperatingsystemkeepsatableindicatingwhichpartsof
memoryareavailableandwhichareoccupied.Initially,allmemoryisavailable
for user processes and is considered one large block of available memory, a
hole. Eventually, as you will see, memory contains a set of holes of various
sizes.
Figure9.7depictsthisscheme.Initially,thememoryisfullyutilized,con-
taining processes 5, 8, and 2. After process 8 leaves, there is one contiguous
hole. Later on, process 9 arrives and is allocated memory. Then process 5
departs,resultingintwononcontiguousholes.
Asprocessesenterthesystem,theoperatingsystemtakesintoaccountthe
memory requirements of each process and the amount of available memory
space in determiningwhich processesare allocated memory.When aprocess
isallocatedspace,itisloadedintomemory,whereitcanthencompeteforCPU
time. When a process terminates, it releases its memory, which the operating
systemmaythenprovidetoanotherprocess.
Whathappenswhenthereisn’tsufficientmemorytosatisfythedemands
ofanarrivingprocess?Oneoptionistosimplyrejecttheprocessandprovide
anappropriateerrormessage.Alternatively,wecanplacesuchprocessesinto
awaitqueue.Whenmemoryislaterreleased,theoperatingsystemchecksthe
wait queue to determine if it will satisfy the memory demands of a waiting
process.
In general, as mentioned, the memory blocks available comprise a set of
holes of various sizes scattered throughout memory. When a process arrives
andneedsmemory,thesystemsearchesthesetforaholethatislargeenough
for this process. If the hole is too large, it is split into two parts. One part is
allocatedtothearrivingprocess;theotherisreturnedtothesetofholes.When
aprocessterminates,itreleasesitsblockofmemory,whichisthenplacedback
inthesetofholes.Ifthenewholeisadjacenttootherholes,theseadjacentholes
aremergedtoformonelargerhole.
This procedure is a particular instance of the general dynamic storage-
allocation problem,which concerns how to satisfy a requestof size n from a
listoffreeholes.Therearemanysolutionstothisproblem.Thefirst-fit,best-fi,
andworst-fi strategiesaretheonesmostcommonlyusedtoselectafreehole
fromthesetofavailableholes.
high
OS OS OS OS
memory
process 5 process 5 process 5
process 9 process 9
process 8
low
process 2 process 2 process 2 process 2
memory
Figure9.7 Variablepartition.9.2 ContiguousMemoryAllocation 359
• Firstfit.Allocatethefirstholethatisbigenough.Searchingcanstarteither
at the beginning of the set of holes or at the location where the previous
first-fitsearchended.Wecanstopsearchingassoonaswefindafreehole
thatislargeenough.
• Bestfi.Allocatethesmallestholethatisbigenough.Wemustsearchthe
entire list, unless the list is ordered by size. This strategy produces the
smallestleftoverhole.
• Worst fit. Allocate the largest hole. Again, we must search the entire list,
unlessitissortedbysize.Thisstrategyproducesthelargestleftoverhole,
which may be more useful than the smaller leftover hole from a best-fit
approach.
Simulationshaveshownthatbothfirstfitandbestfitarebetterthanworst
fitintermsofdecreasingtimeandstorageutilization.Neitherfirstfitnorbest
fitis clearlybetterthanthe otherintermsofstorageutilization,but first fit is
generallyfaster.
9.2.3 Fragmentation
Boththefirst-fitandbest-fitstrategiesformemoryallocationsufferfromexter-
nal fragmentation. As processes are loaded and removed from memory, the
free memory space is broken into little pieces. External fragmentation exists
whenthereisenoughtotalmemoryspacetosatisfyarequestbuttheavailable
spacesarenotcontiguous:storageisfragmentedintoalargenumberofsmall
holes.This fragmentationproblemcan besevere.Inthe worst case,we could
have a block of free (or wasted) memory between every two processes. If all
thesesmallpiecesofmemorywereinonebigfreeblockinstead,wemightbe
abletorunseveralmoreprocesses.
Whetherweareusingthefirst-fitorbest-fitstrategycanaffecttheamount
offragmentation.(Firstfitisbetterforsomesystems,whereasbestfitisbetter
forothers.)Another factor iswhich endof afreeblock isallocated.(Which is
the leftover piece—the one on the top or the one on the bottom?) No matter
whichalgorithmisused,however,externalfragmentationwillbeaproblem.
Dependingonthetotalamountofmemorystorageandtheaverageprocess
size, external fragmentation may be a minor or a major problem. Statistical
analysis of first fit, for instance, reveals that, even with some optimization,
given N allocated blocks, another 0.5 N blocks will be lost to fragmentation.
Thatis,one-thirdofmemorymaybeunusable!Thispropertyisknownasthe
50-percentrule.
Memory fragmentation can be internal as well as external. Consider a
multiple-partitionallocationschemewithaholeof18,464bytes.Supposethat
the next process requests 18,462 bytes. If we allocate exactly the requested
block, we are left with a hole of 2 bytes. The overhead to keep track of this
hole will be substantially larger than the hole itself. The general approach
to avoiding this problem is to break the physical memory into fixed-sized
blocksandallocatememoryinunitsbasedonblock size.Withthisapproach,
the memory allocated to a process may be slightly larger than the requested
memory.Thedifferencebetweenthesetwonumbersisinternalfragmentation
—unusedmemorythatisinternaltoapartition.360 Chapter9 MainMemory
Onesolutiontotheproblemofexternalfragmentationiscompaction.The
goalistoshufflethememorycontentssoastoplaceallfreememorytogether
in one large block. Compaction is not always possible, however. If relocation
isstaticandisdoneatassemblyorloadtime,compactioncannotbedone.Itis
possibleonlyifrelocationisdynamicandisdoneatexecutiontime.Ifaddresses
are relocated dynamically, relocation requires only moving the program and
dataandthenchangingthebaseregistertoreflectthenewbaseaddress.When
compaction is possible,we must determineits cost. The simplestcompaction
algorithmistomoveallprocessestowardoneendofmemory;allholesmovein
theotherdirection,producingonelargeholeofavailablememory.Thisscheme
canbeexpensive.
Anotherpossiblesolutiontotheexternal-fragmentationproblemistoper-
mitthelogicaladdressspaceofprocessestobenoncontiguous,thusallowinga
processtobeallocatedphysicalmemorywhereversuchmemoryisavailable.
This is the strategy used in paging, the most common memory-management
techniqueforcomputersystems.Wedescribepaginginthefollowingsection.
Fragmentationisageneralproblemincomputingthatcanoccurwherever
we must manage blocks of data. We discuss the topic further in the storage
managementchapters(Chapter11throughChapter15).
9.3 Paging
Memory management discussed thus far has required the physical address
space of a process to be contiguous. We now introduce paging, a memory-
managementschemethatpermitsaprocess’sphysicaladdressspacetobenon-
contiguous.Pagingavoidsexternalfragmentationandtheassociatedneedfor
compaction,twoproblemsthatplaguecontiguousmemoryallocation.Because
itoffersnumerousadvantages,paginginitsvariousformsisusedinmostoper-
ating systems, from those for large servers through those for mobile devices.
Pagingisimplementedthroughcooperationbetweentheoperatingsystemand
thecomputerhardware.
9.3.1 Basic Method
Thebasicmethodforimplementingpaginginvolvesbreakingphysicalmem-
ory into fixed-sized blocks called frames and breaking logical memory into
blocksofthesamesizecalledpages.Whenaprocessistobeexecuted,itspages
areloadedintoanyavailablememoryframesfromtheirsource(afilesystemor
thebackingstore).Thebackingstoreisdividedintofixed-sizedblocksthatare
thesamesizeasthememoryframesorclustersofmultipleframes.Thisrather
simple idea has great functionality and wide ramifications. For example, the
logicaladdressspaceisnowtotallyseparatefromthephysicaladdressspace,
soaprocesscanhavealogical64-bitaddressspaceeventhoughthesystemhas
lessthan264 bytesofphysicalmemory.
Every address generated by the CPU is divided into two parts: a page
number(p)andapageoffset(d):
page number page offset
p d9.3 Paging 361
Figure9.8 Paginghardware.
The page number is used as an index into a per-process page table. This is
illustratedinFigure9.8.Thepagetablecontainsthebaseaddressofeachframe
inphysicalmemory,andtheoffsetisthelocationintheframebeingreferenced.
Thus,thebaseaddressoftheframeiscombinedwiththepageoffsettodefine
thephysicalmemoryaddress.ThepagingmodelofmemoryisshowninFigure
9.9.
The following outlines the steps taken by the MMU to translate a logical
addressgeneratedbytheCPUtoaphysicaladdress:
1. Extractthepagenumberpanduseitasanindexintothepagetable.
2. Extractthecorrespondingframenumberf fromthepagetable.
3. Replacethepagenumberpinthelogicaladdresswiththeframenumber
f.
Astheoffsetddoesnotchange, itisnot replaced,andtheframenumberand
offsetnowcomprisethephysicaladdress.
The page size (like the frame size) is defined by the hardware. The size
of a page is a power of 2, typically varying between 4 KB and 1 GB per page,
depending on the computer architecture. The selection of a power of 2 as a
page size makes the translation of a logical address into a page number and
pageoffsetparticularlyeasy.Ifthesizeofthelogicaladdressspaceis2m,anda
pagesizeis2nbytes,thenthehigh-orderm−nbitsofalogicaladdressdesignate
thepagenumber,andthenlow-orderbitsdesignatethepageoffset.Thus,the
logicaladdressisasfollows:
page number page offset
p d
m – n n362 Chapter9 MainMemory
frame
number
page 0 0
0 1
page 1 1 page 0
1 4
2 3
page 2 2
3 7
page 3 page table 3 page 2
logical 4 page 1
memory
5
6
7 page 3
physical
memory
Figure9.9 Pagingmodeloflogicalandphysicalmemory.
where p is an index into the page table and d is the displacement within the
page.
As a concrete (although minuscule) example, consider the memory in
Figure 9.10. Here, in the logical address, n = 2 and m = 4. Using a page size
of 4 bytes and a physical memory of 32 bytes (8 pages), we show how the
programmer’sviewofmemorycanbemappedintophysicalmemory.Logical
address0ispage0,offset0.Indexingintothepagetable,wefindthatpage0
isinframe5.Thus,logicaladdress0mapstophysical address20[=(5×4)+
0].Logicaladdress3(page0,offset3)mapstophysicaladdress23[=(5×4)+
3]. Logical address 4 is page 1, offset 0; according to the page table, page 1 is
mappedtoframe6.Thus,logicaladdress4mapstophysicaladdress24[=(6
×4)+0].Logicaladdress13mapstophysicaladdress9.
You may have noticed that paging itself is a form of dynamic relocation.
Every logical address is bound by the paging hardware to some physical
address.Usingpagingissimilartousingatableofbase(orrelocation)registers,
oneforeachframeofmemory.
When we use a paging scheme, we have no external fragmentation: any
freeframecanbeallocatedtoaprocessthat needsit.However,wemayhave
some internal fragmentation. Notice that frames are allocated as units. If the
memoryrequirementsofaprocessdonothappentocoincidewithpagebound-
aries,thelastframeallocatedmaynotbecompletelyfull.Forexample,ifpage
sizeis2,048bytes,aprocessof72,766byteswillneed35pagesplus1,086bytes.
It will be allocated 36 frames, resulting in internal fragmentation of 2,048 −
1,086=962bytes.Intheworstcase,aprocesswouldneednpagesplus1byte.
Itwouldbeallocatedn+1frames,resultingininternalfragmentationofalmost
anentireframe.9.3 Paging 363
0 a 0
1 b
2 c
3 d
4 e 4 i
5 f j
0 5
6 g k
7 h 1 6 l
8 i 2 1 8 m
9 j n
3 2
10 k o
11 l page table p
12 m 12
13 n
14 o
15 p
logical memory 16
20 a
b
c
d
24 e
f
g
h
28
physical memory
Figure9.10 Pagingexamplefora32-bytememorywith4-bytepages.
If process size is independent of page size, we expect internal fragmen-
tation to average one-half page per process. This consideration suggests that
small page sizes are desirable. However, overhead is involved in each page-
tableentry,andthisoverheadisreducedasthesizeofthepagesincreases.Also,
diskI/Oismoreefficientwhentheamountofdatabeingtransferredislarger
(Chapter 11). Generally, page sizes have grown over time as processes, data
sets,and main memory have become larger. Today, pages are typically either
4 KB or 8 KB in size, and some systems support even larger page sizes. Some
CPUsandoperatingsystemsevensupportmultiplepagesizes.Forinstance,on
x86-64systems,Windows10supportspagesizesof4KBand2MB.Linuxalso
supportstwopagesizes:adefaultpagesize(typically4KB)andanarchitecture-
dependentlargerpagesizecalledhugepages.
Frequently,ona32-bitCPU,eachpage-tableentryis4byteslong,butthat
size can vary as well. A 32-bit entry can point to one of 232 physical page
frames. If the frame size is 4 KB (212), then a system with 4-byte entries can
address244 bytes(or16TB)ofphysicalmemory.Weshouldnoteherethatthe
sizeofphysicalmemoryinapagedmemorysystemistypicallydifferentfrom
themaximumlogicalsizeofaprocess.Aswefurtherexplorepaging,wewill364 Chapter9 MainMemory
OBTAININGTHEPAGESIZEONLINUXSYSTEMS
OnaLinuxsystem,thepagesizevariesaccordingtoarchitecture,andthere
areseveralwaysofobtainingthepagesize.Oneapproachistousethesystem
callgetpagesize().Anotherstrategyistoenterthefollowingcommandon
thecommandline:
getconf PAGESIZE
Eachofthesetechniquesreturnsthepagesizeasanumberofbytes.
introduce other information that must be kept in the page-table entries. That
informationreducesthenumberofbitsavailabletoaddresspageframes.Thus,
asystemwith32-bitpage-tableentriesmayaddresslessphysicalmemorythan
thepossiblemaximum.
When a process arrives in the system to be executed, its size, expressed
inpages,isexamined.Eachpageof theprocessneedsoneframe.Thus, ifthe
process requires n pages, at least n frames must be available in memory. If n
framesareavailable,theyareallocatedtothisarrivingprocess.Thefirstpage
oftheprocessisloadedintooneoftheallocatedframes,andtheframenumber
is put in the page table for this process. The next page is loaded into another
frame,itsframenumberisputintothepagetable,andsoon(Figure9.11).
An important aspect of paging is the clear separation between the pro-
grammer’sviewofmemoryandtheactualphysicalmemory.Theprogrammer
viewsmemoryasonesinglespace,containing onlythisoneprogram.Infact,
the user program is scatteredthroughout physical memory,which also holds
free-frame list free-frame list
14 15
13 13 page 1
13
18
20 14 14 page 0
15
15 15
page 0 16 page 0 16
page 1 page 1
page 2 page 2
17 17
page 3 page 3
new process 18 new process 18 page 2
19 0 14 19
1 13
20 2 18 20 page 3
3 20
21 new-process page table 21
(a) (b)
Figure9.11 Freeframes(a)beforeallocationand(b)afterallocation.9.3 Paging 365
other programs. The difference between the programmer’s view of memory
andtheactualphysicalmemoryisreconciledbytheaddress-translationhard-
ware.The logical addressesare translated intophysical addresses.Thismap-
pingishiddenfromtheprogrammerandiscontrolledbytheoperatingsystem.
Notice that the user process by definition is unable to access memory it does
notown.Ithasnowayofaddressingmemoryoutsideofitspagetable,andthe
tableincludesonlythosepagesthattheprocessowns.
Sincetheoperatingsystemismanagingphysicalmemory,itmustbeaware
of the allocation details of physical memory—which frames are allocated,
whichframesareavailable,howmany totalframesthereare,andsoon.This
information is generally kept in a single, system-wide data structure called
a frame table. The frame table has one entry for each physical page frame,
indicatingwhetherthelatterisfreeorallocatedand,ifitisallocated,towhich
pageofwhichprocess(orprocesses).
Inaddition,theoperatingsystemmustbeawarethatuserprocessesoper-
ateinuserspace,andalllogicaladdressesmustbemappedtoproducephysical
addresses.Ifausermakesasystemcall(todoI/O,forexample)andprovides
anaddressasaparameter(abuffer,forinstance),thataddressmustbemapped
toproducethecorrectphysicaladdress.Theoperatingsystemmaintainsacopy
ofthepagetableforeachprocess,justasitmaintainsacopyoftheinstruction
counterandregistercontents.Thiscopyisusedtotranslatelogicaladdressesto
physicaladdresseswhenevertheoperatingsystemmustmapalogicaladdress
toaphysicaladdressmanually.ItisalsousedbytheCPUdispatchertodefine
the hardware page table when a process is to be allocated the CPU. Paging
thereforeincreasesthecontext-switchtime.
9.3.2 Hardware Support
As page tables are per-process data structures, a pointer to the page table
is stored with the other register values (like the instruction pointer) in the
processcontrolblockofeachprocess.WhentheCPUschedulerselectsaprocess
for execution, it must reload the user registers and the appropriatehardware
page-tablevaluesfromthestoreduserpagetable.
The hardware implementation of the page table can be done in several
ways.Inthesimplestcase,thepagetableisimplementedasasetofdedicated
high-speedhardwareregisters,whichmakesthepage-addresstranslationvery
efficient.However,thisapproachincreasescontext-switchtime,aseachoneof
theseregistersmustbeexchangedduringacontextswitch.
Theuseofregistersforthepagetableissatisfactoryifthepagetableisrea-
sonably small (for example, 256 entries). Most contemporary CPUs, however,
supportmuchlargerpagetables(forexample,220entries).Forthesemachines,
the use of fast registers to implement the page table is not feasible. Rather,
thepagetableiskeptinmainmemory,andapage-tablebaseregister(PTBR)
pointstothepagetable.Changingpagetablesrequireschangingonlythisone
register,substantiallyreducingcontext-switchtime.
9.3.2.1 TranslationLook-AsideBuffer
Although storing the page table in main memory can yield faster context
switches,itmayalsoresultinslowermemoryaccesstimes.Supposewewant
toaccesslocationi.Wemustfirstindexintothepagetable,usingthevaluein366 Chapter9 MainMemory
thePTBRoffsetbythepagenumberfori.Thistaskrequiresonememoryaccess.
Itprovidesuswiththeframenumber,whichiscombinedwiththepageoffset
toproducetheactualaddress.Wecanthenaccessthedesiredplaceinmemory.
Withthisscheme,twomemoryaccessesareneededtoaccessdata(oneforthe
page-tableentryandonefortheactualdata).Thus,memoryaccessisslowedby
afactorof2,adelaythatisconsideredintolerableundermostcircumstances.
Thestandardsolutiontothisproblemistouseaspecial,small,fast-lookup
hardwarecache calledatranslationlook-asidebuffer(TLB).TheTLBisasso-
ciative,high-speedmemory.EachentryintheTLBconsistsoftwoparts:akey
(ortag)andavalue.Whentheassociativememoryispresentedwithanitem,
theitemiscomparedwithallkeyssimultaneously.Iftheitemisfound,thecor-
respondingvaluefieldisreturned.Thesearchisfast;aTLBlookupinmodern
hardwareispartoftheinstructionpipeline,essentiallyaddingnoperformance
penalty. To be able to execute the search within a pipeline step, however, the
TLBmustbekeptsmall.Itistypicallybetween32and1,024entriesinsize.Some
CPUs implementseparateinstructionand dataaddressTLBs.Thatcandouble
the number of TLB entries available, because those lookups occur in different
pipelinesteps.Wecanseeinthisdevelopmentanexampleoftheevolutionof
CPUtechnology:systemshaveevolvedfromhavingnoTLBstohavingmultiple
levelsofTLBs,justastheyhavemultiplelevelsofcaches.
The TLB is used with page tables in the following way. The TLB contains
only a few of the page-table entries. When a logical address is generated by
the CPU, the MMU first checks if its page number is present in the TLB. If the
pagenumberisfound,itsframenumberisimmediatelyavailableandisused
to access memory. As just mentioned, these steps are executed as part of the
instructionpipelinewithintheCPU,addingnoperformancepenaltycompared
withasystemthatdoesnotimplementpaging.
If the page number is not in the TLB (known as a TLB miss), address
translation proceeds following the steps illustrated in Section 9.3.1, where a
memoryreferencetothepagetablemustbemade.Whentheframenumberis
obtained,wecanuseittoaccessmemory(Figure9.12).Inaddition,weaddthe
pagenumberandframenumbertotheTLB,sothattheywillbefoundquickly
onthenextreference.
If the TLB is already full of entries, an existing entry must be selected
for replacement. Replacement policies range from least recently used (LRU)
throughround-robintorandom.SomeCPUsallowtheoperatingsystemtopar-
ticipateinLRUentryreplacement,whileothershandlethematterthemselves.
Furthermore,someTLBsallowcertainentriestobewireddown,meaningthat
theycannotberemovedfromtheTLB.Typically,TLBentriesforkeykernelcode
arewireddown.
Some TLBs store address-space identifier (ASIDs) in each TLB entry. An
ASID uniquely identifies each process and is used to provide address-space
protectionforthatprocess.WhentheTLBattemptstoresolvevirtualpagenum-
bers, it ensures that the ASID for the currently running process matches the
ASID associated with the virtual page. If the ASIDs do not match, the attempt
istreatedasaTLBmiss.Inadditiontoprovidingaddress-spaceprotection,an
ASID allows the TLB to contain entries for severaldifferentprocesses simulta-
neously. If the TLB does not support separate ASIDs, then every time a new
pagetableisselected(forinstance,witheachcontextswitch),theTLBmustbe
flushe (orerased)toensurethatthenextexecutingprocessdoesnotusethe9.3 Paging 367
logical
address
CPU p d
page frame
number number
TLB hit
physical
address
f d
TLB
p
TLB miss
f
physical
memory
page table
Figure9.12 PaginghardwarewithTLB.
wrong translation information. Otherwise, the TLB could include old entries
that contain valid virtual addresses but have incorrect or invalid physical
addressesleftoverfromthepreviousprocess.
The percentage of times that the page number of interest is found in the
TLB is called the hit ratio. An 80-percent hit ratio, for example, means that
we find the desiredpage number in the TLB 80 percent of the time. If it takes
10 nanoseconds to access memory, then a mapped-memory access takes 10
nanoseconds when the page number is in the TLB. If we fail to find the page
number in the TLB then we must first access memory for the page table and
frame number (10 nanoseconds) and then access the desiredbyte in memory
(10nanoseconds),foratotalof20nanoseconds.(Weareassumingthatapage-
table lookup takesonly one memoryaccess, but it can take more, aswe shall
see.) To find the effective memory-access time, we weight the case by its
probability:
effectiveaccesstime=0.80×10+0.20×20
=12nanoseconds
In this example, we suffer a 20-percent slowdown in average memory-access
time (from 10 to 12 nanoseconds). For a 99-percent hit ratio, which is much
morerealistic,wehave
effectiveaccesstime=0.99×10+0.01×20
=10.1nanoseconds
Thisincreasedhitrateproducesonlya1percentslowdowninaccesstime.368 Chapter9 MainMemory
Asnotedearlier,CPUstodaymayprovidemultiplelevelsofTLBs.Calculat-
ingmemoryaccesstimesinmodernCPUsisthereforemuchmorecomplicated
than shown in the example above. For instance, the Intel Core i7 CPU has a
128-entryL1instructionTLBanda64-entryL1dataTLB.Inthecaseofamissat
L1,ittakestheCPUsixcyclestocheckfortheentryintheL2512-entryTLB.A
missinL2meansthattheCPUmusteitherwalkthroughthepage-tableentries
in memory to find the associated frame address, which can take hundreds of
cycles,orinterrupttotheoperatingsystemtohaveitdothework.
A complete performance analysis of paging overhead in such a system
wouldrequiremiss-rateinformationabouteachTLBtier.Wecanseefromthe
generalinformationabove,however,thathardwarefeaturescanhaveasignif-
icanteffectonmemoryperformanceandthatoperating-systemimprovements
(such as paging) can result in and, in turn, be affected by hardware changes
(suchasTLBs).WewillfurtherexploretheimpactofthehitratioontheTLBin
Chapter10.
TLBsareahardwarefeatureandthereforewouldseemtobeoflittleconcern
tooperatingsystemsandtheirdesigners.Butthedesignerneedstounderstand
thefunctionandfeaturesofTLBs,whichvarybyhardwareplatform.Foropti-
mal operation, an operating-system design for a given platform must imple-
ment paging according to the platform’s TLB design. Likewise, a change in
theTLBdesign(forexample,betweendifferentgenerationsofIntelCPUs)may
necessitate a change in the paging implementation of the operating systems
thatuseit.
9.3.3 Protection
Memoryprotectioninapagedenvironmentisaccomplishedbyprotectionbits
associatedwitheachframe.Normally,thesebitsarekeptinthepagetable.
One bit can define a page to be read–write or read-only. Every reference
to memory goes through the page table to find the correct frame number. At
thesametimethatthephysicaladdressisbeingcomputed,theprotectionbits
canbecheckedtoverifythatnowritesarebeingmadetoaread-onlypage.An
attempt to write to a read-only page causes a hardware trap to the operating
system(ormemory-protectionviolation).
Wecan easilyexpandthisapproachtoprovideafinerlevelofprotection.
We can create hardware to provide read-only, read–write, or execute-only
protection;or,byprovidingseparateprotectionbitsforeachkindofaccess,we
can allow any combination of these accesses. Illegal attemptswill be trapped
totheoperatingsystem.
One additional bit is generally attached to each entry in the page table: a
valid–invalid bit. When this bit is set to valid, the associated page is in the
process’s logical address space and is thus a legal (or valid) page. When the
bitissettoinvalid,thepageisnotintheprocess’slogicaladdressspace.Illegal
addresses are trapped by use of the valid–invalid bit. The operating system
setsthisbitforeachpagetoallowordisallowaccesstothepage.
Suppose, for example, that in a system with a 14-bit address space (0 to
16383), we have a program that should use only addresses 0 to 10468. Given
apagesizeof2 KB, we have thesituationshown inFigure9.13.Addressesin
pages 0, 1, 2, 3, 4, and 5 are mapped normally through the page table. Any
attempt to generate an address in pages 6 or 7, however, will find that the9.3 Paging 369
0
1
2 page 0
frame number valid–invalid bit
12,287
page 5 3 page 1
10,468
0 2 v
page 4 4 page 2
1 3 v
2 4 v
page 3 5
3 7 v
page 2 4 8 v 6
5 9 v
page 1 6 0 i 7 page 3
7 0 i
page 0 8 page 4
00000 page table
9 page 5
•
•
•
page n
Figure9.13 Valid(v)orinvalid(i)bitinapagetable.
valid–invalidbitissettoinvalid,andthecomputerwilltraptotheoperating
system(invalidpagereference).
Notice that this scheme has created a problem. Because the program
extends only to address 10468, any reference beyond that address is illegal.
However,referencestopage5areclassifiedasvalid,soaccessestoaddresses
upto12287arevalid.Onlytheaddressesfrom12288to16383areinvalid.This
problemisaresultofthe2-KBpagesizeandreflectstheinternalfragmentation
ofpaging.
Rarely does a process use all its address range. In fact, many processes
use only a small fraction of the address space available to them. It would be
wasteful in these cases to create a page table with entries for every page in
the address range. Most of this table would be unused but would take up
valuable memory space. Some systems provide hardware, in the form of a
page-table length register (PTLR), to indicate the size of the page table. This
value is checked against every logical address to verify that the address is in
the valid range for the process. Failure of this test causes an error trap to the
operatingsystem.
9.3.4 Shared Pages
Anadvantageofpagingisthepossibilityofsharingcommoncode,aconsidera-
tionthatisparticularlyimportantinanenvironmentwithmultipleprocesses.
Consider the standard C library, which provides a portion of the system call
interface for many versions of UNIX and Linux. On a typical Linux system,
mostuserprocessesrequirethestandardClibrarylibc.Oneoptionistohave370 Chapter9 MainMemory
eachprocessloaditsowncopyoflibcintoitsaddressspace.Ifasystemhas
40 user processes, and the libc library is 2 MB, this would require 80 MB of
memory.
Ifthecodeisreentrantcode,however,itcanbeshared,asshowninFigure
9.14.Here,weseethreeprocessessharingthepagesforthestandardClibrary
libc. (Although the figure shows the libc library occupying four pages, in
reality, it would occupy more.) Reentrant code is non-self-modifying code: it
neverchangesduringexecution.Thus,twoormoreprocessescanexecutethe
samecodeatthesametime.Eachprocesshasitsowncopyofregistersanddata
storagetoholdthedatafortheprocess’sexecution.Thedatafortwodifferent
processeswill,ofcourse,bedifferent.OnlyonecopyofthestandardClibrary
needbekeptinphysicalmemory,andthepagetableforeachuserprocessmaps
ontothe samephysical copyoflibc.Thus, tosupport40processes,we need
onlyonecopyofthelibrary,andthetotalspacenowrequiredis2MBinstead
of80MB—asignificantsaving!
Inadditiontorun-timelibrariessuchaslibc,otherheavilyusedprograms
canalsobeshared—compilers,windowsystems,databasesystems,andsoon.
ThesharedlibrariesdiscussedinSection9.1.5aretypicallyimplementedwith
sharedpages.Tobesharable,thecodemustbereentrant.Theread-onlynature
ofsharedcodeshouldnotbelefttothecorrectnessofthecode;theoperating
systemshouldenforcethisproperty.
libc 1
0
3
libc 2
4
1 libc 4
6
libc 3
1
2
...
libc 4
... page table libc 1 3 libc 1
forP
1
3
process P libc 2 4 4 libc 2
1
6
libc 3
5
1
...
libc 4
6 libc 3
... page table
libc 1 forP
2
3 7
libc 2 4 process P 2
6 8
libc 3
1
...
libc 4 9
... page table
forP
3 physical memory
process P
3
Figure9.14 SharingofstandardClibraryinapagingenvironment.9.4 StructureofthePageTable 371
The sharing of memory among processes on a system is similar to the
sharing of the address space of a task by threads, described in Chapter 4.
Furthermore,recallthatinChapter3wedescribedsharedmemoryasamethod
of interprocess communication. Some operating systems implement shared
memoryusingsharedpages.
Organizing memory according to pages provides numerous benefits in
addition to allowing several processes to share the same physical pages. We
coverseveralotherbenefitsinChapter10.
9.4 Structure of the Page Table
Inthissection,weexploresomeofthemostcommontechniquesforstructuring
thepagetable,includinghierarchicalpaging,hashedpagetables,andinverted
pagetables.
9.4.1 Hierarchical Paging
Most modern computer systems support a large logical address space
(232 to264).Insuch an environment,the pagetable itselfbecomes excessively
large.Forexample,considerasystemwitha32-bitlogicaladdressspace.Ifthe
pagesizeinsuchasystemis4KB(212),thenapagetablemay consistofover
1millionentries(220 = 232/212).Assumingthateachentryconsistsof4bytes,
eachprocessmayneedupto4MBofphysicaladdressspaceforthepagetable
alone. Clearly, we would not want to allocate the page table contiguously in
mainmemory.Onesimplesolutiontothisproblemistodividethepagetable
intosmallerpieces.Wecanaccomplishthisdivisioninseveralways.
One way is to use a two-level paging algorithm, in which the page table
itselfisalsopaged(Figure9.15).Forexample,consideragainthesystemwith
a 32-bit logical address space and a page size of 4 KB. A logical address is
dividedinto a page number consisting of 20 bits and a page offset consisting
of12bits.Becausewepagethepagetable,thepagenumberisfurtherdivided
intoa10-bitpagenumberanda10-bitpageoffset.Thus,alogicaladdressisas
follows:
page number page offset
p p d
1 2
10 10 12
where p is an index into the outer page table and p is the displacement
1 2
withinthepageoftheinnerpagetable.Theaddress-translationmethodforthis
architecture is shown in Figure 9.16. Because address translation works from
theouterpagetableinward,thisschemeisalsoknownasaforward-mapped
pagetable.
Forasystemwitha64-bitlogicaladdressspace,atwo-levelpagingscheme
is no longer appropriate. To illustrate this point, let’s suppose that the page
size in such a system is 4 KB (212). In this case, the page table consists of up
to252 entries.Ifweuseatwo-levelpagingscheme,thentheinnerpagetables
canconvenientlybeonepagelong,orcontain2104-byteentries.Theaddresses
looklikethis:372 Chapter9 MainMemory
0
1
1
(cid:129)
(cid:129) (cid:129)
(cid:129) (cid:129)
(cid:129) 100
500
(cid:129)
(cid:129) (cid:129)
(cid:129) (cid:129)
(cid:129)
100
500
(cid:129) (cid:129)
(cid:129) (cid:129)
(cid:129) (cid:129) (cid:129)
(cid:129)
708 (cid:129)
(cid:129) 708
(cid:129)
(cid:129)
(cid:129)
outer page 929 900 (cid:129) (cid:129)
table (cid:129)
(cid:129)
(cid:129)
(cid:129)
900 (cid:129)
(cid:129)
page of 929
page table
(cid:129)
(cid:129)
page table (cid:129)
memory
Figure9.15 Atwo-levelpage-tablescheme.
outer page inner page offset
p p d
1 2
42 10 12
The outer page table consists of 242 entries, or 244 bytes. The obvious way to
avoid such a large table is to divide the outer page table into smaller pieces.
(Thisapproachisalsousedonsome32-bitprocessorsforaddedflexibilityand
efficiency.)
Wecan dividetheouterpagetable invariousways. Forexample,we can
pagetheouterpagetable,givingusathree-levelpagingscheme.Supposethat
theouterpagetableismadeupofstandard-sizepages(210entries,or212bytes).
Inthiscase,a64-bitaddressspaceisstilldaunting:
2nd outer page outer page inner page offset
p p p d
1 2 3
32 10 10 12
Theouterpagetableisstill234 bytes(16GB)insize.
Thenextstepwouldbeafour-levelpagingscheme,wherethesecond-level
outerpagetableitselfisalsopaged,andsoforth.The64-bitUltraSPARCwould
require sevenlevels of paging—a prohibitive number of memory accesses—9.4 StructureofthePageTable 373
logical address
p p d
1 2
p
1
p
2
outer page
d
table
page of
page table
Figure9.16 Addresstranslationforatwo-level32-bitpagingarchitecture.
totranslateeachlogicaladdress.Youcanseefromthisexamplewhy,for64-bit
architectures,hierarchicalpagetablesaregenerallyconsideredinappropriate.
9.4.2 Hashed Page Tables
Oneapproachforhandlingaddressspaceslargerthan32bitsistouseahashed
pagetable,withthehashvaluebeingthevirtualpagenumber.Eachentryin
thehashtablecontainsalinkedlistofelementsthathashtothesamelocation
(tohandlecollisions).Eachelementconsistsofthreefields:(1)thevirtualpage
number,(2)thevalueofthemappedpageframe,and(3)apointertothenext
elementinthelinkedlist.
The algorithm works as follows: The virtual page number in the virtual
address is hashed into the hash table. The virtual page number is compared
with field 1 in the first element in the linked list. If there is a match, the
correspondingpageframe(field2)isusedtoformthedesiredphysicaladdress.
If there is no match, subsequent entries in the linked list are searched for a
matchingvirtualpagenumber.ThisschemeisshowninFigure9.17.
physical
logical address address
p d r d
hash physical
function q s p r (cid:129) (cid:129) (cid:129) memory
hash table
Figure9.17 Hashedpagetable.374 Chapter9 MainMemory
A variation of this scheme that is useful for 64-bit address spaces has
been proposed. This variation uses clustered page tables, which are similar
tohashedpagetablesexceptthateachentryinthehashtablereferstoseveral
pages (such as 16) rather than a single page. Therefore, a single page-table
entry can store the mappings for multiple physical-page frames. Clustered
page tables are particularly useful for sparse address spaces, where memory
referencesarenoncontiguousandscatteredthroughouttheaddressspace.
9.4.3 Inverted Page Tables
Usually, each process has an associated page table. The page table has one
entry for each page that the process is using (or one slot for each virtual
address,regardlessofthelatter’svalidity).Thistablerepresentationisanatural
one,sinceprocessesreferencepagesthroughthepages’virtualaddresses.The
operating system must then translate this reference into a physical memory
address.Sincethetableissortedbyvirtualaddress,theoperatingsystemisable
tocalculatewhereinthetabletheassociatedphysicaladdressentryislocated
andtousethatvaluedirectly.Oneofthedrawbacksofthismethodisthateach
pagetablemayconsistofmillionsofentries.Thesetablesmayconsumelarge
amountsofphysicalmemoryjusttokeeptrackofhowotherphysicalmemory
isbeingused.
To solve this problem, we can use an inverted page table. An inverted
page table has one entry for each realpage (or frame) of memory.Each entry
consistsofthevirtualaddressofthepagestoredinthatrealmemorylocation,
with information about the process that owns the page. Thus, only one page
table is in the system, and it has only one entry for each page of physical
memory.Figure9.18showstheoperationofaninvertedpagetable.Compare
it with Figure 9.8, which depicts astandard page table in operation. Inverted
page tables often require that an address-space identifier (Section 9.3.2) be
storedineachentryofthepagetable,sincethetableusuallycontains several
logical
physical
address
address
physical
CPU pid p d i d
memory
search i
pid p
page table
Figure9.18 Invertedpagetable.9.4 StructureofthePageTable 375
differentaddressspacesmappingphysicalmemory.Storingtheaddress-space
identifierensuresthatalogicalpageforaparticularprocessismappedtothe
correspondingphysicalpageframe.Examplesofsystemsusinginvertedpage
tablesincludethe64-bitUltraSPARCandPowerPC.
Toillustratethismethod,wedescribeasimplifiedversionoftheinverted
pagetableusedintheIBMRT.IBMwasthefirstmajorcompanytouseinverted
page tables, starting with the IBM System 38 and continuing through the
RS/6000andthecurrentIBMPowerCPUs.FortheIBMRT,eachvirtualaddress
inthesystemconsistsofatriple:
<process-id,page-number,offset>.
Eachinvertedpage-tableentryisapair<process-id,page-number>wherethe
process-id assumes the role of the address-space identifier. When a memory
reference occurs, part of the virtual address, consisting of <process-id, page-
number>, is presented to the memory subsystem. The inverted page table
is then searched for a match. If a match is found—say, at entry i—then the
physicaladdress<i,offset>isgenerated.Ifnomatchisfound,thenanillegal
addressaccesshasbeenattempted.
Although this scheme decreases the amount of memory needed to store
eachpagetable,itincreasestheamountoftimeneededtosearchthetablewhen
apagereferenceoccurs.Becausetheinvertedpagetableissortedbyphysical
address, but lookups occur on virtual addresses, the whole table might need
to be searched before a match is found. This search would take far too long.
To alleviate this problem, we use a hash table, as described in Section 9.4.2,
to limit the search to one—or at most a few—page-table entries. Of course,
eachaccesstothehashtableaddsamemoryreferencetotheprocedure,soone
virtualmemoryreferencerequiresatleasttworealmemoryreads—oneforthe
hash-tableentryandoneforthepagetable.(RecallthattheTLBissearchedfirst,
beforethehashtableisconsulted,offeringsomeperformanceimprovement.)
One interesting issue with inverted page tables involves shared memory.
With standard paging, each process has its own page table, which allows
multiple virtual addresses to be mapped to the same physical address. This
method cannot be used with inverted page tables; because there is only one
virtualpageentryforeveryphysicalpage,onephysicalpagecannothavetwo
(ormore)sharedvirtualaddresses.Therefore,withinvertedpagetables,only
onemappingofavirtualaddresstothesharedphysicaladdressmayoccurat
anygiventime.Areferencebyanotherprocesssharingthememorywillresult
inapagefaultandwillreplacethemappingwithadifferentvirtualaddress.
9.4.4 Oracle SPARC Solaris
Considerasafinalexampleamodern64-bitCPUandoperatingsystemthatare
tightly integrated to provide low-overhead virtual memory. Solaris running
on the SPARC CPU is a fully 64-bit operating system and as such has to solve
the problem of virtual memory without using up all of its physical memory
by keeping multiple levels of page tables. Its approach is a bit complex but
solves the problem efficiently using hashed page tables. There are two hash
tables—oneforthekernelandoneforalluserprocesses.Eachmapsmemory
addresses from virtual to physical memory. Each hash-table entry represents
a contiguous area of mapped virtual memory, which is more efficient than376 Chapter9 MainMemory
havingaseparatehash-tableentryforeachpage.Eachentryhasabaseaddress
andaspanindicatingthenumberofpagestheentryrepresents.
Virtual-to-physicaltranslationwouldtaketoolongifeachaddressrequired
searchingthroughahashtable,sotheCPUimplementsaTLBthatholdstransla-
tiontableentries(TTEs)forfasthardwarelookups.AcacheoftheseTTEsresides
in a translation storage buffer (TSB), which includes an entry per recently
accessedpage.Whenavirtualaddressreferenceoccurs,thehardwaresearches
theTLBforatranslation.Ifnoneisfound,thehardwarewalksthroughthein-
memory TSB looking for the TTE that corresponds to the virtual address that
caused the lookup. This TLB walk functionality is found on many modern
CPUs.IfamatchisfoundintheTSB,theCPUcopiestheTSBentryintotheTLB,
and the memory translation completes. If no match is found in the TSB, the
kernel is interrupted to search the hash table. The kernel then creates a TTE
fromtheappropriatehashtableandstoresitintheTSBforautomaticloading
intotheTLBbytheCPUmemory-managementunit.Finally,theinterrupthan-
dlerreturnscontroltotheMMU,whichcompletestheaddresstranslationand
retrievestherequestedbyteorwordfrommainmemory.
9.5 Swapping
Process instructions and the data they operate on must be in memory to be
executed. However, a process, or a portion of a process, can be swapped
temporarily out of memory to a backing store and then brought back into
memory for continued execution (Figure 9.19). Swapping makes it possible
forthetotalphysicaladdressspaceofallprocessestoexceedtherealphysical
memory of the system, thus increasing the degreeof multiprogramming in a
system.
operating
system
process P
1 swap out 1
process P
2
2 swap in
user
space
backing store
main memory
Figure9.19 Standardswappingoftwoprocessesusingadiskasabackingstore.9.5 Swapping 377
9.5.1 Standard Swapping
Standardswappinginvolvesmovingentireprocessesbetweenmainmemory
and a backing store. The backing store is commonly fast secondary storage.
Itmustbelargeenoughtoaccommodatewhateverpartsofprocessesneedto
be stored and retrieved, and it must provide direct access to these memory
images. When a process or part is swapped to the backing store, the data
structures associated with the process must be written to the backing store.
For a multithreaded process, all per-thread data structures must be swapped
aswell.Theoperatingsystemmustalsomaintainmetadataforprocessesthat
havebeenswappedout,sotheycanberestoredwhentheyareswappedback
intomemory.
Theadvantageofstandardswappingisthatitallowsphysicalmemoryto
be oversubscribed,so that the systemcan accommodate more processesthan
there is actual physical memory to store them. Idle or mostly idle processes
are good candidates for swapping; any memory that has been allocated to
theseinactiveprocessescanthenbededicatedtoactiveprocesses.Ifaninactive
processthathasbeenswappedoutbecomesactiveonceagain,itmustthenbe
swappedbackin.ThisisillustratedinFigure9.19.
9.5.2 Swapping with Paging
StandardswappingwasusedintraditionalUNIXsystems,butitisgenerallyno
longer used in contemporary operating systems, because the amount of time
required to move entire processes between memory and the backing store is
prohibitive.(AnexceptiontothisisSolaris,whichstillusesstandardswapping,
howeveronlyunderdirecircumstanceswhenavailablememoryisextremely
low.)
Mostsystems,includingLinuxandWindows,nowuseavariationofswap-
ping in which pages of a process—rather than an entire process—can be
swapped.Thisstrategystillallowsphysicalmemorytobeoversubscribed,but
does not incur the cost of swapping entire processes, as presumably only a
smallnumberofpageswillbeinvolvedinswapping.Infact,thetermswapping
now generally refers to standard swapping, and paging refers to swapping
withpaging.Apageoutoperationmovesapagefrommemorytothebacking
store;thereverseprocessisknownasapagein.Swappingwithpagingisillus-
tratedin Figure9.20 where a subset of pages for processesA and B are being
paged-outandpaged-inrespectively.AsweshallseeinChapter10,swapping
withpagingworkswellinconjunctionwithvirtualmemory.
9.5.3 Swapping on Mobile Systems
MostoperatingsystemsforPCsandserverssupportswappingpages.Incon-
trast,mobile systemstypicallydonot support swappinginany form. Mobile
devicesgenerallyuseflashmemoryratherthanmorespaciousharddisksfor
nonvolatile storage. The resulting space constraint is one reason why mobile
operating-systemdesignersavoidswapping.Otherreasonsincludethelimited
numberofwritesthatflashmemorycantoleratebeforeitbecomesunreliable
and the poor throughput between main memory and flash memory in these
devices.378 Chapter9 MainMemory
a
bbb
process cc page out 0 1 2 3
A
d 4 b 5 c 6 e 7
ee
8 9 10 11
12 13 14 15
ff
g page in 16 17 f 18 h19 j
process
hhh
B 20 21 22 23
i
jjj
backing store
main
memory
Figure9.20 Swappingwithpaging.
Insteadofusingswapping,whenfreememoryfallsbelowacertainthresh-
old, Apple’s iOS asks applications to voluntarily relinquish allocated mem-
ory.Read-onlydata(suchascode)areremovedfrommainmemoryandlater
reloadedfromflashmemoryifnecessary.Datathathavebeenmodified(such
asthestack)areneverremoved.However,anyapplicationsthatfailtofreeup
sufficientmemorymaybeterminatedbytheoperatingsystem.
Androidadoptsa strategysimilarto that used byiOS. It may terminatea
processifinsufficientfreememoryisavailable.However,beforeterminatinga
process,Androidwritesitsapplicationstatetoflashmemorysothatitcanbe
quicklyrestarted.
Becauseoftheserestrictions,developersformobilesystemsmustcarefully
allocate and release memory to ensure that their applications do not use too
muchmemoryorsufferfrommemoryleaks.
SYSTEMPERFORMANCEUNDERSWAPPING
Althoughswappingpagesismoreefficientthanswappingentireprocesses,
whenasystemisundergoinganyformofswapping,itisoftenasignthereare
more active processes than available physical memory. There are generally
twoapproachesforhandlingthissituation:(1)terminatesomeprocesses,or
(2)getmorephysicalmemory!9.6 Example:Intel32-and64-bitArchitectures 379
9.6 Example: Intel 32- and 64-bit Architectures
ThearchitectureofIntelchipshasdominatedthepersonalcomputerlandscape
for decades. The 16-bit Intel 8086 appeared in the late 1970s and was soon
followedbyanother16-bitchip—theIntel8088—whichwasnotableforbeing
the chip used in the original IBM PC. Intel later produced a series of 32-bit
chips—the IA-32—which included the family of 32-bit Pentium processors.
More recently, Intel has produced a series of 64-bit chips based on the x86-64
architecture.Currently,allthemostpopularPCoperatingsystemsrunonIntel
chips,includingWindows,macOS,andLinux(althoughLinux,ofcourse,runs
on several other architectures as well). Notably, however, Intel’s dominance
hasnotspreadtomobilesystems,wheretheARMarchitecturecurrentlyenjoys
considerablesuccess(seeSection9.7).
In this section, we examine address translation for both IA-32 and x86-64
architectures.Beforeweproceed,however,itisimportanttonotethatbecause
Intelhasreleasedseveralversions—aswellasvariations—ofitsarchitectures
over the years, we cannot provide a complete description of the memory-
managementstructureofallitschips.NorcanweprovidealloftheCPUdetails,
as that information is best left to books on computer architecture. Rather, we
presentthemajormemory-managementconceptsoftheseIntelCPUs.
9.6.1 IA-32 Architecture
Memory management in IA-32 systems is divided into two components—
segmentation and paging—and works as follows: The CPU generates logical
addresses, which are given to the segmentation unit. The segmentation unit
produces a linear address for each logical address. The linear address is then
giventothepagingunit,whichinturngeneratesthephysicaladdressinmain
memory.Thus,thesegmentationandpagingunitsformtheequivalentofthe
memory-managementunit(MMU).ThisschemeisshowninFigure9.21.
9.6.1.1 IA-32Segmentation
The IA-32 architecture allows a segment to be as large as 4 GB, and the max-
imum number of segments per process is 16 K. The logical address space of
a process is divided into two partitions. The first partition consists of up to
8 K segments that are private to that process. The second partition consists
of up to 8 K segments that are shared among all the processes. Information
aboutthefirstpartitioniskeptinthelocaldescriptortable(LDT);information
about the second partition is kept in the global descriptor table (GDT). Each
entryintheLDTandGDTconsistsofan8-bytesegmentdescriptorwithdetailed
informationaboutaparticularsegment,includingthebaselocationandlimit
ofthatsegment.
logical linear physical
address segmentation address paging address physical
CPU
unit unit memory
Figure9.21 LogicaltophysicaladdresstranslationinIA-32.380 Chapter9 MainMemory
logical address selector offset
descriptor table
segment descriptor +
32-bit linear address
Figure9.22 IA-32segmentation.
Thelogicaladdressisapair(selector,offset),wheretheselectorisa16-bit
number:
s g p
13 1 2
Here, s designates the segment number, g indicates whether the segment is
in the GDT or LDT, and p deals with protection. The offset is a 32-bit number
specifyingthelocationofthebytewithinthesegmentinquestion.
The machine has six segment registers, allowing six segments to be
addressed at any one time by a process. It also has six 8-byte microprogram
registerstoholdthecorrespondingdescriptorsfromeithertheLDTortheGDT.
ThiscacheletsthePentiumavoidhavingtoreadthedescriptorfrommemory
foreverymemoryreference.
The linear address on the IA-32 is 32 bits long and is formed as follows.
The segment register points to the appropriate entry in the LDT or GDT. The
base and limitinformation about the segment inquestionisused togenerate
a linear address. First, the limit is used to check for address validity. If the
address is not valid, a memory fault is generated, resulting in a trap to the
operatingsystem.Ifitisvalid,thenthevalueoftheoffsetisaddedtothevalue
ofthebase,resultingina32-bitlinearaddress.ThisisshowninFigure9.22.In
thefollowingsection,wediscusshowthepagingunitturnsthislinearaddress
intoaphysicaladdress.
9.6.1.2 IA-32Paging
TheIA-32architectureallowsapagesizeofeither4KBor4MB.For4-KBpages,
IA-32usesatwo-levelpagingschemeinwhichthedivisionofthe32-bitlinear
addressisasfollows:
page number page offset
p p d
1 2
10 10 129.6 Example:Intel32-and64-bitArchitectures 381
(linear address)
page directory page table offset
31 2221 1211 0
page 4-KB
table page
page
directory
CR3
4-MB
register
page
page directory offset
31 2221 0
Figure9.23 PagingintheIA-32architecture.
The address-translation scheme for this architecture is similar to the scheme
showninFigure9.16.TheIA-32addresstranslationisshowninmoredetailin
Figure 9.23. The 10 high-order bits reference an entry in the outermost page
table, which IA-32 terms the page directory. (The CR3 register points to the
page directoryfor the current process.)The page directoryentry points to an
innerpagetablethatisindexedbythecontentsoftheinnermost10bitsinthe
linear address. Finally, the low-order bits 0–11 refer to the offset in the 4-KB
pagepointedtointhepagetable.
One entry in the page directory is the Page Size flag, which—if set—
indicates that the size of the page frame is 4 MB and not the standard 4 KB.
If this flag is set, the page directory points directly to the 4-MB page frame,
bypassingtheinnerpagetable;andthe22low-orderbitsinthelinearaddress
refertotheoffsetinthe4-MBpageframe.
To improve the efficiency of physical memory use, IA-32 page tables can
be swapped to disk. In this case, an invalid bit is used in the page directory
entrytoindicatewhetherthetabletowhichtheentryispointingisinmemory
or on disk. If the table is on disk, the operating system can use the other 31
bitstospecifythedisklocationofthetable.Thetablecanthenbebroughtinto
memoryondemand.
As software developers began to discover the 4-GB memory limitations
of 32-bit architectures, Intel adopted a page address extension (PAE), which
allows32-bitprocessorstoaccessaphysicaladdressspacelargerthan4GB.The
fundamentaldifferenceintroducedbyPAEsupportwasthatpagingwentfrom
a two-level scheme (as shown in Figure 9.23) to a three-level scheme, where
thetoptwobitsrefertoapagedirectorypointertable.Figure9.24illustrates
aPAEsystemwith4-KBpages.(PAEalsosupports2-MBpages.)
PAEalsoincreasedthepage-directoryandpage-tableentriesfrom32to64
bitsinsize,whichallowedthebaseaddressofpagetablesandpageframesto382 Chapter9 MainMemory
page directory page table offset
313029 2120 1211 0
4-KB
page
CR3
register page directory page page
pointer table directory table
Figure9.24 Pageaddressextensions.
extendfrom20to24bits.Combinedwiththe12-bitoffset,addingPAEsupport
to IA-32 increased the address space to 36 bits, which supports up to 64 GB
of physical memory. It is important to note that operating system support
is required to use PAE. Both Linux and macOS support PAE. However, 32-bit
versionsofWindowsdesktopoperatingsystemsstillprovidesupportforonly
4GBofphysicalmemory,evenifPAEisenabled.
9.6.2 x86-64
Intel has had an interesting history of developing 64-bit architectures. Its ini-
tial entry was the IA-64 (later named Itanium) architecture, but that architec-
ture was not widelyadopted. Meanwhile, another chip manufacturer—AMD
— began developing a 64-bit architecture known as x86-64 that was based
on extending the existing IA-32 instruction set. The x86-64 supported much
larger logical and physical address spaces, as well as several other architec-
tural advances. Historically, AMD had often developedchips based on Intel’s
architecture, but now the roles were reversed as Intel adopted AMD’s x86-64
architecture.Indiscussingthisarchitecture,ratherthanusingthecommercial
namesAMD64andIntel64,wewillusethemoregeneraltermx86-64.
Support for a 64-bit address space yields an astonishing 264 bytes of
addressable memory—a number greater than 16 quintillion(or 16 exabytes).
However,eventhough64-bitsystemscanpotentiallyaddressthismuchmem-
ory, in practice far fewer than 64 bits are used for address representation in
current designs. The x86-64 architecture currently provides a 48-bit virtual
address with support for page sizes of 4 KB, 2 MB, or 1 GB using four levels
ofpaginghierarchy.TherepresentationofthelinearaddressappearsinFigure
9.25.BecausethisaddressingschemecanusePAE,virtualaddressesare48bits
insizebutsupport52-bitphysicaladdresses(4,096terabytes).
page map page directory page page
unused level 4 pointer table directory table offset
6633 4847 39 38 3029 2120 1211 0
Figure9.25 x86-64linearaddress.9.7 Example:ARMv8Architecture 383
9.7 Example: ARMv8 Architecture
AlthoughIntelchipshavedominatedthepersonalcomputermarketformore
than 30 years, chips for mobile devices such as smartphones and tablet com-
putersofteninsteadrun onARM processors.Interestingly,whereasIntelboth
designs and manufactures chips, ARM only designs them. It then licenses
its architectural designs to chip manufacturers. Apple has licensed the ARM
designforitsiPhoneandiPadmobiledevices,andmostAndroid-basedsmart-
phones use ARM processors as well. In addition to mobile devices, ARM also
providesarchitecturedesignsforreal-timeembeddedsystems.Becauseofthe
abundance of devicesthat run on the ARM architecture, over 100 billion ARM
processors have been produced,making it the most widely used architecture
whenmeasuredinthequantityofchipsproduced.Inthissection,wedescribe
the64-bitARMv8architecture.
The ARMv8 has three different translation granules: 4 KB, 16 KB, and 64
KB. Each translation granule provides different page sizes, as well as larger
sectionsofcontiguousmemory,knownasregions.Thepageandregionsizes
forthedifferenttranslationgranulesareshownbelow:
TranslationGranuleSize PageSize RegionSize
4KB 4KB 2MB,1GB
16KB 16KB 32MB
64KB 64KB 512MB
For 4-KB and 16-KB granules, up to four levels of paging may be used,
with up to three levels of paging for 64-KB granules. Figure 9.26 illustrates
the ARMv8 addressstructure for the 4-KB translation granule with up to four
levelsofpaging.(NoticethatalthoughARMv8isa64-bitarchitecture,only48
bits are currently used.) The four-level hierarchical paging structure for the
4-KB translation granule is illustrated in Figure 9.27. (The TTBR register is the
translation table base register and points to the level 0 table for the current
thread.)
Ifallfourlevelsareused,theoffset(bits0–11 inFigure9.26)referstothe
offsetwithina4-KBpage.However,noticethatthetableentriesforlevel1and
64-BITCOMPUTING
Historyhastaughtusthateventhoughmemorycapacities,CPUspeeds,and
similar computer capabilities seem large enough to satisfy demand for the
foreseeable future, the growth of technology ultimately absorbs available
capacities,andwefindourselvesinneedofadditionalmemoryorprocessing
power,oftensoonerthanwethink.Whatmightthefutureoftechnologybring
thatwouldmakea64-bitaddressspaceseemtoosmall?384 Chapter9 MainMemory
level 0 level 1 level 2 level 3
unused index index index index offset
6633 48 47 39 38 30 29 2120 1211 0
Figure9.26 ARM4-KBtranslationgranule.
level 2 may refer either to another table or to a 1-GB region (level-1 table) or
2-MB region(level-2table).As an example,if the level-1table refersto a1-GB
regionratherthanalevel-2table,thelow-order30bits(bits0–29inFigure9.26)
are used as an offset into this 1-GB region. Similarly,if the level-2table refers
toa2-MBregionratherthanalevel-3table,thelow-order21bits(bits0–20in
Figure9.26)refertotheoffsetwithinthis2-MBregion.
The ARM architecture also supports two levels of TLBs. At the inner level
are two micro TLBs—a TLB for data and another for instructions. The micro
TLB supports ASIDs as well. At the outer level is a single main TLB. Address
translationbeginsatthemicro-TLBlevel.Inthecaseofamiss,themainTLBis
thenchecked.IfbothTLBsyieldmisses,apagetablewalkmustbeperformed
inhardware.
9.8 Summary
• Memory is central to the operation of a modern computer system and
consistsofalargearrayofbytes,eachwithitsownaddress.
• Onewaytoallocateanaddressspacetoeachprocessisthroughtheuseof
baseandlimitregisters.Thebaseregisterholdsthesmallestlegalphysical
memoryaddress,andthelimitspecifiesthesizeoftherange.
level 0 level 1 level 2 level 3
index index index index offset
level 3
table
level 2
table
level 1 4-KB
level 0 table page
table
TTBR
register
1-GB 2-MB
region region
Figure9.27 ARMfour-levelhierarchicalpaging.PracticeExercises 385
• Binding symbolic address references to actual physical addresses may
occurduring(1)compile,(2)load,or(3)executiontime.
• An address generated by the CPU is known as a logical address, which
the memory management unit (MMU) translates to a physical address in
memory.
• Oneapproachtoallocatingmemoryistoallocatepartitionsofcontiguous
memoryofvaryingsizes.Thesepartitionsmaybeallocatedbasedonthree
possiblestrategies:(1)firstfit,(2)bestfit,and(3)worstfit.
• Modernoperatingsystemsusepagingtomanagememory.Inthisprocess,
physical memory is divided into fixed-sized blocks called frames and
logicalmemoryintoblocksofthesamesizecalledpages.
• When paging is used, a logical address is divided into two parts: a page
numberandapageoffset.Thepagenumberservesasanindexintoaper-
processpagetablethatcontainstheframeinphysicalmemorythatholds
thepage.Theoffsetisthespecificlocationintheframebeingreferenced.
• Atranslationlook-asidebuffer(TLB)isahardwarecacheofthepagetable.
EachTLBentrycontainsapagenumberanditscorrespondingframe.
• UsingaTLBinaddresstranslationforpagingsystemsinvolvesobtaining
thepagenumberfromthelogicaladdressandcheckingiftheframeforthe
pageisintheTLB.Ifitis,theframeisobtainedfromtheTLB.Iftheframe
isnotpresentintheTLB,itmustberetrievedfromthepagetable.
• Hierarchicalpaginginvolvesdividingalogicaladdressintomultipleparts,
each referring to different levels of page tables. As addresses expand
beyond 32bits,thenumber ofhierarchicallevelsmaybecomelarge.Two
strategies that address this problem are hashed page tables and inverted
pagetables.
• Swappingallowsthesystemtomovepagesbelongingtoaprocesstodisk
toincreasethedegreeofmultiprogramming.
• The Intel 32-bit architecture has two levels of page tables and supports
either 4-KB or 4-MB page sizes. This architecture also supports page-
address extension, which allows 32-bit processors to access a physical
address space larger than 4 GB. The x86-64 and ARMv9 architectures are
64-bitarchitecturesthatusehierarchicalpaging.
Practice Exercises
9.1 Nametwodifferencesbetweenlogicalandphysicaladdresses.
9.2 Whyarepagesizesalwayspowersof2?
9.3 Considerasysteminwhichaprogramcanbeseparatedintotwoparts:
codeanddata.TheCPUknowswhetheritwantsaninstruction(instruc-
tionfetch)ordata(datafetchorstore).Therefore,twobase–limitregister
pairsareprovided:oneforinstructionsandonefordata.Theinstruction386 Chapter9 MainMemory
base–limit registerpair is automatically read-only,so programs can be
shared among different users. Discuss the advantages and disadvan-
tagesofthisscheme.
9.4 Consider a logical address space of 64 pages of 1,024 words each,
mappedontoaphysicalmemoryof32frames.
a. Howmanybitsarethereinthelogicaladdress?
b. Howmanybitsarethereinthephysicaladdress?
9.5 Whatistheeffectofallowingtwoentriesinapagetabletopointtothe
same page frame in memory? Explain how this effect could be used to
decreasetheamountoftimeneededtocopyalargeamountofmemory
fromoneplacetoanother.Whateffectwouldupdatingsomebyteonone
pagehaveontheotherpage?
9.6 Given six memory partitions of 300 KB, 600 KB, 350 KB, 200 KB, 750 KB,
and 125 KB (in order), how would the first-fit, best-fit, and worst-fit
algorithms place processes of size 115 KB, 500 KB, 358 KB, 200 KB, and
375KB(inorder)?
9.7 Assuming a 1-KB page size, what are the page numbers and offsets for
thefollowingaddressreferences(providedasdecimalnumbers):
a. 3085
b. 42095
c. 215201
d. 650000
e. 2000001
9.8 The BTV operating system has a 21-bit virtual address, yet on certain
embedded devices, it has only a 16-bit physical address. It also has a
2-KBpagesize.Howmanyentriesarethereineachofthefollowing?
a. Aconventional,single-levelpagetable
b. Aninvertedpagetable
WhatisthemaximumamountofphysicalmemoryintheBTVoperating
system?
9.9 Consider a logical address space of 256 pages with a 4-KB page size,
mappedontoaphysicalmemoryof64frames.
a. Howmanybitsarerequiredinthelogicaladdress?
b. Howmanybitsarerequiredinthephysicaladdress?
9.10 Consideracomputersystemwitha32-bitlogicaladdressand4-KBpage
size.Thesystemsupportsupto512MBofphysicalmemory.Howmany
entriesarethereineachofthefollowing?
a. Aconventional,single-levelpagetable
b. AninvertedpagetableBibliography 387
Further Reading
The concept of paging can be credited to the designers of the Atlas system,
which has been described by [Kilburn et al. (1961)] and by [Howarth et al.
(1961)].
[Hennessy and Patterson (2012)] explain the hardware aspects of TLBs,
caches,andMMUs.[JacobandMudge(2001)]describetechniquesformanaging
theTLB.[Fangetal.(2001)]evaluatesupportforlargepages.
PAEsupportforWindowssystems.isdiscussedinhttp://msdn.microsoft.co
m/en-us/library/windows/hardware/gg487512.aspxAnoverviewof the ARM
architectureisprovidedinhttp://www.arm.com/products/processors/cortex-
a/cortex-a9.php
Bibliography
[Fangetal.(2001)] Z.Fang,L.Zhang,J.B.Carter,W.C.Hsieh,andS.A.McKee,
“ReevaluatingOnlineSuperpagePromotionwithHardwareSupport”,Proceed-
ings of the International Symposium on High-Performance Computer Architecture,
Volume50,Number5(2001).
[HennessyandPatterson(2012)] J.HennessyandD.Patterson,ComputerArchi-
tecture:AQuantitativeApproach,FifthEdition,MorganKaufmann(2012).
[Howarthetal.(1961)] D. J. Howarth, R. B. Payne, and F. H. Sumner, “The
Manchester University Atlas Operating System, Part II: User’s Description”,
ComputerJournal,Volume4,Number3(1961),pages226–229.
[JacobandMudge(2001)] B.JacobandT.Mudge,“UniprocessorVirtualMem-
oryWithoutTLBs”,IEEETransactionsonComputers,Volume50,Number5(2001).
[Kilburnetal.(1961)] T.Kilburn,D.J.Howarth,R.B.Payne,andF.H.Sumner,
“TheManchesterUniversityAtlasOperatingSystem,PartI:InternalOrganiza-
tion”,ComputerJournal,Volume4,Number3(1961),pages222–225.Exercises EX-32
Chapter 9 Exercises
9.11 Explainthedifferencebetweeninternalandexternalfragmentation.
9.12 Consider the following process for generating binaries. A compiler is
usedtogeneratetheobjectcodeforindividualmodules,andalinkeris
usedtocombinemultipleobjectmodulesintoasingleprogrambinary.
Howdoesthelinkerchangethebindingofinstructionsanddatatomem-
oryaddresses?Whatinformationneedstobepassedfromthecompiler
tothelinkertofacilitatethememory-bindingtasksofthelinker?
9.13 Givensixmemorypartitionsof100MB,170MB,40MB,205MB,300MB,
and 185 MB (in order), how would the first-fit, best-fit, and worst-fit
algorithms place processes of size 200 MB, 15 MB, 185 MB, 75 MB, 175
MB, and80MB(inorder)?Indicatewhich—if any—requestscannot be
satisfied. Comment on how efficiently each of the algorithms manages
memory.
9.14 Most systems allow a program to allocate more memory to its address
space during execution. Allocation of data in the heap segments of
programsisanexampleofsuchallocatedmemory.Whatisrequiredto
supportdynamicmemoryallocationinthefollowingschemes?
a. Contiguousmemoryallocation
b. Paging
9.15 Comparethememoryorganizationschemesofcontiguousmemoryallo-
cationandpagingwithrespecttothefollowingissues:
a. Externalfragmentation
b. Internalfragmentation
c. Abilitytosharecodeacrossprocesses
9.16 On asystem with paging, a process cannot access memory that it does
not own. Why? How could the operating system allow access to addi-
tionalmemory?Whyshoulditorshoulditnot?
9.17 ExplainwhymobileoperatingsystemssuchasiOSandAndroiddonot
supportswapping.
9.18 Although Android does not support swapping on its boot disk, it is
possibletosetupaswapspaceusingaseparateSDnonvolatilememory
card.WhywouldAndroiddisallowswappingonitsbootdiskyetallow
itonasecondarydisk?
9.19 Explainwhyaddress-spaceidentifiers(ASIDs)areusedinTLBs.
9.20 Program binaries in many systems are typically structured as follows.
Codeisstoredstartingwithasmall,fixedvirtualaddress,suchas0.The
codesegmentisfollowedbythedatasegment,whichisusedforstoring
theprogramvariables.Whentheprogramstartsexecuting,thestack is
allocated at the other end of the virtual address space and is allowed
togrowtowardlowervirtualaddresses.Whatisthesignificanceofthis
structureforthefollowingschemes?EX-33
a. Contiguousmemoryallocation
b. Paging
9.21 Assuming a 1-KB page size, what are the page numbers and offsets for
thefollowingaddressreferences(providedasdecimalnumbers)?
a. 21205
b. 164250
c. 121357
d. 16479315
e. 27253187
9.22 The MPV operating system is designed for embedded systems and has
a24-bitvirtualaddress,a20-bitphysicaladdress,anda4-KBpagesize.
Howmanyentriesarethereineachofthefollowing?
a. Aconventional,single-levelpagetable
b. Aninvertedpagetable
WhatisthemaximumamountofphysicalmemoryintheMPVoperating
system?
9.23 Consider a logical address space of 2,048 pages with a 4-KB page size,
mappedontoaphysicalmemoryof512frames.
a. Howmanybitsarerequiredinthelogicaladdress?
b. Howmanybitsarerequiredinthephysicaladdress?
9.24 Consideracomputersystemwitha32-bitlogicaladdressand8-KBpage
size. The system supports up to 1 GB of physical memory. How many
entriesarethereineachofthefollowing?
a. Aconventional,single-levelpagetable
b. Aninvertedpagetable
9.25 Considerapagingsystemwiththepagetablestoredinmemory.
a. If a memory reference takes 50 nanoseconds, how long does a
pagedmemoryreferencetake?
b. If we add TLBs, and if 75 percent of all page-table references
are found in the TLBs, what is the effective memory reference
time?(Assume that finding a page-table entry in the TLBs takes 2
nanoseconds,iftheentryispresent.)
9.26 Whatisthepurposeofpagingthepagetables?
9.27 ConsidertheIA-32address-translationschemeshowninFigure9.22.
a. Describe all the steps taken by the IA-32 in translating a logical
addressintoaphysicaladdress.
b. Whataretheadvantagestotheoperatingsystemofhardwarethat
providessuchcomplicatedmemorytranslation?Exercises EX-34
c. Arethereanydisadvantagestothisaddress-translationsystem?If
so, what are they? If not, why is this scheme not used by every
manufacturer?ProgrammingProjects P-48
Programming Problems
9.28 Assumethatasystemhasa32-bitvirtualaddresswitha4-KBpagesize.
Write a C program that is passed a virtual address (in decimal) on the
command line and have it output the page number and offset for the
givenaddress.Asanexample,yourprogramwouldrunasfollows:
./addresses 19986
Yourprogramwouldoutput:
The address 19986 contains:
page number = 4
offset = 3602
Writing this program will require using the appropriate data type to
store32bits.Weencourageyoutouseunsigneddatatypesaswell.
Programming Projects
Contiguous Memory Allocation
InSection9.2,wepresenteddifferentalgorithmsforcontiguousmemoryallo-
cation. This project will involvemanaging a contiguous region of memory of
sizeMAXwhereaddressesmayrangefrom0...MAX−1.Yourprogrammust
respondtofourdifferentrequests:
1. Requestforacontiguousblockofmemory
2. Releaseofacontiguousblockofmemory
3. Compactunusedholesofmemoryintoonesingleblock
4. Reporttheregionsoffreeandallocatedmemory
Your program will be passed the initial amount of memory at startup. For
example, the following initializes the program with 1 MB (1,048,576 bytes) of
memory:
./allocator 1048576
Onceyourprogramhasstarted,itwillpresenttheuserwiththefollowing
prompt:
allocator>
It will then respond to the following commands: RQ (request), RL (release), C
(compact),STAT(statusreport),andX(exit).
Arequestfor40,000byteswillappearasfollows:
allocator>RQ P0 40000 WP-49 Chapter9 MainMemory
The first parameter to the RQ command is the new process that requires the
memory,followedbytheamountofmemorybeingrequested,andfinallythe
strategy.(Inthissituation,“W”referstoworstfit.)
Similarly,areleasewillappearas:
allocator>RL P0
ThiscommandwillreleasethememorythathasbeenallocatedtoprocessP0.
Thecommandforcompactionisenteredas:
allocator>C
Thiscommandwillcompactunusedholesofmemoryintooneregion.
Finally, the STAT command for reporting the status of memory is entered
as:
allocator>STAT
Giventhiscommand,yourprogramwillreporttheregionsofmemorythatare
allocatedandtheregionsthatareunused.Forexample,onepossiblearrange-
mentofmemoryallocationwouldbeasfollows:
Addresses [0:315000] Process P1
Addresses [315001: 512500] Process P3
Addresses [512501:625575] Unused
Addresses [625575:725100] Process P6
Addresses [725001] . . .
Allocating Memory
Your program will allocate memory using one of the three approaches high-
lighted in Section 9.2.2, depending on the flag that is passed to the RQ com-
mand.Theflagsare:
• F—firstfit
• B—bestfit
• W—worstfit
Thiswillrequirethatyourprogramkeeptrackofthedifferentholesrepre-
sentingavailablememory.Whenarequestformemoryarrives,itwillallocate
the memory from one of the available holes based on the allocation strategy.
If there is insufficient memory to allocate to a request, it will output an error
messageandrejecttherequest.
Your program will also need to keep track of which region of memory
has been allocated to which process. This is necessary to support the STAT
commandandisalsoneededwhenmemoryisreleasedviatheRLcommand,
astheprocessreleasingmemoryispassedtothiscommand.Ifapartitionbeing
releasedisadjacenttoanexistinghole,besuretocombinethetwoholesintoa
singlehole.Bibliography P-50
Compaction
IftheuserenterstheCcommand,yourprogramwillcompactthesetofholes
into one larger hole. For example, if you have four separate holes of size 550
KB,375KB,1,900KB,and4,500KB,yourprogramwillcombinethesefourholes
intoonelargeholeofsize7,325KB.
There are several strategies for implementing compaction, one of which
is suggested in Section 9.2.3. Be sure to update the beginning address of any
processesthathavebeenaffectedbycompaction.10
CHAPTER
Virtual
Memory
In Chapter 9, we discussed various memory-management strategies used in
computer systems. All these strategies have the same goal: to keep many
processes in memory simultaneously to allow multiprogramming. However,
theytendtorequirethatanentireprocessbeinmemorybeforeitcanexecute.
Virtual memoryisatechniquethatallows theexecutionof processesthat
arenotcompletelyinmemory.Onemajoradvantageofthisschemeisthatpro-
gramscanbelargerthanphysicalmemory.Further,virtualmemoryabstracts
main memory into an extremely large, uniform array of storage, separating
logical memory as viewed by the programmer from physical memory. This
technique frees programmers from the concerns of memory-storage limita-
tions. Virtual memory also allows processes to share files and libraries, and
toimplementsharedmemory.Inaddition,itprovidesanefficientmechanism
for process creation. Virtual memory is not easy to implement, however, and
may substantially decrease performance if it is used carelessly. In this chap-
ter, we provide a detailed overview of virtual memory, examine how it is
implemented,andexploreitscomplexityandbenefits.
CHAPTER OBJECTIVES
• Definevirtualmemoryanddescribeitsbenefits.
• Illustratehowpagesareloadedintomemoryusingdemandpaging.
• ApplytheFIFO,optimal,andLRUpage-replacementalgorithms.
• Describe the working set of a process, and explain how it is related to
programlocality.
• DescribehowLinux,Windows10,andSolarismanagevirtualmemory.
• Design a virtual memory manager simulation in the C programming lan-
guage.
10.1 Background
The memory-management algorithms outlined in Chapter 9 are necessary
because of one basic requirement:the instructions being executed must be in
389390 Chapter10 VirtualMemory
physical memory. The first approach to meeting this requirement is to place
theentirelogicaladdressspaceinphysicalmemory.Dynamiclinkingcanhelp
to ease this restriction, but it generally requires special precautions and extra
workbytheprogrammer.
The requirementthat instructions must be in physical memory to be exe-
cutedseemsbothnecessaryandreasonable;butitisalsounfortunate,sinceit
limitsthesizeofaprogramtothesizeofphysicalmemory.Infact,anexami-
nationofrealprogramsshowsusthat,inmanycases,theentireprogramisnot
needed.Forinstance,considerthefollowing:
• Programsoftenhavecodetohandleunusualerrorconditions.Sincethese
errorsseldom,ifever,occurinpractice,thiscodeisalmostneverexecuted.
• Arrays,lists,andtablesareoftenallocatedmorememorythantheyactu-
allyneed.Anarray maybe declared100by 100elements,eventhough it
isseldomlargerthan10by10elements.
• Certainoptionsandfeaturesofaprogrammaybeusedrarely.Forinstance,
theroutinesonU.S.governmentcomputersthatbalancethebudgethave
notbeenusedinmanyyears.
Even in those cases where the entire program is needed, it may not all be
neededatthesametime.
The ability to execute a program that is only partially in memory would
confermanybenefits:
• A program would no longer be constrained by the amount of physical
memory that is available. Users would be able to write programs for an
extremelylargevirtualaddressspace,simplifyingtheprogrammingtask.
• Because each program could take less physical memory, more programs
couldberunatthesametime,withacorrespondingincreaseinCPUutiliza-
tionandthroughputbutwithnoincreaseinresponsetimeorturnaround
time.
• Less I/O would be needed to load or swap portions of programs into
memory,soeachprogramwouldrunfaster.
Thus,runningaprogramthatisnotentirelyinmemorywouldbenefitboththe
systemanditsusers.
Virtual memory involves the separation of logical memory as perceived
by developers from physical memory. This separation allows an extremely
large virtual memory to be provided for programmers when only a smaller
physicalmemoryisavailable(Figure10.1).Virtualmemorymakesthetaskof
programmingmucheasier,becausetheprogrammernolongerneedstoworry
about the amount of physical memory available; she can concentrate instead
onprogrammingtheproblemthatistobesolved.
Thevirtualaddressspaceofaprocessreferstothelogical(orvirtual)view
of how a process is stored in memory. Typically, this view is that a process
beginsatacertainlogicaladdress—say,address0—and existsincontiguous
memory, as shown in Figure 10.2. Recall from Chapter 9, though, that in fact
physical memory is organized in page frames and that the physical page
frames assigned to a process may not be contiguous. It is up to the memory-10.1 Background 391
page 0
page 1
page 2
•
•
•
memory
map
page v physical backing store
memory
virtual
memory
Figure10.1 Diagramshowingvirtualmemorythatislargerthanphysicalmemory.
management unit (MMU) to map logical pages to physical page frames in
memory.
NoteinFigure10.2thatweallowtheheaptogrowupwardinmemoryas
itisusedfor dynamicmemoryallocation.Similarly,weallowfor thestackto
growdownwardinmemorythroughsuccessivefunctioncalls.Thelargeblank
space (or hole) between the heap and the stack is part of the virtual address
space but will require actual physical pages only if the heap or stack grows.
Virtualaddressspacesthatincludeholesareknownassparseaddressspaces.
Usingasparseaddressspaceisbeneficialbecausetheholescanbefilledasthe
stack or heap segments grow or if we wish to dynamically link libraries (or
possiblyothersharedobjects)duringprogramexecution.
max
stack
heap
data
text
0
Figure10.2 Virtualaddressspaceofaprocessinmemory.392 Chapter10 VirtualMemory
stack stack
shared
shared library pages shared library
heap heap
data data
text text
Figure10.3 Sharedlibraryusingvirtualmemory.
In addition to separating logical memory from physical memory, virtual
memory allows files and memory to be shared by two or more processes
throughpagesharing(Section9.3.4).Thisleadstothefollowingbenefits:
• System libraries such as the standard C library can be shared by several
processes through mapping of the shared object into a virtual address
space. Although each process considers the libraries to be part of its vir-
tualaddressspace,theactualpageswherethelibrariesresideinphysical
memoryaresharedbyalltheprocesses(Figure10.3).Typically,alibraryis
mappedread-onlyintothespaceofeachprocessthatislinkedwithit.
• Similarly, processes can share memory. Recall from Chapter 3 that two
or more processes can communicate through the use of shared memory.
Virtualmemoryallowsoneprocesstocreatearegionofmemorythatitcan
share with another process. Processessharing this regionconsider it part
oftheirvirtualaddressspace,yettheactualphysicalpagesofmemoryare
shared,muchasisillustratedinFigure10.3.
• Pagescanbesharedduringprocesscreationwiththefork()systemcall,
thusspeedingupprocesscreation.
We further explore these—and other—benefits of virtual memory later in
thischapter.First,though,wediscussimplementingvirtualmemorythrough
demandpaging.
10.2 Demand Paging
Considerhowanexecutableprogrammightbeloadedfromsecondarystorage
into memory. One option is to load the entire program in physical memory
at program execution time. However, a problem with this approach is that10.2 DemandPaging 393
we may not initially need the entireprogram in memory.Suppose a program
startswithalistofavailableoptionsfromwhichtheuseristoselect.Loading
theentireprogramintomemoryresultsinloadingtheexecutablecodeforall
options, regardless of whether or not an option is ultimately selected by the
user.
Analternativestrategyistoloadpagesonlyastheyareneeded.Thistech-
niqueisknownasdemandpagingandiscommonlyusedinvirtualmemory
systems. With demand-paged virtual memory, pages are loaded only when
they are demanded during program execution. Pages that are never accessed
arethusneverloadedintophysicalmemory.Ademand-pagingsystemissimi-
lartoapagingsystemwithswapping(Section9.5.2)whereprocessesresidein
secondarymemory(usuallyanHDDorNVMdevice).Demandpagingexplains
oneoftheprimarybenefitsofvirtualmemory—byloadingonlytheportions
ofprogramsthatareneeded,memoryisusedmoreefficiently.
10.2.1 Basic Concepts
Thegeneralconceptbehinddemandpaging,asmentioned,istoloadapagein
memoryonlywhenitisneeded.Asaresult,whileaprocessisexecuting,some
pageswillbeinmemory,andsomewillbeinsecondarystorage.Thus,weneed
some form of hardware support to distinguish between the two. The valid–
invalidbitschemedescribedinSection9.3.3canbeusedforthispurpose.This
0
1
0 A 2
valid–invalid
1 B frame bit 3
2 C 0 4 v 4 A
3 D 1 i 5
2 6 v
4 E 6 C A B
3 i
5 F 4 i 7
5 9 v C D E
6 G 8
6 i
7 H 7 i 9 F F G H
page table
logical 10
memory
11
12
backing store
13
14
15
physical memory
Figure10.4 Pagetablewhensomepagesarenotinmainmemory.394 Chapter10 VirtualMemory
time,however,whenthebitissetto“valid,”theassociatedpageisbothlegal
and in memory. If the bit is set to “invalid,” the page either is not valid (that
is,notinthelogicaladdressspaceoftheprocess)orisvalidbutiscurrentlyin
secondarystorage.Thepage-tableentryforapagethatisbroughtintomemory
is set as usual, but the page-table entry for a page that is not currently in
memory is simply marked invalid. This situation is depicted in Figure 10.4.
(Notice that marking a page invalid will have no effect if the process never
attemptstoaccessthatpage.)
Butwhathappensiftheprocesstriestoaccessapagethatwasnotbrought
intomemory?Accesstoapagemarkedinvalidcausesapagefault.Thepaging
hardware,intranslatingtheaddressthroughthepagetable,willnoticethatthe
invalidbitisset,causingatraptotheoperatingsystem.Thistrapistheresult
of the operating system’s failure to bring the desired page into memory. The
procedureforhandlingthispagefaultisstraightforward(Figure10.5):
1. We check an internal table (usually kept with the process control block)
for this process to determine whether the reference was a valid or an
invalidmemoryaccess.
2. Ifthereferencewasinvalid,weterminatetheprocess.Ifitwasvalidbut
wehavenotyetbroughtinthatpage,wenowpageitin.
3. Wefindafreeframe(bytakingonefromthefree-framelist,forexample).
page is on
3
backing store
operating
system
2
reference
trap
1
load M i
6
restart page table
instruction
free frame
5 4 backing store
reset page bring in
table missing page
physical
memory
Figure10.5 Stepsinhandlingapagefault.10.2 DemandPaging 395
4. Wescheduleasecondarystorageoperationtoreadthedesiredpageinto
thenewlyallocatedframe.
5. Whenthestoragereadiscomplete,wemodifytheinternaltablekeptwith
theprocessandthepagetabletoindicatethatthepageisnowinmemory.
6. We restart the instruction that was interrupted by the trap. The process
cannowaccessthepageasthoughithadalwaysbeeninmemory.
In the extreme case, we can start executing a process with no pages in
memory. When the operating system sets the instruction pointer to the first
instructionoftheprocess,whichisonanon-memory-residentpage,theprocess
immediately faults for the page. After this page is brought into memory, the
process continues to execute, faulting as necessary until every page that it
needs is in memory. At that point, it can execute with no more faults. This
scheme is pure demand paging: never bring a page into memory until it is
required.
Theoretically,some programs could access severalnew pages of memory
with each instruction execution (one page for the instruction and many for
data), possibly causing multiple page faults per instruction. This situation
would result in unacceptable system performance. Fortunately, analysis of
runningprocessesshowsthatthisbehaviorisexceedinglyunlikely.Programs
tendtohavelocalityofreference,describedinSection10.6.1,whichresultsin
reasonableperformancefromdemandpaging.
Thehardwaretosupportdemandpagingisthesameasthehardwarefor
pagingandswapping:
• Page table. This table has the ability to mark an entry invalid through a
valid–invalidbitoraspecialvalueofprotectionbits.
• Secondarymemory.Thismemoryholdsthosepagesthatarenotpresent
in main memory. The secondary memory is usually a high-speed disk or
NVM device. It is known as the swap device, and the section of storage
used for this purpose is known as swap space. Swap-space allocation is
discussedinChapter11.
A crucial requirement for demand paging is the ability to restart any
instruction after a page fault. Because we save the state (registers, condi-
tioncode,instructioncounter)oftheinterruptedprocesswhenthepagefault
occurs, we must be able to restart the process in exactly the same place and
state,exceptthatthedesiredpageisnowinmemoryandisaccessible.Inmost
cases,thisrequirementiseasytomeet.Apagefaultmayoccuratanymemory
reference. If the page fault occurs on the instruction fetch, we can restart by
fetching the instruction again. If a page fault occurs while we are fetching an
operand, we must fetch and decode the instruction again and then fetch the
operand.
Asaworst-caseexample,considerathree-addressinstructionsuchasADD
thecontentofAtoB,placingtheresultinC.Thesearethestepstoexecutethis
instruction:
1. Fetchanddecodetheinstruction(ADD).
2. FetchA.396 Chapter10 VirtualMemory
3. FetchB.
4. AddAandB.
5. StorethesuminC.
IfwefaultwhenwetrytostoreinC(becauseCisinapagenotcurrently
in memory), we will have to get the desired page, bring it in, correct the
page table, and restart the instruction. The restart will require fetching the
instruction again, decoding it again, fetching the two operands again, and
then adding again. However, there is not much repeatedwork (less than one
complete instruction), and the repetition is necessary only when a page fault
occurs.
The major difficulty arises when one instruction may modify several dif-
ferent locations. For example, consider the IBM System 360/370 MVC (move
character) instruction, which can move up to 256 bytes from one location to
another(possiblyoverlapping)location.Ifeitherblock(sourceordestination)
straddles a page boundary, a page fault might occur after the move is par-
tiallydone.Inaddition,ifthesourceanddestinationblocksoverlap,thesource
block may have been modified, in which case we cannot simply restart the
instruction.
This problem can be solved in two different ways. In one solution, the
microcodecomputesandattemptstoaccessbothendsofbothblocks.Ifapage
faultisgoingtooccur,itwillhappenatthisstep,beforeanythingismodified.
Themovecanthentakeplace;weknowthatnopagefaultcanoccur,sinceall
therelevantpagesareinmemory.Theothersolutionusestemporaryregisters
to hold the valuesof overwrittenlocations. If thereis apage fault, all the old
valuesarewrittenbackintomemorybeforethetrapoccurs.Thisactionrestores
memory to its state before the instruction was started, so that the instruction
canberepeated.
Thisisbynomeanstheonlyarchitecturalproblemresultingfromadding
paging to an existing architecture to allow demand paging, but it illustrates
some of the difficulties involved. Paging is added between the CPU and the
memoryinacomputer system.Itshould beentirelytransparenttoaprocess.
Thus,peopleoftenassumethatpagingcanbeaddedtoanysystem.Although
thisassumptionistrueforanon-demand-pagingenvironment,whereapage
fault representsafatal error,itisnot truewhereapagefault meansonly that
anadditionalpagemustbebroughtintomemoryandtheprocessrestarted.
10.2.2 Free-Frame List
When a page fault occurs, the operating system must bring the desired page
fromsecondarystorageintomainmemory.Toresolvepagefaults,mostoper-
ating systems maintain a free-frame list, a pool of free frames for satisfying
suchrequests(Figure10.6).(Freeframesmustalsobeallocatedwhenthestack
or heap segments from a process expand.) Operating systems typically allo-
...
head 7 97 15 126 75
Figure10.6 Listoffreeframes.10.2 DemandPaging 397
cate free frames using a technique known as zero-fill-on-deman . Zero-fill-
on-demandframesare“zeroed-out”beforebeingallocated,thuserasingtheir
previouscontents.(Considerthepotentialsecurityimplicationsofnotclearing
outthecontentsofaframebeforereassigningit.)
Whenasystemstartsup,allavailablememoryisplacedonthefree-frame
list. As free frames are requested(for example,through demand paging), the
sizeofthefree-framelistshrinks.Atsomepoint,thelisteitherfallstozeroor
fallsbelowacertainthreshold,atwhichpointitmustberepopulated.Wecover
strategiesforbothofthesesituationsinSection10.4.
10.2.3 Performance of Demand Paging
Demandpagingcansignificantlyaffecttheperformanceofacomputersystem.
Toseewhy,let’scomputetheeffectiveaccesstimeforademand-pagedmem-
ory.Assumethememory-accesstime,denotedma,is10nanoseconds.Aslong
as we have no page faults, the effective access time is equal to the memory
access time. If, however, a page fault occurs, we must first read the relevant
pagefromsecondarystorageandthenaccessthedesiredword.
Let p be the probability of a page fault (0 ≤ p ≤ 1). We would expect p to
beclosetozero—thatis,wewouldexpecttohaveonlyafewpagefaults.The
effectiveaccesstimeisthen
effectiveaccesstime=(1−p)×ma+p×pagefaulttime.
To compute the effective access time, we must know how much time is
neededto service a page fault. Apage fault causes the following sequence to
occur:
1. Traptotheoperatingsystem.
2. Savetheregistersandprocessstate.
3. Determinethattheinterruptwasapagefault.
4. Checkthatthepagereferencewaslegal,anddeterminethelocationofthe
pageinsecondarystorage.
5. Issueareadfromthestoragetoafreeframe:
a. Waitinaqueueuntilthereadrequestisserviced.
b. Waitforthedeviceseekand/orlatencytime.
c. Beginthetransferofthepagetoafreeframe.
6. Whilewaiting,allocatetheCPUcoretosomeotherprocess.
7. ReceiveaninterruptfromthestorageI/Osubsystem(I/Ocompleted).
8. Save the registers and process state for the other process (if step 6 is
executed).
9. Determinethattheinterruptwasfromthesecondarystoragedevice.
10. Correct the page table and other tables to show that the desiredpage is
nowinmemory.
11. WaitfortheCPUcoretobeallocatedtothisprocessagain.398 Chapter10 VirtualMemory
12. Restoretheregisters,processstate,andnewpagetable,andthenresume
theinterruptedinstruction.
Notallofthesestepsarenecessaryineverycase.Forexample,weareassuming
that, in step 6, the CPU is allocated to another process while the I/O occurs.
This arrangement allows multiprogramming to maintain CPU utilization but
requiresadditionaltimetoresumethepage-faultserviceroutinewhentheI/O
transferiscomplete.
Inanycase,therearethreemajortaskcomponentsofthepage-faultservice
time:
1. Servicethepage-faultinterrupt.
2. Readinthepage.
3. Restarttheprocess.
The first and third tasks can be reduced, with careful coding, to several
hundredinstructions.Thesetasksmaytakefrom1to100microsecondseach.
Let’s consider the case of HDDs being used as the paging device. The page-
switch time will probably be close to 8 milliseconds.(Atypical hard disk has
an average latency of 3 milliseconds, a seek of 5 milliseconds, and a transfer
timeof0.05milliseconds.Thus,the totalpaging timeisabout 8milliseconds,
includinghardwareandsoftwaretime.)Rememberalsothatwearelookingat
onlythedevice-servicetime.Ifaqueueofprocessesiswaitingforthedevice,
we have to add queuing time as we wait for the paging device to be free to
serviceourrequest,increasingevenmorethetimetopagein.
Withanaveragepage-faultservicetimeof8millisecondsandamemory-
accesstimeof200nanoseconds,theeffectiveaccesstimeinnanosecondsis
effectiveaccesstime=(1−p)×(200)+p(8milliseconds)
=(1−p)×200+p×8,000,000
=200+7,999,800×p.
We see, then, that the effective access time is directly proportional to the
page-faultrate.Ifoneaccessoutof1,000causesapagefault,theeffectiveaccess
timeis8.2microseconds.Thecomputerwillbesloweddownbyafactorof40
becauseofdemandpaging!Ifwewantperformancedegradationtobelessthan
10percent,weneedtokeeptheprobabilityofpagefaultsatthefollowinglevel:
220>200+7,999,800×p,
20>7,999,800×p,
p<0.0000025.
Thatis,tokeeptheslowdownduetopagingatareasonablelevel,wecanallow
fewerthatonememoryaccessoutof399,990topage-fault.Insum,itisimpor-
tant to keep the page-fault rate low in a demand-paging system. Otherwise,
theeffectiveaccesstimeincreases,slowingprocessexecutiondramatically.
Anadditionalaspectofdemandpagingisthehandlingandoveralluseof
swapspace.I/Otoswapspaceisgenerallyfasterthanthattothefilesystem.It
isfasterbecauseswapspaceisallocatedinmuchlargerblocks,andfilelookups
andindirectallocationmethodsarenotused(Chapter11).Oneoptionforthe10.3 Copy-on-Write 399
systemtogainbetterpagingthroughputisbycopyinganentirefileimageinto
the swap space at processstartup and thenperformingdemand pagingfrom
the swap space. The obvious disadvantageof this approach isthe copying of
the file image at program start-up. A second option—and one practiced by
severaloperatingsystems,includingLinuxandWindows—istodemand-page
from the file systeminitially but towrite the pages to swap space as they are
replaced.Thisapproachwillensurethatonlyneededpagesarereadfromthe
filesystembutthatallsubsequentpagingisdonefromswapspace.
Some systems attempt to limit the amount of swap space used through
demand paging of binary executable files. Demand pages for such files are
brought directly from the file system. However, when page replacement is
called for, these frames can simply be overwritten (because they are never
modified),and the pages can be read in from the file system again if needed.
Usingthisapproach,thefilesystemitselfservesasthebackingstore.However,
swap space must still be used for pages not associated with a file (known as
anonymous memory); these pages include the stack and heap for a process.
Thismethodappearstobeagoodcompromiseandisusedinseveralsystems,
includingLinuxandBSDUNIX.
As described in Section 9.5.3, mobile operating systems typically do not
support swapping. Instead, these systems demand-page from the file sys-
temand reclaimread-only pages (such as code)from applications ifmemory
becomesconstrained.Suchdatacanbedemand-pagedfromthefilesystemif
it is later needed.Under iOS, anonymous memory pages are never reclaimed
froman applicationunlessthe applicationis terminatedor explicitlyreleases
thememory.InSection10.7,wecovercompressedmemory,acommonlyused
alternativetoswappinginmobilesystems.
10.3 Copy-on-Write
In Section 10.2, we illustrated how a process can start quickly by demand-
paginginthepagecontainingthefirstinstruction.However,processcreation
usingthefork()systemcallmayinitiallybypasstheneedfordemandpaging
by using a technique similar to page sharing (covered in Section 9.3.4). This
techniqueprovidesrapidprocesscreationand minimizesthenumber ofnew
pagesthatmustbeallocatedtothenewlycreatedprocess.
Recallthatthefork()systemcallcreatesachildprocessthatisaduplicate
of its parent. Traditionally, fork() worked by creating a copy of the parent’s
address space for the child, duplicating the pages belonging to the parent.
However,consideringthatmanychildprocessesinvoketheexec()systemcall
immediatelyafter creation, the copying of the parent’s addressspace may be
unnecessary.Instead,wecanuseatechniqueknownascopy-on-write,which
works by allowing the parent and child processes initially to share the same
pages. These shared pages are marked as copy-on-write pages, meaning that
ifeitherprocesswritestoasharedpage,acopyofthesharedpageiscreated.
Copy-on-writeisillustratedinFigures10.7and10.8,whichshowthecontents
ofthephysicalmemorybeforeandafterprocess1modifiespageC.
For example, assume that the child process attempts to modify a page
containing portions of the stack, with the pages set to be copy-on-write. The
operatingsystemwillobtainaframefromthefree-framelistandcreateacopy400 Chapter10 VirtualMemory
physical
process memory process
1 2
page A
page B
page C
Figure10.7 Beforeprocess1modifiespageC.
of this page, mapping it to the address space of the child process. The child
process will then modify its copied page and not the page belonging to the
parentprocess.Obviously,whenthecopy-on-writetechniqueisused,onlythe
pages that are modified by either process are copied; all unmodified pages
can be shared by the parent and child processes. Note, too, that only pages
that can be modified need be marked as copy-on-write. Pages that cannot
be modified (pages containing executable code) can be shared by the parent
and child. Copy-on-write is a common technique used by several operating
systems,includingWindows,Linux,andmacOS.
SeveralversionsofUNIX(includingLinux,macOS,andBSDUNIX)provide
avariationofthefork()systemcall—vfork()(forvirtualmemoryfork)—
that operatesdifferentlyfromfork()withcopy-on-write. Withvfork(),the
parent process is suspended, and the child process uses the address space of
the parent. Because vfork() does not use copy-on-write, if the child process
changes any pages of the parent’s address space, the altered pages will be
visible to the parent once it resumes. Therefore, vfork() must be used with
cautiontoensurethatthechild processdoesnotmodifytheaddressspaceof
theparent.vfork()isintendedtobeusedwhenthechildprocesscallsexec()
immediatelyaftercreation.Becausenocopyingofpagestakesplace,vfork()
physical
process memory process
1 2
page A
page B
page C
copy of page C
Figure10.8 Afterprocess1modifiespageC.10.4 PageReplacement 401
isanextremelyefficientmethodofprocesscreationandissometimesusedto
implementUNIXcommand-lineshellinterfaces.
10.4 Page Replacement
In our earlier discussion of the page-fault rate, we assumed that each page
faultsatmostonce,whenitisfirstreferenced.Thisrepresentationisnotstrictly
accurate,however.Ifaprocessoftenpagesactuallyusesonlyhalfofthem,then
demand paging saves the I/O necessary to load the five pages that are never
used. We could also increase our degree of multiprogramming by running
twice as many processes. Thus, if we had forty frames, we could run eight
processes,ratherthanthefourthatcouldrunifeachrequiredtenframes(five
ofwhichwereneverused).
If we increase our degree of multiprogramming, we are over-allocating
memory.Ifwerunsixprocesses,eachofwhichistenpagesinsizebutactually
uses only five pages, we have higher CPU utilization and throughput, with
ten frames to spare. It is possible, however, that each of these processes, for
aparticulardataset,maysuddenlytrytousealltenofitspages,resultingina
needforsixtyframeswhenonlyfortyareavailable.
Further,considerthatsystemmemoryisnotusedonlyforholdingprogram
pages.BuffersforI/Oalsoconsumeaconsiderableamountofmemory.Thisuse
canincreasethestrainonmemory-placementalgorithms.Decidinghowmuch
memory to allocate to I/O and how much to program pages is a significant
challenge.SomesystemsallocateafixedpercentageofmemoryforI/Obuffers,
whereasothersallowbothprocessesandtheI/Osubsystemtocompeteforall
systemmemory.Section14.6discussestheintegratedrelationshipbetweenI/O
buffersandvirtualmemorytechniques.
Over-allocation of memory manifests itself as follows. While a process is
executing, a page fault occurs. The operating system determines where the
desired page is residing on secondary storage but then finds that there are
no free frames on the free-frame list; all memory is in use. This situation is
illustratedinFigure10.9,wherethefactthattherearenofreeframesisdepicted
byaquestionmark.
The operatingsystemhas severaloptions atthispoint.Itcouldterminate
the process. However, demand paging is the operating system’s attempt to
improvethecomputersystem’sutilizationandthroughput.Usersshouldnot
beawarethattheirprocessesarerunningonapagedsystem—pagingshould
belogicallytransparenttotheuser.Sothisoptionisnotthebestchoice.
The operating system could instead use standard swapping and swap
out a process, freeing all its frames and reducing the level of multiprogram-
ming. However, as discussed in Section 9.5, standard swapping is no longer
used by most operating systems due to the overhead of copying entire pro-
cesses between memory and swap space. Most operating systems now com-
bineswappingpageswithpagereplacement,atechniquewedescribeindetail
intheremainderofthissection.
10.4.1 Basic Page Replacement
Pagereplacementtakesthefollowingapproach.Ifnoframeisfree,wefindone
thatisnotcurrentlybeingusedandfreeit.Wecanfreeaframebywritingits402 Chapter10 VirtualMemory
Figure10.9 Needforpagereplacement.
contents to swap space and changing the page table (and all other tables) to
indicatethatthepageisnolongerinmemory(Figure10.10).Wecannowuse
thefreedframetoholdthepageforwhichtheprocessfaulted.Wemodifythe
page-faultserviceroutinetoincludepagereplacement:
1. Findthelocationofthedesiredpageonsecondarystorage.
2. Findafreeframe:
a. Ifthereisafreeframe,useit.
b. Ifthereisnofreeframe,useapage-replacementalgorithmtoselect
avictimframe.
c. Write the victim frame to secondary storage (if necessary); change
thepageandframetablesaccordingly.
3. Read the desiredpage into the newly freedframe; change the page and
frametables.
4. Continuetheprocessfromwherethepagefaultoccurred.
Notice that, if no frames are free, two page transfers (one for the page-out
and one for the page-in) are required. This situation effectively doubles the
page-faultservicetimeandincreasestheeffectiveaccesstimeaccordingly.
Wecanreducethisoverheadbyusingamodifybit(ordirtybit).Whenthis
scheme is used,each page or frame has a modify bit associated with it in the
hardware.Themodifybitforapageissetbythehardwarewheneveranybyte
inthepageis writteninto,indicating that thepagehas beenmodified.When
we select a page for replacement, we examine its modify bit. If the bit is set,10.4 PageReplacement 403
frame valid–invalid bit
page out
change victim
0 i 2 to invalid page
1
f v
4 f victim
reset page
table for
page table 3
new page
page in
desired
page
backing store
physical
memory
Figure10.10 Pagereplacement.
weknowthatthepagehasbeenmodifiedsinceitwasreadinfromsecondary
storage.Inthiscase,wemustwritethepagetostorage.Ifthemodifybitisnot
set,however,thepagehasnotbeenmodifiedsinceitwasreadintomemory.In
thiscase,weneednotwritethememorypagetostorage:itisalreadythere.This
techniquealsoappliestoread-onlypages(forexample,pagesofbinarycode).
Such pages cannot be modified; thus, they may be discarded when desired.
Thisschemecansignificantlyreducethetimerequiredtoserviceapagefault,
sinceitreducesI/Otimebyone-halfif thepagehasnotbeenmodified.
Page replacement is basic to demand paging. It completes the separation
betweenlogicalmemoryandphysicalmemory.Withthismechanism,anenor-
mousvirtualmemorycanbeprovidedforprogrammersonasmallerphysical
memory.Withnodemandpaging,logicaladdressesaremappedintophysical
addresses, and the two sets of addresses can be different. All the pages of a
processstillmustbeinphysicalmemory,however.Withdemandpaging,the
sizeofthelogicaladdressspaceisnolongerconstrainedbyphysicalmemory.
Ifwehaveaprocessoftwentypages,wecanexecuteitintenframessimplyby
usingdemandpagingandusingareplacementalgorithmtofindafreeframe
whenever necessary. If a page that has been modified is to be replaced, its
contents are copied to secondary storage. A later reference to that page will
cause a page fault. At that time, the page will be brought back into memory,
perhapsreplacingsomeotherpageintheprocess.
Wemustsolvetwomajorproblemstoimplementdemandpaging:wemust
develop a frame-allocation algorithm and a page-replacement algorithm.
Thatis,ifwehavemultipleprocessesinmemory,wemustdecidehowmany
frames to allocate to each process; and when page replacement is required,
wemustselecttheframesthataretobereplaced.Designingappropriatealgo-
rithmstosolvetheseproblemsisanimportanttask,becausesecondarystorage404 Chapter10 VirtualMemory
I/O is so expensive. Even slight improvements in demand-paging methods
yieldlargegainsinsystemperformance.
There are many different page-replacement algorithms. Every operating
system probably has its own replacement scheme. How do we select a par-
ticular replacement algorithm? In general, we want the one with the lowest
page-faultrate.
We evaluatean algorithm by running it on a particular string of memory
references and computing the number of page faults. The string of memory
referencesis called a reference string. We can generate reference strings arti-
ficially (by using a random-number generator, for example), or we can trace
a given system and record the address of each memory reference. The latter
choice produces a large number of data (on the order of 1 million addresses
persecond).Toreducethenumberofdata,weusetwofacts.
First,foragivenpagesize(andthepagesizeisgenerallyfixedbythehard-
ware or system), we need to consider only the page number, rather than the
entireaddress.Second,ifwehaveareferencetoapagep,thenanyreferences
to page p that immediately follow will never cause a page fault. Page p will
beinmemoryafterthefirstreference,sotheimmediatelyfollowingreferences
willnotfault.
Forexample,ifwetraceaparticularprocess,wemightrecordthefollowing
addresssequence:
0100,0432,0101,0612,0102,0103,0104,0101,0611,0102,0103,
0104,0101,0610,0102,0103,0104,0101,0609,0102,0105
At 100 bytes per page, this sequence is reduced to the following reference
string:
1,4,1,6,1,6,1,6,1,6,1
Todeterminethenumberofpagefaultsforaparticularreferencestringand
page-replacementalgorithm,wealsoneedtoknowthenumberofpageframes
available.Obviously,asthenumberofframesavailableincreases,thenumber
of page faults decreases. For the reference string considered previously, for
example,if we had three or more frames, we would have only three faults—
one fault for the first referencetoeachpage.Incontrast, with only one frame
available, we would have a replacement with every reference, resulting in
elevenfaults.Ingeneral,weexpectacurvesuchasthatinFigure10.11.Asthe
numberofframesincreases,thenumberofpagefaultsdropstosomeminimal
level.Ofcourse,addingphysicalmemoryincreasesthenumberofframes.
We next illustrate several page-replacement algorithms. In doing so, we
usethereferencestring
7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1
foramemorywiththreeframes.
10.4.2 FIFO Page Replacement
The simplest page-replacement algorithm is a first-in, first-out (FIFO) algo-
rithm.AFIFOreplacementalgorithmassociateswitheachpagethetimewhen
thatpagewasbroughtintomemory.Whenapagemustbereplaced,theoldest
pageischosen.Noticethatitisnotstrictlynecessarytorecordthetimewhena10.4 PageReplacement 405
stluaf
egap
fo
rebmun
16
14
12
10
8
6
4
2
1 2 3 4 5 6
number of frames
Figure10.11 Graphofpagefaultsversusnumberofframes.
pageisbroughtin.WecancreateaFIFOqueuetoholdallpagesinmemory.We
replacethepageattheheadofthequeue.Whenapageisbroughtintomemory,
weinsertitatthetailofthequeue.
Forourexamplereferencestring,ourthreeframesareinitiallyempty.The
firstthreereferences(7,0,1)causepagefaultsandarebroughtintotheseempty
frames.Thenextreference(2)replacespage7,becausepage7wasbroughtin
first.Since0isthenextreferenceand0isalreadyinmemory,wehavenofault
forthisreference.Thefirstreferenceto3resultsinreplacementofpage0,since
itisnowfirstinline.Becauseofthisreplacement,thenextreference,to0,will
fault. Page 1 is then replaced by page 0. This process continues as shown in
Figure10.12.Everytimeafaultoccurs,weshowwhichpagesareinourthree
frames.Therearefifteenfaultsaltogether.
TheFIFOpage-replacementalgorithmiseasytounderstandandprogram.
However, its performance is not always good. On the one hand, the page
replacedmaybeaninitializationmodulethatwasusedalongtimeagoandis
nolongerneeded.Ontheotherhand,itcouldcontainaheavilyusedvariable
thatwasinitializedearlyandisinconstantuse.
Notice that, even if we select for replacement a page that is in active use,
everything still works correctly. After we replace an active page with a new
reference string
7 0 1 2 0 3 0 4 2 3 0 3 2 1 2 0 1 7 0 1
7 7 7 2 2 2 4 4 4 0 0 0 7 7 7
0 0 0 3 3 3 2 2 2 1 1 1 0 0
1 1 1 0 0 0 3 3 3 2 2 2 1
page frames
Figure10.12 FIFOpage-replacementalgorithm.406 Chapter10 VirtualMemory
stluaf
egap
fo
rebmun
16
14
12
10
8
6
4
2
1 2 3 4 5 6 7
number of frames
Figure10.13 Page-faultcurveforFIFOreplacementonareferencestring.
one,afaultoccursalmostimmediatelytoretrievetheactivepage.Someother
pagemustbereplacedtobringtheactivepagebackintomemory.Thus,abad
replacementchoiceincreasesthepage-faultrateandslowsprocessexecution.
Itdoesnot,however,causeincorrectexecution.
To illustrate the problems that are possible with a FIFO page-replacement
algorithm,considerthefollowingreferencestring:
1,2,3,4,1,2,5,1,2,3,4,5
Figure10.13showsthecurveofpagefaultsforthisreferencestringversusthe
number of available frames. Notice that the number of faults for four frames
(ten) is greater than the number of faults for three frames (nine)! This most
unexpectedresultisknownasBelady’sanomaly:forsomepage-replacement
algorithms,thepage-faultratemayincreaseasthenumberofallocatedframes
increases. We would expect that giving more memory to a process would
improveitsperformance.Insomeearlyresearch,investigatorsnoticedthatthis
assumptionwasnotalwaystrue.Belady’sanomalywasdiscoveredasaresult.
10.4.3 Optimal Page Replacement
OneresultofthediscoveryofBelady’sanomalywasthesearchforanoptimal
page-replacement algorithm—the algorithm that has the lowest page-fault
rate of all algorithms and will never suffer from Belady’s anomaly. Such an
algorithmdoesexistandhasbeencalledOPTorMIN.Itissimplythis:
Replacethepagethatwillnotbeusedforthelongestperiodoftime.
Use of this page-replacementalgorithm guarantees the lowest possible page-
faultrateforafixednumberofframes.
Forexample,onoursamplereferencestring,theoptimalpage-replacement
algorithmwouldyieldninepagefaults,asshowninFigure10.14.Thefirstthree
references cause faults that fill the three empty frames. The reference to page
2replacespage7,becausepage7willnotbeuseduntilreference18,whereas10.4 PageReplacement 407
reference string
7 0 1 2 0 3 0 4 2 3 0 3 2 1 2 0 1 7 0 1
7 7 7 2 2 2 2 2 7
0 0 0 0 4 0 0 0
1 1 3 3 3 1 1
page frames
Figure10.14 Optimalpage-replacementalgorithm.
page 0 will be used at 5, and page 1 at 14. The reference to page 3 replaces
page1,aspage1willbethelastofthethreepagesinmemorytobereferenced
again. With only nine page faults, optimal replacement is much better than
a FIFO algorithm, which results in fifteen faults. (If we ignore the first three,
whichallalgorithmsmustsuffer,thenoptimalreplacementistwiceasgoodas
FIFOreplacement.)Infact,noreplacementalgorithmcanprocessthisreference
stringinthreeframeswithfewerthanninefaults.
Unfortunately, the optimal page-replacement algorithm is difficult to
implement, because it requires future knowledge of the reference string.
(WeencounteredasimilarsituationwiththeSJFCPU-schedulingalgorithmin
Section5.3.2.)Asaresult,theoptimalalgorithmisusedmainlyforcomparison
studies.Forinstance,itmaybeusefultoknowthat,althoughanewalgorithm
is not optimal, it is within 12.3 percent of optimal at worst and within 4.7
percentonaverage.
10.4.4 LRU Page Replacement
Iftheoptimalalgorithmisnotfeasible,perhapsanapproximationoftheopti-
malalgorithmispossible.ThekeydistinctionbetweentheFIFOandOPTalgo-
rithms (other than looking backward versus forward in time) is that the FIFO
algorithm usesthe time when a page was brought into memory, whereasthe
OPTalgorithmusesthetimewhenapageistobeused.Ifweusetherecentpast
asanapproximationofthenearfuture,thenwecanreplacethepagethathas
notbeenusedforthelongestperiodoftime.Thisapproachistheleastrecently
used(LRU)algorithm.
LRUreplacementassociateswitheachpagethetimeofthatpage’slastuse.
When a page must be replaced,LRU chooses the page that has not been used
for the longest period of time. We can think of this strategy as the optimal
page-replacement algorithm looking backward in time, rather than forward.
(Strangely,ifweletSRbethereverseofareferencestringS,thenthepage-fault
rate for the OPT algorithm on S is the same as the page-fault rate for the OPT
algorithmonSR.Similarly,thepage-faultratefortheLRUalgorithmonSisthe
sameasthepage-faultratefortheLRUalgorithmonSR.)
TheresultofapplyingLRUreplacementtoourexamplereferencestringis
showninFigure10.15.TheLRUalgorithmproducestwelvefaults.Noticethat
the first five faults are the same as those for optimal replacement. When the
reference to page 4 occurs, however, LRU replacement sees that, of the three
frames in memory, page 2 was used least recently. Thus, the LRU algorithm
replacespage2,notknowingthatpage2isabouttobeused.Whenitthenfaults408 Chapter10 VirtualMemory
reference string
7 0 1 2 0 3 0 4 2 3 0 3 2 1 2 0 1 7 0 1
7 7 7 2 2 4 4 4 0 1 1 1
0 0 0 0 0 0 3 3 3 0 0
1 1 3 3 2 2 2 2 2 7
page frames
Figure10.15 LRUpage-replacementalgorithm.
forpage2,theLRUalgorithmreplacespage3,sinceitisnowtheleastrecently
usedofthethreepagesinmemory.Despitetheseproblems,LRUreplacement
withtwelvefaultsismuchbetterthanFIFOreplacementwithfifteen.
TheLRUpolicyisoftenusedasapage-replacementalgorithmandiscon-
sideredtobegood.ThemajorproblemishowtoimplementLRUreplacement.
AnLRU page-replacementalgorithm may requiresubstantial hardware assis-
tance.Theproblemistodetermineanorderfortheframesdefinedbythetime
oflastuse.Twoimplementationsarefeasible:
• Counters.Inthe simplestcase,we associate witheach page-tableentrya
time-of-usefieldandaddtotheCPUalogicalclockorcounter.Theclockis
incrementedforeverymemoryreference.Wheneverareferencetoapage
is made, the contents of the clock register are copied to the time-of-use
field in the page-table entry for that page. In this way, we always have
the“time”ofthelastreferencetoeachpage.Wereplacethepagewiththe
smallesttimevalue.Thisschemerequiresasearchofthepagetabletofind
the LRUpageand awrite tomemory (tothetime-of-usefieldin thepage
table) for each memory access. The times must also be maintained when
page tables are changed (due to CPU scheduling). Overflow of the clock
mustbeconsidered.
• Stack. Another approach to implementing LRU replacement is to keep a
stackofpagenumbers.Wheneverapageisreferenced,itisremovedfrom
the stack and put on the top. In this way, the most recently used page is
always at the top of the stack, and the least recently used page is always
at the bottom (Figure 10.16). Because entries must be removed from the
middleofthestack,itisbesttoimplementthisapproachbyusingadoubly
linked list with a head pointer and a tail pointer. Removing a page and
putting it on the top of the stack then requires changing six pointers at
worst. Each update is a little more expensive, but there is no search for
a replacement;the tail pointer points to the bottom of the stack, which is
the LRU page. This approach is particularly appropriate for software or
microcodeimplementationsofLRUreplacement.
Likeoptimalreplacement,LRUreplacementdoesnotsufferfromBelady’s
anomaly. Both belong to a class of page-replacement algorithms, called stack
algorithms, that can never exhibit Belady’s anomaly. Astack algorithm is an
algorithm for which it can be shown that the set of pages in memory for n
framesisalwaysasubset ofthesetofpagesthatwouldbeinmemorywithn10.4 PageReplacement 409
reference string
4 7 0 7 1 0 1 2 1 2 7 1 2
2 7
a b
1 2
0 1
7 0
4 4
stack stack
before after
a b
Figure10.16 Useofastacktorecordthemostrecentpagereferences.
+ 1 frames. For LRU replacement,the set of pages in memory would be the n
most recently referenced pages. If the number of frames is increased, these n
pageswillstillbethemostrecentlyreferencedandsowillstillbeinmemory.
Note that neither implementation of LRU would be conceivable without
hardware assistance beyond the standard TLB registers. The updating of the
clock fields or stack must be done for every memory reference. If we were
to use an interrupt for every reference to allow software to update such data
structures, it would slow every memory reference by a factor of at least ten,
henceslowingeveryprocessbyafactoroften.Fewsystemscouldtoleratethat
levelofoverheadformemorymanagement.
10.4.5 LRU-Approximation Page Replacement
NotmanycomputersystemsprovidesufficienthardwaresupportfortrueLRU
page replacement. In fact, some systems provide no hardware support, and
other page-replacement algorithms (such as a FIFO algorithm) must be used.
Manysystemsprovidesomehelp,however,intheformofareferencebit.The
referencebitforapageissetbythehardwarewheneverthatpageisreferenced
(eitherareadorawritetoanybyteinthepage).Referencebitsareassociated
witheachentryinthepagetable.
Initially, all bits are cleared (to 0) by the operating system. As a process
executes, the bit associated with each page referenced is set (to 1) by the
hardware.Aftersometime,wecandeterminewhichpageshavebeenusedand
whichhavenotbeenusedbyexaminingthereferencebits,althoughwedonot
knowtheorderofuse.Thisinformationisthebasisformanypage-replacement
algorithmsthatapproximateLRUreplacement.
10.4.5.1 Additional-Reference-BitsAlgorithm
Wecangainadditionalorderinginformationbyrecordingthereferencebitsat
regularintervals.Wecankeepan8-bitbyteforeachpageinatableinmemory.
At regular intervals (say, every 100 milliseconds), a timer interrupt transfers
control to the operating system. The operating system shifts the reference bit
foreachpageintothehigh-orderbitofits8-bitbyte,shiftingtheotherbitsright410 Chapter10 VirtualMemory
by1bitanddiscardingthelow-orderbit.These8-bitshiftregisterscontainthe
historyofpageuseforthelasteighttimeperiods.Iftheshiftregistercontains
00000000,forexample,thenthepagehasnotbeenusedforeighttimeperiods.
A page that is used at least once in each period has a shift register value of
11111111.Apagewithahistoryregistervalueof11000100hasbeenusedmore
recentlythanonewithavalueof01110111. Ifweinterpretthese8-bitbytesas
unsignedintegers,thepagewiththelowestnumberistheLRUpage,anditcan
bereplaced.Noticethatthenumbersarenotguaranteedtobeunique,however.
We can either replace (swap out) all pages with the smallest value or use the
FIFOmethodtochooseamongthem.
The number of bits of history included in the shift registercan be varied,
ofcourse, and is selected(dependingonthe hardware available)tomake the
updatingasfastaspossible.Intheextremecase,thenumbercanbereducedto
zero,leavingonly thereferencebit itself.This algorithmiscalledthe second-
chancepage-replacementalgorithm.
10.4.5.2 Second-ChanceAlgorithm
Thebasicalgorithmofsecond-chancereplacementisaFIFOreplacementalgo-
rithm.Whenapagehasbeenselected,however,weinspectitsreferencebit.If
thevalueis0,weproceedtoreplacethispage;butifthereferencebitissetto
1,wegivethepageasecondchanceandmoveontoselectthenextFIFOpage.
When a page gets a second chance, its reference bit is cleared, and its arrival
time is reset to the current time. Thus, a page that is given a second chance
willnotbereplaceduntilallotherpageshavebeenreplaced(orgivensecond
chances). In addition, if a page is used often enough to keep its reference bit
set,itwillneverbereplaced.
One way to implementthe second-chance algorithm (sometimesreferred
to as the clock algorithm) is as a circular queue.Apointer (that is, a hand on
theclock)indicateswhichpageistobereplacednext.Whenaframeisneeded,
thepointeradvancesuntilitfindsapagewitha0referencebit.Asitadvances,
itclearsthereferencebits(Figure10.17).Onceavictimpageisfound,thepage
isreplaced,andthenewpageisinsertedinthecircularqueueinthatposition.
Noticethat,intheworstcase,whenallbitsareset,thepointercyclesthrough
thewholequeue,givingeachpageasecondchance. Itclearsallthereference
bitsbeforeselectingthenextpageforreplacement.Second-chancereplacement
degeneratestoFIFOreplacementifallbitsareset.
10.4.5.3 EnhancedSecond-ChanceAlgorithm
Wecanenhancethesecond-chancealgorithmbyconsideringthereferencebit
andthemodifybit(describedinSection10.4.1)asanorderedpair.Withthese
twobits,wehavethefollowingfourpossibleclasses:
1. (0,0)neitherrecentlyusednormodified—bestpagetoreplace
2. (0,1)notrecentlyusedbutmodified—notquiteasgood,becausethepage
willneedtobewrittenoutbeforereplacement
3. (1,0)recentlyusedbutclean—probablywillbeusedagainsoon10.4 PageReplacement 411
reference pages
bits
0
0
next
1
victim
1
0
1
1
circular queue of pages
(a)
… …
reference pages
bits
0
0
0
0
0
1
1
circular queue of pages
(b)
… …
Figure10.17 Second-chance(clock)page-replacementalgorithm.
4. (1,1)recentlyusedandmodified—probablywillbeusedagainsoon,and
thepagewillbeneedtobewrittenouttosecondarystoragebeforeitcan
bereplaced
Eachpageisinoneofthesefourclasses.Whenpagereplacementiscalled
for,weusethesameschemeasintheclockalgorithm;butinsteadofexamining
whether the page to which we are pointing has the reference bit set to 1,
we examine the class to which that page belongs. We replace the first page
encounteredinthelowestnonemptyclass.Noticethatwemayhavetoscanthe
circular queue several times before we find a page to be replaced. The major
differencebetweenthisalgorithmandthesimplerclockalgorithmisthathere
wegivepreferencetothosepagesthathavebeenmodifiedinordertoreduce
thenumberofI/Osrequired.
10.4.6 Counting-Based Page Replacement
There are many other algorithms that can be used for page replacement. For
example, we can keep a counter of the number of references that have been
madetoeachpageanddevelopthefollowingtwoschemes.
• Theleastfrequentlyused(LFU)page-replacementalgorithmrequiresthat
thepagewiththesmallestcountbereplaced.Thereasonforthisselectionis
thatanactivelyusedpageshouldhavealargereferencecount.Aproblem
arises, however, when a page is used heavily during the initial phase of412 Chapter10 VirtualMemory
a process but then is never used again. Since it was used heavily, it has
alargecountandremainsinmemoryeventhoughitisnolongerneeded.
Onesolutionistoshiftthecountsrightby1bitatregularintervals,forming
anexponentiallydecayingaverageusagecount.
• The most frequently used (MFU) page-replacement algorithm is based
on the argument that the page with the smallest count was probably just
broughtinandhasyettobeused.
Asyoumightexpect,neitherMFUnorLFUreplacementiscommon.Theimple-
mentationofthesealgorithmsisexpensive,andtheydonotapproximateOPT
replacementwell.
10.4.7 Page-Buffering Algorithms
Other procedures are often used in addition to a specific page-replacement
algorithm.Forexample,systemscommonlykeepapooloffreeframes.When
a page fault occurs, a victim frame is chosen as before. However, the desired
pageisreadintoafreeframefromthepoolbeforethevictimiswrittenout.This
procedureallowstheprocesstorestartassoonaspossible,withoutwaitingfor
thevictimpagetobewrittenout.Whenthevictimislaterwrittenout,itsframe
isaddedtothefree-framepool.
Anexpansionofthisideaistomaintainalistofmodifiedpages.Whenever
thepagingdeviceisidle,amodifiedpageisselectedandiswrittentosecondary
storage.Itsmodifybitisthenreset.Thisschemeincreasestheprobabilitythat
apagewillbecleanwhenitisselectedforreplacementandwillnotneedtobe
writtenout.
Another modification is to keep a pool of free frames but to remember
whichpagewasineachframe.Sincetheframecontentsarenotmodifiedwhen
aframeiswrittentosecondarystorage,theoldpagecanbereuseddirectlyfrom
thefree-framepoolifitisneededbeforethatframeisreused.NoI/Oisneeded
inthiscase.Whenapagefaultoccurs,wefirstcheckwhetherthedesiredpage
isinthefree-framepool.Ifitisnot,wemustselectafreeframeandreadinto
it.
Some versions of the UNIX system use this method in conjunction with
the second-chance algorithm. It can be a useful augmentation to any page-
replacementalgorithm,toreducethepenaltyincurredifthewrongvictimpage
isselected.Wedescribethese—andother—modificationsinSection10.5.3.
10.4.8 Applications and Page Replacement
Incertaincases,applicationsaccessingdatathroughtheoperatingsystem’svir-
tualmemoryperformworsethaniftheoperatingsystemprovidednobuffer-
ing at all. A typical example is a database, which provides its own memory
managementandI/Obuffering.Applicationslikethisunderstandtheirmem-
oryuseandstorageusebetterthandoesanoperatingsystemthatisimplement-
ingalgorithmsforgeneral-purposeuse.Furthermore,iftheoperatingsystem
isbufferingI/Oandtheapplicationisdoingsoaswell,thentwicethememory
isbeingusedforasetofI/O.
Inanotherexample,datawarehousesfrequentlyperformmassivesequen-
tial storage reads, followed by computations and writes. The LRU algorithm10.5 AllocationofFrames 413
would be removing old pages and preserving new ones, while the applica-
tionwouldmorelikelybereadingolderpagesthannewerones(asitstartsits
sequentialreadsagain).Here,MFUwouldactuallybemoreefficientthanLRU.
Becauseofsuchproblems,someoperatingsystemsgivespecialprograms
the ability to use a secondary storage partition as a large sequential array of
logical blocks, without any file-system data structures. This array is some-
times called the raw disk, and I/O to this array is termed raw I/O. Raw I/O
bypasses all the file-system services, such as file I/O demand paging, file
locking, prefetching, space allocation, file names, and directories. Note that
althoughcertainapplicationsaremoreefficientwhenimplementingtheirown
special-purposestorageservicesonarawpartition,mostapplicationsperform
betterwhentheyusetheregularfile-systemservices.
10.5 Allocation of Frames
Weturnnexttotheissueofallocation.Howdoweallocatethefixedamountof
freememoryamongthevariousprocesses?Ifwehave93freeframesandtwo
processes,howmanyframesdoeseachprocessget?
Considerasimplecaseofasystemwith128frames.Theoperatingsystem
may take 35, leaving 93 frames for the user process. Under pure demand
paging,all93frameswouldinitiallybeputonthefree-framelist.Whenauser
processstartedexecution,itwouldgenerateasequenceofpagefaults.Thefirst
93 page faults would all get free frames from the free-frame list. When the
free-frame list was exhausted, a page-replacement algorithm would be used
to select one of the 93 in-memory pages to be replaced with the 94th, and so
on. When the process terminated, the 93 frames would once again be placed
onthefree-framelist.
Therearemanyvariationsonthissimplestrategy.Wecanrequirethatthe
operatingsystemallocateallitsbufferandtablespacefromthefree-framelist.
Whenthisspaceisnotinusebytheoperatingsystem,itcanbeusedtosupport
userpaging.Wecantrytokeepthreefreeframesreservedonthefree-framelist
at all times. Thus, when a page fault occurs, there is a free frame available to
pageinto.Whilethepageswapistakingplace,areplacementcanbeselected,
which is then written to the storage device as the user process continues to
execute. Other variants are also possible, but the basic strategy is clear: the
userprocessisallocatedanyfreeframe.
10.5.1 Minimum Number of Frames
Our strategies for the allocation of frames are constrained in various ways.
We cannot, for example, allocate more than the total number of available
frames(unlessthereispagesharing).Wemustalsoallocateatleastaminimum
numberofframes.Here,welookmorecloselyatthelatterrequirement.
One reason for allocating at least a minimum number of frames involves
performance. Obviously, as the number of frames allocated to each process
decreases, the page-fault rate increases, slowing process execution. In addi-
tion,rememberthat,whenapagefaultoccursbeforeanexecutinginstruction
is complete, the instruction must be restarted. Consequently, we must have
enough frames to hold all the different pages that any single instruction can
reference.414 Chapter10 VirtualMemory
For example, consider a machine in which all memory-reference instruc-
tionsmayreferenceonlyonememoryaddress.Inthiscase,weneedatleastone
framefortheinstructionandoneframeforthememoryreference.Inaddition,
ifone-levelindirectaddressingisallowed(forexample,aloadinstructionon
frame 16 can refer to an address on frame 0, which is an indirect reference to
frame23),thenpagingrequiresatleastthreeframesperprocess.(Thinkabout
whatmighthappenifaprocesshadonlytwoframes.)
Theminimumnumberofframesisdefinedbythecomputerarchitecture.
For example, if the move instruction for a given architecture includes more
thanonewordforsomeaddressingmodes,theinstructionitselfmaystraddle
twoframes.Inaddition,ifeachofitstwooperandsmaybeindirectreferences,
a total of six frames are required. As another example, the move instruction
forIntel32-and64-bitarchitecturesallowsdatatomoveonlyfromregisterto
registerandbetweenregistersandmemory;itdoesnotallowdirectmemory-
to-memory movement, thereby limiting the required minimum number of
framesforaprocess.
Whereas the minimum number of frames per process is defined by the
architecture, the maximum number is defined by the amount of available
physicalmemory.Inbetween,wearestillleftwithsignificantchoiceinframe
allocation.
10.5.2 Allocation Algorithms
The easiest way to split m frames among n processes is to give everyone an
equalshare,m/nframes(ignoringframesneededbytheoperatingsystemfor
themoment).Forinstance,ifthereare93framesand5processes,eachprocess
willget18frames.The3leftoverframescanbeusedasafree-framebufferpool.
Thisschemeiscalledequalallocation.
An alternative is to recognize that various processes will need differing
amounts of memory. Consider a system with a 1-KB frame size. If a small
student process of 10 KB and an interactive database of 127 KB are the only
twoprocessesrunninginasystemwith62freeframes,itdoesnotmakemuch
sensetogiveeachprocess31frames.Thestudentprocessdoesnotneedmore
than10frames,sotheother21are,strictlyspeaking,wasted.
To solve this problem, we can use proportional allocation, in which we
allocateavailablememorytoeachprocessaccordingtoitssize.Letthesizeof
thevirtualmemoryforprocessp bes,anddefine
i i
S=∑s.
i
Then, if the total number of available frames is m, we allocate a frames to
i
processp,wherea isapproximately
i i
a =s/S×m.
i i
Of course, we must adjust each a to be an integer that is greater than the
i
minimum number of frames required by the instruction set, with a sum not
exceedingm.
Withproportionalallocation,wewouldsplit62framesbetweentwopro-
cesses, one of 10 pages and one of 127 pages, by allocating 4 frames and 57
frames,respectively,since10.5 AllocationofFrames 415
10/137×62≈4and
127/137×62≈57.
In this way, both processes share the available frames according to their
“needs,”ratherthanequally.
In both equal and proportional allocation, of course, the allocation may
varyaccordingtothemultiprogramminglevel.Ifthemultiprogramminglevel
isincreased,eachprocesswilllosesomeframestoprovidethememoryneeded
forthenewprocess.Conversely,ifthemultiprogrammingleveldecreases,the
frames that were allocated to the departed process can be spread over the
remainingprocesses.
Notice that, with either equal or proportional allocation, a high-priority
processistreatedthesameasalow-priorityprocess.Byitsdefinition,however,
we may want to give the high-priority process more memory to speed its
execution, to the detriment of low-priority processes. One solution is to use
a proportional allocation scheme wherein the ratio of frames depends not on
the relativesizesof processesbut rather onthe prioritiesof processesor on a
combinationofsizeandpriority.
10.5.3 Global versus Local Allocation
Another important factor in the way frames are allocated to the various pro-
cessesispagereplacement.Withmultipleprocessescompetingforframes,we
can classify page-replacement algorithms into two broad categories: global
replacement and local replacement. Global replacement allows a process to
select a replacement frame from the set of all frames, even if that frame is
currentlyallocatedtosomeotherprocess;thatis,oneprocesscantakeaframe
fromanother.Localreplacementrequiresthateachprocessselectfromonlyits
ownsetofallocatedframes.
For example, consider an allocation scheme wherein we allow high-
priorityprocessestoselectframesfromlow-priorityprocessesforreplacement.
Aprocess can select a replacementfrom among its own frames or the frames
ofanylower-priorityprocess.Thisapproachallowsahigh-priorityprocessto
increaseitsframeallocationattheexpenseofalow-priorityprocess.Whereas
withalocalreplacementstrategy,thenumberofframesallocatedtoaprocess
does not change, with global replacement, a process may happen to select
onlyframesallocatedtootherprocesses,thusincreasingthenumberofframes
allocated to it (assuming that other processes do not choose its frames for
replacement).
One problemwithaglobalreplacementalgorithm isthat thesetofpages
inmemoryforaprocessdependsnotonlyonthepagingbehaviorofthatpro-
cess, but also on the paging behavior of other processes. Therefore, the same
processmayperformquitedifferently(forexample,taking0.5secondsforone
execution and 4.3 seconds for the next execution) because of totally external
circumstances.Suchisnotthecasewithalocalreplacementalgorithm.Under
local replacement,the set of pages in memory for a process is affected by the
paging behavior of only that process. Local replacement might hinder a pro-
cess,however,bynotmakingavailabletoitother,lessusedpagesofmemory.
Thus,globalreplacementgenerallyresultsingreatersystemthroughput.Itis
thereforethemorecommonlyusedmethod.416 Chapter10 VirtualMemory
MAJORANDMINORPAGEFAULTS
As described in Section 10.2.1, a page fault occurs when a page does not
havea valid mappingin theaddress spaceofa process.Operatingsystems
generally distinguish between two types of page faults: major and minor
faults. (Windows refers to major and minor faults as hard and soft faults,
respectively.) Amajor page fault occurs when a page is referenced and the
page is not in memory. Servicing a major page fault requires reading the
desiredpagefromthebackingstoreintoafreeframeandupdatingthepage
table.Demandpagingtypicallygeneratesaninitiallyhighrateofmajorpage
faults.
Minorpagefaultsoccurwhenaprocessdoesnothavealogicalmapping
toapage,yetthatpageisinmemory.Minorfaultscanoccurforoneoftwo
reasons.First,aprocessmayreferenceasharedlibrarythatisinmemory,but
theprocessdoesnothaveamappingtoitinitspagetable.Inthisinstance,
it is only necessary to update the page table to refer to the existing page in
memory. A second cause of minor faults occurs when a page is reclaimed
from a process and placed on the free-frame list, but the page has not yet
been zeroed out and allocated to another process. When this kind of fault
occurs, the frame is removedfrom the free-frame list and reassigned to the
process.Asmightbeexpected,resolvingaminorpagefaultistypicallymuch
lesstimeconsumingthanresolvingamajorpagefault.
You can observe the number of major and minor page faults in a Linux
systemusingthecommandps -eo min flt,maj flt,cmd,whichoutputs
the number of minor and major page faults, as well as the command that
launchedtheprocess.Anexampleoutputofthispscommandappearsbelow:
MINFL MAJFL CMD
186509 32 /usr/lib/systemd/systemd-logind
76822 9 /usr/sbin/sshd -D
1937 0 vim 10.tex
699 14 /sbin/auditd -n
Here,itisinterestingtonotethat,formostcommands,thenumberofmajor
pagefaultsisgenerallyquitelow,whereasthenumberofminorfaultsismuch
higher.ThisindicatesthatLinuxprocesseslikelytakesignificantadvantage
of shared libraries as, once a library is loaded in memory,subsequent page
faultsareonlyminorfaults.
Next, we focus on one possible strategy that we can use to implement a
global page-replacement policy. With this approach, we satisfy all memory
requestsfromthefree-framelist,butratherthanwaitingforthelisttodropto
zerobeforewebeginselectingpagesforreplacement,wetriggerpagereplace-
ment when the list falls below a certain threshold. This strategy attempts to
ensurethereisalwayssufficientfreememorytosatisfynewrequests.
Such a strategy is depicted in Figure 10.18. The strategy’s purpose is to
keeptheamountoffreememoryaboveaminimumthreshold.Whenitdrops10.5 AllocationofFrames 417
b d maximum
threshold
minimum
threshold
a c
time
kernel resumes
reclaiming
pages
yromem
eerf
kernel suspends
reclaiming
pages
Figure10.18 Reclaimingpages.
belowthisthreshold,akernelroutineistriggeredthatbeginsreclaimingpages
from all processes in the system (typically excluding the kernel). Such kernel
routines are often known as reapers, and they may apply any of the page-
replacement algorithms covered in Section 10.4. When the amount of free
memoryreachesthemaximumthreshold,thereaperroutineissuspended,only
toresumeoncefreememoryagainfallsbelowtheminimumthreshold.
In Figure 10.18, we see that at point a the amount of free memory drops
below the minimum threshold, and the kernel begins reclaiming pages and
addingthemtothefree-framelist.Itcontinuesuntilthemaximumthresholdis
reached(pointb).Overtime,thereareadditionalrequestsformemory,andat
pointctheamountoffreememoryagainfallsbelowtheminimumthreshold.
Page reclamation resumes, only to be suspended when the amount of free
memoryreachesthemaximumthreshold(pointd).Thisprocesscontinues as
longasthesystemisrunning.
As mentioned above, the kernel reaper routine may adopt any page-
replacementalgorithm,buttypicallyitusessomeformofLRUapproximation.
Considerwhatmayhappen,though,ifthereaperroutineisunabletomaintain
the list of free frames below the minimum threshold. Under these circum-418 Chapter10 VirtualMemory
stances,thereaperroutinemaybegintoreclaimpagesmoreaggressively.For
example, perhaps it will suspend the second-chance algorithm and use pure
FIFO. Another, more extreme, example occurs in Linux; when the amount of
free memory falls to very low levels, a routine known as the out-of-memory
(OOM) killer selects a process to terminate,thereby freeing its memory.How
does Linux determine which process to terminate? Each process has what is
knownasanOOMscore,withahigherscoreincreasingthelikelihoodthatthe
processcouldbeterminatedbytheOOMkillerroutine.OOMscoresarecalcu-
lated according to the percentage of memory a process is using—the higher
the percentage, the higher the OOM score. (OOM scores can be viewed in the
/procfilesystem,wherethescoreforaprocesswithpid2500canbeviewed
as/proc/2500/oom score.)
Ingeneral,notonlycanreaperroutinesvaryhowaggressivelytheyreclaim
memory, but the values of the minimum and maximum thresholds can be
varied as well. These values can be set to default values, but some systems
may allow a systemadministrator to configure them based on the amount of
physicalmemoryinthesystem.
10.5.4 Non-Uniform Memory Access
Thus far in our coverage of virtual memory, we have assumed that all main
memory is created equal—or at least that it is accessed equally. On non-
uniform memory access (NUMA) systems with multiple CPUs (Section 1.3.2),
thatisnotthecase.Onthesesystems,agivenCPUcanaccesssomesectionsof
main memory faster than it can access others. These performance differences
arecausedbyhowCPUsandmemoryareinterconnectedinthesystem.Sucha
systemismadeupofmultipleCPUs,eachwithitsownlocalmemory(Figure
10.19). The CPUs are organized using a shared system interconnect, and as
youmightexpect,aCPUcanaccessitslocalmemoryfasterthanmemorylocal
toanother CPU. NUMAsystemsarewithout exceptionslowerthan systemsin
whichallaccessestomainmemoryaretreatedequally.However,asdescribed
in Section 1.3.2, NUMA systems can accommodate more CPUs and therefore
achievegreaterlevelsofthroughputandparallelism.
memory memory
0 1
interconnect
CPU CPU
0 1
CPU CPU
2 3
memory memory
2 3
Figure10.19 NUMAmultiprocessingarchitecture.10.6 Thrashing 419
Managing which page frames are stored at which locations can signifi-
cantly affect performance in NUMA systems. If we treat memory as uniform
insuchasystem,CPUsmaywaitsignificantly longerfor memoryaccessthan
if we modify memory allocation algorithms to take NUMA into account. We
described some of these modifications in Section 5.5.4. Their goal is to have
memoryframesallocated“ascloseaspossible”totheCPUonwhichtheprocess
isrunning.(Thedefinitionofcloseis“withminimumlatency,”whichtypically
means on the same system board as the CPU). Thus, when a process incurs a
pagefault,aNUMA-aware virtualmemorysystemwillallocatethatprocessa
frameascloseaspossibletotheCPUonwhichtheprocessisrunning.
To take NUMA into account, the scheduler must track the last CPU on
which each process ran. If the scheduler tries to schedule each process onto
its previous CPU, and the virtual memory system tries to allocate frames for
the process close to the CPU on which it is being scheduled, then improved
cachehitsanddecreasedmemoryaccesstimeswillresult.
The picture is more complicated once threads are added. For example, a
processwithmanyrunningthreadsmayendupwiththosethreadsscheduled
onmanydifferentsystemboards.Howshouldthememorybeallocatedinthis
case?
As we discussedin Section5.7.1, Linux manages this situation by having
thekernelidentifyahierarchyofschedulingdomains.TheLinuxCFSscheduler
does not allow threads to migrate across different domains and thus incur
memory access penalties. Linux also has a separate free-frame list for each
NUMAnode,therebyensuringthatathreadwillbeallocatedmemoryfromthe
node on which it is running. Solaris solves the problem similarly by creating
lgroups (for “locality groups”) in the kernel. Each lgroup gathers together
CPUs and memory, and each CPU in that group can access any memory in
the group within a defined latency interval. In addition, there is a hierarchy
oflgroupsbasedontheamountoflatencybetweenthegroups,similartothe
hierarchyofschedulingdomainsinLinux.Solaristriestoscheduleallthreads
of a process and allocate all memory of a process within an lgroup. If that is
notpossible,itpicksnearbylgroupsfortherestoftheresourcesneeded.This
practiceminimizesoverallmemorylatencyandmaximizesCPUcachehitrates.
10.6 Thrashing
Considerwhatoccursifaprocessdoesnothave“enough”frames—thatis,it
doesnothavetheminimumnumberofframesitneedstosupportpagesinthe
workingset.Theprocesswillquicklypage-fault.Atthispoint,itmustreplace
somepage.However,sinceallitspagesareinactiveuse,itmustreplaceapage
thatwillbeneededagainrightaway.Consequently,itquicklyfaultsagain,and
again,andagain,replacingpagesthatitmustbringbackinimmediately.
This high paging activity is called thrashing. Aprocess is thrashing if it
isspendingmoretimepagingthanexecuting.Asyoumightexpect,thrashing
resultsinsevereperformanceproblems.
10.6.1 Cause of Thrashing
Considerthefollowingscenario,whichisbasedontheactualbehaviorofearly
pagingsystems.TheoperatingsystemmonitorsCPUutilization.IfCPUutiliza-420 Chapter10 VirtualMemory
tion is too low, we increase the degree of multiprogramming by introducing
a new process to the system. A global page-replacement algorithm is used;
it replaces pages without regard to the process to which they belong. Now
suppose that a process enters a new phase in its execution and needs more
frames.Itstartsfaultingandtakingframesaway fromotherprocesses.These
processesneedthosepages,however,andsotheyalsofault,takingframesfrom
otherprocesses.Thesefaultingprocessesmustusethepagingdevicetoswap
pages in and out. As they queue up for the paging device, the ready queue
empties.Asprocesseswaitforthepagingdevice,CPUutilizationdecreases.
The CPU scheduler sees the decreasing CPU utilization and increases the
degreeofmultiprogrammingasaresult.Thenewprocesstriestogetstartedby
takingframesfromrunningprocesses,causingmorepagefaultsandalonger
queue for the paging device. As a result, CPU utilization drops even further,
andtheCPUschedulertriestoincreasethedegreeofmultiprogrammingeven
more. Thrashing has occurred, and system throughput plunges. The page-
faultrateincreasestremendously.Asaresult,theeffectivememory-accesstime
increases.Noworkisgettingdone,becausetheprocessesarespendingalltheir
timepaging.
This phenomenon is illustrated in Figure 10.20, in which CPU utilization
is plotted against the degree of multiprogramming. As the degree of multi-
programmingincreases,CPUutilizationalsoincreases,althoughmoreslowly,
until a maximum is reached. If the degree of multiprogramming is increased
further, thrashing sets in, and CPU utilization drops sharply. At this point, to
increase CPU utilization and stop thrashing, we must decrease the degree of
multiprogramming.
We can limit the effects of thrashing by using a local replacement algo-
rithm(orpriorityreplacementalgorithm).Asmentionedearlier,localreplace-
mentrequiresthateachprocessselectfromonlyitsownsetofallocatedframes.
Thus,ifoneprocessstartsthrashing,itcannot stealframesfromanother pro-
cessandcausethelattertothrashaswell.However,theproblemisnotentirely
solved. If processes are thrashing, they will be in the queue for the paging
devicemostofthetime.Theaverageservicetimeforapagefaultwillincrease
thrashing
degree of multiprogramming
noitazilitu
UPC
Figure10.20 Thrashing.10.6 Thrashing 421
becauseofthelongeraveragequeueforthepagingdevice.Thus,theeffective
accesstimewillincreaseevenforaprocessthatisnotthrashing.
Topreventthrashing, wemustprovideaprocesswithasmany framesas
it needs. But how do we know how many frames it “needs”? One strategy
startsbylookingathowmanyframesaprocessisactuallyusing.Thisapproach
definesthelocalitymodelofprocessexecution.
Thelocalitymodelstatesthat,asaprocessexecutes,itmovesfromlocality
tolocality.Alocalityisasetofpagesthatareactivelyusedtogether.Arunning
programisgenerallycomposedofseveraldifferentlocalities,whichmayover-
lap. For example, when a function is called, it defines a new locality. In this
34
32
30
28
26
24
22
20
18
srebmun
egap
(a) (b)
execution time
Figure10.21 Localityinamemory-referencepattern.422 Chapter10 VirtualMemory
page reference table
. . . 2 6 1 5 7 7 7 7 5 1 6 2 3 4 1 2 3 4 4 4 3 4 3 4 4 4 1 3 2 3 4 4 4 3 4 4 4 . . .
Δ Δ
t t
1 2
WS(t ) = {1,2,5,6,7} WS(t ) = {3,4}
1 2
Figure10.22 Working-setmodel.
locality,memoryreferencesaremadetotheinstructionsofthefunctioncall,its
localvariables,andasubsetoftheglobalvariables.Whenweexitthefunction,
theprocessleavesthislocality,sincethelocalvariablesandinstructionsofthe
functionarenolongerinactiveuse.Wemayreturntothislocalitylater.
Figure 10.21 illustrates the concept of locality and how a process’s
locality changes over time. At time (a), the locality is the set of pages
{18,19,20,21,22,23,24,29,30,33}. At time (b), the locality changes to
{18,19,20,24,25,26,27,28,29,31,32,33}. Notice the overlap, as some pages
(forexample,18,19,and20)arepartofbothlocalities.
Thus, we see that localities are defined by the program structure and its
data structures. The locality model states that all programs will exhibit this
basicmemoryreferencestructure.Notethatthelocalitymodelistheunstated
principlebehindthecachingdiscussionssofarinthisbook.Ifaccessestoany
typesofdatawererandomratherthanpatterned,cachingwouldbeuseless.
Suppose we allocate enough frames to a process to accommodate its cur-
rent locality. It will fault for the pages in its locality until all these pages are
in memory; then, it will not fault again until it changes localities. If we do
not allocate enough frames to accommodate the size of the current locality,
theprocesswillthrash,sinceitcannot keepinmemoryallthepagesthatitis
activelyusing.
10.6.2 Working-Set Model
The working-set model is based on the assumption of locality. This model
usesaparameter,Δ,todefinetheworking-setwindow.Theideaistoexamine
themostrecentΔpagereferences.ThesetofpagesinthemostrecentΔpage
referencesistheworkingset(Figure10.22).Ifapageisinactiveuse,itwillbein
theworkingset.Ifitisnolongerbeingused,itwilldropfromtheworkingset
Δtimeunitsafteritslastreference.Thus,theworkingsetisanapproximation
oftheprogram’slocality.
For example, given the sequence of memory references shown in Figure
10.22, if Δ = 10 memory references, then the working set at time t is {1, 2, 5,
1
6,7}.Bytimet ,theworkingsethaschangedto{3,4}.
2
Theaccuracy of theworking setdependsontheselectionof Δ.IfΔistoo
small,itwillnotencompasstheentirelocality;ifΔistoolarge,itmayoverlap
several localities. In the extreme, if Δ is infinite, the working set is the set of
pagestouchedduringtheprocessexecution.
The most important property of the working set, then, is its size. If we
compute the working-set size, WSS, for each process in the system, we can
i
thenconsiderthat10.6 Thrashing 423
D=∑WSS,
i
whereDisthetotaldemandforframes.Eachprocessisactivelyusingthepages
in its working set. Thus, process i needs WSS frames. If the total demand is
i
greaterthanthetotalnumberofavailableframes(D>m),thrashingwilloccur,
becausesomeprocesseswillnothaveenoughframes.
Once Δ has been selected, use of the working-set model is simple. The
operating system monitors the working set of each process and allocates to
thatworkingsetenoughframestoprovideitwithitsworking-setsize.Ifthere
are enough extra frames, another process can be initiated. If the sum of the
working-set sizes increases, exceeding the total number of available frames,
the operating system selects a process to suspend. The process’s pages are
written out (swapped), and its frames are reallocated to other processes. The
suspendedprocesscanberestartedlater.
Thisworking-setstrategypreventsthrashingwhilekeepingthedegreeof
multiprogrammingashighaspossible.Thus,itoptimizesCPUutilization.The
difficultywiththeworking-setmodeliskeepingtrackoftheworkingset.The
WORKINGSETSANDPAGE-FAULTRATES
There is a direct relationship between the working set of a process and its
page-fault rate. Typically, as shown in Figure 10.22, the working set of a
processchangesovertimeasreferencestodataandcodesectionsmovefrom
one locality to another. Assuming there is sufficient memory to store the
workingsetofaprocess(thatis,theprocessisnotthrashing),thepage-fault
rateoftheprocesswilltransitionbetweenpeaksandvalleysovertime.This
generalbehaviorisshownbelow:
working set
1
page
fault
rate
0
time
Apeakinthepage-faultrateoccurswhenwebegindemand-paginganew
locality.However,oncetheworkingsetofthisnewlocalityisinmemory,the
page-faultratefalls.Whentheprocessmovestoanewworkingset,thepage-
faultraterisestowardapeakonceagain,returningtoalowerrateoncethe
newworkingsetisloadedintomemory.Thespanoftimebetweenthestart
ofonepeakandthestartofthenextpeakrepresentsthetransitionfromone
workingsettoanother.424 Chapter10 VirtualMemory
working-set window is a moving window. At each memory reference, a new
referenceappearsatoneend,andtheoldestreferencedropsofftheotherend.
A page is in the working set if it is referenced anywhere in the working-set
window.
We can approximate the working-set model with a fixed-interval timer
interrupt and a reference bit. For example, assume that Δ equals 10,000 ref-
erencesandthat wecan causeatimerinterruptevery5,000references.When
we get a timer interrupt, we copy and clear the reference-bit values for each
page. Thus, if a page fault occurs, we can examine the current reference bit
andtwoin-memorybitstodeterminewhetherapagewasusedwithinthelast
10,000to15,000references.Ifitwasused,atleastoneofthesebitswillbeon.
Ifithasnotbeenused,thesebitswillbeoff.Pageswithatleastonebitonwill
beconsideredtobeintheworkingset.
Notethatthisarrangementisnotentirelyaccurate,becausewecannottell
where, within an interval of 5,000, a reference occurred. We can reduce the
uncertaintybyincreasingthenumberofhistorybitsandthefrequencyofinter-
rupts(forexample,10bitsandinterruptsevery1,000references).However,the
costtoservicethesemorefrequentinterruptswillbecorrespondinglyhigher.
10.6.3 Page-Fault Frequency
The working-set model is successful, and knowledge of the working set can
be useful for prepaging(Section10.9.1),but itseemsaclumsy way tocontrol
thrashing. A strategy that uses the page-fault frequency (PFF) takes a more
directapproach.
The specific problem is how to prevent thrashing. Thrashing has a high
page-fault rate. Thus, we want to control the page-fault rate. When it is too
high, we know that the process needs more frames. Conversely, if the page-
fault rate is too low, then the process may have too many frames. We can
establishupperandlowerboundsonthedesiredpage-faultrate(Figure10.23).
If the actual page-fault rate exceeds the upper limit, we allocate the process
increase number
of frames
upper bound
lower bound
decrease number
of frames
number of frames
etar
tluaf-egap
Figure10.23 Page-faultfrequency.10.7 MemoryCompression 425
another frame. If the page-fault rate falls below the lower limit, we removea
frame from the process. Thus, we can directly measure and control the page-
faultratetopreventthrashing.
Aswiththeworking-setstrategy,wemayhavetoswapoutaprocess.Ifthe
page-faultrateincreasesandnofreeframesareavailable,wemustselectsome
processandswapitouttobackingstore.Thefreedframesarethendistributed
toprocesseswithhighpage-faultrates.
10.6.4 Current Practice
Practicallyspeaking,thrashingandtheresultingswappinghaveadisagreeably
high impact on performance. The current best practice in implementing a
computer system is to include enough physical memory, whenever possible,
to avoid thrashing and swapping. From smartphones through large servers,
providingenough memory to keepall working sets in memory concurrently,
exceptunderextremeconditions,providesthebestuserexperience.
10.7 Memory Compression
An alternative to paging is memory compression. Here, rather than paging
outmodifiedframestoswapspace,wecompressseveralframesintoasingle
frame, enabling the system to reduce memory usage without resorting to
swappingpages.
In Figure 10.24, the free-frame list contains six frames. Assume that this
numberoffreeframesfallsbelowacertainthresholdthattriggerspagereplace-
ment.Thereplacementalgorithm(say,anLRUapproximationalgorithm)selects
four frames—15, 3, 35, and 26—to place on the free-frame list. It first places
theseframesonamodified-framelist.Typically,themodified-framelistwould
next be written to swap space, making the frames available to the free-frame
list. An alternative strategy is to compress a number of frames—say, three—
andstoretheircompressedversionsinasinglepageframe.
In Figure 10.25, frame 7 is removed from the free-frame list. Frames 15,
3, and 35 are compressed and stored in frame 7, which is then stored in the
listofcompressedframes.The frames 15, 3,and 35 can now be movedtothe
free-framelist.Ifoneofthethreecompressedframesislaterreferenced,apage
fault occurs, and the compressed frame is decompressed, restoring the three
pages15,3,and35inmemory.
free-frame list
head 7 2 9 21 27 16
modified frame list
head 15 3 35 26
Figure10.24 Free-framelistbeforecompression.426 Chapter10 VirtualMemory
free-frame list
head 2 9 21 27 16 15 3 35
modified frame list
head 26
compressed frame list
head 7
Figure10.25 Free-framelistaftercompression
As we have noted, mobile systems generally do not support either stan-
dardswappingorswappingpages.Thus,memorycompressionisanintegral
partofthememory-managementstrategyformostmobileoperatingsystems,
includingAndroidandiOS.Inaddition,bothWindows10andmacOSsupport
memory compression. For Windows 10, Microsoft developed the Universal
Windows Platform (UWP) architecture, which provides a common app plat-
form for devices that run Windows 10, including mobile devices. UWP apps
running on mobile devices are candidates for memory compression. macOS
first supported memory compression with Version 10.9 of the operating sys-
tem,firstcompressingLRUpageswhenfreememoryisshortandthenpaging
ifthatdoesn’tsolvetheproblem.Performancetestsindicatethatmemorycom-
pression is faster than paging even to SSD secondary storage on laptop and
desktopmacOSsystems.
Although memory compression does require allocating free frames to
hold the compressed pages, a significant memory saving can be realized,
depending on the reductions achieved by the compression algorithm. (In the
example above, the three frames were reduced to one-third of their original
size.)As with any form of data compression, there is contention between the
speedof the compression algorithm and the amount of reductionthat can be
achieved (known as the compression ratio). In general, higher compression
ratios (greater reductions) can be achieved by slower, more computationally
expensivealgorithms.Mostalgorithmsinusetodaybalancethesetwofactors,
achievingrelativelyhighcompressionratiosusingfastalgorithms.Inaddition,
compressionalgorithmshaveimprovedbytakingadvantageofmultiplecom-
putingcoresandperformingcompressioninparallel.Forexample,Microsoft’s
Xpress and Apple’s WKdm compression algorithms are considered fast, and
theyreportcompressingpagesto30to50percentoftheiroriginalsize.
10.8 Allocating Kernel Memory
Whenaprocessrunninginusermoderequestsadditionalmemory,pagesare
allocated from the list of free page frames maintained by the kernel. This list
is typically populated using a page-replacementalgorithm such as those dis-
cussedinSection10.4andmostlikelycontainsfreepagesscatteredthroughout
physical memory, as explained earlier. Remember, too, that if a user process
requests a single byte of memory, internal fragmentation will result, as the
processwillbegrantedanentirepageframe.10.8 AllocatingKernelMemory 427
Kernelmemoryisoftenallocatedfromafree-memorypooldifferentfrom
the list used to satisfy ordinary user-mode processes. There are two primary
reasonsforthis:
1. Thekernelrequestsmemoryfordatastructuresofvaryingsizes,someof
whicharelessthanapageinsize.Asaresult,thekernelmustusememory
conservativelyandattempttominimizewasteduetofragmentation.This
is especially important because many operating systems do not subject
kernelcodeordatatothepagingsystem.
2. Pages allocatedtouser-modeprocessesdonot necessarilyhave tobe in
contiguousphysicalmemory.However,certainhardwaredevicesinteract
directlywithphysicalmemory—withoutthebenefitofavirtualmemory
interface—andconsequentlymayrequirememoryresidinginphysically
contiguouspages.
Inthefollowingsections,weexaminetwostrategiesformanagingfreememory
thatisassignedtokernelprocesses:the“buddysystem”andslaballocation.
10.8.1 Buddy System
The buddy system allocates memory from a fixed-size segment consisting of
physically contiguous pages. Memory is allocated from this segment using a
power-of-2 allocator, which satisfies requests in units sized as a power of 2
(4 KB, 8 KB, 16 KB, and so forth). Arequest in units not appropriately sized is
roundeduptothenexthighestpowerof2.Forexample,arequestfor11KBis
satisfiedwitha16-KBsegment.
Let’s consider a simple example. Assume the size of a memory segment
is initially 256 KB and the kernel requests 21 KB of memory. The segment is
initiallydividedintotwobuddies—whichwewillcallA andA —each128
L R
KBinsize.Oneofthesebuddiesisfurtherdividedintotwo64-KBbuddies—B
L
andB .However,thenext-highestpowerof2from21KBis32KB soeitherB
R L
orB isagaindividedintotwo32-KBbuddies,C andC .Oneofthesebuddies
R L R
isusedtosatisfythe21-KB request.ThisschemeisillustratedinFigure10.26,
whereC isthesegmentallocatedtothe21-KBrequest.
L
Anadvantageofthebuddysystemishowquicklyadjacentbuddiescanbe
combinedtoformlargersegmentsusingatechniqueknownascoalescing.In
Figure10.26,forexample,whenthekernelreleasestheC unititwasallocated,
L
thesystemcancoalesceC andC intoa64-KBsegment.Thissegment,B ,can
L R L
inturn be coalesced with its buddyB to form a128-KB segment. Ultimately,
R
wecanendupwiththeoriginal256-KBsegment.
Theobviousdrawbacktothebuddysystemisthatroundinguptothenext
highestpowerof2isverylikelytocausefragmentationwithinallocatedseg-
ments.Forexample,a33-KBrequestcanonlybesatisfiedwitha64-KBsegment.
Infact,wecannotguaranteethatlessthan50percentoftheallocatedunitwill
bewastedduetointernalfragmentation.Inthefollowingsection,weexplore
amemoryallocationschemewherenospaceislostduetofragmentation.
10.8.2 Slab Allocation
Asecondstrategyforallocatingkernelmemoryisknownasslaballocation.A
slabismadeupofoneormorephysicallycontiguouspages.Acacheconsists428 Chapter10 VirtualMemory
physically contiguous pages
256 KB
128 KB 128 KB
A A
L R
64 KB 64 KB
B B
L R
32 KB 32 KB
C C
L R
Figure10.26 Buddysystemallocation.
ofoneormoreslabs.Thereisasinglecacheforeachuniquekerneldatastruc-
ture—forexample,aseparatecacheforthedatastructurerepresentingprocess
descriptors,aseparatecache forfileobjects,aseparatecacheforsemaphores,
andsoforth.Eachcacheispopulatedwithobjectsthatareinstantiationsofthe
kernel data structure the cache represents. For example, the cache represent-
ingsemaphoresstoresinstances ofsemaphoreobjects,thecache representing
processdescriptorsstoresinstancesofprocessdescriptorobjects,andsoforth.
Therelationshipamongslabs,caches,andobjectsisshowninFigure10.27.The
figureshowstwokernelobjects3KBinsizeandthreeobjects7KBinsize,each
storedinaseparatecache.
kernel objects caches slabs
3-KB
objects
physically
contiguous
pages
7-KB
objects
Figure10.27 Slaballocation.10.8 AllocatingKernelMemory 429
The slab-allocation algorithm uses caches to store kernel objects. When a
cacheiscreated,anumberofobjects—whichareinitiallymarkedasfree—are
allocatedtothecache.Thenumberofobjectsinthecachedependsonthesize
oftheassociatedslab.Forexample,a12-KBslab(madeupofthreecontiguous
4-KB pages) could store six 2-KB objects. Initially, all objects in the cache are
marked as free. When a new object for a kernel data structure is needed, the
allocator can assign any free object from the cache to satisfy the request. The
objectassignedfromthecacheismarkedasused.
Let’s consider a scenario in which the kernel requests memory from the
slab allocator for an object representing a process descriptor. In Linux sys-
tems,aprocessdescriptorisofthetypestruct task struct,whichrequires
approximately 1.7 KB of memory. When the Linux kernel creates a new task,
itrequeststhenecessarymemoryforthestruct task structobjectfromits
cache. The cache will fulfill the request using a struct task struct object
thathasalreadybeenallocatedinaslabandismarkedasfree.
InLinux,aslabmaybeinoneofthreepossiblestates:
1. Full.Allobjectsintheslabaremarkedasused.
2. Empty.Allobjectsintheslabaremarkedasfree.
3. Partial.Theslabconsistsofbothusedandfreeobjects.
The slab allocator first attempts to satisfy the request with a free object in a
partial slab. If none exists, a free object is assigned from an empty slab. If no
empty slabs are available, a new slab is allocated from contiguous physical
pages and assigned to a cache; memory for the object is allocated from this
slab.
Theslaballocatorprovidestwomainbenefits:
1. No memory is wasted due to fragmentation. Fragmentation is not an
issuebecauseeachuniquekerneldatastructurehasanassociatedcache,
and each cache is made up of one or more slabs that are divided into
chunks the size of the objects being represented.Thus, when the kernel
requestsmemoryforanobject,theslaballocatorreturnstheexactamount
ofmemoryrequiredtorepresenttheobject.
2. Memory requests can be satisfied quickly. The slab allocation scheme is
thus particularly effective for managing memory when objects are fre-
quentlyallocatedanddeallocated,asisoftenthecasewithrequestsfrom
thekernel.Theactofallocating—andreleasing—memorycanbeatime-
consumingprocess.However,objectsarecreatedinadvanceandthuscan
be quickly allocated from the cache. Furthermore, when the kernel has
finished withan object and releasesit,itis markedas freeand returned
toitscache,thusmakingitimmediatelyavailableforsubsequentrequests
fromthekernel.
The slab allocator first appeared in the Solaris 2.4 kernel. Because of its
general-purposenature,this allocator is now alsousedfor certainuser-mode
memoryrequestsinSolaris.Linuxoriginallyusedthebuddysystem;however,
beginningwithVersion2.2,theLinuxkerneladoptedtheslaballocator.Linux430 Chapter10 VirtualMemory
referstoitsslabimplementationasSLAB.RecentdistributionsofLinuxinclude
twootherkernelmemoryallocators—theSLOBandSLUBallocators.
TheSLOBallocatorisdesignedforsystemswithalimitedamountofmem-
ory,suchasembeddedsystems.SLOB(whichstandsfor“simplelistofblocks”)
maintainsthreelistsofobjects:small(forobjectslessthan256bytes),medium
(for objectslessthan 1,024bytes),and large(forall otherobjects lessthan the
sizeofapage).Memoryrequestsareallocatedfromanobjectontheappropri-
atelistusingafirst-fitpolicy.
Beginning with Version 2.6.24, the SLUB allocator replaced SLAB as the
default allocator for the Linux kernel. SLUB reduced much of the overhead
requiredbytheSLABallocator.Forinstance,whereasSLABstorescertainmeta-
data with each slab, SLUB stores these data in the page structure the Linux
kernel uses for each page. Additionally, SLUB does not include the per-CPU
queuesthattheSLABallocatormaintainsforobjectsineachcache.Forsystems
with a large number of processors, the amount of memory allocated to these
queues is significant. Thus, SLUB provides better performance as the number
ofprocessorsonasystemincreases.
10.9 Other Considerations
The major decisions that we make for a paging system are the selections of
areplacementalgorithm andanallocationpolicy,which wediscussedearlier
in this chapter. There are many other considerations as well, and we discuss
severalofthemhere.
10.9.1 Prepaging
Anobviouspropertyofpuredemandpagingisthelargenumberofpagefaults
that occur when a process is started. This situation results from trying to get
the initial locality into memory. Prepaging is an attempt to prevent this high
levelofinitialpaging.Thestrategyistobringsome—orall—ofthepagesthat
willbeneededintomemoryatonetime.
Inasystemusingtheworking-setmodel,forexample,wecouldkeepwith
eachprocessalistofthepagesinitsworkingset.Ifwemustsuspendaprocess
(due to a lack of free frames), we remember the working set for that process.
When the process is to be resumed (because I/O has finished or enough free
frames have become available),we automatically bring back into memoryits
entireworkingsetbeforerestartingtheprocess.
Prepaging may offer an advantage in some cases. The question is simply
whether the cost of using prepaging is less than the cost of servicing the
corresponding page faults. It may well be the case that many of the pages
broughtbackintomemorybyprepagingwillnotbeused.
Assume that s pages are prepaged and a fraction α of these s pages is
actually used (0 ≤ α ≤ 1). The question is whether the cost of the s*α saved
pagefaultsisgreaterorlessthanthecostofprepagings*(1−α)unnecessary
pages.Ifαiscloseto0,prepagingloses;ifαiscloseto1,prepagingwins.
Note also that prepaging an executable program may be difficult, as it
may be unclear exactly what pages should be brought in. Prepaging a file
maybemorepredictable,sincefilesareoftenaccessedsequentially.TheLinux10.9 OtherConsiderations 431
readahead()systemcallprefetchesthecontentsofafileintomemorysothat
subsequentaccessestothefilewilltakeplaceinmainmemory.
10.9.2 Page Size
The designers of an operating system for an existing machine seldom have
a choice concerning the page size. However, when new machines are being
designed,adecisionregardingthebestpagesizemustbemade.Asyoumight
expect, there is no single best page size. Rather, there is a set of factors that
supportvarioussizes.Pagesizesareinvariablypowersof2,generallyranging
from4,096(212)to4,194,304(222)bytes.
Howdoweselectapagesize?Oneconcernisthesizeofthepagetable.For
agivenvirtualmemoryspace,decreasingthepagesizeincreasesthenumber
ofpagesandhencethesizeofthepagetable.Foravirtualmemoryof4MB(222),
for example, there would be 4,096 pages of 1,024 bytes but only 512 pages of
8,192 bytes. Because each active process must have its own copy of the page
table,alargepagesizeisdesirable.
Memory is better utilized with smaller pages, however. If a process is
allocatedmemorystartingatlocation00000andcontinuinguntilithasasmuch
as it needs,it probably will not end exactly on apage boundary. Thus, a part
ofthe final page must be allocated (because pages are the units ofallocation)
butwillbeunused(creatinginternalfragmentation).Assumingindependence
of process size and page size, we can expect that, on the average, half of the
finalpageofeachprocesswillbewasted.Thislossisonly256bytesforapage
of 512 bytes but is 4,096 bytes for a page of 8,192 bytes. To minimize internal
fragmentation,then,weneedasmallpagesize.
Anotherproblemisthetimerequiredtoreadorwriteapage.Asyouwill
seeinSection11.1,whenthestoragedeviceisanHDD,I/Otimeiscomposedof
seek, latency, and transfer times. Transfer time is proportional to the amount
transferred(thatis,thepagesize)—afactthatwouldseemtoargueforasmall
page size. However, latency and seek time normally dwarf transfer time. At
a transfer rate of 50 MB per second, it takes only 0.01 millisecondsto transfer
512 bytes. Latency time, though, is perhaps 3 milliseconds, and seek time 5
milliseconds.OfthetotalI/Otime(8.01milliseconds),therefore,onlyabout0.1
percentis attributable to the actual transfer. Doubling the page size increases
I/O time to only 8.02 milliseconds. It takes 8.02 milliseconds to read a single
page of 1,024 bytes but 16.02 milliseconds to read the same amount as two
pagesof512byteseach.Thus,adesiretominimizeI/Otimearguesforalarger
pagesize.
Withasmallerpagesize,though,totalI/Oshouldbereduced,sincelocality
will be improved. A smaller page size allows each page to match program
locality more accurately. For example, consider a process 200 KB in size, of
which only half (100 KB) is actually used in an execution. If we have only
onelargepage,wemustbringintheentirepage,atotalof200KBtransferred
and allocated. If insteadwe had pages of only 1 byte, then we could bring in
onlythe100KBthatareactuallyused,resultinginonly100KBtransferredand
allocated.Withasmallerpagesize,then,wehavebetterresolution,allowing
ustoisolateonlythememorythatisactuallyneeded.Withalargerpagesize,
wemust allocate and transfernot only what isneededbut alsoanything else432 Chapter10 VirtualMemory
that happens to be in the page, whether it is needed or not. Thus, a smaller
pagesizeshouldresultinlessI/Oandlesstotalallocatedmemory.
Butdidyounotice that withapagesizeof1byte,we wouldhave apage
fault for each byte? A process of 200 KB that used only half of that memory
wouldgenerateonlyonepagefaultwithapagesizeof200KBbut102,400page
faults with a page size of 1 byte. Each page fault generates the large amount
of overhead needed for processing the interrupt, saving registers, replacing
a page, queuing for the paging device, and updating tables. To minimize the
numberofpagefaults,weneedtohavealargepagesize.
Otherfactorsmustbeconsideredaswell(suchastherelationshipbetween
page size and sector size on the paging device). The problem has no best
answer.Aswehaveseen,somefactors(internalfragmentation,locality)argue
for a small page size, whereas others (table size, I/O time) argue for a large
page size. Nevertheless,the historical trend is toward larger page sizes, even
formobilesystems.Indeed,thefirsteditionofOperatingSystemConcepts(1983)
used4,096bytesastheupperboundonpagesizes,andthisvaluewasthemost
common page size in 1990. Modern systems may now use much larger page
sizes,asyouwillseeinthefollowingsection.
10.9.3 TLB Reach
In Chapter 9, we introduced the hit ratio of the TLB. Recall that the hit ratio
for the TLB refers to the percentage of virtual address translations that are
resolved in the TLB rather than the page table. Clearly, the hit ratio is related
to the number of entries in the TLB, and the way to increase the hit ratio is
byincreasingthenumberofentries.This,however,doesnotcomecheaply,as
theassociativememoryusedtoconstructtheTLBisbothexpensiveandpower
hungry.
Related to the hit ratio is a similar metric: the TLB reach. The TLB reach
refers to the amount of memory accessible from the TLB and is simply the
number of entries multiplied by the page size. Ideally, the working set for a
process is stored in the TLB. If it is not, the process will spend a considerable
amount of time resolving memory references in the page table rather than
the TLB. If we double the number of entries in the TLB, we double the TLB
reach.However,forsomememory-intensiveapplications,thismaystillprove
insufficientforstoringtheworkingset.
AnotherapproachforincreasingtheTLBreachistoeitherincreasethesize
ofthepageorprovidemultiplepagesizes.Ifweincreasethepagesize—say,
from4KBto16KB—wequadrupletheTLBreach.However,thismayleadtoan
increaseinfragmentationforsomeapplicationsthatdonotrequiresuchalarge
pagesize.Alternatively,mostarchitecturesprovidesupportformorethanone
pagesize,andanoperatingsystemcanbeconfiguredtotakeadvantageofthis
support.Forexample,thedefaultpagesizeonLinuxsystemsis4KB;however,
Linuxalsoprovideshugepages,afeaturethatdesignatesaregionofphysical
memorywherelargerpages(forexample,2MB)maybeused.
Recall from Section 9.7 that the ARMv8 architecture provides support for
pagesandregionsofdifferentsizes.Additionally,eachTLBentryintheARMv8
containsacontiguousbit.IfthisbitissetforaparticularTLBentry,thatentry
mapscontiguous(adjacent)blocksofmemory.Threepossiblearrangementsof10.9 OtherConsiderations 433
contiguousblockscanbemappedinasingleTLBentry,therebyincreasingthe
TLBreach:
1. 64-KBTLBentrycomprising16×4KBadjacentblocks.
2. 1-GBTLBentrycomprising32×32MBadjacentblocks.
3. 2-MBTLBentrycomprisingeither32×64KBadjacentblocks,or128×16
KBadjacentblocks.
Providingsupport for multiplepagesizesmay requirethe operatingsys-
tem—ratherthanhardware—tomanagetheTLB.Forexample,oneofthefields
in a TLB entry must indicate the size of the page frame corresponding to the
entry—or,inthecaseofARMarchitectures,mustindicatethattheentryrefers
toacontiguousblockofmemory.ManagingtheTLBinsoftwareandnothard-
warecomesatacostinperformance.However,theincreasedhitratioandTLB
reachoffsettheperformancecosts.
10.9.4 Inverted Page Tables
Section 9.4.3 introduced the concept of the inverted page table. The purpose
ofthisformofpagemanagementistoreducetheamountofphysicalmemory
needed to track virtual-to-physical address translations. We accomplish this
savings by creating a table that has one entry per page of physical memory,
indexedbythepair<process-id,page-number>.
Becausetheykeepinformationaboutwhichvirtualmemorypageisstored
in each physical frame, inverted page tables reduce the amount of physical
memory needed to store this information. However, the inverted page table
no longer contains complete information about the logical addressspace of a
process,andthatinformationisrequiredifareferencedpageisnotcurrentlyin
memory.Demandpagingrequiresthisinformationtoprocesspagefaults.For
theinformationtobeavailable,anexternalpagetable(oneperprocess)must
be kept. Each such table looks like the traditional per-process page table and
containsinformationonwhereeachvirtualpageislocated.
Butdoexternalpagetablesnegatetheutilityofinvertedpagetables?Since
thesetablesarereferencedonlywhenapagefaultoccurs,theydonotneedto
beavailablequickly.Instead,theyarethemselvespagedinandoutofmemory
as necessary. Unfortunately, a page fault may now cause the virtual memory
managertogenerateanotherpagefaultasitpagesintheexternalpagetableit
needstolocatethevirtualpageonthebackingstore.Thisspecialcaserequires
carefulhandlinginthekernelandadelayinthepage-lookupprocessing.
10.9.5 Program Structure
Demand paging is designed to be transparent to the user program. In many
cases,theuseriscompletelyunawareofthepagednatureofmemory.Inother
cases,however,systemperformancecanbeimprovediftheuser(orcompiler)
hasanawarenessoftheunderlyingdemandpaging.
Let’slookatacontrivedbutinformativeexample.Assumethatpagesare
128 words in size. Consider a C program whose function is to initialize to 0
eachelementofa128-by-128array.Thefollowingcodeistypical:434 Chapter10 VirtualMemory
int i, j;
int[128][128] data;
for (j = 0; j < 128; j++)
for (i = 0; i < 128; i++)
data[i][j] = 0;
Notice that the array is stored row major; that is, the array is stored
data[0][0], data[0][1], ···, data[0][127], data[1][0], data[1][1], ···,
data[127][127].Forpagesof128words,eachrowtakesonepage.Thus,the
precedingcodezerosonewordineachpage,thenanotherwordineachpage,
andsoon.Iftheoperatingsystemallocatesfewerthan128framestotheentire
program,thenitsexecutionwillresultin128×128=16,384pagefaults.
Incontrast,supposewechangethecodeto
int i, j;
int[128][128] data;
for (i = 0; i < 128; i++)
for (j = 0; j < 128; j++)
data[i][j] = 0;
This code zeros all the words on one page before starting the next page,
reducingthenumberofpagefaultsto128.
Careful selection of data structures and programming structures can
increase locality and hence lower the page-fault rate and the number of
pages in the working set. For example, a stack has good locality, since access
is always made to the top. A hash table, in contrast, is designed to scatter
references, producing bad locality. Of course, locality of reference is just one
measureoftheefficiencyoftheuseofadatastructure.Otherheavilyweighted
factors include search speed, total number of memory references, and total
numberofpagestouched.
At a later stage, the compiler and loader can have a significant effect on
paging. Separating code and data and generating reentrant code means that
code pages can be read-only and hence will never be modified. Clean pages
do not have to be paged out to be replaced. The loader can avoid placing
routinesacrosspageboundaries,keepingeachroutinecompletelyinonepage.
Routines that call each other many times can be packed into the same page.
Thispackagingisavariantofthebin-packingproblemofoperationsresearch:
trytopackthevariable-sizedloadsegmentsintothefixed-sizedpagessothat
interpagereferencesareminimized.Suchanapproachisparticularlyusefulfor
largepagesizes.
10.9.6 I/O Interlock and Page Locking
Whendemandpagingisused,wesometimesneedtoallowsomeofthepages
tobelockedinmemory.OnesuchsituationoccurswhenI/Oisdonetoorfrom
user (virtual) memory. I/O is often implemented by a separate I/O processor.
Forexample,acontrollerforaUSBstoragedeviceisgenerallygiventhenumber10.9 OtherConsiderations 435
ofbytestotransferandamemoryaddressforthebuffer(Figure10.28).When
thetransferiscomplete,theCPUisinterrupted.
Wemustbesurethefollowingsequenceofeventsdoesnotoccur:Aprocess
issuesanI/OrequestandisputinaqueueforthatI/Odevice.Meanwhile,the
CPUisgiventootherprocesses.Theseprocessescausepagefaults,andoneof
them,usingaglobalreplacementalgorithm,replacesthepagecontaining the
memory buffer for the waiting process. The pages are paged out. Some time
later,when the I/Orequestadvances tothe headof thedevicequeue,the I/O
occurs to the specified address. However, this frame is now being used for a
differentpagebelongingtoanotherprocess.
Therearetwocommonsolutionstothisproblem.Onesolutionisneverto
executeI/Otousermemory.Instead,dataarealwayscopiedbetweensystem
memoryandusermemory.I/Otakesplaceonlybetweensystemmemoryand
the I/O device. Thus, to write a block on tape, we first copy the block to
system memory and then write it to tape. This extra copying may result in
unacceptablyhighoverhead.
Anothersolutionistoallowpagestobelockedintomemory.Here,alock
bitisassociatedwitheveryframe.Iftheframeislocked,itcannotbeselected
for replacement. Under this approach, to write a block to disk, we lock into
memorythepagescontainingtheblock.Thesystemcanthencontinueasusual.
Locked pages cannot be replaced. When the I/O is complete, the pages are
unlocked.
Lock bits are used in various situations. Frequently, some or all of the
operating-systemkernelislockedintomemory.Manyoperatingsystemscan-
not tolerate a page fault caused by the kernel or by a specific kernel module,
includingtheoneperformingmemorymanagement.Userprocessesmayalso
need to lock pages into memory. Adatabase process may want to manage a
chunkofmemory,forexample,movingblocksbetweensecondarystorageand
buffer
disk drive
Figure10.28 ThereasonwhyframesusedforI/Omustbeinmemory.436 Chapter10 VirtualMemory
memory itself because it has the best knowledge of how it is going to use its
data.Suchpinningofpagesinmemoryisfairlycommon,andmostoperating
systems have a system call allowing an application to request that a region
of its logical address space be pinned. Note that this feature could be abused
andcouldcausestressonthememory-managementalgorithms.Therefore,an
applicationfrequentlyrequiresspecialprivilegestomakesucharequest.
Another use for a lock bit involves normal page replacement. Consider
the following sequence of events: A low-priority process faults. Selecting a
replacementframe,thepagingsystemreadsthenecessarypageintomemory.
Readytocontinue,thelow-priorityprocessentersthereadyqueueandwaits
for the CPU. Since it is a low-priority process, it may not be selected by the
CPUschedulerforatime.Whilethelow-priorityprocesswaits,ahigh-priority
processfaults.Lookingforareplacement,thepagingsystemseesapagethat
is in memory but has not been referenced or modified: it is the page that the
low-priorityprocessjustbroughtin.Thispagelookslikeaperfectreplacement.
Itis cleanand willnot needtobe writtenout, and itapparentlyhas not been
usedforalongtime.
Whether the high-priority process should be able to replace the low-
priority process is a policy decision. After all, we are simply delaying the
low-priorityprocessforthebenefitofthehigh-priorityprocess.However,we
are wasting the effort spent to bring in the page for the low-priority process.
Ifwedecidetopreventreplacementofanewlybrought-inpageuntilitcanbe
usedatleastonce,thenwecanusethelockbittoimplementthismechanism.
Whenapageisselectedforreplacement,itslockbitisturnedon.Itremainson
untilthefaultingprocessisagaindispatched.
Using a lock bit can be dangerous: the lock bit may get turned on but
neverturnedoff.Shouldthissituationoccur(becauseofabugintheoperating
system,forexample),thelockedframebecomesunusable.Forinstance,Solaris
allows locking “hints,” but it is free to disregard these hints if the free-frame
poolbecomestoosmallorifanindividualprocessrequeststhattoomanypages
belockedinmemory.
10.10 Operating-System Examples
In this section, we describe how Linux, Windows and Solarismanage virtual
memory.
10.10.1 Linux
InSection10.8.2,wediscussedhowLinuxmanageskernelmemoryusingslab
allocation. We now cover how Linux manages virtual memory. Linux uses
demandpaging,allocatingpagesfromalistoffreeframes.Inaddition,ituses
aglobalpage-replacementpolicysimilartotheLRU-approximationclockalgo-
rithmdescribedinSection10.4.5.2.Tomanage memory,Linuxmaintainstwo
typesofpagelists:anactive listandaninactive list.Theactive list
contains the pages that are considered in use, while the inactive list con-
tains pages that have not recently been referenced and are eligible to be
reclaimed.10.10 Operating-SystemExamples 437
referenced
new
rear front
page
active_list
referenced
front rear
inactive_list
Figure10.29 TheLinuxactive listandinactive liststructures.
Eachpagehasanaccessed bitthatissetwheneverthepageisreferenced.
(Theactualbitsusedtomarkpageaccessvarybyarchitecture.)Whenapage
is first allocated, its accessed bit is set, and it is added to the rear of the
active list. Similarly, whenever a page in the active list is referenced,
its accessed bit is set, and the page moves to the rear of the list. Periodically,
the accessed bits for pages in the active list are reset. Over time, the least
recentlyusedpagewillbeatthefrontoftheactive list.Fromthere,itmay
migrate to the rear of the inactive list. If a page in the inactive list
is referenced, it moves back to the rear of the active list. This pattern is
illustratedinFigure10.29.
Thetwolistsarekeptinrelativebalance,andwhentheactive listgrows
much larger than the inactive list, pages at the front of the active list
movetotheinactive list,wheretheybecomeeligibleforreclamation.The
Linux kernel has a page-out daemon process kswapd that periodically awak-
ens and checks the amount of free memory in the system. If free memory
falls below a certain threshold, kswapd begins scanning pages in the inac-
tive list and reclaiming them for the free list. Linux virtual memory man-
agementisdiscussedingreaterdetailinChapter20.
10.10.2 Windows
Windows10supports32-and64-bitsystemsrunningonIntel(IA-32andx86-
64)andARMarchitectures.On32-bitsystems,thedefaultvirtualaddressspace
ofaprocessis2GB,althoughitcanbeextendedto3GB.32-bitsystemssupport
4 GB of physical memory. On 64-bit systems, Windows 10 has a 128-TB vir-
tualaddressspaceandsupportsupto24TBofphysicalmemory.(Versionsof
WindowsServersupportupto128TBofphysicalmemory.)Windows10imple-
mentsmostofthememory-managementfeaturesdescribedthusfar,including
shared libraries, demand paging, copy-on-write, paging, and memory com-
pression.438 Chapter10 VirtualMemory
Windows10implementsvirtualmemoryusingdemandpagingwithclus-
tering,astrategythat recognizes localityofmemoryreferencesand therefore
handlespagefaultsbybringinginnotonlythefaultingpagebutalsoseveral
pages immediately preceding and following the faulting page. The size of a
clustervariesbypagetype.Foradatapage,aclustercontainsthreepages(the
pagebeforeandthepageafterthefaultingpage);allotherpagefaultshavea
clustersizeofseven.
A key component of virtual memory management in Windows 10 is
working-setmanagement.Whenaprocessiscreated,itisassignedaworking-
set minimum of 50 pages and a working-set maximum of 345 pages. The
working-setminimumistheminimumnumberofpagestheprocessisguar-
anteedtohaveinmemory;ifsufficientmemoryisavailable,aprocessmaybe
assignedasmanypagesasitsworking-setmaximum.Unlessaprocessiscon-
figuredwithhardworking-setlimits,thesevaluesmaybeignored.Aprocess
cangrowbeyonditsworking-setmaximumif sufficientmemoryisavailable.
Similarly, the amount of memory allocated to a process can shrink below the
minimuminperiodsofhighdemandformemory.
WindowsusestheLRU-approximationclockalgorithm,asdescribedinSec-
tion10.4.5.2,withacombinationoflocalandglobalpage-replacementpolicies.
Thevirtualmemorymanagermaintainsalistoffreepageframes.Associated
withthislistisathresholdvaluethatindicateswhethersufficientfreememory
is available. If a page fault occurs for a process that is below its working-
set maximum, the virtual memory manager allocates a page from the list of
freepages.Ifaprocessthatisatitsworking-setmaximumincursapagefault
andsufficientmemoryisavailable,theprocessisallocatedafreepage,which
allowsittogrowbeyonditsworking-setmaximum.Iftheamountoffreemem-
ory is insufficient, however, the kernel must select a page from the process’s
workingsetforreplacementusingalocalLRUpage-replacementpolicy.
When the amount of free memory falls below the threshold, the vir-
tual memory manager uses a global replacement tactic known as automatic
working-set trimming to restore the value to a level above the threshold.
Automatic working-set trimming works by evaluating the number of pages
allocated to processes. If a process has been allocated more pages than its
working-setminimum,thevirtualmemorymanagerremovespagesfromthe
workingsetuntileitherthereissufficientmemoryavailableortheprocesshas
reached its working-set minimum. Larger processes that have been idle are
targeted before smaller, active processes. The trimming procedure continues
until there is sufficient free memory, even if it is necessary to remove pages
from a process already below its working set minimum. Windows performs
working-settrimmingonbothuser-modeandsystemprocesses.
10.10.3 Solaris
In Solaris, when a thread incurs a page fault, the kernel assigns a page to
the faulting thread from the list of free pages it maintains. Therefore, it is
imperativethatthekernelkeepasufficientamountoffreememoryavailable.
Associatedwiththislistoffreepagesisaparameter—lotsfree—thatrepre-
sentsathresholdtobeginpaging.Thelotsfreeparameteristypicallysetto
1∕64thesizeofthephysicalmemory.Fourtimespersecond,thekernelchecks
whether the amount of free memory is less than lotsfree. If the number of10.10 Operating-SystemExamples 439
freepagesfallsbelowlotsfree,aprocessknownasapageoutstartsup.The
pageoutprocessissimilartothesecond-chancealgorithmdescribedinSection
10.4.5.2,exceptthatitusestwohandswhilescanningpages,ratherthanone.
The pageout process works as follows: The front hand of the clock scans
allpagesinmemory,settingthereferencebitto0.Later,theback hand ofthe
clockexaminesthereferencebitforthepagesinmemory,appendingeachpage
whose reference bit is still set to 0 to the free list and writing its contents to
secondary storage if it has been modified. Solaris also manages minor page
faults by allowing a process to reclaim a page from the free list if the page is
accessedbeforebeingreassignedtoanotherprocess.
Thepageoutalgorithmusesseveralparameterstocontroltherateatwhich
pages are scanned (known as the scanrate). The scanrate is expressed in
pagespersecondandrangesfromslowscantofastscan.Whenfreememory
falls below lotsfree, scanning occurs at slowscan pages per second and
progressestofastscan,dependingontheamountof freememoryavailable.
Thedefaultvalueofslowscanis100pagespersecond.Fastscanistypically
settothevalue(totalphysicalpages)/2pagespersecond,withamaximumof
8,192pagespersecond.ThisisshowninFigure10.30(withfastscansettothe
maximum).
The distance (in pages) between the hands of the clock is determined
by a system parameter, handspread. The amount of time between the front
hand’s clearing a bit and the back hand’s investigating its value depends on
the scanrate and the handspread. If scanrate is 100 pages per second and
handspreadis1,024pages,10secondscanpassbetweenthetimeabitissetby
thefronthandandthetimeitischeckedbythebackhand.However,because
ofthedemandsplacedonthememorysystem,ascanrateofseveralthousand
is not uncommon. This means that the amount of time between clearing and
investigatingabitisoftenafewseconds.
minfree
etar
nacs
8192
fastscan
100
slowscan
desfree lotsfree
amount of free memory
Figure10.30 Solarispagescanner.440 Chapter10 VirtualMemory
As mentioned above, the pageout process checks memory four times per
second.However,iffreememoryfallsbelowthevalueofdesfree(thedesired
amountoffreememoryinthesystem),pageoutwillrunahundredtimesper
second with the intention of keeping at least desfree free memory available
(Figure 10.30). If the pageout process is unable to keep the amount of free
memory at desfree for a 30-second average, the kernel begins swapping
processes,therebyfreeingallpagesallocatedtoswappedprocesses.Ingeneral,
the kernel looks for processes that have been idle for long periods of time. If
the system is unable to maintain the amount of free memory at minfree, the
pageoutprocessiscalledforeveryrequestforanewpage.
The page-scanning algorithm skips pages belonging to libraries that are
beingsharedbyseveralprocesses,eveniftheyareeligibletobeclaimedbythe
scanner.Thealgorithmalsodistinguishesbetweenpagesallocatedtoprocesses
andpagesallocatedtoregulardatafiles.Thisisknownasprioritypagingand
iscoveredinSection14.6.2.
10.11 Summary
• Virtual memory abstracts physical memory into an extremely large uni-
formarrayofstorage.
• Thebenefitsofvirtualmemoryincludethefollowing:(1)aprogramcanbe
largerthanphysicalmemory,(2)aprogramdoesnotneedtobeentirelyin
memory,(3)processescansharememory,and(4)processescanbecreated
moreefficiently.
• Demandpagingisatechniquewherebypagesareloadedonlywhenthey
aredemandedduringprogramexecution.Pagesthatareneverdemanded
arethusneverloadedintomemory.
• A page fault occurs when a page that is currently not in memory is
accessed.Thepagemustbebroughtfromthebackingstoreintoanavail-
ablepageframeinmemory.
• Copy-on-write allows a child process to share the same address space as
itsparent.Ifeitherthechildortheparentprocesswrites(modifies)apage,
acopyofthepageismade.
• When available memory runs low, a page-replacement algorithm
selects an existing page in memory to replace with a new page. Page-
replacement algorithms include FIFO, optimal, and LRU. Pure LRU
algorithms are impractical to implement, and most systems instead use
LRU-approximationalgorithms.
• Globalpage-replacementalgorithmsselectapagefromanyprocessinthe
systemforreplacement,whilelocalpage-replacementalgorithmsselecta
pagefromthefaultingprocess.
• Thrashingoccurswhenasystemspendsmoretimepagingthanexecuting.
• A locality represents a set of pages that are actively used together. As a
processexecutes,itmovesfromlocalitytolocality.Aworkingsetisbased
onlocalityandisdefinedasthesetofpagescurrentlyinusebyaprocess.PracticeExercises 441
• Memory compression is a memory-management technique that com-
pressesanumber of pagesinto asingle page.Compressedmemory is an
alternative to paging and is used on mobile systems that do not support
paging.
• Kernelmemoryisallocateddifferentlythanuser-modeprocesses;itisallo-
catedincontiguouschunksofvaryingsizes.Twocommontechniquesfor
allocatingkernelmemoryare(1)thebuddysystemand(2)slaballocation.
• TLB reach refers to the amount of memory accessible from the TLB and is
equaltothenumberofentriesintheTLBmultipliedbythepagesize.One
techniqueforincreasingTLBreachistoincreasethesizeofpages.
• Linux, Windows, and Solaris manage virtual memory similarly, using
demand paging and copy-on-write, among other features. Each system
alsousesavariationofLRUapproximationknownastheclockalgorithm.
Practice Exercises
10.1 Under what circumstances do page faults occur? Describe the actions
takenbytheoperatingsystemwhenapagefaultoccurs.
10.2 Assume that you have a page-reference string for a process with m
frames(initiallyallempty).Thepage-referencestringhaslengthp,and
n distinct page numbers occur in it. Answer these questions for any
page-replacementalgorithms:
a. Whatisalowerboundonthenumberofpagefaults?
b. Whatisanupperboundonthenumberofpagefaults?
10.3 Considerthefollowingpage-replacementalgorithms.Rankthesealgo-
rithms on afive-point scale from “bad” to“perfect”according totheir
page-fault rate. Separate those algorithms that suffer from Belady’s
anomalyfromthosethatdonot.
a. LRUreplacement
b. FIFOreplacement
c. Optimalreplacement
d. Second-chancereplacement
10.4 An operating system supports a paged virtual memory. The central
processor has a cycle time of 1 microsecond. It costs an additional 1
microsecond to access a page other than the current one. Pages have
1,000 words, and the paging device is a drum that rotates at 3,000
revolutionsperminuteandtransfers1millionwordspersecond.The
followingstatisticalmeasurementswereobtainedfromthesystem:
• Onepercentofallinstructionsexecutedaccessedapageotherthan
thecurrentpage.
• Oftheinstructionsthataccessedanotherpage,80percentaccessed
apagealreadyinmemory.442 Chapter10 VirtualMemory
• When a new page was required, the replaced page was modified
50percentofthetime.
Calculate the effective instruction time on this system, assuming that
the system is running one process only and that the processor is idle
duringdrumtransfers.
10.5 Consider the page table for a system with 12-bit virtual and physical
addressesand256-bytepages.
Page Page Frame
0 –
1 2
2 C
3 A
4 –
5 4
6 3
7 –
8 B
9 0
ThelistoffreepageframesisD,E,F(thatis,Disattheheadofthelist,
E is second, and F is last). Adash for a page frame indicates that the
pageisnotinmemory.
Convertthefollowingvirtualaddressestotheirequivalentphysical
addressesinhexadecimal.Allnumbersaregiveninhexadecimal.
• 9EF
• 111
• 700
• 0FF
10.6 Discussthehardwarefunctionsrequiredtosupportdemandpaging.
10.7 Considerthetwo-dimensionalarrayA:
int A[][] = new int[100][100];
whereA[0][0]isatlocation200inapagedmemorysystemwithpages
ofsize200.Asmallprocessthatmanipulatesthematrixresidesinpage
0(locations0to199).Thus,everyinstructionfetchwillbefrompage0.
For three page frames, how many page faults are generated by the
followingarray-initializationloops?UseLRUreplacement,andassumePracticeExercises 443
that page frame 1 contains the process and the other two are initially
empty.
a. for (int j = 0; j < 100; j++)
for (int i = 0; i < 100; i++)
A[i][j] = 0;
b. for (int i = 0; i < 100; i++)
for (int j = 0; j < 100; j++)
A[i][j] = 0;
10.8 Considerthefollowingpagereferencestring:
1,2,3,4,2,1,5,6,2,1,2,3,7,6,3,2,1,2,3,6.
How many page faults would occur for the following replacement
algorithms,assumingone,two,three,four,five,six,andsevenframes?
Rememberthatallframesareinitiallyempty,soyourfirstuniquepages
willcostonefaulteach.
• LRUreplacement
• FIFOreplacement
• Optimalreplacement
10.9 Considerthefollowingpagereferencestring:
7,2,3,1,2,5,3,4,6,7,7,1,0,5,4,6,2,3,0,1.
Assuming demand paging with three frames, how many page faults
wouldoccurforthefollowingreplacementalgorithms?
• LRUreplacement
• FIFOreplacement
• Optimalreplacement
10.10 Suppose that you want to use a paging algorithm that requires a ref-
erencebit(suchassecond-chancereplacementorworking-setmodel),
but the hardware does not provide one. Sketch how you could simu-
lateareferencebit evenifone werenot providedbythehardware,or
explain why it is not possible to do so. If it is possible, calculate what
thecostwouldbe.
10.11 You have devised a new page-replacement algorithm that you think
maybeoptimal.Insomecontortedtestcases,Belady’sanomalyoccurs.
Isthenewalgorithmoptimal?Explainyouranswer.
10.12 Segmentation is similar to paging but uses variable-sized “pages.”
Define two segment-replacement algorithms, one based on the FIFO
page-replacementschemeandtheotherontheLRUpage-replacement
scheme.Rememberthatsincesegmentsarenotthesamesize,theseg-
mentthatischosenforreplacementmaybetoosmalltoleaveenough444 Chapter10 VirtualMemory
consecutive locations for the needed segment. Consider strategies for
systemswheresegmentscannotberelocatedandstrategiesforsystems
wheretheycan.
10.13 Considerademand-pagedcomputersystemwherethedegreeofmulti-
programmingiscurrentlyfixedatfour.Thesystemwasrecentlymea-
sured to determine utilization of the CPU and the paging disk. Three
alternativeresultsareshownbelow.Foreachcase,whatishappening?
CanthedegreeofmultiprogrammingbeincreasedtoincreasetheCPU
utilization?Isthepaginghelping?
a. CPUutilization13percent;diskutilization97percent
b. CPUutilization87percent;diskutilization3percent
c. CPUutilization13percent;diskutilization3percent
10.14 We have an operating system for a machine that uses base and limit
registers, but we have modified the machine to provide a page table.
Canthepagetablebesetuptosimulatebaseandlimitregisters?How
canitbe,orwhycanitnotbe?
Further Reading
The working-set model was developed by [Denning (1968)]. The
enhanced clock algorithm is discussed by [Carr and Hennessy (1981)].
[Russinovich et al. (2017)] describe how Windows implements vir-
tual memory and memory compression. Compressed memory in
Windows 10 is further discussed in http://www.makeuseof.com/
tag/ram-compression-improves-memory-responsiveness-windows-10.
[McDougallandMauro(2007)]discussvirtualmemoryinSolaris.Virtual
memory techniques in Linux are described in [Love (2010)] and [Mauerer
(2008)].FreeBSDisdescribedin[McKusicketal.(2015)].
Bibliography
[CarrandHennessy(1981)] W.R.CarrandJ.L.Hennessy,“WSClock—ASim-
ple and Effective Algorithm for Virtual Memory Management”, Proceedings of
theACMSymposiumonOperatingSystemsPrinciples(1981),pages87–95.
[Denning(1968)] P.J.Denning,“TheWorkingSetModelforProgramBehavior”,
CommunicationsoftheACM,Volume11,Number5(1968),pages323–333.
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[Mauerer(2008)] W.Mauerer,ProfessionalLinux KernelArchitecture,JohnWiley
andSons(2008).
[McDougallandMauro(2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition,PrenticeHall(2007).Bibliography 445
[McKusicketal.(2015)] M.K.McKusick,G.V.Neville-Neil,andR.N.M.Wat-
son,TheDesignandImplementationoftheFreeBSDUNIXOperatingSystem–Second
Edition,Pearson(2015).
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).EX-35
Chapter 10 Exercises
10.15 Assumethataprogramhasjustreferencedanaddressinvirtualmem-
ory.Describeascenarioinwhicheachofthefollowingcanoccur.(Ifno
suchscenariocanoccur,explainwhy.)
• TLBmisswithnopagefault
• TLBmisswithpagefault
• TLBhitwithnopagefault
• TLBhitwithpagefault
10.16 Asimplifiedviewofthreadstatesisready,running,andblocked,where
athreadiseitherreadyandwaitingtobescheduled,isrunningonthe
processor,orisblocked(forexample,waitingforI/O).
ready
blocked running
Assumingathreadisintherunning state,answerthefollowingques-
tions,andexplainyouranswers:
a. Willthethreadchangestateifitincursapagefault?Ifso,towhat
statewillitchange?
b. Will the thread change state if it generates a TLB miss that is
resolvedinthepagetable?Ifso,towhatstatewillitchange?
c. Willthethreadchangestateifanaddressreferenceisresolvedin
thepagetable?Ifso,towhatstatewillitchange?
10.17 Considerasystemthatusespuredemandpaging.
a. Whenaprocessfirststartsexecution,howwouldyoucharacterize
thepage-faultrate?
b. Once the working set for a process is loaded into memory, how
wouldyoucharacterizethepage-faultrate?
c. Assumethataprocesschangesitslocalityandthesizeofthenew
working set is too large to be stored in available free memory.
Identify some options system designers could choose from to
handlethissituation.
10.18 The following is a page table for a system with 12-bit virtual and
physical addresses and 256-byte pages. Free page frames are to be
allocatedintheorder9, F, D.Adashforapageframeindicatesthat
thepageisnotinmemory.Exercises EX-36
Page Page Frame
0 0 x 4
1 0 x B
2 0 x A
3 –
4 –
5 0 x 2
6 –
7 0 x 0
8 0 x C
9 0 x 1
Convert the following virtual addresses to their equivalent physical
addressesinhexadecimal.Allnumbersaregiveninhexadecimal.Inthe
caseofapagefault,youmustuseoneofthefreeframestoupdatethe
pagetableandresolvethelogicaladdresstoitscorrespondingphysical
address.
• 0x2A1
• 0x4E6
• 0x94A
• 0x316
10.19 Whatisthecopy-on-writefeature,andunderwhatcircumstancesisits
use beneficial? What hardware support is required to implement this
feature?
10.20 Acertaincomputerprovidesitsuserswithavirtualmemoryspaceof
232 bytes.Thecomputerhas222 bytesofphysicalmemory.Thevirtual
memory is implemented by paging, and the page size is 4,096 bytes.
A user process generates the virtual address 11123456. Explain how
thesystemestablishesthecorrespondingphysicallocation.Distinguish
betweensoftwareandhardwareoperations.
10.21 Assume that we have a demand-paged memory. The page table is
held in registers. It takes 8 milliseconds to service a page fault if an
emptyframeisavailableorifthereplacedpageisnotmodifiedand20
milliseconds if the replaced page is modified. Memory-access time is
100nanoseconds.
Assume that the page to be replaced is modified 70 percent of the
time.Whatisthemaximumacceptablepage-faultrateforaneffective
accesstimeofnomorethan200nanoseconds?
10.22 Consider the page table for a system with 16-bit virtual and physical
addressesand4,096-bytepages.EX-37
Page Page Frame Reference Bit
0 9 0
1 – 0
2 10 0
3 15 0
4 6 0
5 13 0
6 8 0
7 12 0
8 7 0
9 – 0
10 5 0
11 4 0
12 1 0
13 0 0
14 – 0
15 2 0
The reference bit for a page is set to 1 when the page has been ref-
erenced. Periodically, a thread zeroes out all values of the reference
bit. Adash for apage frame indicates that the page is not in memory.
Thepage-replacementalgorithmislocalizedLRU,andallnumbersare
providedindecimal.
a. Convert the following virtual addresses (in hexadecimal) to the
equivalentphysicaladdresses.Youmayprovideanswersineither
hexadecimalordecimal.Alsosetthereferencebitfortheappro-
priateentryinthepagetable.
• 0x621C
• 0xF0A3
• 0xBC1A
• 0x5BAA
• 0x0BA1
b. Using the above addresses as a guide, provide an example of a
logicaladdress(inhexadecimal)thatresultsinapagefault.
c. From what set of page frames will the LRU page-replacement
algorithmchooseinresolvingapagefault?
10.23 Whenapagefaultoccurs,theprocessrequestingthepagemustblock
whilewaitingforthepagetobebroughtfromdiskintophysicalmem-
ory.Assumethatthereexistsaprocesswithfiveuser-levelthreadsand
that the mapping of user threads to kernel threads is many to one. IfExercises EX-38
oneuserthreadincursapagefaultwhileaccessingitsstack,wouldthe
otheruserthreadsbelongingtothesameprocessalsobeaffectedbythe
pagefault—thatis,wouldtheyalsohavetowaitforthefaultingpage
tobebroughtintomemory?Explain.
10.24 Apply the (1) FIFO, (2) LRU, and (3) optimal (OPT) replacement algo-
rithmsforthefollowingpage-referencestrings:
• 2,6,9,2,4,2,1,7,3,0,5,2,1,2,9,5,7,3,8,5
• 0,6,3,0,2,6,3,5,2,4,1,3,0,6,1,4,2,3,5,7
• 3,1,4,2,5,4,1,3,5,2,0,1,1,0,2,3,4,5,0,1
• 4,2,1,7,9,8,3,5,2,6,8,1,0,7,2,4,1,3,5,8
• 0,1,2,3,4,4,3,2,1,0,0,1,2,3,4,4,3,2,1,0
Indicate the number of page faults for each algorithm assuming
demandpagingwiththreeframes.
10.25 Assume that you are monitoring the rate at which the pointer in the
clock algorithm moves. (The pointer indicates the candidate page for
replacement.) What can you say about the system if you notice the
followingbehavior:
a. Pointerismovingfast.
b. Pointerismovingslow.
10.26 Discuss situations in which the least frequently used (LFU) page-
replacement algorithm generates fewer page faults than the least
recently used (LRU) page-replacement algorithm. Also discuss under
whatcircumstancestheoppositeholds.
10.27 Discuss situations in which the most frequently used (MFU) page-
replacement algorithm generates fewer page faults than the least
recently used (LRU) page-replacement algorithm. Also discuss under
whatcircumstancestheoppositeholds.
10.28 The KHIE (pronounced “k-hi”) operating system uses a FIFO replace-
ment algorithm for resident pages and a free-frame pool of recently
usedpages.Assumethatthefree-framepoolismanagedusingtheLRU
replacementpolicy.Answerthefollowingquestions:
a. Ifapagefaultoccursandthepagedoesnotexistinthefree-frame
pool,howisfreespacegeneratedforthenewlyrequestedpage?
b. If a page fault occurs and the page exists in the free-frame pool,
how are the resident page set and the free-frame pool managed
tomakespacefortherequestedpage?
c. To what does the system degenerate if the number of resident
pagesissettoone?
d. Towhatdoesthesystemdegenerateifthenumberofpagesinthe
free-framepooliszero?EX-39
10.29 Considerademand-pagingsystemwiththefollowingtime-measured
utilizations:
CPUutilization 20%
Pagingdisk 97.7%
OtherI/Odevices 5%
For each of the following, indicate whether it will (or is likely to)
improveCPUutilization.Explainyouranswers.
a. InstallafasterCPU.
b. Installabiggerpagingdisk.
c. Increasethedegreeofmultiprogramming.
d. Decreasethedegreeofmultiprogramming.
e. Installmoremainmemory.
f. Install a faster hard disk or multiple controllers with multiple
harddisks.
g. Addprepagingtothepage-fetchalgorithms.
h. Increasethepagesize.
10.30 Explainwhyminorpagefaultstakelesstimetoresolvethanmajorpage
faults.
10.31 Explain why compressed memory is used in operating systems for
mobiledevices.
10.32 Suppose that a machine provides instructions that can access mem-
ory locations using the one-level indirect addressing scheme. What
sequenceofpagefaultsisincurredwhenallofthepagesofaprogram
arecurrentlynonresidentandthefirstinstructionoftheprogramisan
indirect memory-load operation? What happens when the operating
systemisusingaper-processframeallocationtechniqueandonlytwo
pagesareallocatedtothisprocess?
10.33 Considerthepagereferences:Exercises
34
32
30
28
26
24
22
20
18
sserdda
yromem
srebmun
egap
EX-40
(X)
execution time
Whatpagesrepresentthelocalityattime(X)?
10.34 Supposethatyourreplacementpolicy(inapagedsystem)istoexamine
eachpageregularlyandtodiscardthatpageifithasnotbeenusedsince
thelastexamination.What wouldyougainand what wouldyoulose
byusingthispolicyratherthanLRUorsecond-chancereplacement?
10.35 A page-replacement algorithm should minimize the number of page
faults. We can achieve this minimization by distributing heavily used
pagesevenlyoverallofmemory,ratherthanhavingthemcompetefor
asmallnumberofpageframes.Wecanassociatewitheachpageframe
a counter of the number of pages associated with that frame. Then,EX-41
to replace a page, we can search for the page frame with the smallest
counter.
a. Defineapage-replacementalgorithmusingthisbasicidea.Specif-
icallyaddresstheseproblems:
• Whatistheinitialvalueofthecounters?
• Whenarecountersincreased?
• Whenarecountersdecreased?
• Howisthepagetobereplacedselected?
b. Howmanypagefaultsoccurforyouralgorithmforthefollowing
referencestringwithfourpageframes?
1,2,3,4,5,3,4,1,6,7,8,7,8,9,7,8,9,5,4,5,4,2.
c. Whatistheminimumnumberofpagefaultsforanoptimalpage-
replacement strategy for the reference string in part b with four
pageframes?
10.36 Consider a demand-paging system with a paging disk that has an
average access and transfer time of 20 milliseconds. Addresses are
translated through a page table in main memory, with an access time
of 1 microsecond per memory access. Thus, each memory reference
through the page table takes two accesses. To improve this time, we
have added an associative memory that reduces access time to one
memoryreferenceifthepage-tableentryisintheassociativememory.
Assumethat80percentoftheaccessesareintheassociativememory
andthat,ofthoseremaining,10percent(or2percentofthetotal)cause
pagefaults.Whatistheeffectivememoryaccesstime?
10.37 Whatisthecauseofthrashing?Howdoesthesystemdetectthrashing?
Once it detects thrashing, what can the system do to eliminate this
problem?
10.38 Isitpossibleforaprocesstohavetwoworkingsets,one representing
dataandanotherrepresentingcode?Explain.
10.39 Consider the parameter Δused to define the working-set window in
theworking-setmodel.WhenΔissettoalowvalue,whatistheeffect
onthepage-faultfrequencyandthenumberofactive(nonsuspended)
processescurrentlyexecutinginthesystem?WhatistheeffectwhenΔ
issettoaveryhighvalue?
10.40 In a 1,024-KB segment, memory is allocated using the buddy system.
UsingFigure10.26asaguide,drawatreeillustratinghowthefollowing
memoryrequestsareallocated:
• Request5-KB
• Request135KB.
• Request14KB.
• Request3KB.Exercises EX-42
• Request12KB.
Next, modify the tree for the following releases of memory. Perform
coalescingwheneverpossible:
• Release3KB.
• Release5KB.
• Release14KB.
• Release12KB.
10.41 Asystemprovidessupportforuser-levelandkernel-levelthreads.The
mapping in this system is one to one (there is a corresponding kernel
thread for each user thread). Does a multithreaded process consist of
(a) a working set for the entire process or (b) a working set for each
thread?Explain
10.42 The slab-allocation algorithm uses a separate cache for each different
object type.Assumingthereisone cache perobject type,explainwhy
thisschemedoesn’tscalewellwithmultipleCPUs.Whatcouldbedone
toaddressthisscalabilityissue?
10.43 Considerasystemthatallocatespagesofdifferentsizestoitsprocesses.
What are the advantages of such a paging scheme? What modifica-
tions to the virtual memory system would be needed to provide this
functionality?ProgrammingProblems P-51
Programming Problems
10.44 Write a program that implements the FIFO, LRU, and optimal (OPT)
page-replacementalgorithmspresentedinSection10.4.Haveyourpro-
gram initially generate a random page-reference string where page
numbersrangefrom0to9.Applytherandompage-referencestringto
eachalgorithm,andrecordthenumberofpagefaultsincurredbyeach
algorithm.Pass thenumber ofpageframestotheprogramatstartup.
You may implement this program in any programming language of
yourchoice.(YoumayfindyourimplementationofeitherFIFOorLRU
tobehelpfulinthevirtualmemorymanagerprogrammingproject.)
Programming Projects
Designing aVirtualMemoryManager
This project consists of writing a program that translates logical to physical
addressesforavirtualaddressspaceofsize216 =65,536bytes.Yourprogram
willreadfromafilecontaininglogicaladdressesand,usingaTLBandapage
table,willtranslateeachlogicaladdresstoitscorrespondingphysicaladdress
and output the value of the byte stored at the translated physical address.
Your learning goal is to use simulation to understand the steps involved in
translatinglogicaltophysicaladdresses.Thiswillincluderesolvingpagefaults
usingdemandpaging,managingaTLB,andimplementingapage-replacement
algorithm.
Specific
Your program will read a file containing several 32-bit integer numbers that
represent logical addresses. However, you need only be concerned with 16-
bitaddresses,soyoumustmasktherightmost16bitsofeachlogicaladdress.
These 16 bits are divided into (1) an 8-bit page number and (2) an 8-bit page
offset.Hence,theaddressesarestructuredasshownas:
page
offset
number
31 1615 8 7 0
Otherspecificsincludethefollowing:
• 28 entriesinthepagetable
• Pagesizeof28 bytes
• 16entriesintheTLB
• Framesizeof28 bytes
• 256frames
• Physicalmemoryof65,536bytes(256frames×256-byteframesize)P-52 Chapter10 VirtualMemory
Additionally, your program need only be concerned with reading logical
addressesandtranslatingthemtotheircorrespondingphysicaladdresses.You
donotneedtosupportwritingtothelogicaladdressspace.
AddressTranslation
YourprogramwilltranslatelogicaltophysicaladdressesusingaTLBandpage
table as outlined in Section 9.3. First, the page number is extracted from the
logical address, and the TLB is consulted. In the case of a TLB hit, the frame
number is obtained from the TLB. In the case of a TLB miss, the page table
mustbeconsulted.Inthelattercase,eithertheframenumberisobtainedfrom
the page table, or a page fault occurs. Avisual representationof the address-
translationprocessis:
page
offset
number
page frame
number number
0
1
2
. 0 frame 0
.
TLB hit 1 frame 1
.
. 2 frame 2
.
15 frame offset .
number .
TLB
.
0 page 0 255 frame 255
1 page 1
physical
2 page 2 memory
.
.
.
TLB miss .
255 page 255
page
table
HandlingPageFaults
YourprogramwillimplementdemandpagingasdescribedinSection10.2.The
backing store is represented by the file BACKING STORE.bin, a binary file of
size 65,536 bytes. When a page fault occurs, you will read in a 256-byte page
fromthefileBACKING STOREandstoreitinanavailablepageframeinphysical
memory.For example, if a logical address with page number 15 resultedin a
pagefault,yourprogramwouldreadinpage15fromBACKING STORE(remem-
berthatpagesbeginat0andare256bytesinsize)andstoreitinapageframe
inphysicalmemory.Oncethisframeisstored(andthepagetableandTLBare
updated),subsequentaccessestopage15willberesolvedbyeithertheTLBor
thepagetable.ProgrammingProjects P-53
YouwillneedtotreatBACKING STORE.binasarandom-accessfilesothat
youcanrandomlyseektocertainpositionsofthefileforreading.Wesuggest
usingthestandardClibraryfunctionsforperformingI/O,includingfopen(),
fread(),fseek(),andfclose().
Thesizeofphysicalmemoryisthesameasthesizeofthevirtualaddress
space—65,536bytes—soyoudonotneedtobeconcernedaboutpagereplace-
ments during a page fault. Later, we describe a modification to this project
usingasmalleramountofphysicalmemory;atthatpoint,apage-replacement
strategywillberequired.
TestFile
Weprovidethefileaddresses.txt,whichcontainsintegervaluesrepresent-
ing logical addresses ranging from 0to65535 (the size of the virtual address
space).Yourprogramwillopenthisfile,readeachlogicaladdressandtranslate
ittoitscorrespondingphysicaladdress,andoutputthevalueofthesignedbyte
atthephysicaladdress.
HowtoBegin
First, write a simple program that extracts the page number and offset based
on:
page
offset
number
31 1615 8 7 0
fromthefollowingintegernumbers:
1,256,32768,32769,128,65534,33153
Perhapstheeasiestwaytodothisisbyusingtheoperatorsforbit-maskingand
bit-shifting.Onceyoucancorrectlyestablishthepagenumberandoffsetfrom
anintegernumber,youarereadytobegin.
Initially,wesuggestthatyoubypasstheTLBanduseonlyapagetable.You
can integrate the TLB once your page table is working properly. Remember,
addresstranslationcanworkwithoutaTLB;theTLBjustmakesitfaster.When
you are ready to implement the TLB, recall that it has only sixteen entries, so
youwillneedtouseareplacementstrategywhen youupdateafullTLB.You
mayuseeitheraFIFOoranLRUpolicyforupdatingyourTLB.
HowtoRunYourProgram
Yourprogramshouldrunasfollows:
./a.out addresses.txt
Yourprogramwillreadinthefileaddresses.txt,whichcontains1,000logical
addresses ranging from 0 to 65535. Your program is to translate each logical
address to a physical address and determine the contents of the signed byte
storedatthecorrectphysicaladdress.(RecallthatintheClanguage,thechar
datatypeoccupiesabyteofstorage,sowesuggestusingcharvalues.)P-54 Chapter10 VirtualMemory
Yourprogramistooutputthefollowingvalues:
1. The logical address being translated (the integer value being read from
addresses.txt).
2. The corresponding physical address (what your program translates the
logicaladdressto).
3. Thesignedbytevaluestoredinphysicalmemoryatthetranslatedphys-
icaladdress.
We also provide the file correct.txt, which contains the correct output
valuesforthefileaddresses.txt.Youshouldusethisfiletodetermineifyour
programiscorrectlytranslatinglogicaltophysicaladdresses.
Statistics
Aftercompletion,yourprogramistoreportthefollowingstatistics:
1. Page-fault rate—The percentage of address references that resulted in
pagefaults.
2. TLBhitrate—Thepercentageofaddressreferencesthatwereresolvedin
theTLB.
Since the logical addresses in addresses.txt were generated randomly and
donotreflectanymemoryaccesslocality,donotexpecttohaveahighTLBhit
rate.
PageReplacement
Thusfar,thisprojecthasassumedthatphysicalmemoryisthesamesizeasthe
virtualaddressspace.Inpractice,physicalmemoryistypicallymuchsmaller
than a virtual address space. This phase of the project now assumes using
a smaller physical address space with 128 page frames rather than 256. This
changewillrequiremodifyingyourprogramsothatitkeepstrackoffreepage
framesaswellasimplementingapage-replacementpolicyusingeitherFIFOor
LRU(Section10.4)toresolvepagefaultswhenthereisnofreememory.Part Five
Storage
Management
Computer systems must provide mass storage for permanently storing
filesanddata.Moderncomputersimplementmassstorageassecondary
storage,usingbothharddisksandnonvolatilememorydevices.
Secondary storage devices vary in many aspects. Some transfer a
character at a time, and some a block of characters. Some can be
accessedonlysequentially,andothersrandomly.Sometransferdatasyn-
chronously,and othersasynchronously.Somearededicated,andsome
shared. They can be read-only or read–write. And although they vary
greatly in speed, they are in many ways the slowest major component
ofthecomputer.
Because of all this device variation, the operating system needs to
provide a wide range of functionality so that applications can control
all aspects of the devices. One key goal of an operating system’s I/O
subsystemistoprovidethesimplestinterfacepossibletotherestofthe
system. Because devices are a performance bottleneck, another key is
tooptimizeI/Oformaximumconcurrency.11
CHAPTER
Mass -Storage
Structure
In this chapter, we discuss how mass storage—the nonvolatile storage sys-
tem of a computer—is structured. The main mass-storage system in modern
computersissecondarystorage,whichisusuallyprovidedbyharddiskdrives
(HDD)andnonvolatilememory(NVM)devices.Somesystemsalsohaveslower,
larger,tertiarystorage,generallyconsistingofmagnetictape,opticaldisks,or
evencloudstorage.
Becausethemostcommonandimportantstoragedevicesinmoderncom-
putersystemsareHDDsandNVMdevices,thebulkofthischapterisdevoted
todiscussingthesetwotypesofstorage.Wefirstdescribetheirphysicalstruc-
ture.Wethenconsiderschedulingalgorithms,whichscheduletheorderofI/Os
to maximize performance. Next, we discuss device formatting and manage-
mentofbootblocks,damagedblocks,andswapspace.Finally,weexaminethe
structureofRAIDsystems.
There are many types of mass storage, and we use the general term non-
volatile storage (NVS) or talk about storage “drives” when the discussion
includes all types. Particular devices, such as HDDs and NVM devices, are
specifiedasappropriate.
CHAPTER OBJECTIVES
• Describethephysicalstructuresofvarioussecondarystoragedevicesand
theeffectofadevice’sstructureonitsuses.
• Explaintheperformancecharacteristicsofmass-storagedevices.
• EvaluateI/Oschedulingalgorithms.
• Discuss operating-system services provided for mass storage, including
RAID.
11.1 Overview of Mass-Storage Structure
The bulk of secondary storage for modern computers is provided by hard
disk drives (HDDs) and nonvolatile memory (NVM) devices. In this section,
449450 Chapter11 Mass-StorageStructure
track t spindle
arm assembly
sector s
cylinder c read-write
head
platter
arm
rotation
Figure11.1 HDDmoving-headdiskmechanism.
we describe the basic mechanisms of these devices and explain how operat-
ing systems translate their physical properties to logical storage via address
mapping.
11.1.1 Hard Disk Drives
Conceptually, HDDs are relatively simple (Figure 11.1). Each disk platter has
a flat circular shape, like a CD. Common platter diameters range from 1.8 to
3.5inches.Thetwosurfacesofaplatterarecoveredwithamagneticmaterial.
Westoreinformationbyrecordingitmagneticallyontheplatters,andweread
informationbydetectingthemagneticpatternontheplatters.
A read–write head “flies” just above each surface of every platter. The
headsareattachedtoadiskarmthatmovesalltheheadsasaunit.Thesurface
ofaplatterislogicallydividedintocirculartracks,whicharesubdividedinto
sectors. The set of tracks at a given arm position make up a cylinder. There
maybethousandsofconcentriccylindersinadiskdrive,andeachtrackmay
contain hundreds of sectors. Each sector has a fixed size and is the smallest
unit of transfer. The sector size was commonly 512 bytes until around 2010.
Atthatpoint,manymanufacturersstartmigratingto4KBsectors.Thestorage
capacityofcommondiskdrivesismeasuredingigabytesandterabytes.Adisk
drivewiththecoverremovedisshowninFigure11.2.
Adiskdrivemotorspinsitathighspeed.Mostdrivesrotate60to250times
persecond,specifiedintermsofrotationsperminute(RPM).Commondrives
spin at 5,400, 7,200, 10,000, and 15,000 RPM. Some drives power down when
not in use and spin up upon receiving an I/O request. Rotation speed relates
to transfer rates. The transfer rate is the rate at which data flow between the
driveandthecomputer.Anotherperformanceaspect,thepositioningtime,or
random-accesstime,consistsoftwoparts:thetimenecessarytomovethedisk
armtothedesiredcylinder,calledtheseektime,andthetimenecessaryforthe11.1 OverviewofMass-StorageStructure 451
Figure11.2 A3.5-inchHDDwithcoverremoved.
desiredsectortorotatetothediskhead,calledtherotationallatency.Typical
diskscantransfertenstohundredsofmegabytesofdatapersecond,andthey
haveseektimesandrotationallatenciesofseveralmilliseconds.Theyincrease
performancebyhavingDRAMbuffersinthedrivecontroller.
Thediskheadfliesonanextremelythincushion(measuredinmicrons)of
airoranothergas,suchashelium,andthereisadangerthattheheadwillmake
contactwiththedisksurface.Althoughthediskplattersarecoatedwithathin
protective layer, the head will sometimes damage the magnetic surface. This
accidentiscalledaheadcrash.Aheadcrashnormallycannotberepaired;the
entirediskmustbereplaced,andthedataonthediskarelostunlesstheywere
backed up to other storage or RAID protected. (RAID is discussed in Section
11.8.)
HDDs are sealed units, and some chassis that hold HDDs allow their
removalwithout shuttingdownthesystemorstoragechassis.Thisishelpful
when a system needs more storage than can be connected at a given time or
whenitisnecessarytoreplaceabaddrivewithaworkingone.Othertypesof
storagemediaarealsoremovable,includingCDs,DVDs,andBlu-raydiscs.
DISKTRANSFERRATES
As with many aspects of computing, published performance numbers for
disks are not the same as real-world performance numbers. Stated transfer
ratesarealwayshigherthaneffectivetransferrates,forexample.Thetransfer
ratemaybetherateatwhichbitscanbereadfromthemagneticmediabythe
diskhead,butthatisdifferentfromtherateatwhichblocksaredeliveredto
theoperatingsystem.452 Chapter11 Mass-StorageStructure
11.1.2 Nonvolatile Memory Devices
Nonvolatile memory (NVM) devices are growing in importance. Simply
described,NVMdevicesareelectricalratherthanmechanical.Mostcommonly,
such adeviceis composed ofacontroller and flashNAND diesemiconductor
chips, which are used to store data. Other NVM technologies exist, like
DRAM with battery backing so it doesn’t lose its contents, as well as other
semiconductor technology like 3D XPoint, but they are far less common and
soarenotdiscussedinthisbook.
11.1.2.1 OverviewofNonvolatileMemoryDevices
Flash-memory-basedNVMisfrequentlyusedinadisk-drive-likecontainer,in
whichcaseitiscalledasolid-statedisk(SSD)(Figure11.3).Inotherinstances,
ittakestheformofaUSBdrive(alsoknownasathumbdriveorflashdrive)ora
DRAMstick.Itisalsosurface-mountedontomotherboardsasthemainstorage
indeviceslikesmartphones.Inallforms,itactsandcanbetreatedinthesame
way.OurdiscussionofNVMdevicesfocusesonthistechnology.
NVMdevicescanbemorereliablethanHDDsbecausetheyhavenomoving
parts and can be faster because they have no seek time or rotational latency.
In addition, they consume less power. On the negative side, they are more
expensivepermegabytethantraditionalharddisksandhavelesscapacitythan
the larger hard disks. Over time, however, the capacity of NVM devices has
increasedfasterthanHDDcapacity,andtheirpricehasdroppedmorequickly,
so their use is increasing dramatically. In fact, SSDs and similar devices are
now used in some laptop computers to make them smaller, faster, and more
energy-efficient.
Because NVMdevicescan be much faster than hard diskdrives,standard
bus interfaces can cause a major limit on throughput. Some NVM devices
are designed to connect directly to the system bus (PCIe, for example). This
technology is changing other traditional aspects of computer design as well.
Figure11.3 A3.5-inchSSDcircuitboard.11.1 OverviewofMass-StorageStructure 453
Some systems use it as a direct replacement for disk drives, while others use
it as a new cache tier, moving data among magnetic disks, NVM, and main
memorytooptimizeperformance.
NAND semiconductors have some characteristics that present their own
storage and reliability challenges. For example, they can be read and written
in a “page” increment (similar to a sector), but data cannot be overwritten—
rather, the NAND cells have to be erased first. The erasure, which occurs in
a “block” increment that is several pages in size, takes much more time than
a read (the fastest operation) or a write (slower than read, but much faster
than erase). Helping the situation is that NVM flash devices are composed
of many die, with many datapaths to each die, so operations can happen in
parallel (each using a datapath). NAND semiconductors also deteriorate with
every erase cycle, and after approximately 100,000 program-erase cycles (the
specific number varies depending on the medium), the cells no longer retain
data.Becauseofthewritewear,andbecausetherearenomovingparts,NAND
NVM lifespan is not measured in years but in Drive Writes Per Day (DWPD).
That measure is how many times the drive capacity can be written per day
before the drive fails. For example, a 1 TB NAND drive with a 5 DWPD rating
isexpectedtohave5TBperdaywrittentoitforthewarrantyperiodwithout
failure.
Theselimitationshaveledtoseveralamelioratingalgorithms.Fortunately,
theyareusuallyimplementedintheNVMdevicecontrollerandarenotofcon-
cern to the operating system. The operating system simply reads and writes
logical blocks, and the device manages how that is done. (Logical blocks are
discussedinmoredetailinSection11.1.5.)However,NVMdeviceshaveperfor-
mancevariationsbasedontheiroperatingalgorithms,soabriefdiscussionof
whatthecontrollerdoesiswarranted.
11.1.2.2 NANDFlashControllerAlgorithms
Because NAND semiconductors cannot be overwrittenonce written, there are
usually pages containing invalid data. Consider a file-system block, written
once and then later written again. If no erase has occurred in the meantime,
thepagefirstwrittenhastheolddata,whicharenowinvalid,andthesecond
page has the current, good version of the block. A NAND block containing
validandinvalidpagesisshowninFigure11.4.Totrackwhichlogicalblocks
containvaliddata,thecontrollermaintainsaflas translationlayer(FTL).This
tablemapswhichphysicalpagescontaincurrentlyvalidlogicalblocks.Italso
Figure11.4 ANANDblockwithvalidandinvalidpages.454 Chapter11 Mass-StorageStructure
tracks physical block state—that is, which blocks contain only invalid pages
andthereforecanbeerased.
Now considera full SSD with a pendingwrite request.Becausethe SSD is
full, all pages have been written to, but there might be a block that contains
no valid data. In that case, the write could wait for the erase to occur, and
then the write could occur. But what if there are no free blocks? There still
couldbesomespaceavailableifindividualpagesareholdinginvaliddata.In
thatcase,garbagecollectioncouldoccur—gooddatacouldbecopiedtoother
locations, freeing up blocks that could be erased and could then receive the
writes.However,wherewouldthegarbagecollectionstorethegooddata?To
solvethisproblemandimprovewriteperformance,theNVMdeviceusesover-
provisioning.Thedevicesetsasideanumberofpages(frequently20percentof
thetotal)asanareaalwaysavailabletowriteto.Blocksthataretotallyinvalid
by garbage collection, or write operations invalidating older versions of the
data,areerasedandplacedintheover-provisioningspaceifthedeviceisfull
orreturnedtothefreepool.
The over-provisioning space can also help with wear leveling. If some
blocksareerasedrepeatedly,whileothersarenot,thefrequentlyerasedblocks
will wear out faster than the others, and the entire devicewill have a shorter
lifespan than it would if all the blocks wore out concurrently. The controller
tries to avoid that by using various algorithms to place data on less-erased
blocks so that subsequent erases will happen on those blocks rather than on
themoreerasedblocks,levelingthewearacrosstheentiredevice.
In terms of data protection, like HDDs, NVM devices provide error-
correcting codes,which are calculated and storedalong with the dataduring
writing and read with the data to detect errors and correct them if possible.
(Error-correcting codes are discussed in Section 11.5.1.) If a page frequently
has correctible errors, the page might be marked as bad and not used in
subsequent writes. Generally, a single NVM device, like an HDD, can have
a catastrophic failure in which it corrupts or fails to reply to read or write
requests.Toallowdatatoberecoverableinthoseinstances,RAIDprotectionis
used.
11.1.3 Volatile Memory
It might seem odd to discuss volatile memory in a chapter on mass-storage
structure,butitisjustifiablebecauseDRAMisfrequentlyusedasamass-storage
device.Specifically,RAMdrives(whichareknownbymanynames,including
RAM disks) act like secondary storage but are created by device drivers that
carve out a section of the system’s DRAM and present it to the rest of the
systemasitifwereastoragedevice.These“drives”canbeusedasrawblock
devices,butmorecommonly,filesystemsarecreatedonthemforstandardfile
operations.
Computersalreadyhavebufferingandcaching,sowhatisthepurposeof
yetanotheruseofDRAMfortemporarydatastorage?Afterall,DRAMisvolatile,
anddataonaRAMdrivedoesnotsurviveasystemcrash,shutdown,orpower
down. Cachesand buffersareallocatedby theprogrammeror operatingsys-
tem,whereasRAMdrivesallowtheuser(aswellastheprogrammer)toplace11.1 OverviewofMass-StorageStructure 455
MAGNETICTAPES
Magnetic tape was used as an early secondary-storage medium. Although
itisnonvolatileandcanholdlargequantitiesofdata,itsaccesstimeisslow
comparedwiththatofmainmemoryanddrives.Inaddition,randomaccess
to magnetic tape is about a thousand times slower than random access to
HDDs and about a hundred thousand times slower than random access to
SSDs so tapes are not very useful for secondary storage. Tapes are used
mainly for backup, for storage of infrequently used information, and as a
mediumfortransferringinformationfromonesystemtoanother.
A tape is kept in a spool and is wound or rewound past a read–write
head.Movingtothecorrectspotonatapecantakeminutes,butonceposi-
tioned, tape drives can read and write data at speeds comparableto HDDs.
Tapecapacitiesvarygreatly,dependingontheparticularkindoftapedrive,
withcurrentcapacitiesexceedingseveralterabytes.Sometapeshavebuilt-in
compressionthatcanmorethandoubletheeffectivestorage.Tapesandtheir
driversareusuallycategorizedbywidth,including4,8,and19millimeters
and1/4and1/2inch.Somearenamedaccordingtotechnology,suchasLTO-6
(Figure11.5)andSDLT.
Figure11.5 AnLTO-6Tapedrivewithtapecartridgeinserted.
datain memoryfor temporarysafekeepingusing standard file operations.In
fact,RAMdrivefunctionalityisusefulenoughthatsuchdrivesarefoundinall
majoroperatingsystems.OnLinuxthereis/dev/ram,onmacOSthediskutil
command creates them, Windows has them via third-party tools, and Solaris
andLinuxcreate/tmpatboottimeoftype“tmpfs”,whichisaRAMdrive.
RAM drives are useful as high-speed temporary storage space. Although
NVMdevicesarefast,DRAMismuchfaster,andI/OoperationstoRAMdrives
are the fastest way to create, read, write, and delete files and their contents.
Many programs use (or could benefit from using) RAM drives for storing
temporary files. For example, programs can share data easily by writing and
readingfilesfromaRAMdrive.Foranotherexample,Linuxatboottimecreates
a temporary root file system (initrd) that allows other parts of the system
to have access to a root file system and its contents before the parts of the
operatingsystemthatunderstandstoragedevicesareloaded.456 Chapter11 Mass-StorageStructure
11.1.4 Secondary Storage Connection Methods
Asecondarystoragedeviceisattachedtoacomputerbythesystembusoran
I/Obus.Severalkindsofbusesareavailable,includingadvancedtechnology
attachment (ATA), serial ATA (SATA), eSATA, serial attached SCSI (SAS), uni-
versalserialbus(USB),andfibr channel(FC).Themostcommonconnection
methodisSATA.BecauseNVMdevicesaremuchfasterthanHDDs,theindustry
created a special, fast interface for NVM devices called NVM express (NVMe).
NVMedirectlyconnectsthedevicetothesystemPCIbus,increasingthroughput
anddecreasinglatencycomparedwithotherconnectionmethods.
Thedatatransfersonabusarecarriedoutbyspecialelectronicprocessors
called controllers (or host-bus adapters (HBA)). The host controller is the
controller at the computer end of the bus. A device controller is built into
each storage device. To perform a mass storage I/O operation, the computer
places a command into the host controller, typically using memory-mapped
I/O ports, as described in Section 12.2.1. The host controller then sends the
command via messages to the device controller, and the controller operates
thedrivehardwaretocarryoutthecommand.Devicecontrollersusuallyhave
abuilt-incache.Datatransferatthedrivehappensbetweenthecacheandthe
storage media, and data transfer to the host, at fast electronic speeds, occurs
betweenthecachehostDRAMviaDMA.
11.1.5 Address Mapping
Storage devices are addressed as large one-dimensional arrays of logical
blocks, where the logical block is the smallest unit of transfer. Each logical
block mapstoaphysical sectoror semiconductorpage.Theone-dimensional
arrayoflogicalblocksismappedontothesectorsorpagesofthedevice.Sector
0couldbethefirstsectorofthefirsttrackontheoutermostcylinderonanHDD,
forexample.Themappingproceedsinorderthroughthattrack,thenthrough
therestofthetracksonthatcylinder,andthenthroughtherestofthecylinders,
from outermost to innermost. For NVM the mapping is from a tuple (finite
ordered list) of chip, block, and page to an array of logical blocks. A logical
blockaddress(LBA)iseasierforalgorithmstousethanasector,cylinder,head
tupleorchip,block,pagetuple.
ByusingthismappingonanHDD,wecan—atleastintheory—converta
logicalblocknumberintoanold-stylediskaddressthatconsistsofacylinder
number,atracknumberwithinthatcylinder,andasectornumberwithinthat
track. In practice, it is difficult to perform this translation, for three reasons.
First, most drives have some defective sectors, but the mapping hides this
by substituting spare sectors from elsewhere on the drive. The logical block
addressstayssequential,butthephysicalsectorlocationchanges.Second,the
numberofsectorspertrackisnotaconstantonsomedrives.Third,diskman-
ufacturers manage LBAto physical address mapping internally, so in current
drives there is little relationship between LBA and physical sectors. In spite
of these physical address vagaries, algorithms that deal with HDDs tend to
assumethatlogicaladdressesarerelativelyrelatedtophysicaladdresses.That
is,ascendinglogicaladdressestendtomeanascendingphysicaladdress.
Let’s look more closely at the second reason. On mediathat use constant
linearvelocity(CLV),thedensityofbitspertrackisuniform.Thefartheratrack
isfromthecenterofthedisk,thegreateritslength,sothemoresectorsitcan11.2 HDDScheduling 457
hold.Aswemovefromouterzonestoinnerzones,thenumberofsectorsper
track decreases. Tracks in the outermost zone typically hold 40 percent more
sectors than do tracks in the innermost zone. The drive increases its rotation
speedastheheadmovesfromtheoutertotheinnertrackstokeepthesamerate
ofdatamovingunderthehead.ThismethodisusedinCD-ROMandDVD-ROM
drives.Alternatively,thediskrotationspeedcanstayconstant;inthiscase,the
densityofbitsdecreasesfrominnertrackstooutertrackstokeepthedatarate
constant(andperformancerelativelythesamenomatterwheredataisonthe
drive). This method is used in hard disks and is known as constant angular
velocity(CAV).
The number of sectors per track has been increasing as disk technology
improves,andtheouterzoneofadiskusuallyhasseveralhundredsectorsper
track. Similarly, the number of cylinders per disk has been increasing; large
diskshavetensofthousandsofcylinders.
Note that there are more types of storage devices than are reasonable
to cover in an operating systems text. For example, there are “shingled
magnetic recording” hard drives with higher density but worse perfor-
mance than mainstream HDDs (see http://www.tomsitpro.com/articles/
shingled-magnetic-recoding-smr-101-basics,2-933.html). There are also
combination devices that include NVM and HDD technology, or volume
managers(seeSection11.5)that can knittogetherNVMand HDDdevicesinto
a storage unit faster than HDD but lower cost than NVM. These devices have
different characteristics from the more common devices, and might need
differentcachingandschedulingalgorithmstomaximizeperformance.
11.2 HDD Scheduling
One of the responsibilities of the operating system is to use the hardware
efficiently.ForHDDs,meetingthisresponsibilityentailsminimizingaccesstime
andmaximizingdatatransferbandwidth.
For HDDs and other mechanical storage devices that use platters, access
time has two major components, as mentioned in Section 11.1. The seek time
isthetimeforthedevicearmtomovetheheadstothecylindercontainingthe
desiredsector,andtherotationallatencyistheadditionaltimefortheplatterto
rotatethedesiredsectortothehead.Thedevicebandwidthisthetotalnumber
of bytes transferred, divided by the total time between the first request for
serviceandthecompletionofthelasttransfer.Wecanimproveboththeaccess
timeandthebandwidthbymanagingtheorderinwhichstorageI/Orequests
areserviced.
WheneveraprocessneedsI/Otoorfromthedrive,itissuesasystemcall
totheoperatingsystem.Therequestspecifiesseveralpiecesofinformation:
• Whetherthisoperationisinputoroutput
• Theopenfilehandleindicatingthefiletooperateon
• Whatthememoryaddressforthetransferis
• Theamountofdatatotransfer458 Chapter11 Mass-StorageStructure
Ifthedesireddriveandcontrollerareavailable,therequestcanbeserviced
immediately.Ifthedriveorcontrollerisbusy,anynewrequestsforservicewill
beplacedinthequeueofpendingrequestsforthatdrive.Foramultiprogram-
ming system with many processes, the device queue may often have several
pendingrequests.
The existence of a queue of requests to a device that can have its perfor-
mance optimized by avoiding head seeks allows device drivers a chance to
improveperformanceviaqueueordering.
Inthepast,HDDinterfacesrequiredthatthehostspecifywhichtrackand
whichheadtouse,andmucheffortwasspentondiskschedulingalgorithms.
Drivesnewerthantheturnofthecenturynotonlydonotexposethesecontrols
to the host, but also map LBAto physical addresses under drive control. The
current goals of disk scheduling include fairness, timeliness, and optimiza-
tions, such as bunching reads or writes that appear in sequence, as drives
perform best with sequential I/O. Therefore some scheduling effort is still
useful. Any one of several disk-scheduling algorithms can be used, and we
discuss them next. Note that absolute knowledge of head location and phys-
ical block/cylinder locations is generally not possible on modern drives. But
as a rough approximation, algorithms can assume that increasing LBAs mean
increasingphysicaladdresses,andLBAsclosetogetherequatetophysicalblock
proximity.
11.2.1 FCFS Scheduling
Thesimplestformofdiskschedulingis,ofcourse,thefirst-come,first-served
(FCFS) algorithm (or FIFO). This algorithm is intrinsically fair, but it generally
doesnotprovidethefastestservice.Consider,forexample,adiskqueuewith
requestsforI/Otoblocksoncylinders
98,183,37,122,14,124,65,67,
inthatorder.Ifthediskheadisinitiallyatcylinder53,itwillfirstmovefrom
53 to 98, then to 183, 37, 122, 14, 124, 65, and finally to 67, for a total head
movementof640cylinders.ThisscheduleisdiagrammedinFigure11.6.
Thewildswingfrom122to14andthenbackto124illustratestheproblem
with this schedule. If the requests for cylinders 37 and 14 could be serviced
together,beforeoraftertherequestsfor122and124,thetotalheadmovement
couldbedecreasedsubstantially,andperformancecouldbetherebyimproved.
11.2.2 SCAN Scheduling
In the SCAN algorithm, the disk arm starts at one end of the disk and moves
towardtheotherend,servicingrequestsasitreacheseachcylinder,untilitgets
totheotherendofthedisk.Attheotherend,thedirectionofheadmovement
is reversed, and servicing continues. The head continuously scans back and
forth across the disk. The SCAN algorithm is sometimes called the elevator
algorithm,since thediskarmbehavesjustlikeanelevatorinabuilding,first
servicing all the requests going up and then reversing to service requests the
otherway.
Let’sreturntoourexampletoillustrate.BeforeapplyingSCANtoschedule
therequestsoncylinders98,183,37,122,14,124,65,and67,weneedtoknow11.2 HDDScheduling 459
queue = 98, 183, 37, 122, 14, 124, 65, 67
head starts at 53
0 14 37 536567 98 122124 183199
Figure11.6 FCFSdiskscheduling.
the direction of head movement in addition to the head’s current position.
Assuming that the disk arm is moving toward 0 and that the initial head
position is again 53, the head will next service 37 and then 14. At cylinder 0,
thearmwillreverseandwillmovetowardtheotherendofthedisk,servicing
therequestsat65,67,98,122,124,and183(Figure11.7).Ifarequestarrivesin
the queue just in front of the head, it will be serviced almost immediately; a
requestarrivingjustbehindtheheadwillhavetowaituntilthearmmovesto
theendofthedisk,reversesdirection,andcomesback.
Assuming a uniform distribution of requests for cylinders, consider the
densityofrequestswhentheheadreachesoneendandreversesdirection.At
this point, relatively few requests are immediately in front of the head, since
these cylinders have recently been serviced. The heaviest density of requests
isattheotherendofthedisk.Theserequestshavealsowaitedthelongest,so
whynotgotherefirst?Thatistheideaofthenextalgorithm.
queue = 98, 183, 37, 122, 14, 124, 65, 67
head starts at 53
0 14 37 536567 98 122124 183199
Figure11.7 SCANdiskscheduling.460 Chapter11 Mass-StorageStructure
11.2.3 C-SCAN Scheduling
CircularSCAN(C-SCAN)schedulingisavariantofSCANdesignedtoprovide
amoreuniformwaittime.LikeSCAN,C-SCANmovestheheadfromoneendof
thedisktotheother,servicingrequestsalongtheway.Whentheheadreaches
the other end, however, it immediately returns to the beginning of the disk
withoutservicinganyrequestsonthereturntrip.
Let’sreturntoourexampletoillustrate.BeforeapplyingC-SCANtosched-
ule the requests on cylinders 98, 183, 37, 122, 14, 124, 65, and 67, we need to
know the direction of head movement in which the requests are scheduled.
Assumingthattherequestsarescheduledwhenthediskarmismovingfrom
0to199andthattheinitialheadpositionisagain53,therequestwillbeserved
asdepictedinFigure11.8.TheC-SCANschedulingalgorithmessentiallytreats
thecylindersasacircularlistthatwrapsaroundfromthefinalcylindertothe
firstone.
11.2.4 Selection of a Disk-Scheduling Algorithm
There are many disk-scheduling algorithms not included in this coverage,
because they are rarely used. But how do operating system designers decide
whichtoimplement,anddeployerschosethebesttouse?Foranyparticularlist
of requests, we can define an optimal order of retrieval, but the computation
needed to find an optimal schedule may not justify the savings over SCAN.
Withanyschedulingalgorithm,however,performancedependsheavilyonthe
number and types of requests. For instance, suppose that the queue usually
has just one outstanding request.Then, all scheduling algorithms behave the
same,becausetheyhaveonlyonechoiceofwheretomovethediskhead:they
allbehavelikeFCFSscheduling.
SCANandC-SCANperformbetterforsystemsthatplaceaheavyloadonthe
disk,becausetheyarelesslikelytocauseastarvationproblem.Therecanstill
bestarvationthough,whichdroveLinuxtocreatethedeadlinescheduler.This
schedulermaintainsseparatereadandwritequeues,andgivesreadspriority
becauseprocessesaremorelikelytoblockonreadthanwrite.Thequeuesare
queue = 98, 183, 37, 122, 14, 124, 65, 67
head starts at 53
0 14 37 536567 98 122124 183199
Figure11.8 C-SCANdiskscheduling.11.3 NVMScheduling 461
sortedinLBAorder,essentiallyimplementingC-SCAN.AllI/Orequestsaresent
in a batch in this LBA order. Deadline keeps four queues: two read and two
write,onesortedbyLBAandtheotherbyFCFS.Itchecksaftereachbatchtosee
iftherearerequestsintheFCFSqueuesolderthanaconfiguredage(bydefault,
500ms).Ifso,theLBAqueue(readorwrite)containingthatrequestisselected
forthenextbatchofI/O.
The deadlineI/Oscheduleris thedefaultinthe LinuxRedHat7distribu-
tion,butRHEL7alsoincludestwoothers.NOOPispreferredforCPU-boundsys-
temsusingfaststoragesuchasNVMdevices,andtheCompletelyFairQueue-
ingscheduler(CFQ)isthedefaultforSATAdrives.CFQmaintainsthreequeues
(withinsertionsorttokeepthemsortedinLBAorder):realtime,besteffort(the
default),andidle.Eachhasexclusivepriorityovertheothers,inthatorder,with
starvationpossible. It uses historical data, anticipating if a process will likely
issue more I/O requests soon. If it so determines, it idles waiting for the new
I/O,ignoringotherqueuedrequests.Thisistominimizeseektime,assuming
localityofreferenceofstorageI/Orequests,perprocess.Detailsofthesesched-
ulers can be found in https://access.redhat.com/site/documentation/en-US
/Red Hat Enterprise Linux/7/html/Performance Tuning Guide/index.html.
11.3 NVM Scheduling
The disk-scheduling algorithms just discussed apply to mechanical platter-
based storage like HDDs. They focus primarily on minimizing the amount of
disk head movement. NVM devices do not contain moving disk heads and
commonly use a simple FCFS policy. For example, the Linux NOOP scheduler
uses an FCFS policy but modifies it to merge adjacent requests. The observed
behavior of NVM devices indicates that the time required to service reads is
uniformbutthat,becauseofthepropertiesofflashmemory,writeservicetime
is not uniform. Some SSD schedulers have exploitedthis property and merge
onlyadjacentwriterequests,servicingallreadrequestsinFCFSorder.
Aswehaveseen,I/Ocanoccursequentiallyorrandomly.Sequentialaccess
is optimal for mechanical devices like HDD and tape because the data to be
read or written is near the read/write head. Random-access I/O, which is
measuredininput/outputoperationspersecond(IOPS),causesHDDdiskhead
movement.Naturally,randomaccessI/OismuchfasteronNVM.AnHDDcan
produce hundreds of IOPS, while an SSD can produce hundreds of thousands
ofIOPS.
NVMdevicesoffermuchlessofanadvantageforrawsequentialthrough-
put, where HDD head seeks are minimized and reading and writing of data
to the media are emphasized. In those cases, for reads, performance for the
two types of devices can range from equivalent to an order of magnitude
advantageforNVMdevices.WritingtoNVMisslowerthanreading,decreasing
the advantage. Furthermore, while write performance for HDDs is consistent
throughout the life of the device, write performance for NVM devices varies
dependingonhowfullthedeviceis(recalltheneedforgarbagecollectionand
over-provisioning) and how “worn” it is. An NVM device near its end of life
duetomany erasecycles generallyhas much worse performance than anew
device.462 Chapter11 Mass-StorageStructure
One way to improve the lifespan and performance of NVM devices over
timeistohavethefilesysteminformthedevicewhenfilesaredeleted,sothat
the device can erase the blocks those files were stored on. This approach is
discussedfurtherinSection14.5.6.
Let’slookmorecloselyattheimpactofgarbagecollectiononperformance.
ConsideranNVMdeviceunderrandomreadand writeload.Assumethatall
blockshavebeenwrittento,butthereisfreespaceavailable.Garbagecollection
must occur to reclaim space taken by invalid data. That means that a write
might cause a read of one or more pages, a write of the good data in those
pagestooverprovisioningspace,aneraseoftheall-invalid-datablock,andthe
placement of that block into overprovisioning space. In summary, one write
request eventually causes a page write (the data), one or more page reads
(by garbage collection), and one or more page writes (of good data from the
garbage-collected blocks). The creation of I/O requests not by applications
but by the NVM device doing garbage collection and space management is
called write amplificatio and can greatly impact the write performance of
the device.In the worst case, several extra I/Os are triggered with each write
request.
11.4 Error Detection and Correction
Error detection and correction are fundamental to many areas of computing,
including memory, networking, and storage. Error detection determines if a
problem has occurred — for example a bit in DRAM spontaneously changed
froma0toa1,thecontentsofanetworkpacketchangedduringtransmission,
orablockofdatachangedbetweenwhenitwaswrittenandwhenitwasread.
By detecting the issue, the system can halt an operation before the error is
propagated,report the error to the user or administrator, or warn of a device
thatmightbestartingtofailorhasalreadyfailed.
Memorysystemshavelongdetectedcertainerrorsbyusingparitybits.In
this scenario, each byte in a memory system has a parity bit associated with
it that records whether the number of bits in the byte set to 1 is even (parity
= 0) or odd (parity = 1). If one of the bits in the byte is damaged (either a 1
becomesa0,ora0becomesa1),theparityofthebytechangesandthusdoes
not match the stored parity. Similarly, if the stored parity bit is damaged, it
doesnotmatchthecomputedparity.Thus,allsingle-biterrorsaredetectedby
the memory system. Adouble-bit-error might go undetected, however. Note
that parity is easily calculated by performing an XOR (for “eXclusive OR”) of
thebits.Alsonotethatforeverybyteofmemory,wenowneedanextrabitof
memorytostoretheparity.
Parity is one form of checksums, which use modular arithmetic to
compute, store, and compare values on fixed-length words. Another
error-detection method, common in networking, is a cyclic redundancy
check (CRCs), which uses a hash function to detect multiple-bit errors (see
http://www.mathpages.com/home/kmath458/kmath458.htm).
An error-correction code (ECC) not only detects the problem, but also
corrects it. The correction is done by using algorithms and extra amounts of
storage.Thecodesvarybasedonhowmuchextrastoragetheyneedandhow
manyerrorstheycancorrect.Forexample,disksdrivesuseper-sectorECCand11.5 StorageDeviceManagement 463
flash drives per-page ECC. When the controller writes a sector/page of data
duringnormalI/O,theECCiswrittenwithavaluecalculatedfromallthebytes
inthedatabeingwritten.Whenthesector/pageisread,theECCisrecalculated
andcomparedwiththestoredvalue.Ifthestoredandcalculatednumbersare
different, this mismatch indicates that the data have become corrupted and
thatthestoragemediamaybebad(Section11.5.3).TheECCiserrorcorrecting
because it contains enough information, if only a few bits of data have been
corrupted, to enable the controller to identify which bits have changed and
calculatewhattheircorrectvaluesshouldbe.Itthenreportsarecoverablesoft
error.Iftoomany changesoccur, andtheECC cannot correcttheerror,anon-
correctable hard error is signaled. The controller automatically does the ECC
processingwheneverasectororpageisreadorwritten.
Errordetectionandcorrectionarefrequentlydifferentiatorsbetweencon-
sumer products and enterprise products. ECC is used in some systems for
DRAMerrorcorrectionanddatapathprotection,forexample.
11.5 Storage Device Management
Theoperatingsystemisresponsibleforseveralotheraspectsofstoragedevice
management,too.Here,wediscussdriveinitialization,booting fromadrive,
andbad-blockrecovery.
11.5.1 Drive Formatting, Partitions, and Volumes
Anewstoragedeviceisablankslate:itisjustaplatterofamagneticrecording
materialorasetofuninitializedsemiconductorstoragecells.Beforeastorage
device can store data, it must be divided into sectors that the controller can
readandwrite.NVMpagesmustbeinitializedandtheFTLcreated.Thisprocess
is called low-level formatting, or physical formatting. Low-level formatting
fillsthedevicewithaspecialdatastructureforeachstoragelocation.Thedata
structureforasectororpagetypicallyconsistsofaheader,adataarea,anda
trailer.Theheaderandtrailercontaininformationusedbythecontroller,such
asasector/pagenumberandanerrordetectionorcorrectioncode.
Most drives are low-level-formatted at the factory as a part of the manu-
facturingprocess.Thisformattingenablesthemanufacturertotestthedevice
andtoinitializethemappingfromlogicalblocknumberstodefect-freesectors
orpagesonthemedia.Itisusuallypossibletochooseamongafewsectorsizes,
such as 512 bytes and 4KB.Formatting adisk with alargersector size means
that fewer sectors can fit on each track, but it also means that fewer headers
andtrailersarewrittenoneachtrackandmorespaceisavailableforuserdata.
Someoperatingsystemscanhandleonlyonespecificsectorsize.
Before it can use a drive to hold files, the operating system still needs to
recorditsowndatastructuresonthedevice.Itdoessointhreesteps.
The first step is to partition the device into one or more groupsof blocks
or pages. The operating system can treat each partition as though it were a
separatedevice.Forinstance,onepartitioncanholdafilesystemcontaininga
copy of the operating system’s executable code, another the swap space, and
another a file system containing the user files. Some operating systems and
filesystemsperformthepartitioningautomaticallywhenanentiredeviceisto464 Chapter11 Mass-StorageStructure
bemanagedbythefilesystem.Thepartitioninformationiswritteninafixed
formatatafixedlocationonthestoragedevice.InLinux,thefdiskcommand
isusedtomanagepartitionsonstoragedevices.Thedevice,whenrecognized
bytheoperatingsystem,hasitspartitioninformationread,andtheoperating
system then creates device entries for the partitions (in /dev in Linux). From
there, a configuration file, such as /etc/fstab, tells the operating system to
mounteachpartitioncontainingafilesystemataspecifiedlocationandtouse
mount options such as read-only. Mounting a file system is making the file
systemavailableforusebythesystemanditsusers.
The second step is volume creation and management. Sometimes, this
step is implicit, as when a file system is placed directly within a partition.
That volume is then ready to be mounted and used. At other times, volume
creationandmanagementisexplicit—forexamplewhenmultiplepartitionsor
deviceswillbeusedtogetherasaRAIDset(seeSection11.8)withoneormore
file systems spread across the devices. The Linux volume manager lvm2 can
providethesefeatures,ascancommercialthird-partytoolsforLinuxandother
operating systems. ZFS provides both volume management and a file system
integratedintoonesetofcommandsandfeatures.(Notethat“volume”canalso
meananymountablefilesystem,evenafilecontainingafilesystemsuchasa
CDimage.)
The third step is logical formatting, or creation of a file system. In this
step,theoperatingsystemstorestheinitialfile-systemdatastructuresontothe
device.Thesedatastructuresmayincludemapsoffreeandallocatedspaceand
aninitialemptydirectory.
The partition information also indicates if a partition contains a bootable
file system (containing the operating system). The partition labeled for boot
is used to establish the root of the file system. Once it is mounted, device
links for all other devices and their partitions can be created. Generally, a
computer’s“filesystem”consistsofallmountedvolumes.OnWindows,these
areseparatelynamedviaaletter(C:,D:,E:).Onothersystems,suchasLinux,
at boot time the boot file system is mounted, and other file systems can be
mountedwithinthattreestructure(asdiscussedinSection13.3).OnWindows,
thefilesysteminterfacemakesitclearwhenagivendeviceisbeingused,while
inLinuxasinglefileaccessmighttraversemanydevicesbeforetherequested
file in the requested file system (within a volume) is accessed. Figure 11.9
shows the Windows 7 Disk Management tool displaying three volumes (C:,
E:, and F:). Note that E: and F: are each in a partition of the “Disk 1” device
andthatthereisunallocatedspaceonthatdeviceformorepartitions(possibly
containingfilesystems).
To increase efficiency, most file systems group blocks together into larger
chunks,frequentlycalledclusters.DeviceI/Oisdoneviablocks,butfilesystem
I/Oisdoneviaclusters,effectivelyassuringthatI/Ohasmoresequential-access
andfewerrandom-accesscharacteristics.Filesystemstrytogroupfilecontents
nearitsmetadataaswell,reducingHDDheadseekswhenoperatingonafile,
forexample.
Someoperatingsystemsgivespecialprogramstheabilitytouseapartition
as a large sequential array of logical blocks, without any file-system data
structures.Thisarrayissometimescalledtherawdisk,andI/Otothisarrayis
termedrawI/O.Itcanbeusedforswapspace(seeSection11.6.2),forexample,
andsomedatabasesystemspreferrawI/Obecauseitenablesthemtocontrol11.5 StorageDeviceManagement 465
Figure11.9 Windows7Disk Managementtoolshowingdevices,partitions,volumes,
andfilesystems.
theexactlocationwhereeachdatabaserecordisstored.RawI/Obypassesall
thefile-systemservices,suchasthebuffercache,filelocking,prefetching,space
allocation,filenames,anddirectories.Wecanmakecertainapplicationsmore
efficient by allowing them to implement their own special-purpose storage
services on a raw partition, but most applications use a provided file system
rather than managing data themselves. Note that Linux generally does not
support raw I/O but can achieve similar access by using the DIRECT flag to
theopen()systemcall.
11.5.2 Boot Block
For a computer to start running—for instance, when it is powered up or
rebooted—itmusthaveaninitialprogramtorun.Thisinitialbootstraploader
tends to be simple. For most computers, the bootstrap is stored in NVM flash
memoryfirmwareonthesystemmotherboardandmappedtoaknownmem-
orylocation.Itcanbeupdatedbyproductmanufacturersasneeded,butalso
can be written to by viruses, infecting the system. It initializes all aspects of
the system, from CPU registersto devicecontrollers and the contents of main
memory.
This tiny bootstrap loader program is also smart enough to bring in a
full bootstrap program from secondary storage. The full bootstrap program
is stored in the “boot blocks” at a fixed location on the device. The default
Linuxbootstraploaderisgrub2(https://www.gnu.org/software/grub/manual/
grub.html/).Adevicethathasabootpartitioniscalledabootdiskorsystem
disk.
ThecodeinthebootstrapNVMinstructsthestoragecontrollertoreadthe
bootblocksintomemory(nodevicedriversareloadedatthispoint)andthen
starts executing that code. The full bootstrap program is more sophisticated
thanthebootstraploader:itisabletoloadtheentireoperatingsystemfroma
non-fixedlocationonthedeviceandtostarttheoperatingsystemrunning.
Let’sconsiderasanexamplethebootprocessinWindows.First,notethat
Windows allows a drive to be divided into partitions, and one partition—
identified as the boot partition—contains the operating system and device
drivers.TheWindows systemplacesitsbootcodeinthefirstlogicalblockon
theharddiskor firstpageofthe NVMdevice,which ittermsthe master boot466 Chapter11 Mass-StorageStructure
boot
MBR code
partition 1 partition
table
partition 2
boot partition
partition 3
partition 4
Figure11.10 BootingfromastoragedeviceinWindows.
record,orMBR.Bootingbeginsbyrunningcodethatisresidentinthesystem’s
firmware. This code directs the system to read the boot code from the MBR,
understandingjustenoughaboutthestoragecontrollerandstoragedeviceto
load a sector from it. In addition to containing boot code, the MBR contains a
table listing the partitions for the drive and a flag indicating which partition
thesystemistobebootedfrom,asillustratedinFigure11.10.Oncethesystem
identifies the boot partition, it reads the first sector/page from that partition
(calledthebootsector),whichdirectsittothekernel.Itthencontinueswiththe
remainderofthebootprocess,whichincludesloadingthevarioussubsystems
andsystemservices.
11.5.3 Bad Blocks
Because disks have moving parts and small tolerances (recall that the disk
headfliesjustabovethedisksurface),theyarepronetofailure.Sometimesthe
failureiscomplete;inthiscase,thediskneedstobereplacedanditscontents
restored from backup media to the new disk. More frequently, one or more
sectors become defective. Most disks even come from the factory with bad
blocks.Dependingonthediskandcontrollerinuse,theseblocksarehandled
inavarietyofways.
On older disks, such as some disks with IDE controllers, bad blocks are
handled manually. One strategy is to scan the disk to find bad blocks while
thediskisbeingformatted.Anybadblocksthatarediscoveredareflaggedas
unusablesothatthefilesystemdoesnotallocatethem.Ifblocksgobadduring
normaloperation,aspecialprogram(suchastheLinuxbadblockscommand)
mustberunmanuallytosearchforthebadblocksandtolockthemaway.Data
thatresidedonthebadblocksusuallyarelost.
More sophisticated disks are smarter about bad-block recovery. The con-
troller maintains a list of bad blocks on the disk. The list is initialized during
thelow-levelformattingatthefactoryandisupdatedoverthelifeofthedisk.
Low-levelformattingalsosetsasidesparesectorsnotvisibletotheoperating
system.Thecontrollercanbetoldtoreplaceeachbadsectorlogicallywithone
ofthesparesectors.Thisschemeisknownassectorsparingorforwarding.
Atypicalbad-sectortransactionmightbeasfollows:
• Theoperatingsystemtriestoreadlogicalblock87.11.6 Swap-SpaceManagement 467
• ThecontrollercalculatestheECCandfindsthatthesectorisbad.Itreports
thisfindingtotheoperatingsystemasanI/Oerror.
• Thedevicecontrollerreplacesthebadsectorwithaspare.
• After that, whenever the system requests logical block 87, the request is
translatedintothereplacementsector’saddressbythecontroller.
Note that such a redirection by the controller could invalidate any opti-
mizationbytheoperatingsystem’sdisk-schedulingalgorithm!Forthisreason,
most disks are formatted to provide a few spare sectors in each cylinder and
asparecylinderaswell.Whenabadblockisremapped,thecontrollerusesa
sparesectorfromthesamecylinder,ifpossible.
As an alternative to sector sparing, some controllers can be instructed to
replaceabadblockbysectorslipping.Hereisanexample:Supposethatlogical
block 17 becomes defective and the first available spare follows sector 202.
Sector slipping then remaps all the sectors from 17 to 202, moving them all
downonespot.Thatis,sector202iscopiedintothespare,thensector201into
202,then200into201,andsoon,untilsector18iscopiedintosector19.Slipping
the sectors in this way frees up the space of sector 18 so that sector 17 can be
mappedtoit.
Recoverablesofterrorsmaytriggeradeviceactivityinwhichacopyofthe
blockdataismadeandtheblockissparedorslipped.Anunrecoverablehard
error, however, results in lost data. Whatever file was using that block must
berepaired(forinstance,byrestorationfromabackuptape),andthatrequires
manualintervention.
NVMdevicesalsohavebits,bytes,andevenpagesthateitherarenonfunc-
tionalatmanufacturingtimeorgobadovertime.Managementofthosefaulty
areasissimplerthanforHDDsbecausethereisnoseektimeperformanceloss
tobeavoided.Eithermultiplepagescanbesetasideandusedasreplacement
locations, or space from the over-provisioning area can be used (decreasing
the usable capacity of the over-provisioning area). Either way, the controller
maintainsatableofbadpagesandneversetsthosepagesasavailabletowrite
to,sotheyareneveraccessed.
11.6 Swap-Space Management
SwappingwasfirstpresentedinSection9.5,wherewediscussedmovingentire
processesbetweensecondarystorageandmainmemory.Swappinginthatset-
tingoccurswhentheamountofphysicalmemoryreachesacriticallylowpoint
andprocessesaremovedfrommemorytoswapspacetofreeavailablememory.
In practice, very few modern operating systems implement swapping in this
fashion. Rather, systems now combine swapping with virtual memory tech-
niques(Chapter10) and swap pages,not necessarilyentireprocesses.Infact,
some systems now use the terms “swapping” and “paging” interchangeably,
reflectingthemergingofthesetwoconcepts.
Swap-space management is another low-level task of the operating sys-
tem. Virtual memory uses secondary storage space as an extension of main
memory. Since drive access is much slower than memory access, using swap468 Chapter11 Mass-StorageStructure
spacesignificantlydecreasessystemperformance.Themaingoalforthedesign
andimplementationofswapspaceistoprovidethebestthroughputforthevir-
tualmemorysystem.Inthissection,wediscusshowswapspaceisused,where
swapspaceislocatedonstoragedevices,andhowswapspaceismanaged.
11.6.1 Swap-Space Use
Swapspaceisusedinvariouswaysbydifferentoperatingsystems,depending
on the memory-management algorithms in use. For instance, systems that
implement swapping may use swap space to hold an entire process image,
includingthecodeanddatasegments.Pagingsystemsmaysimplystorepages
thathavebeenpushedoutofmainmemory.Theamountofswapspaceneeded
onasystemcanthereforevaryfromafewmegabytesofdiskspacetogigabytes,
dependingontheamountofphysicalmemory,theamountofvirtualmemory
itisbacking,andthewayinwhichthevirtualmemoryisused.
Notethatitmaybesafertooverestimatethantounderestimatetheamount
of swap space required, because if a system runs out of swap space it may
be forced to abort processes or may crash entirely. Overestimation wastes
secondary storage spacethat could otherwisebe usedfor files,but it doesno
other harm. Some systems recommend the amount to be set aside for swap
space. Solaris, for example, suggests setting swap space equal to the amount
by which virtual memory exceeds pageable physical memory. In the past,
Linux has suggested setting swap space to double the amount of physical
memory.Today,thepagingalgorithmshavechanged,andmostLinuxsystems
useconsiderablylessswapspace.
Some operating systems—including Linux—allow the use of multiple
swap spaces, including both files and dedicatedswap partitions.Theseswap
spaces are usually placed on separate storage devicesso that the load placed
on the I/O system by paging and swapping can be spread over the system’s
I/Obandwidth.
11.6.2 Swap-Space Location
Aswapspacecanresideinoneoftwoplaces:itcanbecarvedoutofthenormal
filesystem,oritcanbeinaseparatepartition.Iftheswapspaceissimplyalarge
filewithinthefilesystem,normalfile-systemroutinescanbeusedtocreateit,
nameit,andallocateitsspace.
Alternatively, swap space can be created in a separate raw partition. No
file system or directory structure is placed in this space. Rather, a separate
swap-space storage manager is used to allocate and deallocate the blocks
from the raw partition. This manager uses algorithms optimized for speed
rather than for storage efficiency, because swap space is accessed much more
frequentlythanfilesystems,whenitisused(recallthatswapspaceisusedfor
swapping and paging). Internal fragmentation may increase, but this trade-
off is acceptable because the life of data in the swap space generally is much
shorter than that of files in the file system. Since swap space is reinitialized
at boot time, any fragmentation is short-lived. The raw-partition approach
creates a fixed amount of swap space during disk partitioning. Adding more
swap space requires either repartitioning the device (which involves moving11.7 StorageAttachment 469
the other file-system partitions or destroying them and restoring them from
backup)oraddinganotherswapspaceelsewhere.
Some operating systems are flexible and can swap both in raw partitions
and in file-system space. Linux is an example: the policy and implementa-
tion are separate,allowing the machine’s administrator to decidewhich type
of swapping to use. The trade-off is between the convenience of allocation
and management in the file systemand the performance of swapping in raw
partitions.
11.6.3 Swap-Space Management: An Example
Wecanillustratehowswapspaceisusedbyfollowingtheevolutionofswap-
pingandpaginginvariousUNIXsystems.ThetraditionalUNIXkernelstarted
with an implementation of swapping that copied entire processes between
contiguous diskregionsandmemory.UNIXlaterevolvedtoacombination of
swappingandpagingaspaginghardwarebecameavailable.
In Solaris 1 (SunOS), the designers changed standard UNIX methods to
improve efficiency and reflect technological developments. When a process
executes, text-segment pages containing code are brought in from the file
system, accessed in main memory, and thrown away if selected for pageout.
It is more efficient to reread a page from the file system than to write it to
swapspaceandthenrereaditfromthere.Swapspaceisonlyusedasabacking
storeforpagesofanonymousmemory(memorynotbackedbyanyfile),which
includes memory allocated for the stack, heap, and uninitialized data of a
process.
More changes were made in later versions of Solaris. The biggest change
is that Solaris now allocates swap space only when a page is forced out of
physical memory, rather than when the virtual memory page is first created.
Thisschemegivesbetterperformanceonmoderncomputers,whichhavemore
physicalmemorythanoldersystemsandtendtopageless.
LinuxissimilartoSolarisinthatswapspaceisnowusedonlyforanony-
mousmemory.Linuxallowsoneormoreswapareastobeestablished.Aswap
areamaybeineitheraswapfileonaregularfilesystemoradedicatedswap
partition.Eachswapareaconsistsofaseriesof4-KBpageslots,whichareused
to hold swapped pages. Associated with each swap area is a swap map—an
arrayof integercounters,eachcorrespondingtoapageslotintheswaparea.
If the value of a counter is 0, the corresponding page slot is available. Values
greaterthan0indicatethatthepageslotisoccupiedbyaswappedpage.The
valueofthecounter indicatesthenumberofmappingstotheswappedpage.
Forexample,avalueof3indicatesthattheswappedpageismappedtothree
differentprocesses(whichcanoccuriftheswappedpageisstoringaregionof
memorysharedbythreeprocesses).ThedatastructuresforswappingonLinux
systemsareshowninFigure11.11.
11.7 Storage Attachment
Computersaccesssecondarystorageinthreeways:viahost-attachedstorage,
network-attachedstorage,andcloudstorage.470 Chapter11 Mass-StorageStructure
swap area
page
slot
swap partition
or swap file
swap map 1 0 3 0 1
Figure11.11 ThedatastructuresforswappingonLinuxsystems.
11.7.1 Host-Attached Storage
Host-attachedstorageisstorageaccessedthroughlocalI/Oports.Theseports
useseveraltechnologies,the mostcommon being SATA,as mentionedearlier.
AtypicalsystemhasoneorafewSATAports.
To allow a system to gain access to more storage, either an individual
storage device, a device in a chassis, or multiple drives in a chassis can be
connectedviaUSB FireWireorThunderboltportsandcables.
High-end workstations and servers generally need more storage or need
to share storage, so use more sophisticated I/O architectures, such as fibr
channel(FC),ahigh-speedserialarchitecturethatcanoperateoveropticalfiber
oroverafour-conductorcoppercable.Becauseofthelargeaddressspaceand
theswitchednatureofthecommunication,multiplehostsandstoragedevices
canattachtothefabric,allowinggreatflexibilityinI/Ocommunication.
A wide variety of storage devices are suitable for use as host-attached
storage. Among these are HDDs; NVM devices; CD, DVD, Blu-ray, and tape
drives; and storage-area networks (SANs) (discussed in Section 11.7.4). The
I/Ocommandsthatinitiatedatatransferstoahost-attachedstoragedeviceare
readsandwritesoflogicaldatablocksdirectedtospecificallyidentifiedstorage
units(suchasbusIDortargetlogicalunit).
11.7.2 Network-Attached Storage
Network-attached storage (NAS) (Figure 11.12) provides access to storage
acrossanetwork.AnNASdevicecanbeeitheraspecial-purposestoragesystem
or a general computer system that provides its storage to other hosts across
thenetwork.Clientsaccessnetwork-attachedstorageviaaremote-procedure-
call interface such as NFS for UNIX and Linux systems or CIFS for Windows
machines. The remote procedure calls (RPCs) are carried via TCPor UDPover
anIPnetwork—usuallythesamelocal-areanetwork(LAN)thatcarriesalldata
traffictotheclients.Thenetwork-attachedstorageunitisusuallyimplemented
asastoragearraywithsoftwarethatimplementstheRPCinterface.
CIFSandNFSprovidevariouslockingfeatures,allowingthesharingoffiles
betweenhostsaccessingaNASwiththoseprotocols.Forexample,auserlogged
intomultipleNASclientscanaccessherhomedirectoryfromallofthoseclients,
simultaneously.11.7 StorageAttachment 471
client
NAS
LAN/WAN client
NAS
client
Figure11.12 Network-attachedstorage.
Network-attachedstorageprovidesaconvenientwayforallthecomputers
on a LAN toshare a pool of storage with the same ease of naming and access
enjoyedwithlocalhost-attachedstorage.However,ittendstobelessefficient
andhavelowerperformancethansomedirect-attachedstorageoptions.
iSCSIisthelatestnetwork-attachedstorageprotocol.Inessence,itusesthe
IP network protocol to carry the SCSI protocol. Thus, networks—rather than
SCSIcables—canbeusedastheinterconnectsbetweenhostsandtheirstorage.
Asaresult,hostscan treattheirstorageasifitweredirectlyattached,evenif
thestorageisdistantfromthehost.WhereasNFSandCIFSpresentafilesystem
andsendpartsoffilesacrossthenetwork,iSCSIsendslogicalblocksacrossthe
network and leaves it to the client to use the blocks directly or create a file
systemwiththem.
11.7.3 Cloud Storage
Section1.10.5discussedcloudcomputing.Oneofferingfromcloudproviders
iscloudstorage.Similartonetwork-attachedstorage,cloudstorageprovides
accesstostorageacrossanetwork.UnlikeNAS,thestorageisaccessedoverthe
InternetoranotherWANtoaremotedatacenterthatprovidesstorageforafee
(orevenforfree).
Another difference between NAS and cloud storage is how the storage is
accessedandpresentedtousers.NASisaccessedasjustanotherfilesystemif
theCIFSorNFSprotocolsareused,orasarawblockdeviceiftheiSCSIprotocolis
used.MostoperatingsystemshavetheseprotocolsintegratedandpresentNAS
storageinthesamewayasotherstorage.Incontrast,cloudstorageisAPIbased,
andprogramsusetheAPIstoaccessthestorage.AmazonS3isaleadingcloud
storage offering. Dropbox is an example of a company that provides apps to
connecttothecloudstoragethatitprovides.OtherexamplesincludeMicrosoft
OneDriveandAppleiCloud.
One reason that APIs are used instead of existing protocols is the latency
andfailurescenariosofaWAN.NASprotocolsweredesignedforuseinLANs,
whichhavelowerlatencythanWANsandaremuchlesslikelytoloseconnectiv-
itybetweenthestorageuserandthestoragedevice.IfaLANconnectionfails,
a system using NFS or CIFS might hang until it recovers. With cloud storage,
failureslike that are more likely,so an application simplypauses access until
connectivityisrestored.472 Chapter11 Mass-StorageStructure
client
server
client
storage LAN/WAN
array server
client
storage SAN
array data-processing
center
tape web content
library provider
Figure11.13 Storage-areanetwork.
11.7.4 Storage-Area Networks and Storage Arrays
One drawback of network-attached storage systems is that the storage I/O
operations consume bandwidth on the data network, thereby increasing the
latency of network communication. This problem can be particularly acute
inlargeclient–serverinstallations—thecommunicationbetweenserversand
clients competes for bandwidth with the communication among servers and
storagedevices.
Astorage-areanetwork(SAN)isaprivatenetwork(usingstorageprotocols
rather than networking protocols) connecting servers and storage units, as
showninFigure11.13.ThepowerofaSANliesinitsflexibility.Multiplehosts
and multiple storage arrays can attach to the same SAN, and storage can be
dynamically allocated to hosts. The storage arrays can be RAID protected or
unprotected drives (Just a Bunch of Disks (JBOD)). A SAN switch allows or
prohibitsaccessbetweenthehostsandthestorage.Asoneexample,ifahostis
runninglowondiskspace,theSANcanbeconfiguredtoallocatemorestorage
to that host. SANs make it possible for clusters of servers to share the same
storage and for storage arrays to include multiple direct host connections.
SANs typically have more ports—and cost more—than storage arrays. SAN
connectivityisovershortdistancesandtypicallyhasnorouting,soaNAScan
havemanymoreconnectedhoststhanaSAN.
Astorage array is a purpose-built device (see Figure 11.14) that includes
SANports,networkports,orboth.Italsocontainsdrivestostoredataandacon-
troller(orredundantsetofcontrollers)tomanagethestorageandallowaccess
to the storage across the networks. The controllers are composed of CPUs,
memory, and software that implement the features of the array, which can
include network protocols, user interfaces, RAID protection, snapshots, repli-
cation, compression, deduplication, and encryption. Some of those functions
arediscussedinChapter14.
SomestoragearraysincludeSSDs.AnarraymaycontainonlySSDs,result-
ing in maximum performance but smaller capacity, or may include a mix of
SSDs and HDDs, with the array software (or the administrator) selecting the
best medium for a given use or using the SSDs as a cache and HDDs as bulk
storage.11.8 RAIDStructure 473
Figure11.14 Astoragearray.
FCisthemostcommonSANinterconnect,althoughthesimplicityofiSCSI
is increasing its use. Another SAN interconnect is InfiniBan (IB)—a special-
purpose bus architecture that provides hardware and software support for
high-speedinterconnectionnetworksforserversandstorageunits.
11.8 RAID Structure
Storage devices have continued to get smaller and cheaper, so it is now eco-
nomically feasible to attach many drives to a computer system. Having a
large number of drives in a system presents opportunities for improving the
rate at which data can be read or written, if the drives are operated in paral-
lel. Furthermore, this setup offers the potential for improving the reliability
of data storage, because redundant information can be stored on multiple
drives. Thus, failure of one drive does not lead to loss of data. A variety of
disk-organization techniques, collectively called redundant arrays of inde-
pendent disks (RAIDs), are commonly used to address the performance and
reliabilityissues.
Inthepast,RAIDscomposedofsmall,cheap diskswereviewedas acost-
effectivealternativeto large, expensivedisks. Today,RAIDs are used for their
higher reliability and higher data-transfer rate rather than for economic rea-
sons.Hence,theIinRAID,whichoncestoodfor“inexpensive,”nowstandsfor
“independent.”
11.8.1 Improvement of Reliability via Redundancy
Let’sfirstconsiderthereliabilityofaRAIDofHDDs.Thechancethatsomedisk
outofasetof N diskswillfailismuch greaterthanthe chance thataspecific
single disk will fail. Suppose that the mean time between failures (MTBF) of
a single disk is 100,000 hours. Then the MTBF of some disk in an array of 100474 Chapter11 Mass-StorageStructure
STRUCTURINGRAID
RAID storage can bestructuredin a varietyofways. For example,a system
can have drives directly attached to its buses. In this case, the operating
systemorsystemsoftwarecanimplementRAIDfunctionality.Alternatively,
an intelligent host controller can control multiple attached devices and can
implement RAID on those devices in hardware. Finally, a storage array can
beused.Astoragearray,asjustdiscussed,isastandaloneunitwithitsown
controller,cache,anddrives.Itisattachedtothehostviaoneormorestandard
controllers(forexample,FC).Thiscommonsetupallowsanoperatingsystem
orsoftwarewithoutRAIDfunctionalitytohaveRAID-protectedstorage.
diskswillbe100,000/100=1,000hours,or41.66days,whichisnotlongatall!
Ifwestoreonlyonecopyofthedata,theneachdiskfailurewillresultinlossof
asignificantamountofdata—andsuchahighrateofdatalossisunacceptable.
The solution to the problem of reliability is to introduce redundancy; we
storeextrainformationthatisnotnormallyneededbutcanbeusedintheevent
ofdiskfailuretorebuildthelostinformation.Thus,evenifadiskfails,dataare
not lost. RAID can be applied to NVM devices as well, although NVM devices
havenomovingpartsandthereforearelesslikelytofailthanHDDs.
Thesimplest(butmostexpensive)approachtointroducingredundancyis
toduplicateeverydrive.Thistechniqueiscalledmirroring.Withmirroring,a
logical disk consists of two physical drives,and everywrite is carried out on
bothdrives.Theresultiscalledamirroredvolume.Ifoneofthedrivesinthe
volumefails,thedatacanbe readfromthe other.Datawillbe lostonly ifthe
seconddrivefailsbeforethefirstfaileddriveisreplaced.
The MTBF of a mirrored volume—where failure is the loss of data—
depends on two factors. One is the MTBF of the individual drives.The other
isthemeantimetorepair,whichisthetimeittakes(onaverage)toreplacea
failed driveand to restorethe dataon it. Suppose that the failuresof the two
drivesareindependent;thatis,thefailureofoneisnotconnectedtothefailure
oftheother.Then,iftheMTBFofasingledriveis100,000hoursandthemean
timetorepairis10hours,themeantimetodatalossofamirroreddrivesystem
is100,0002∕(2∗10)=500∗106 hours,or57,000years!
Youshouldbeawarethatwecannotreallyassumethatdrivefailureswill
be independent. Power failures and natural disasters, such as earthquakes,
fires,andfloods,mayresultindamagetobothdrivesatthe sametime.Also,
manufacturing defects in a batch of drives can cause correlated failures. As
drivesage,theprobabilityoffailuregrows,increasingthechancethatasecond
drive will fail while the first is being repaired.In spite of all these considera-
tions, however, mirrored-drive systems offer much higher reliability than do
single-drivesystems.
Powerfailuresareaparticularsourceofconcern,sincetheyoccurfarmore
frequently than do natural disasters. Even with mirroring of drives, if writes
are in progress to the same block in both drives, and power fails before both
blocks are fully written, the two blocks can be in an inconsistent state. One
solutiontothisproblemistowriteonecopyfirst,thenthenext.Anotheristo
addasolid-statenonvolatilecachetotheRAIDarray.Thiswrite-backcache is11.8 RAIDStructure 475
protectedfromdatalossduringpowerfailures,sothewritecanbeconsidered
complete at that point, assuming the cache has some kind of error protection
andcorrection,suchasECCormirroring.
11.8.2 Improvement in Performance via Parallelism
Now let’s consider how parallel access to multiple drives improves perfor-
mance. With mirroring, the rate at which read requests can be handled is
doubled, since read requests can be sent to either drive (as long as both in a
pairarefunctional,asisalmostalwaysthecase).Thetransferrateofeachread
isthesameasinasingle-drivesystem,butthenumberofreadsperunittime
hasdoubled.
Withmultipledrives,wecanimprovethetransferrateaswell(orinstead)
by striping data across the drives. In its simplest form, data striping consists
ofsplittingthebitsofeachbyteacrossmultipledrives;suchstripingiscalled
bit-level striping. For example, if we have an array of eight drives,we write
bitiofeachbytetodrivei.Thearrayofeightdrivescanbetreatedasasingle
drive with sectors that are eight times the normal size and, more important,
haveeighttimestheaccessrate.Everydriveparticipatesineveryaccess(read
orwrite);sothenumberofaccessesthatcanbeprocessedpersecondisabout
thesameasonasingledrive,buteachaccesscanreadeighttimesasmanydata
inthesametimeasonasingledrive.
Bit-level striping can be generalized to include a number of drives that
either is a multiple of 8 or divides 8. For example, if we use an array of four
drives,bitsiand4+iofeachbytegotodrivei.Further,stripingneednotoccur
atthebitlevel.Inblock-levelstriping,forinstance,blocksofafilearestriped
acrossmultipledrives;withndrives,blockiofafilegoestodrive(imodn)+1.
Otherlevelsofstriping,suchasbytesofasectororsectorsofablock,alsoare
possible.Block-levelstripingistheonlycommonlyavailablestriping.
Parallelisminastoragesystem,asachievedthroughstriping,hastwomain
goals:
1. Increasethethroughputofmultiplesmallaccesses(thatis,pageaccesses)
byloadbalancing.
2. Reducetheresponsetimeoflargeaccesses.
11.8.3 RAID Levels
Mirroringprovideshighreliability,butitisexpensive.Stripingprovideshigh
data-transfer rates, but it does not improve reliability. Numerous schemes
to provide redundancy at lower cost by using disk striping combined with
“parity”bits(whichwedescribeshortly)havebeenproposed.Theseschemes
have different cost–performance trade-offs and are classified according to
levels called RAID levels. We describe only the most common levels here;
Figure11.15showsthempictorially(inthefigure,Pindicateserror-correcting
bits and C indicates a second copy of the data). In all cases depicted in the
figure, four drives’ worth of data are stored, and the extra drivesare used to
storeredundantinformationforfailurerecovery.476 Chapter11 Mass-StorageStructure
Figure11.15 RAIDlevels.
• RAID level 0. RAID level0 referstodrivearrays with stripingat the level
of blocks but without any redundancy (such as mirroring or parity bits),
asshowninFigure11.15(a).
• RAIDlevel1.RAIDlevel1referstodrivemirroring.Figure11.15(b)shows
amirroredorganization.
• RAIDlevel4.RAIDlevel4isalsoknownasmemory-styleerror-correcting-
code(ECC)organization.ECCisalsousedinRAID5and6.
The idea of ECC can be used directly in storage arrays via striping of
blocks across drives. For example, the first data block of a sequence of
writescanbestoredindrive1,thesecondblockindrive2,andsoonuntil
the Nth block is stored in drive N; the error-correction calculation result
of those blocks is stored on drive N +1. This scheme is shown in Figure
11.15(c),wherethedrivelabeledPstorestheerror-correctionblock.Ifone
ofthedrivesfails,theerror-correctioncoderecalculationdetectsthatand11.8 RAIDStructure 477
prevents the data from being passed to the requesting process, throwing
anerror.
RAID 4 can actually correct errors, even though there is only one ECC
block. It takes into account the fact that, unlike memory systems, drive
controllerscandetectwhetherasectorhasbeenreadcorrectly,soasingle
parityblockcanbeusedforerrorcorrectionanddetection.Theideaisas
follows:Ifoneofthesectorsisdamaged,weknowexactlywhichsectorit
is.Wedisregardthedatainthatsectorandusetheparitydatatorecalculate
thebaddata.Foreverybitintheblock,wecandetermineifitisa1ora0
bycomputingtheparityofthecorrespondingbitsfromsectorsintheother
drives.Iftheparityoftheremainingbitsisequaltothestoredparity,the
missingbitis0;otherwise,itis1.
A block read accesses only one drive, allowing other requests to be
processed by the other drives.The transfer ratesfor largereadsare high,
since all the disks can be read in parallel. Large writes also have high
transferrates,sincethedataandparitycanbewritteninparallel.
Smallindependentwritescannotbeperformedinparallel.Anoperating-
systemwriteofdatasmallerthan ablock requiresthat the block be read,
modifiedwiththenewdata,andwrittenback.Theparityblockhastobe
updated as well. This is known as the read-modify-write cycle. Thus, a
single write requires four drive accesses: two to read the two old blocks
andtwotowritethetwonewblocks.
WAFL(whichwecoverinChapter14)usesRAIDlevel4becausethisRAID
levelallowsdrivestobeaddedtoaRAIDsetseamlessly.Iftheaddeddrives
areinitializedwithblockscontainingonlyzeros,thentheparityvaluedoes
notchange,andtheRAIDsetisstillcorrect.
RAID level 4 has two advantages over level 1 while providing equal
data protection. First, the storage overhead is reduced because only one
paritydriveisneededforseveralregulardrives,whereasonemirrordrive
is needed for every drive in level 1. Second, since reads and writes of a
series of blocks are spread out over multiple drives with N-way striping
ofdata,thetransferrateforreadingorwritingasetofblocksisNtimesas
fastaswithlevel1.
Aperformance problem with RAID 4—and with all parity-based RAID
levels—is the expense of computing and writing the XOR parity. This
overhead can result in slower writes than with non-parity RAID arrays.
Modern general-purpose CPUs are very fast compared with drive I/O,
however,sotheperformancehitcanbeminimal.Also,manyRAIDstorage
arraysorhostbus-adaptersincludeahardwarecontrollerwithdedicated
parity hardware. This controller offloads the parity computation from
the CPU to the array. The array has an NVRAM cache as well, to store
the blocks while the parity is computed and to buffer the writes from
the controller to the drives. Such buffering can avoid most read-modify-
write cycles by gathering datato be written intoa full stripeand writing
to all drives in the stripe concurrently. This combination of hardware
acceleration and buffering can make parity RAID almost as fast as non-
parityRAID,frequentlyoutperforminganon-cachingnon-parityRAID.
• RAID level5.RAID level5,or block-interleaveddistributedparity,differs
fromlevel4inthatitspreadsdataandparityamongallN+1drives,rather478 Chapter11 Mass-StorageStructure
than storing data in N drives and parity in one drive. For each set of N
blocks, one of the drives stores the parity and the others store data. For
example,withanarrayoffivedrives,theparityforthenthblockisstored
indrive(nmod5)+1.Thenthblocksoftheotherfourdrivesstoreactual
data for that block. This setup is shown in Figure 11.15(d), where the Ps
aredistributedacrossallthedrives.Aparityblockcannotstoreparityfor
blocks in the same drive, because a drive failure would result in loss of
dataaswellasofparity,andhencethelosswouldnotberecoverable.By
spreadingtheparityacrossallthedrivesintheset,RAID5avoidspotential
overuseofasingleparitydrive,whichcanoccurwithRAID4.RAID5isthe
mostcommonparityRAID.
• RAID level 6. RAID level 6, also called the P + Q redundancy scheme, is
much like RAID level 5 but stores extra redundant information to guard
against multipledrivefailures.XOR parity cannot be usedon both parity
blocksbecausetheywouldbeidenticalandwouldnotprovidemorerecov-
ery information. Instead of parity, error-correcting codes such as Galois
fiel mathareusedtocalculateQ.IntheschemeshowninFigure11.15(e),
2 blocks of redundant data are stored for every 4 blocks of data—com-
paredwith1parityblockinlevel5—andthesystemcantoleratetwodrive
failures.
• Multidimensional RAID level 6. Some sophisticated storage arrays
amplify RAID level 6. Consider an array containing hundreds of drives.
Putting those drives in a RAID level 6 stripe would result in many data
drivesand only two logical parity drives.Multidimensional RAID level6
logicallyarrangesdrivesintorowsandcolumns(twoormoredimensional
arrays)andimplementsRAIDlevel6bothhorizontallyalongtherowsand
vertically down the columns. The system can recover from any failure
—or, indeed, multiple failures—by using parity blocks in any of these
locations. This RAID level is shown in Figure 11.15(f). For simplicity, the
figure shows the RAID parity on dedicateddrives,but in reality the RAID
blocksarescatteredthroughouttherowsandcolumns.
• RAIDlevels0+1and1+0.RAIDlevel0+1referstoacombinationofRAID
levels 0 and 1. RAID 0 provides the performance, while RAID 1 provides
thereliability.Generally,thislevelprovidesbetterperformancethanRAID
5. It is common in environments where both performance and reliability
areimportant.Unfortunately,likeRAID1,itdoublesthenumberofdrives
neededforstorage,soitisalsorelativelyexpensive.InRAID0+1,asetof
drives are striped, and then the stripe is mirrored to another, equivalent
stripe.
AnotherRAIDvariationisRAIDlevel1+0,inwhichdrivesaremirrored
inpairsandthentheresultingmirroredpairsarestriped.Thisschemehas
sometheoreticaladvantagesoverRAID0+1.Forexample,ifasingledrive
fails in RAID 0 + 1, an entire stripe is inaccessible, leaving only the other
stripe. With a failure in RAID 1 + 0, a single drive is unavailable, but the
drivethatmirrorsitisstillavailable,asarealltherestofthedrives(Figure
11.16).11.8 RAIDStructure 479
stripe
x
mirror
stripe
a) RAID 0 1 1 with a single disk failure.
x
stripe
mirror mirror mirror mirror
b) RAID 1 1 0 with a single disk failure.
Figure11.16 RAID0+1and1+0withasinglediskfailure.
NumerousvariationshavebeenproposedtothebasicRAIDschemesdescribed
here. As a result, some confusion may exist about the exact definitions of the
differentRAIDlevels.
The implementation of RAID is another area of variation. Consider the
followinglayersatwhichRAIDcanbeimplemented.
• Volume-managementsoftwarecanimplementRAIDwithinthekernelorat
the system software layer. In this case, the storage hardware can provide
minimalfeaturesandstillbepartofafullRAIDsolution.
• RAID can be implemented in the host bus-adapter (HBA) hardware. Only
the drives directly connected to the HBAcan be part of a given RAID set.
Thissolutionislowincostbutnotveryflexible.
• RAIDcanbeimplementedinthehardwareofthestoragearray.Thestorage
array can create RAID sets of various levels and can even slice these sets
into smaller volumes, which are then presented to the operating system.
Theoperatingsystemneedonlyimplementthefilesystemoneachofthe
volumes.Arrayscanhavemultipleconnectionsavailableorcanbepartof
aSAN,allowingmultiplehoststotakeadvantageofthearray’sfeatures.
• RAIDcanbeimplementedintheSANinterconnectlayerbydrivevirtualiza-
tiondevices.Inthiscase,adevicesitsbetweenthehostsandthestorage.It480 Chapter11 Mass-StorageStructure
accepts commands from the servers and manages access to the storage.
It could provide mirroring, for example, by writing each block to two
separatestoragedevices.
Other features,such assnapshots and replication,can be implementedat
eachoftheselevelsaswell.Asnapshotisaviewofthefilesystembeforethe
lastupdatetookplace.(SnapshotsarecoveredmorefullyinChapter14.)Repli-
cationinvolvestheautomaticduplicationofwritesbetweenseparatesitesfor
redundancy and disaster recovery. Replication can be synchronous or asyn-
chronous. Insynchronous replication,eachblock mustbe writtenlocallyand
remotely before the write is considered complete, whereas in asynchronous
replication, the writes are grouped together and written periodically. Asyn-
chronous replication can result in data loss if the primary site fails, but it is
faster and has no distance limitations. Increasingly, replication is also used
within a data center or even within a host. As an alternative to RAID protec-
tion,replicationprotectsagainstdatalossandalsoincreasesreadperformance
(byallowingreadsfromeachofthereplicacopies).Itdoesofcourseusemore
storagethanmosttypesofRAID.
The implementation of these features differs depending on the layer at
whichRAIDisimplemented.Forexample,ifRAIDisimplementedinsoftware,
then each host may need to carry out and manage its own replication. If
replication is implemented in the storage array or in the SAN interconnect,
however, then whatever the host operating system or its features, the host’s
datacanbereplicated.
One other aspect of most RAID implementations is a hot spare drive or
drives. A hot spare is not used for data but is configured to be used as a
replacement in case of drive failure. For instance, a hot spare can be used to
rebuildamirroredpairshouldoneofthedrivesinthepairfail.Inthisway,the
RAID level can be reestablished automatically, without waiting for the failed
drivetobereplaced.Allocatingmorethanonehotspareallowsmorethanone
failuretoberepairedwithouthumanintervention.
11.8.4 Selecting a RAID Level
Given the many choices they have, how do system designers choose a RAID
level? One consideration is rebuild performance. If a drive fails, the time
neededtorebuilditsdatacanbesignificant. Thismaybeanimportantfactor
if a continuous supply of data is required, as it is in high-performance or
interactivedatabasesystems.Furthermore,rebuildperformanceinfluencesthe
meantimebetweenfailures.
RebuildperformancevarieswiththeRAIDlevelused.Rebuildingiseasiest
for RAID level 1, since data can be copied from another drive. For the other
levels, we need to access all the other drives in the array to rebuild data in a
faileddrive.RebuildtimescanbehoursforRAIDlevel5rebuildsoflargedrive
sets.
RAID level 0 is used in high-performance applications where data loss is
not critical. For example, in scientific computing where a data set is loaded
and explored, RAID level 0 works well because any drive failures would just
require a repair and reloading of the data from its source. RAID level 1 is
popular for applications that require high reliability with fast recovery. RAID11.8 RAIDStructure 481
THEInServSTORAGEARRAY
Innovation,inanefforttoprovidebetter,faster,andlessexpensivesolutions,
frequentlyblursthelinesthatseparatedprevioustechnologies.Considerthe
InServstoragearrayfromHP3Par.Unlikemostotherstoragearrays,InServ
does not require that a set of drives be configured at a specific RAID level.
Rather,eachdriveisbrokeninto256-MB“chunklets.” RAIDisthenappliedat
thechunkletlevel.AdrivecanthusparticipateinmultipleandvariousRAID
levelsasitschunkletsareusedformultiplevolumes.
InServ also provides snapshots similar to those created by the WAFLfile
system. The format of InServ snapshots can be read–write as well as read-
only,allowingmultiplehoststomountcopiesofagivenfilesystemwithout
needingtheirowncopiesoftheentirefilesystem.Anychangesahostmakes
initsowncopyarecopy-on-writeandsoarenotreflectedintheothercopies.
Afurther innovation is utility storage. Some file systems do not expand
orshrink.Onthesesystems,theoriginalsizeistheonlysize,andanychange
requires copying data. An administrator can configure InServ to provide a
host with a large amount of logical storage that initially occupies only a
smallamountofphysicalstorage.Asthehoststartsusingthestorage,unused
drivesareallocatedtothehost,uptotheoriginallogicallevel.Thehostthus
canbelievethatithasalargefixedstoragespace,createitsfilesystemsthere,
andsoon.DrivescanbeaddedtoorremovedfromthefilesystembyInServ
without the file system’s noticing the change. This feature can reduce the
number of drives needed by hosts, or at least delay the purchase of drives
untiltheyarereallyneeded.
0+1and1+0areusedwherebothperformanceandreliabilityareimportant
—for example, for small databases. Due to RAID 1’s high space overhead,
RAID 5 is often preferred for storing moderate volumes of data. RAID 6 and
multidimensionalRAID6arethemostcommonformatsinstoragearrays.They
offergoodperformanceandprotectionwithoutlargespaceoverhead.
RAIDsystemdesignersandadministratorsofstoragehavetomakeseveral
other decisions as well. For example, how many drives should be in a given
RAIDset?Howmanybitsshouldbeprotectedbyeachparitybit?Ifmoredrives
areinanarray,data-transferratesarehigher,butthesystemismoreexpensive.
Ifmorebitsareprotectedbyaparitybit,thespaceoverheadduetoparitybits
islower,butthechancethataseconddrivewillfailbeforethefirstfaileddrive
isrepairedisgreater,andthatwillresultindataloss.
11.8.5 Extensions
TheconceptsofRAIDhavebeengeneralizedtootherstoragedevices,including
arraysoftapes,andeventothebroadcastofdataoverwirelesssystems.When
appliedtoarraysoftapes,RAIDstructuresareabletorecoverdataevenifone
ofthetapesinanarrayisdamaged.Whenappliedtobroadcastofdata,ablock
ofdataissplitintoshortunitsandisbroadcastalongwithaparityunit.Ifone
oftheunitsisnotreceivedforanyreason,itcanbereconstructedfromtheother482 Chapter11 Mass-StorageStructure
units.Commonly,tape-driverobotscontainingmultipletapedriveswillstripe
dataacrossallthedrivestoincreasethroughputanddecreasebackuptime.
11.8.6 Problems with RAID
Unfortunately, RAID does not always assure that data are available for the
operatingsystemanditsusers.Apointertoafilecouldbewrong,forexample,
orpointerswithinthefilestructurecouldbewrong.Incompletewrites(called
“torn writes”), if not properly recovered, could result in corrupt data. Some
otherprocesscouldaccidentallywriteoverafilesystem’sstructures,too.RAID
protects against physical media errors, but not other hardware and software
errors.AfailureofthehardwareRAIDcontroller,orabuginthesoftwareRAID
code, could result in total data loss. As large as is the landscape of software
andhardwarebugs,thatishownumerousarethepotentialperilsfordataon
asystem.
TheSolarisZFSfilesystemtakesaninnovativeapproachtosolvingthese
problems through the use of checksums. ZFS maintains internal checksums
of all blocks, including data and metadata. These checksums are not kept
with the block that is being checksummed. Rather, they are stored with the
pointertothatblock.(SeeFigure11.17.)Consideraninode—adatastructure
for storing file system metadata—with pointers to its data. Within the inode
is the checksum of each block of data. If there is a problem with the data,
the checksum will be incorrect, and the file system will know about it. If the
dataaremirrored,andthereisablock withacorrect checksumand onewith
an incorrect checksum, ZFS will automatically update the bad block with the
good one. Similarly, the directory entry that points to the inode has a check-
sum for the inode. Any problem in the inode is detected when the directory
is accessed. This checksumming takes places throughout all ZFS structures,
providing a much higher level of consistency, error detection, and error cor-
metadata block 1
address 1 address 2
checksum MB2 checksum
metadata block 2
address address
checksum D1 checksum D2
data 1 data 2
Figure11.17 ZFSchecksumsallmetadataanddata.11.8 RAIDStructure 483
rection than is found in RAID drive sets or standard file systems. The extra
overhead that is created by the checksum calculation and extra block read-
modify-writecyclesisnotnoticeablebecausetheoverallperformanceofZFSis
veryfast.(AsimilarchecksumfeatureisfoundintheLinuxBTRFSfilesystem.
Seehttps://btrfs.wiki.kernel.org/index.php/Btrfs design.)
Another issuewith most RAID implementationsis lack of flexibility.Con-
sider a storage array with twenty drivesdividedinto four sets of five drives.
EachsetoffivedrivesisaRAIDlevel5set.Asaresult,therearefourseparate
volumes, each holding a file system. But what if one file system is too large
to fit on a five-drive RAID level 5 set? And what if another file system needs
verylittlespace?Ifsuchfactorsareknownaheadoftime,thenthedrivesand
volumes can be properly allocated. Very frequently, however, drive use and
requirementschangeovertime.
Even if the storage array allowed the entire set of twenty drives to be
created as one large RAID set, other issues could arise. Several volumes of
various sizes could be built on the set. But some volume managers do not
allowustochangeavolume’ssize.Inthatcase,wewouldbeleftwiththesame
issuedescribedabove—mismatchedfile-systemsizes.Somevolumemanagers
allowsizechanges,butsomefilesystemsdonotallowforfile-systemgrowth
orshrinkage.Thevolumescouldchangesizes,butthefilesystemswouldneed
toberecreatedtotakeadvantageofthosechanges.
ZFS combines file-system management and volume management into a
unit providing greater functionality than the traditional separation of those
functionsallows.Drives,orpartitionsofdrives,aregatheredtogetherviaRAID
sets into pools of storage. Apool can hold one or more ZFS file systems. The
entirepool’sfreespaceisavailabletoallfilesystemswithinthatpool.ZFSuses
the memory model of malloc() and free() to allocate and release storage
for each file system as blocks are used and freed within the file system. As
a result, there are no artificial limits on storage use and no need to relocate
filesystemsbetweenvolumesorresizevolumes.ZFSprovidesquotastolimit
thesizeofafilesystemandreservationstoassurethatafilesystemcangrow
by a specified amount, but those variables can be changed by the file-system
owneratanytime.OthersystemslikeLinuxhavevolumemanagersthatallow
thelogicaljoiningofmultiplediskstocreatelarger-than-diskvolumestohold
largefilesystems.Figure11.18(a)depictstraditionalvolumesandfilesystems,
andFigure11.18(b)showstheZFSmodel.
11.8.7 Object Storage
General-purposecomputerstypicallyusefilesystemstostorecontentforusers.
Another approach to data storage is to start with a storage pool and place
objects in that pool. This approach differs from file systems in that there is
no way to navigate the pool and find those objects. Thus, rather than being
user-oriented, object storage is computer-oriented, designed to be used by
programs.Atypicalsequenceis:
1. Createanobjectwithinthestoragepool,andreceiveanobjectID.
2. AccesstheobjectwhenneededviatheobjectID.
3. DeletetheobjectviatheobjectID.484 Chapter11 Mass-StorageStructure
FS FS FS
volume volume volume
(a) Traditional volumes and file systems.
ZFS ZFS ZFS
storage pool
(b) ZFS and pooled storage.
Figure11.18 TraditionalvolumesandfilesystemscomparedwiththeZFSmodel.
Object storage management software, such as the Hadoop fil system
(HDFS) and Ceph, determines where to store the objects and manages object
protection. Typically, this occurs on commodity hardware rather than RAID
arrays.Forexample,HDFScanstoreN copiesofanobjectonN differentcom-
puters.Thisapproachcanbelowerincostthanstoragearraysandcanprovide
fastaccesstothatobject(atleastonthoseNsystems).AllsystemsinaHadoop
clustercanaccesstheobject,butonlysystemsthathaveacopyhavefastaccess
via the copy. Computations on the data occur on those systems, with results
sent across the network, for example, only to the systems requesting them.
Othersystemsneednetworkconnectivitytoreadandwritetotheobject.There-
fore, object storage is usually used for bulk storage, not high-speed random
access. Object storage has the advantage of horizontal scalability. That is,
whereas a storagearray has afixed maximum capacity, toadd capacity toan
object store, we simply add more computers with internal disks or attached
externaldisksandaddthemtothepool.Objectstoragepoolscanbepetabytes
insize.
Anotherkeyfeatureofobjectstorageisthateachobjectisself-describing,
including description of its contents. In fact, object storage is also known as
content-addressable storage, because objects can be retrieved based on their
contents. There is no set format for the contents, so what the system stores is
unstructureddata.
Whileobjectstorageisnotcommonongeneral-purposecomputers,huge
amountsofdataarestoredinobjectstores,includingGoogle’sInternetsearch
contents,Dropboxcontents,Spotify’ssongs,andFacebookphotos.Cloudcom-
puting (such as Amazon AWS) generally uses object stores (in Amazon S3) to
holdfilesystemsaswellasdataobjectsforcustomerapplicationsrunningon
cloudcomputers.PracticeExercises 485
Forthehistoryofobjectstoresseehttp://www.theregister.co.uk/2016/07/15
/the history boys cas and object storage map.
11.9 Summary
• Harddiskdrivesandnonvolatilememorydevicesarethemajorsecondary
storageI/Ounitsonmostcomputers.Modernsecondarystorageisstruc-
turedaslargeone-dimensionalarraysoflogicalblocks.
• Drivesofeithertypemaybeattachedtoacomputersysteminoneofthree
ways: (1) through the local I/O ports on the host computer, (2) directly
connectedtomotherboards,or(3)throughacommunicationsnetworkor
storagenetworkconnection.
• Requests for secondary storage I/O are generated by the file system and
by the virtual memory system. Each request specifies the address on the
devicetobereferencedintheformofalogicalblocknumber.
• Disk-schedulingalgorithmscanimprovetheeffectivebandwidthofHDDs,
the average response time, and the variance in response time. Algo-
rithms such as SCAN and C-SCAN are designed to make such improve-
ments through strategies for disk-queue ordering. Performance of disk-
schedulingalgorithmscanvarygreatlyonharddisks.Incontrast,because
solid-state disks have no moving parts, performance varies little among
schedulingalgorithms,andquiteoftenasimpleFCFSstrategyisused.
• Datastorageandtransmissionarecomplexandfrequentlyresultinerrors.
Error detection attempts to spot such problems to alert the system for
corrective action and to avoid error propagation. Error correction can
detect and repair problems, depending on the amount of correction data
availableandtheamountofdatathatwascorrupted.
• Storage devices are partitioned into one or more chunks of space. Each
partition can hold a volume or be part of a multidevice volume. File
systemsarecreatedinvolumes.
• The operating system manages the storage device’s blocks. New devices
typically come pre-formatted. The device is partitioned, file systems are
created,andbootblocksareallocatedtostorethesystem’sbootstrappro-
gramifthedevicewillcontainanoperatingsystem.Finally,whenablock
orpageiscorrupted,thesystemmusthaveawaytolockoutthatblockor
toreplaceitlogicallywithaspare.
• An efficient swap space is a key to good performance in some systems.
Somesystemsdedicatearawpartitiontoswapspace,andothersuseafile
withinthefilesysteminstead.Stillothersystemsallowtheuserorsystem
administratortomakethedecisionbyprovidingbothoptions.
• Becauseoftheamountofstoragerequiredonlargesystems,andbecause
storage devices fail in various ways, secondary storage devices are fre-
quently made redundant via RAID algorithms. These algorithms allow
morethanonedrivetobeusedforagivenoperationandallowcontinued486 Chapter11 Mass-StorageStructure
operationandevenautomaticrecoveryinthefaceofadrivefailure.RAID
algorithms are organized into different levels; each level provides some
combinationofreliabilityandhightransferrates.
• Object storage is used for big data problems such as indexing the Inter-
net and cloud photo storage.Objects are self-defining collections ofdata,
addressedby object ID rather than file name. Typically it uses replication
fordataprotection,computesbasedonthedataonsystemswhereacopy
of the data exists, and is horizontally scalable for vast capacity and easy
expansion.
Practice Exercises
11.1 Isdiskscheduling,otherthan FCFSscheduling,usefulinasingle-user
environment?Explainyouranswer.
11.2 ExplainwhySSTFschedulingtendstofavormiddlecylindersoverthe
innermostandoutermostcylinders.
11.3 Why is rotational latency usually not considered in disk scheduling?
How would you modify SSTF, SCAN, and C-SCAN to include latency
optimization?
11.4 Why is it important to balance file-system I/O among the disks and
controllersonasysteminamultitaskingenvironment?
11.5 What are the tradeoffs involved in rereading code pages from the file
systemversususingswapspacetostorethem?
11.6 Is there any way to implement truly stable storage? Explain your
answer.
11.7 It is sometimes said that tape is a sequential-access medium, whereas
a hard disk is a random-access medium. In fact, the suitability of a
storage device for random access depends on the transfer size. The
termstreamingtransferratedenotestherateforadatatransferthatis
underway,excludingtheeffectofaccesslatency.Incontrast,theeffec-
tive transfer rate is the ratio of total bytes to total seconds, including
overheadtimesuchasaccesslatency.
Supposewehaveacomputerwiththefollowingcharacteristics:the
level-2 cache has an access latency of 8 nanoseconds and a streaming
transfer rate of 800 megabytes per second, the main memory has an
access latency of 60 nanoseconds and a streaming transfer rate of 80
megabytes per second, the hard disk has an access latency of 15 mil-
lisecondsandastreamingtransferrateof5megabytespersecond,and
atapedrivehasanaccesslatencyof60secondsandastreamingtransfer
rateof2megabytespersecond.
a. Random access causes the effective transfer rate of a device to
decrease,becausenodataaretransferredduringtheaccesstime.
For the disk described, what is the effective transfer rate if anFurtherReading 487
averageaccessisfollowedbyastreamingtransferof(1)512bytes,
(2)8kilobytes,(3)1megabyte,and(4)16megabytes?
b. Theutilizationofadeviceistheratioofeffectivetransferrateto
streamingtransferrate.Calculatetheutilizationofthediskdrive
foreachofthefourtransfersizesgiveninparta.
c. Supposethatautilizationof25percent(orhigher)isconsidered
acceptable. Using the performance figures given, compute the
smallesttransfersizeforadiskthatgivesacceptableutilization.
d. Complete the following sentence: A disk is a random-
access device for transfers larger than bytes and is a
sequential-accessdeviceforsmallertransfers.
e. Computetheminimumtransfersizesthatgiveacceptableutiliza-
tionforcache,memory,andtape.
f. When is a tape a random-access device, and when is it a
sequential-accessdevice?
11.8 CouldaRAIDlevel1organizationachievebetterperformanceforread
requeststhanaRAIDlevel0organization(withnonredundantstriping
ofdata)?Ifso,how?
11.9 GivethreereasonstouseHDDsassecondarystorage.
11.10 GivethreereasonstouseNVMdevicesassecondarystorage.
Further Reading
[Services(2012)]providesanoverviewofdatastorageinavarietyofmodern
computing environments. Discussions of redundant arrays of independent
disks (RAIDs) are presented by [Patterson et al. (1988)]. [Kim et al. (2009)]
discussdisk-schedulingalgorithmsforSSDs.Object-basedstorageisdescribed
by[Mesnieretal.(2003)].
[Russinovich et al. (2017)], [McDougall and Mauro (2007)], and [Love
(2010)]discussfile-systemdetailsinWindows,Solaris,andLinux,respectively.
Storagedevicesarecontinuouslyevolving,withgoalsofincreasingperfor-
mance,increasingcapacity,orboth.Foronedirectionincapacityimprovement
seehttp://www.tomsitpro.com/articles/shingled-magnetic-recoding-smr-101-
basics,2-933.html).
RedHat (and other) Linux distributions have multiple, selectable disk
schedulingalgorithms.Fordetailsseehttps://access.redhat.com/site/docume
ntation/en-US/Red Hat Enterprise Linux/7/html/Performance Tuning Guide/in
dex.html.
Learn more about the default Linux bootstrap loader at
https://www.gnu.org/software/grub/manual/grub.html/.
Arelativelynewfilesystem,BTRFS,isdetailedinhttps://btrfs.wiki.kernel.or
g/index.php/Btrfs design.
Forthehistoryofobjectstoresseehttp://www.theregister.co.uk/2016/07/15
/the history boys cas and object storage map.488 Chapter11 Mass-StorageStructure
Bibliography
[Kimetal.(2009)] J.Kim,Y.Oh,E.Kim,J.C.D.Lee,andS.Noh,“DiskSched-
ulersforSolidStateDrivers”,ProceedingsoftheseventhACMinternationalconfer-
enceonEmbeddedsoftware(2009),pages295–304.
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[McDougallandMauro(2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition,PrenticeHall(2007).
[Mesnieretal.(2003)] M.Mesnier,G.Ganger,andE.Ridel,“Object-basedstor-
age”,IEEECommunicationsMagazine,Volume41,Number8(2003),pages84–99.
[Pattersonetal.(1988)] D. A. Patterson, G. Gibson, and R. H. Katz, “A Case
for Redundant Arrays of Inexpensive Disks (RAID)”, Proceedings of the ACM
SIGMOD International Conference on the Management of Data (1988), pages 109–
116.
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).
[Services(2012)] E. E. Services, Information Storage and Management: Storing,
Managing,andProtectingDigitalInformationinClassic,Virtualized,andCloudEnvi-
ronments,Wiley(2012).EX-43
Chapter 11 Exercises
11.11 Noneofthedisk-schedulingdisciplines,exceptFCFS,istrulyfair(star-
vationmayoccur).
a. Explainwhythisassertionistrue.
b. Describe a way to modify algorithms such as SCAN to ensure
fairness.
c. Explainwhyfairnessisanimportantgoalinamulti-usersystems.
d. Give three or more examples of circumstances in which it is
important that the operating system be unfair in serving I/O
requests.
11.12 ExplainwhyNVMdevicesoftenuseanFCFSdisk-schedulingalgorithm.
11.13 Supposethatadiskdrivehas5,000cylinders,numbered0to4,999.The
driveiscurrentlyservingarequestatcylinder2,150,andtheprevious
request was at cylinder 1,805. The queue of pending requests, in FIFO
order,is:
2,069;1,212;2,296;2,800;544;1,618;356;1,523;4,965;3,681
Starting from the current head position, what is the total distance (in
cylinders) that the disk arm moves to satisfy all the pending requests
foreachofthefollowingdisk-schedulingalgorithms?
a. FCFS
b. SCAN
c. C-SCAN
11.14 Elementaryphysicsstatesthatwhenanobjectissubjectedtoaconstant
acceleration a, the relationship between distance d and time t is given
by d = 1at2. Suppose that, during a seek, the disk in Exercise 11.14
2
acceleratesthediskarmataconstant rateforthefirsthalfoftheseek,
thendeceleratesthediskarmatthesamerateforthesecondhalfofthe
seek.Assumethatthediskcanperformaseektoanadjacentcylinder
in 1 millisecond and a full-stroke seek over all 5,000 cylinders in 18
milliseconds.
a. Thedistanceofaseekisthenumberofcylindersoverwhichthe
head moves. Explain why the seek time is proportional to the
squarerootoftheseekdistance.
b. Write an equation for the seek time as a function of the seek
distance.Thisequationshouldbeoftheformt=x+y√L,wheret
isthetimeinmillisecondsandListheseekdistanceincylinders.
c. CalculatethetotalseektimeforeachoftheschedulesinExercise
11.14. Determine which schedule is the fastest (has the smallest
totalseektime).Exercises EX-44
d. Thepercentagespeedupisthetimesaveddividedbytheoriginal
time.Whatisthepercentagespeedupofthefastestscheduleover
FCFS?
11.15 SupposethatthediskinExercise11.15rotatesat7,200RPM.
a. Whatistheaveragerotationallatencyofthisdiskdrive?
b. Whatseekdistancecanbecoveredinthetimethatyoufoundfor
parta?
11.16 CompareandcontrastHDDsandNVMdevices.Whatarethebestappli-
cationsforeachtype?
11.17 DescribesomeadvantagesanddisadvantagesofusingNVMdevicesas
a caching tier and as a disk-drive replacement compared with using
onlyHDDs.
11.18 Compare the performance of C-SCAN and SCAN scheduling, assum-
ing auniform distributionof requests.Considertheaverageresponse
time (the time between the arrival of a request and the completion of
thatrequest’sservice),thevariationinresponsetime,andtheeffective
bandwidth.Howdoesperformancedependontherelativesizesofseek
timeandrotationallatency?
11.19 Requests are not usually uniformly distributed. For example, we can
expect a cylinder containing the file-system metadata to be accessed
more frequently than a cylinder containing only files. Suppose you
know that 50 percent of the requests are for a small, fixed number of
cylinders.
a. Wouldanyoftheschedulingalgorithmsdiscussedinthischapter
beparticularlygoodforthiscase?Explainyouranswer.
b. Propose a disk-scheduling algorithm that gives even better per-
formancebytakingadvantageofthis“hotspot”onthedisk.
11.20 Consider a RAID level 5 organization comprising five disks, with the
parityforsetsoffourblocksonfourdisksstoredonthefifthdisk.How
manyblocksareaccessedinordertoperformthefollowing?
a. Awriteofoneblockofdata
b. Awriteofsevencontinuousblocksofdata
11.21 ComparethethroughputachievedbyaRAIDlevel5organizationwith
thatachievedbyaRAIDlevel1organizationforthefollowing:
a. Readoperationsonsingleblocks
b. Readoperationsonmultiplecontiguousblocks
11.22 ComparetheperformanceofwriteoperationsachievedbyaRAIDlevel
5organizationwiththatachievedbyaRAIDlevel1organization.
11.23 Assume that you have a mixed configuration comprising disks orga-
nized as RAID level 1 and RAID level 5 disks. Assume that the system
hasflexibilityindecidingwhichdiskorganizationtouseforstoringaEX-45
particular file. Which files should be stored in the RAID level 1 disks
andwhichintheRAIDlevel5disksinordertooptimizeperformance?
11.24 Thereliabilityofastoragedeviceistypicallydescribedintermsofmean
timebetweenfailures(MTBF).Althoughthisquantityiscalleda“time,”
theMTBFactuallyismeasuredindrive-hoursperfailure.
a. Ifasystemcontains1,000diskdrives,eachofwhichhasa750,000-
hour MTBF, which of the following best describes how often a
drivefailurewilloccurinthatdiskfarm:onceperthousandyears,
oncepercentury,onceperdecade,onceperyear,oncepermonth,
once perweek,once perday,once perhour, once perminute,or
oncepersecond?
b. Mortality statistics indicate that, on the average, a U.S. resident
hasabout1chancein1,000ofdyingbetweentheagesof20and21.
DeducetheMTBFhoursfor20-year-olds.Convertthisfigurefrom
hours to years.What does this MTBF tellyouabout the expected
lifetimeofa20-year-old?
c. Themanufacturerguaranteesa1-million-hourMTBFforacertain
modelofdiskdrive.Whatcanyouconcludeaboutthenumberof
yearsforwhichoneofthesedrivesisunderwarranty?
11.25 Discuss the relative advantages and disadvantages of sector sparing
andsectorslipping.
11.26 Discuss the reasons why the operating system might require accurate
informationonhowblocksarestoredonadisk.Howcouldtheoperat-
ingsystemimprovefile-systemperformancewiththisknowledge?P-55 Chapter11 Mass-StorageStructure
Programming Problems
11.27 Writeaprogramthat implementsthefollowing disk-schedulingalgo-
rithms:
a. FCFS
b. SCAN
c. C-SCAN
Your program will service a disk with 5,000 cylinders numbered 0 to
4,999. The program will generate a random series of 1,000 cylinder
requests and service them according to each of the algorithms listed
above.Theprogramwillbepassedtheinitialpositionofthediskhead
(as a parameter on the command line) and report the total amount of
headmovementrequiredbyeachalgorithm.12
CHAPTER
I/O Systems
The two main jobs of a computer are I/O and computing. In many cases, the
main job is I/O, and the computing or processing is merely incidental. For
instance, when we browse a web page or edit a file, our immediate interest
istoreadorentersomeinformation,nottocomputeananswer.
The role of the operating system in computer I/O is to manage and con-
trol I/O operations and I/O devices. Although related topics appear in other
chapters, here we bring together the pieces to paint a complete picture of
I/O. First, we describe the basics of I/O hardware, because the nature of the
hardwareinterfaceplacesconstraintsontheinternalfacilitiesoftheoperating
system. Next, we discuss the I/O services provided by the operating system
and the embodiment of these services in the application I/O interface. Then,
we explain how the operating system bridges the gap between the hardware
interface and the application interface. We also discuss the UNIX System V
STREAMS mechanism, which enables an application to assemble pipelines of
driver code dynamically. Finally, we discuss the performance aspects of I/O
andtheprinciplesofoperating-systemdesignthatimproveI/Operformance.
CHAPTER OBJECTIVES
• Explorethestructureofanoperatingsystem’sI/Osubsystem.
(cid:129) DiscusstheprinciplesandcomplexitiesofI/Ohardware.
(cid:129) ExplaintheperformanceaspectsofI/Ohardwareandsoftware.
12.1 Overview
The control of devices connected to the computer is a major concern of
operating-systemdesigners.BecauseI/Odevicesvarysowidelyintheirfunc-
tion and speed (consider a mouse, a hard disk, a flash drive, and a tape
robot), varied methods are needed to control them. These methods form the
I/O subsystem of the kernel, which separates the rest of the kernel from the
complexitiesofmanagingI/Odevices.
489490 Chapter12 I/OSystems
I/O-devicetechnologyexhibitstwoconflictingtrends.Ontheonehand,we
seeincreasingstandardizationofsoftwareandhardwareinterfaces.Thistrend
helps us toincorporate improveddevicegenerations intoexisting computers
andoperatingsystems.Ontheotherhand,weseeanincreasinglybroadvariety
of I/O devices. Some new devices are so unlike previous devices that it is
a challenge to incorporate them into our computers and operating systems.
Thischallengeismetbyacombinationofhardwareandsoftwaretechniques.
ThebasicI/Ohardwareelements,suchasports,buses,anddevicecontrollers,
accommodate a wide variety of I/O devices. To encapsulate the details and
oddities of different devices, the kernel of an operating system is structured
to use device-driver modules. The device drivers present a uniform device-
accessinterfacetotheI/Osubsystem,muchassystemcallsprovideastandard
interfacebetweentheapplicationandtheoperatingsystem.
12.2 I/O Hardware
Computers operate a great many kinds of devices. Most fit into the general
categoriesofstoragedevices(disks,tapes),transmissiondevices(networkcon-
nections, Bluetooth), and human-interface devices (screen, keyboard, mouse,
audioinandout).Otherdevicesaremorespecialized,suchasthoseinvolved
inthesteeringofajet.Intheseaircraft,ahumangivesinputtotheflightcom-
puterviaajoystickandfootpedals,andthecomputersendsoutputcommands
thatcausemotorstomoveruddersandflapsandfuelstotheengines.Despite
the incrediblevarietyofI/Odevices,though, we needonly afewconcepts to
understandhowthedevicesareattachedandhowthesoftwarecancontrolthe
hardware.
Adevice communicates with a computer system by sending signals over
a cable or even through the air. The device communicates with the machine
via a connection point, or port—for example, a serial port. (The term PHY,
shorthand for the OSI model physical layer, is also used in reference to ports
butismorecommonindata-centernomenclature.)Ifdevicesshareacommon
setofwires,theconnectioniscalledabus.Abus,likethePCIbususedinmost
computerstoday,isasetofwiresandarigidlydefinedprotocolthatspecifies
asetofmessagesthatcanbesentonthewires.Intermsoftheelectronics,the
messages are conveyed by patterns of electrical voltagesapplied to the wires
withdefinedtimings.WhendeviceAhasacablethatplugsintodeviceB,and
deviceBhasacablethatplugsintodeviceC,anddeviceCplugsintoaporton
thecomputer,thisarrangementiscalledadaisychain.Adaisychainusually
operatesasabus.
Buses are used widely in computer architecture and vary in their signal-
ing methods, speed, throughput, and connection methods. A typical PC bus
structure appears in Figure 12.1. In the figure, a PCIe bus (the common PC
system bus) connects the processor–memory subsystem to fast devices, and
anexpansionbusconnectsrelativelyslowdevices,suchasthekeyboardand
serial and USB ports. In the lower-left portion of the figure, four disks are
connected together on a serial-attached SCSI (SAS) bus plugged into an SAS
controller. PCIe is a flexible bus that sends data over one or more “lanes.” A
lane is composed of two signaling pairs, one pair for receiving data and the
otherfortransmitting.Eachlaneisthereforecomposedoffourwires,andeach12.2 I/OHardware 491
monitor processor
cache
graphics bridge/memory
memory
controller controller
PCIe bus
expansion bus
SAS controller keyboard
interface
expansion bus
disk disk disk disk
USB USB
port port
Figure12.1 AtypicalPCbusstructure.
laneisusedasafull-duplexbytestream,transportingdatapacketsinaneight-
bit byte format simultaneously in both directions. Physically, PCIe links may
contain1,2,4,8,12,16,or32lanes,assignifiedbyan“x”prefix.APCIecardor
connectorthatuses8lanesisdesignatedx8,forexample.Inaddition,PCIehas
gone through multiple “generations,” with more coming in the future. Thus,
forexample,acardmightbe“ PCIegen3x8”,whichmeansitworkswithgen-
eration3ofPCIeanduses8lanes.Suchadevicehasmaximumthroughputof
8gigabytespersecond.DetailsaboutPCIecanbefoundathttps://pcisig.com.
Acontrollerisacollectionofelectronicsthatcanoperateaport,abus,or
adevice.Aserial-portcontrollerisasimpledevicecontroller.Itisasinglechip
(or portion of a chip) in the computer that controls the signals on the wires
of a serial port. By contrast, a fibr channel (FC) bus controller is not simple.
Because the FC protocol is complex and used in data centers rather than on
PCs, the FC bus controller is often implemented as a separate circuit board
—or a host bus adapter (HBA)—that connects to a bus in the computer. It
typicallycontainsaprocessor,microcode,andsomeprivatememorytoenable
it to process the FC protocol messages. Some devices have their own built-in
controllers. If you look at a disk drive, you will see a circuit board attached
to one side. This board is the disk controller. It implements the disk side of
theprotocolforsomekindsofconnection—SAS andSATA,forinstance.Ithas
microcode and a processor to do many tasks, such as bad-sector mapping,
prefetching,buffering,andcaching.
12.2.1 Memory-Mapped I/O
Howdoestheprocessorgivecommandsanddatatoacontrollertoaccomplish
anI/Otransfer?Theshortansweristhatthecontrollerhasoneormoreregisters
for data and control signals. The processor communicates with the controller
by reading and writing bit patterns in these registers. One way in which
this communication can occur is through the use of special I/O instructions492 Chapter12 I/OSystems
I/O address range (hexadecimal) device
000–00F DMA controller
020–021 interrupt controller
040–043 timer
200–20F game controller
2F8–2FF serial port (secondary)
320–32F hard-disk controller
378–37F parallel port
3D0–3DF graphics controller
3F0–3F7 diskette-drive controller
3F8–3FF serial port (primary)
Figure12.2 DeviceI/OportlocationsonPCs(partial).
that specify the transfer of a byte or a word to an I/O port address. The I/O
instructiontriggersbuslinestoselecttheproperdeviceandtomovebitsintoor
outofadeviceregister.Alternatively,thedevicecansupportmemory-mapped
I/O. In this case, the device-control registers are mapped into the address
spaceoftheprocessor.TheCPUexecutesI/Orequestsusingthestandarddata-
transfer instructions to read and write the device-control registers at their
mappedlocationsinphysicalmemory.
In the past, PCs often used I/O instructions to control some devices and
memory-mapped I/O to control others. Figure 12.2 shows the usual I/O port
addresses for PCs. The graphics controller has I/O ports for basic control
operations, but the controller has a large memory-mapped region to hold
screen contents. A thread sends output to the screen by writing data into
thememory-mappedregion.Thecontrollergeneratesthescreenimagebased
on the contents of this memory. This technique is simple to use. Moreover,
writing millions of bytes to the graphics memory is faster than issuing mil-
lions of I/O instructions. Therefore, over time, systems have moved toward
memory-mappedI/O.Today,mostI/Oisperformedbydevicecontrollersusing
memory-mappedI/O.
I/O device control typically consists of four registers, called the status,
control,data-in,anddata-outregisters.
• Thedata-inregisterisreadbythehosttogetinput.
• Thedata-outregisteriswrittenbythehosttosendoutput.
• The status register contains bits that can be read by the host. These bits
indicate states, such as whether the current command has completed,
whetherabyteisavailabletobereadfromthedata-inregister,andwhether
adeviceerrorhasoccurred.
• The control register can be written by the host to start a command or
to change the mode of a device. For instance, a certain bit in the control
registerofaserialportchoosesbetweenfull-duplexandhalf-duplexcom-12.2 I/OHardware 493
munication, another bitenablesparitychecking, athirdbitsetstheword
lengthto 7or 8bits, and other bits selectone ofthe speedssupportedby
theserialport.
The dataregistersaretypically 1to4bytes insize.Somecontrollers have
FIFO chips that can hold several bytes of input or output data to expand the
capacityofthecontrollerbeyondthesizeofthedataregister.AFIFOchipcan
holdasmallburstofdatauntilthedeviceorhostisabletoreceivethosedata.
12.2.2 Polling
The complete protocol for interaction between the host and a controller can
be intricate, but the basic handshaking notion is simple. We explain hand-
shaking with an example. Assume that 2 bits are used to coordinate the
producer–consumerrelationshipbetweenthecontrollerandthehost.Thecon-
trollerindicatesitsstatethroughthebusybitinthestatusregister.(Recallthat
to set a bit means to write a 1 into the bit and to clear a bit means to write a
0 into it.) The controller sets the busy bit when it is busy working and clears
thebusybitwhenitisreadytoacceptthenextcommand.Thehostsignalsits
wishes via the command-ready bit in the command register. The host sets the
command-readybitwhenacommandisavailableforthecontrollertoexecute.
Forthisexample,thehostwritesoutputthroughaport,coordinatingwiththe
controllerbyhandshakingasfollows.
1. Thehostrepeatedlyreadsthebusybituntilthatbitbecomesclear.
2. Thehostsetsthewritebitinthecommandregisterandwritesabyteinto
thedata-outregister.
3. Thehostsetsthecommand-readybit.
4. Whenthecontrollernoticesthatthecommand-readybitisset,itsetsthe
busybit.
5. Thecontrollerreadsthecommandregisterandseesthewritecommand.
It reads the data-out register to get the byte and does the I/O to the
device.
6. The controller clears the command-ready bit, clears the error bit in the
status register to indicate that the device I/O succeeded, and clears the
busybittoindicatethatitisfinished.
Thisloopisrepeatedforeachbyte.
In step 1, the host is busy-waiting or polling: it is in a loop, reading the
statusregisteroverandoveruntilthebusybitbecomesclear.Ifthecontroller
anddevicearefast,thismethodisareasonableone.Butifthewaitmaybelong,
thehostshouldprobablyswitchtoanothertask.How,then,doesthehostknow
whenthecontrollerhasbecomeidle?Forsomedevices,thehostmustservice
thedevicequickly,ordatawillbelost.Forinstance,whendataarestreaming
in on a serial port or from a keyboard, the small buffer on the controller will
overflowanddatawillbelostifthehostwaitstoolongbeforereturningtoread
thebytes.494 Chapter12 I/OSystems
Inmanycomputerarchitectures,threeCPU-instructioncyclesaresufficient
to poll a device: read a device register, logical-and to extract a status bit,
and branch if not zero. Clearly, the basic polling operation is efficient. But
polling becomes inefficient when it is attemptedrepeatedlyyet rarelyfinds a
devicereadyforservice,whileotherusefulCPUprocessingremainsundone.In
suchinstances,itmaybemoreefficienttoarrangeforthehardwarecontroller
to notify the CPU when the device becomes ready for service, rather than
to require the CPU to poll repeatedly for an I/O completion. The hardware
mechanismthatenablesadevicetonotifytheCPUiscalledaninterrupt.
12.2.3 Interrupts
The basic interrupt mechanism works as follows. The CPU hardware has a
wirecalledtheinterrupt-requestlinethattheCPUsensesafterexecutingevery
instruction. When the CPU detects that a controller has asserted a signal on
the interrupt-request line, the CPU performs a state save and jumps to the
interrupt-handler routine at a fixed address in memory. The interrupt han-
dlerdeterminesthecauseoftheinterrupt,performsthenecessaryprocessing,
performsastaterestore,andexecutesareturn from interruptinstruction
to return the CPU to the execution state prior to the interrupt. We say that
thedevicecontrollerraisesaninterruptbyassertingasignalontheinterrupt
request line, the CPU catches the interrupt and dispatches it to the interrupt
CPU I/O controller
1
device driver initiates I/O
2
initiates I/O
CPU executing checks for
interrupts between instructions
3
CPU receiving interrupt, 4 input ready, output
transfers control to complete, or error
interrupt handler generates interrupt signal
7
5
interrupt handler
processes data,
returns from interrupt
6
CPU resumes
processing of
interrupted task
Figure12.3 Interrupt-drivenI/Ocycle.12.2 I/OHardware 495
Figure12.4 LatencycommandonMacOSX.
handler, and the handler clears the interrupt by servicing the device. Figure
12.3summarizestheinterrupt-drivenI/Ocycle.
We stress interrupt management in this chapter because even single-user
modernsystemsmanagehundredsofinterruptspersecondandservershun-
dreds of thousands per second. For example, Figure 12.4 shows the latency
command output on macOS, revealing that over ten seconds a quiet desktop
computerperformedalmost23,000interrupts.
ThebasicinterruptmechanismjustdescribedenablestheCPUtorespondto
anasynchronousevent,aswhenadevicecontrollerbecomesreadyforservice.
Inamodernoperatingsystem,however,weneedmoresophisticatedinterrupt-
handlingfeatures.
1. Weneedtheabilitytodeferinterrupthandlingduringcriticalprocessing.
2. Weneedanefficientwaytodispatchtotheproperinterrupthandlerfor
adevicewithoutfirst pollingallthe devicestoseewhich oneraisedthe
interrupt.
3. We need multilevel interrupts, so that the operating system can distin-
guish between high- and low-priority interrupts and can respond with
the appropriate degree of urgency when there are multiple concurrent
interrupts.
4. We need a way for an instruction to get the operating system’s atten-
tion directly (separately from I/O requests), for activities such as page
faults and errors such as division by zero. As we shall see, this task is
accomplishedby“traps.”
Inmoderncomputerhardware,thesefeaturesareprovidedbytheCPUandby
theinterrupt-controllerhardware.
Most CPUs have two interrupt request lines. One is the nonmaskable
interrupt,whichisreservedforeventssuchasunrecoverablememoryerrors.
The second interrupt line is maskable: it can be turned off by the CPU before496 Chapter12 I/OSystems
theexecutionofcriticalinstructionsequencesthatmustnotbeinterrupted.The
maskableinterruptisusedbydevicecontrollerstorequestservice.
The interrupt mechanism accepts an address—a number that selects a
specificinterrupt-handlingroutinefromasmallset.Inmostarchitectures,this
addressisanoffsetinatablecalledthe interruptvector.Thisvectorcontains
the memory addresses of specialized interrupt handlers. The purpose of a
vectored interrupt mechanism is to reduce the need for a single interrupt
handler to search all possible sources of interrupts to determine which one
needsservice.Inpractice,however,computershavemoredevices(and,hence,
interrupt handlers) than they have address elements in the interrupt vector.
Acommon way to solve this problem is to use interrupt chaining, in which
each element in the interrupt vector points to the head of a list of interrupt
handlers. When an interrupt is raised, the handlers on the corresponding list
are called one by one, until one is found that can service the request. This
structureisacompromisebetweentheoverheadofahugeinterrupttableand
theinefficiencyofdispatchingtoasingleinterrupthandler.
Figure 12.5 illustrates the design of the interrupt vector for the Intel Pen-
tium processor. The events from 0 to 31, which are nonmaskable, are used
to signal various error conditions (which cause system crashes), page faults
(needingimmediateaction),anddebuggingrequests(stoppingnormalopera-
tionandjumpingtoadebuggerapplication).Theeventsfrom32to255,which
aremaskable,areusedforpurposessuchasdevice-generatedinterrupts.
vector number description
0 divide error
1 debug exception
2 null interrupt
3 breakpoint
4 INTO-detected overflow
5 bound range exception
6 invalid opcode
7 device not available
8 double fault
9 coprocessor segment overrun (reserved)
10 invalid task state segment
11 segment not present
12 stack fault
13 general protection
14 page fault
15 (Intel reserved, do not use)
16 floating-point error
17 alignment check
18 machine check
19–31 (Intel reserved, do not use)
32–255 maskable interrupts
Figure12.5 IntelPentiumprocessorevent-vectortable.12.2 I/OHardware 497
The interrupt mechanism also implements a system of interrupt priority
levels.TheselevelsenabletheCPUtodeferthehandlingoflow-priorityinter-
rupts without masking all interrupts and make it possible for a high-priority
interrupttopreempttheexecutionofalow-priorityinterrupt.
Amodernoperatingsysteminteractswiththeinterruptmechanisminsev-
eral ways. At boot time, the operating system probes the hardware buses to
determine what devices are present and installs the corresponding interrupt
handlers into the interrupt vector. During I/O, the various device controllers
raiseinterruptswhen theyarereadyfor service.Theseinterruptssignifythat
output has completed, or that input data are available, or that a failure has
beendetected.Theinterruptmechanismisalsousedtohandleawidevariety
of exceptions, such as dividing by zero, accessing a protected or nonexis-
tent memory address, or attempting to execute a privileged instruction from
user mode. The events that trigger interrupts have a common property: they
are occurrences that induce the operating system to execute an urgent, self-
containedroutine.
Becauseinterrupthandinginmanycasesistimeandresourceconstrained
and therefore complicated to implement, systems frequently split interrupt
managementbetweenafirst-leve interrupthandler(FLIH)andasecond-level
interrupthandler(SLIH).TheFLIHperformsthecontextswitch,statestorage,
and queuing of a handling operation, while the separately scheduled SLIH
performsthehandlingoftherequestedoperation.
Operatingsystemshaveothergoodusesforinterruptsaswell.Forexam-
ple,manyoperatingsystemsusetheinterruptmechanismforvirtualmemory
paging. A page fault is an exception that raises an interrupt. The interrupt
suspends the current process and jumps to the page-fault handler in the ker-
nel.Thishandlersavesthestateoftheprocess,movestheprocesstothewait
queue,performspage-cachemanagement,schedulesanI/Ooperationtofetch
thepage,schedulesanotherprocesstoresumeexecution,andthenreturnsfrom
theinterrupt.
Anotherexampleisfoundintheimplementationofsystemcalls.Usually,a
programuseslibrarycallstoissuesystemcalls.Thelibraryroutinescheckthe
argumentsgivenbytheapplication,buildadatastructuretoconveytheargu-
ments to the kernel, and then execute a special instruction called a software
interrupt, or trap. This instruction has an operand that identifies the desired
kernelservice.Whenaprocessexecutesthetrapinstruction,theinterrupthard-
waresavesthestateoftheusercode,switchestokernelmode,anddispatches
tothekernelroutineorthreadthatimplementstherequestedservice.Thetrap
is given a relatively low interrupt priority compared with those assigned to
device interrupts—executing a system call on behalf of an application is less
urgentthan servicing adevicecontroller before its FIFO queueoverflows and
losesdata.
Interrupts can also be used to manage the flow of control within the ker-
nel. For example, consider the case of the processing required to complete a
disk read. One step may copy data from kernel space to the user buffer. This
copying is time consuming but not urgent—it should not block other high-
priority interrupt handling. Another step is to start the next pending I/O for
that disk drive. This step has higher priority. If the disks are to be used effi-
ciently, we need to start the next I/O as soon as the previous one completes.
Consequently, a pair of interrupt handlers implements the kernel code that498 Chapter12 I/OSystems
completesadiskread.Thehigh-priorityhandlerrecordstheI/Ostatus,clears
the device interrupt, starts the next pending I/O, and raises a low-priority
interrupttocompletethework.Later,whentheCPUisnotoccupiedwithhigh-
prioritywork,thelow-priorityinterruptwillbedispatched.Thecorresponding
handlercompletestheuser-levelI/Obycopyingdatafromkernelbufferstothe
applicationspaceandthencallingtheschedulertoplacetheapplicationonthe
readyqueue.
Athreadedkernelarchitectureiswellsuitedtoimplementmultipleinter-
ruptprioritiesandtoenforcetheprecedenceofinterrupthandlingoverback-
groundprocessinginkernelandapplicationroutines.Weillustratethispoint
with the Solaris kernel. In Solaris, interrupt handlers are executed as kernel
threads. A range of high scheduling priorities is reserved for these threads.
Theseprioritiesgiveinterrupthandlersprecedenceoverapplicationcodeand
kernel housekeeping and implement the priority relationships among inter-
rupthandlers.TheprioritiescausetheSolaristhreadschedulertopreemptlow-
priority interrupt handlers in favor of higher-priority ones, and the threaded
implementationenablesmultiprocessorhardwaretorunseveralinterrupthan-
dlersconcurrently.WedescribetheinterruptarchitectureofLinuxinChapter
20,Windows10inChapter21,andUNIXinAppendixC.
Insummary,interruptsareusedthroughoutmodernoperatingsystemsto
handle asynchronous events and to trap to supervisor-mode routines in the
kernel. To enable the most urgent work to be done first, modern computers
use a system of interrupt priorities. Device controllers, hardware faults, and
system calls all raise interrupts to trigger kernel routines. Because interrupts
are used so heavily for time-sensitiveprocessing, efficient interrupt handling
is required for good system performance. Interrupt-driven I/O is now much
morecommonthanpolling,withpollingbeingusedforhigh-throughputI/O.
Sometimesthetwoareusedtogether.Somedevicedriversuseinterruptswhen
the I/O rate is low and switch to polling when the rate increases to the point
wherepollingisfasterandmoreefficient.
12.2.4 Direct Memory Access
For a device that does large transfers, such as a disk drive, it seems waste-
ful to use an expensive general-purpose processor to watch status bits and
to feed data into a controller register one byte at a time—a process termed
programmedI/O(PIO).ComputersavoidburdeningthemainCPUwithPIOby
offloading some of this work to a special-purpose processor called a direct-
memory-access (DMA) controller.To initiatea DMAtransfer, the host writesa
DMAcommandblockintomemory.Thisblockcontainsapointertothesource
of a transfer, a pointer to the destination of the transfer, and a count of the
number of bytes to be transferred. A command block can be more complex,
includingalistofsourcesanddestinationsaddressesthatarenotcontiguous.
Thisscatter–gathermethodallowsmultipletransferstobeexecutedviaasin-
gleDMAcommand.TheCPUwritestheaddressofthiscommandblocktothe
DMA controller, then goes on with other work. The DMA controller proceeds
to operate the memory bus directly, placing addresses on the bus to perform
transferswithoutthehelpofthemainCPU.AsimpleDMAcontrollerisastan-
dardcomponentinallmoderncomputers,fromsmartphonestomainframes.12.2 I/OHardware 499
Note that it is most straightforward for the target address to be in kernel
addressspace.Ifitwereinuserspace,theusercould,forexample,modifythe
contents of that space during the transfer, losing some set of data. To get the
DMA-transferred data to the user space for thread access, however, a second
copyoperation,thistimefromkernelmemorytousermemory,isneeded.This
double bufferingis inefficient. Over time, operating systems have moved to
using memory-mapping (see Section 12.2.1) to perform I/O transfers directly
betweendevicesanduseraddressspace.
Handshaking between the DMA controller and the device controller is
performed via a pair of wires called DMA-request and DMA-acknowledge.
ThedevicecontrollerplacesasignalontheDMA-requestwirewhenawordof
dataisavailablefortransfer.ThissignalcausestheDMAcontrollertoseizethe
memorybus,placethedesiredaddressonthememory-addresswire,andplace
asignalontheDMA-acknowledgewire.Whenthedevicecontrollerreceivesthe
DMA-acknowledgesignal,ittransfersthewordofdatatomemoryandremoves
theDMA-requestsignal.
Whentheentiretransferisfinished,theDMAcontrollerinterruptstheCPU.
This process is depicted in Figure 12.6. When the DMA controller seizes the
memory bus, the CPU is momentarily prevented from accessing main mem-
ory, although it can still access data items in its caches. Although this cycle
stealing can slow down the CPU computation, offloading the data-transfer
work to a DMA controller generally improves the total system performance.
Some computer architectures use physical memory addresses for DMA, but
drive 1 drive 2
Figure12.6 StepsinaDMAtransfer.500 Chapter12 I/OSystems
othersperformdirectvirtualmemoryaccess(DVMA),usingvirtualaddresses
that undergo translation to physical addresses. DVMAcan perform a transfer
betweentwomemory-mappeddeviceswithouttheinterventionoftheCPUor
theuseofmainmemory.
Onprotected-modekernels,theoperatingsystemgenerallypreventspro-
cesses from issuing device commands directly. This discipline protects data
fromaccess-controlviolationsandalsoprotectsthesystemfromerroneoususe
of device controllers, which could cause a system crash. Instead, the operat-
ing system exports functions that a sufficiently privileged process can use to
access low-level operations on the underlying hardware. On kernels without
memoryprotection,processescanaccessdevicecontrollersdirectly.Thisdirect
accesscanbeusedtoachievehighperformance,sinceitcanavoidkernelcom-
munication, context switches, and layersof kernelsoftware. Unfortunately,it
interfereswith system security and stability. Common general-purposeoper-
atingsystemsprotectmemoryanddevicessothatthesystemcantrytoguard
againsterroneousormaliciousapplications.
12.2.5 I/O Hardware Summary
Although the hardware aspects of I/O are complex when considered at the
level of detail of electronics-hardware design, the concepts that we have just
describedaresufficienttoenableustounderstandmanyI/Ofeaturesofoper-
atingsystems.Let’sreviewthemainconcepts:
• Abus
• Acontroller
• AnI/Oportanditsregisters
• Thehandshakingrelationshipbetweenthehostandadevicecontroller
• Theexecutionofthishandshakinginapollinglooporviainterrupts
• TheoffloadingofthisworktoaDMAcontrollerforlargetransfers
We gave a basic example of the handshaking that takes place between a
devicecontrollerandthehostearlierinthissection.Inreality,thewidevariety
ofavailabledevicesposesaproblemforoperating-systemimplementers.Each
kind of devicehas its own set of capabilities, control-bit definitions, and pro-
tocols for interacting with the host—and they are all different. How can the
operating system be designed so that we can attach new devices to the com-
puterwithoutrewritingtheoperatingsystem?Andwhenthedevicesvaryso
widely,howcantheoperatingsystemgiveaconvenient,uniformI/Ointerface
toapplications?Weaddressthosequestionsnext.
12.3 Application I/O Interface
In this section, we discuss structuring techniques and interfaces for the oper-
atingsystemthatenableI/Odevicestobetreatedinastandard,uniformway.
Weexplain,forinstance,howanapplicationcanopenafileonadiskwithout12.3 ApplicationI/OInterface 501
kernel
erawtfos
erawdrah
kernel I/O subsystem
SAS keyboard mouse PCIe bus 802.11 USB
device device device (cid:129) (cid:129) (cid:129) device device device
driver driver driver driver driver driver
SAS keyboard mouse PCIe bus 802.11 USB
device device device (cid:129) (cid:129) (cid:129) device device device
controller controller controller controller controller controller
USB
SAS 802.11 devices
devices keyboard mouse (cid:129) (cid:129) (cid:129) PCIe bus devices (disks,
tapes,
drives)
Figure12.7 AkernelI/Ostructure.
knowing what kindofdiskitisandhownewdisksand otherdevicescanbe
addedtoacomputerwithoutdisruptionoftheoperatingsystem.
Like other complex software-engineering problems, the approach here
involvesabstraction,encapsulation,andsoftwarelayering.Specifically,wecan
abstractawaythedetaileddifferencesinI/Odevicesbyidentifyingafewgen-
eral kinds. Each general kind is accessed through a standardized set of func-
tions—aninterface.Thedifferencesareencapsulatedinkernelmodulescalled
device drivers that internally are custom-tailored to specific devices but that
exportoneofthestandardinterfaces.Figure12.7illustrateshowtheI/O-related
portionsofthekernelarestructuredinsoftwarelayers.
The purpose of the device-driver layer is to hide the differences among
devicecontrollersfromtheI/Osubsystemofthe kernel,muchas theI/Osys-
temcallsencapsulatethebehaviorofdevicesinafewgenericclassesthathide
hardware differences from applications. Making the I/O subsystem indepen-
dent of the hardware simplifies the job of the operating-system developer. It
also benefits the hardware manufacturers. They either design new devicesto
becompatiblewithanexistinghostcontrollerinterface(suchasSATA),orthey
write device driversto interface the new hardware to popular operating sys-
tems.Thus,wecanattachnewperipheralstoacomputerwithoutwaitingfor
theoperating-systemvendortodevelopsupportcode.
Unfortunatelyfordevice-hardwaremanufacturers,eachtypeofoperating
system has its own standards for the device-driver interface. Agiven device
may ship with multiple device drivers—for instance, drivers for Windows,
Linux, AIX, and macOS. Devices vary on many dimensions, as illustrated in
Figure12.8.502 Chapter12 I/OSystems
aspect variation example
character terminal
data-transfer mode
block disk
sequential modem
access method
random CD-ROM
synchronous tape
transfer schedule
asynchronous keyboard
dedicated tape
sharing
sharable keyboard
device speed latency
seek time
transfer rate
delay between operations
read only CD-ROM
I/O direction write only graphics controller
read–write disk
Figure12.8 CharacteristicsofI/Odevices.
• Character-streamorblock.Acharacter-streamdevicetransfersbytesone
byone,whereasablockdevicetransfersablockofbytesasaunit.
• Sequentialorrandomaccess.Asequentialdevicetransfersdatainafixed
order determined by the device, whereas the user of a random-access
devicecan instructthedevicetoseektoany of theavailabledatastorage
locations.
• Synchronous or asynchronous. A synchronous device performs data
transfers with predictable response times, in coordination with other
aspects of the system. An asynchronous device exhibits irregular or
unpredictable response times not coordinated with other computer
events.
• Sharable or dedicated. A sharable device can be used concurrently by
severalprocessesorthreads;adedicateddevicecannot.
• Speedofoperation.Devicespeedsrangefromafewbytespersecond to
gigabytespersecond.
• Read–write,readonly,writeonce.Somedevicesperformbothinputand
output, but others support only one data transfer direction. Some allow
data to be modified after write, but others can be written only once and
areread-onlythereafter.
Forthepurposeofapplicationaccess,manyofthesedifferencesarehidden
bytheoperatingsystem,andthedevicesaregroupedintoafewconventional
types. The resulting styles of device access have been found to be useful and
broadlyapplicable.Althoughtheexactsystemcallsmaydifferacrossoperating
systems, the device categories are fairly standard. The major access conven-12.3 ApplicationI/OInterface 503
tionsincludeblockI/O,character-streamI/O,memory-mappedfileaccess,and
networksockets.Operatingsystemsalsoprovidespecialsystemcallstoaccess
afewadditionaldevices,suchasatime-of-dayclockandatimer.Someoper-
ating systems provide a set of system calls for graphical display, video, and
audiodevices.
Mostoperatingsystemsalsohaveanescape(orbackdoor)thattranspar-
ently passes arbitrary commands from an application to a device driver. In
UNIX,thissystemcallisioctl()(for“ I/Ocontrol”).Theioctl()systemcall
enablesanapplicationtoaccessanyfunctionalitythatcanbeimplementedby
anydevicedriver,withouttheneedtoinventanewsystemcall.Theioctl()
system call has three arguments. The first is a device identifier that connects
theapplicationtothedriverbyreferringtoahardwaredevicemanagedbythat
driver.Thesecondisanintegerthatselectsoneofthecommandsimplemented
in the driver. The third is a pointer to an arbitrary data structure in memory
thatenablestheapplicationanddrivertocommunicateanynecessarycontrol
informationordata.
The device identifier in UNIX and Linux is a tuple of “major and minor”
device numbers. The major number is the device type, and the second is the
instanceofthatdevice.Forexample,considertheseSSDdevicesonasystem.If
oneissuesacommand:
% ls -l /dev/sda*
thenthefollowingoutput
brw-rw---- 1 root disk 8, 0 Mar 16 09:18 /dev/sda
brw-rw---- 1 root disk 8, 1 Mar 16 09:18 /dev/sda1
brw-rw---- 1 root disk 8, 2 Mar 16 09:18 /dev/sda2
brw-rw---- 1 root disk 8, 3 Mar 16 09:18 /dev/sda3
shows that 8 is the major device number. The operating system uses that
informationtorouteI/Orequeststotheappropriatedevicedriver.Theminor
numbers0,1,2,and3indicatetheinstanceofthedevice,allowingrequestsfor
I/Otoadeviceentrytoselecttheexactdevicefortherequest.
12.3.1 Block and Character Devices
Theblock-deviceinterfacecapturesalltheaspectsnecessaryforaccessingdisk
drivesandotherblock-orienteddevices.Thedeviceisexpectedtounderstand
commands such as read() and write(). If it is a random-access device, it
is also expected to have a seek() command to specify which block to trans-
fer next. Applications normally access such a device through a file-system
interface.Wecanseethatread(),write(),andseek()capturetheessential
behaviorsofblock-storagedevices,sothatapplicationsareinsulatedfromthe
low-leveldifferencesamongthosedevices.
The operating system itself, as well as special applications such as
database-management systems, may prefer to access a block device as a
simplelineararrayofblocks.ThismodeofaccessissometimescalledrawI/O.
If the application performs its own buffering, then using a file system would
cause extra, unneeded buffering. Likewise, if an application provides its
ownlocking ofblocks or regions,thenany operating-systemlocking services
would be redundant at the least and contradictory at the worst. To avoid504 Chapter12 I/OSystems
these conflicts, raw-device access passes control of the device directly to the
application,lettingtheoperatingsystemstepoutoftheway.Unfortunately,no
operating-system services are then performed on this device. Acompromise
that is becoming common is for the operating system to allow a mode of
operationonafilethatdisablesbufferingandlocking.IntheUNIXworld,this
iscalleddirectI/O.
Memory-mappedfileaccesscanbelayeredontopofblock-devicedrivers.
Rather than offering read and write operations, a memory-mapped interface
provides access to disk storage via an array of bytes in main memory. The
systemcall that maps afile into memoryreturns the virtualmemoryaddress
that contains a copy of the file. The actual data transfers are performed only
when needed to satisfy access to the memory image. Because the transfers
are handled by the same mechanism as that used for demand-paged virtual
memory access, memory-mapped I/O is efficient. Memory mapping is also
convenient for programmers—access to a memory-mapped file is as simple
as reading from and writing to memory. Operating systems that offer virtual
memorycommonlyusethemappinginterfaceforkernelservices.Forinstance,
toexecuteaprogram,theoperatingsystemmapstheexecutableintomemory
andthentransferscontroltotheentryaddressoftheexecutable.Themapping
interfaceisalsocommonlyusedforkernelaccesstoswapspaceondisk.
Akeyboardisanexampleofadevicethatisaccessedthroughacharacter-
streaminterface.Thebasicsystemcallsinthisinterfaceenableanapplication
to get() or put() one character. On top of this interface, libraries can be
built that offer line-at-a-time access, with buffering and editing services (for
example, when a user types a backspace, the preceding character is removed
fromtheinputstream).Thisstyleofaccessisconvenientforinputdevicessuch
askeyboards,mice,andmodemsthatproducedataforinput“spontaneously”
—thatis,attimesthatcannotnecessarilybepredictedbytheapplication.This
accessstyleisalsogoodforoutputdevicessuchasprintersandaudioboards,
whichnaturallyfittheconceptofalinearstreamofbytes.
12.3.2 Network Devices
BecausetheperformanceandaddressingcharacteristicsofnetworkI/Odiffer
significantlyfromthoseofdiskI/O,mostoperatingsystemsprovideanetwork
I/O interface that is different from the read()–write()–seek() interface
used for disks. One interface available in many operating systems, including
UNIXandWindows,isthenetworksocketinterface.
Think of a wall socket for electricity: any electrical appliance can be
plugged in. By analogy, the system calls in the socket interface enable an
application to create a socket, to connect a local socket to a remote address
(whichplugsthisapplicationintoasocketcreatedbyanotherapplication),to
listen for any remote application to plug into the local socket, and to send
and receive packets over the connection. To support the implementation of
networkservers,thesocketinterfacealsoprovidesafunctioncalledselect()
that manages a set of sockets. Acall to select() returns information about
which sockets have a packet waiting to be received and which sockets have
roomtoacceptapackettobesent.Theuseofselect()eliminatesthepolling
and busy waiting that would otherwise be necessary for network I/O. These
functions encapsulate the essential behaviors of networks, greatly facilitating12.3 ApplicationI/OInterface 505
the creation of distributed applications that can use any underlying network
hardwareandprotocolstack.
Manyotherapproachestointerprocesscommunicationandnetworkcom-
munication have been implemented. For instance, Windows provides one
interface to the network interface card and a second interface to the network
protocols.InUNIX,whichhasalonghistoryasaprovinggroundfornetwork
technology,wefindhalf-duplexpipes,full-duplexFIFOs,full-duplexSTREAMS,
message queues, and sockets. Information on UNIX networking is given in
SectionC.9.
12.3.3 Clocks and Timers
Most computers have hardware clocks and timers that provide three basic
functions:
• Givethecurrenttime.
• Givetheelapsedtime.
• SetatimertotriggeroperationXattimeT.
Thesefunctionsareusedheavilybytheoperatingsystem,aswellasbytime-
sensitive applications. Unfortunately, the system calls that implement these
functionsarenotstandardizedacrossoperatingsystems.
Thehardwaretomeasureelapsedtimeandtotriggeroperationsiscalled
aprogrammableintervaltimer.Itcanbesettowaitacertainamountoftime
and then generate an interrupt, and it can be set to do this once or to repeat
theprocesstogenerateperiodicinterrupts.Theschedulerusesthismechanism
to generate an interrupt that will preempt a process at the end of its time
slice. The disk I/O subsystem uses it to invoke the periodic flushing of dirty
cache buffers todisk,and the networksubsystemusesit tocancel operations
thatareproceedingtooslowlybecauseofnetworkcongestionorfailures.The
operatingsystemmayalsoprovideaninterfaceforuserprocessestousetimers.
The operating system can support more timer requests than the number of
timer hardware channels by simulating virtual clocks. To do so, the kernel
(or the timer device driver) maintains a list of interrupts wanted by its own
routinesandbyuserrequests,sortedinearliest-time-firstorder.Itsetsthetimer
fortheearliesttime.Whenthetimerinterrupts,thekernelsignalstherequester
andreloadsthetimerwiththenextearliesttime.
Computers have clock hardware that is used for a variety of purposes.
Modern PCs include a high-performance event timer (HPET), which runs at
rates in the 10-megahertz range. It has several comparators that can be set
to trigger once or repeatedly when the value they hold matches that of the
HPET. The trigger generates an interrupt, and the operating system’s clock
management routines determine what the timer was for and what action to
take.Theprecisionoftriggersislimitedbytheresolutionofthetimer,together
withtheoverheadofmaintainingvirtualclocks.Furthermore,ifthetimerticks
areusedtomaintainthesystemtime-of-dayclock,thesystemclockcandrift.
Driftcanbecorrectedviaprotocolsdesignedforthatpurpose,suchasNTP,the
networktimeprotocol,whichusessophisticatedlatencycalculationstokeep
acomputer’sclockaccuratealmosttoatomic-clocklevels.Inmostcomputers,506 Chapter12 I/OSystems
the hardware clock is constructed from a high-frequency counter. In some
computers,thevalueofthiscountercanbereadfromadeviceregister,inwhich
casethecountercanbeconsideredahigh-resolutionclock.Althoughthisclock
doesnotgenerateinterrupts,itoffersaccuratemeasurementsoftimeintervals.
12.3.4 Nonblocking and Asynchronous I/O
Anotheraspectofthesystem-callinterfacerelatestothechoicebetweenblock-
ing I/O and nonblocking I/O. When an application issues a blocking system
call,theexecutionofthecallingthreadissuspended.Thethreadismovedfrom
the operatingsystem’srunqueuetoawait queue.Afterthesystemcall com-
pletes,thethreadismovedbacktotherunqueue,whereitiseligibletoresume
execution. When it resumes execution, it will receive the values returned by
the system call. The physical actions performed by I/O devices are generally
asynchronous—they take a varying or unpredictable amount of time. Nev-
ertheless,operatingsystemsprovideblockingsystemcallsfortheapplication
interface,becauseblockingapplicationcodeiseasiertowritethannonblocking
applicationcode.
Some user-level processes need nonblocking I/O. One example is a user
interface that receives keyboard and mouse input while processing and dis-
playingdataonthescreen.Anotherexampleisavideoapplicationthatreads
framesfromafileondiskwhilesimultaneouslydecompressinganddisplaying
theoutputonthedisplay.
One way an applicationwriter can overlapexecution with I/O istowrite
amultithreadedapplication.Somethreadscanperformblockingsystemcalls,
whileotherscontinueexecuting.Someoperatingsystemsprovidenonblocking
I/Osystemcalls.Anonblockingcalldoesnothalttheexecutionofthethreadfor
anextendedtime.Instead,itreturnsquickly,withareturnvaluethatindicates
howmanybytesweretransferred.
An alternative to a nonblocking system call is an asynchronous system
call.Anasynchronouscallreturnsimmediately,withoutwaitingfortheI/Oto
complete.Thethreadcontinuestoexecuteitscode.ThecompletionoftheI/O
atsomefuturetimeiscommunicatedtothethread,eitherthroughthesetting
of some variable in the address space of the thread or through the triggering
ofasignalorsoftwareinterruptoracall-backroutinethatisexecutedoutside
thelinearcontrolflowofthethread.Thedifferencebetweennonblockingand
asynchronous systemcallsisthat anonblockingread()returnsimmediately
withwhateverdataareavailable—thefullnumberofbytesrequested,fewer,
or none at all. An asynchronous read() call requests a transfer that will be
performedinitsentiretybutwillcompleteatsomefuturetime.ThesetwoI/O
methodsareshowninFigure12.9.
Asynchronousactivitiesoccurthroughoutmodernoperatingsystems.Fre-
quently,theyarenotexposedtousersorapplicationsbutratherarecontained
withintheoperating-systemoperation.Secondarystoragedeviceandnetwork
I/O are useful examples. By default, when an application issues a network
send request or a storage device write request, the operating system notes
the request, buffers the I/O, and returns to the application. When possible,
to optimize overall system performance, the operating system completes the
request.Ifasystemfailureoccursintheinterim,theapplicationwillloseany
“in-flight” requests. Therefore, operating systems usually put a limit on how12.3 ApplicationI/OInterface 507
Figure12.9 TwoI/Omethods:(a)synchronousand(b)asynchronous.
long they will buffer a request. Some versions of UNIX flush their secondary
storagebuffersevery30seconds,forexample,oreachrequestisflushedwithin
30 seconds of its occurrence. Systems provide a way to allow applications to
requestaflushofsomebuffers(likesecondarystoragebuffers)sothedatacan
be forced to secondary storage without waiting for the buffer flush interval.
Dataconsistencywithinapplicationsismaintainedbythekernel,whichreads
datafromitsbuffersbeforeissuingI/Orequeststodevices,ensuringthatdata
notyetwrittenareneverthelessreturnedtoarequestingreader.Notethatmul-
tiplethreadsperformingI/Otothesamefilemightnotreceiveconsistentdata,
dependingonhowthekernelimplementsitsI/O.Inthissituation,thethreads
may need to use locking protocols. Some I/O requests need to be performed
immediately, so I/O system calls usually have a way to indicate that a given
request,orI/Otoaspecificdevice,shouldbeperformedsynchronously.
Agood exampleofnonblocking behavioristheselect()systemcall for
network sockets. This system call takes an argument that specifies a maxi-
mum waiting time. By setting it to 0, a thread can poll for network activity
without blocking. But using select() introduces extra overhead, because
the select() call only checks whether I/O is possible. For a data transfer,
select() must be followed by some kind of read() or write() command.
Avariationonthisapproach,foundinMach,isablockingmultiple-readcall.
Itspecifiesdesiredreadsforseveraldevicesinonesystemcallandreturnsas
soonasanyoneofthemcompletes.
12.3.5 Vectored I/O
SomeoperatingsystemsprovideanothermajorvariationofI/Oviatheirappli-
cationinterfaces.VectoredI/OallowsonesystemcalltoperformmultipleI/O
operations involving multiple locations. For example, the UNIX readv sys-
tem call accepts a vector of multiple buffers and either reads from a source
to that vector or writes from that vector to a destination. The same transfer508 Chapter12 I/OSystems
could be caused by several individual invocations of system calls, but this
scatter–gathermethodisusefulforavarietyofreasons.
Multipleseparatebuffers can have their contents transferredviaone sys-
tem call, avoiding context-switching and system-call overhead. Without vec-
tored I/O, the data might first need to be transferred to a larger buffer in
the right order and then transmitted, which is inefficient. In addition, some
versionsofscatter–gatherprovideatomicity,assuringthat allthe I/Oisdone
withoutinterruption(andavoidingcorruptionofdataifotherthreadsarealso
performing I/O involving those buffers). When possible, programmers make
useofscatter–gatherI/Ofeaturestoincreasethroughputanddecreasesystem
overhead.
12.4 Kernel I/O Subsystem
Kernels provide many services related to I/O. Several services—scheduling,
buffering,caching,spooling,devicereservation,anderrorhandling—arepro-
vided by the kernel’s I/O subsystem and build on the hardware and device-
driverinfrastructure.TheI/Osubsystemisalsoresponsibleforprotectingitself
fromerrantprocessesandmalicioususers.
12.4.1 I/O Scheduling
ToscheduleasetofI/Orequestsmeanstodetermineagoodorderinwhichto
executethem.Theorderinwhichapplications issuesystemcalls rarelyisthe
best choice. Scheduling can improve overall system performance, can share
deviceaccessfairlyamongprocesses,andcanreducetheaveragewaitingtime
forI/Otocomplete.Hereisasimpleexampletoillustrate.Supposethatadisk
armisnearthebeginningofadiskandthatthreeapplicationsissueblocking
readcallstothatdisk.Application1requestsablockneartheendofthedisk,
application2requestsonenearthebeginning,andapplication3requestsone
inthemiddleofthedisk.Theoperatingsystemcanreducethedistancethatthe
disk arm travels by serving the applications in the order 2, 3, 1. Rearranging
theorderofserviceinthiswayistheessenceofI/Oscheduling.
Operating-system developers implement scheduling by maintaining a
waitqueueofrequestsforeachdevice.Whenanapplicationissuesablocking
I/O system call, the request is placed on the queue for that device. The I/O
schedulerrearrangestheorderofthequeuetoimprovetheoverallsystemeffi-
ciencyandtheaverageresponsetimeexperiencedbyapplications.Theoperat-
ingsystemmayalsotrytobefair,sothatnooneapplicationreceivesespecially
poor service, or it may give priority service for delay-sensitive requests. For
instance,requestsfromthevirtualmemorysubsystemmaytakepriorityover
applicationrequests.SeveralschedulingalgorithmsfordiskI/Oweredetailed
inSection11.2.
When a kernel supports asynchronous I/O, it must be able to keep track
ofmanyI/Orequestsatthesametime.Forthispurpose,theoperatingsystem
mightattachthewaitqueuetoadevice-statustable.Thekernelmanagesthis
table, which contains an entry for each I/O device, as shown in Figure 12.10.
Eachtableentryindicatesthedevice’stype,address,andstate(notfunctioning,12.4 KernelI/OSubsystem 509
device: keyboard
status: idle
request for
device: laser printer
laser printer
status: busy
address: 38546
device: mouse length: 1372
status: idle
device: disk unit 1
status: idle
device: disk unit 2
request for request for
status: busy
. disk unit 2 disk unit 2
.
.
file: xxx file: yyy
operation: read operation: write
address: 43046 address: 03458
length: 20000 length: 500
Figure12.10 Device-statustable.
idle,orbusy).Ifthedeviceisbusywitharequest,thetypeofrequestandother
parameterswillbestoredinthetableentryforthatdevice.
SchedulingI/OoperationsisonewayinwhichtheI/Osubsystemimproves
theefficiencyofthecomputer.Anotherwayisbyusingstoragespaceinmain
memory or elsewhere in the storage hierarchy via buffering, caching, and
spooling.
12.4.2 Buffering
Abuffer,ofcourse,isamemoryareathatstoresdatabeingtransferredbetween
twodevicesorbetweenadeviceandanapplication.Bufferingisdoneforthree
reasons. One reason is to cope with a speed mismatch between the producer
and consumer of a data stream. Suppose, for example, that a file is being
received via Internet for storage on an SSD. The network speed may be a
thousand timesslower thanthe drive.Soabuffer is createdin mainmemory
to accumulate the bytes receivedfrom the network. When an entire buffer of
data has arrived, the buffer can be written to the drive in a single operation.
Sincethedrivewriteisnotinstantaneousandthenetworkinterfacestillneedsa
placetostoreadditionalincomingdata,twobuffersareused.Afterthenetwork
fillsthefirstbuffer,thedrivewriteisrequested.Thenetworkthenstartstofill
the second buffer while the first buffer is written to storage. By the time the
networkhasfilledthesecondbuffer,thedrivewritefromthefirstoneshould
have completed, so the network can switch back to the first buffer while the
drivewritesthesecondone.Thisdoublebufferingdecouplestheproducerof
datafromtheconsumer,thusrelaxingtimingrequirementsbetweenthem.The
needforthisdecouplingisillustratedinFigure12.11,whichliststheenormous
differencesindevicespeedsfortypicalcomputerhardwareandinterfaces.
A second use of buffering is to provide adaptations for devices that
have different data-transfer sizes. Such disparities are especially common in
computer networking, where buffers are used widely for fragmentation and510 Chapter12 I/OSystems
Figure12.11 CommonPCanddata-centerI/Odeviceandinterfacespeeds.
reassembly of messages. At the sending side, a large message is fragmented
into small network packets. The packets are sent over the network, and the
receivingsideplacestheminareassemblybuffertoformanimageofthesource
data.
Athird use of buffering is to support copy semantics for application I/O.
An example will clarify the meaning of “copy semantics.” Suppose that an
application has a buffer of data that it wishes to write to disk. It calls the
write()systemcall,providingapointertothebufferandanintegerspecifying
the number of bytes to write. After the system call returns, what happens
if the application changes the contents of the buffer? With copy semantics,
the version of the data written to disk is guaranteed to be the version at the
time of the application system call, independent of any subsequent changes
in the application’s buffer. Asimple way in which the operating system can
guaranteecopysemanticsisforthewrite()systemcalltocopytheapplication
data into a kernel buffer before returning control to the application. The disk
write is performed from the kernel buffer, so that subsequent changes to the
applicationbufferhavenoeffect.Copyingofdatabetweenkernelbuffersand
applicationdataspaceiscommoninoperatingsystems,despitetheoverhead
thatthisoperationintroduces,becauseofthecleansemantics.Thesameeffect
canbeobtainedmoreefficientlybycleveruseofvirtualmemorymappingand
copy-on-writepageprotection.
12.4.3 Caching
A cache is a region of fast memory that holds copies of data. Access to the
cached copy is more efficient than access to the original. For instance, the
instructions of the currently running process are stored on disk, cached in
physicalmemory,andcopiedagainintheCPU’ssecondaryandprimarycaches.12.4 KernelI/OSubsystem 511
Thedifferencebetweenabufferandacacheisthatabuffermayholdtheonly
existing copy of a data item, whereas a cache, by definition, holds a copy on
fasterstorageofanitemthatresideselsewhere.
Caching and buffering are distinct functions, but sometimes a region of
memorycanbeusedforbothpurposes.Forinstance,topreservecopyseman-
tics and to enable efficient scheduling of disk I/O, the operating system uses
buffers in main memory to hold disk data. These buffers are also used as a
cache,toimprovetheI/Oefficiencyforfilesthataresharedbyapplicationsor
that are being written and reread rapidly. When the kernel receives a file I/O
request, the kernel first accesses the buffer cache to see whether that region
of the file is already available in main memory. If it is, a physical disk I/O
can be avoided or deferred. Also, disk writes are accumulated in the buffer
cacheforseveralseconds,sothatlargetransfersaregatheredtoallowefficient
write schedules. This strategy of delaying writes to improve I/O efficiency is
discussed,inthecontextofremotefileaccess,inSection19.8.
12.4.4 Spooling and Device Reservation
Aspoolisabufferthatholdsoutputforadevice,suchasaprinter,thatcannot
acceptinterleaveddatastreams.Althoughaprintercanserveonlyonejobata
time,severalapplicationsmaywishtoprinttheiroutputconcurrently,without
havingtheiroutputmixedtogether.Theoperatingsystemsolvesthisproblem
by intercepting all output to the printer. Each application’s output is spooled
toaseparatesecondarystoragefile.Whenanapplicationfinishesprinting,the
spoolingsystemqueuesthecorrespondingspoolfileforoutputtotheprinter.
Thespoolingsystemcopiesthequeuedspoolfilestotheprinteroneatatime.In
someoperatingsystems,spoolingismanagedbyasystemdaemonprocess.In
others,itishandledbyanin-kernelthread.Ineithercase,theoperatingsystem
provides a control interface that enables users and system administrators to
display the queue, remove unwanted jobs before those jobs print, suspend
printingwhiletheprinterisserviced,andsoon.
Somedevices,suchastapedrivesandprinters,cannotusefullymultiplex
the I/O requests of multiple concurrent applications. Spooling is one way
operatingsystemscancoordinateconcurrentoutput.Anotherwaytodealwith
concurrentdeviceaccessistoprovideexplicitfacilitiesforcoordination.Some
operatingsystems(includingVMS)providesupportforexclusivedeviceaccess
by enabling a process to allocate an idle device and to deallocate that device
when it is no longer needed. Other operating systems enforce a limit of one
openfile handletosuch adevice.Many operating systemsprovidefunctions
that enable processes to coordinate exclusive access among themselves. For
instance,Windowsprovidessystemcallstowaituntiladeviceobjectbecomes
available.Italsohas aparametertotheOpenFile()systemcallthat declares
the types of access to be permitted to other concurrent threads. On these
systems,itisuptotheapplicationstoavoiddeadlock.
12.4.5 Error Handling
An operating system that uses protected memory can guard against many
kinds of hardware and application errors, so that a complete system failure
isnottheusualresultofeachminormechanicalmalfunction.DevicesandI/O
transferscanfailinmanyways,eitherfortransientreasons,aswhenanetwork512 Chapter12 I/OSystems
becomes overloaded, or for “permanent” reasons, as when a disk controller
becomes defective. Operating systems can often compensate effectively for
transientfailures.Forinstance,adiskread()failureresultsinaread()retry,
andanetworksend()errorresultsinaresend(),iftheprotocolsospecifies.
Unfortunately,ifanimportantcomponentexperiencesapermanentfailure,the
operatingsystemisunlikelytorecover.
As a general rule, an I/O system call will return one bit of information
about the status of the call, signifying either success or failure. In the UNIX
operatingsystem,anadditionalintegervariablenamederrnoisusedtoreturn
anerrorcode—oneofaboutahundredvalues—indicatingthegeneralnature
of the failure (for example, argument out of range, bad pointer, or file not
open). By contrast, some hardware can provide highly detailed error infor-
mation,althoughmanycurrentoperatingsystemsarenotdesignedtoconvey
this information to the application. For instance, a failure of a SCSI device is
reported by the SCSI protocol in three levels of detail: a sense key that iden-
tifies the general nature of the failure, such as a hardware error or an illegal
request;anadditionalsensecodethatstatesthecategoryoffailure,suchasa
bad command parameter or a self-test failure; and an additional sense-code
qualifie thatgivesevenmoredetail,suchaswhichcommandparameterwas
in error or which hardware subsystem failed its self-test. Further, many SCSI
devicesmaintaininternalpagesoferror-loginformationthatcanberequested
bythehost—butseldomare.
12.4.6 I/O Protection
Errors are closely related to the issue of protection. Auser process may acci-
dentallyorpurposelyattempttodisruptthenormaloperationofasystemby
attemptingtoissueillegalI/Oinstructions.Wecanusevariousmechanismsto
ensurethatsuchdisruptionscannottakeplaceinthesystem.
TopreventusersfromperformingillegalI/O,wedefineallI/Oinstructions
tobeprivilegedinstructions.Thus,userscannotissueI/Oinstructionsdirectly;
they must do it through the operating system. To do I/O, a user program
executesasystemcalltorequestthattheoperatingsystemperformI/Oonits
behalf(Figure12.12).Theoperatingsystem,executinginmonitormode,checks
that the request is valid and, if it is, does the I/O requested. The operating
systemthenreturnstotheuser.
In addition, any memory-mapped and I/O port memory locations must
be protected from user access by the memory-protection system. Note that a
kernel cannot simply deny all user access. Most graphics games and video
editingandplaybacksoftwareneeddirectaccesstomemory-mappedgraphics
controllermemorytospeedtheperformanceofthegraphics,forexample.The
kernel might in this case provide a locking mechanism to allow a section of
graphics memory (representing a window on screen) to be allocated to one
processatatime.
12.4.7 Kernel Data Structures
ThekernelneedstokeepstateinformationabouttheuseofI/Ocomponents.It
doessothroughavarietyofin-kerneldatastructures,suchastheopen-filetable12.4 KernelI/OSubsystem 513
Figure12.12 UseofasystemcalltoperformI/O.
structurediscussedinSection14.1.Thekernelusesmanysimilarstructuresto
track network connections, character-device communications, and other I/O
activities.
UNIXprovidesfile-systemaccesstoavarietyofentities,suchasuserfiles,
raw devices, and the address spaces of processes. Although each of these
entities supports a read() operation, the semantics differ. For instance, to
read a user file, the kernel needs to probe the buffer cache before deciding
whethertoperformadiskI/O.Toreadarawdisk,thekernelneedstoensure
that the request size is a multiple of the disk sector size and is aligned on a
sector boundary. To reada process image,it is merelynecessary to copy data
frommemory.UNIXencapsulatesthesedifferenceswithinauniformstructure
by using an object-oriented technique. The open-file record, shown in Figure
12.13,containsadispatchtablethatholdspointerstotheappropriateroutines,
dependingonthetypeoffile.
Some operating systems use object-oriented methods even more exten-
sively.Forinstance,Windowsusesamessage-passingimplementationforI/O.
An I/O request is converted into a message that is sent through the kernel to
theI/Omanagerandthentothedevicedriver,eachofwhichmaychangethe
messagecontents.Foroutput,themessagecontainsthedatatobewritten.For
input,themessagecontainsabuffertoreceivethedata.Themessage-passing
approach can add overhead, by comparison with procedural techniques that
useshareddatastructures,butitsimplifiesthestructureanddesignoftheI/O
systemandaddsflexibility.514 Chapter12 I/OSystems
system-wide open-file table
active-inode
file-system record table
inode pointer
pointer to read and write functions
pointer to select function
per-process
pointer to ioctl function
file descriptor open-file table
pointer to close function
(cid:129)
(cid:129)
network-
(cid:129)
information
networking (socket) record
user-process memory table
pointer to network info
pointer to read and write functions
pointer to select function
pointer to ioctl function
pointer to close function
(cid:129)
(cid:129)
(cid:129)
kernel memory
Figure12.13 UNIXI/Okernelstructure.
12.4.8 Power Management
Computers residing in data centers may seem far removed from issues of
power use, but as power costs increase and the world becomes increasingly
troubled about the long-term effects of greenhouse gas emissions, data cen-
ters have become a cause for concern and a target for increased efficiencies.
Electricityusegeneratesheat,andcomputercomponents canfailduetohigh
temperatures, so cooling is part of the equation as well. Consider that cool-
ing a modern data center may use twice as much electricity as powering the
equipment does. Many approaches to data-center power optimization are in
use,rangingfrominterchangingdata-centerairwithoutsideair,chillingwith
naturalsourcessuchaslakewater,andsolarpanels.
Operating systems play a role in power use (and therefore heat gener-
ation and cooling). In cloud computing environments, processing loads can
be adjusted by monitoring and management tools to evacuate all user pro-
cesses from systems, idling those systems and powering them off until the
loadrequirestheiruse.Anoperatingsystemcouldanalyzeitsloadand,ifsuf-
ficiently low and hardware-enabled, power off components such as CPUsand
externalI/Odevices.
CPUcorescanbesuspendedwhenthesystemloaddoesnotrequirethem
and resumed when the load increases and more cores are needed to run the
queue of threads. Their state, of course, needs to be saved on suspend and
restoredonresume.Thisfeatureisneededinserversbecauseadatacenterfull12.4 KernelI/OSubsystem 515
of servers can use vast amounts of electricity, and disabling unneeded cores
candecreaseelectricity(andcooling)needs.
Inmobilecomputing,powermanagementbecomesahigh-priorityaspect
oftheoperatingsystem.Minimizingpoweruseandthereforemaximizingbat-
terylifeincreasestheusabilityofadeviceandhelpsitcompetewithalternative
devices. Today’s mobile devices offer the functionality of yesterday’s high-
enddesktop,yetarepoweredbybatteriesandaresmallenoughtofitinyour
pocket.Inordertoprovidesatisfactorybatterylife,modernmobileoperating
systems are designed from the ground up with power management as a key
feature. Let’s examine in detail three major features that enable the popular
Androidmobilesystemtomaximizebatterylife:powercollapse,component-
levelpowermanagement,andwakelocks.
Power collapse is the ability to put a device into a very deep sleep state.
Thedeviceusesonlymarginallymorepowerthanifitwerefullypoweredoff,
yet it is still able to respond to external stimuli, such as the user pressing a
button, at which time it quickly powers back on. Power collapse is achieved
bypoweringoffmanyoftheindividualcomponentswithinadevice—suchas
thescreen,speakers,andI/Osubsystem—sothattheyconsumenopower.The
operatingsystemthenplacestheCPUinitslowestsleepstate.AmodernARM
CPU might consume hundreds of milliwatts per core under typical load yet
onlyahandfulofmilliwattsinitslowestsleepstate.Insuchastate,although
the CPU is idle, it can receive an interrupt, wake up, and resume its previous
activity very quickly. Thus, an idle Android phone in your pocket uses very
littlepower,butitcanspringtolifewhenitreceivesaphonecall.
How is Android able to turn off the individual components of a phone?
How does it know when it is safe to power off the flash storage, and how
doesitknowtodothatbeforepoweringdowntheoverallI/Osubsystem?The
answeriscomponent-levelpowermanagement,whichisaninfrastructurethat
understandstherelationshipbetweencomponentsandwhethereachcompo-
nent is in use. To understand the relationship between components, Android
buildsadevicetreethat representsthephone’s physical-devicetopology.For
example,insuchatopology,flashandUSBstoragewouldbesub-nodesofthe
I/Osubsystem,whichisasub-nodeofthesystembus,whichinturnconnects
totheCPU.Tounderstandusage,eachcomponentisassociatedwithitsdevice
driver,and the driver tracks whether the component is in use—for example,
if there is I/O pending to flash or if an application has an open reference to
the audio subsystem. With this information, Android can manage the power
ofthe phone’s individualcomponents: If acomponent is unused, it is turned
off.Ifallofthecomponentson,say,thesystembusareunused,thesystembus
isturnedoff.Andifallofthecomponentsintheentiredevicetreeareunused,
thesystemmayenterpowercollapse.
Withthesetechnologies,Androidcanaggressivelymanageitspowercon-
sumption.Butafinalpieceofthesolutionismissing:theabilityforapplications
to temporarily prevent the system from entering power collapse. Consider a
user playing a game, watching a video, or waiting for a web page to open.
In all of these cases, the application needs a way to keep the device awake,
atleasttemporarily.Wakelocksenablethisfunctionality.Applicationsacquire
andreleasewakelocksasneeded.Whileanapplicationholdsawakelock,the
kernel will prevent the system from entering power collapse. For example,
whiletheAndroidMarketisupdatinganapplication,itwillholdawakelockto516 Chapter12 I/OSystems
ensurethatthesystemdoesnotgotosleepuntiltheupdateiscomplete.Once
complete,theAndroidMarketwillreleasethewakelock,allowingthesystem
toenterpowercollapse.
Power management in general is based on device management, which is
morecomplicatedthanwehavesofarportrayedit.Atboottime,thefirmware
systemanalyzesthesystemhardwareandcreatesadevicetreeinRAM.Theker-
nelthenusesthatdevicetreetoloaddevicedriversandmanagedevices.Many
additional activities pertaining to devices must be managed, though, includ-
ing addition and subtraction of devices from a running system (“hot-plug”),
understandingandchanging devicestates,andpowermanagement.Modern
general-purposecomputers use another set of firmware code,advanced con-
figuratio andpower interface (ACPI), tomanage these aspectsof hardware.
ACPIisanindustrystandard(http://www.acpi.info)withmanyfeatures.Itpro-
videscodethatrunsasroutinescallablebythekernelfordevicestatediscovery
and management, device error management, and power management. For
example,whenthekernelneedstoquiesceadevice,itcallsthedevicedriver,
whichcallstheACPIroutines,whichthentalktothedevice.
12.4.9 Kernel I/O Subsystem Summary
Insummary,theI/Osubsystemcoordinatesanextensivecollectionofservices
that are available to applications and to other parts of the kernel. The I/O
subsystemsupervisestheseprocedures:
• Managementofthenamespaceforfilesanddevices
• Accesscontroltofilesanddevices
• Operationcontrol(forexample,amodemcannotseek())
• File-systemspaceallocation
• Deviceallocation
• Buffering,caching,andspooling
• I/Oscheduling
• Device-statusmonitoring,errorhandling,andfailurerecovery
• Device-driverconfigurationandinitialization
• PowermanagementofI/Odevices
The upper levels of the I/O subsystem access devices via the uniform
interfaceprovidedbythedevicedrivers.
12.5 Transforming I/O Requests to Hardware
Operations
Earlier, we described the handshaking between a device driver and a device
controller,butwedidnotexplainhowtheoperatingsystemconnectsanappli-
cation request to a set of network wires or to a specific disk sector. Consider,12.5 TransformingI/ORequeststoHardwareOperations 517
for example, reading a file from disk. The application refers to the data by a
filename. Within adisk,the filesystemmaps from thefile name throughthe
file-systemdirectoriestoobtainthespaceallocationofthefile.Forinstance,in
MS-DOS for FAT (arelativelysimpleoperatingand file system stillused today
asacommon interchange format), thename maps toanumber that indicates
an entry in the file-access table, and that table entry tells which disk blocks
areallocatedtothefile.InUNIX,thenamemapstoaninodenumber,andthe
correspondinginodecontainsthespace-allocationinformation.Buthowisthe
connectionmadefromthefilename tothediskcontroller(thehardwareport
addressorthememory-mappedcontrollerregisters)?
One method is that used by MS-DOS for FAT, mentioned above. The first
part of an MS-DOS file name, preceding the colon, is a string that identifies a
specific hardware device. For example, C: is the first part of every file name
on the primary hard disk. The fact that C: represents the primary hard disk
is built into the operating system; C: is mapped to a specific port address
throughadevicetable.Becauseofthecolonseparator,thedevicenamespaceis
separatefromthefile-systemnamespace.Thisseparationmakesiteasyforthe
operatingsystemtoassociateextrafunctionalitywitheachdevice.Forinstance,
itiseasytoinvokespoolingonanyfileswrittentotheprinter.
If,instead,thedevicenamespaceisincorporatedintheregularfile-system
namespace,asitisinUNIX,thenormalfile-systemnameservicesareprovided
automatically. If the file system provides ownership and access control to all
filenames,thendeviceshaveownersandaccesscontrol.Sincefilesarestored
on devices, such an interface provides access to the I/O system at two levels.
Namescanbeusedtoaccessthedevicesthemselvesortoaccessthefilesstored
onthedevices.
UNIX represents device names in the regular file-system name space.
UnlikeanMS-DOSFATfilename,whichhasacolonseparator,aUNIXpathname
hasnoclearseparationofthedeviceportion.Infact,nopartofthepathname
isthenameofadevice.UNIXhasamounttablethatassociatesprefixesofpath
nameswithspecificdevicenames.Toresolveapathname,UNIXlooksupthe
nameinthemounttabletofindthelongestmatchingprefix;thecorresponding
entryinthemounttablegivesthedevicename.Thisdevicenamealsohasthe
formofanameinthefile-systemnamespace.WhenUNIXlooksupthisnamein
thefile-systemdirectorystructures,itfindsnotaninodenumberbuta<major,
minor> device number. The major device number identifies a device driver
that should be called to handle I/O to this device. The minor device number
ispassedtothedevicedrivertoindexintoadevicetable.Thecorresponding
device-table entry gives the port address or the memory-mapped address of
thedevicecontroller.
Modern operating systems gain significant flexibility from the multiple
stagesoflookuptablesinthepathbetweenarequestandaphysicaldevicecon-
troller. The mechanisms that pass requests between applications and drivers
are general. Thus, we can introduce new devices and drivers into a com-
puter without recompiling the kernel. In fact, some operating systems have
the ability to load device drivers on demand. At boot time, the system first
probes the hardware buses to determine what devices are present. It then
loads the necessary drivers, either immediately or when first required by an
I/Orequest.Devicesaddedafterboot canbedetectedbytheerrortheycause
(interrupt-generatedwithnoassociatedinterrupthandler,forexample),which518 Chapter12 I/OSystems
can prompt the kernel to inspect the device details and load an appropri-
ate device driver dynamically. Of course, dynamic loading (and unloading)
ismorecomplicatedthanstaticloading,requiringmorecomplexkernelalgo-
rithms,device-structurelocking,errorhandling,andsoforth.
Wenextdescribethetypicallifecycleofablockingreadrequest,asdepicted
inFigure12.14.ThefiguresuggeststhatanI/Ooperationrequiresagreatmany
stepsthattogetherconsumeatremendousnumberofCPUcycles.
1. Aprocessissuesablockingread()systemcalltoafiledescriptorofafile
thathasbeenopenedpreviously.
2. Thesystem-callcodeinthekernelcheckstheparametersforcorrectness.
Inthe caseofinput,ifthedataarealreadyavailableinthe buffercache,
thedataarereturnedtotheprocess,andtheI/Orequestiscompleted.
3. Otherwise, a physical I/O must be performed. The process is removed
fromtherunqueueandisplacedonthewaitqueueforthedevice,andthe
I/Orequestisscheduled.Eventually,theI/Osubsystemsendstherequest
to the device driver. Depending on the operating system, the request is
sentviaasubroutinecalloranin-kernelmessage.
Figure12.14 ThelifecycleofanI/Orequest.12.6 STREAMS 519
4. The device driver allocates kernel buffer space to receive the data and
schedulestheI/O.Eventually,thedriversendscommands tothe device
controllerbywritingintothedevice-controlregisters.
5. The device controller operates the device hardware to perform the data
transfer.
6. The driver may poll for status and data, or it may have set up a DMA
transfer into kernel memory. We assume that the transfer is managed
by a DMA controller, which generates an interrupt when the transfer
completes.
7. The correct interrupt handler receives the interrupt via the interrupt-
vector table, stores any necessary data, signals the device driver, and
returnsfromtheinterrupt.
8. The devicedriverreceivesthe signal, determineswhich I/O requesthas
completed, determines the request’s status, and signals the kernel I/O
subsystemthattherequesthasbeencompleted.
9. The kernel transfers data or return codes to the address space of the
requesting process and moves the process from the wait queue back to
thereadyqueue.
10. Moving the process to the ready queue unblocks the process. When the
schedulerassignstheprocesstothe CPU,theprocessresumesexecution
atthecompletionofthesystemcall.
12.6 STREAMS
UNIXSystemV(andmanysubsequentUNIXreleases)hasaninterestingmech-
anism, called STREAMS, that enables an application to assemble pipelines of
drivercodedynamically.Astreamisafull-duplexconnectionbetweenadevice
driverandauser-levelprocess.Itconsistsofastreamheadthatinterfaceswith
theuserprocess,adriverendthatcontrolsthedevice,andzeroormorestream
modules between the stream head and the driver end. Each of these compo-
nents contains a pair of queues—a read queue and a write queue. Message
passing is used to transfer data between queues. The STREAMS structure is
showninFigure12.15.
ModulesprovidethefunctionalityofSTREAMSprocessing;theyarepushed
onto a stream by use of the ioctl() system call. For example, a process can
open a USB device (like a keyboard) via a stream and can push on a module
to handle input editing. Because messages are exchanged between queues in
adjacentmodules,aqueueinonemodulemayoverflowanadjacentqueue.To
preventthisfromoccurring,aqueuemaysupportflo control.Withoutflow
control, a queue accepts all messages and immediately sends them on to the
queueintheadjacentmodulewithoutbufferingthem.Aqueuethatsupports
flowcontrolbuffersmessagesanddoesnotacceptmessageswithoutsufficient
buffer space. This process involves exchanges of control messages between
queuesinadjacentmodules.520 Chapter12 I/OSystems
user process
stream head
read queue write queue
read queue write queue
STREAMS
modules
read queue write queue
read queue write queue
driver end
device
Figure12.15 TheSTREAMSstructure.
A user process writes data to a device using either the write() or
putmsg()systemcall.Thewrite()systemcallwritesrawdatatothestream,
whereas putmsg() allows the user process to specify a message. Regardless
of the system call used by the user process, the stream head copies the data
into a message and delivers it to the queue for the next module in line. This
copying of messages continues until the message is copied to the driver end
and hence the device. Similarly, the user process reads data from the stream
head using either the read() or getmsg()system call. Ifread() is used,the
streamheadgetsamessagefromitsadjacentqueueandreturnsordinarydata
(an unstructured byte stream) to the process. If getmsg() is used, a message
isreturnedtotheprocess.
STREAMSI/Oisasynchronous(ornonblocking)exceptwhentheuserpro-
cesscommunicateswiththestreamhead.Whenwritingtothestream,theuser
process will block, assuming the next queue uses flow control, until there is
roomtocopythemessage.Likewise,theuserprocesswillblockwhenreading
fromthestreamuntildataareavailable.
As mentioned, the driver end—like the stream head and modules—has
areadandwritequeue.However,thedriverendmustrespondtointerrupts,
suchasonetriggeredwhenaframeisreadytobereadfromanetwork.Unlike
the stream head, which may block if it is unable to copy a message to the
next queue in line, the driver end must handle all incoming data. Drivers
must support flow control as well. However, if a device’s buffer is full, the
device typically resorts to dropping incoming messages. Consider a network
card whose input buffer is full. The network card must simply drop further
messagesuntilthereisenoughbufferspacetostoreincomingmessages.12.7 Performance 521
ThebenefitofusingSTREAMSisthatitprovidesaframeworkforamodular
and incremental approach to writing device drivers and network protocols.
Modules may be used by different streams and hence by different devices.
Forexample,anetworkingmodulemaybeusedbybothanEthernetnetwork
card and a 802.11 wireless network card. Furthermore, rather than treating
character-device I/O as an unstructured byte stream, STREAMS allows sup-
port for message boundaries and control information when communicating
betweenmodules.MostUNIXvariantssupportSTREAMS,anditisthepreferred
methodforwritingprotocolsanddevicedrivers.Forexample,SystemVUNIX
andSolarisimplementthesocketmechanismusingSTREAMS.
12.7 Performance
I/O is a major factor in system performance. It places heavy demands on
the CPU to execute device-driver code and to schedule processes fairly and
efficiently as they block and unblock. The resulting context switches stress
the CPU and its hardware caches. I/O also exposes any inefficiencies in the
interrupt-handlingmechanismsinthekernel.Inaddition,I/Oloadsdownthe
memorybusduringdatacopiesbetweencontrollersandphysicalmemoryand
againduringcopiesbetweenkernelbuffersandapplicationdataspace.Coping
gracefullywithallthesedemandsisoneofthemajorconcerns ofacomputer
architect.
Althoughmoderncomputerscanhandlemanythousandsofinterruptsper
second,interrupthandlingisarelativelyexpensivetask.Eachinterruptcauses
the system to perform a state change, to execute the interrupt handler, and
then to restore state. Programmed I/O can be more efficient than interrupt-
drivenI/O,ifthenumber ofcyclesspentinbusywaiting isnot excessive.An
I/Ocompletiontypicallyunblocks aprocess,leadingtothefulloverheadofa
contextswitch.
Network traffic can also cause a high context-switch rate. Consider, for
instance, a remote login from one machine to another. Each character typed
onthelocalmachinemustbetransportedtotheremotemachine.Onthelocal
machine, the character is typed; a keyboard interrupt is generated; and the
character is passed through the interrupt handler to the device driver, to the
kernel, and then to the user process. The user process issues a network I/O
system call to send the character to the remote machine. The character then
flowsintothelocalkernel,throughthenetworklayersthatconstructanetwork
packet,andintothenetworkdevicedriver.Thenetworkdevicedrivertransfers
thepackettothenetworkcontroller,whichsendsthecharacterandgenerates
an interrupt.The interrupt is passed back up through the kernel to cause the
networkI/Osystemcalltocomplete.
Now, the remote system’s network hardware receives the packet, and an
interrupt is generated. The character is unpacked from the network proto-
cols and is given to the appropriate network daemon. The network daemon
identifieswhichremoteloginsessionisinvolvedandpassesthepackettothe
appropriatesubdaemonfor that session.Throughout thisflow, therearecon-
textswitchesandstateswitches(Figure12.16).Usually,thereceiverechoesthe
characterbacktothesender;thatapproachdoublesthework.522 Chapter12 I/OSystems
Figure12.16 Intercomputercommunications.
Somesystemsuseseparatefront-endprocessorsforterminalI/Otoreduce
the interrupt burden on the main CPU. For instance, a terminal concentrator
canmultiplexthetrafficfromhundredsofremoteterminalsintooneportona
large computer. AnI/O channelis a dedicated,special-purposeCPU found in
mainframes and in other high-end systems.The job of a channel isto offload
I/OworkfromthemainCPU.Theideaisthatthechannelskeepthedataflowing
smoothly,whilethemainCPUremainsfreetoprocessthedata.Likethedevice
controllers and DMA controllers found in smaller computers, a channel can
process more general and sophisticated programs, so channels can be tuned
forparticularworkloads.
WecanemployseveralprinciplestoimprovetheefficiencyofI/O:
• Reducethenumberofcontextswitches.
• Reduce the number of times that data must be copied in memory while
passingbetweendeviceandapplication.
• Reduce the frequency of interrupts by using large transfers, smart con-
trollers,andpolling(ifbusywaitingcanbeminimized).
• Increase concurrency by using DMA-knowledgeable controllers or chan-
nelstooffloadsimpledatacopyingfromtheCPU.
• Move processing primitives into hardware, to allow their operation in
devicecontrollerstobeconcurrentwithCPUandbusoperation.
• Balance CPU, memory subsystem, bus, and I/O performance, because an
overloadinanyoneareawillcauseidlenessinothers.
I/Odevicesvarygreatlyincomplexity.Forinstance,amouseissimple.The
mousemovementsandbuttonclicksareconvertedintonumericvaluesthatare
passed from hardware, through the mouse device driver, to the application.
By contrast, the functionality providedby the Windows disk devicedriver is
complex.ItnotonlymanagesindividualdisksbutalsoimplementsRAIDarrays12.7 Performance 523
(Section11.8).Todoso,itconvertsanapplication’sreadorwriterequestintoa
coordinatedsetofdiskI/Ooperations.Moreover,itimplementssophisticated
error-handlinganddata-recoveryalgorithmsandtakesmanystepstooptimize
diskperformance.
WhereshouldtheI/Ofunctionalitybeimplemented—inthedevicehard-
ware,in thedevicedriver,or inapplicationsoftware? Sometimeswe observe
theprogressiondepictedinFigure12.17.
• Initially, we implement experimental I/O algorithms at the application
level,becauseapplicationcodeisflexibleandapplicationbugsareunlikely
tocausesystemcrashes.Furthermore,bydevelopingcodeattheapplica-
tionlevel,weavoidtheneedtorebootorreloaddevicedriversafterevery
changetothecode.Anapplication-levelimplementationcanbeinefficient,
however, because of the overhead of context switches and because the
application cannot take advantage of internal kernel data structures and
kernelfunctionality(suchasefficientin-kernelmessaging,threading,and
locking).TheFUSEsysteminterface,forexample,allowsfilesystemstobe
writtenandruninusermode.
• Whenanapplication-levelalgorithmhasdemonstrateditsworth,wemay
reimplementitinthekernel.Thiscanimproveperformance,butthedevel-
opment effort is more challenging, because an operating-system kernel
is alarge, complexsoftware system. Moreover,an in-kernelimplementa-
tion must be thoroughly debugged to avoid data corruption and system
crashes.
• The highest performance may be obtained through a specialized imple-
mentationinhardware,eitherinthedeviceorinthecontroller.Thedisad-
vantagesofahardwareimplementationincludethedifficultyandexpense
of making further improvements or of fixing bugs, the increased devel-
new algorithm
application code
kernel code
device-driver code
device-controller code (hardware)
device code (hardware)
)snoitareneg(
emit
desaercni
ycneiciffe
desaercni
tsoc
tnempoleved
desaercni
noitcartsba
desaercni
ytilibixelf
desaercni
Figure12.17 Devicefunctionalityprogression.524 Chapter12 I/OSystems
Figure12.18 I/Operformanceofstorage(andnetworklatency).
opmenttime(monthsratherthandays),andthedecreasedflexibility.For
instance, a hardware RAID controller may not provide any means for the
kernel to influence the order or location of individual block reads and
writes,evenifthekernelhasspecialinformationabouttheworkloadthat
wouldenableittoimprovetheI/Operformance.
Over time, as with other aspects of computing, I/O devices have been
increasing in speed. Nonvolatile memory devices are growing in popularity
andinthevarietyofdevicesavailable.ThespeedofNVMdevicesvariesfrom
hightoextraordinary,withnext-generationdevicesnearingthespeedofDRAM.
These developments are increasing pressure on I/O subsystems as well as
operatingsystemalgorithmstotakeadvantageoftheread/writespeedsnow
available. Figure 12.18 shows CPU and storage devices in two dimensions:
capacityandlatencyofI/Ooperations.Addedtothefigureisarepresentation
ofnetworkinglatencytorevealtheperformance“tax”networkingaddstoI/O.
12.8 Summary
• ThebasichardwareelementsinvolvedinI/Oarebuses,devicecontrollers,
andthedevicesthemselves.
• Theworkofmovingdatabetweendevicesandmainmemoryisperformed
bytheCPUasprogrammedI/OorisoffloadedtoaDMAcontroller.
• The kernel module that controls a device is a device driver. The system-
callinterfaceprovidedtoapplicationsisdesignedtohandleseveralbasic
categoriesofhardware,includingblockdevices,character-streamdevices,
memory-mappedfiles,networksockets,andprogrammedintervaltimers.
Thesystemcallsusuallyblocktheprocessesthatissuethem,butnonblock-
ingandasynchronouscallsareusedbythekernelitselfandbyapplications
thatmustnotsleepwhilewaitingforanI/Ooperationtocomplete.PracticeExercises 525
• Thekernel’sI/Osubsystemprovidesnumerousservices.Amongtheseare
I/Oscheduling,buffering,caching,spooling,devicereservation,errorhan-
dling.Anotherservice,nametranslation,makestheconnectionsbetween
hardware devices and the symbolic file names used by applications. It
involves several levels of mapping that translate from character-string
names,tospecificdevicedriversanddeviceaddresses,andthentophys-
ical addresses of I/O ports or bus controllers. This mapping may occur
withinthefile-systemnamespace,asitdoesinUNIX,orinaseparatedevice
namespace,asitdoesinMS-DOS.
• STREAMS is an implementation and methodology that provides a frame-
work for a modular and incremental approach to writing device drivers
and network protocols. Through STREAMS, drivers can be stacked, with
datapassingthroughthemsequentiallyandbidirectionallyforprocessing.
• I/O system calls are costly in terms of CPU consumption because of the
many layers of software between a physical device and an application.
These layers imply overhead from several sources: context switching to
cross the kernel’s protection boundary, signal and interrupt handling to
service the I/O devices, and the load on the CPU and memory system to
copydatabetweenkernelbuffersandapplicationspace.
Practice Exercises
12.1 State three advantages of placing functionality in a device controller,
ratherthaninthekernel.Statethreedisadvantages.
12.2 The example of handshaking in Section 12.2 used two bits: a busy bit
andacommand-readybit.Isitpossibletoimplementthishandshaking
withonlyonebit?Ifitis,describetheprotocol.Ifitisnot,explainwhy
onebitisinsufficient.
12.3 Whymightasystemuseinterrupt-drivenI/Otomanageasingleserial
portandpollingI/Otomanageafront-endprocessor,suchasaterminal
concentrator?
12.4 Polling foranI/Ocompletioncanwastealargenumberof CPUcycles
iftheprocessoriteratesabusy-waitingloopmanytimesbeforetheI/O
completes.ButiftheI/Odeviceisreadyforservice,pollingcanbemuch
more efficient than catching and dispatching an interrupt. Describe a
hybridstrategythatcombinespolling,sleeping,andinterruptsforI/O
device service. For each of these three strategies (pure polling, pure
interrupts, hybrid), describe a computing environment in which that
strategyismoreefficientthaneitheroftheothers.
12.5 HowdoesDMAincreasesystemconcurrency?Howdoesitcomplicate
hardwaredesign?
12.6 Why is it important to scale up system-bus and devicespeedsas CPU
speedincreases?
12.7 Distinguish between a driverend and a stream module in a STREAMS
operation.526 Chapter12 I/OSystems
Further Reading
[Hennessy and Patterson (2012)] describe multiprocessor systems and cache-
consistencyissues.[Intel(2011)]isagoodsourceofinformationforIntelpro-
cessors.
DetailsaboutPCIecanbefoundathttps://pcisig.com.FormoreaboutACPI
seehttp://www.acpi.info.
The use of FUSE for user-mode file systems can create performance prob-
lems. An analysis of those issues can be found in https://www.usenix.org
/conference/fast17/technical-sessions/presentation/vangoor.
Bibliography
[HennessyandPatterson(2012)] J.HennessyandD.Patterson,ComputerArchi-
tecture:AQuantitativeApproach,FifthEdition,MorganKaufmann(2012).
[Intel(2011)] Intel 64 and IA-32 Architectures Software Developer’s Manual, Com-
binedVolumes:1,2A,2B,3Aand3B. IntelCorporation(2011).Exercises EX-46
Chapter 12 Exercises
12.8 When multiple interrupts from different devices appear at about the
same time, a priority scheme could be used to determinethe order in
whichtheinterruptswouldbeserviced.Discusswhatissuesneedtobe
consideredinassigningprioritiestodifferentinterrupts.
12.9 What are the advantages and disadvantages of supporting memory-
mappedI/Otodevice-controlregisters?
12.10 ConsiderthefollowingI/Oscenariosonasingle-userPC:
a. Amouseusedwithagraphicaluserinterface
b. Atapedriveonamultitaskingoperatingsystem(withnodevice
preallocationavailable)
c. Adiskdrivecontaininguserfiles
d. A graphics card with direct bus connection, accessible through
memory-mappedI/O
For each of these scenarios, would you design the operating system
to use buffering, spooling, caching, or acombination? Would you use
polledI/Oorinterrupt-drivenI/O?Givereasonsforyourchoices.
12.11 In most multiprogrammed systems, user programs access memory
throughvirtualaddresses,whiletheoperatingsystemusesrawphysi-
caladdressestoaccessmemory.Whataretheimplicationsofthisdesign
for theinitiationof I/Ooperationsby theuserprogramandtheirexe-
cutionbytheoperatingsystem?
12.12 What are the various kinds of performance overhead associated with
servicinganinterrupt?
12.13 Describe three circumstances under which blocking I/O should be
used. Describe three circumstances under which nonblocking I/O
should be used. Why not just implement nonblocking I/O and have
processesbusy-waituntiltheirdevicesareready?
12.14 Typically,atthecompletionofadeviceI/O,asingleinterruptisraised
and appropriately handled by the host processor. In certain settings,
however, the code that is to be executed at the completion of the I/O
canbebrokenintotwoseparatepieces.Thefirstpieceexecutesimme-
diately after the I/O completes and schedules a second interrupt for
theremainingpieceofcodetobeexecutedatalatertime.Whatisthe
purposeofusingthisstrategyinthedesignofinterrupthandlers?
12.15 Some DMA controllers support direct virtual memory access, where
the targets of I/O operations are specified as virtual addresses and
a translation from virtual to physical address is performed during
the DMA. How does this design complicate the design of the DMA
controller?Whataretheadvantagesofprovidingsuchfunctionality?
12.16 UNIXcoordinatestheactivitiesofthekernelI/Ocomponentsbymanip-
ulatingsharedin-kerneldatastructures,whereasWindowsusesobject-EX-47
oriented message passing between kernel I/O components. Discuss
threeprosandthreeconsofeachapproach.
12.17 Write (in pseudocode) an implementation of virtual clocks, including
the queueing and management of timer requests for the kernel and
applications.Assumethatthehardwareprovidesthreetimerchannels.
12.18 Discuss the advantages and disadvantages of guaranteeing reliable
transferofdatabetweenmodulesintheSTREAMSabstraction.Part Six
File System
A file is a collection of related information definedby its creator. Files are
mappedbytheoperatingsystemontophysicalmass-storagedevices.A
filesystemdescribeshowfilesaremappedontophysicaldevices,aswell
ashowtheyareaccessedandmanipulatedbybothusersandprograms.
Accessing physical storage can often be slow, so file systems must
be designed for efficient access. Other requirements may be important
aswell,includingprovidingsupportforfilesharingandremoteaccessto
files.13
CHAPTER
File -System
Interface
Formostusers,thefilesystemisthemostvisibleaspectofageneral-purpose
operatingsystem.Itprovidesthemechanismforon-linestorageofandaccess
to both data and programs of the operating system and all the users of the
computersystem.Thefilesystemconsistsoftwodistinctparts:acollectionof
files,eachstoringrelateddata,andadirectorystructure,whichorganizesand
providesinformationaboutallthefilesinthesystem.Mostfilesystemsliveon
storagedevices,whichwedescribedinChapter11andwillcontinuetodiscuss
inthenextchapter.Inthischapter,weconsiderthevariousaspectsoffilesand
the major directory structures. We also discuss the semantics of sharing files
among multipleprocesses,users,and computers.Finally,wediscuss ways to
handle file protection, necessary when we have multiple users and want to
controlwhomayaccessfilesandhowfilesmaybeaccessed.
CHAPTER OBJECTIVES
• Explainthefunctionoffilesystems.
• Describetheinterfacestofilesystems.
• Discussfile-systemdesigntradeoffs,includingaccessmethods,fileshar-
ing,filelocking,anddirectorystructures.
• Explorefile-systemprotection.
13.1 File Concept
Computers can store information on various storage media, such as NVM
devices,HDDs,magnetictapes,andopticaldisks.Sothatthecomputersystem
will be convenient to use, the operating system provides a uniform logical
viewofstoredinformation.Theoperatingsystemabstracts fromthephysical
propertiesofitsstoragedevicestodefinealogicalstorageunit,thefil .Filesare
mappedbytheoperatingsystemontophysicaldevices.Thesestoragedevices
areusuallynonvolatile,sothecontentsarepersistentbetweensystemreboots.
529530 Chapter13 File-SystemInterface
Afileisanamedcollectionofrelatedinformationthatisrecordedonsec-
ondary storage. From a user’s perspective, a file is the smallest allotment of
logicalsecondarystorage;thatis,datacannotbewrittentosecondarystorage
unlesstheyarewithinafile.Commonly,filesrepresentprograms(bothsource
and object forms) and data. Data files may be numeric, alphabetic, alphanu-
meric,orbinary.Filesmaybefreeform,suchastextfiles,ormaybeformatted
rigidly.Ingeneral,afileisasequenceofbits,bytes,lines,orrecords,themean-
ing of which is defined by the file’s creator and user. The concept of a file is
thusextremelygeneral.
Because files are the method users and applications use to store and
retrievedata,andbecausetheyaresogeneralpurpose,theirusehasstretched
beyonditsoriginalconfines.Forexample,UNIX,Linux,andsomeotheroper-
ating systems provide a proc file system that uses file-system interfaces to
provideaccesstosysteminformation(suchasprocessdetails).
The information in afile is definedby its creator.Many differenttypesof
informationmaybestoredinafile—sourceorexecutableprograms,numeric
ortextdata,photos,music,video,andsoon.Afilehasacertaindefinedstruc-
ture,whichdependsonitstype.Atextfil isasequenceofcharactersorganized
intolines(andpossiblypages).Asourcefil isasequenceoffunctions,eachof
whichisfurtherorganizedasdeclarationsfollowedbyexecutablestatements.
An executable fil is a series of code sections that the loader can bring into
memoryandexecute.
13.1.1 File Attributes
Afile is named, for the convenience of its human users, and is referredto by
its name. Aname is usually a string of characters, such as example.c. Some
systems differentiate between uppercase and lowercase characters in names,
whereasothersystemsdonot.Whenafileisnamed,itbecomesindependent
oftheprocess,theuser,andeventhesystemthat createdit.Forinstance,one
user might create the file example.c, and another user might edit that file
by specifying its name. The file’s owner might write the file to a USB drive,
senditas an e-mailattachment, or copy itacross anetwork, and itcould still
be calledexample.conthe destinationsystem.Unlessthereis asharing and
synchonizationmethod,thatsecondcopyisnowindependentofthefirstand
canbechangedseparately.
Afile’sattributesvaryfromoneoperatingsystemtoanotherbuttypically
consistofthese:
• Name. The symbolic file name is the only information kept in human-
readableform.
• Identifie.Thisuniquetag,usuallyanumber,identifiesthefilewithinthe
filesystem;itisthenon-human-readablenameforthefile.
• Type.Thisinformationisneededforsystemsthatsupportdifferenttypes
offiles.
• Location. This information is a pointer to a device and to the location of
thefileonthatdevice.13.1 FileConcept 531
• Size. Thecurrent sizeof thefile (inbytes,words,or blocks) and possibly
themaximumallowedsizeareincludedinthisattribute.
• Protection. Access-control information determines who can do reading,
writing,executing,andsoon.
• Timestamps and user identificatio . This information may be kept for
creation,lastmodification,andlastuse.Thesedatacanbeusefulforpro-
tection,security,andusagemonitoring.
Somenewerfilesystemsalsosupportextendedfileattributes,includingchar-
acterencodingofthefileandsecurityfeaturessuchasafilechecksum.Figure
13.1illustratesafil infowindowonmacOSthatdisplaysafile’sattributes.
The information about all files is kept in the directory structure, which
residesonthesamedeviceasthefilesthemselves.Typically,adirectoryentry
consists of the file’s name and its unique identifier. The identifier in turn
locates the other file attributes. It may take more than a kilobyte to record
this information for each file. In a system with many files, the size of the
directoryitselfmaybemegabytesorgigabytes.Becausedirectoriesmustmatch
the volatility of the files, like files, they must be stored on the device and are
usuallybroughtintomemorypiecemeal,asneeded.
Figure13.1 AfileinfowindowonmacOS.532 Chapter13 File-SystemInterface
13.1.2 File Operations
Afileisanabstractdatatype.Todefineafileproperly,weneedtoconsiderthe
operations that can be performed on files. The operating system can provide
system calls to create, write, read, reposition, delete, and truncate files. Let’s
examine what the operating system must do to perform each of these seven
basicfileoperations.Itshouldthenbeeasytoseehowothersimilaroperations,
suchasrenamingafile,canbeimplemented.
• Creatingafil .Twostepsarenecessarytocreateafile.First,spaceinthe
filesystemmustbefoundforthefile.Wediscusshowtoallocatespacefor
thefileinChapter14.Second,anentryforthenewfilemustbemadeina
directory.
• Opening a fil . Rather than have all file operations specify a file name,
causing the operating system to evaluate the name, check access permis-
sions, and so on, all operations except create and delete require a file
open()first.Ifsuccessful,theopencallreturnsafilehandlethatisusedas
anargumentintheothercalls.
• Writing a fil . To write a file, we make a system call specifying both the
openfilehandleandtheinformationtobewrittentothefile.Thesystem
must keep a write pointer tothe location in the file where the next write
is to take place if it is sequential. The write pointer must be updated
wheneverawriteoccurs.
• Readingafil . Toreadfrom afile, we useasystemcall that specifiesthe
file handle and where (in memory) the next block of the file should be
put. Again, the system needs to keep a read pointer to the location in
the file where the next read is to take place, if sequential. Once the read
hastakenplace,thereadpointerisupdated.Becauseaprocessisusually
eitherreadingfromorwritingtoafile,thecurrentoperationlocationcan
be kept as a per-process current-file-positio pointer. Both the read and
writeoperationsusethissamepointer,savingspaceandreducingsystem
complexity.
• Repositioningwithinafile.Thecurrent-file-positionpointeroftheopen
file is repositioned to a given value. Repositioning within a file need not
involveanyactualI/O.Thisfileoperationisalsoknownasafileseek.
• Deletingafil .Todeleteafile,wesearchthedirectoryforthenamedfile.
Having found the associated directory entry, we release all file space, so
thatitcanbereusedbyotherfiles,anderaseormarkasfreethedirectory
entry.Notethat some systemsallowhardlinks—multiple names (direc-
tory entries) for the same file. In this case the actual file contents is not
deleteduntilthelastlinkisdeleted.
• Truncating a fil . The user may want to erase the contents of a file but
keepitsattributes.Ratherthanforcingtheusertodeletethefileandthen
recreateit,thisfunctionallowsallattributestoremainunchanged—except
for file length. The file can then be reset to length zero, and its file space
canbereleased.13.1 FileConcept 533
These seven basic operations comprise the minimal set of required file
operations. Other common operations include appending new information
to the end of an existing file and renaming an existing file. These primitive
operationscanthenbecombinedtoperformotherfileoperations.Forinstance,
wecancreateacopyofafilebycreatinganewfileandthenreadingfromthe
oldandwritingtothenew.Wealsowanttohaveoperationsthatallowauser
togetandsetthevariousattributesofafile.Forexample,wemaywanttohave
operationsthatallowausertodeterminethestatusofafile,suchasthefile’s
length,andtosetfileattributes,suchasthefile’sowner.
Asmentioned,mostofthefileoperationsmentionedinvolvesearchingthe
directory for the entry associated with the named file. To avoid this constant
searching,manysystemsrequirethatanopen()systemcallbemadebeforea
fileisfirstused.Theoperatingsystemkeepsatable,calledtheopen-fil table,
containinginformationaboutallopenfiles.Whenafileoperationisrequested,
the file is specified via an index into this table, so no searching is required.
Whenthefileisnolongerbeingactivelyused,itisclosedbytheprocess,and
the operating system removes its entry from the open-file table, potentially
releasinglocks.create()anddelete()aresystemcallsthatworkwithclosed
ratherthanopenfiles.
Somesystemsimplicitlyopenafilewhen thefirst referencetoitismade.
The file is automatically closed when the job or program that opened the
file terminates. Most systems, however, require that the programmer open a
file explicitly with the open() system call before that file can be used. The
open() operation takes a file name and searches the directory, copying the
directoryentryintotheopen-filetable.Theopen()callcanalsoacceptaccess-
mode information—create, read-only, read–write, append-only, and so on.
This mode is checked against the file’s permissions. If the request mode is
allowed, the file is opened for the process. The open() system call typically
returnsapointertotheentryintheopen-filetable.Thispointer,nottheactual
file name, is used in all I/O operations, avoiding any further searching and
simplifyingthesystem-callinterface.
The implementationofthe open()andclose()operationsismorecom-
plicatedinanenvironmentwhereseveralprocessesmayopenthefilesimulta-
neously.Thismayoccurinasystemwhereseveraldifferentapplicationsopen
thesamefileatthesametime.Typically,theoperatingsystemusestwolevels
ofinternaltables:aper-processtableandasystem-widetable.Theper-process
tabletracksallfilesthataprocesshasopen.Storedinthistableisinformation
regardingtheprocess’suseofthefile.Forinstance,thecurrentfilepointerfor
eachfileisfoundhere.Accessrightstothefileandaccountinginformationcan
alsobeincluded.
Eachentryintheper-processtableinturnpointstoasystem-wideopen-file
table.Thesystem-widetablecontainsprocess-independentinformation,such
asthelocationofthefileondisk,accessdates,andfilesize.Onceafilehasbeen
opened by one process, the system-wide table includes an entry for the file.
When another process executes an open() call, a new entry is simply added
totheprocess’sopen-filetablepointingtotheappropriateentryinthesystem-
widetable.Typically,theopen-filetablealsohasanopencountassociatedwith
each file to indicate how many processes have the file open. Each close()
decreasesthisopencount,andwhentheopencountreacheszero,thefileisno
longerinuse,andthefile’sentryisremovedfromtheopen-filetable.534 Chapter13 File-SystemInterface
FILELOCKINGINJAVA
In the Java API, acquiring a lock requires first obtaining the FileChannel
forthefiletobelocked.Thelock()methodoftheFileChannelisusedto
acquirethelock.TheAPIofthelock()methodis
FileLock lock(long begin, long end, boolean shared)
wherebeginandendarethebeginningandendingpositionsoftheregion
being locked. Setting shared to true is for shared locks; setting shared
tofalseacquiresthelockexclusively.Thelockisreleasedbyinvokingthe
release()oftheFileLockreturnedbythelock()operation.
The program in Figure 13.2 illustrates file locking in Java. This program
acquirestwolocksonthefilefile.txt.Thelockforthefirsthalfofthefile
isanexclusivelock;thelockforthesecondhalfisasharedlock.
Insummary,severalpiecesofinformationareassociatedwithanopenfile.
• File pointer. On systems that do not include a file offset as part of the
read() and write() system calls, the system must track the last read–
write location as a current-file-position pointer. This pointer is unique to
eachprocessoperatingonthefileandthereforemustbekeptseparatefrom
theon-diskfileattributes.
• File-open count. As files are closed, the operating system must reuse its
open-file table entries, or it could run out of space in the table. Multiple
processes may have opened a file, and the system must wait for the last
filetoclosebeforeremovingtheopen-filetableentry.Thefile-opencount
tracks the number ofopens and closesand reaches zeroon the lastclose.
Thesystemcanthenremovetheentry.
• Locationofthefil .Mostfileoperationsrequirethesystemtoreadorwrite
datawithinthefile.Theinformationneededtolocatethefile(whereverit
islocated,beitonmassstorage,onafileserveracrossthenetwork,oron
aRAMdrive)iskeptinmemorysothatthesystemdoesnothavetoreadit
fromthedirectorystructureforeachoperation.
• Accessrights.Eachprocessopensafileinanaccessmode.Thisinforma-
tionisstoredontheper-processtablesotheoperatingsystemcanallowor
denysubsequentI/Orequests.
Someoperatingsystemsprovidefacilitiesforlockinganopenfile(orsec-
tions of a file). File locks allow one process to lock a file and prevent other
processesfromgainingaccesstoit.Filelocksareusefulforfilesthatareshared
byseveralprocesses—forexample,asystemlogfilethatcanbeaccessedand
modifiedbyanumberofprocessesinthesystem.
Filelocksprovidefunctionalitysimilartoreader–writerlocks,coveredin
Section7.1.2.Asharedlockisakintoareaderlockinthatseveralprocessescan
acquirethelockconcurrently.Anexclusivelockbehaveslikeawriterlock;only
one process at a time can acquire such a lock. It is important to note that not13.1 FileConcept 535
import java.io.*;
import java.nio.channels.*;
public class LockingExample {
public static final boolean EXCLUSIVE = false;
public static final boolean SHARED = true;
public static void main(String args[]) throws IOException {
FileLock sharedLock = null;
FileLock exclusiveLock = null;
try {
RandomAccessFile raf = new RandomAccessFile("file.txt","rw");
// get the channel for the file
FileChannel ch = raf.getChannel();
// this locks the first half of the file - exclusive
exclusiveLock = ch.lock(0, raf.length()/2, EXCLUSIVE);
/** Now modify the data . . . */
// release the lock
exclusiveLock.release();
// this locks the second half of the file - shared
sharedLock = ch.lock(raf.length()/2+1,raf.length(),SHARED);
/** Now read the data . . . */
// release the lock
sharedLock.release();
} catch (java.io.IOException ioe) {
System.err.println(ioe);
}
finally {
if (exclusiveLock != null)
exclusiveLock.release();
if (sharedLock != null)
sharedLock.release();
}
}
}
Figure13.2 File-lockingexampleinJava.
alloperatingsystemsprovidebothtypesoflocks:somesystemsprovideonly
exclusivefilelocking.
Furthermore, operating systems may provide either mandatory or advi-
soryfile-lockingmechanisms.Withmandatorylocking,onceaprocessacquires
an exclusive lock, the operating system will prevent any other process from536 Chapter13 File-SystemInterface
accessingthelockedfile.Forexample,assumeaprocessacquiresanexclusive
lockonthefilesystem.log.Ifweattempttoopensystem.logfromanother
process—forexample,atexteditor—theoperatingsystemwillpreventaccess
untiltheexclusivelockisreleased.Alternatively,ifthelockisadvisory,thenthe
operatingsystemwillnotpreventthetexteditorfromacquiringaccesstosys-
tem.log.Rather,thetexteditormustbewrittensothatitmanuallyacquiresthe
lockbeforeaccessingthefile.Inotherwords,ifthelockingschemeismanda-
tory, the operating system ensures locking integrity. For advisory locking, it
is up to software developers to ensure that locks are appropriately acquired
andreleased.Asageneralrule,Windowsoperatingsystemsadoptmandatory
locking,andUNIXsystemsemployadvisorylocks.
Theuseoffilelocksrequiresthesameprecautionsasordinaryprocesssyn-
chronization.Forexample,programmersdevelopingonsystemswithmanda-
tory locking must be careful to hold exclusive file locks only while they are
accessingthefile.Otherwise,theywillpreventotherprocessesfromaccessing
thefileaswell.Furthermore,somemeasuresmustbetakentoensurethattwo
ormoreprocessesdonotbecomeinvolvedinadeadlockwhiletryingtoacquire
filelocks.
13.1.3 File Types
When we design a file system—indeed, an entire operating system—we
alwaysconsiderwhethertheoperatingsystemshouldrecognizeandsupport
filetypes.Ifanoperatingsystemrecognizesthetypeofafile,itcanthenoperate
onthefileinreasonableways.Forexample,acommonmistakeoccurswhena
usertriestooutputthebinary-objectformofaprogram.Thisattemptnormally
produces garbage; however, the attempt can succeed if the operating system
hasbeentoldthatthefileisabinary-objectprogram.
A common technique for implementing file types is to include the type
as part of the file name. The name is split into two parts—a name and an
extension, usually separated by a period (Figure 13.3). In this way, the user
andtheoperatingsystemcantellfromthenamealonewhat thetypeofafile
is. Most operating systems allow users to specify a file name as a sequence
of characters followed by a period and terminated by an extension made
up of additional characters. Examples include resume.docx, server.c, and
ReaderThread.cpp.
Thesystemusestheextensiontoindicatethetypeofthefileandthetype
ofoperationsthatcanbedoneonthatfile.Onlyafilewitha.com,.exe,or.sh
extensioncanbeexecuted,forinstance.The.comand.exefilesaretwoforms
of binary executable files, whereas the .sh file is a shell script containing, in
ASCII format, commands to the operating system. Application programs also
useextensionstoindicatefiletypesinwhichtheyareinterested.Forexample,
Javacompilersexpectsourcefilestohavea.javaextension,andtheMicrosoft
Wordword processorexpectsitsfilestoendwitha .docor .docxextension.
Theseextensionsarenotalwaysrequired,soausermayspecifyafilewithout
the extension (to save typing), and the application will look for a file with
the given name and the extension it expects. Because these extensions are
not supportedby the operatingsystem,they canbe considered“hints” tothe
applicationsthatoperateonthem.
Consider, too, the macOS operating system. In this system, each file has
a type, such as .app (for application). Each file also has a creator attribute13.1 FileConcept 537
file type usual extension function
executable exe, com, bin ready-to-run machine-
or none language program
object obj, o compiled, machine
language, not linked
source code c, cc, java, perl, source code in various
asm languages
batch bat, sh commands to the command
interpreter
markup xml, html, tex textual data, documents
word processor xml, rtf, various word-processor
docx formats
library lib, a, so, dll libraries of routines for
programmers
print or view gif, pdf, jpg ASCII or binary file in a
format for printing or
viewing
archive rar, zip, tar related files grouped into
one file, sometimes com-
pressed, for archiving
or storage
multimedia mpeg, mov, mp3, binary file containing
mp4, avi audio or A/V information
Figure13.3 Commonfiletypes.
containing the name of the program that created it. This attribute is set by
the operating system during the create() call, so its use is enforced and
supported by the system. For instance, a file produced by a word processor
hasthewordprocessor’snameasitscreator.Whentheuseropensthatfile,by
double-clickingthemouseontheiconrepresentingthefile,thewordprocessor
isinvokedautomatically,andthefileisloaded,readytobeedited.
The UNIX system uses a magic number stored at the beginning of some
binary files to indicate the type of data in the file (for example, the format
of an image file). Likewise, it uses a text magic number at the start of text
files to indicate the type of file (which shell language a script is written in)
and so on. (For more details on magic numbers and other computer jargon,
see http://www.catb.org/esr/jargon/.) Not all files have magic numbers, so
system features cannot be based solely on this information. UNIX does not
record the name of the creating program, either. UNIX does allow file-name-
extensionhints,buttheseextensionsareneitherenforcednordependedonby
theoperatingsystem;theyaremeantmostlytoaidusersindeterminingwhat
typeofcontentsthefilecontains.Extensionscanbeusedorignoredbyagiven
application,butthatisuptotheapplication’sprogrammer.
13.1.4 File Structure
Filetypesalsocanbeusedtoindicatetheinternalstructureofthefile.Source
and object files have structures that match the expectations of the programs
thatreadthem.Further,certainfilesmustconformtoarequiredstructurethat538 Chapter13 File-SystemInterface
is understood by the operating system. For example, the operating system
requiresthatanexecutablefilehaveaspecificstructuresothatitcandetermine
whereinmemorytoloadthefileandwhatthelocationofthefirstinstruction
is. Some operating systems extend this idea into a set of system-supported
filestructures,withsetsofspecialoperationsformanipulatingfileswiththose
structures.
This point brings us to one of the disadvantages of having the operating
system support multiple file structures: it makes the operating system large
andcumbersome.Iftheoperatingsystemdefinesfivedifferentfilestructures,it
needstocontainthecodetosupportthesefilestructures.Inaddition,itmaybe
necessarytodefineeveryfileasoneofthefiletypessupportedbytheoperating
system. When new applications require information structured in ways not
supportedbytheoperatingsystem,severeproblemsmayresult.
For example, assume that a system supports two types of files: text files
(composed of ASCII characters separated by a carriage return and line feed)
andexecutablebinaryfiles.Now,ifwe(asusers)wanttodefineanencrypted
file to protect the contents from being read by unauthorized people, we may
findneitherfiletypetobeappropriate.TheencryptedfileisnotASCIItextlines
butratheris(apparently)randombits.Althoughitmayappeartobeabinary
file,itisnotexecutable.Asaresult,wemayhavetocircumventormisusethe
operatingsystem’sfile-typemechanismorabandonourencryptionscheme.
Some operating systems impose (and support) a minimal number of file
structures. This approach has been adopted in UNIX, Windows, and others.
UNIX considers each file to be a sequence of 8-bit bytes; no interpretation of
these bits is made by the operating system. This scheme provides maximum
flexibility but little support. Each application program must include its own
code to interpret an input file as to the appropriate structure. However, all
operatingsystemsmustsupportatleastonestructure—thatofanexecutable
file—sothatthesystemisabletoloadandrunprograms.
13.1.5 Internal File Structure
Internally,locatinganoffsetwithinafilecanbecomplicatedfortheoperating
system. Disk systems typically have a well-defined block size determinedby
the size of a sector. All disk I/O is performed in units of one block (physical
record),andallblocksarethesamesize.Itisunlikelythatthephysicalrecord
sizewillexactlymatchthelengthofthedesiredlogicalrecord.Logicalrecords
may even vary in length. Packing a number of logical records into physical
blocksisacommonsolutiontothisproblem.
For example, the UNIX operating system defines all files to be simply
streams of bytes. Each byte is individually addressable by its offset from the
beginning(orend)ofthefile.Inthiscase,thelogicalrecordsizeis1byte.The
filesystemautomaticallypacksandunpacksbytesintophysicaldiskblocks—
say,512bytesperblock—asnecessary.
The logical record size, physical block size, and packing technique deter-
minehowmanylogicalrecordsareineachphysicalblock.Thepackingcanbe
done either by the user’s application program or by the operating system. In
either case, the file may be considered a sequence of blocks. All the basic I/O
functions operate in terms of blocks. The conversion from logical records to
physicalblocksisarelativelysimplesoftwareproblem.13.2 AccessMethods 539
Because disk space is always allocated in blocks, some portion of the last
blockofeachfileisgenerallywasted.Ifeachblockwere512bytes,forexample,
thenafileof 1,949byteswouldbeallocatedfour blocks (2,048bytes);thelast
99 bytes would be wasted. The waste incurred to keep everything in units
of blocks (instead of bytes) is internal fragmentation. All file systems suffer
frominternalfragmentation;thelargertheblock size,thegreatertheinternal
fragmentation.
13.2 Access Methods
Filesstoreinformation.Whenitisused,thisinformationmustbeaccessedand
read into computer memory. The information in the file can be accessed in
severalways. Somesystemsprovideonly one access methodfor files.Others
(such as mainframe operating systems) support many access methods, and
choosingtherightoneforaparticularapplicationisamajordesignproblem.
13.2.1 Sequential Access
The simplest access method is sequential access. Information in the file is
processed in order, one record after the other. This mode of access is by far
the most common; for example, editors and compilers usually access files in
thisfashion.
Reads and writes make up the bulk of the operations on a file. A read
operation—read next()—readsthenextportionofthefileandautomatically
advances a file pointer, which tracks the I/O location. Similarly, the write
operation—write next()—appendstotheendofthefileandadvancestothe
endofthenewlywrittenmaterial(thenewendoffile).Suchafilecanbereset
tothebeginning,andonsomesystems,aprogrammaybeabletoskipforward
orbackwardnrecordsforsomeintegern—perhapsonlyforn=1.Sequential
access,whichisdepictedinFigure13.4,isbasedonatapemodelofafileand
worksaswellonsequential-accessdevicesasitdoesonrandom-accessones.
13.2.2 Direct Access
Another method is direct access (or relative access). Here, a file is made up
offixed-lengthlogicalrecordsthatallowprogramstoreadandwriterecords
rapidly in no particular order. The direct-access method is based on a disk
model of a file, since disks allow random access to any file block. For direct
access, the file is viewed as a numbered sequence of blocks or records. Thus,
current position
beginning end
rewind
read or write
Figure13.4 Sequential-accessfile.540 Chapter13 File-SystemInterface
wemayreadblock14,thenreadblock53,andthenwriteblock7.Thereareno
restrictionsontheorderofreadingorwritingforadirect-accessfile.
Direct-access files are of great use for immediate access to large amounts
of information. Databases are often of this type. When a query concerning a
particular subject arrives, we compute which block contains the answer and
thenreadthatblockdirectlytoprovidethedesiredinformation.
Asasimpleexample,onanairline-reservationsystem,wemightstoreall
the informationabout aparticular flight (for example,flight 713)inthe block
identifiedby the flight number. Thus, the number of available seats for flight
713 is stored in block 713 of the reservationfile. To store information about a
largerset,suchaspeople,wemightcomputeahashfunction onthepeople’s
names or search a small in-memory index to determine a block to read and
search.
For the direct-access method, the file operations must be modified to
include the block number as a parameter. Thus, we have read(n), where
n is the block number, rather than read next(), and write(n) rather
than write next(). An alternative approach is to retain read next() and
write next() and to add an operation position file(n) where n is the
block number. Then, to effect a read(n), we would position file(n) and
thenread next().
Theblocknumberprovidedbytheusertotheoperatingsystemisnormally
a relative block number. Arelative block number is an index relative to the
beginning of the file. Thus, the first relative block of the file is 0, the next is
1, and so on, even though the absolute disk address may be 14703 for the
first block and 3192 for the second. The use of relative block numbers allows
the operating system to decide where the file should be placed (called the
allocationproblem,aswediscussinChapter14)andhelpstopreventtheuser
fromaccessingportionsofthefilesystemthatmaynotbepartofherfile.Some
systemsstarttheirrelativeblocknumbersat0;othersstartat1.
How,then,doesthesystemsatisfyarequestforrecordNinafile?Assum-
ing we have a logical record length L, the request for record N is turned into
anI/OrequestforLbytesstartingatlocationL∗(N)withinthefile(assuming
thefirstrecordisN=0).Sincelogicalrecordsareofafixedsize,itisalsoeasy
toread,write,ordeletearecord.
Not all operating systems support both sequential and direct access for
files. Some systems allow only sequential file access; others allow only direct
access.Somesystemsrequirethatafilebedefinedassequentialordirectwhen
it is created. Such a file can be accessed only in a manner consistent with its
declaration.Wecaneasilysimulatesequentialaccessonadirect-accessfileby
simply keeping a variable cp that defines our current position, as shown in
Figure13.5.Simulatingadirect-accessfileonasequential-accessfile,however,
isextremelyinefficientandclumsy.
13.2.3 Other Access Methods
Other access methods can be built on top of a direct-access method. These
methodsgenerallyinvolvetheconstructionofanindexforthefile.Theindex,
likeanindexinthebackofabook,containspointerstothevariousblocks.To
find a record in the file, we first search the index and then use the pointer to
accessthefiledirectlyandtofindthedesiredrecord.13.3 DirectoryStructure 541
sequential access implementation for direct access
reset cp 0;
read_next read cp;
cp cp 1;
write_next write cp;
cp cp 1;
Figure13.5 Simulationofsequentialaccessonadirect-accessfile.
Forexample,aretail-pricefilemightlisttheuniversalproductcodes(UPCs)
foritems,withtheassociatedprices.Eachrecordconsistsofa10-digitUPCand
a 6-digit price, for a 16-byte record. If our disk has 1,024 bytes per block, we
can store 64 records per block. Afile of 120,000 records would occupy about
2,000blocks(2millionbytes).BykeepingthefilesortedbyUPC,wecandefine
anindexconsistingofthefirstUPCineachblock.Thisindexwouldhave2,000
entriesof10digitseach,or20,000bytes,andthuscouldbekeptinmemory.To
find the price of a particular item, we can make a binary search of the index.
Fromthissearch,welearnexactlywhichblockcontainsthedesiredrecordand
accessthatblock.ThisstructureallowsustosearchalargefiledoinglittleI/O.
With large files, the index file itself may become too large to be kept in
memory.Onesolutionistocreateanindexfortheindexfile.Theprimaryindex
file contains pointers to secondary index files, which point to the actual data
items.
Forexample,IBM’s indexedsequential-accessmethod(ISAM)usesasmall
master index that points to disk blocks of a secondary index. The secondary
indexblockspointtotheactualfileblocks.Thefileiskeptsortedonadefined
key.Tofindaparticularitem,wefirstmakeabinarysearchofthemasterindex,
which provides the block number of the secondary index. This block is read
in, and again a binary search is used to find the block containing the desired
record.Finally,thisblockissearchedsequentially.Inthisway,anyrecordcan
belocatedfromitskeybyatmosttwodirect-accessreads.Figure13.6showsa
similarsituationasimplementedbyOpenVMSindexandrelativefiles.
13.3 Directory Structure
The directory can be viewed as a symbol table that translates file names into
theirfilecontrolblocks.Ifwetakesuchaview,weseethatthedirectoryitself
can be organized in many ways. The organization must allow us to insert
entries,todeleteentries,tosearchforanamedentry,andtolistalltheentries
in the directory. In this section, we examine several schemes for defining the
logicalstructureofthedirectorysystem.
Whenconsideringaparticulardirectorystructure,weneedtokeepinmind
theoperationsthataretobeperformedonadirectory:
• Searchforafil .Weneedtobeabletosearchadirectorystructuretofind
theentryforaparticularfile.Sincefileshavesymbolicnames,andsimilar542 Chapter13 File-SystemInterface
logical record
last name number
Adams
Arthur
Asher smith, john social-security age
(cid:129)
(cid:129)
(cid:129)
Smith
index file relative file
Figure13.6 Exampleofindexandrelativefiles.
namesmayindicatearelationshipamongfiles,wemaywanttobeableto
findallfileswhosenamesmatchaparticularpattern.
• Createafil .Newfilesneedtobecreatedandaddedtothedirectory.
• Deleteafile.Whenafileisnolongerneeded,wewanttobeabletoremove
itfromthedirectory.Noteadeleteleavesaholeinthedirectorystructure
and the file system may have a method to defragement the directory
structure.
• List a directory. We need to be able to list the files in a directory and the
contentsofthedirectoryentryforeachfileinthelist.
• Renameafile.Becausethenameofafilerepresentsitscontentstoitsusers,
we must be able to change the name when the contents or use of the file
changes.Renamingafilemayalsoallowitspositionwithinthedirectory
structuretobechanged.
• Traversethefilesystem.Wemaywishtoaccesseverydirectoryandevery
filewithinadirectorystructure.Forreliability,itisagoodideatosavethe
contentsandstructureoftheentirefilesystematregularintervals.Often,
wedothisbycopyingallfilestomagnetictape,othersecondarystorage,or
acrossanetworktoanothersystemorthecloud.Thistechniqueprovides
abackupcopyincaseofsystemfailure.Inaddition,ifafileisnolongerin
use,thefilecanbecopiedthebackuptargetandthediskspaceofthatfile
releasedforreusebyanotherfile.
Inthefollowingsections,wedescribethemostcommonschemesfordefining
thelogicalstructureofadirectory.
13.3.1 Single-Level Directory
The simplestdirectorystructureisthe single-leveldirectory.All filesare con-
tainedinthesamedirectory,whichiseasytosupportandunderstand(Figure
13.7).13.3 DirectoryStructure 543
directory cat bo a test data mail cont hex records
files
Figure13.7 Single-leveldirectory.
A single-level directory has significant limitations, however, when the
numberoffilesincreasesorwhenthesystemhasmorethanoneuser.Sinceall
filesareinthesamedirectory,theymusthaveuniquenames.Iftwouserscall
theirdatafile test.txt,then the unique-name ruleis violated.For example,
in one programming class, 23 students called the program for their second
assignment prog2.c; another 11 called it assign2.c. Fortunately, most file
systems support file names of up to 255 characters, so it is relatively easy to
selectuniquefilenames.
Evenasingleuseronasingle-leveldirectorymayfinditdifficulttoremem-
berthenamesofallthefilesasthenumberoffilesincreases.Itisnotuncommon
for a user to have hundreds of files on one computer system and an equal
numberofadditionalfilesonanothersystem.Keepingtrackofsomanyfilesis
adauntingtask.
13.3.2 Two-Level Directory
Aswehaveseen,asingle-leveldirectoryoftenleadstoconfusionoffilenames
among different users.The standard solution is to create a separatedirectory
foreachuser.
Inthetwo-leveldirectorystructure,eachuserhashisownuserfil direc-
tory (UFD). The UFDs have similar structures, but each lists only the files of
a single user. When a user job starts or a user logs in, the system’s master
fil directory(MFD)issearched.TheMFDisindexedbyusernameoraccount
number,andeachentrypointstotheUFDforthatuser(Figure13.8).
Whenauserreferstoaparticularfile,onlyhisownUFDissearched.Thus,
differentusersmayhavefileswiththesamename,aslongasallthefilenames
within each UFD are unique. To create a file for a user, the operating system
searches only that user’s UFD to ascertain whether another file of that name
master file
user 1 user 2 user 3 user 4
directory
user file
cat bo a test a data a test x data a
directory
Figure13.8 Two-leveldirectorystructure.544 Chapter13 File-SystemInterface
exists.Todeleteafile,theoperatingsystemconfinesitssearchtothelocalUFD;
thus,itcannotaccidentallydeleteanotheruser’sfilethathasthesamename.
Theuserdirectoriesthemselvesmustbecreatedanddeletedasnecessary.
Aspecialsystemprogramisrunwiththeappropriateusernameandaccount
information. The program creates a new UFD and adds an entry for it to the
MFD.Theexecutionofthisprogrammightberestrictedtosystemadministra-
tors.Theallocationofdiskspaceforuserdirectoriescanbehandledwiththe
techniquesdiscussedinChapter14forfilesthemselves.
Althoughthetwo-leveldirectorystructuresolvesthename-collisionprob-
lem,itstillhasdisadvantages.Thisstructureeffectivelyisolatesoneuserfrom
another.Isolationisanadvantagewhentheusersarecompletelyindependent
but is a disadvantage when the users want to cooperate on some task and to
accessoneanother’sfiles.Somesystemssimplydonotallowlocaluserfilesto
beaccessedbyotherusers.
If access is to be permitted, one user must have the ability to name a file
in another user’s directory. To name a particular file uniquely in a two-level
directory, we must give both the user name and the file name. A two-level
directorycanbethoughtofasatree,oraninvertedtree,ofheight2.Theroot
ofthetreeistheMFD.ItsdirectdescendantsaretheUFDs.Thedescendantsof
theUFDsarethefilesthemselves.Thefilesaretheleavesofthetree.Specifying
ausernameandafilenamedefinesapathinthetreefromtheroot(theMFD)
to a leaf (the specified file). Thus, a user name and a file name define a path
name.Everyfileinthesystemhasapathname.Tonameafileuniquely,auser
mustknowthepathnameofthefiledesired.
Forexample,ifuserAwishestoaccessherowntestfilenamedtest.txt,
she can simply refer to test.txt. To access the file named test.txt of user
B (with directory-entry name userb), however, she might have to refer to
/userb/test.txt.Everysystemhasitsownsyntaxfornamingfilesindirec-
toriesotherthantheuser’sown.
Additional syntax is needed to specify the volume of a file. For instance,
in Windows a volume is specified by a letter followed by a colon. Thus, a
file specification might be C:∖userb∖test. Some systems go even further
and separate the volume, directory name, and file name parts of the speci-
fication. In OpenVMS, for instance, the file login.com might be specified as:
u:[sst.crissmeyer]login.com;1,where u is the name of the volume, sst
isthenameofthedirectory,crissmeyeristhenameofthesubdirectory,and
1 is the version number. Other systems—such as UNIX and Linux—simply
treat the volume name as part of the directory name. The first name given
is that of the volume, and the rest is the directory and file. For instance,
/u/pgalvin/testmightspecifyvolumeu,directorypgalvin,andfiletest.
Aspecialinstance ofthissituationoccurs withthesystemfiles.Programs
provided as part of the system—loaders, assemblers, compilers, utility rou-
tines,libraries,andsoon—aregenerallydefinedasfiles.Whentheappropriate
commandsaregiventotheoperatingsystem,thesefilesarereadbytheloader
and executed. Many command interpreters simply treat such a command as
thenameofafiletoloadandexecute.Inthedirectorysystemaswedefinedit
above, this file name would be searched for in the current UFD. One solution
would be to copy the system files into each UFD. However, copying all the
system files would waste an enormous amount of space. (If the system files13.3 DirectoryStructure 545
require 5 MB, then supporting 12 users would require 5 × 12 = 60 MB just for
copiesofthesystemfiles.)
The standard solution is to complicate the search procedure slightly. A
specialuserdirectoryisdefinedtocontainthesystemfiles(forexample,user
0). Whenever a file name is given to be loaded, the operating system first
searchesthelocalUFD.Ifthefileisfound,itisused.Ifitisnotfound,thesystem
automaticallysearchesthespecialuserdirectorythatcontainsthesystemfiles.
Thesequenceofdirectoriessearchedwhenafileisnamediscalledthesearch
path.Thesearchpathcanbeextendedtocontainanunlimitedlistofdirectories
tosearchwhen acommand nameisgiven.This methodistheone mostused
inUNIXandWindows.Systemscanalsobedesignedsothateachuserhashis
ownsearchpath.
13.3.3 Tree-Structured Directories
Once we have seen how to view a two-level directory as a two-level tree,
the natural generalization is to extend the directory structure to a tree of
arbitrary height (Figure 13.9). This generalization allows users to create their
own subdirectories and to organize their files accordingly. Atree is the most
commondirectorystructure.Thetreehasarootdirectory,andeveryfileinthe
systemhasauniquepathname.
A directory (or subdirectory) contains a set of files or subdirectories. In
many implementations, a directory is simply another file, but it is treated in
a special way. All directories have the same internal format. One bit in each
directory entry defines the entry as a file (0) or as a subdirectory (1). Special
root
spell bin programs
stat mail dist find count hex reorder p e mail
prog copy prt exp reorder list find hex count
list obj spell all last first
Figure13.9 Tree-structureddirectorystructure.546 Chapter13 File-SystemInterface
systemcallsareusedtocreateanddeletedirectories.Inthiscasetheoperating
system (or the file system code) implements another file format, that of a
directory.
Innormaluse,eachprocesshasacurrentdirectory.Thecurrentdirectory
shouldcontainmostofthefilesthatareofcurrentinteresttotheprocess.When
referenceismadetoafile,thecurrentdirectoryissearched.Ifafileisneeded
thatisnotinthecurrentdirectory,thentheuserusuallymusteitherspecifya
pathnameorchangethecurrentdirectorytobethedirectoryholdingthatfile.
To change directories, a system call could be provided that takes a directory
nameasaparameterandusesittoredefinethecurrentdirectory.Thus,theuser
can change hercurrent directorywhenevershe wants. Othersystemsleaveit
to the application (say, a shell) to track and operate on a current directory, as
eachprocesscouldhavedifferentcurrentdirectories.
Theinitialcurrentdirectoryofauser’sloginshellisdesignatedwhenthe
userjobstartsortheuserlogsin.Theoperatingsystemsearchestheaccounting
file (or some other predefined location) to find an entry for this user (for
accounting purposes). In the accounting file is a pointer to (or the name of)
theuser’sinitialdirectory.Thispointeriscopiedtoalocalvariableforthisuser
thatspecifiestheuser’sinitialcurrentdirectory.Fromthatshell,otherprocesses
canbespawned.Thecurrentdirectoryofanysubprocessisusuallythecurrent
directoryoftheparentwhenitwasspawned.
Pathnamescanbeoftwotypes:absoluteandrelative.InUNIXandLinux,
an absolute path name begins at the root (which is designated by an initial
“/”)andfollowsapathdowntothespecifiedfile,givingthedirectorynames
onthepath.Arelativepathnamedefinesapathfromthecurrentdirectory.For
example,inthetree-structuredfilesystemofFigure13.9,ifthecurrentdirectory
is/spell/mail,thentherelativepathnameprt/firstreferstothesamefile
asdoestheabsolutepathname/spell/mail/prt/first.
Allowing a user to define her own subdirectories permits her to impose
a structure on her files. This structure might result in separate directories for
filesassociatedwithdifferenttopics(forexample,asubdirectorywascreated
toholdthetextofthisbook)ordifferentformsofinformation.Forexample,the
directoryprogramsmaycontainsourceprograms;thedirectorybinmaystore
allthebinaries.(Asasidenote,executablefileswereknowninmanysystems
as“binaries”whichledtothembeingstoredinthebindirectory.)
Aninterestingpolicydecisioninatree-structureddirectoryconcernshow
to handle the deletion of a directory. If a directory is empty, its entry in the
directorythat contains it can simplybe deleted.However,supposethe direc-
torytobedeletedisnotemptybutcontainsseveralfilesorsubdirectories.One
oftwoapproachescanbetaken.Somesystemswillnotdeleteadirectoryunless
it is empty. Thus, to delete a directory, the user must first delete all the files
in that directory. If any subdirectories exist, this procedure must be applied
recursivelytothem,sothattheycanbedeletedalso.Thisapproachcanresult
in a substantial amount of work. An alternative approach, such as that taken
by the UNIX rm command, is to provide an option: when a request is made
to deletea directory,all that directory’s files and subdirectoriesare also to be
deleted.Eitherapproachisfairlyeasytoimplement;thechoiceisoneofpolicy.
Thelatterpolicyismoreconvenient,butitisalsomoredangerous,becausean
entiredirectorystructurecanberemovedwithonecommand.Ifthatcommand13.3 DirectoryStructure 547
isissuedinerror,alargenumberoffilesanddirectorieswillneedtoberestored
(assumingabackupexists).
Withatree-structureddirectorysystem,userscanbeallowedtoaccess,in
additiontotheirfiles,thefilesofotherusers.Forexample,userBcanaccessa
fileofuserAbyspecifyingitspathname.UserBcanspecifyeitheranabsolute
orarelativepathname.Alternatively,userBcanchangehercurrentdirectory
tobeuserA’sdirectoryandaccessthefilebyitsfilename.
13.3.4 Acyclic-Graph Directories
Considertwoprogrammerswhoareworkingonajointproject.Thefilesasso-
ciatedwiththatprojectcanbestoredinasubdirectory,separatingthemfrom
otherprojectsandfilesofthetwoprogrammers.Butsincebothprogrammers
areequallyresponsiblefortheproject,bothwantthesubdirectorytobeintheir
owndirectories.Inthissituation,thecommonsubdirectoryshouldbeshared.
Ashared directory or file exists in the file system in two (or more) places at
once.
A tree structure prohibits the sharing of files or directories. An acyclic
graph—thatis,agraphwithnocycles—allowsdirectoriestosharesubdirec-
tories and files (Figure 13.10). The same file or subdirectory may be in two
different directories. The acyclic graph is a natural generalization of the tree-
structureddirectoryscheme.
Itisimportanttonotethatasharedfile(ordirectory)isnotthesameastwo
copiesofthefile.Withtwocopies,eachprogrammercanviewthecopyrather
thantheoriginal,butifoneprogrammerchangesthefile,thechangeswillnot
appearintheother’scopy.Withasharedfile,onlyoneactualfileexists,soany
changes made by one person are immediately visible to the other. Sharing is
root
dict spell
list all w count count words list
list rade w7
Figure13.10 Acyclic-graphdirectorystructure.548 Chapter13 File-SystemInterface
particularlyimportantforsubdirectories;anewfilecreatedbyonepersonwill
automaticallyappearinallthesharedsubdirectories.
Whenpeopleareworkingasateam,allthefilestheywanttosharecanbe
putintoonedirectory.Thehomedirectoryofeachteammembercouldcontain
thisdirectoryofsharedfilesasasubdirectory.Eveninthecaseofasingleuser,
the user’s file organization may require that some file be placed in different
subdirectories.Forexample,aprogramwrittenforaparticularprojectshould
bebothinthedirectoryofallprogramsandinthedirectoryforthatproject.
Shared files and subdirectories can be implemented in several ways. A
commonway,exemplifiedbyUNIXsystems,istocreateanewdirectoryentry
calledalink.Alinkiseffectivelyapointertoanotherfileorsubdirectory.For
example, a link may be implemented as an absolute or a relative path name.
When a reference to a file is made, we search the directory. If the directory
entryismarkedasalink,thenthenameoftherealfileisincludedinthelink
information. We resolve the link by using that path name to locate the real
file. Links are easily identified by their format in the directory entry (or by
havingaspecialtypeonsystemsthatsupporttypes)andareeffectivelyindirect
pointers. The operating system ignores these links when traversing directory
treestopreservetheacyclicstructureofthesystem.
Another common approach to implementing shared files is simply to
duplicate all information about them in both sharing directories. Thus, both
entriesareidenticalandequal.Considerthedifferencebetweenthisapproach
andthecreationofalink.Thelinkisclearlydifferentfromtheoriginaldirectory
entry;thus,thetwoarenotequal.Duplicatedirectoryentries,however,make
the original and the copy indistinguishable. Amajor problem with duplicate
directoryentriesismaintainingconsistencywhenafileismodified.
An acyclic-graph directory structure is more flexible than a simple tree
structure, but it is also more complex. Several problems must be considered
carefully. Afile may now have multiple absolute path names. Consequently,
distinct file names may refer to the same file. This situation is similar to the
aliasingproblemforprogramminglanguages.Ifwearetryingtotraversethe
entirefilesystem—tofindafile,toaccumulatestatisticsonallfiles,ortocopy
allfilestobackupstorage—thisproblembecomessignificant,sincewedonot
wanttotraversesharedstructuresmorethanonce.
Another problem involves deletion. When can the space allocated to a
shared file be deallocated and reused? One possibility is to remove the file
wheneveranyonedeletesit,butthisactionmayleavedanglingpointerstothe
now-nonexistent file.Worse,if theremainingfile pointerscontain actual disk
addresses,andthespaceissubsequentlyreusedforotherfiles,thesedangling
pointersmaypointintothemiddleofotherfiles.
Inasystemwheresharingisimplementedbysymboliclinks,thissituation
issomewhateasiertohandle.Thedeletionofalinkneednotaffecttheoriginal
file; only the link is removed. If the file entry itself is deleted, the space for
thefileisdeallocated,leavingthelinksdangling.Wecansearchfortheselinks
andremovethemaswell,butunlessalistoftheassociatedlinksiskeptwith
each file, this search can be expensive. Alternatively, we can leave the links
untilanattemptismadetousethem.Atthattime,wecandeterminethatthe
file of the name given by the link does not exist and can fail to resolve the
linkname;theaccessistreatedjustaswithanyotherillegalfilename.(Inthis
case, the system designer should consider carefully what to do when a file is13.3 DirectoryStructure 549
deletedandanotherfileofthesamenameiscreated,beforeasymboliclinkto
theoriginalfileisused.)InthecaseofUNIX,symboliclinksareleftwhenafile
isdeleted,anditisuptotheusertorealizethattheoriginalfileisgoneorhas
beenreplaced.MicrosoftWindowsusesthesameapproach.
Another approach to deletion is to preserve the file until all references to
it are deleted. To implement this approach, we must have some mechanism
for determining that the last reference to the file has been deleted. We could
keepalistofallreferencestoafile(directoryentriesorsymboliclinks).When
a link or a copy of the directory entry is established, a new entry is added to
thefile-referencelist.Whenalinkordirectoryentryisdeleted,weremoveits
entryonthelist.Thefileisdeletedwhenitsfile-referencelistisempty.
Thetroublewiththisapproachisthevariableandpotentiallylargesizeof
the file-reference list. However, we really do not need to keep the entire list
—we need to keep only a count of the number of references. Adding a new
linkordirectoryentryincrementsthereferencecount.Deletingalinkorentry
decrementsthecount.Whenthecountis0,thefilecanbedeleted;thereareno
remaining references to it. The UNIX operating system uses this approach for
nonsymbolic links (orhard links),keeping areferencecount inthe file infor-
mationblock (or inode; seeSectionC.7.2).By effectivelyprohibiting multiple
referencestodirectories,wemaintainanacyclic-graphstructure.
To avoid problems such as the ones just discussed, some systems simply
donotallowshareddirectoriesorlinks.
13.3.5 General Graph Directory
Aseriousproblemwithusinganacyclic-graphstructureisensuringthatthere
are no cycles. If we start with a two-level directory and allow users to create
subdirectories,atree-structureddirectoryresults.Itshouldbefairlyeasytosee
thatsimplyaddingnewfilesandsubdirectoriestoanexistingtree-structured
directory preserves the tree-structured nature. However, when we add links,
the tree structure is destroyed, resulting in a simple graph structure (Figure
13.11).
Theprimaryadvantageofanacyclicgraphistherelativesimplicityofthe
algorithms to traverse the graph and to determine when there are no more
references to a file. We want to avoid traversing shared sections of an acyclic
graphtwice,mainlyforperformancereasons.Ifwehavejustsearchedamajor
shared subdirectory for a particular file without finding it, we want to avoid
searchingthatsubdirectoryagain;thesecondsearchwouldbeawasteoftime.
If cycles are allowed to exist in the directory, we likewise want to avoid
searching any component twice, for reasons of correctness as well as perfor-
mance.Apoorlydesignedalgorithmmightresultinaninfiniteloopcontinually
searching through the cycle and never terminating. One solution is to limit
arbitrarilythenumberofdirectoriesthatwillbeaccessedduringasearch.
A similar problem exists when we are trying to determine when a file
can be deleted. With acyclic-graph directory structures, a value of 0 in the
referencecountmeansthattherearenomorereferencestothefileordirectory,
and the file can be deleted. However, when cycles exist, the reference count
may not be 0 evenwhen it is no longer possible to referto a directory or file.
Thisanomalyresultsfromthepossibilityofself-referencing(oracycle)inthe
directorystructure.Inthiscase,wegenerallyneedtouseagarbagecollection550 Chapter13 File-SystemInterface
root
avi tc jim
text mail count book book mail unhex hyp
avi count unhex hex
Figure13.11 Generalgraphdirectory.
scheme to determine when the last reference has been deleted and the disk
spacecanbereallocated.Garbagecollectioninvolvestraversingtheentirefile
system,markingeverythingthatcanbeaccessed.Then,asecondpasscollects
everything that is not marked onto a list of free space. (A similar marking
procedurecanbeusedtoensurethatatraversalorsearchwillcovereverything
inthefilesystemonceandonlyonce.)Garbagecollectionforadisk-basedfile
system,however,isextremelytimeconsumingandisthusseldomattempted.
Garbagecollectionisnecessaryonlybecauseofpossiblecyclesinthegraph.
Thus,anacyclic-graphstructureismucheasiertoworkwith.Thedifficultyisto
avoidcyclesasnewlinksareaddedtothestructure.Howdoweknowwhena
newlinkwillcompleteacycle?Therearealgorithmstodetectcyclesingraphs;
however,theyarecomputationallyexpensive,especiallywhenthegraphison
disk storage. Asimpler algorithm in the special case of directories and links
istobypasslinksduringdirectorytraversal.Cyclesareavoided,andnoextra
overheadisincurred.
13.4 Protection
When information is stored in a computer system, we want to keep it safe
fromphysicaldamage(theissueofreliability)andimproperaccess(theissue
ofprotection).
Reliabilityisgenerallyprovidedbyduplicatecopiesoffiles.Manycomput-
ershavesystemsprogramsthatautomatically(orthroughcomputer-operator
intervention)copydiskfilestotapeatregularintervals(onceperdayorweek
or month) to maintain a copy should a file system be accidentally destroyed.
Filesystemscanbedamagedbyhardwareproblems(suchaserrorsinreading
orwriting),powersurgesorfailures,headcrashes,dirt,temperatureextremes,13.4 Protection 551
andvandalism.Filesmaybedeletedaccidentally.Bugsinthefile-systemsoft-
ware can also cause file contents to be lost. Reliability was covered in more
detailinChapter11.
Protection can be provided in many ways. For a laptop system running
amodernoperatingsystem,wemightprovideprotectionbyrequiringauser
nameandpasswordauthenticationtoaccessit,encryptingthesecondarystor-
agesoevensomeoneopeningthelaptopandremovingthedrivewouldhave
adifficulttimeaccessingitsdata,andfirewallingnetworkaccesssothatwhen
it is in use it is difficult to break in via its network connection. In multiuser
system,evenvalidaccessofthesystemneedsmoreadvancedmechanismsto
allowonlyvalidaccessofthedata.
13.4.1 Types of Access
Theneedtoprotectfilesisadirectresultoftheabilitytoaccessfiles.Systems
thatdonotpermitaccesstothefilesofotherusersdonotneedprotection.Thus,
wecouldprovidecompleteprotectionbyprohibitingaccess.Alternatively,we
couldprovidefreeaccesswithnoprotection.Bothapproachesaretooextreme
forgeneraluse.Whatisneedediscontrolledaccess.
Protection mechanisms providecontrolled access by limiting the types of
file access that can be made. Access is permitted or denied depending on
severalfactors, one ofwhich is thetypeof access requested.Severaldifferent
typesofoperationsmaybecontrolled:
• Read.Readfromthefile.
• Write.Writeorrewritethefile.
• Execute.Loadthefileintomemoryandexecuteit.
• Append.Writenewinformationattheendofthefile.
• Delete.Deletethefileandfreeitsspaceforpossiblereuse.
• List.Listthenameandattributesofthefile.
• Attributechange.Changingtheattributesofthefile.
Otheroperations,suchasrenaming,copying,andeditingthefile,mayalso
be controlled. For many systems, however, these higher-level functions may
be implemented by a system program that makes lower-level system calls.
Protectionisprovidedatonlythelowerlevel.Forinstance,copyingafilemay
beimplementedsimplybyasequenceofreadrequests.Inthiscase,auserwith
readaccesscanalsocausethefiletobecopied,printed,andsoon.
Many protection mechanisms have been proposed. Each has advantages
and disadvantages and must be appropriate for its intended application. A
smallcomputersystemthatisusedbyonlyafewmembersofaresearchgroup,
for example, may not need the same types of protection as a large corporate
computer that is used for research, finance, and personnel operations. We
discuss some approaches to protection in the following sections and present
amorecompletetreatmentinChapter17.552 Chapter13 File-SystemInterface
13.4.2 Access Control
Themostcommonapproachtotheprotectionproblemistomakeaccessdepen-
dent on the identity of the user. Different users may need different types of
access to a file or directory. The most general scheme to implement identity-
dependentaccessistoassociatewitheachfileanddirectoryanaccess-control
list(ACL)specifyingusernamesandthetypesofaccessallowedforeachuser.
When a user requests access to a particular file, the operating system checks
the access list associated with that file. If that user is listed for the requested
access,theaccessisallowed.Otherwise,aprotectionviolationoccurs,andthe
userjobisdeniedaccesstothefile.
This approach has the advantage of enabling complex access methodolo-
gies. The main problem with access lists is their length. If we want to allow
everyonetoreadafile,wemustlistalluserswithreadaccess.Thistechnique
hastwoundesirableconsequences:
• Constructingsuchalistmaybeatediousandunrewardingtask,especially
ifwedonotknowinadvancethelistofusersinthesystem.
• Thedirectoryentry,previouslyoffixedsize,nowmustbeofvariablesize,
resultinginmorecomplicatedspacemanagement.
These problems can be resolved by use of a condensed version of the access
list.
Tocondense thelengthofthe access-control list,manysystemsrecognize
threeclassificationsofusersinconnectionwitheachfile:
• Owner.Theuserwhocreatedthefileistheowner.
• Group.Asetofuserswhoaresharingthefileandneedsimilaraccessisa
group,orworkgroup.
• Other.Allotherusersinthesystem.
Themostcommonrecentapproachistocombineaccess-controllistswith
themoregeneral(andeasiertoimplement)owner,group,anduniverseaccess-
controlschemejustdescribed.Forexample,Solarisusesthethreecategoriesof
accessbydefaultbutallowsaccess-controlliststobeaddedtospecificfilesand
directorieswhenmorefine-grainedaccesscontrolisdesired.
Toillustrate,consideraperson, Sara,who iswriting anewbook. Shehas
hiredthreegraduatestudents(Jim,Dawn,andJill)tohelpwiththeproject.The
text of the book is kept in a file named book.tex. The protection associated
withthisfileisasfollows:
• Sarashouldbeabletoinvokealloperationsonthefile.
• Jim, Dawn, and Jill should be able only to read and write the file; they
shouldnotbeallowedtodeletethefile.
• All other users should be able to read, but not write, the file. (Sara is
interested in letting as many people as possible read the text so that she
canobtainfeedback.)13.4 Protection 553
PERMISSIONSINAUNIXSYSTEM
In the UNIX system, directory protection and file protection are handled
similarly. Associated with each file and directory are three fields—owner,
group,anduniverse—eachconsistingofthethreebitsrwx,wherercontrols
readaccess,wcontrolswriteaccess,andxcontrolsexecution.Thus,ausercan
listthecontentofasubdirectoryonlyiftherbitissetintheappropriatefield.
Similarly,ausercanchangehiscurrentdirectorytoanothercurrentdirectory
(say,foo)onlyifthexbitassociatedwiththefoosubdirectoryissetinthe
appropriatefield.
AsampledirectorylistingfromaUNIXenvironmentisshowninbelow:
-rw-rw-r-- 1 pbg staff 31200 Sep 3 08:30 intro.ps
drwx------ 5 pbg staff 512 Jul 8 09.33 private/
drwxrwxr-x 2 pbg staff 512 Jul 8 09:35 doc/
drwxrwx--- 2 jwg student 512 Aug 3 14:13 student-proj/
-rw-r--r-- 1 pbg staff 9423 Feb 24 2017 program.c
-rwxr-xr-x 1 pbg staff 20471 Feb 24 2017 program
drwx--x--x 4 tag faculty 512 Jul 31 10:31 lib/
drwx------ 3 pbg staff 1024 Aug 29 06:52 mail/
drwxrwxrwx 3 pbg staff 512 Jul 8 09:35 test/
Thefirstfielddescribestheprotectionofthefileordirectory.Adasthefirst
characterindicatesasubdirectory.Alsoshownarethenumberoflinkstothe
file,theowner’sname,thegroup’sname,thesizeofthefileinbytes,thedate
oflastmodification,andfinallythefile’sname(withoptionalextension).
To achieve such protection, we must create a new group—say, text—
with members Jim, Dawn, and Jill. The name of the group, text, must then
be associated with the file book.tex, and the access rights must be set in
accordancewiththepolicywehaveoutlined.
NowconsideravisitortowhomSarawouldliketogranttemporaryaccess
toChapter1.Thevisitorcannotbeaddedtothetextgroupbecausethatwould
give him access to all chapters. Because a file can be in only one group, Sara
cannot add another group to Chapter 1. With the addition of access-control-
list functionality, though, the visitor can be added to the access control list of
Chapter1.
Forthisschemetoworkproperly,permissionsandaccesslistsmustbecon-
trolledtightly.Thiscontrolcanbeaccomplishedinseveralways.Forexample,
intheUNIXsystem,groupscanbecreatedandmodifiedonlybythemanager
ofthefacility(orbyanysuperuser).Thus,controlisachievedthroughhuman
interaction.AccesslistsarediscussedfurtherinSection17.6.2.
Withthemorelimitedprotectionclassification,onlythreefieldsareneeded
todefineprotection.Often,eachfieldisacollectionofbits,andeachbiteither
allowsorpreventstheaccessassociatedwithit.Forexample,theUNIXsystem
defines three fields of three bits each—rwx, where r controls read access, w
controlswriteaccess,andxcontrolsexecution.Aseparatefieldiskeptforthe554 Chapter13 File-SystemInterface
fileowner,forthefile’sgroup,andforallotherusers.Inthisscheme,ninebits
perfileareneededtorecordprotectioninformation.Thus,forourexample,the
protectionfieldsforthefilebook.texareasfollows:fortheownerSara,allbits
areset;forthegrouptext,therandwbitsareset;andfortheuniverse,only
therbitisset.
Onedifficultyincombiningapproachescomesintheuserinterface.Users
mustbeabletotellwhentheoptionalACLpermissionsaresetonafile.Inthe
Solarisexample,a“+”isappendedtotheregularpermissions,asin:
19 -rw-r--r--+ 1 jim staff 130 May 25 22:13 file1
A separate set of commands, setfacl and getfacl, is used to manage the
ACLs.
Windows users typically manage access-control lists via the GUI. Figure
13.12showsafile-permissionwindowonWindows7NTFSfilesystem.Inthis
example,user“guest”isspecificallydeniedaccesstothefileListPanel.java.
Another difficulty is assigning precedence when permission and ACLs
conflict.Forexample,ifWalterisinafile’sgroup,whichhasreadpermission,
but the file has an ACL granting Walter read and write permission, should a
write by Walter be granted or denied? Solaris and other operating systems
give ACLs precedence(as they are more fine-grained and are not assigned by
default).Thisfollowsthegeneralrulethatspecificityshouldhavepriority.
13.4.3 Other Protection Approaches
Another approach to the protection problem is to associate a password with
each file. Just as access to the computer system is often controlled by a pass-
word, access to each file can be controlled in the same way. If the passwords
arechosenrandomlyandchangedoften,thisschememaybeeffectiveinlim-
itingaccesstoafile.Theuseofpasswordshasafewdisadvantages,however.
First, the number of passwords that a user needs to remember may become
large,makingtheschemeimpractical.Second,ifonlyonepasswordisusedfor
all the files, then once it is discovered,all files are accessible; protection is on
an all-or-none basis.Some systemsallow ausertoassociate apasswordwith
a subdirectory, rather than with an individual file, to address this problem.
More commonly encryption of a partition or individual files provides strong
protection,butpasswordmanagementiskey.
Inamultileveldirectorystructure,weneedtoprotectnotonlyindividual
files but also collections of files in subdirectories; that is, we need to provide
a mechanism for directory protection. The directory operations that must be
protectedaresomewhatdifferentfromthefileoperations.Wewanttocontrol
thecreationanddeletionoffilesinadirectory.Inaddition,weprobablywant
to control whether a user can determine the existence of a file in a directory.
Sometimes, knowledge of the existence and name of a file is significant in
itself. Thus, listing the contents of a directory must be a protected operation.
Similarly,ifapathnamereferstoafileinadirectory,theusermustbeallowed
access to both the directory and the file. In systems where files may have
numerouspathnames(suchasacyclicandgeneralgraphs),agivenusermay
have different access rights to a particular file, depending on the path name
used.13.5 Memory-MappedFiles 555
Figure13.12 Windows10access-controllistmanagement.
13.5 Memory-Mapped Files
There is one other method of accessing files, and it is very commonly used.
Consider a sequential read of a file on disk using the standard system calls
open(),read(),andwrite().Eachfileaccessrequiresasystemcallanddisk
access. Alternatively,we can use the virtual memory techniques discussed in
Chapter10totreatfileI/Oasroutinememoryaccesses.Thisapproach,known
as memory mapping a file, allows a part of the virtual address space to be
logically associated with the file. As we shall see, this can lead to significant
performanceincreases.
13.5.1 Basic Mechanism
Memorymappingafileisaccomplishedbymappingadiskblocktoapage(or
pages)inmemory.Initialaccesstothefileproceedsthroughordinarydemand556 Chapter13 File-SystemInterface
paging, resulting in a page fault. However, a page-sized portion of the file is
readfromthefilesystemintoaphysicalpage(somesystemsmayopttoread
inmorethanapage-sizedchunkofmemoryatatime).Subsequentreadsand
writes to the file are handled as routine memory accesses. Manipulating files
throughmemoryratherthanincurringtheoverheadofusingtheread()and
write()systemcallssimplifiesandspeedsupfileaccessandusage.
Notethat writestothe filemappedinmemoryare not necessarilyimme-
diate(synchronous)writestothefileonsecondarystorage.Generally,systems
update the file based on changes to the memory image only when the file is
closed.Undermemorypressure,systemswillhaveanyintermediatechanges
to swap space to not lose them when freeing memory for other uses. When
the file is closed, all the memory-mapped data are written back to the file on
secondarystorageandremovedfromthevirtualmemoryoftheprocess.
Someoperatingsystemsprovidememorymappingonlythroughaspecific
system call and use the standard system calls to perform all other file I/O.
However,somesystemschoosetomemory-mapafileregardlessofwhetherthe
filewasspecifiedasmemory-mapped.Let’stakeSolarisasanexample.Ifafile
is specified as memory-mapped(using the mmap() systemcall), Solaris maps
the file into the address space of the process. If a file is opened and accessed
usingordinarysystemcalls,suchasopen(),read(),andwrite(),Solarisstill
memory-mapsthefile;however,thefileismappedtothekerneladdressspace.
Regardlessofhowthefileisopened,then,SolaristreatsallfileI/Oasmemory-
mapped,allowingfileaccesstotakeplaceviatheefficientmemorysubsystem
and avoiding system call overhead caused by each traditional read() and
write().
Multiple processes may be allowed to map the same file concurrently, to
allowsharingofdata.Writesbyanyoftheprocessesmodifythedatainvirtual
memory and can be seen by all others that map the same section of the file.
Given our earlier discussions of virtual memory, it should be clear how the
sharing of memory-mapped sections of memory is implemented: the virtual
memory map of each sharing process points to the same page of physical
memory—thepagethatholdsacopyofthediskblock.Thismemorysharingis
illustratedinFigure13.13.Thememory-mappingsystemcallscanalsosupport
copy-on-write functionality, allowing processes to share a file in read-only
mode but to have their own copies of any data they modify. So that access
totheshareddataiscoordinated,theprocessesinvolvedmightuseoneofthe
mechanismsforachievingmutualexclusiondescribedinChapter6.
Quite often, shared memoryis infact implementedby memory mapping
files. Under this scenario, processes can communicate using shared mem-
ory by having the communicating processes memory-map the same file into
their virtual address spaces. The memory-mapped file serves as the region
of shared memory between the communicating processes (Figure 13.14). We
have already seen this in Section 3.5, where a POSIX shared-memory object
is created and each communicating process memory-maps the object into its
address space. In the following section, we discuss support in the Windows
APIforsharedmemoryusingmemory-mappedfiles.
13.5.2 Shared Memory in the Windows API
The general outline for creating a region of shared memory using memory-
mappedfilesintheWindowsAPIinvolvesfirstcreatingafil mappingforthe13.5 Memory-MappedFiles 557
1
2
3
1 4
2 3 5
3 6
4
5 6
6
1
process A process B
5
virtual memory virtual memory
4
2
physical memory
1 2 3 4 5 6
disk file
Figure13.13 Memory-mappedfiles.
filetobemappedandthenestablishingaviewofthemappedfileinaprocess’s
virtual address space. A second process can then open and create a view of
the mapped file in its virtual address space. The mapped file represents the
shared-memoryobject that will enable communication to take place between
theprocesses.
We next illustrate these steps in more detail. In this example, a producer
processfirstcreatesashared-memoryobjectusingthememory-mappingfea-
tures available in the Windows API. The producer then writes a message to
sharedmemory.Afterthat,aconsumerprocessopensamappingtotheshared-
memoryobjectandreadsthemessagewrittenbytheconsumer.
process process
1 2
shared memory-mapped
memory file
shared
memory
shared
memory
Figure13.14 Sharedmemoryusingmemory-mappedI/O.558 Chapter13 File-SystemInterface
To establish a memory-mapped file, a process first opens the file to be
mapped with the CreateFile() function, which returns a HANDLE to the
opened file. The process then creates a mapping of this file HANDLE using the
CreateFileMapping() function. Once the file mapping is done, the process
establishes a view of the mapped file in its virtual address space with the
MapViewOfFile() function. The view of the mapped file represents the por-
tionofthefilebeingmappedinthevirtualaddressspaceoftheprocess—the
entirefileoronlyaportionofitmaybemapped.Thissequenceintheprogram
#include <windows.h>
#include <stdio.h>
int main(int argc, char *argv[])
{
HANDLE hFile, hMapFile;
LPVOID lpMapAddress;
hFile = CreateFile("temp.txt", /* file name */
GENERIC READ | GENERIC WRITE, /* read/write access */
0, /* no sharing of the file */
NULL, /* default security */
OPEN ALWAYS, /* open new or existing file */
FILE ATTRIBUTE NORMAL, /* routine file attributes */
NULL); /* no file template */
hMapFile = CreateFileMapping(hFile, /* file handle */
NULL, /* default security */
PAGE READWRITE, /* read/write access to mapped pages */
0, /* map entire file */
0,
TEXT("SharedObject")); /* named shared memory object */
lpMapAddress = MapViewOfFile(hMapFile, /* mapped object handle */
FILE MAP ALL ACCESS, /* read/write access */
0, /* mapped view of entire file */
0,
0);
/* write to shared memory */
sprintf(lpMapAddress,"Shared memory message");
UnmapViewOfFile(lpMapAddress);
CloseHandle(hFile);
CloseHandle(hMapFile);
}
Figure13.15 ProducerwritingtosharedmemoryusingtheWindowsAPI.13.5 Memory-MappedFiles 559
is shown in Figure 13.15. (We eliminate much of the error checking for code
brevity.)
ThecalltoCreateFileMapping()createsanamedshared-memoryobject
called SharedObject. The consumer process will communicate using this
shared-memory segment by creating a mapping to the same named object.
The producer then creates a view of the memory-mapped file in its virtual
address space. By passing the last three parameters the value 0, it indicates
that the mapped view is the entire file. It could instead have passed values
specifyinganoffsetandsize,thuscreatingaviewcontainingonlyasubsection
of the file.(Itis important tonote that the entiremapping may not be loaded
intomemorywhenthemappingisestablished.Rather,themappedfilemaybe
demand-paged,thus bringing pages into memory only as they are accessed.)
TheMapViewOfFile()functionreturnsapointertotheshared-memoryobject;
anyaccessestothismemorylocationarethusaccessestothememory-mapped
file.Inthisinstance,theproducerprocesswritesthemessage“Shared memory
message”tosharedmemory.
A program illustrating how the consumer process establishes a view of
the named shared-memory object is shown in Figure 13.16. This program is
#include <windows.h>
#include <stdio.h>
int main(int argc, char *argv[])
{
HANDLE hMapFile;
LPVOID lpMapAddress;
hMapFile = OpenFileMapping(FILE MAP ALL ACCESS, /* R/W access */
FALSE, /* no inheritance */
TEXT("SharedObject")); /* name of mapped file object */
lpMapAddress = MapViewOfFile(hMapFile, /* mapped object handle */
FILE MAP ALL ACCESS, /* read/write access */
0, /* mapped view of entire file */
0,
0);
/* read from shared memory */
printf("Read message %s", lpMapAddress);
UnmapViewOfFile(lpMapAddress);
CloseHandle(hMapFile);
}
Figure13.16 ConsumerreadingfromsharedmemoryusingtheWindowsAPI.560 Chapter13 File-SystemInterface
somewhatsimplerthantheoneshowninFigure13.15,asallthatisnecessary
is for the process to create a mapping to the existing named shared-memory
object.The consumer processmust alsocreateaviewof the mappedfile,just
astheproducerprocessdidintheprograminFigure13.15.Theconsumerthen
readsfromsharedmemorythemessage“Shared memory message”thatwas
writtenbytheproducerprocess.
Finally, both processes remove the view of the mapped file with a call to
UnmapViewOfFile(). We provide a programming exercise at the end of this
chapterusingsharedmemorywithmemorymappingintheWindowsAPI.
13.6 Summary
• Afileis anabstract datatypedefinedand implementedby theoperating
system.Itisasequenceoflogicalrecords.Alogicalrecordmaybeabyte,
a line (of fixed or variable length), or a more complex data item. The
operating system may specifically support various record types or may
leavethatsupporttotheapplicationprogram.
• A major task for the operating system is to map the logical file concept
ontophysicalstoragedevicessuchasharddiskor NVMdevice.Sincethe
physicalrecordsizeofthedevicemaynotbethesameasthelogicalrecord
size, it may be necessary to order logical records into physical records.
Again,thistaskmaybesupportedbytheoperatingsystemorleftforthe
applicationprogram.
• Within a file system, it is useful to create directories to allow files to be
organized. Asingle-level directory in a multiuser system causes naming
problems,sinceeachfilemusthaveauniquename.Atwo-leveldirectory
solves this problem by creating a separate directory for each user’s files.
Thedirectoryliststhefilesbynameandincludesthefile’slocationonthe
disk,length,type,owner,timeofcreation,timeoflastuse,andsoon.
• The natural generalization of a two-level directory is a tree-structured
directory.Atree-structureddirectoryallowsausertocreatesubdirectories
toorganize files.Acyclic-graph directorystructures enable usersto share
subdirectoriesand files but complicate searching and deletion.Ageneral
graphstructureallowscompleteflexibilityinthesharingoffilesanddirec-
tories but sometimes requires garbage collection to recover unused disk
space.
• Remote file systems present challenges in reliability, performance, and
security.Distributed information systems maintain user, host, and access
informationsothatclientsandserverscansharestateinformationtoman-
ageuseandaccess.
• Sincefilesarethemaininformation-storagemechanisminmostcomputer
systems, file protection is needed on multiuser systems. Access to files
canbecontrolledseparatelyforeachtypeofaccess—read,write,execute,
append,delete,listdirectory,andsoon.Fileprotectioncanbeprovidedby
accesslists,passwords,orothertechniques.FurtherReading 561
Practice Exercises
13.1 Somesystemsautomaticallydeletealluserfileswhenauserlogsoffor
a job terminates, unless the user explicitly requests that they be kept.
Other systems keep all files unless the user explicitly deletes them.
Discusstherelativemeritsofeachapproach.
13.2 Whydosomesystemskeeptrackofthetypeofafile,whilestillothers
leave it to the user and others simply do not implement multiple file
types?Whichsystemis“better”?
13.3 Similarly, some systems support many types of structures for a file’s
data, while others simply support a stream of bytes. What are the
advantagesanddisadvantagesofeachapproach?
13.4 Couldyousimulateamultileveldirectorystructurewithasingle-level
directorystructureinwhicharbitrarilylongnamescanbeused?Ifyour
answer is yes, explain how you can do so, and contrast this scheme
withthemultileveldirectoryscheme.Ifyouranswerisno,explainwhat
preventsyoursimulation’ssuccess.Howwouldyouranswerchangeif
filenameswerelimitedtosevencharacters?
13.5 Explainthepurposeoftheopen()andclose()operations.
13.6 Insomesystems,asubdirectorycanbereadandwrittenbyanautho-
rizeduser,justasordinaryfilescanbe.
a. Describetheprotectionproblemsthatcouldarise.
b. Suggestaschemefordealingwitheachoftheseprotectionprob-
lems.
13.7 Considerasystemthatsupports5,000users.Supposethatyouwantto
allow4,990oftheseuserstobeabletoaccessonefile.
a. HowwouldyouspecifythisprotectionschemeinUNIX?
b. Canyousuggestanotherprotectionschemethatcanbeusedmore
effectivelyforthispurposethantheschemeprovidedbyUNIX?
13.8 Researchers have suggested that, instead of having an access-control
listassociatedwitheachfile(specifyingwhichuserscanaccessthefile,
andhow),weshouldhaveausercontrollistassociatedwitheachuser
(specifyingwhichfilesausercanaccess,andhow).Discusstherelative
meritsofthesetwoschemes.
Further Reading
AmultileveldirectorystructurewasfirstimplementedontheMULTICSsystem
([Organick(1972)]).Mostoperatingsystemsnowimplementmultileveldirec-
tory structures. These include Linux ([Love (2010)]), macOS ([Singh (2007)]),
Solaris([McDougallandMauro(2007)]),andallversionsofWindows([Russi-
novichetal.(2017)]).562 Chapter13 File-SystemInterface
A general discussion of Solaris file systems is found in the Sun Sys-
tem Administration Guide: Devices and File Systems (http://docs.sun.com/app/
docs/doc/817-5093).
The network file system (NFS), designed by Sun Microsystems, allows
directory structures to be spread across networked computer systems. NFS
Version4isdescribedinRFC3505(http://www.ietf.org/rfc/rfc3530.txt).
Agreatsourceofthemeaningsofcomputerjargonishttp://www.catb.org/
esr/jargon/.
Bibliography
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[McDougallandMauro(2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition,PrenticeHall(2007).
[Organick(1972)] E.I.Organick,TheMulticsSystem:AnExaminationofItsStruc-
ture,MITPress(1972).
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).
[Singh(2007)] A. Singh, Mac OS X Internals: A Systems Approach, Addison-
Wesley(2007).Exercises EX-48
Chapter 13 Exercises
13.9 Considerafilesysteminwhichafilecanbedeletedanditsdiskspace
reclaimedwhilelinkstothatfilestillexist.Whatproblemsmayoccurif
anewfileiscreatedinthesamestorageareaorwiththesameabsolute
pathname?Howcantheseproblemsbeavoided?
13.10 Theopen-filetableisusedtomaintaininformationaboutfilesthatare
currentlyopen.Shouldtheoperatingsystemmaintainaseparatetable
foreachuserormaintainjustonetablethatcontainsreferencestofiles
that arecurrently beingaccessedby allusers?Ifthesame fileisbeing
accessedbytwodifferentprogramsorusers,shouldtherebeseparate
entriesintheopen-filetable?Explain.
13.11 What are the advantages and disadvantages of providing mandatory
locksinsteadofadvisorylockswhoseuseislefttousers’discretion?
13.12 Provide examples of applications that typically access files according
tothefollowingmethods:
• Sequential
• Random
13.13 Somesystemsautomaticallyopenafilewhenitisreferencedforthefirst
timeandclosethefilewhenthejobterminates.Discusstheadvantages
anddisadvantagesofthisschemecomparedwiththemoretraditional
one,wheretheuserhastoopenandclosethefileexplicitly.
13.14 If the operating system knew that a certain application was going
to access file data in a sequential manner, how could it exploit this
informationtoimproveperformance?
13.15 Give an example of an application that could benefit from operating-
systemsupportforrandomaccesstoindexedfiles.
13.16 Some systems provide file sharing by maintaining a single copy of a
file. Other systems maintain several copies, one for each of the users
sharingthefile.Discusstherelativemeritsofeachapproach.14
CHAPTER
File -System
Implementation
As we saw in Chapter 13, the file system provides the mechanism for on-
line storage and access to file contents, including data and programs. File
systemsusuallyresidepermanentlyonsecondarystorage,which isdesigned
toholdalargeamountofdata.Thischapterisprimarilyconcernedwithissues
surrounding file storage and access on the most common secondary-storage
media, hard disk drives and nonvolatile memory devices. We explore ways
to structure file use, to allocate storage space, to recover freed space, to track
the locations of data, and to interface other parts of the operating system to
secondarystorage.Performanceissuesareconsideredthroughoutthechapter.
Agiven general-purpose operating system provides several file systems.
Additionally,manyoperatingsystemsallowadministratorsoruserstoaddfile
systems.Whysomany?Filesystemsvaryinmanyrespects,includingfeatures,
performance,reliability,anddesigngoals,anddifferentfilesystemsmayserve
differentpurposes.Forexample,atemporaryfilesystemisusedforfaststorage
and retrieval of nonpersistent files, while the default secondary storage file
system(suchasLinuxext4)sacrificesperformanceforreliabilityandfeatures.
Aswe’veseenthroughoutthisstudyofoperatingsystems,thereareplentyof
choicesandvariations,makingthoroughcoverageachallenge.Inthischapter,
weconcentrateonthecommondenominators.
CHAPTER OBJECTIVES
• Describethedetailsofimplementinglocalfilesystemsanddirectorystruc-
tures.
• Discussblockallocationandfree-blockalgorithmsandtrade-offs.
• Explorefilesystemefficiencyandperformanceissues.
• Lookatrecoveryfromfilesystemfailures.
• DescribetheWAFLfilesystemasaconcreteexample.
563564 Chapter14 File-SystemImplementation
14.1 File-System Structure
Disks providemostof thesecondary storageon which file systemsaremain-
tained.Twocharacteristicsmakethemconvenientforthispurpose:
1. Adisk can be rewritten in place; it is possible to read a block from the
disk,modifytheblock,andwriteitbackintothesameblock.
2. Adiskcanaccessdirectlyanyblockofinformationitcontains.Thus,itis
simple to access any file either sequentiallyor randomly, and switching
fromonefiletoanotherrequiresthedrivemovingtheread–writeheads
andwaitingforthemediatorotate.
Nonvolatile memory (NVM) devices are increasingly used for file storage
andthusasalocationforfilesystems.Theydifferfromharddisksinthatthey
cannotberewritteninplaceandtheyhavedifferentperformancecharacteris-
tics.WediscussdiskandNVM-devicestructureindetailinChapter11.
ToimproveI/Oefficiency,I/Otransfersbetweenmemoryandmassstorage
are performed in units of blocks. Each block on a hard disk drive has one or
moresectors.Dependingon thediskdrive,sector sizeisusually512bytes or
4,096 bytes. NVM devices usually have blocks of 4,096 bytes, and the transfer
methodsusedaresimilartothoseusedbydiskdrives.
Filesystemsprovideefficientandconvenientaccesstothestoragedevice
byallowingdatatobestored,located,andretrievedeasily.Afilesystemposes
two quite different design problems. The first problem is defining how the
file system should look to the user. This task involves defining a file and its
attributes, the operations allowed on a file, and the directory structure for
organizingfiles.Thesecondproblemiscreatingalgorithmsanddatastructures
tomapthelogicalfilesystemontothephysicalsecondary-storagedevices.
The file system itself is generally composed of many different levels.The
structureshowninFigure14.1isanexampleofalayereddesign.Eachlevelin
the design uses the features of lower levels to create new features for use by
higherlevels.
The I/O control level consists of device drivers and interrupt handlers
to transfer information between the main memory and the disk system. A
device driver can be thought of as a translator. Its input consists of high-
levelcommands,suchas“retrieveblock123.”Itsoutputconsistsoflow-level,
hardware-specificinstructionsthatareusedbythehardwarecontroller,which
interfaces the I/O device to the rest of the system. The device driver usually
writesspecificbitpatternstospeciallocationsintheI/Ocontroller’smemory
totellthecontrollerwhich devicelocationtoactonandwhat actions totake.
ThedetailsofdevicedriversandtheI/OinfrastructurearecoveredinChapter
12.
The basic file system (called the “block I/O subsystem” in Linux) needs
only to issue generic commands to the appropriate devicedriverto readand
write blocks on the storage device. It issues commands to the drive based
on logical block addresses. It is also concerned with I/O request scheduling.
Thislayeralsomanagesthememorybuffersandcachesthatholdvariousfile-
system,directory,anddatablocks.Ablockinthebufferisallocatedbeforethe
transfer of a mass storage block can occur. When the buffer is full, the buffer
manager must find more buffer memory or free up buffer space to allow a14.1 File-SystemStructure 565
application programs
logical file system
file-organization module
basic file system
I/O control
devices
Figure14.1 Layeredfilesystem.
requestedI/Otocomplete.Cachesareusedtoholdfrequentlyusedfile-system
metadata to improve performance, so managing their contents is critical for
optimumsystemperformance.
The file-organizatio module knows about files and their logical blocks.
Each file’s logical blocks are numbered from 0 (or 1) through N. The file-
organizationmodulealsoincludesthefree-spacemanager,whichtracksunal-
locatedblocksandprovidestheseblockstothefile-organizationmodulewhen
requested.
Finally, the logical file system manages metadata information. Metadata
includes all of the file-system structure except the actual data (or contents of
the files). The logical file system manages the directory structure to provide
the file-organization module with the information the latter needs, given a
symbolic file name. It maintains file structure via file-control blocks. A file
controlblock(FCB)(aninodeinUNIXfilesystems)containsinformationabout
thefile,includingownership,permissions,andlocationofthefilecontents.The
logical file system is alsoresponsible for protection, as discussed in Chapters
13and17.
Whenalayeredstructureisusedforfile-systemimplementation,duplica-
tionofcodeisminimized.TheI/Ocontrolandsometimesthebasicfile-system
code can be used by multiple file systems. Each file system can then have its
ownlogicalfile-systemandfile-organizationmodules.Unfortunately,layering
canintroducemoreoperating-systemoverhead,whichmayresultindecreased
performance.Theuseoflayering,includingthedecisionabouthowmanylay-
erstouseandwhateachlayershoulddo,isamajorchallengeindesigningnew
systems.
Many file systems are in use today, and most operating systems support
more than one. For example, most CD-ROMs are written in the ISO 9660 for-
mat, a standard format agreed on by CD-ROM manufacturers. In addition to
removable-media file systems, each operating system has one or more disk-
basedfilesystems.UNIXusestheUNIXfil system(UFS),whichisbasedonthe566 Chapter14 File-SystemImplementation
BerkeleyFastFileSystem(FFS).Windowssupportsdiskfile-systemformatsof
FAT,FAT32,andNTFS(orWindowsNTFileSystem),aswellasCD-ROMandDVD
file-systemformats. Although Linux supportsover 130 different file systems,
the standard Linux file system is known as the extended file system, with
themostcommonversionsbeingext3andext4.Therearealsodistributedfile
systems in which a file system on a server is mounted by one or more client
computersacrossanetwork.
File-system research continues to be an active area of operating-system
design and implementation. Google created its own file system to meet
the company’s specific storage and retrieval needs, which include high-
performance access from many clients across a very large number of disks.
AnotherinterestingprojectistheFUSEfilesystem,whichprovidesflexibilityin
file-systemdevelopmentandusebyimplementingandexecutingfilesystems
as user-levelrather than kernel-levelcode. Using FUSE, a user can add a new
file system to a variety of operating systems and can use that file system to
manageherfiles.
14.2 File-System Operations
AswasdescribedinSection13.1.2,operatingsystemsimplementopen()and
close() systems calls for processes to request access to file contents. In this
section, we delve into the structures and operations used to implement file-
systemoperations.
14.2.1 Overview
Several on-storage and in-memory structures are used to implement a file
system.Thesestructuresvarydependingontheoperatingsystemandthefile
system,butsomegeneralprinciplesapply.
On storage, the file system may contain information about how to boot
anoperatingsystemstoredthere,thetotalnumberofblocks,thenumberand
location of free blocks, the directory structure, and individual files. Many of
these structures are detailed throughout the remainder of this chapter. Here,
wedescribethembriefly:
• Abootcontrolblock(pervolume)cancontaininformationneededbythe
systemtobootanoperatingsystemfromthatvolume.Ifthediskdoesnot
contain an operating system, this block can be empty. It is typically the
firstblockofavolume.InUFS,itiscalledthebootblock.InNTFS,itisthe
partitionbootsector.
• Avolumecontrolblock(pervolume)containsvolumedetails,suchasthe
numberofblocksinthevolume,thesizeoftheblocks,afree-blockcount
andfree-blockpointers,andafree-FCBcountandFCBpointers.InUFS,this
iscalledasuperblock.InNTFS,itisstoredinthemasterfil table.
• Adirectorystructure(perfilesystem)isusedtoorganizethefiles.InUFS,
thisincludesfilenamesandassociatedinodenumbers.InNTFS,itisstored
inthemasterfiletable.14.2 File-SystemOperations 567
• Aper-fileFCBcontainsmanydetailsaboutthefile.Ithasauniqueidentifier
numbertoallowassociationwithadirectoryentry.InNTFS,thisinforma-
tionisactuallystoredwithinthemasterfiletable,whichusesarelational
databasestructure,witharowperfile.
Thein-memoryinformationisusedforbothfile-systemmanagementand
performance improvement via caching. The data are loaded at mount time,
updated during file-system operations, and discarded at dismount. Several
typesofstructuresmaybeincluded.
• An in-memory mount table contains information about each mounted
volume.
• An in-memory directory-structure cache holds the directory information
of recently accessed directories. (For directories at which volumes are
mounted,itcancontainapointertothevolumetable.)
• Thesystem-wideopen-fil tablecontainsacopyofthe FCBofeachopen
file,aswellasotherinformation.
• The per-process open-fil table contains pointers to the appropriate
entries in the system-wide open-file table, as well as other information,
forallfilestheprocesshasopen.
• Buffersholdfile-systemblocks whentheyarebeingreadfromor written
toafilesystem.
To create a new file, a process calls the logical file system. The logical file
system knows the format of the directory structures. To create a new file, it
allocates a new FCB. (Alternatively, if the file-system implementation creates
all FCBs at file-system creation time, an FCB is allocated from the set of free
FCBs.)Thesystemthenreadstheappropriatedirectoryintomemory,updates
itwiththenewfilenameandFCB,andwritesitbacktothefilesystem.Atypical
FCBisshowninFigure14.2.
Someoperatingsystems,includingUNIX,treatadirectoryexactlythesame
as a file—one with a “type” field indicating that it is a directory. Other oper-
file permissions
file dates (create, access, write)
file owner, group, ACL
file size
file data blocks or pointers to file data blocks
Figure14.2 Atypicalfile-controlblock.568 Chapter14 File-SystemImplementation
ating systems, including Windows, implement separate system calls for files
and directories and treat directories as entities separate from files. Whatever
thelargerstructuralissues,thelogicalfilesystemcancallthefile-organization
moduletomapthedirectoryI/Ointostorageblocklocations,whicharepassed
ontothebasicfilesystemandI/Ocontrolsystem.
14.2.2 Usage
Nowthat afile has beencreated,itcan beusedfor I/O. First,though, itmust
be opened. The open() call passes a file name to the logical file system. The
open()systemcallfirstsearchesthesystem-wideopen-filetabletoseeifthefile
isalreadyinusebyanotherprocess.Ifitis,aper-processopen-filetableentryis
createdpointingtotheexistingsystem-wideopen-filetable.Thisalgorithmcan
savesubstantialoverhead.Ifthefileisnotalreadyopen,thedirectorystructure
issearchedforthegivenfilename.Partsofthedirectorystructureareusually
cached in memory to speed directory operations. Once the file is found, the
FCBiscopiedintoasystem-wideopen-filetableinmemory.Thistablenotonly
storestheFCBbutalsotracksthenumberofprocessesthathavethefileopen.
Next, an entry is made in the per-process open-file table, with a pointer
to the entry in the system-wide open-file table and some other fields. These
otherfieldsmayincludeapointertothecurrentlocationinthefile(forthenext
read() or write()operation)and the access modein which the file is open.
The open() call returns a pointer to the appropriate entry in the per-process
file-system table. All file operations are then performed via this pointer. The
file name may not be part of the open-file table, as the system has no use for
it once the appropriate FCB is located on disk. It could be cached, though, to
save time on subsequent opens of the same file. The name given to the entry
varies. UNIX systems refer to it as a fil descriptor; Windows refers to it as a
fil handle.
Whenaprocessclosesthefile,theper-processtableentryisremoved,and
thesystem-wideentry’sopencountisdecremented.Whenallusersthathave
openedthefilecloseit,anyupdatedmetadataarecopiedbacktothedisk-based
directorystructure,andthesystem-wideopen-filetableentryisremoved.
The caching aspects of file-system structures should not be overlooked.
Mostsystemskeepallinformationaboutanopenfile,exceptforitsactualdata
blocks,inmemory.TheBSDUNIXsystemistypicalinitsuseofcacheswherever
diskI/Ocanbesaved.Itsaveragecachehitrateof85percentshowsthatthese
techniques are well worth implementing. The BSD UNIX system is described
fullyinAppendixC.
Theoperatingstructuresofafile-systemimplementationaresummarized
inFigure14.3.
14.3 Directory Implementation
The selection of directory-allocation and directory-management algorithms
significantly affects the efficiency, performance, and reliability of the file sys-
tem.Inthissection,wediscussthetrade-offsinvolvedinchoosingoneofthese
algorithms.14.3 DirectoryImplementation 569
directory structure
open (file name)
directory structure
file-control block
user space kernel memory secondary storage
(a)
index
data blocks
read (index)
per-process system-wide file-control block
open-file table open-file table
user space kernel memory secondary storage
(b)
Figure14.3 In-memoryfile-systemstructures.(a)Fileopen.(b)Fileread.
14.3.1 Linear List
The simplestmethod of implementing a directory is to use a linear list of file
names with pointers to the data blocks. This method is simple to program
but time-consuming to execute. To create a new file, we must first search the
directorytobesurethatnoexistingfilehasthesamename.Then,weaddanew
entryattheendofthedirectory.Todeleteafile,wesearchthedirectoryforthe
named file and then release the space allocated to it. To reuse the directory
entry, we can do one of several things. We can mark the entry as unused (by
assigningitaspecialname,suchasanall-blankname,assigningitaninvalid
inodenumber(suchas0),orbyincludingaused–unusedbitineachentry),or
wecanattachittoalistoffreedirectoryentries.Athirdalternativeistocopy
thelastentryinthedirectoryintothefreedlocationandtodecreasethelength
ofthedirectory.Alinkedlistcanalsobeusedtodecreasethetimerequiredto
deleteafile.
The real disadvantage of a linear list of directory entries is that finding a
filerequiresalinearsearch.Directoryinformationisusedfrequently,andusers
will notice if access to it is slow. In fact, many operating systems implement
a software cache to store the most recently used directory information. A
cachehitavoidstheneedtoconstantlyrereadtheinformationfromsecondary
storage.Asortedlistallowsabinarysearchanddecreasestheaveragesearch
time. However, the requirement that the list be kept sorted may complicate
creatinganddeletingfiles,sincewemayhavetomovesubstantialamountsof570 Chapter14 File-SystemImplementation
directoryinformationtomaintainasorteddirectory.Amoresophisticatedtree
datastructure, such as a balanced tree,might help here.An advantage of the
sortedlististhatasorteddirectorylistingcanbeproducedwithoutaseparate
sortstep.
14.3.2 Hash Table
Anotherdatastructureusedforafiledirectoryisahashtable.Here,alinearlist
storesthedirectoryentries,butahashdatastructureisalsoused.Thehashtable
takesavaluecomputedfromthefilenameandreturnsapointertothefilename
in the linear list. Therefore, it can greatly decrease the directory search time.
Insertionanddeletionarealsofairlystraightforward,althoughsomeprovision
must be made for collisions—situations in which two file names hash to the
samelocation.
Themajordifficultieswithahashtableareitsgenerallyfixedsizeandthe
dependence of the hash function on that size. For example, assume that we
makealinear-probinghashtablethatholds64entries.Thehashfunctioncon-
vertsfilenamesintointegersfrom0to63(forinstance,byusingtheremainder
ofadivisionby64).Ifwelatertrytocreatea65thfile,wemustenlargethedirec-
toryhashtable—say,to128entries.Asaresult,weneedanewhashfunction
that must map file names to the range 0 to 127, and we must reorganize the
existingdirectoryentriestoreflecttheirnewhash-functionvalues.
Alternatively,we can use a chained-overflowhash table. Each hash entry
canbealinkedlistinsteadofanindividualvalue,andwecanresolvecollisions
byaddingthenewentrytothelinkedlist.Lookupsmaybesomewhatslowed,
because searching for a name might require stepping through a linked list of
collidingtableentries.Still,thismethodislikelytobemuchfasterthanalinear
searchthroughtheentiredirectory.
14.4 Allocation Methods
Thedirect-accessnatureofsecondarystoragegivesusflexibilityintheimple-
mentation of files. In almost every case, many files are stored on the same
device.Themainproblemishowtoallocatespacetothesefilessothatstorage
spaceisutilizedeffectivelyandfilescanbeaccessedquickly.Threemajormeth-
odsofallocatingsecondarystoragespaceareinwideuse:contiguous,linked,
andindexed.Eachmethodhasadvantagesanddisadvantages.Althoughsome
systemssupportallthree,itismorecommonforasystemtouseonemethod
forallfileswithinafile-systemtype.
14.4.1 Contiguous Allocation
Contiguousallocationrequiresthateachfileoccupyasetofcontiguousblocks
onthedevice.Deviceaddressesdefinealinearorderingonthedevice.Withthis
ordering,assumingthatonlyonejobisaccessingthedevice,accessingblockb
+1afterblockbnormallyrequiresnoheadmovement.Whenheadmovement
is needed (from the last sector of one cylinder to the first sector of the next
cylinder),theheadneedonlymovefromonetracktothenext.Thus,forHDDs,
thenumberofdiskseeksrequiredforaccessingcontiguouslyallocatedfilesis14.4 AllocationMethods 571
directory
file start length
count
0 1 2 3 count 0 2
f tr 14 3
4 5 6 7 mail 19 6
list 28 4
8 9 10 11
f 6 2
tr
12 13 14 15
16 17 18 19
mail
20 21 22 23
24 25 26 27
list
28 29 30 31
Figure14.4 Contiguousallocationofdiskspace.
minimal(assumingblockswithcloselogicaladdressesareclosephysically),as
isseektimewhenaseekisfinallyneeded.
Contiguous allocation of a file is defined by the address of the first block
and length (in block units) of the file. If the file is n blocks long and starts at
locationb,thenitoccupiesblocksb,b+1,b+2,...,b+n−1.Thedirectoryentry
foreachfileindicatestheaddressofthestartingblockandthelengthofthearea
allocatedforthisfile(Figure14.4).Contiguousallocationiseasytoimplement
buthaslimitations,andisthereforenotusedinmodernfilesystems.
Accessingafilethathasbeenallocatedcontiguouslyiseasy.Forsequential
access,thefilesystemrememberstheaddressofthelastblockreferencedand,
whennecessary,readsthe next block. For directaccess toblock i ofafile that
startsatblockb,wecanimmediatelyaccessblockb+i.Thus,bothsequential
anddirectaccesscanbesupportedbycontiguousallocation.
Contiguousallocationhassomeproblems,however.Onedifficultyisfind-
ing space for a new file. The system chosen to manage free space determines
how this task is accomplished; these management systems are discussed in
Section14.5.Anymanagementsystemcanbeused,butsomeareslowerthan
others.
Thecontiguous-allocationproblemcanbeseenasaparticularapplication
of the general dynamic storage-allocation problem discussed in Section 9.2,
whichinvolveshowtosatisfyarequestofsizenfromalistoffreeholes.First
fit and best fit are the most common strategiesusedtoselectafreehole from
thesetofavailableholes.Simulationshaveshownthatbothfirstfitandbestfit
aremoreefficient than worst fit intermsof both timeand storageutilization.
Neitherfirstfitnorbestfitisclearlybestintermsofstorageutilization,butfirst
fitisgenerallyfaster.
Allthesealgorithmssufferfromtheproblemofexternalfragmentation.As
filesareallocatedanddeleted,thefreestoragespaceisbrokenintolittlepieces.572 Chapter14 File-SystemImplementation
External fragmentation exists whenever free space is broken into chunks. It
becomes a problem when the largest contiguous chunk is insufficient for a
request;storage is fragmentedinto a number of holes, none of which is large
enoughtostorethedata.Dependingonthetotalamountofdiskstorageandthe
averagefilesize,externalfragmentationmaybeaminororamajorproblem.
Onestrategyforpreventinglossofsignificantamountsofstoragespaceto
external fragmentation is to copy an entire file system onto another device.
The original device is then freed completely, creating one large contiguous
free space. We then copy the files back onto the original device by allocating
contiguous space from this one large hole. This scheme effectively compacts
all free space into one contiguous space, solving the fragmentation problem.
Thecostofthiscompactionistime,however,andthecostcanbeparticularly
highforlargestoragedevices.Compactingthesedevicesmaytakehoursand
may be necessary on a weekly basis. Some systems require that this function
be done off-line, with the file system unmounted. During this down time,
normalsystemoperationgenerallycannotbepermitted,sosuchcompactionis
avoidedatallcostsonproductionmachines.Mostmodernsystemsthatneed
defragmentationcanperformiton-lineduringnormalsystemoperations,but
theperformancepenaltycanbesubstantial.
Another problem with contiguous allocation is determining how much
space is needed for a file. When the file is created, the total amount of space
it will need must be found and allocated. How does the creator (program or
person)knowthesizeofthefiletobecreated?Insomecases,thisdetermina-
tion may be fairly simple (copying an existing file, for example). In general,
however,thesizeofanoutputfilemaybedifficulttoestimate.
If we allocate too little space to a file, we may find that the file cannot
be extended. Especially with a best-fit allocation strategy, the space on both
sidesofthefilemaybeinuse.Hence,wecannotmakethefilelargerinplace.
Two possibilities then exist. First, the user program can be terminated, with
an appropriate error message. The user must then allocate more space and
run the program again. These repeated runs may be costly. To prevent them,
theuserwill normallyoverestimatetheamount ofspace needed,resultingin
considerable wastedspace.The other possibilityis tofind alargerhole,copy
the contents of the file to the new space, and releasethe previousspace. This
series of actions can be repeated as long as space exists, although it can be
time consuming. The user need never be informed explicitly about what is
happening,however;thesystemcontinuesdespitetheproblem,althoughmore
andmoreslowly.
Even if the total amount of space needed for a file is known in advance,
preallocationmaybeinefficient.Afilethatwillgrowslowlyoveralongperiod
(monthsoryears)mustbeallocatedenoughspaceforitsfinalsize,eventhough
muchofthatspacewillbeunusedforalongtime.Thefilethereforehasalarge
amountofinternalfragmentation.
To minimize these drawbacks, an operating system can use a modified
contiguous-allocation scheme.Here,acontiguous chunk ofspaceisallocated
initially.Then,ifthatamountprovesnottobelargeenough,anotherchunkof
contiguousspace,knownasanextent,isadded.Thelocationofafile’sblocks
is then recorded as a location and a block count, plus a link to the first block
of the next extent. On some systems, the owner of the file can set the extent
size, but this setting results in inefficiencies if the owner is incorrect. Internal14.4 AllocationMethods 573
fragmentation can still be a problem if the extents are too large, and external
fragmentationcanbecomeaproblemasextentsofvaryingsizesareallocated
and deallocated. The commercial Symantec Veritas file system uses extents
to optimize performance. Veritas is a high-performance replacement for the
standardUNIXUFS.
14.4.2 Linked Allocation
Linked allocation solves all problems of contiguous allocation. With linked
allocation,eachfileisalinkedlistofstorageblocks;theblocksmaybescattered
anywhere on the device. The directory contains a pointer to the first and last
blocks of the file. For example, a file of five blocks might start at block 9 and
continue at block 16, then block 1, then block 10, and finally block 25 (Figure
14.5). Each block contains a pointer to the next block. These pointers are not
madeavailabletotheuser.Thus,ifeachblockis512bytesinsize,andablock
address(thepointer)requires4bytes,thentheuserseesblocksof508bytes.
To create a new file, we simply create a new entry in the directory. With
linked allocation, each directory entry has a pointer to the first block of the
file.Thispointerisinitializedtonull(theend-of-listpointervalue)tosignify
anemptyfile.Thesizefieldisalsosetto0.Awritetothefilecausesthefree-
space management system to find a free block, and this new block is written
toandislinkedtotheendofthefile.Toreadafile,wesimplyreadblocksby
followingthepointersfromblocktoblock.Thereisnoexternalfragmentation
withlinkedallocation,andanyfreeblockonthefree-spacelistcanbeusedto
satisfyarequest.Thesizeofafileneednotbedeclaredwhenthefileiscreated.
Afilecancontinuetogrowaslongasfreeblocksareavailable.Consequently,
itisnevernecessarytocompactdiskspace.
Linkedallocation doeshave disadvantages,however. The major problem
isthatitcanbeusedeffectivelyonlyforsequential-accessfiles.Tofindtheith
directory
file start end
jeep 9 25
0 1 2 3
4 5 6 7
8 9 10 11
12 13 14 15
16 17 18 19
20 21 22 23
24 25 26 27
28 29 30 31
Figure14.5 Linkedallocationofdiskspace.574 Chapter14 File-SystemImplementation
blockofafile,wemuststartatthebeginningofthatfileandfollowthepointers
untilwegettotheithblock.Eachaccesstoapointerrequiresastoragedevice
read,andsomerequireanHDDseek.Consequently,itisinefficienttosupport
adirect-accesscapabilityforlinked-allocationfiles.
Another disadvantage is the space required for the pointers. If a pointer
requires4bytesout ofa512-byte block, then 0.78percentof thediskis being
usedforpointers,ratherthanforinformation.Eachfilerequiresslightlymore
spacethanitwouldotherwise.
Theusualsolutiontothisproblemistocollectblocksintomultiples,called
clusters,andtoallocateclustersratherthanblocks.Forinstance,thefilesystem
may define a cluster as four blocks and operate on the secondary storage
device only in cluster units. Pointers then use a much smaller percentage of
the file’s space. This method allows the logical-to-physical block mapping to
remainsimplebutimprovesHDDthroughput(becausefewerdisk-headseeks
arerequired)anddecreasesthespaceneededforblockallocationandfree-list
management.Thecostofthisapproachisanincreaseininternalfragmentation,
becausemorespaceiswastedwhenaclusterispartiallyfullthanwhenablock
ispartiallyfull.AlsorandomI/Operformance suffersbecause arequestfora
small amount of data transfers a large amount of data. Clusters can be used
toimprovethedisk-accesstimeformanyotheralgorithmsaswell,sotheyare
usedinmostfilesystems.
Yet another problem of linked allocation is reliability. Recall that the files
arelinkedtogetherbypointersscatteredalloverthedevice,andconsiderwhat
wouldhappenifapointerwaslostordamaged.Abugintheoperating-system
software or a hardware failure might result in picking up the wrong pointer.
Thiserrorcouldinturnresultinlinkingintothefree-spacelistorintoanother
file. One partial solution is to use doubly linked lists, and another is to store
thefilenameandrelativeblocknumberineachblock.However,theseschemes
requireevenmoreoverheadforeachfile.
An important variation on linked allocation is the use of a file-allocatio
table(FAT).Thissimplebutefficientmethodofdisk-spaceallocationwasused
bytheMS-DOSoperatingsystem.Asectionofstorageatthebeginningofeach
volumeissetasidetocontainthetable.Thetablehasoneentryforeachblock
and is indexed by block number. The FAT is used in much the same way as
a linked list. The directory entry contains the block number of the first block
of the file. The table entry indexed by that block number contains the block
numberofthenextblockinthefile.Thischaincontinuesuntilitreachesthelast
block,whichhasaspecialend-of-filevalueasthetableentry.Anunusedblock
is indicated by a table value of 0. Allocating a new block to a file is a simple
matteroffindingthefirst0-valuedtableentryandreplacingthepreviousend-
of-filevaluewiththeaddressofthenewblock.The0isthenreplacedwiththe
end-of-filevalue.AnillustrativeexampleistheFATstructureshowninFigure
14.6forafileconsistingofdiskblocks217,618,and339.
TheFATallocationschemecanresultinasignificant numberofdiskhead
seeks, unless the FAT is cached. The disk head must move to the start of the
volume to read the FAT and find the location of the block in question, then
movetothelocationoftheblockitself.Intheworstcase,bothmovesoccurfor
eachof theblocks. Abenefitis that random-access timeis improved,because
thediskheadcanfindthelocationofanyblockbyreadingtheinformationin
theFAT.14.4 AllocationMethods 575
directory entry
test • • • 217
name start block
0
217 618
339
618 339
number of disk blocks –1
FAT
Figure14.6 File-allocationtable.
14.4.3 Indexed Allocation
Linkedallocationsolvestheexternal-fragmentationandsize-declarationprob-
lemsofcontiguousallocation.However,intheabsenceofaFAT,linkedalloca-
tioncannot supportefficientdirectaccess,sincethepointerstotheblocks are
scattered with the blocks themselves all over the disk and must be retrieved
in order. Indexed allocation solves this problem by bringing all the pointers
togetherintoonelocation:theindexblock.
Each file has its own index block, which is an array of storage-block
addresses. The ith entry in the index block points to the ith block of the file.
Thedirectorycontainstheaddressoftheindexblock(Figure14.7).Tofindand
readtheithblock,weusethepointerintheithindex-blockentry.Thisscheme
issimilartothepagingschemedescribedinSection9.3.
When the file is created, all pointers in the index block are set to null.
When the ith block is first written, a block is obtained from the free-space
manager,anditsaddressisputintheithindex-blockentry.
Indexedallocationsupportsdirectaccess,withoutsufferingfromexternal
fragmentation, because any free block on the storage device can satisfy a
request for more space. Indexed allocation does suffer from wasted space,
however.Thepointeroverheadoftheindexblockisgenerallygreaterthanthe
pointer overhead of linked allocation. Consider a common case in which we
haveafileofonlyoneortwoblocks.Withlinkedallocation,welosethespace
of only one pointer per block. With indexed allocation, an entire index block
mustbeallocated,evenifonlyoneortwopointerswillbenon-null.
Thispointraisesthequestionofhowlargetheindexblockshouldbe.Every
file must have an index block, so we want the index block to be as small as576 Chapter14 File-SystemImplementation
directory
file index block
jeep 19
0 1 2 3
4 5 6 7
8 9 10 11
9
16
12 13 14 15
1
10
16 17 18 19 19
25
–1
20 21 22 23 –1
–1
24 25 26 27
28 29 30 31
Figure14.7 Indexedallocationofdiskspace.
possible. If the index block is too small, however, it will not be able to hold
enoughpointersforalargefile,andamechanismwillhavetobeavailableto
dealwiththisissue.Mechanismsforthispurposeincludethefollowing:
• Linkedscheme.Anindexblockisnormallyonestorageblock.Thus,itcan
be readand writtendirectlyby itself.Toallow for largefiles,we can link
togetherseveralindexblocks.Forexample,anindexblockmightcontaina
smallheadergivingthenameofthefileandasetofthefirst100disk-block
addresses.Thenextaddress(thelastwordintheindexblock)isnull(for
asmallfile)orisapointertoanotherindexblock(foralargefile).
• Multilevelindex.Avariantoflinkedrepresentationusesafirst-levelindex
blocktopointtoasetofsecond-levelindexblocks,whichinturnpointto
thefile blocks. Toaccess ablock, the operatingsystemusesthefirst-level
indextofindasecond-levelindexblockandthenusesthatblocktofindthe
desireddatablock.Thisapproachcouldbecontinuedtoathirdorfourth
level,dependingonthedesiredmaximumfilesize.With4,096-byteblocks,
we could store 1,024 four-byte pointers in an index block. Two levels of
indexesallow1,048,576datablocksandafilesizeofupto4GB.
• Combinedscheme.Anotheralternative,usedinUNIX-basedfilesystems,
is to keep the first, say, 15 pointers of the index block in the file’s inode.
The first 12 of these pointers point to direct blocks; that is, they contain
addresses of blocks that contain data of the file. Thus, the data for small
files(ofnomorethan12blocks)donotneedaseparateindexblock.Ifthe
blocksizeis4KB,thenupto48KBofdatacanbeaccesseddirectly.Thenext
threepointerspointtoindirectblocks.Thefirstpointstoasingleindirect
block, which is an index block containing not data but the addresses of
blocksthatdocontaindata.Thesecondpointstoadoubleindirectblock,
whichcontainstheaddressofablockthatcontainstheaddressesofblocks
thatcontainpointerstotheactualdatablocks.Thelastpointercontainsthe
addressofatripleindirectblock.(AUNIXinodeisshowninFigure14.8.)14.4 AllocationMethods 577
file
metadata
data
direct blocks
data
data
single indirect
blocks
data
double indirect
blocks
triple indirect
blocks
.
.
.
data
data
data
data
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. .
.
.
.
.
. .
.
. .
.
.
. data
data
data
data
data
data
data
data
Figure14.8 TheUNIXinode.
Underthismethod,thenumberofblocksthatcanbeallocatedtoafile
exceeds the amount of space addressableby the 4-byte file pointers used
by many operating systems. A 32-bit file pointer reaches only 232 bytes,
or 4 GB. Many UNIX and Linux implementations now support 64-bit file
pointers,whichallowsfilesandfilesystemstobeseveralexbibytesinsize.
TheZFSfilesystemsupports128-bitfilepointers.
Indexed-allocation schemes suffer from some of the same performance
problemsasdoeslinkedallocation.Specifically,theindexblockscanbecached
inmemory,butthedatablocksmaybespreadalloveravolume.
14.4.4 Performance
Theallocationmethodsthatwehavediscussedvaryintheirstorageefficiency
anddata-blockaccesstimes.Bothareimportantcriteriainselectingtheproper
methodormethodsforanoperatingsystemtoimplement.
Before selecting an allocation method, we need to determine how the
systems will be used. Asystem with mostly sequential access should not use
thesamemethodasasystemwithmostlyrandomaccess.
For any type of access, contiguous allocation requires only one access to
getablock.Sincewecaneasilykeeptheinitialaddressofthefileinmemory,
we can calculate immediately the address of the ith block (or the next block)
andreaditdirectly.
For linked allocation, we can also keep the address of the next block in
memoryandreaditdirectly.Thismethodisfineforsequentialaccess;fordirect
access, however, an access to the ith block might require i block reads. This578 Chapter14 File-SystemImplementation
problemindicateswhylinkedallocationshouldnotbeusedforanapplication
requiringdirectaccess.
As a result, some systems support direct-access files by using contiguous
allocation and sequential-access files by using linked allocation. For these
systems,thetypeofaccesstobemademustbedeclaredwhenthefileiscreated.
Afilecreatedforsequentialaccesswillbelinkedandcannotbeusedfordirect
access.Afilecreatedfordirectaccesswillbecontiguousandcansupportboth
directaccessandsequentialaccess,butitsmaximumlengthmustbedeclared
when it is created. In this case, the operating system must have appropriate
datastructuresandalgorithmstosupportbothallocationmethods.Filescanbe
convertedfromonetypetoanotherbythecreationofanewfileofthedesired
type, into which the contents of the old file are copied. The old file may then
bedeletedandthenewfilerenamed.
Indexedallocationismorecomplex.Iftheindexblockisalreadyinmem-
ory, then the access can be made directly. However, keeping the index block
in memory requires considerable space. If this memory space is not avail-
able, then we may have to read first the index block and then the desired
data block. For a two-level index, two index-block reads might be necessary.
For an extremely large file, accessing a block near the end of the file would
require reading in all the index blocks before the needed data block finally
could be read. Thus, the performance of indexed allocation depends on the
indexstructure,onthesizeofthefile,andonthepositionoftheblockdesired.
Some systems combine contiguous allocation with indexed allocation by
usingcontiguousallocationforsmallfiles(uptothreeorfourblocks)andauto-
maticallyswitchingtoanindexedallocationifthefilegrowslarge.Sincemost
files are small, and contiguous allocation is efficient for small files, average
performancecanbequitegood.
Many other optimizations are in use. Given the disparity between CPU
speedanddiskspeed,itisnotunreasonabletoaddthousandsofextrainstruc-
tions to the operating system to save just a few disk-head movements. Fur-
thermore, this disparity is increasing over time, to the point where hundreds
ofthousandsofinstructionscouldreasonablybeusedtooptimizeheadmove-
ments.
For NVM devices, there are no disk head seeks, so different algorithms
andoptimizationsareneeded.UsinganoldalgorithmthatspendsmanyCPU
cyclestryingtoavoidanonexistentheadmovementwouldbeveryinefficient.
Existingfilesystemsarebeingmodifiedandnewonesbeingcreatedtoattain
maximum performance from NVM storage devices. These developments aim
to reduce the instruction count and overall path between the storage device
andapplicationaccesstothedata.
14.5 Free-Space Management
Since storage space is limited, we need to reuse the space from deleted files
fornewfiles,ifpossible.(Write-onceopticaldisksallowonlyonewritetoany
given sector, and thus reuse is not physically possible.) To keep track of free
disk space, the system maintains a free-space list. The free-space list records
allfreedeviceblocks—thosenotallocatedtosomefileordirectory.Tocreatea
file,wesearchthefree-spacelistfortherequiredamountofspaceandallocate14.5 Free-SpaceManagement 579
thatspacetothenewfile.Thisspaceisthenremovedfromthefree-spacelist.
When a file is deleted,itsspace is addedto the free-space list. The free-space
list, despite its name, is not necessarily implemented as a list, as we discuss
next.
14.5.1 Bit Vector
Frequently,the free-spacelistis implementedas a bitmap or bit vector. Each
block is represented by 1 bit. If the block is free, the bit is 1; if the block is
allocated,thebitis0.
Forexample,consideradiskwhereblocks2,3,4,5,8,9,10,11,12,13,17,
18,25,26,and27arefreeandtherestoftheblocksareallocated.Thefree-space
bitmapwouldbe
001111001111110001100000011100000 ...
The main advantageofthis approach is itsrelativesimplicityand itseffi-
ciency in finding the first free block or n consecutive free blocks on the disk.
Indeed,manycomputerssupplybit-manipulationinstructionsthatcanbeused
effectively for that purpose. One technique for finding the first free block on
a system that uses a bit vector to allocate space is to sequentially check each
word in the bitmap to see whether that value is not 0, since a 0-valued word
contains only 0 bits and represents a set of allocated blocks. The first non-0
wordis scanned for thefirst 1bit,which isthelocation ofthe firstfreeblock.
Thecalculationoftheblocknumberis
(numberofbitsperword)×(numberof0-valuewords)+offsetoffirst1bit.
Again, we see hardware featuresdrivingsoftware functionality. Unfortu-
nately,bitvectorsareinefficientunlesstheentirevectoriskeptinmainmemory
(andiswrittentothedevicecontainingthefilesystemoccasionallyforrecov-
eryneeds).Keepingitinmainmemoryispossibleforsmallerdevicesbutnot
necessarily for larger ones. A1.3-GB disk with 512-byte blocks would need a
bitmapofover332KBtotrackitsfreeblocks,althoughclusteringtheblocksin
groupsoffourreducesthisnumbertoaround83KBperdisk.A1-TBdiskwith
4-KB blocks would require 32 MB (240 / 212 = 228 bits = 225 bytes = 25 MB) to
storeitsbitmap.Giventhatdisksizeconstantlyincreases,theproblemwithbit
vectorswillcontinuetoescalateaswell.
14.5.2 Linked List
Another approach to free-space management is to link together all the free
blocks, keepinga pointerto the first freeblock in aspecial location inthe file
system and caching it in memory. This first block contains a pointer to the
nextfreeblock,andsoon.Recallourearlierexample(Section14.5.1),inwhich
blocks 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17, 18, 25, 26, and 27 were free and the
restoftheblockswereallocated.Inthissituation,wewouldkeepapointerto
block2asthefirstfreeblock.Block2wouldcontainapointertoblock3,which
would point to block 4, which would point to block 5, which would point to
block 8, and so on (Figure 14.9). This scheme is not efficient; to traverse the
list, we must read each block, which requires substantial I/O time on HDDs.
Fortunately,however,traversingthefreelistisnot afrequentaction. Usually,580 Chapter14 File-SystemImplementation
free-space list head
0 1 2 3
4 5 6 7
8 9 10 11
12 13 14 15
16 17 18 19
20 21 22 23
24 25 26 27
28 29 30 31
Figure14.9 Linkedfree-spacelistondisk.
theoperatingsystemsimplyneedsafreeblocksothatitcanallocatethatblock
toafile,sothefirstblockinthefreelistisused.TheFATmethodincorporates
free-blockaccountingintotheallocationdatastructure.Noseparatemethodis
needed.
14.5.3 Grouping
Amodification of the free-list approach stores the addresses of n free blocks
in the first free block. The first n−1 of these blocks are actually free. The last
blockcontainstheaddressesofanothernfreeblocks,andsoon.Theaddresses
ofalargenumberoffreeblockscannowbefoundquickly,unlikethesituation
whenthestandardlinked-listapproachisused.
14.5.4 Counting
Anotherapproachtakesadvantageofthefactthat,generally,severalcontigu-
ousblocksmaybeallocatedorfreedsimultaneously,particularlywhenspace
is allocated with the contiguous-allocation algorithm or through clustering.
Thus, rather than keeping a list of n free block addresses, we can keep the
addressofthefirstfreeblockandthenumber(n)offreecontiguousblocksthat
followthefirstblock.Eachentryinthefree-spacelistthenconsistsofadevice
address and a count. Although each entry requires more space than would a
simplediskaddress,theoveralllistisshorter,aslongasthecountisgenerally
greater than 1. Note that this method of tracking free space is similar to the
extent method of allocating blocks. These entries can be stored in a balanced
tree,ratherthanalinkedlist,forefficientlookup,insertion,anddeletion.14.5 Free-SpaceManagement 581
14.5.5 Space Maps
Oracle’s ZFS file system (found in Solaris and some other operating systems)
was designed to encompass huge numbers of files, directories, and even file
systems(inZFS, we can createfile-systemhierarchies).Onthesescales, meta-
data I/O can have a large performance impact. Consider, for example, that if
thefree-spacelistisimplementedasabitmap,bitmapsmustbemodifiedboth
whenblocks areallocatedandwhentheyarefreed.Freeing1GBofdataona
1-TBdiskcould cause thousands of blocks ofbitmaps to be updated,because
those data blocks could be scattered over the entire disk. Clearly, the data
structuresforsuchasystemcouldbelargeandinefficient.
In its management of free space, ZFS uses a combination of techniques to
control the size of data structures and minimize the I/O needed to manage
thosestructures.First,ZFScreatesmetaslabstodividethespaceonthedevice
into chunks of manageable size. A given volume may contain hundreds of
metaslabs.Eachmetaslabhasanassociatedspacemap.ZFSusesthecounting
algorithm to store information about free blocks. Rather than write counting
structurestodisk,ituseslog-structuredfile-systemtechniquestorecordthem.
The space map is a log of all block activity (allocating and freeing), in time
order, in counting format. When ZFS decides to allocate or free space from a
metaslab, it loads the associated space map into memory in a balanced-tree
structure (for very efficient operation), indexed by offset, and replays the log
intothat structure.Thein-memoryspace mapisthenanaccurate representa-
tionoftheallocatedandfreespaceinthemetaslab.ZFSalsocondensesthemap
as much as possible by combining contiguous free blocks into a single entry.
Finally,thefree-spacelistisupdatedondiskaspartofthetransaction-oriented
operationsofZFS.Duringthecollectionandsortingphase,blockrequestscan
stilloccur,andZFSsatisfiestheserequestsfromthelog.Inessence,thelogplus
thebalancedtreeisthefreelist.
14.5.6 TRIMing Unused Blocks
HDDsandotherstoragemediathatallowblockstobeoverwrittenforupdates
needonlythefreelistformanagingfreespace.Blocksdonotneedtobetreated
specially when freed. Afreed block typically keeps its data (but without any
filepointerstotheblock)untilthedataareoverwrittenwhentheblockisnext
allocated.
Storage devices that do not allow overwrite, such as NVM flash-based
storage devices,suffer badly when these same algorithms are applied.Recall
from Section 11.1.2 that such devices must be erased before they can again
be written to, and that those erases must be made in large chunks (blocks,
composed of pages) and take a relatively long time compared with reads or
writes.
Anewmechanismisneededtoallowthefilesystemtoinformthestorage
devicethatapageisfreeandcanbeconsideredforerasure(oncetheblockcon-
tainingthepageisentirelyfree).Thatmechanismvariesbasedonthestorage
controller.ForATA-attacheddrives,itisTRIM,whileforNVMe-basedstorage,it
istheunallocatecommand.Whateverthespecificcontrollercommand,this
mechanismkeepsstoragespaceavailableforwriting.Withoutsuchacapabil-
ity,thestoragedevicegetsfullandneedsgarbagecollectionandblockerasure,
leadingtodecreasesinstorageI/Owriteperformance(knownas“awritecliff”).582 Chapter14 File-SystemImplementation
WiththeTRIMmechanismandsimilarcapabilities,thegarbagecollectionand
erase steps can occur before the device is nearly full, allowing the device to
providemoreconsistentperformance.
14.6 Efficiency and Performance
Now that we have discussed various block-allocation and directory-
management options, we can further consider their effect on performance
andefficientstorageuse.Diskstendtorepresentamajorbottleneckinsystem
performance,sincetheyaretheslowestmaincomputercomponent.EvenNVM
devicesareslowcomparedwithCPUandmainmemory,sotheirperformance
must be optimizedas well.In this section, we discussa varietyoftechniques
usedtoimprovetheefficiencyandperformanceofsecondarystorage.
14.6.1 Efficiency
The efficient use of storage device space depends heavily on the allocation
and directory algorithms in use. For instance, UNIX inodes are preallocated
onavolume.Evenanemptydiskhasapercentageofitsspacelosttoinodes.
However,bypreallocatingtheinodesandspreadingthemacrossthevolume,
weimprovethefilesystem’sperformance.Thisimprovedperformanceresults
from the UNIX allocation and free-spacealgorithms,which try tokeepa file’s
datablocksnearthatfile’sinodeblocktoreduceseektime.
As another example, let’s reconsider the clustering scheme discussed in
Section14.4,whichimprovesfile-seekandfile-transferperformanceatthecost
of internal fragmentation. To reduce this fragmentation, BSD UNIX varies the
cluster size as a file grows. Large clusters are used where they can be filled,
and small clusters are used for small files and the last cluster of a file. This
systemisdescribedinAppendixC.
The types of data normally kept in a file’s directory (or inode) entry also
require consideration. Commonly, a “last write date” is recorded to supply
informationtotheuserand todeterminewhether the fileneedstobe backed
up. Somesystems alsokeepa “last access date,”sothat a usercan determine
when the file was last read. The result of keeping this information is that,
wheneverthefileisread,afieldinthedirectorystructuremustbewrittento.
That means the block must be read into memory, a section changed, and the
blockwrittenbackouttothedevice,becauseoperationsonsecondarystorage
occuronlyinblock(orcluster)chunks.Soanytimeafileisopenedforreading,
itsFCBmustbereadandwrittenaswell.Thisrequirementcanbeinefficientfor
frequentlyaccessedfiles,sowemustweighitsbenefitagainstitsperformance
costwhendesigningafilesystem.Generally,everydataitemassociatedwith
afileneedstobeconsideredforitseffectonefficiencyandperformance.
Consider,forinstance,howefficiencyisaffectedbythesizeofthepointers
usedtoaccessdata.Mostsystemsuseeither32-bitor64-bitpointersthrough-
outtheoperatingsystem.Using32-bitpointerslimitsthesizeofafileto232,or4
GB.Using64-bitpointersallowsverylargefilesizes,but64-bitpointersrequire
more space to store. As a result, the allocation and free-space-management
methods(linkedlists,indexes,andsoon)usemorestoragespace.14.6 Efficienc andPerformance 583
Oneofthedifficultiesinchoosingapointersize—or,indeed,anyfixedallo-
cationsizewithinanoperatingsystem—isplanningfortheeffectsofchanging
technology.ConsiderthattheIBMPCXThada10-MBharddriveandanMS-DOS
FAT file system that could support only 32 MB. (Each FAT entry was 12 bits,
pointing to an 8-KB cluster.) As disk capacities increased, larger disks had to
be split into 32-MB partitions, because the file system could not track blocks
beyond32MB.Asharddiskswithcapacitiesofover100MBbecamecommon,
thediskdatastructuresandalgorithmsinMS-DOShadtobemodifiedtoallow
larger file systems. (Each FAT entry was expanded to 16 bits and later to 32
bits.) The initial file-system decisions were made for efficiency reasons; how-
ever, with the advent of MS-DOS Version 4, millions of computer users were
inconveniencedwhentheyhadtoswitchtothenew,largerfilesystem.Solaris’s
ZFSfilesystemuses128-bitpointers,whichtheoreticallyshouldneverneedto
beextended.(Theminimummassofadevicecapableofstoring2128bytesusing
atomic-levelstoragewouldbeabout272trillionkilograms.)
As another example, consider the evolution of the Solaris operating sys-
tem.Originally,manydatastructureswereoffixedlength,allocatedatsystem
startup. These structures included the process table and the open-file table.
Whentheprocesstablebecamefull,nomoreprocessescouldbecreated.When
thefiletablebecamefull,nomorefilescouldbeopened.Thesystemwouldfail
toprovideservicestousers.Tablesizescouldbeincreasedonlybyrecompiling
the kernel and rebooting the system. With later releases of Solaris, (as with
modernLinuxkernels)almostallkernelstructureswereallocateddynamically,
eliminatingtheseartificiallimitsonsystemperformance.Ofcourse,thealgo-
rithms that manipulate these tables are more complicated, and the operating
system is a little slower because it must dynamically allocate and deallocate
tableentries;butthatpriceistheusualoneformoregeneralfunctionality.
14.6.2 Performance
Even after the basic file-system algorithms have been selected, we can still
improveperformanceinseveralways.AswasdiscussedinChapter12,storage
devicecontrollersincludelocalmemorytoformanon-boardcachethatislarge
enough to store entire tracks or blocks at a time. On an HDD, once a seek is
performed,thetrackisreadintothediskcachestartingatthesectorunderthe
diskhead(reducinglatencytime).Thediskcontrollerthentransfersanysector
requeststotheoperatingsystem.Onceblocksmakeitfromthediskcontroller
intomainmemory,theoperatingsystemmaycachetheblocksthere.
Some systems maintain a separate section of main memory for a buffer
cache, where blocks are kept under the assumption that they will be used
again shortly. Other systems cache file data using a page cache. The page
cache uses virtual memory techniques to cache file data as pages rather than
asfile-system-orientedblocks.Cachingfiledatausingvirtualaddressesisfar
moreefficientthancachingthroughphysicaldiskblocks,asaccessesinterface
withvirtualmemoryratherthan thefile system.Severalsystems—including
Solaris,Linux,and Windows—use pagecaching tocache both processpages
andfiledata.Thisisknownasunifie virtualmemory.
Some versions of UNIX and Linux provide a unifie buffer cache. To
illustratethebenefitsoftheunifiedbuffercache,considerthetwoalternatives584 Chapter14 File-SystemImplementation
I/O using
memory-mapped I/O
read( ) and write( )
page cache
buffer cache
file system
Figure14.10 I/Owithoutaunifiedbuffercache.
for opening and accessing a file. One approach is to use memory mapping
(Section 13.5); the second is to use the standard system calls read() and
write().Withoutaunifiedbuffercache,wehaveasituationsimilartoFigure
14.10.Here,theread()andwrite()systemcallsgothroughthebuffercache.
The memory-mapping call, however, requires using two caches—the page
cache and the buffer cache. Amemory mapping proceeds by reading in disk
blocks from the file system and storing them in the buffer cache. Because the
virtualmemorysystemdoesnotinterfacewiththebuffercache,thecontentsof
thefileinthebuffercachemustbecopiedintothepagecache.Thissituation,
known as double caching, requires caching file-system data twice. Not only
doesthiswastememorybutitalsowastessignificantCPUandI/Ocyclesdue
totheextradatamovementwithinsystemmemory.Inaddition,inconsistencies
betweenthetwocachescanresultincorruptfiles.Incontrast,whenaunified
buffercacheisprovided,bothmemorymappingandtheread()andwrite()
systemcallsusethesamepagecache.Thishasthebenefitofavoidingdouble
caching,anditallowsthevirtualmemorysystemtomanagefile-systemdata.
TheunifiedbuffercacheisshowninFigure14.11.
Regardless of whether we are caching storage blocks or pages (or both),
least recently used (LRU) (Section 10.4.4) seems a reasonable general-purpose
algorithmforblockorpagereplacement.However,theevolutionoftheSolaris
page-cachingalgorithmsrevealsthedifficultyinchoosinganalgorithm.Solaris
allowsprocessesandthepagecachetoshareunusedmemory.Versionsearlier
than Solaris 2.5.1 made no distinction between allocating pages to a process
andallocatingthemtothepagecache.Asaresult,asystemperformingmany
I/Ooperationsusedmostoftheavailablememoryforcachingpages.Because
of the high rates of I/O, the page scanner (Section 10.10.3) reclaimed pages
from processes—rather than from the page cache—when free memory ran
low.Solaris2.6andSolaris7optionallyimplementedprioritypaging,inwhich
thepagescannergaveprioritytoprocesspagesoverthepagecache.Solaris8
appliedafixedlimittoprocesspagesandthefile-systempagecache,prevent-14.6 Efficienc andPerformance 585
I/O using
memory-mapped I/O
read( ) and write( )
buffer cache
file system
Figure14.11 I/Ousingaunifiedbuffercache.
ingeitherfromforcingtheotheroutofmemory.Solaris9and10againchanged
thealgorithmstomaximizememoryuseandminimizethrashing.
Another issue that can affect the performance of I/O is whether writes to
the file system occur synchronously or asynchronously. Synchronous writes
occur in the order in which the storage subsystem receives them, and the
writes are not buffered. Thus, the calling routine must wait for the data to
reach the drive before it can proceed. In an asynchronous write, the data
are stored in the cache, and control returns to the caller. Most writes are
asynchronous.However,metadatawrites,amongothers,canbesynchronous.
Operating systems frequently include a flag in the open system call to allow
a process to request that writes be performed synchronously. For example,
databases use this feature for atomic transactions, to assure that data reach
stablestorageintherequiredorder.
Some systems optimize their page cache by using different replacement
algorithms,dependingontheaccesstypeofthefile.Afilebeingreadorwritten
sequentially should not have its pages replaced in LRU order, because the
most recently used page will be used last, or perhaps never again. Instead,
sequential access can be optimized by techniques known as free-behind and
read-ahead. Free-behind removes a page from the buffer as soon as the next
page is requested. The previous pages are not likely to be used again and
wastebufferspace.Withread-ahead,arequestedpageandseveralsubsequent
pages are read and cached. These pages are likely to be requested after the
currentpageisprocessed.Retrievingthesedatafrom thediskinonetransfer
andcaching themsavesaconsiderableamountoftime.Onemightthinkthat
a track cache on the controller would eliminate the need for read-ahead on a
multiprogrammedsystem.However,becauseofthehighlatencyandoverhead
involvedinmakingmanysmalltransfersfromthetrackcachetomainmemory,
performingaread-aheadremainsbeneficial.
Thepagecache,thefilesystem,andthedevicedrivershavesomeinterest-
ing interactions. When small amounts of data are written to a file, the pages
arebufferedinthecache,andthestoragedevicedriversortsitsoutputqueue
accordingtodeviceaddress.Thesetwoactionsallowadiskdrivertominimize
disk-headseeks.Unlesssynchronouswritesarerequired,aprocesswritingto
disk simply writes into the cache, and the system asynchronously writes the586 Chapter14 File-SystemImplementation
data to disk when convenient. The user process sees very fast writes. When
data are read from a disk file, the block I/O system does some read-ahead;
however, writes are much more nearly asynchronous than are reads. Thus,
outputtothediskthroughthefilesystemisoftenfasterthanisinputforsmall
transfers, counter tointuition. No matterhow much buffering and caching is
available, large, continuous I/O can overrun the capacity and end up bottle-
necked on the device’s performance. Consider writing a large movie file to a
HDD. If the file is larger than the page cache (or the part of the page cache
available to the process)then the page cache will fill and all I/O will occur at
drivespeed.CurrentHDDs readfaster than they write, soin this instance the
performanceaspectsarereversedfromsmallerI/Operformance.
14.7 Recovery
Filesanddirectoriesarekeptbothinmainmemoryandonthestoragevolume,
andcaremustbetakentoensurethatasystemfailuredoesnotresultinlossof
dataorindatainconsistency.Asystemcrashcancauseinconsistenciesamong
on-storagefile-systemdatastructures,suchasdirectorystructures,free-block
pointers, and free FCB pointers. Many file systems apply changes to these
structures in place. A typical operation, such as creating a file, can involve
manystructuralchangeswithinthefilesystemonthedisk.Directorystructures
aremodified,FCBsareallocated,datablocksareallocated,andthefreecounts
for all of these blocks are decreased. These changes can be interrupted by a
crash, and inconsistencies among the structures can result. For example, the
freeFCBcountmightindicatethatanFCBhadbeenallocated,butthedirectory
structuremightnotpointtotheFCB.Compoundingthisproblemisthecaching
thatoperatingsystemsdotooptimizeI/Operformance.Somechangesmaygo
directlytostorage, while others may be cached. If the cached changes donot
reachthestoragedevicebeforeacrashoccurs,morecorruptionispossible.
In addition to crashes, bugs in file-system implementation, device con-
trollers,andevenuserapplicationscancorruptafilesystem.Filesystemshave
varying methods to deal with corruption, depending on the file-system data
structuresandalgorithms.Wedealwiththeseissuesnext.
14.7.1 Consistency Checking
Whateverthecauseofcorruption,afilesystemmustfirstdetecttheproblems
and then correct them. For detection, a scan of all the metadata on each file
systemcanconfirmordenytheconsistencyofthesystem.Unfortunately,this
scancantakeminutesorhoursandshouldoccureverytimethesystemboots.
Alternatively,afilesystemcanrecorditsstatewithinthefile-systemmetadata.
At the start of any metadata change, a status bit is set to indicate that the
metadataisinflux.Ifallupdatestothemetadatacompletesuccessfully,thefile
systemcanclearthatbit.If,however,thestatusbitremainsset,aconsistency
checkerisrun.
The consistency checker—a systems program such as fsck in UNIX—
compares the data in the directory structure and other metadata with the
state on storage and tries to fix any inconsistencies it finds. The allocation
and free-space-management algorithms dictate what types of problems the14.7 Recovery 587
checker can find and how successful it will be in fixing them. For instance,
if linked allocation is used and there is a link from any block to its next
block, then the entire file can be reconstructed from the data blocks, and the
directory structure can be recreated. In contrast, the loss of a directory entry
on an indexed allocation system can be disastrous, because the data blocks
have no knowledge of one another. For this reason, some UNIX file systems
cachedirectoryentriesforreads,butanywritethatresultsinspaceallocation,
or other metadata changes, is done synchronously, before the corresponding
data blocks are written. Of course, problems can still occur if a synchronous
writeisinterruptedbyacrash.SomeNVMstoragedevicescontainabatteryor
supercapacitor to provide enough power, even during a power loss, to write
datafromdevicebufferstothestoragemediasothedataarenotlost.Buteven
thoseprecautionsdonotprotectagainstcorruptionduetoacrash.
14.7.2 Log-Structured File Systems
Computer scientists often find that algorithms and technologies originally
used in one area are equally useful in other areas. Such is the case with the
databaselog-basedrecoveryalgorithms.Theseloggingalgorithmshavebeen
applied successfully to the problem of consistency checking. The resulting
implementationsareknownaslog-basedtransaction-oriented(orjournaling)
filesystems.
Note that with the consistency-checking approach discussed in the pre-
ceding section, we essentially allow structures to break and repair them on
recovery.However,thereareseveralproblemswiththisapproach.Oneisthat
the inconsistency may be irreparable. The consistency check may not be able
to recover the structures, resulting in loss of files and even entire directories.
Consistencycheckingcanrequirehumaninterventiontoresolveconflicts,and
thatisinconvenientifnohumanisavailable.Thesystemcanremainunavail-
ableuntil the human tellsit how toproceed.Consistency checking alsotakes
systemandclocktime.Tocheckterabytesofdata,hoursofclocktimemaybe
required.
The solutiontothis problem istoapply log-basedrecoverytechniquesto
file-system metadata updates. Both NTFS and the Veritas file system use this
method,anditisincludedinrecentversionsofUFSonSolaris.Infact,itisnow
commononmanyfilesystemsincludingext3,ext4,andZFS.
Fundamentally, all metadata changes are written sequentially to a log.
Each set of operations for performing a specific task is a transaction. Once
the changes are written to this log, they are considered to be committed,
and the system call can return to the user process, allowing it to continue
execution. Meanwhile, these log entries are replayed across the actual file-
system structures. As the changes are made, a pointer is updated to indicate
whichactionshavecompletedandwhicharestillincomplete.Whenanentire
committed transaction is completed, and entry is made in the log indicating
that.Thelogfileisisactuallyacircularbuffer.Acircularbufferwritestothe
endofitsspaceandthencontinuesatthebeginning,overwritingoldervalues
as it goes. We would not want the buffer to write over data that had not yet
beensaved,sothatscenarioisavoided.Thelogmaybeinaseparatesectionof
thefilesystemorevenonaseparatestoragedevice.588 Chapter14 File-SystemImplementation
If the system crashes, the log file will contain zero or more transactions.
Anytransactionsitcontainswerenotcompletedtothefilesystem,eventhough
theywerecommittedbytheoperatingsystem,sotheymustnowbecompleted.
The transactions can be executedfromthe pointeruntil the work iscomplete
so that the file-system structures remain consistent. The only problem occurs
whenatransactionwasaborted—thatis,wasnotcommittedbeforethesystem
crashed. Any changes from such a transaction that were applied to the file
system must be undone, again preserving the consistency of the file system.
Thisrecoveryisallthatisneededafteracrash,eliminatinganyproblemswith
consistencychecking.
A side benefit of using logging on disk metadata updates is that those
updates proceed much faster than when they are applied directly to the on-
disk data structures. The reason is found in the performance advantage of
sequential I/O over random I/O. The costly synchronous random metadata
writes are turned into much less costly synchronous sequential writes to the
log-structuredfilesystem’sloggingarea.Thosechanges,inturn,arereplayed
asynchronously via random writes to the appropriate structures. The overall
result is a significant gain in performance of metadata-oriented operations,
suchasfilecreationanddeletion,onHDDstorage.
14.7.3 Other Solutions
Another alternative to consistency checking is employed by Network Appli-
ance’s WAFL file system and the Solaris ZFS file system. These systems never
overwriteblockswithnewdata.Rather,atransactionwritesalldataandmeta-
data changes to new blocks. When the transaction is complete, the metadata
structuresthatpointedtotheoldversionsoftheseblocksareupdatedtopoint
to the new blocks. The file system can then remove the old pointers and the
old blocks and make them available for reuse. If the old pointers and blocks
are kept, a snapshot is created; the snapshot is a view of the file system at a
specific point in time (before any updates after that time were applied). This
solutionshouldrequirenoconsistencycheckingifthepointerupdateisdone
atomically. WAFL does have a consistency checker, however, so some failure
scenarios can still cause metadata corruption. (See Section 14.8 for details of
theWAFLfilesystem.)
ZFStakesanevenmoreinnovativeapproachtodiskconsistency.LikeWAFL,
itneveroverwritesblocks.However,ZFSgoesfurtherandprovideschecksum-
ming of all metadata and data blocks. This solution (when combined with
RAID) assures that data are always correct. ZFS therefore has no consistency
checker.(MoredetailsonZFSarefoundinSection11.8.6.)
14.7.4 Backup and Restore
Storagedevicessometimesfail,andcaremustbetakentoensurethatthedata
lostinsuchafailurearenotlostforever.Tothisend,systemprogramscanbe
used to back up data from one storage device to another, such as a magnetic
tapeorothersecondarystoragedevice.Recoveryfromthelossofanindividual
file, or of an entire device, may then be a matter of restoring the data from
backup.
Tominimizethecopyingneeded,wecanuseinformationfromeachfile’s
directory entry. For instance, if the backup program knows when the last14.8 Example:TheWAFLFileSystem 589
backupofafilewasdone,andthefile’slastwritedateinthedirectoryindicates
that the file has not changed since that date, then the file does not needto be
copiedagain.Atypicalbackupschedulemaythenbeasfollows:
• Day1.Copytoabackupmediumallfilesfromthefilesystem.Thisiscalled
afullbackup.
• Day 2. Copy to another medium all files changed since day 1. This is an
incrementalbackup.
• Day3.Copytoanothermediumallfileschangedsinceday2.
...
• DayN.CopytoanothermediumallfileschangedsincedayN−1.Thengo
backtoday1.
Thenewcyclecanhaveitsbackupwrittenovertheprevioussetorontoanew
setofbackupmedia.
Usingthismethod,wecanrestoreanentirefilesystembystartingrestores
withthefullbackupandcontinuingthrougheachoftheincrementalbackups.
Ofcourse,thelargerthevalueofN,thegreaterthenumberofmediathatmust
bereadforacompleterestore.Anaddedadvantageofthisbackupcycleisthat
wecanrestoreany fileaccidentallydeletedduringthecyclebyretrievingthe
deletedfilefromthebackupofthepreviousday.
The length of the cycle is a compromise between the amount of backup
neededandthenumberofdayscoveredbyarestore.Todecreasethenumber
oftapesthatmustbereadtodoarestore,anoptionistoperformafullbackup
andtheneachdaybackupallfilesthathavechangedsincethefullbackup.In
thisway,arestorecanbedoneviathemostrecentincrementalbackupandthe
full backup, with no other incremental backups needed. The trade-off is that
more files will be modified each day, so each successive incremental backup
involvesmorefilesandmorebackupmedia.
Auser may notice that a particular file is missing or corrupted long after
the damage was done. For this reason, we usually plan to take a full backup
from time to time that will be saved“forever.”It is a good ideato store these
permanent backups far away from the regular backups to protect against
hazard, such as a fire that destroys the computer and all the backups too. In
the TV show “Mr. Robot,” hackers not only attacked the primary sources of
banks’ data but also their backup sites. Having multiple backup sites might
notbeabadideaifyourdataareimportant.
14.8 Example: The WAFL File System
Becausesecondary-storageI/Ohassuchahugeimpactonsystemperformance,
file-systemdesignandimplementationcommandquitealotofattentionfrom
system designers. Some file systems are general purpose, in that they can
provide reasonable performance and functionality for a wide variety of file
sizes, file types, and I/O loads. Others are optimized for specific tasks in an
attempt to provide better performance in those areas than general-purpose590 Chapter14 File-SystemImplementation
file systems. The write-anywhere file layout (WAFL) from NetApp, Inc. is an
example of this sort of optimization. WAFL is a powerful, elegant file system
optimizedforrandomwrites.
WAFLisusedexclusivelyonnetworkfileserversproducedbyNetAppand
is meant for use as a distributedfile system. It can provide files to clients via
theNFS,CIFS,iSCSI,ftp,andhttpprotocols,althoughitwasdesignedjustfor
NFS and CIFS. When many clients use these protocols to talk to a file server,
theservermayseeaverylargedemandforrandomreadsandanevenlarger
demandforrandomwrites.The NFSand CIFSprotocols cache datafrom read
operations,sowritesareofthegreatestconcerntofile-servercreators.
WAFL is used on file servers that include an NVRAM cache for writes.
The WAFL designers took advantage of running on a specific architecture to
optimize the file system for random I/O, with a stable-storage cache in front.
EaseofuseisoneoftheguidingprinciplesofWAFL.Itscreatorsalsodesignedit
toincludeanewsnapshotfunctionalitythatcreatesmultipleread-onlycopies
ofthefilesystematdifferentpointsintime,asweshallsee.
The file system is similar to the Berkeley Fast File System, with many
modifications. It is block-based and uses inodes to describe files. Each inode
contains16pointerstoblocks(orindirectblocks)belongingtothefiledescribed
bytheinode.Eachfilesystemhasarootinode.Allofthemetadatalivesinfiles.
All inodes are in one file, the free-block map in another, and the free-inode
mapinathird,asshowninFigure14.12.Becausethesearestandardfiles,the
data blocks are not limited in location and can be placed anywhere. If a file
systemisexpandedbyadditionofdisks,thelengthsofthemetadatafilesare
automaticallyexpandedbythefilesystem.
Thus, a WAFL file system is a tree of blocks with the root inode as its
base. To take a snapshot, WAFL creates a copy of the root inode. Any file or
metadata updates after that go to new blocks rather than overwriting their
existingblocks.Thenewrootinodepointstometadataanddatachangedasa
resultofthesewrites.Meanwhile,thesnapshot(theoldrootinode)stillpoints
totheoldblocks,whichhavenotbeenupdated.Itthereforeprovidesaccessto
thefilesystemjustasitwasattheinstantthesnapshotwasmade—andtakes
very little storage space to do so. In essence, the extra space occupied by a
snapshotconsistsofjusttheblocksthathavebeenmodifiedsincethesnapshot
wastaken.
root inode (cid:129)(cid:129)(cid:129)
inode file (cid:129)(cid:129)(cid:129)
free block map free inode map file in the file system... (cid:129)(cid:129)(cid:129)
Figure14.12 TheWAFLfilelayout.14.8 Example:TheWAFLFileSystem 591
Animportantchangefrommorestandardfilesystemsisthatthefree-block
map has more than one bit per block. It is a bitmap with a bit set for each
snapshotthatisusingtheblock.Whenallsnapshotsthathavebeenusingthe
blockaredeleted,thebitmapforthatblockisallzeros,andtheblockisfreeto
bereused.Usedblocksareneveroverwritten,sowritesareveryfast,because
awritecanoccuratthefreeblocknearestthecurrentheadlocation.Thereare
manyotherperformanceoptimizationsinWAFLaswell.
Many snapshots can exist simultaneously, so one can be taken each hour
of the day and each day of the month, for example. A user with access to
thesesnapshotscanaccessfilesastheywereatanyofthetimesthesnapshots
weretaken.Thesnapshotfacilityisalsousefulforbackups,testing,versioning,
and so on. WAFL’s snapshot facility is very efficient in that it does not even
requirethatcopy-on-writecopiesofeachdatablockbetakenbeforetheblock
is modified. Other file systems provide snapshots, but frequently with less
efficiency.WAFLsnapshotsaredepictedinFigure14.13.
Newer versions of WAFL actually allow read–write snapshots, known as
clones. Clones are also efficient, using the same techniques as shapshots. In
thiscase,aread-onlysnapshotcapturesthestateofthefilesystem,andaclone
refers back to that read-only snapshot. Any writes to the clone are stored in
new blocks, and the clone’s pointers are updated to refer to the new blocks.
Theoriginalsnapshotisunmodified,stillgivingaviewintothefilesystemas
root inode
block A B C D E
(a) Before a snapshot.
root inode new snapshot
block A B C D E
(b) After a snapshot, before any blocks change.
root inode new snapshot
block A B C D E D´
(c) After block D has changed to D´.
Figure14.13 SnapshotsinWAFL.592 Chapter14 File-SystemImplementation
THEAPPLEFILESYSTEM
In2017,Apple,Inc.,releasedanewfilesystemtoreplaceits30-year-oldHFS+
filesystem.HFS+hadbeenstretchedtoaddmanynewfeatures,butasusual,
this process added complexity, along with lines of code, and made adding
morefeaturesmoredifficult.Startingfromscratchonablankpageallowsa
designtostartwithcurrenttechnologiesandmethodologiesandprovidethe
exactsetoffeaturesneeded.
Apple File System (APFS) is a good example of such a design. Its goal
is to run on all current Apple devices, from the Apple Watch through the
iPhonetotheMaccomputers.CreatingafilesystemthatworksinwatchOS,
I/Os,tvOS,andmacOSiscertainlyachallenge.APFSisfeature-rich,including
64-bitpointers,clonesforfilesanddirectories,snapshots,spacesharing,fast
directorysizing,atomicsafe-saveprimitives,copy-on-writedesign,encryp-
tion(single-andmulti-key),andI/Ocoalescing.ItunderstandsNVMaswell
asHDDstorage.
Mostofthesefeatureswe’vediscussed,butthereareafewnewconcepts
worthexploring.SpacesharingisaZFS-likefeatureinwhichstorageisavail-
able as one or more large free spaces (containers) from which file systems
candrawallocations(allowingAPFS-formattedvolumestogrowandshrink).
Fast directory sizing provides quick used-space calculation and updating.
Atomic safe-save is a primitive (available via API, not via file-system com-
mands) that performs renames of files, bundles of files, and directories as
singleatomicoperations.I/OcoalescingisanoptimizationforNVMdevices
in which several small writes are gathered together into a large write to
optimizewriteperformance.
Apple chose not to implement RAID as part of the new APFS, instead
dependingontheexistingAppleRAIDvolumemechanismforsoftwareRAID.
APFS is also compatible with HFS+, allowing easy conversion for existing
deployments.
it was before the clone was updated. Clones can also be promoted to replace
theoriginalfilesystem;thisinvolvesthrowing outalloftheoldpointersand
any associated old blocks. Clones are useful for testing and upgrades, as the
originalversionisleftuntouchedandtheclonedeletedwhenthetestisdone
oriftheupgradefails.
AnotherfeaturethatnaturallyresultsfromtheWAFLfilesystemimplemen-
tationisreplication,theduplicationandsynchronizationofasetofdataovera
networktoanothersystem.First,asnapshotofaWAFLfilesystemisduplicated
to another system. When another snapshot is taken on the source system, it
is relativelyeasy to update the remotesystem just by sending over all blocks
contained in the new snapshot. These blocks are the ones that have changed
betweenthetimesthetwosnapshotsweretaken.Theremotesystemaddsthese
blockstothefilesystemandupdatesitspointers,andthenewsystemthenisa
duplicateofthesourcesystemasofthetimeofthesecondsnapshot.Repeating
thisprocessmaintainstheremotesystemasanearlyup-to-datecopyofthefirst
system.Such replicationisusedfor disasterrecovery.Shouldthe first system
bedestroyed,mostofitsdataareavailableforuseontheremotesystem.14.9 Summary 593
Finally,notethattheZFSfilesystemsupportssimilarlyefficientsnapshots,
clones, and replication, and those features are becoming more common in
variousfilesystemsastimegoesby.
14.9 Summary
• Mostfilesystemsresideonsecondarystorage,whichisdesignedtoholda
large amount of data permanently.The most common secondary-storage
mediumisthedisk,buttheuseofNVMdevicesisincreasing.
• Storagedevicesaresegmentedintopartitionstocontrolmediauseandto
allowmultiple,possiblyvarying,filesystemsonasingledevice.Thesefile
systemsaremountedontoalogicalfilesystemarchitecturetomakethem
availableforuse.
• File systems are often implemented in a layered or modular structure.
Thelowerlevelsdealwiththephysicalpropertiesofstoragedevicesand
communicatingwiththem.Upperlevelsdealwithsymbolicfilenamesand
logicalpropertiesoffiles.
• Thevariousfileswithinafilesystemcanbeallocatedspaceonthestorage
device in three ways: through contiguous, linked, or indexed allocation.
Contiguous allocation can suffer from external fragmentation. Direct
access is very inefficient with linked allocation. Indexed allocation may
require substantial overhead for its index block. These algorithms can
be optimized in many ways. Contiguous space can be enlarged through
extents to increase flexibility and to decrease external fragmentation.
Indexed allocation can be done in clusters of multiple blocks to increase
throughput and to reduce the number of index entries needed. Indexing
inlargeclustersissimilartocontiguousallocationwithextents.
• Free-space allocation methods also influence the efficiency of disk-space
use, the performance of the file system, and the reliability of secondary
storage.Themethodsusedincludebitvectorsandlinkedlists.Optimiza-
tionsincludegrouping,counting,andtheFAT,whichplacesthelinkedlist
inonecontiguousarea.
• Directory-management routines must consider efficiency, performance,
and reliability.Ahash table is a commonly used method, as it is fast and
efficient.Unfortunately,damagetothetableorasystemcrashcanresultin
inconsistencybetweenthedirectoryinformationandthedisk’scontents.
• A consistency checker can be used to repair damaged file-system struc-
tures.Operating-systembackuptoolsallowdatatobecopiedtomagnetic
tape or other storagedevices,enabling the user torecoverfrom dataloss
orevenentiredevicelossduetohardwarefailure,operatingsystembug,
orusererror.
• Due to the fundamental role that file systems play in system operation,
theirperformanceandreliabilityarecrucial.Techniquessuchaslogstruc-
tures and caching help improve performance, while log structures and
RAIDimprovereliability.TheWAFLfilesystemisanexampleofoptimiza-
tionofperformancetomatchaspecificI/Oload.594 Chapter14 File-SystemImplementation
Practice Exercises
14.1 Consider a file currently consisting of 100 blocks. Assume that the
file-control block (and the index block, in the case of indexed alloca-
tion) is already in memory. Calculate how many disk I/O operations
are required for contiguous, linked, and indexed (single-level)alloca-
tion strategies, if, for one block, the following conditions hold. In the
contiguous-allocationcase,assumethatthereisnoroomtogrowatthe
beginning but there is room to grow at the end. Also assume that the
blockinformationtobeaddedisstoredinmemory.
a. Theblockisaddedatthebeginning.
b. Theblockisaddedinthemiddle.
c. Theblockisaddedattheend.
d. Theblockisremovedfromthebeginning.
e. Theblockisremovedfromthemiddle.
f. Theblockisremovedfromtheend.
14.2 Whymustthebitmapforfileallocationbekeptonmassstorage,rather
thaninmainmemory?
14.3 Consider a system that supports the strategies of contiguous, linked,
andindexedallocation.Whatcriteriashouldbeusedindecidingwhich
strategyisbestutilizedforaparticularfile?
14.4 Oneproblemwithcontiguousallocationisthattheusermustpreallo-
cate enough space for each file. If the file grows to be larger than the
space allocated for it, special actions must be taken. One solution to
this problem is to define a file structure consisting of an initial con-
tiguous areaofaspecifiedsize.Ifthis areais filled,the operatingsys-
temautomaticallydefinesanoverflowareathatislinkedtotheinitial
contiguous area. If the overflow area is filled, another overflow area
is allocated. Compare this implementation of a file with the standard
contiguousandlinkedimplementations.
14.5 How do caches help improve performance? Why do systems not use
moreorlargercachesiftheyaresouseful?
14.6 Whyisitadvantageoustotheuserforanoperatingsystemtodynami-
callyallocateitsinternaltables?Whatarethepenaltiestotheoperating
systemfordoingso?
Further Reading
The internals of the BSD UNIX system are covered in full in [McKusick et al.
(2015)].DetailsconcerningfilesystemsforLinuxcanbefoundin[Love(2010)].
The Google file system is described in [Ghemawat et al. (2003)]. FUSE can be
foundathttp://fuse.sourceforge.net.FurtherReading 595
Log-structuredfileorganizationsforenhancingbothperformanceandcon-
sistency are discussed in [Rosenblum and Ousterhout (1991)], [Seltzer et al.
(1993)], and [Seltzer et al. (1995)]. Log-structured designs for networked file
systemsareproposedin[HartmanandOusterhout(1995)]and[Thekkathetal.
(1997)].
TheZFSsourcecodeforspacemapscanbefoundathttp://src.opensolaris.o
rg/source/xref/onnv/onnv-gate/usr/src/uts/common/fs/zfs/space map.c.
ZFSdocumentationcanbefoundathttp://www.opensolaris.org/os/commu
nity/ZFS/docs.
TheNTFSfilesystemisexplainedin[Solomon(1998)],theExt3filesystem
used in Linux is described in [Mauerer (2008)], and the WAFL file system is
coveredin[Hitzetal.(1995)].
Bibliography
[Ghemawatetal.(2003)] S. Ghemawat, H. Gobioff, and S.-T. Leung, “The
Google File System”, Proceedings of the ACM Symposium on Operating Systems
Principles(2003).
[HartmanandOusterhout(1995)] J. H. Hartman and J. K. Ousterhout, “The
Zebra Striped Network File System”, ACM Transactions on Computer Systems,
Volume13,Number3(1995),pages274–310.
[Hitzetal.(1995)] D.Hitz,J.Lau,andM.Malcolm,“FileSystemDesignforan
NFSFileServerAppliance”,Technicalreport,NetApp(1995).
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[Mauerer(2008)] W.Mauerer,ProfessionalLinux KernelArchitecture,JohnWiley
andSons(2008).
[McKusicketal.(2015)] M.K.McKusick,G.V.Neville-Neil,andR.N.M.Wat-
son,TheDesignandImplementationoftheFreeBSDUNIXOperatingSystem–Second
Edition,Pearson(2015).
[RosenblumandOusterhout(1991)] M.RosenblumandJ.K.Ousterhout,“The
DesignandImplementationofaLog-StructuredFileSystem”,Proceedingsofthe
ACMSymposiumonOperatingSystemsPrinciples(1991),pages1–15.
[Seltzeretal.(1993)] M. I. Seltzer, K. Bostic, M. K. McKusick, and C. Staelin,
“AnImplementationofaLog-StructuredFileSystemforUNIX”,USENIXWinter
(1993),pages307–326.
[Seltzeretal.(1995)] M. I. Seltzer, K. A. Smith, H. Balakrishnan, J. Chang,
S.McMains,andV.N.Padmanabhan,“FileSystemLoggingVersusClustering:
APerformanceComparison”,USENIXWinter(1995),pages249–264.
[Solomon(1998)] D.A.Solomon,InsideWindowsNT,SecondEdition,Microsoft
Press(1998).596 Chapter14 File-SystemImplementation
[Thekkathetal.(1997)] C. A. Thekkath, T. Mann, and E. K. Lee, “Frangipani:
AScalableDistributedFileSystem”,SymposiumonOperatingSystemsPrinciples
(1997),pages224–237.EX-49
Chapter 14 Exercises
14.7 Consider a file system that uses a modified contiguous-allocation
scheme with support for extents. Afile is a collection of extents, with
each extent corresponding to a contiguous set of blocks. A key issue
in such systems is the degree of variability in the size of the extents.
Whataretheadvantagesanddisadvantagesofthefollowingschemes?
a. Allextentsareofthesamesize,andthesizeispredetermined.
b. Extentscanbeofanysizeandareallocateddynamically.
c. Extents can be of a few fixed sizes, and these sizes are predeter-
mined.
14.8 Contrast the performance of the three techniques for allocating disk
blocks (contiguous, linked, and indexed)for both sequential and ran-
domfileaccess.
14.9 Whataretheadvantagesofthevariantoflinkedallocationthatusesa
FATtochaintogethertheblocksofafile?
14.10 Considerasystemwherefreespaceiskeptinafree-spacelist.
a. Suppose that the pointer to the free-space list is lost. Can the
systemreconstructthefree-spacelist?Explainyouranswer.
b. Consider a file system similar to the one used by UNIX with
indexed allocation. How many disk I/O operations might be
required to read the contents of a small local file at /a/b/c?
Assumethatnoneofthediskblocksiscurrentlybeingcached.
c. Suggestaschemetoensurethatthepointerisneverlostasaresult
ofmemoryfailure.
14.11 Somefilesystemsallowdiskstoragetobeallocatedatdifferentlevels
of granularity. For instance, a file system could allocate 4 KB of disk
space as a single 4-KB block or as eight 512-byte blocks. How could
we take advantage of this flexibility to improve performance? What
modifications would have to be made to the free-space management
schemeinordertosupportthisfeature?
14.12 Discusshowperformanceoptimizationsforfilesystemsmightresultin
difficulties in maintaining the consistency of the systems in the event
ofcomputercrashes.
14.13 Discusstheadvantagesanddisadvantagesofsupportinglinkstofiles
thatcrossmountpoints(thatis,thefilelinkreferstoafilethatisstored
inadifferentvolume).
14.14 Consider a file system on a disk that has both logical and physical
block sizes of 512 bytes. Assume that the information about each file
is already in memory. For each of the three allocation strategies (con-
tiguous,linked,andindexed),answerthesequestions:Exercises EX-50
a. How is the logical-to-physical address mapping accomplished
in this system? (For the indexed allocation, assume that a file is
alwayslessthan512blockslong.)
b. Ifwearecurrentlyatlogicalblock10(thelastblockaccessedwas
block 10)andwanttoaccesslogicalblock4,howmanyphysical
blocksmustbereadfromthedisk?
14.15 Consider a file system that uses inodes to represent files. Disk blocks
are8KBinsize,andapointertoadiskblockrequires4bytes.Thisfile
system has 12 direct disk blocks, as well as single, double, and triple
indirect disk blocks. What is the maximum size of a file that can be
storedinthisfilesystem?
14.16 Fragmentation on a storage device can be eliminated through com-
paction. Typical disk devices do not have relocation or base registers
(suchasthoseusedwhenmemoryistobecompacted),sohowcanwe
relocatefiles?Givethreereasons why compacting and relocating files
areoftenavoided.
14.17 Explainwhy logging metadataupdatesensuresrecoveryofafilesys-
temafterafile-systemcrash.
14.18 Considerthefollowingbackupscheme:
• Day1.Copytoabackupmediumallfilesfromthedisk.
• Day2.Copytoanothermediumallfileschangedsinceday1.
• Day3.Copytoanothermediumallfileschangedsinceday1.
This differs from the schedule given in Section 14.7.4 by having all
subsequentbackups copyallfilesmodifiedsincethefirstfullbackup.
What are the benefits of this system over the one in Section 14.7.4?
What are the drawbacks? Are restore operations made easier or more
difficult?Explainyouranswer.
14.19 Discusstheadvantagesanddisadvantagesofassociatingwithremote
file systems (stored on file servers) a set of failure semantics different
fromthoseassociatedwithlocalfilesystems.
14.20 What are the implications of supporting UNIX consistency semantics
forsharedaccesstofilesstoredonremotefilesystems?15
CHAPTER
File -System
Internals
Aswe sawinChapter13, the filesystemprovidesthe mechanism for on-line
storageandaccesstofilecontents,includingdataandprograms.Thischapteris
primarilyconcernedwiththeinternalstructuresandoperationsoffilesystems.
We explore in detail ways to structure file use, to allocate storage space, to
recoverfreedspace,totrackthelocationsofdata,andtointerfaceotherparts
oftheoperatingsystemtosecondarystorage.
CHAPTER OBJECTIVES
• Delveintothedetailsoffilesystemsandtheirimplementation.
• Explorebootingandfilesharing.
• Describeremotefilesystems,usingNFSasanexample.
15.1 File Systems
Certainly,nogeneral-purposecomputerstoresjustonefile.Therearetypically
thousands,millions,evenbillionsoffileswithinacomputer.Filesarestoredon
random-accessstoragedevices,includingharddiskdrives,opticaldisks,and
nonvolatilememorydevices.
As youhaveseeninthe precedingchapters,ageneral-purposecomputer
systemcanhavemultiplestoragedevices,andthosedevicescanbeslicedup
intopartitions,whichholdvolumes,whichinturnholdfilesystems.Depend-
ing on the volume manager, a volume may span multiple partitions as well.
Figure15.1showsatypicalfile-systemorganization.
Computer systems may also have varying numbers of file systems, and
thefilesystemsmaybeofvaryingtypes.Forexample,atypicalSolarissystem
may have dozens of file systems of a dozen different types, as shown in the
file-systemlistinFigure15.2.
In this book, we consider only general-purpose file systems. It is worth
noting,though,thattherearemanyspecial-purposefilesystems.Considerthe
typesoffilesystemsintheSolarisexamplementionedabove:
597598 Chapter15 File-SystemInternals
Figure15.1 Atypicalstoragedeviceorganization.
• tmpfs—a“temporary”filesystemthatiscreatedinvolatilemainmemory
andhasitscontentserasedifthesystemrebootsorcrashes
• objfs—a “virtual” file system (essentially an interface to the kernel that
lookslikeafilesystem)thatgivesdebuggersaccesstokernelsymbols
• ctfs—a virtual file system that maintains “contract” information to man-
agewhichprocessesstartwhenthesystembootsandmustcontinuetorun
duringoperation
• lofs—a“loopback”filesystemthatallowsonefilesystemtobeaccessed
inplaceofanotherone
• procfs—avirtualfilesystemthatpresentsinformationonallprocessesas
afilesystem
• ufs,zfs—general-purposefilesystems
The file systems of computers, then, can be extensive. Even within a file
system,itisusefultosegregatefilesintogroupsandmanageandactonthose
groups.Thisorganizationinvolvestheuseofdirectories(seeSection14.3).
15.2 File-System Mounting
Just as a file must be opened before it can be used, a file system must be
mountedbeforeitcanbeavailabletoprocessesonthesystem.Morespecifically,
the directory structure may be built out of multiple file-system-containing
volumes, which must be mounted to make them available within the file-
systemnamespace.
Themountprocedureisstraightforward.Theoperatingsystemisgiventhe
nameofthedeviceandthemountpoint—thelocationwithinthefilestructure
wherethefilesystemistobeattached.Someoperatingsystemsrequirethata
file-systemtypebeprovided,whileothersinspectthestructuresofthedevice15.2 File-SystemMounting 599
/ ufs
/devices devfs
/dev dev
/system/contract ctfs
/proc proc
/etc/mnttab mntfs
/etc/svc/volatile tmpfs
/system/object objfs
/lib/libc.so.1 lofs
/dev/fd fd
/var ufs
/tmp tmpfs
/var/run tmpfs
/opt ufs
/zpbge zfs
/zpbge/backup zfs
/export/home zfs
/var/mail zfs
/var/spool/mqueue zfs
/zpbg zfs
/zpbg/zones zfs
Figure15.2 Solarisfilesystems.
and determine the type of file system. Typically, a mount point is an empty
directory.Forinstance,onaUNIXsystem,afilesystemcontainingauser’shome
directoriesmightbemountedas/home;then,toaccessthedirectorystructure
withinthat filesystem,we couldprecedethedirectorynameswith/home,as
in /home/jane. Mounting that file system under /users would result in the
pathname/users/jane,whichwecouldusetoreachthesamedirectory.
Next, the operating system verifies that the device contains a valid file
system. It does so by asking the device driver to read the device directory
andverifyingthatthedirectoryhastheexpectedformat.Finally,theoperating
system notes in its directory structure that a file system is mounted at the
specified mount point. This scheme enables the operating system to traverse
itsdirectorystructure,switchingamongfilesystems,andevenfilesystemsof
varyingtypes,asappropriate.
Toillustratefilemounting,considerthefilesystemdepictedinFigure15.3,
wherethetrianglesrepresentsubtreesofdirectoriesthatareofinterest.Figure
15.3(a)showsanexistingfilesystem,whileFigure15.3(b)showsanunmounted
volumeresidingon /device/dsk.Atthispoint, only thefileson theexisting
file system can be accessed. Figure 15.4 shows the effects of mounting the
volume residing on /device/dsk over /users. If the volume is unmounted,
thefilesystemisrestoredtothesituationdepictedinFigure15.3.
Systems impose semantics to clarify functionality. For example, a system
maydisallowamountoveradirectorythatcontainsfiles;oritmaymakethe600 Chapter15 File-SystemInternals
/
users
bill fred sue jane
help doc
prog
(a) (b)
Figure15.3 Filesystem.(a)Existingsystem.(b)Unmountedvolume.
mounted file system available at that directory and obscure the directory’s
existingfilesuntilthefilesystemisunmounted,terminatingtheuseofthefile
system and allowing access to the original files in that directory. As another
example,asystemmayallowthesamefilesystemtobemountedrepeatedly,
atdifferentmountpoints;oritmayonlyallowonemountperfilesystem.
ConsidertheactionsofthemacOSoperatingsystem.Wheneverthesystem
encounters a disk for the first time (either at boot time or while the system is
running),themacOSoperatingsystemsearchesforafilesystemonthedevice.
If it finds one, it automatically mounts the file system under the /Volumes
directory, adding a folder icon labeled with the name of the file system (as
stored in the device directory). The user is then able to click on the icon and
thusdisplaythenewlymountedfilesystem.
The Microsoft Windows family of operating systems maintains an
extended two-level directory structure, with devices and volumes assigned
drive letters. Each volume has a general graph directory structure associated
/
users
sue jane
doc
prog
Figure15.4 Volumemountedat/users.15.3 PartitionsandMounting 601
with its drive letter. The path to a specific file takes the form drive-
letter:∖path∖to∖file. The more recent versions of Windows allow a file
system to be mounted anywhere in the directory tree, just as UNIX does.
Windows operating systems automatically discover all devices and mount
all located file systems at boot time. In some systems, like UNIX, the mount
commands are explicit. Asystem configuration file contains a list of devices
andmountpointsforautomaticmountingatboottime,butothermountsmay
beexecutedmanually.
Issues concerning file system mounting are further discussed in Section
15.3andinSectionC.7.5.
15.3 Partitions and Mounting
The layout of a disk can have many variations, depending on the operating
systemandvolumemanagementsoftware.Adiskcanbeslicedintomultiple
partitions, or a volume can span multiple partitions on multiple disks. The
formerlayoutisdiscussedhere,whilethelatter,whichismoreappropriately
consideredaformofRAID,iscoveredinSection11.8.
Eachpartitioncanbeeither“raw,”containingnofilesystem,or“cooked,”
containingafilesystem.Rawdiskisusedwherenofilesystemisappropriate.
UNIX swap space can use a raw partition, for example, since it uses its own
format on disk and does not use a file system. Likewise, some databases use
rawdiskandformatthedatatosuittheirneeds.Rawdiskcanalsoholdinfor-
mationneededbydiskRAIDsystems,suchasbitmapsindicatingwhichblocks
aremirroredandwhichhavechangedandneedtobemirrored.Similarly,raw
diskcancontainaminiaturedatabaseholdingRAIDconfigurationinformation,
suchaswhichdisksaremembersofeachRAIDset.Rawdiskuseisdiscussed
inSection11.5.1.
If a partition contains a file system that is bootable—that has a properly
installedandconfiguredoperatingsystem—thenthepartitionalsoneedsboot
information,asdescribedinSection11.5.2.Thisinformationhasitsownformat,
becauseatboottimethesystemdoesnothavethefile-systemcodeloadedand
therefore cannot interpret the file-system format. Rather, boot information is
usuallyasequentialseriesofblocksloadedasanimageintomemory.Execution
oftheimagestartsatapredefinedlocation,suchasthefirstbyte.Thisimage,
thebootstraploader,inturnknowsenoughaboutthefile-systemstructureto
beabletofindandloadthekernelandstartitexecuting.
The boot loadercancontain morethanthe instructionsfor booting aspe-
cificoperatingsystem.Forinstance,manysystemscanbedual-booted,allow-
ing us to install multiple operating systems on a single system. How does
the system know which one to boot? A boot loader that understands multi-
ple file systems and multiple operating systems can occupy the boot space.
Once loaded, it can boot one of the operating systems available on the drive.
Thedrivecanhavemultiplepartitions,eachcontainingadifferenttypeoffile
systemandadifferentoperatingsystem.Notethatifthebootloaderdoesnot
understandaparticularfile-systemformat,anoperatingsystemstoredonthat
filesystemisnotbootable.Thisisoneofthereasonsonlysomefilesystemsare
supportedasrootfilesystemsforanygivenoperatingsystem.602 Chapter15 File-SystemInternals
The root partition selected by the boot loader, which contains the
operating-system kernel and sometimes other system files, is mounted at
boot time.Othervolumescan beautomatically mountedat boot ormanually
mounted later, depending on the operating system. As part of a successful
mount operation, the operating system verifies that the device contains a
valid file system. It does so by asking the device driver to read the device
directory and verifying that the directory has the expected format. If the
formatisinvalid,thepartitionmusthaveitsconsistencycheckedandpossibly
corrected, either with or without user intervention. Finally, the operating
system notes in its in-memory mount table that a file system is mounted,
along with the type of the file system. The details of this function depend on
theoperatingsystem.
Microsoft Windows–based systems mount each volume in a separate
name space, denoted by a letter and a colon, as mentioned earlier. To record
that a file system is mounted at F:, for example, the operating system places
a pointer to the file systemin a field of the devicestructurecorresponding to
F:. When a process specifies the driver letter, the operating system finds the
appropriate file-system pointer and traverses the directory structures on that
device to find the specified file or directory. Later versions of Windows can
mountafilesystematanypointwithintheexistingdirectorystructure.
OnUNIX,filesystemscanbemountedatanydirectory.Mountingisimple-
mentedbysettingaflaginthein-memorycopyoftheinodeforthatdirectory.
The flag indicates that the directory is a mount point. Afield then points to
an entry in the mount table, indicating which device is mounted there. The
mount table entry contains a pointer to the superblock of the file system on
thatdevice.Thisschemeenablestheoperatingsystemtotraverseitsdirectory
structure,switchingseamlesslyamongfilesystemsofvaryingtypes.
15.4 File Sharing
The ability to share files is very desirable for users who want to collaborate
andtoreducetheeffortrequiredtoachieveacomputinggoal.Therefore,user-
orientedoperatingsystemsmustaccommodatetheneedtosharefilesinspite
oftheinherentdifficulties.
In this section, we examine more aspects of file sharing. We begin by
discussing general issues that arise when multiple users share files. Once
multipleusersareallowedtosharefiles,thechallengeistoextendsharing to
multiplefilesystems,includingremotefilesystems;wediscussthatchallenge
aswell.Finally,weconsiderwhattodoaboutconflictingactionsoccurringon
sharedfiles. For instance, ifmultipleusers arewriting toa file,should all the
writes be allowed to occur, or should the operating system protect the users’
actionsfromoneanother?
15.4.1 Multiple Users
When an operating system accommodates multiple users, the issues of file
sharing,filenaming,andfileprotectionbecomepreeminent.Givenadirectory
structurethat allowsfilestobesharedbyusers,thesystemmustmediatethe
filesharing.Thesystemcaneitherallowausertoaccessthefilesofotherusers15.5 VirtualFileSystems 603
bydefaultorrequirethatauserspecificallygrantaccesstothefiles.Theseare
theissuesofaccesscontrolandprotection,whicharecoveredinSection13.4.
Toimplementsharingandprotection,thesystemmustmaintainmorefile
and directory attributes than are needed on a single-user system. Although
manyapproacheshavebeentakentomeetthisrequirement,mostsystemshave
evolvedtousetheconceptsoffile(ordirectory)owner(oruser)andgroup.The
owneristheuserwhocanchangeattributesandgrantaccessandwhohasthe
most control over the file. The group attribute defines a subset of users who
canshareaccesstothefile.Forexample,theownerofafileonaUNIXsystem
canissuealloperationsonafile,whilemembersofthefile’sgroupcanexecute
onesubsetofthoseoperations,andallotheruserscanexecuteanothersubset
of operations. Exactly which operations can be executed by group members
andotherusersisdefinablebythefile’sowner.
TheownerandgroupIDsofagivenfile(ordirectory)arestoredwiththe
otherfileattributes.Whenauserrequestsanoperationonafile,theuserIDcan
becomparedwiththeownerattributetodetermineiftherequestinguseristhe
ownerofthefile.Likewise,thegroupIDscanbecompared.Theresultindicates
whichpermissionsareapplicable.Thesystemthenappliesthosepermissions
totherequestedoperationandallowsordeniesit.
Many systems have multiple local file systems, including volumes of a
single disk or multiple volumes on multiple attached disks. In these cases,
the ID checking and permission matching are straightforward, once the file
systemsaremounted.Butconsideranexternaldiskthatcanbemovedbetween
systems.WhatiftheIDsonthesystemsaredifferent?Caremustbetakentobe
surethatIDsmatchbetweensystemswhendevicesmovebetweenthemorthat
fileownershipisresetwhensuchamoveoccurs.(Forexample,wecancreate
anewuserIDandsetallfilesontheportabledisktothatID,tobesurenofiles
areaccidentallyaccessibletoexistingusers.)
15.5 Virtual File Systems
Aswe’veseen,modernoperatingsystemsmustconcurrentlysupportmultiple
typesoffilesystems.Buthowdoesanoperatingsystemallowmultipletypes
offilesystemstobeintegratedintoadirectorystructure?Andhowcanusers
seamlessly move between file-system types as they navigate the file-system
space?Wenowdiscusssomeoftheseimplementationdetails.
Anobviousbutsuboptimalmethodofimplementingmultipletypesoffile
systemsistowritedirectoryandfileroutinesforeachtype.Instead,however,
mostoperatingsystems,includingUNIX,useobject-orientedtechniquestosim-
plify,organize,andmodularizetheimplementation.Theuseofthesemethods
allows very dissimilar file-system types to be implemented within the same
structure, including network file systems, such as NFS. Users can access files
containedwithinmultiplefilesystemsonthelocaldriveorevenonfilesystems
availableacrossthenetwork.
Data structures and procedures are used to isolate the basic system-call
functionality from the implementation details. Thus, the file-system imple-
mentation consists of three major layers, as depicted schematically in Figure
15.5. The first layer is the file-system interface,based on the open(),read(),
write(),andclose()callsandonfiledescriptors.604 Chapter15 File-SystemInternals
file-system interface
VFS interface
local file system local file system remote file system
type 1 type 2 type 1
disk disk
network
Figure15.5 Schematicviewofavirtualfilesystem.
Thesecondlayeriscalledthevirtualfilesystem(VFS)layer.TheVFSlayer
servestwoimportantfunctions:
1. Itseparatesfile-system-genericoperationsfromtheirimplementationby
definingacleanVFSinterface.SeveralimplementationsfortheVFSinter-
face may coexist on the same machine, allowing transparent access to
differenttypesoffilesystemsmountedlocally.
2. Itprovidesamechanismforuniquelyrepresentingafilethroughoutanet-
work.TheVFSisbasedonafile-representationstructure,calledavnode,
that contains a numerical designator for a network-wide unique file.
(UNIXinodesareuniquewithinonlyasinglefilesystem.)Thisnetwork-
wide uniqueness is required for support of network file systems. The
kernelmaintains onevnodestructureforeachactivenode(fileordirec-
tory).
Thus, the VFS distinguishes local files from remote ones, and local files are
furtherdistinguishedaccordingtotheirfile-systemtypes.
The VFS activates file-system-specific operations to handle local requests
according to their file-system types and calls the NFS protocol procedures (or
otherprotocolproceduresforothernetworkfilesystems)forremoterequests.
Filehandlesareconstructedfromtherelevantvnodesandarepassedasargu-
mentstotheseprocedures.Thelayerimplementingthefile-systemtypeorthe
remote-file-systemprotocolisthethirdlayerofthearchitecture.
Let’s briefly examine the VFS architecture in Linux. The four main object
typesdefinedbytheLinuxVFSare:15.6 RemoteFileSystems 605
• Theinodeobject,whichrepresentsanindividualfile
• Thefil object,whichrepresentsanopenfile
• Thesuperblockobject,whichrepresentsanentirefilesystem
• Thedentryobject,whichrepresentsanindividualdirectoryentry
Foreachofthesefourobjecttypes,theVFSdefinesasetofoperationsthat
maybeimplemented.Everyobject ofoneofthesetypescontains apointerto
a function table. The function table lists the addresses of the actual functions
thatimplementthedefinedoperationsforthatparticularobject.Forexample,
anabbreviatedAPIforsomeoftheoperationsforthefileobjectincludes:
• int open(. . .)—Openafile.
• int close(. . .)—Closeanalready-openfile.
• ssize t read(. . .)—Readfromafile.
• ssize t write(. . .)—Writetoafile.
• int mmap(. . .)—Memory-mapafile.
Animplementationofthefileobjectforaspecificfiletypeisrequiredtoimple-
menteachfunctionspecifiedinthedefinitionofthefileobject.(Thecomplete
definition of the file object is specified in the file struct file operations,
whichislocatedinthefile/usr/include/linux/fs.h.)
Thus, the VFS software layer can perform an operation on one of these
objects by calling the appropriate function from the object’s function table,
without having to know in advance exactly what kind of object it is dealing
with.TheVFSdoesnotknow,orcare,whetheraninoderepresentsadiskfile,
adirectoryfile,oraremotefile.Theappropriatefunctionforthatfile’sread()
operation will always be at the same place in its function table, and the VFS
softwarelayerwillcallthatfunctionwithoutcaringhowthedataareactually
read.
15.6 Remote File Systems
Withtheadventofnetworks(Chapter19),communicationamongremotecom-
puters became possible. Networking allows the sharing of resources spread
across a campus or even around the world. One obvious resource to share is
dataintheformoffiles.
Throughtheevolutionofnetworkandfiletechnology,remotefile-sharing
methods have changed. The first implemented method involves manually
transferringfilesbetweenmachines viaprogramslikeftp.The secondmajor
method uses a distributed fil system (DFS), in which remote directories are
visiblefromalocalmachine.Insomeways,thethirdmethod,theWorldWide
Web, is a reversion to the first. A browser is needed to gain access to the
remotefiles,andseparateoperations(essentiallyawrapperforftp)areused
totransferfiles.Increasingly,cloudcomputing(Section1.10.5)isbeingusedfor
filesharingaswell.606 Chapter15 File-SystemInternals
ftp is used for both anonymous and authenticated access. Anonymous
accessallowsausertotransferfileswithouthavinganaccountontheremote
system. The World Wide Web uses anonymous file exchange almost exclu-
sively. DFS involves a much tighter integration between the machine that is
accessingtheremotefilesandthemachineprovidingthefiles.Thisintegration
addscomplexity,aswedescribeinthissection.
15.6.1 The Client–Server Model
Remotefilesystemsallowacomputertomountoneormorefilesystemsfrom
one or more remote machines. In this case, the machine containing the files
is the server, and the machine seeking access to the files is the client. The
client–server relationship is common with networked machines. Generally,
the server declares that a resource is available to clients and specifies exactly
which resource (in this case, which files) and exactly which clients. Aserver
canservemultipleclients,andaclientcanusemultipleservers,dependingon
theimplementationdetailsofagivenclient–serverfacility.
The server usually specifies the available files on a volume or directory
level.Clientidentificationismoredifficult.Aclientcan bespecifiedby anet-
worknameorotheridentifier,suchasanIPaddress,butthesecanbespoofed,
or imitated. As a result of spoofing, an unauthorized client could be allowed
accesstotheserver.Moresecuresolutionsincludesecureauthenticationofthe
clientviaencryptedkeys.Unfortunately,withsecuritycomemanychallenges,
including ensuring compatibility of the client and server (they must use the
sameencryptionalgorithms)andsecurityofkeyexchanges(interceptedkeys
could again allow unauthorized access). Because of the difficulty of solving
theseproblems,unsecureauthenticationmethodsaremostcommonlyused.
InthecaseofUNIXanditsnetworkfilesystem(NFS),authenticationtakes
place via the client networking information, by default. In this scheme, the
user’s IDs on the client and servermust match. If they donot, the serverwill
be unable to determine access rights to files. Consider the example of a user
who has an ID of 1000 on the client and 2000 on the server. A request from
the client to the serverfor a specific file will not be handled appropriately,as
theserverwilldetermineifuser1000has access tothefilerather thanbasing
thedeterminationontherealuserIDof2000.Accessisthusgrantedordenied
basedonincorrectauthenticationinformation.Theservermusttrusttheclient
topresentthecorrectuserID.NotethattheNFSprotocolsallowmany-to-many
relationships. That is, many servers can provide files to many clients. In fact,
agivenmachinecanbebothaservertosomeNFSclientsandaclientofother
NFSservers.
Once the remote file system is mounted, file operation requests are sent
on behalf of the user across the network to the server via the DFS protocol.
Typically, a file-open request is sent along with the ID of the requesting user.
The server then applies the standard access checks to determine if the user
has credentials to access the file in the mode requested. The request is either
allowedordenied.Ifitisallowed,afilehandleisreturnedtotheclientappli-
cation,andtheapplicationthencanperformread,write,andotheroperations
on the file. The client closes the file when access is completed. The operating
system may apply semantics similar to those for a local file-system mount or
mayusedifferentsemantics.15.6 RemoteFileSystems 607
15.6.2 Distributed Information Systems
Tomakeclient–serversystemseasiertomanage,distributedinformationsys-
tems,alsoknownasdistributednamingservices,provideunifiedaccesstothe
information needed for remote computing. The domain name system (DNS)
provides host-name-to-network-address translations for the entire Internet.
Before DNS became widespread, files containing the same information were
sentviae-mailorftpbetweenallnetworkedhosts.Obviously,thismethodol-
ogywasnotscalable!DNSisfurtherdiscussedinSection19.3.1.
Other distributed information systems provideuser name/password/user
ID/group ID space for a distributed facility. UNIX systems have employed a
wide variety of distributed information methods. Sun Microsystems (now
partofOracleCorporation)introducedyellowpages(sincerenamednetwork
information service, or NIS), and most of the industry adopted its use. It
centralizesstorageofusernames,hostnames,printerinformation,andthelike.
Unfortunately, it uses unsecure authentication methods, including sending
userpasswordsunencrypted(incleartext)andidentifyinghostsbyIPaddress.
Sun’s NIS+ was a much more securereplacementfor NIS but was much more
complicatedandwasnotwidelyadopted.
In the case of Microsoft’s common Internet file system (CIFS), network
information is used in conjunction with user authentication (user name and
password) to create a network login that the server uses to decide whether
to allow or deny access to a requested file system. For this authentication
to be valid, the user names must match from machine to machine (as with
NFS). Microsoft uses active directory as a distributed naming structure to
provide a single name space for users. Once established, the distributed
naming facility is used by all clients and servers to authenticate users
via Microsoft’s version of the Kerberos network authentication protocol
(https://web.mit.edu/kerberos/).
The industry is moving toward use of the lightweight directory-access
protocol (LDAP) as a secure distributed naming mechanism. In fact, active
directory is based on LDAP. Oracle Solaris and most other major operating
systems include LDAPand allow it to be employedfor user authentication as
well as system-wide retrieval of information, such as availability of printers.
Conceivably,onedistributedLDAPdirectorycouldbeusedbyanorganization
tostorealluserandresourceinformationforalltheorganization’scomputers.
The result would be secure single sign-on for users, who would enter their
authenticationinformationonceforaccesstoallcomputerswithintheorgani-
zation.Itwouldalsoeasesystem-administrationeffortsbycombining,inone
location,informationthatiscurrentlyscatteredinvariousfilesoneachsystem
orindifferentdistributedinformationservices.
15.6.3 Failure Modes
Local file systems can fail for a variety of reasons, including failure of the
drivecontainingthefilesystem,corruptionofthedirectorystructureorother
disk-management information (collectively called metadata), disk-controller
failure, cable failure, and host-adapter failure. User or system-administrator
failure can also cause files to be lost or entire directories or volumes to be
deleted.Manyofthesefailureswillcauseahosttocrashandanerrorcondition
tobedisplayed,andhumaninterventionmayberequiredtorepairthedamage.608 Chapter15 File-SystemInternals
Remote file systems have even more failure modes. Because of the
complexityofnetworksystemsandtherequiredinteractionsbetweenremote
machines, many more problems can interfere with the proper operation of
remote file systems. In the case of networks, the network can be interrupted
betweentwohosts.Suchinterruptionscanresultfromhardwarefailure,poor
hardware configuration, or networking implementation issues. Although
some networks have built-in resiliency, including multiple paths between
hosts, many do not. Any single failure can thus interrupt the flow of DFS
commands.
Consideraclientinthemidstofusingaremotefilesystem.Ithasfilesopen
from the remote host; among other activities, it may be performing directory
lookups to open files, reading or writing data to files, and closing files. Now
considerapartitioningofthenetwork,acrashoftheserver,orevenascheduled
shutdownoftheserver.Suddenly,theremotefilesystemisnolongerreachable.
This scenario is rather common, so it would not be appropriate for the client
systemtoactasitwouldifalocalfilesystemwerelost.Rather,thesystemcan
either terminate all operations to the lost server or delay operations until the
serverisagainreachable.Thesefailuresemanticsaredefinedandimplemented
as part of the remote-file-system protocol. Termination of all operations can
result in users’ losing data—and patience. Thus, most DFS protocols either
enforce or allow delaying of file-system operations to remote hosts, with the
hopethattheremotehostwillbecomeavailableagain.
Toimplementthiskindofrecoveryfromfailure,somekindofstateinfor-
mationmaybemaintainedonboththeclientandtheserver.Ifbothserverand
clientmaintainknowledgeoftheircurrentactivitiesandopenfiles,thenthey
canseamlesslyrecoverfromafailure.Inthesituationwheretheservercrashes
but must recognize that it has remotely mounted exported file systems and
openedfiles,NFSVersion3takesasimpleapproach,implementingastateless
DFS.Inessence,itassumesthataclientrequestforafilereadorwritewouldnot
haveoccurredunlessthefilesystemhadbeenremotelymountedand thefile
hadbeenpreviouslyopen.TheNFSprotocolcarriesalltheinformationneeded
to locate the appropriate file and perform the requested operation. Similarly,
it does not track which clients have the exported volumes mounted, again
assumingthatifarequestcomesin,itmustbelegitimate.Whilethisstateless
approach makes NFS resilient and rather easy to implement, it also makes it
unsecure. For example,forgedread or write requestscould be allowed by an
NFS server. These issues are addressed in the industry standard NFS Version
4, in which NFS is made stateful to improve its security, performance, and
functionality.
15.7 Consistency Semantics
Consistencysemanticsrepresentanimportantcriterionforevaluatinganyfile
systemthatsupportsfilesharing.Thesesemanticsspecifyhowmultipleusers
ofasystemaretoaccessasharedfilesimultaneously.Inparticular,theyspecify
whenmodificationsofdatabyoneuserwillbeobservablebyotherusers.These
semanticsaretypicallyimplementedascodewiththefilesystem.
Consistency semantics are directly related to the process synchronization
algorithmsofChapter6.However,thecomplexalgorithmsofthatchaptertend15.7 ConsistencySemantics 609
nottobeimplementedinthecaseoffileI/Obecauseofthegreatlatenciesand
slowtransferratesofdisksandnetworks.Forexample,performinganatomic
transaction to a remote disk could involve several network communications,
severaldiskreadsand writes,or both. Systemsthat attemptsuch afull setof
functionalitiestendtoperformpoorly.Asuccessfulimplementationofcomplex
sharingsemanticscanbefoundintheAndrewfilesystem.
Forthefollowingdiscussion,weassumethataseriesoffileaccesses(that
is, reads and writes) attempted by a user to the same file is always enclosed
between the open() and close() operations. The series of accesses between
theopen()and close()operationsmakesupa fil session. Toillustratethe
concept,wesketchseveralprominentexamplesofconsistencysemantics.
15.7.1 UNIX Semantics
TheUNIXfilesystem(Chapter19)usesthefollowingconsistencysemantics:
• Writestoanopenfilebyauserarevisibleimmediatelytootheruserswho
havethisfileopen.
• Onemodeofsharingallowsuserstosharethepointerofcurrentlocation
into the file. Thus, the advancing of the pointer by one user affects all
sharing users.Here,afilehas asingleimagethat interleavesallaccesses,
regardlessoftheirorigin.
In the UNIX semantics, a file is associated with a single physical image that
is accessed as an exclusive resource. Contention for this single image causes
delaysinuserprocesses.
15.7.2 Session Semantics
TheAndrewfilesystem(OpenAFS)usesthefollowingconsistencysemantics:
• Writestoanopenfilebyauserarenotvisibleimmediatelytootherusers
thathavethesamefileopen.
• Onceafileisclosed,thechangesmadetoitarevisibleonlyinsessionsstart-
inglater.Alreadyopeninstancesofthefiledonotreflectthesechanges.
Accordingtothesesemantics,afilemaybeassociatedtemporarilywithseveral
(possiblydifferent)imagesatthesametime.Consequently,multipleusersare
allowedtoperformbothreadandwriteaccessesconcurrentlyontheirimages
of the file, without delay. Almost no constraints are enforced on scheduling
accesses.
15.7.3 Immutable-Shared-Files Semantics
Aunique approach is that of immutable shared files. Once a file is declared
assharedbyitscreator,itcannotbemodified.Animmutablefilehastwokey
properties: its name may not be reused, and its contents may not be altered.
Thus, the name of an immutable file signifies that the contents of the file are
fixed.Theimplementationofthesesemanticsinadistributedsystem(Chapter
19)issimple,becausethesharingisdisciplined(read-only).610 Chapter15 File-SystemInternals
15.8 NFS
Network file systems are commonplace. They are typically integrated with
the overall directory structure and interface of the client system. NFS is a
goodexampleofawidelyused,wellimplementedclient–servernetworkfile
system.Here,weuseitasanexampletoexploretheimplementationdetailsof
networkfilesystems.
NFSisbothanimplementationandaspecificationofasoftwaresystemfor
accessingremotefilesacrossLANs(orevenWANs).NFSispartofONC+,which
mostUNIXvendorsandsomePCoperatingsystemssupport.Theimplementa-
tiondescribedhereispartoftheSolarisoperatingsystem,whichisamodified
version of UNIX SVR4. It uses either the TCP or UDP/IP protocol (depending
ontheinterconnectingnetwork).Thespecificationandtheimplementationare
intertwinedinour descriptionof NFS.Wheneverdetailisneeded,we referto
the Solaris implementation;whenever the descriptionis general, it applies to
thespecificationalso.
There are multiple versions of NFS, with the latest being Version 4. Here,
wedescribeVersion3,whichistheversionmostcommonlydeployed.
15.8.1 Overview
NFS views a set of interconnected workstations as a set of independent
machines with independentfile systems. The goal is toallow some degreeof
sharingamongthesefilesystems(onexplicitrequest)inatransparentmanner.
Sharingisbasedonaclient–serverrelationship.Amachinemaybe,andoften
is,bothaclientandaserver.Sharingisallowedbetweenanypairofmachines.
Toensuremachineindependence,sharingofaremotefilesystemaffectsonly
theclientmachineandnoothermachine.
Sothataremotedirectorywillbeaccessibleinatransparentmannerfrom
aparticularmachine—say,fromM1—aclientofthatmachinemustfirstcarry
out a mount operation. The semantics of the operation involve mounting a
remotedirectoryoveradirectoryofalocalfilesystem.Oncethemountoper-
ationiscompleted,themounteddirectorylookslikeanintegralsubtreeofthe
localfilesystem,replacingthesubtreedescendingfromthelocaldirectory.The
localdirectorybecomesthenameoftherootofthenewlymounteddirectory.
Specificationof theremotedirectoryasanargumentforthemount operation
isnot done transparently; the location (or host name) of the remotedirectory
has to be provided.However, from then on, users on machine M1 can access
filesintheremotedirectoryinatotallytransparentmanner.
Toillustratefilemounting,considerthefilesystemdepictedinFigure15.6,
where the triangles represent subtrees of directories that are of interest. The
figure shows three independent file systems of machines named U, S1, and
S2.Atthispoint,oneachmachine,onlythelocalfilescanbeaccessed.Figure
15.7(a) shows the effects of mounting S1:/usr/shared over U:/usr/local.
This figure depicts the view users on U have of their file system. After the
mountiscomplete,theycanaccessanyfilewithinthedir1directoryusingthe
prefix/usr/local/dir1.Theoriginaldirectory/usr/localonthatmachine
isnolongervisible.
Subject to access-rights accreditation, any file system, or any directory
within a file system, can be mounted remotely on top of any local directory.15.8 NFS 611
U: S1: S2:
usr usr usr
local shared dir2
dir1
Figure15.6 Threeindependentfilesystems.
Disklessworkstationscanevenmounttheirownrootsfromservers.Cascading
mountsarealsopermittedinsomeNFSimplementations.Thatis,afilesystem
canbemountedoveranotherfilesystemthatisremotelymounted,notlocal.A
machineisaffectedbyonlythosemountsthatithasitselfinvoked.Mountinga
remotefilesystemdoesnotgivetheclientaccesstootherfilesystemsthatwere,
bychance,mountedovertheformerfilesystem.Thus,themountmechanism
doesnotexhibitatransitivityproperty.
In Figure 15.7(b), we illustrate cascading mounts. The figure shows the
resultofmountingS2:/usr/dir2overU:/usr/local/dir1,whichisalready
remotelymountedfromS1.Userscanaccessfileswithindir2onU usingthe
prefix/usr/local/dir1.Ifasharedfilesystemismountedoverauser’shome
directoriesonallmachinesinanetwork,theusercanlogintoanyworkstation
andgethisorherhomeenvironment.Thispropertypermitsusermobility.
OneofthedesigngoalsofNFSwastooperateinaheterogeneousenviron-
mentofdifferentmachines,operatingsystems,andnetworkarchitectures.The
U: U:
usr usr
local local
dir1 dir1
(a) (b)
Figure15.7 MountinginNFS.(a)Mounts.(b)Cascadingmounts.612 Chapter15 File-SystemInternals
NFSspecificationisindependentofthesemedia.Thisindependenceisachieved
throughtheuseofRPCprimitivesbuiltontopofanexternaldatarepresenta-
tion(XDR)protocolusedbetweentwoimplementation-independentinterfaces.
Hence, if the system’s heterogeneous machines and file systems are properly
interfaced to NFS, file systems of different types can be mounted both locally
andremotely.
The NFS specification distinguishes between the services provided by a
mountmechanismandtheactualremote-file-accessservices.Accordingly,two
separateprotocolsarespecifiedfortheseservices:amountprotocolandapro-
tocol for remotefileaccesses,theNFS protocol.The protocolsarespecifiedas
setsofRPCs.TheseRPCsarethebuildingblocksusedtoimplementtransparent
remotefileaccess.
15.8.2 The Mount Protocol
Themountprotocolestablishestheinitiallogicalconnectionbetweenaserver
andaclient.InSolaris,eachmachinehasaserverprocess,outsidethekernel,
performingtheprotocolfunctions.
A mount operation includes the name of the remote directory to be
mounted and the name of the server machine storing it. The mount request
is mapped to the corresponding RPC and is forwarded to the mount server
running on the specific server machine. The server maintains an export
list that specifies local file systems that it exports for mounting, along with
namesofmachinesthatarepermittedtomountthem.(InSolaris,thislististhe
/etc/dfs/dfstab,whichcanbeeditedonlybyasuperuser.)Thespecification
canalsoincludeaccessrights,suchasreadonly.Tosimplifythemaintenance
ofexportlistsand mount tables,adistributednaming schemecan beusedto
holdthisinformationandmakeitavailabletoappropriateclients.
Recall that any directory within an exported file system can be mounted
remotely by an accredited machine. A component unit is such a directory.
When the server receives a mount request that conforms to its export list, it
returnstotheclientafilehandlethatservesasthekeyforfurtheraccessesto
fileswithinthemountedfilesystem.Thefilehandlecontainsalltheinforma-
tion that the server needs to distinguish an individual file it stores. In UNIX
terms,thefilehandleconsistsofafile-systemidentifierandaninodenumber
toidentifytheexactmounteddirectorywithintheexportedfilesystem.
Theserveralsomaintainsalistoftheclientmachinesandthecorrespond-
ing currently mounted directories.This list is used mainly for administrative
purposes—forinstance,fornotifyingallclientsthattheserverisgoingdown.
Onlythroughadditionanddeletionofentriesinthislistcantheserverstatebe
affectedbythemountprotocol.
Usually,asystemhasastaticmountingpreconfigurationthatisestablished
atboottime(/etc/vfstabinSolaris);however,thislayoutcanbemodified.In
addition to the actual mount procedure, the mount protocol includes several
otherprocedures,suchasunmountandreturnexportlist.
15.8.3 The NFS Protocol
TheNFSprotocolprovidesasetofRPCsforremotefileoperations.Theproce-
duressupportthefollowingoperations:15.8 NFS 613
• Searchingforafilewithinadirectory
• Readingasetofdirectoryentries
• Manipulatinglinksanddirectories
• Accessingfileattributes
• Readingandwritingfiles
These procedures can be invoked only after a file handle for the remotely
mounteddirectoryhasbeenestablished.
The omission of open and close operations is intentional. A prominent
featureofNFSserversisthattheyarestateless.Serversdonotmaintaininfor-
mation about their clients from one access to another. No parallels to UNIX’s
open-files table or file structures exist on the server side. Consequently, each
requesthastoprovideafullsetofarguments,includingauniquefileidentifier
andanabsoluteoffsetinsidethefilefortheappropriateoperations.Theresult-
ing design is robust; no special measures need be taken to recover a server
after a crash. File operations must be idempotent for this purpose—that is,
the same operationperformedmultipletimes must have the same effect as if
ithad onlybeenperformedonce. Toachieveidempotence,everyNFS request
hasasequencenumber,allowingtheservertodetermineifarequesthasbeen
duplicatedorifanyaremissing.
Maintaining the list of clients that we mentioned seems to violate the
statelessness of the server. However, this list is not essential for the correct
operationoftheclientortheserver,andhenceitdoesnotneedtoberestored
after a server crash. Consequently, it may include inconsistent data and is
treatedasonlyahint.
Afurtherimplicationofthestateless-serverphilosophyandaresultofthe
synchrony of an RPC is that modified data (including indirection and status
blocks) must be committed to the server’s disk before results are returned to
the client. That is, a client can cache write blocks, but when it flushes them
totheserver,itassumesthattheyhavereachedtheserver’sdisks.Theserver
mustwriteallNFSdatasynchronously.Thus,aservercrashandrecoverywill
beinvisibletoaclient;allblocksthattheserverismanagingfortheclientwillbe
intact.Theresultingperformancepenaltycanbelarge,becausetheadvantages
ofcachingarelost.Performancecanbeincreasedbyusingstoragewithitsown
nonvolatile cache (usually battery-backed-up memory). The disk controller
acknowledgesthediskwritewhenthewriteisstoredinthenonvolatilecache.
In essence, the host sees a very fast synchronous write. These blocks remain
intactevenafterasystemcrashandarewrittenfromthisstablestoragetodisk
periodically.
A single NFS write procedure call is guaranteed to be atomic and is not
intermixedwithotherwritecallstothesamefile.TheNFSprotocol,however,
doesnotprovideconcurrency-controlmechanisms.Awrite()systemcallmay
be broken down into several RPC writes, because each NFS write or read call
cancontainupto8KBofdataandUDPpacketsarelimitedto1,500bytes.Asa
result,twouserswritingtothesameremotefilemaygettheirdataintermixed.
The claim is that, because lock management is inherently stateful, a service
outsidethe NFS should providelocking (and Solaris does).Users are advised
tocoordinateaccesstosharedfilesusingmechanismsoutsidethescopeofNFS.614 Chapter15 File-SystemInternals
client server
system-calls interface
VFS interface VFS interface
other types of UNIX file NFS NFS UNIX file
file systems system client server system
RPC/XDR RPC/XDR
disk disk
network
Figure15.8 SchematicviewoftheNFSarchitecture.
NFSisintegratedintotheoperatingsystemviaaVFS.Asanillustrationof
thearchitecture,let’stracehowanoperationonanalready-openremotefileis
handled(followtheexampleinFigure15.8).Theclientinitiatestheoperation
witharegularsystemcall.Theoperating-systemlayermapsthiscalltoaVFS
operationontheappropriatevnode.TheVFSlayeridentifiesthefileasaremote
one and invokes the appropriate NFS procedure. An RPC call is made to the
NFSservicelayerattheremoteserver.ThiscallisreinjectedtotheVFSlayeron
theremotesystem,whichfindsthatitislocalandinvokestheappropriatefile-
systemoperation.Thispathisretracedtoreturntheresult.Anadvantageofthis
architectureisthattheclientandtheserverareidentical;thus,amachinemay
beaclient,oraserver,orboth.Theactualserviceoneachserverisperformed
bykernelthreads.
15.8.4 Path-Name Translation
Path-name translation in NFS involves the parsing of a path name such as
/usr/local/dir1/file.txtinto separate directoryentries, or components:
(1) usr, (2) local, and (3) dir1. Path-name translation is done by breaking
thepathintocomponentnamesandperformingaseparateNFSlookup call
for every pair of component name and directory vnode. Once a mount point
is crossed, every component lookup causes a separate RPC to the server. This
expensive path-name-traversal scheme is needed, since the layout of each
client’s logical name space is unique, dictated by the mounts the client has
performed. It would be much more efficient to hand a server a path name
and receive a target vnode once a mount point is encountered. At any point,
however,theremightbeanothermountpointfortheparticularclientofwhich
thestatelessserverisunaware.15.9 Summary 615
So that lookup is fast, a directory-name-lookup cache on the client side
holdsthevnodesforremotedirectorynames.Thiscachespeedsupreferences
tofileswiththesameinitialpathname.Thedirectorycacheisdiscardedwhen
attributes returned from the server do not match the attributes of the cached
vnode.
Recall that some implementations of NFS allow mounting a remote file
system on top of another already-mounted remote file system (a cascading
mount). When a client has a cascading mount, more than one server can be
involvedin a path-name traversal.However, when a client does a lookup on
adirectoryon which the serverhas mounteda file system,the client seesthe
underlyingdirectoryinsteadofthemounteddirectory.
15.8.5 Remote Operations
Withtheexceptionofopeningandclosingfiles,thereisanalmostone-to-one
correspondencebetweentheregularUNIXsystemcallsforfileoperationsand
theNFSprotocolRPCs.Thus,aremotefileoperationcanbetranslateddirectly
to the corresponding RPC. Conceptually, NFS adheres to the remote-service
paradigm;butinpractice,bufferingandcachingtechniquesareemployedfor
the sake of performance. No direct correspondence exists between a remote
operation and an RPC. Instead, file blocks and file attributes are fetched by
theRPCsandarecachedlocally.Futureremoteoperationsusethecacheddata,
subjecttoconsistencyconstraints.
There are two caches: the file-attribute (inode-information) cache and the
file-blocks cache. When a file is opened, the kernel checks with the remote
server to determine whether to fetch or revalidate the cached attributes. The
cachedfileblocksareusedonlyifthecorrespondingcachedattributesareup
to date. The attribute cache is updated whenever new attributes arrive from
theserver.Cached attributesare,by default,discardedafter60seconds.Both
read-aheadanddelayed-writetechniquesareusedbetweentheserverandthe
client. Clients do not free delayed-write blocks until the server confirms that
thedatahavebeenwrittentodisk.Delayed-writeisretainedevenwhenafile
isopened concurrently, inconflicting modes.Hence,UNIX semantics (Section
15.7.1)arenotpreserved.
Tuning the system for performance makes it difficult to characterize the
consistency semantics of NFS. New files created on a machine may not be
visibleelsewherefor30seconds.Furthermore,writestoafileatone sitemay
or may not be visible at other sites that have this file open for reading. New
opensofafileobserveonlythechangesthathavealreadybeenflushedtothe
server.Thus, NFS providesneither strictemulationof UNIX semanticsnor the
sessionsemanticsofAndrew(Section15.7.2).Inspiteofthesedrawbacks,the
utilityandgoodperformanceofthemechanismmakeitthemostwidelyused
multi-vendor-distributedsysteminoperation.
15.9 Summary
• General-purposeoperatingsystemsprovidemanyfile-systemtypes,from
special-purposethroughgeneral.616 Chapter15 File-SystemInternals
• Volumescontainingfilesystemscanbemountedintothecomputer’sfile-
systemspace.
• Depending on the operating system, the file-system space is seamless
(mounted file systems integrated into the directory structure) or distinct
(eachmountedfilesystemhavingitsowndesignation).
• Atleastonefilesystemmustbebootableforthesystemtobeabletostart
—thatis,itmustcontainanoperatingsystem.Thebootloaderisrunfirst;
itisasimpleprogramthatisabletofindthekernelinthefilesystem,load
it,andstartitsexecution.Systemscancontainmultiplebootablepartitions,
lettingtheadministratorchoosewhichtorunatboottime.
• Mostsystemsaremulti-userandthusmustprovideamethodforfileshar-
ingandfileprotection.Frequently,filesanddirectoriesincludemetadata,
suchasowner,user,andgroupaccesspermissions.
• MassstoragepartitionsareusedeitherforrawblockI/Oorforfilesystems.
Each file system resides in a volume, which can be composed of one
partitionormultiplepartitionsworkingtogetherviaavolumemanager.
• Tosimplifyimplementationofmultiplefilesystems,anoperatingsystem
can use a layered approach, with a virtual file-system interface making
accesstopossiblydissimilarfilesystemsseamless.
• Remotefilesystemscanbeimplementedsimplybyusingaprogramsuch
asftporthewebserversandclientsintheWorldWideWeb,orwithmore
functionalityviaaclient–servermodel.MountrequestsanduserIDsmust
beauthenticatedtopreventunapprovedaccess.
• Client–serverfacilitiesdonotnativelyshareinformation,butadistributed
information system such as DNS can be used to allow such sharing, pro-
viding a unified user name space, password management, and system
identification. For example, Microsoft CIFS uses active directory, which
employsaversionoftheKerberosnetworkauthenticationprotocoltopro-
videafullsetofnamingandauthenticationservicesamongthecomputers
inanetwork.
• Oncefilesharingispossible,aconsistencysemanticsmodelmustbecho-
senandimplementedtomoderatemultipleconcurrentaccesstothesame
file.SemanticsmodelsincludeUNIX,session,andimmutable-shared-files
semantics.
• NFS is an example of a remote file system, providing clients with seam-
lessaccesstodirectories,files,andevenentirefilesystems.Afull-featured
remotefilesystemincludesacommunicationprotocolwithremoteopera-
tionsandpath-nametranslation.
Practice Exercises
15.1 ExplainhowtheVFSlayerallowsanoperatingsystemtosupportmul-
tipletypesoffilesystemseasily.
15.2 Whyhavemorethanonefilesystemtypeonagivensystem?Bibliography 617
15.3 On a Unix or Linux system that implements the procfs file system,
determinehowtousetheprocfsinterfacetoexploretheprocessname
space.Whataspectsofprocessescanbeviewedviathisinterface?How
wouldthesameinformationbegatheredonasystemlackingtheprocfs
filesystem?
15.4 Whydosomesystemsintegratemountedfilesystemsintotherootfile
systemnamingstructure,whileothersuseaseparatenamingmethod
formountedfilesystems?
15.5 Given a remote file access facility such as ftp, why were remote file
systemslikeNFScreated?
Further Reading
The internals of the BSD UNIX system are covered in full in [McKusick et al.
(2015)].DetailsconcerningfilesystemsforLinuxcanbefoundin[Love(2010)].
Thenetworkfilesystem(NFS)isdiscussedin[Callaghan(2000)].NFSVer-
sion 4 is a standard described at http://www.ietf.org/rfc/rfc3530.txt. [Ouster-
hout (1991)] discusses the role of distributed state in networked file systems.
NFS and the UNIX file system (UFS) are described in [Mauro and McDougall
(2007)].
The Kerberos network authentication protocol is explored in
https://web.mit.edu/kerberos/.
Bibliography
[Callaghan(2000)] B.Callaghan,NFSIllustrated,Addison-Wesley(2000).
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[MauroandMcDougall(2007)] J. Mauro and R. McDougall, Solaris Internals:
CoreKernelArchitecture,PrenticeHall(2007).
[McKusicketal.(2015)] M.K.McKusick,G.V.Neville-Neil,andR.N.M.Wat-
son,TheDesignandImplementationoftheFreeBSDUNIXOperatingSystem–Second
Edition,Pearson(2015).
[Ousterhout(1991)] J. Ousterhout. “The Role of Distributed State”. In CMU
ComputerScience:a25thAnniversaryCommemorative,R.F.Rashid,Ed.,Addison-
Wesley(1991).EX-51
Chapter 15 Exercises
15.6 Assume that in a particular augmentation of a remote-file-access pro-
tocol,eachclientmaintainsanamecachethatcachestranslationsfrom
file names to corresponding file handles. What issues should we take
intoaccountinimplementingthenamecache?
15.7 Given a mounted file system with write operations underway, and a
systemcrash or power loss,what must be done beforethe file system
is remounted if: (a) The file system is not log-structured? (b) The file
systemislog-structured?
15.8 Whydooperatingsystemsmounttherootfilesystemautomaticallyat
boottime?
15.9 Why do operating systems require file systems other than root to be
mounted?Part Seven
Security and
Protection
Security ensures the authentication of system users to protect the
integrity of the information stored in the system (both data and code),
as well as the physical resources of the computer system. The security
systempreventsunauthorizedaccess,maliciousdestructionoralteration
ofdata,andaccidentalintroductionofinconsistency.
Protection mechanisms control access to a system by limiting the
typesoffileaccesspermittedtousers.Inaddition,protectionmustensure
thatonlyprocessesthathavegainedproperauthorizationfromtheoper-
ating system can operate on memory segments, the CPU, and other
resources.
Protection is provided by a mechanism that controls the access of
programs, processes, or users to the resources defined by a computer
system. This mechanism must provide a means for specifying the con-
trolstobeimposed,togetherwithameansofenforcingthem.16
CHAPTER
Security
Both protection and security are vital to computer systems. We distinguish
betweenthesetwoconceptsinthefollowingway:Securityisameasureofcon-
fidencethattheintegrityofasystemanditsdatawillbepreserved.Protection
is the set of mechanisms that control the access of processes and users to the
resourcesdefinedbyacomputersystem.Wefocusonsecurityinthischapter
andaddressprotectioninChapter17.
Security involves guarding computer resources against unauthorized
access, malicious destruction or alteration, and accidental introduction of
inconsistency. Computer resources include the information stored in the
system(both data and code), as well as the CPU, memory,secondary storage,
tertiary storage, and networking that compose the computer facility. In this
chapter, we start by examining ways in which resources may be accidentally
orpurposelymisused.Wethenexploreakeysecurityenabler—cryptography.
Finally,welookatmechanismstoguardagainstordetectattacks.
CHAPTER OBJECTIVES
• Discusssecuritythreatsandattacks.
• Explainthefundamentalsofencryption,authentication,andhashing.
• Examinetheusesofcryptographyincomputing.
• Describevariouscountermeasurestosecurityattacks.
16.1 The Security Problem
In many applications, ensuring the security of the computer system is worth
considerable effort. Large commercial systems containing payroll or other
financialdataareinvitingtargetstothieves.Systemsthatcontaindatapertain-
ing to corporate operations may be of interest to unscrupulous competitors.
Furthermore, loss of such data, whether by accident or fraud, can seriously
impairtheabilityofthecorporationtofunction.Evenrawcomputingresources
areattractivetoattackersforbitcoinmining,forsendingspam,andasasource
fromwhichtoanonymouslyattackothersystems.
621622 Chapter16 Security
InChapter17,wediscussmechanismsthattheoperatingsystemcanpro-
vide(withappropriateaidfromthehardware)thatallowuserstoprotecttheir
resources,includingprogramsanddata.Thesemechanismsworkwellonlyas
longastheusersconformtotheintendeduseofandaccesstotheseresources.
We say that a system is secure if its resources are used and accessed
as intended under all circumstances. Unfortunately, total security cannot be
achieved.Nonetheless,we must havemechanisms tomakesecurity breaches
arareoccurrence,ratherthanthenorm.
Security violations (or misuse) of the system can be categorized as inten-
tional(malicious)oraccidental.Itiseasiertoprotectagainstaccidentalmisuse
than against malicious misuse. For the most part, protection mechanisms are
thecoreofaccidentavoidance.Thefollowinglistincludesseveralformsofacci-
dentalandmalicioussecurityviolations.Notethatinourdiscussionofsecurity,
weusethetermsintruder,hacker,andattackerforthoseattemptingtobreach
security.Inaddition,athreatisthepotentialforasecurityviolation,suchasthe
discoveryofavulnerability,whereasanattackisanattempttobreaksecurity.
• Breach of confidentialit . This type of violation involves unauthorized
reading of data (or theft of information). Typically, a breach of confiden-
tiality is the goal of an intruder. Capturing secret data from a system or
adatastream,suchascredit-cardinformationoridentityinformationfor
identitytheft,orunreleasedmoviesorscripts,canresultdirectlyinmoney
fortheintruderandembarrassmentforthehackedinstitution.
• Breach of integrity. This violation involves unauthorized modification
of data. Such attacks can, for example, result in passing of liability to
an innocent party or modification of the source code of an important
commercialoropen-sourceapplication.
• Breachofavailability.Thisviolationinvolvesunauthorizeddestructionof
data.Someattackerswouldratherwreakhavocandgetstatusorbragging
rightsthan gainfinancially. Websitedefacementisacommon exampleof
thistypeofsecuritybreach.
• Theft of service. This violation involves unauthorized use of resources.
Forexample,anintruder(orintrusionprogram)mayinstalladaemonon
asystemthatactsasafileserver.
• Denial of service. This violation involves preventing legitimate use of
thesystem.Denial-of-service(DOS)attacksaresometimesaccidental.The
originalInternetwormturnedintoaDOSattackwhenabugfailedtodelay
itsrapidspread.WediscussDOSattacksfurtherinSection16.3.2.
Attackers use several standard methods in their attempts to breach secu-
rity.Themostcommonismasquerading,inwhichoneparticipantinacommu-
nicationpretendstobesomeoneelse(anotherhostoranotherperson).Bymas-
querading, attackers breach authentication, the correctness of identification;
they can then gain access that they would not normally be allowed. Another
common attack is to replay a captured exchange of data. A replay attack
consists of the malicious or fraudulent repeat of a valid data transmission.
Sometimes the replay comprises the entire attack—for example, in a repeat
of a request to transfer money. But frequently it is done along with message16.1 TheSecurityProblem 623
modificatio ,inwhichtheattackerchangesdatainacommunicationwithout
thesender’sknowledge.Considerthedamagethatcouldbedoneifarequest
forauthenticationhadalegitimateuser’sinformationreplacedwithanunau-
thorized user’s. Yet another kind of attack is the man-in-the-middle attack,
inwhich an attacker sits in the dataflow of a communication, masquerading
as the sender to the receiver, and vice versa. In a network communication, a
man-in-the-middle attack may be preceded by a session hijacking, in which
anactivecommunicationsessionisintercepted.
Another broad class of attacks is aimed at privilege escalation. Every
systemassigns privilegestousers, evenif there is just one user and that user
is the administrator. Generally, the system includes several sets of privileges,
oneforeachuseraccount andsomeforthesystem.Frequently,privilegesare
alsoassignedtononusersofthesystem(suchasusersfromacrosstheInternet
accessingawebpagewithoutlogginginoranonymoususersofservicessuch
asfile transfer).Evenasenderofemailtoaremotesystemcan be considered
to have privileges—the privilege of sending an email to a receiving user on
thatsystem.Privilegeescalationgivesattackersmoreprivilegesthantheyare
supposed to have. For example, an email containing a script or macro that is
executed exceeds the email sender’s privileges. Masquerading and message
modification,mentionedabove,areoftendonetoescalateprivileges.Thereare
many more examples, as this is a very common type of attack. Indeed, it is
difficulttodetectandpreventallofthevariousattacksinthiscategory.
As we have already suggested, absolute protection of the system from
malicious abuse is not possible, but the cost to the perpetrator can be made
sufficiently high to deter most intruders. In some cases, such as a denial-of-
service attack, it is preferable to prevent the attack but sufficient to detect it
so that countermeasures can be taken (such as up-stream filtering or adding
resourcessuchthattheattackisnotdenyingservicestolegitimateusers).
Toprotectasystem,wemusttakesecuritymeasuresatfourlevels:
1. Physical. The site or sites containing the computer systems must be
physically secured against entry by intruders. Both the machine rooms
and the terminals or computers that have access to the target machines
must be secured, for example by limiting access to the building they
residein,orlockingthemtothedeskonwhichtheysit.
2. Network. Most contemporary computer systems—from servers to
mobile devices to Internet of Things (IoT) devices—are networked.
Networkingprovidesameansforthesystemtoaccessexternalresources
butalsoprovidesapotentialvectorforunauthorizedaccesstothesystem
itself.
Further,computerdatainmodernsystemsfrequentlytraveloverpri-
vateleasedlines,sharedlinesliketheInternet,wirelessconnections,and
dial-up lines. Intercepting these data can be just as harmful as breaking
into a computer, and interruption of communications can constitute a
remotedenial-of-serviceattack,diminishingusers’useofandtrustinthe
system.
3. Operating system. The operating system and its built-in set of appli-
cations and services comprise a huge code base that may harbor many
vulnerabilities.Insecuredefaultsettings,misconfigurations,andsecurity624 Chapter16 Security
bugsareonlyafewpotentialproblems.Operatingsystemsmustthusbe
keptup todate(viacontinuous patching)and“hardened”—configured
and modified to decrease the attack surface and avoid penetration. The
attack surface is the set of points at which an attacker can try to break
intothesystem.
4. Application. Third-party applications may also pose risks, especially
if they possess significant privileges. Some applications are inherently
malicious,butevenbenignapplicationsmaycontainsecuritybugs.Due
to the vast number of third-party applications and their disparate code
bases, it is virtually impossible to ensure that all such applications are
secure.
Thisfour-layeredsecuritymodelisshowninFigure16.1.
Thefour-layermodelofsecurityislikeachainmadeoflinks:avulnerabil-
ityinanyofitslayerscanleadtofullsystemcompromise.Inthatrespect,the
oldadagethatsecurityisonlyasstrongasitsweakestlinkholdstrue.
Anotherfactorthatcannotbeoverlookedisthehumanone.Authorization
must be performed carefully to ensure that only allowed, trusted users have
access to the system. Even authorized users, however, may be malicious or
maybe“encouraged”toletothersusetheiraccess—whetherwillinglyorwhen
dupedthroughsocialengineering,whichusesdeceptiontopersuadepeople
to give up confidential information. One type of social-engineering attack is
phishing, in which a legitimate-looking e-mail or web page misleads a user
into entering confidential information. Sometimes, all it takes is a click of a
link onabrowser pageorinan emailtoinadvertentlydownload amalicious
payload,compromising systemsecurityon theuser’s computer.Usuallythat
PC is not the end target, but rather some more valuable resource. From that
compromised system, attacks on other systems on the LAN or other users
ensue.
So far, we’ve seen that all four factors in the four-level model, plus the
humanfactor,mustbetakenintoaccount ifsecurityistobemaintained.Fur-
thermore, the system must provide protection (discussed in great detail in
Chapter17)toallowtheimplementationofsecurityfeatures.Withouttheabil-
ity to authorize users and processes to control their access, and to log their
activities,itwouldbeimpossibleforanoperatingsystemtoimplementsecu-
rity measures or to run securely. Hardware protection features are needed to
supportanoverallprotectionscheme.Forexample,asystemwithoutmemory
Figure16.1 Thefour-layeredmodelofsecurity.16.2 ProgramThreats 625
protection cannot be secure. New hardware features are allowing systems to
bemademoresecure,asweshalldiscuss.
Unfortunately, little in security is straightforward. As intruders exploit
security vulnerabilities, security countermeasures are created and deployed.
Thiscausesintruderstobecomemoresophisticatedintheirattacks.Forexam-
ple, spyware can provide a conduit for spam through innocent systems (we
discussthispracticeinSection16.2),whichinturncandeliverphishingattacks
to other targets. This cat-and-mouse game is likely to continue, with more
securitytoolsneededtoblocktheescalatingintrudertechniquesandactivities.
In the remainder of this chapter, we address security at the network and
operating-systemlevels.Securityatthe application,physicaland humanlev-
els, although important, is for the most part beyond the scope of this text.
Securitywithintheoperatingsystemandbetweenoperatingsystemsisimple-
mented in several ways, ranging from passwords for authentication through
guardingagainstvirusestodetectingintrusions.Westartwithanexploration
ofsecuritythreats.
16.2 Program Threats
Processes, along with the kernel, are the only means of accomplishing work
onacomputer.Therefore,writingaprogramthatcreatesabreachofsecurity,
or causing a normal process to change its behavior and create a breach, is a
commongoalofattackers.Infact,evenmostnonprogramsecurityeventshave
astheirgoalcausingaprogramthreat.Forexample,whileitisusefultologin
toasystemwithoutauthorization,itisquitealotmoreusefultoleavebehind
aback-door daemonor RemoteAccess Tool(RAT)that providesinformation
orallowseasyaccesseveniftheoriginalexploitisblocked.Inthissection,we
describecommonmethodsbywhichprogramscausesecuritybreaches.Note
thatthereisconsiderablevariationinthenamingconventionsforsecurityholes
andthatweusethemostcommonordescriptiveterms.
16.2.1 Malware
Malwareissoftwaredesignedtoexploit,disableordamagecomputersystems.
There are many ways to perform such activities, and we explore the major
variationsinthissection.
Manysystemshavemechanismsforallowingprogramswrittenbyauser
tobeexecutedbyotherusers.Iftheseprogramsareexecutedinadomainthat
provides the access rights of the executing user, the other users may misuse
theserights.Aprogramthatactsinaclandestineormaliciousmanner,rather
thansimplyperformingitsstatedfunction,iscalledaTrojanhorse.Ifthepro-
gramisexecutedinanotherdomain,itcanescalateprivileges.Asanexample,
consider a mobile app that purports to provide some benign functionality—
say, a flashlight app—but that meanwhile surreptitiously accesses the user’s
contactsormessagesandsmugglesthemtosomeremoteserver.
A classic variation of the Trojan horse is a “Trojan mule” program that
emulatesaloginprogram.Anunsuspectinguserstartstologinataterminal,
computer, or web page and notices that she has apparently mistyped her626 Chapter16 Security
password. She tries again and is successful. What has happened is that her
authentication key and password have been stolen by the login emulator,
which was left running on the computer by the attacker or reached via a
bad URL. The emulator stored away the password, printed out a login error
message,andexited;theuserwasthenprovidedwithagenuineloginprompt.
This type of attack can be defeated by having the operating system print a
usagemessageattheendofaninteractivesession,byrequiringanontrappable
key sequence to get to the login prompt, such as the control-alt-delete
combination used by all modern Windows operating systems, or by the user
ensuringtheURListheright,validone.
Another variation on the Trojan horse is spyware. Spyware sometimes
accompanies a program that the user has chosen to install. Most frequently,
it comes along with freeware or shareware programs, but sometimes it is
included with commercial software. Spyware may download ads to display
on the user’s system, create pop-up browser windows when certain sites are
visited,orcaptureinformationfromtheuser’ssystemandreturnittoacentral
site.Theinstallationofaninnocuous-seemingprogramonaWindowssystem
couldresultintheloadingofaspywaredaemon.Thespywarecouldcontacta
centralsite,begivenamessageandalistofrecipientaddresses,anddelivera
spammessagetothoseusersfromtheWindowsmachine.Thisprocesswould
continue until the user discovered the spyware. Frequently, the spyware is
not discovered. In 2010, it was estimated that 90 percent of spam was being
deliveredbythismethod.Thistheftofserviceisnot evenconsideredacrime
inmostcountries!
A fairly recent and unwelcome development is a class of malware that
doesn’tstealinformation.Ransomwareencryptssomeoralloftheinformation
onthetargetcomputerandrendersitinaccessibletotheowner.Theinforma-
tion itself has little value to the attacker but lots of value to the owner. The
ideaistoforcetheownertopaymoney(theransom)togetthedecryptionkey
neededtodecrypt the data. As with other dealings with criminals, of course,
paymentoftheransomdoesnotguaranteereturnofaccess.
Trojans and othermalware especiallythriveincases wherethereisavio-
lation of the principle of least privilege. This commonly occurs when the
operatingsystemallowsbydefaultmoreprivilegesthananormaluserneedsor
whentheuserrunsbydefaultasanadministrator(aswastrueinallWindows
operating systems up to Windows 7). In such cases, the operating system’s
own immune system—permissions and protections of various kinds—can-
not“kickin,”sothemalwarecanpersistandsurviveacrossreboot,aswellas
extenditsreachbothlocallyandoverthenetwork.
Violatingtheprincipleofleastprivilegeisacaseofpooroperating-system
design decision making. An operating system (and, indeed, software in gen-
eral)shouldallowfine-grainedcontrolofaccessandsecurity,sothatonlythe
privilegesneededtoperformataskareavailableduringthetask’sexecution.
Thecontrolfeaturemustalsobeeasytomanageandunderstand.Inconvenient,
inadequate, and misunderstood security measures are bound to be circum-
vented, causing an overall weakening of the security they were designed to
implement.
Inyetanotherformofmalware,thedesignerofaprogramorsystemleaves
a hole in the software that only she is capable of using. This type of security
breach, a trap door (or back door), was shown in the movie War Games. For16.2 ProgramThreats 627
THEPRINCIPLEOFLEASTPRIVILEGE
“The principle of least privilege. Every program and every privileged
user of the system should operate using the least amount of privilege
necessary to complete the job. The purpose of this principle is to reduce
the number of potential interactions among privileged programs to
the minimum necessary to operate correctly, so that one may develop
confidence that unintentional, unwanted, or improper uses of privilege
do not occur.”—Jerome H. Saltzer, describing a design principle of the
Multics operating system in 1974: https://pdfs.semanticscholar.org/
1c8d/06510ad449ad24fbdd164f8008cc730cab47.pdf.
instance,thecodemightcheckforaspecificuserIDorpassword,anditmight
circumventnormal securityprocedureswhenitreceivesthatIDorpassword.
Programmers have used the trap-door method to embezzle from banks by
including rounding errors in their code and having the occasional half-cent
creditedtotheiraccounts.Thisaccountcreditingcanadduptoalargeamount
ofmoney,consideringthenumberoftransactionsthatalargebankexecutes.
Atrapdoormaybesettooperateonlyunderaspecificsetoflogiccondi-
tions,inwhichcaseitisreferredtoasalogicbomb.Backdoorsofthistypeare
especiallydifficulttodetect,astheymayremaindormantforalongtime,possi-
blyyears,beforebeingdetected—usuallyafterthedamagehasbeendone.For
example, one network administrator had a destructive reconfiguration of his
company’snetworkexecutewhenhisprogramdetectedthathewasnolonger
employedatthecompany.
A clever trap door could be included in a compiler. The compiler could
generate standard object code as well as a trap door, regardless of the source
code being compiled. This activity is particularly nefarious, since a search of
the source code of the program will not reveal any problems. Only reverse
engineeringofthecodeofthecompileritselfwouldrevealthistrapdoor.This
typeofattackcanalsobeperformedbypatchingthecompilerorcompile-time
libraries after the fact. Indeed, in 2015, malware that targets Apple’s XCode
compiler suite (dubbed “XCodeGhost”) affected many software developers
who used compromised versions of XCode not downloaded directly from
Apple.
Trap doors pose a difficult problem because, to detect them, we have to
analyze all the source code for all components of a system. Given that soft-
ware systems may consist of millions of lines of code, this analysis is not
done frequently,and frequently it is not done at all!Asoftware development
methodology that can help counter this type of security hole is code review.
In code review, the developer who wrote the code submits it to the code
base, and one or more developers review the code and approve it or pro-
videcomments.Onceadefinedsetofreviewersapprovethecode(sometimes
after comments are addressed and the code is resubmitted and re-reviewed),
the code is admitted into the code base and then compiled, debugged, and
finallyreleasedforuse.Manygoodsoftwaredevelopersusedevelopmentver-
sion control systems that provide tools for code review—for example, git
(https://github.com/git/). Note,too,thatthereareautomaticcode-reviewand628 Chapter16 Security
#include <stdio.h>
#define BUFFER SIZE 0
int main(int argc, char *argv[])
{
int j = 0;
char buffer[BUFFER SIZE];
int k = 0;
if (argc < 2) {return -1;}
strcpy(buffer,argv[1]);
printf("K is %d, J is %d, buffer is %s∖n", j,k,buffer);
return 0;
}
}
Figure16.2 Cprogramwithbuffer-overflowcondition.
code-scanningtoolsdesignedtofindflaws,includingsecurityflaws,butgen-
erallygoodprogrammersarethebestcodereviewers.
For those not involved in developing the code, code review is useful for
finding and reporting flaws (or for finding and exploiting them). For most
software, source code is not available, making code review much harder for
nondevelopers.
16.2.2 Code Injection
Most software is not malicious, but it can nonetheless pose serious threats to
security due to a code-injection attack, in which executable code is added
or modified. Even otherwise benign software can harbor vulnerabilities that,
if exploited, allow an attacker to take over the program code, subverting its
existingcodefloworentirelyreprogrammingitbysupplyingnewcode.
Code-injection attacks are nearly always the result of poor or insecure
programming paradigms, commonly in low-level languages such as C or
C++, which allow direct memory access through pointers. This direct mem-
ory access, coupled with the need to carefully decide on sizes of memory
buffersandtakecarenottoexceedthem,canleadtomemorycorruptionwhen
memorybuffersarenotproperlyhandled.
Asanexample,considerthesimplestcode-injectionvector—abufferover-
flow.TheprograminFigure16.2illustratessuchanoverflow,whichoccursdue
to an unbounded copy operation, the call to strcpy(). The function copies
with no regard to the buffer size in question, halting only when a NULL (∖0)
byte is encountered. If such a byte occurs before the BUFFER SIZE is reached,
theprogrambehavesasexpected.Butthecopycouldeasilyexceedthebuffer
size—whatthen?
The answer is that the outcome of an overflow depends largely on the
lengthoftheoverflowandtheoverflowingcontents(Figure16.3).Italsovaries
greatly with the code generated by the compiler, which may be optimized16.2 ProgramThreats 629
Figure16.3 Thepossibleoutcomesofbufferoverflows.
in ways that affect the outcome: optimizations often involve adjustments to
memorylayout(commonly,repositioningorpaddingvariables).
1. Iftheoverflowisverysmall(onlyalittlemorethanBUFFER SIZE),thereis
agoodchanceitwillgoentirelyunnoticed.Thisisbecausetheallocation
of BUFFER SIZE bytes will often be padded to an architecture-specified
boundary (commonly 8 or 16 bytes). Padding is unused memory, and
therefore an overflow into it, though technically out of bounds, has no
illeffect.
2. If the overflow exceedsthe padding, the next automatic variable on the
stack will be overwritten with the overflowing contents. The outcome
here will depend on the exact positioning of the variable and on its
semantics (for example, if it is employed in a logical condition that can
thenbesubverted).Ifuncontrolled,thisoverflowcouldleadtoaprogram
crash,asanunexpectedvalueinavariablecouldleadtoanuncorrectable
error.
3. Iftheoverflowgreatlyexceedsthepadding,allofthecurrentfunction’s
stackframeisoverwritten.Attheverytopoftheframeisthefunction’s
return address, which is accessed when the function returns. The flow
of the program is subverted and can be redirected by the attacker to
anotherregionofmemory,includingmemorycontrolledbytheattacker
(forexample,theinputbufferitself,orthestackortheheap).Theinjected
codeisthenexecuted,allowing theattackertorunarbitrarycodeasthe
processes’effectiveID.
Notethatacarefulprogrammercouldhaveperformedboundscheckingon
the size of argv[1] by using the strncpy() function rather than strcpy(),
replacing the line “strcpy(buffer, argv[1]);” with “strncpy(buffer,
argv[1], sizeof(buffer)-1);”. Unfortunately, good bounds checking is
theexceptionratherthanthenorm.strcpy()isoneofaknownclassofvulner-
ablefunctions,whichincludesprintf(),gets(),andotherfunctionswithno630 Chapter16 Security
regardtobuffersizes.Butevensize-awarevariantscanharborvulnerabilities
when coupled with arithmetic operations over finite-length integers, which
mayleadtoanintegeroverflow.
At this point, the dangers inherent in a simple oversight in maintaining
a buffer should be clearly evident. Brian Kerningham and Dennis Ritchie (in
their book The C Programming Language) referred to the possible outcome
as“undefinedbehavior,”butperfectlypredictablebehaviorcanbecoercedby
anattacker,aswas firstdemonstratedby theMorrisWorm(and documented
in RFC1135: https://tools.ietf.org/html/rfc1135). It was not until several years
later, however, that an article in issue 49 of Phrack magazine (“Smashing the
StackforFunandProfit” http://phrack.org/issues/49/14.html)introducedthe
exploitationtechniquetothemasses,unleashingadelugeofexploits.
Toachievecodeinjection,theremustfirstbeinjectablecode.Theattacker
firstwritesashortcodesegmentsuchasthefollowing:
void func (void) {
execvp(“/bin/sh”, “/bin/sh”, NULL); ;
}
Usingtheexecvp()systemcall,thiscodesegmentcreatesashellprocess.Ifthe
program being attacked runs with root permissions, this newly created shell
will gain complete access to the system. Of course, the code segment can do
anythingallowedbytheprivilegesoftheattackedprocess.Thecodesegmentis
nextcompiledintoitsassemblybinaryopcodeformandthentransformedinto
abinarystream.Thecompiledformisoftenreferredtoasshellcode,duetoits
classicfunctionofspawningashell,butthetermhasgrowntoencompassany
typeofcode,includingmoreadvancedcodeusedtoaddnewuserstoasystem,
reboot, or even connect over the network and wait for remote instructions
(called a “reverse shell”). A shellcode exploit is shown in Figure 16.4. Code
thatisbrieflyused,onlytoredirectexecutiontosomeotherlocation,ismuch
likeatrampoline,“bouncing”codeflowfromonespottoanother.
Figure16.4 Trampolinetocodeexecutionwhenexploitingabufferoverflow.16.2 ProgramThreats 631
There are, in fact, shellcode compilers (the “MetaSploit” project being a
notable example), which also take care of such specifics as ensuring that the
codeiscompactandcontainsnoNULLbytes(incaseofexploitationviastring
copy,whichwouldterminateonNULLs).Suchacompilermayevenmaskthe
shellcodeasalphanumericcharacters.
Iftheattackerhas managed tooverwritethereturnaddress(or any func-
tion pointer, such as that of a VTable), then all it takes (in the simple case) is
toredirecttheaddresstopointtothesuppliedshellcode,whichiscommonly
loaded as part of the user input, through an environment variable, or over
somefileornetworkinput.Assumingnomitigationsexist(asdescribedlater),
this is enough for the shellcode to execute and the hacker to succeed in the
attack. Alignment considerations are often handled by adding a sequence of
NOP instructions before the shellcode. The result is known as a NOP-sled, as
it causes execution to “slide” down the NOP instructions until the payload is
encounteredandexecuted.
Thisexampleofabuffer-overflowattackrevealsthatconsiderableknowl-
edge and programming skill are needed to recognize exploitable code and
thentoexploitit.Unfortunately,itdoesnottakegreatprogrammerstolaunch
security attacks. Rather, one hacker can determine the bug and then write an
exploit.Anyonewithrudimentarycomputerskillsandaccesstotheexploit—
aso-calledscriptkiddie—canthentrytolaunchtheattackattargetsystems.
The buffer-overflow attack is especially pernicious because it can be run
betweensystemsandcantraveloverallowedcommunicationchannels. Such
attackscanoccurwithinprotocolsthatareexpectedtobeusedtocommunicate
withthetargetmachine,andtheycanthereforebehardtodetectandprevent.
Theycanevenbypassthesecurityaddedbyfirewalls(Section16.6.6).
Note that buffer overflows are just one of several vectors which can be
manipulated for code injection. Overflows can also be exploited when they
occur in the heap. Using memory buffers after freeing them, as well as over-
freeingthem(callingfree()twice),canalsoleadtocodeinjection.
16.2.3 Viruses and Worms
Anotherformofprogramthreatisavirus.Avirusisafragmentofcodeembed-
ded in a legitimate program. Viruses are self-replicating and are designed to
“infect” other programs. They can wreak havoc in a system by modifying or
destroying files and causing system crashes and program malfunctions. As
with most penetration attacks (direct attacks on a system), viruses are very
specifictoarchitectures,operatingsystems,andapplications.Virusesareapar-
ticularproblemforusersofPCs.UNIX andothermultiuseroperatingsystems
generally are not susceptible to viruses because the executable programs are
protected from writing by the operating system. Even if a virus does infect
such a program, its powers usually are limited because other aspects of the
systemareprotected.
Virusesareusuallyborneviaspame-mailandphishingattacks.Theycan
also spread when users download viral programs from Internet file-sharing
servicesorexchangeinfecteddisks.Adistinctioncanbemadebetweenviruses,
which require human activity, and worms, which use a network to replicate
withoutanyhelpfromhumans.632 Chapter16 Security
For an example of how a virus “infects” a host, consider Microsoft Office
files.Thesefilescancontainmacros(orVisualBasicprograms)thatprograms
in the Office suite (Word, PowerPoint, and Excel) will execute automatically.
Becausetheseprogramsrunundertheuser’sownaccount,themacroscanrun
largelyunconstrained (for example,deletinguser files at will). The following
codesampleshowshowsimpleitistowriteaVisualBasicmacrothataworm
couldusetoformattheharddriveofaWindowscomputerassoonasthefile
containingthemacrowasopened:
Sub AutoOpen()
Dim oFS
Set oFS = CreateObject(”Scripting.FileSystemObject”)
vs = Shell(”c: command.com /k format c:”,vbHide)
End Sub
Commonly,thewormwillalsoe-mailitselftoothersintheuser’scontactlist.
How doviruseswork? Once a virusreachesa target machine, a program
knownasavirusdropperinsertsthevirusintothesystem.Thevirusdropper
is usually a Trojan horse, executed for other reasons but installing the virus
as its core activity. Once installed, the virus may do any one of a number of
things.Thereareliterallythousandsofviruses,buttheyfallintoseveralmain
categories.Notethatmanyvirusesbelongtomorethanonecategory.
• File. A standard file virus infects a system by appending itself to a file.
It changes the start of the program so that execution jumps to its code.
Afterit executes,it returns control to the program sothat its executionis
notnoticed.Filevirusesaresometimesknownasparasiticviruses,asthey
leavenofullfilesbehindandleavethehostprogramstillfunctional.
• Boot. Aboot virus infects the boot sector of the system, executing every
time the system is booted and before the operating system is loaded. It
watchesforotherbootablemediaandinfectsthem.Thesevirusesarealso
knownasmemoryviruses,becausetheydonotappearinthefilesystem.
Figure16.5showshowabootvirusworks.Bootviruseshavealsoadapted
to infect firmware, such as network card PXE and Extensible Firmware
Interface(EFI)environments.
• Macro.Mostvirusesarewritteninalow-levellanguage,suchasassembly
or C. Macro viruses are written in a high-level language, such as Visual
Basic. These viruses are triggered when a program capable of executing
the macro is run. For example, a macro virus could be contained in a
spreadsheetfile.
• Rootkit.OriginallycoinedtodescribebackdoorsonUNIXsystemsmeant
to provide easy root access, the term has since expanded to viruses and
malware that infiltrate the operating system itself. The result is complete
systemcompromise;noaspectofthesystemcanbedeemedtrusted.When
malware infects the operating system, it can take over all of the system’s
functions,includingthosefunctionsthatwouldnormallyfacilitateitsown
detection.16.2 ProgramThreats 633
virus copies boot
sector to unused
location X
virus replaces
original boot block
with itself
at system boot, virus
decreases physical
memory, hides in memory
above new limit
virus attaches to disk read-
write interrupt, monitors all
disk activity
whenever new it blocks any attempts of it has a logic bomb to
removable R/W disk other programs to write the wreak havoc at a
is installed, it infects boot sector certain date
that as well
Figure16.5 Aboot-sectorcomputervirus.
• Sourcecode.Asourcecodeviruslooksforsourcecodeandmodifiesitto
includethevirusandtohelpspreadthevirus.
• Polymorphic. A polymorphic virus changes each time it is installed to
avoiddetectionbyantivirussoftware.Thechangesdonotaffectthevirus’s
functionalitybutratherchangethevirus’ssignature.Avirussignatureis
apatternthatcanbeusedtoidentifyavirus,typicallyaseriesofbytesthat
makeuptheviruscode.
• Encrypted. An encrypted virus includes decryption code along with the
encryptedvirus,againtoavoiddetection.Thevirusfirstdecryptsandthen
executes.
• Stealth. This trickyvirusattemptstoavoiddetectionby modifying parts
ofthesystemthatcouldbeusedtodetectit.Forexample,itcouldmodify
thereadsystemcallsothatifthefileithas modifiedisread,theoriginal
formofthecodeisreturnedratherthantheinfectedcode.634 Chapter16 Security
• Multipartite.Avirusofthistypeisabletoinfectmultiplepartsofasystem,
includingbootsectors,memory,andfiles.Thismakesitdifficulttodetect
andcontain.
• Armored.Anarmoredvirusisobfuscated—thatis,writtensoastobehard
for antivirus researchers to unravel and understand. It can also be com-
pressed to avoid detection and disinfection. In addition, virus droppers
andotherfullfilesthatarepartofavirusinfestationarefrequentlyhidden
viafileattributesorunviewablefilenames.
Thisvastvarietyofviruseshascontinuedtogrow.Forexample,in2004a
widespread virus was detected. It exploited three separate bugs for its oper-
ation. This virus started by infecting hundreds of Windows servers (includ-
ing many trusted sites) running Microsoft Internet Information Server (IIS).
Any vulnerable Microsoft Explorer web browser visiting those sites received
a browser virus with any download. The browser virus installed several
back-doorprograms,includingakeystrokelogger,whichrecordseverything
entered on the keyboard (including passwords and credit-card numbers). It
also installed a daemon to allow unlimited remote access by an intruder and
another that allowedan intrudertoroute spam through the infecteddesktop
computer.
An active security-related debate within the computing community con-
cerns the existence of a monoculture, in which many systems run the same
hardware,operatingsystem,andapplicationsoftware.Thismonoculturesup-
posedlyconsistsofMicrosoftproducts.Onequestioniswhethersuchamono-
culture even exists today. Another question is whether, if it does, it increases
thethreatofanddamagecausedbyvirusesandothersecurityintrusions.Vul-
nerability information is bought and sold in places like the dark web (World
Wide Web systems reachable via unusual client configurations or methods).
Themoresystemsanattackcanaffect,themorevaluabletheattack.
16.3 System and Network Threats
Programthreats,bythemselves,poseserioussecurityrisks.Butthoserisksare
compoundedbyordersofmagnitudewhenasystemisconnectedtoanetwork.
Worldwideconnectivitymakesthesystemvulnerabletoworldwideattacks.
The more open an operating system is—the more services it has enabled
and themorefunctions it allows—the morelikelyitisthat abug isavailable
to exploit it. Increasingly, operating systems strive to be secure by default.
For example, Solaris 10 moved from a model in which many services (FTP,
telnet, and others) were enabled by default when the system was installed
to a model in which almost all services are disabled at installation time and
must specifically be enabled by system administrators. Such changes reduce
thesystem’sattacksurface.
All hackers leave tracks behind them—whether via network traffic pat-
terns,unusualpackettypes,orothermeans.Forthatreason,hackersfrequently
launch attacks from zombie systems—independent systems or devices that
have been compromised by hackers but that continue to serve their own-
erswhilebeing usedwithouttheowners’knowledgefornefariouspurposes,16.3 SystemandNetworkThreats 635
Normal
communication
sender receiver
attacker
Masquerading
sender communication receiver
attacker
Man-in-the-middle
sender communication communication receiver
attacker
Figure16.6 Standardsecurityattacks.1
includingdenial-of-serviceattacksandspamrelay.Zombiesmakehackerspar-
ticularly difficult to track because they mask the original source of the attack
andtheidentityoftheattacker.Thisisoneofmanyreasonsforsecuring“incon-
sequential” systems, not just systems containing “valuable” information or
services—lesttheybeturnedintostrongholdsforhackers.
The widespread use of broadband and WiFi has only exacerbated the
difficulty in tracking down attackers: even a simple desktop machine, which
canoftenbeeasilycompromisedbymalware,canbecomeavaluablemachine
if used for its bandwidth or network access. Wireless ethernet makes it easy
for attackers to launch attacks by joining a public network anonymously or
“WarDriving”—locatingaprivateunprotectednetworktotarget.
16.3.1 Attacking Network Traffic
Networksarecommonandattractivetargets,andhackershavemanyoptions
for mounting network attacks. As shown in Figure 16.6, an attacker can opt
toremainpassiveandinterceptnetworktraffic(anattackcommonly referred
toassniffin ),oftenobtaining usefulinformationaboutthetypesof sessions
1LorelynMedina/Shutterstock.636 Chapter16 Security
conductedbetweensystemsorthesessions’content.Alternatively,anattacker
cantakeamoreactiverole,eithermasqueradingasoneoftheparties(referred
toasspoofin ),orbecomingafullyactiveman-in-the-middle,interceptingand
possiblymodifyingtransactionsbetweentwopeers.
Next,wedescribeacommontypeofnetworkattack,thedenial-of-service
(DoS) attack. Note that it is possible to guard against attacks through such
meansasencryptionandauthentication,whicharediscussedlaterinthechap-
ter.Internetprotocolsdonot,however,supporteitherencryptionorauthenti-
cationbydefault.
16.3.2 Denial of Service
Asmentionedearlier,denial-of-serviceattacksareaimednotatgaininginfor-
mation or stealing resources but rather at disrupting legitimate use of a sys-
tem or facility. Most such attacks involve target systems or facilities that the
attackerhasnotpenetrated.Launchinganattackthatpreventslegitimateuse
isfrequentlyeasierthanbreakingintoasystemorfacility.
Denial-of-service attacks are generally network based. They fall into two
categories. Attacks in the first category use so many facility resources that,
in essence, no useful work can be done. For example, a website click could
download a Java applet that proceedsto use all available CPU time or to pop
upwindowsinfinitely.Thesecondcategoryinvolvesdisruptingthenetworkof
thefacility.Therehavebeenseveralsuccessfuldenial-of-serviceattacksofthis
kindagainstmajorwebsites.Suchattacks,whichcanlasthoursordays,have
caused partial or full failure of attempts to use the target facility. The attacks
are usually stopped at the network level until the operating systems can be
updatedtoreducetheirvulnerability.
Generally,itisimpossibletopreventdenial-of-serviceattacks.Theattacks
usethesamemechanismsasnormaloperation.Evenmoredifficulttoprevent
and resolve are Distributed Denial-of-Service (DDoS) attacks. These attacks
arelaunchedfrommultiplesitesatonce,towardacommontarget,typicallyby
zombies. DDoS attacks have become more common and are sometimes asso-
ciated with blackmail attempts. Asite comes under attack, and the attackers
offertohalttheattackinexchangeformoney.
Sometimesasitedoesnot evenknow itisunderattack.Itcan bedifficult
todeterminewhetherasystemslowdownisanattackorjustasurgeinsystem
use. Consider that a successful advertising campaign that greatly increases
traffictoasitecouldbeconsideredaDDoS.
There are other interesting aspects of DoS attacks. For example, if an
authentication algorithm locks an account for a period of time after several
incorrect attempts to access the account, then an attacker could cause all
authenticationtobeblockedbypurposelymakingincorrectattemptstoaccess
allaccounts.Similarly,afirewallthatautomaticallyblockscertainkindsoftraf-
fic could be induced to block that traffic when it should not. These examples
suggest that programmers and systems managers need to fully understand
thealgorithmsandtechnologiestheyaredeploying.Finally,computerscience
classes are notorious sources of accidental system DoS attacks. Consider the
first programming exercises in which students learn to create subprocesses
or threads. A common bug involves spawning subprocesses infinitely. The
system’sfreememoryandCPUresourcesdon’tstandachance.16.4 CryptographyasaSecurityTool 637
16.3.3 Port Scanning
Port scanning is not itself an attack but is a means for a hacker to detect a
system’s vulnerabilities to attack. (Security personnel also use port scanning
—forexample,todetectservicesthatarenotneededorarenotsupposedtobe
running.)Portscanningtypicallyisautomated,involvingatoolthatattempts
tocreateaTCP/IPconnectionorsendaUDPpackettoaspecificportorarange
ofports.
Port scanning is often part of a reconnaissance technique known as fin-
gerprinting, in which an attacker attempts to deduce the type of operating
systeminuseanditssetofservicesinordertoidentifyknownvulnerabilities.
Many servers and clients make this easier by disclosing their exact version
number as part of network protocol headers (for example, HTTP’s “Server:”
and “User-Agent:” headers). Detailed analyses of idiosyncratic behaviors by
protocolhandlerscanalsohelptheattackerfigureoutwhatoperatingsystem
thetargetisusing—anecessarystepforsuccessfulexploitation.
Network vulnerability scanners are sold as commercial products. There
are also tools that perform subsets of the functionality of a full scanner. For
example,nmap(fromhttp://www.insecure.org/nmap/)isaveryversatileopen-
source utility for network exploration and security auditing. When pointed
atatarget,itwilldeterminewhat servicesarerunning, including application
names and versions. It can identify the host operating system. It can also
provide information about defenses, such as what firewalls are defending
the target. It does not exploit known bugs. Other tools, however (such as
Metasploit), pick up where the port scanners leave off and provide payload
construction facilities that can be used to test for vulnerabilities—or exploit
thembycreatingaspecificpayloadthattriggersthebug.
The seminal work on port-scanning techniques can be found in
http://phrack.org/issues/49/15.html. Techniques are constantly evolving,
as are measures to detect them (which form the basis for network intrusion
detectionsystems,discussedlater).
16.4 Cryptography as a Security Tool
There are many defenses against computer attacks, running the gamut from
methodology to technology. The broadest tool available to system designers
and users is cryptography. In this section, we discuss cryptography and its
useincomputersecurity.Notethatthecryptographydiscussedherehasbeen
simplified for educational purposes; readers are cautioned against using any
ofthe schemesdescribedhereinthe realworld.Good cryptographylibraries
arewidelyavailableandwouldmakeagoodbasisforproductionapplications.
In an isolated computer, the operating system can reliably determine the
sender and recipient of all interprocess communication, since it controls all
communication channels in the computer. In a network of computers, the
situation is quite different. A networked computer receives bits “from the
wire” with no immediate and reliable way of determining what machine or
applicationsentthosebits.Similarly,thecomputersendsbitsontothenetwork
with no way of knowing who might eventually receive them. Additionally,
when either sending or receiving, the system has no way of knowing if an
eavesdropperlistenedtothecommunication.638 Chapter16 Security
Commonly,networkaddressesareusedtoinferthepotentialsendersand
receiversofnetworkmessages.Networkpacketsarrivewithasourceaddress,
such as an IP address. And when a computer sends a message, it names the
intended receiver by specifying a destination address. However, for appli-
cations where security matters, we are asking for trouble if we assume that
thesource or destinationaddressofapacket reliablydetermineswhosent or
received that packet. A rogue computer can send a message with a falsified
sourceaddress,and numerouscomputersotherthantheonespecifiedby the
destinationaddresscan(andtypicallydo)receiveapacket.Forexample,allof
theroutersonthewaytothedestinationwillreceivethepacket,too.How,then,
isanoperatingsystemtodecidewhethertograntarequestwhenitcannottrust
thenamedsourceoftherequest?Andhowisitsupposedtoprovideprotection
for arequestordatawhenit cannot determinewho will receivethe response
ormessagecontentsitsendsoverthenetwork?
It is generally considered infeasible to build a network of any scale in
which the source and destination addresses of packets can be trusted in this
sense. Therefore, the only alternative is somehow to eliminate the need to
trustthenetwork.Thisisthejobofcryptography.Abstractly,cryptographyis
usedtoconstrainthepotentialsendersand/orreceiversofamessage.Modern
cryptographyisbasedonsecretscalledkeysthatareselectivelydistributedto
computersinanetworkandusedtoprocessmessages.Cryptographyenablesa
recipientofamessagetoverifythatthemessagewascreatedbysomecomputer
possessing a certain key. Similarly, a sender can encode its message so that
only a computer with a certain key can decode the message. Unlike network
addresses,however,keysaredesignedsothatitisnotcomputationallyfeasible
toderivethemfromthemessagestheywereusedtogenerateorfromanyother
public information. Thus, they provide a much more trustworthy means of
constrainingsendersandreceiversofmessages.
Cryptography is a powerful tool, and the use of cryptography can cause
contention. Some countries ban its use in certain forms or limit how long the
keyscanbe.Othershaveongoingdebatesaboutwhethertechnologyvendors
(suchassmartphonevendors)mustprovideabackdoortotheincludedcryp-
tography, allowing law enforcement to bypass the privacy it provides. Many
observersargue,however,thatbackdoorsareanintentionalsecurityweakness
thatcouldbeexploitedbyattackersorevenmisusedbygovernments.
Finally,notethatcryptographyisafieldofstudyuntoitself,withlargeand
smallcomplexitiesandsubtleties.Here,weexplorethemostimportantaspects
ofthepartsofcryptographythatpertaintooperatingsystems.
16.4.1 Encryption
Becauseitsolvesawidevarietyofcommunicationsecurityproblems,encryp-
tionisusedfrequentlyinmanyaspectsofmoderncomputing.Itisusedtosend
messagessecurelyacross anetwork, as wellas toprotectdatabase data,files,
andevenentiredisksfromhavingtheircontentsreadbyunauthorizedentities.
Anencryptionalgorithm enables the senderof amessagetoensurethat only
a computer possessing a certain key can read the message or to ensure that
thewriterofdataistheonly readerofthedata.Encryptionofmessagesisan
ancient practice,ofcourse,andtherehavebeenmanyencryptionalgorithms,16.4 CryptographyasaSecurityTool 639
dating back to ancient times. In this section, we describe important modern
encryptionprinciplesandalgorithms.
Anencryptionalgorithmconsistsofthefollowingcomponents:
• AsetKofkeys.
• AsetMofmessages.
• AsetCofciphertexts.
• An encrypting function E : K → (M → C). That is, for each k ∈ K, E is a
k
functionforgeneratingciphertextsfrommessages.BothEandE foranyk
k
shouldbeefficientlycomputablefunctions.Generally,E isarandomized
k
mappingfrommessagestociphertexts.
• Adecrypting function D : K → (C → M). That is, for each k ∈ K, D is a
k
functionforgeneratingmessagesfromciphertexts.BothDandD forany
k
kshouldbeefficientlycomputablefunctions.
An encryption algorithm must provide this essential property: given a
ciphertext c ∈ C, a computer can compute m such that E (m) = c only
k
if it possesses k. Thus, a computer holding k can decrypt ciphertexts to the
plaintextsusedtoproducethem,butacomputernotholdingkcannotdecrypt
ciphertexts. Since ciphertexts are generally exposed (for example, sent on a
network),itisimportantthatitbeinfeasibletoderivekfromtheciphertexts.
Therearetwomaintypesofencryptionalgorithms:symmetricandasym-
metric.Wediscussbothtypesinthefollowingsections.
16.4.1.1 SymmetricEncryption
In a symmetric encryption algorithm, the same key is used to encrypt and
to decrypt. Therefore, the secrecy of k must be protected. Figure 16.7 shows
an example of two users communicating securely via symmetric encryption
over an insecure channel. Note that the key exchange can take place directly
betweenthetwopartiesorviaatrustedthirdparty(thatis,acertificateauthor-
ity),asdiscussedinSection16.4.1.4.
Forthepastseveraldecades,themostcommonlyusedsymmetricencryp-
tionalgorithmintheUnitedStatesforcivilianapplicationshasbeenthedata-
encryption standard (DES) cipher adopted by the National Institute of Stan-
dardsandTechnology(NIST).DESworksbytakinga64-bitvalueanda56-bit
keyandperformingaseriesoftransformationsthatarebasedonsubstitution
andpermutationoperations.BecauseDESworksonablockofbitsatatime,is
knownasablockcipher,anditstransformationsaretypicalofblockciphers.
Withblockciphers,ifthesamekeyisusedforencryptinganextendedamount
ofdata,itbecomesvulnerabletoattack.
DESisnowconsideredinsecureformanyapplicationsbecauseitskeyscan
beexhaustivelysearchedwithmoderatecomputingresources.(Note,though,
that it is still frequently used.) Rather than giving up on DES, NIST created a
modification called triple DES, in which the DES algorithm is repeated three
times (two encryptions and one decryption) on the same plaintext using two
or three keys—for example, c = E (D (E (m))). When three keys are used,
k3 k2 k1
theeffectivekeylengthis168bits.640 Chapter16 Security
write message m
encryption encryption
key k algorithm
E
key
exchange
decryption decryption
key k algorithm
D
read message m
erucesni lennahc c =
Ek(m)
m
=
Dk(c)
plaintext
ciphertext
plaintext
attacker
Figure16.7 Asecurecommunicationoveraninsecuremedium.2
In2001,NISTadoptedanewblockcipher,calledtheadvancedencryption
standard(AES),toreplaceDES.AES(alsoknownasRijndael)hasbeenstandard-
ized in FIPS-197 (http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.197.pdf). It
canusekeylengthsof128,192,or256bitsandworkson128-bitblocks. Gen-
erally,thealgorithmiscompactandefficient.
Blockciphersarenotnecessarilysecureencryptionschemes.Inparticular,
they do not directly handle messages longer than their required block sizes.
Analternativeisstreamciphers,whichcanbeusedtosecurelyencryptlonger
messages.
Astream cipher is designed to encrypt and decrypt a stream of bytes or
bits rather than a block. This is useful when the length of a communication
wouldmakeablockciphertooslow.Thekeyisinputintoapseudo–random-
bit generator, which is an algorithm that attempts to produce random bits.
The output of the generator when fed a key is a keystream. A keystream is
an infinite set of bits that can be used to encrypt a plaintext stream through
anXORoperation.(XOR,for“exclusiveOR”isanoperationthatcomparestwo
inputbitsandgeneratesoneoutputbit.Ifthebitsarethesame,theresultis0.
Ifthebitsaredifferent,theresultis1.)AES-basedciphersuitesincludestream
ciphersandarethemostcommontoday.
2LorelynMedina/Shutterstock.16.4 CryptographyasaSecurityTool 641
16.4.1.2 AsymmetricEncryption
In an asymmetric encryption algorithm, there are different encryption and
decryption keys. An entity preparing to receive encrypted communication
creates two keys and makes one of them (called the public key) available to
anyonewhowantsit.Anysendercanusethatkeytoencryptacommunication,
butonlythekeycreatorcandecryptthecommunication.Thisscheme,known
as public-key encryption, was a breakthrough in cryptography (first
described by Diffie and Hellman in https://www-ee.stanford.edu/ hell-
man/publications/24.pdf).Nolongermustakeybekeptsecretanddelivered
securely.Instead,anyonecanencryptamessagetothereceivingentity,andno
matterwhoelseislistening,onlythatentitycandecryptthemessage.
Asanexampleofhowpublic-keyencryptionworks,wedescribeanalgo-
rithm known as RSA, afterits inventors,Rivest,Shamir,and Adleman.RSAis
the most widely used asymmetric encryption algorithm. (Asymmetric algo-
rithmsbasedonellipticcurvesaregainingground,however,becausethekey
length of such an algorithm can be shorter for the same amount of crypto-
graphicstrength.)
In RSA, k is the publickey, and k is the private key. N is the product of
e d
twolarge,randomlychosenprimenumberspandq(forexample,pandqare
2048bitseach).Itmustbecomputationallyinfeasibletoderivek fromk ,so
d,N e,N
thatk neednotbekeptsecretandcanbewidelydisseminated.Theencryption
e
algorithmisE ke,N(m)=mk e modN,wherek esatisfiesk ek d mod(p−1)(q−1)=1.
ThedecryptionalgorithmisthenD k ,N(c)=ck d modN.
d
AnexampleusingsmallvaluesisshowninFigure16.8.Inthisexample,we
makep=7andq=13.WethencalculateN =7∗13=91and(p−1)(q−1)=72.
Wenextselectk relativelyprimeto72and<72,yielding5.Finally,wecalculate
e
k suchthatk k mod72=1,yielding29.Wenowhaveourkeys:thepublickey,
d e d
k = 5,91,andtheprivatekey,k = 29,91.Encryptingthemessage69with
e,N d,N
thepublickeyresultsinthemessage62,whichisthendecodedbythereceiver
viatheprivatekey.
Theuseofasymmetricencryptionbeginswiththepublicationofthepublic
keyofthedestination.Forbidirectionalcommunication,thesourcealsomust
publish its public key. “Publication” can be as simple as handing over an
electroniccopyofthekey,oritcanbemorecomplex.Theprivatekey(or“secret
key”)mustbezealouslyguarded,asanyoneholdingthatkeycandecryptany
messagecreatedbythematchingpublickey.
We should note that the seemingly small difference in key use between
asymmetricandsymmetriccryptographyisquitelargeinpractice.Asymmet-
ric cryptography is much more computationally expensive to execute. It is
muchfasterforacomputertoencodeanddecodeciphertextbyusingtheusual
symmetric algorithms than by using asymmetric algorithms. Why, then, use
anasymmetricalgorithm?Intruth,thesealgorithmsarenotusedforgeneral-
purposeencryptionoflargeamountsofdata.However,theyareusednotonly
forencryptionofsmallamountsofdatabutalsoforauthentication,confiden-
tiality,andkeydistribution,asweshowinthefollowingsections.
16.4.1.3 Authentication
We have seen that encryption offers a way of constraining the set of possible
receiversofamessage.Constrainingthesetofpotentialsendersofamessage642 Chapter16 Security
write message 69
encryption
695 mod 91
key k
5,91
decryption
6229 mod 91
key k
29,91
read 69
erucesni lennahc
plaintext
62
Figure16.8 EncryptionanddecryptionusingRSAasymmetriccryptography.3
iscalledauthentication.Authenticationisthuscomplementarytoencryption.
Authenticationisalsousefulforprovingthatamessagehasnotbeenmodified.
Next, we discuss authentication as a constraint on possible senders of a mes-
sage. Note that this sort of authentication is similar to but distinct from user
authentication,whichwediscussinSection16.5.
Anauthenticationalgorithmusingsymmetrickeysconsistsofthefollow-
ingcomponents:
• AsetKofkeys.
• AsetMofmessages.
• AsetAofauthenticators.
• Afunction S : K → (M → A). That is, for each k ∈ K, S is a function for
k
generatingauthenticators from messages.Both S and S for any k should
k
beefficientlycomputablefunctions.
3LorelynMedina/Shutterstock.16.4 CryptographyasaSecurityTool 643
• AfunctionV : K → (M×A →{true,false}).Thatis,foreachk ∈ K,V
k
is afunction for verifyingauthenticators on messages.Both V and V for
k
anykshouldbeefficientlycomputablefunctions.
Thecriticalpropertythatanauthenticationalgorithmmustpossessisthis:
for a message m, a computer can generate an authenticator a ∈ A such that
V (m,a)=trueonlyifitpossessesk.Thus,acomputerholdingkcangenerate
k
authenticatorsonmessagessothatanycomputerpossessingkcanverifythem.
However, a computer not holding k cannot generate authenticators on mes-
sagesthatcanbeverifiedusingV .Sinceauthenticatorsaregenerallyexposed
k
(forexample,sentonanetworkwiththemessagesthemselves),itmustnotbe
feasibletoderivekfromtheauthenticators.Practically,ifV (m,a)=true,then
k
weknowthatmhasnotbeenmodifiedandthatthesenderofthemessagehas
k.Ifwesharekwithonlyoneentity,thenweknowthatthemessageoriginated
fromk.
Just as there are two types of encryption algorithms, there are two main
varieties of authentication algorithms. The first step in understanding these
algorithmsistoexplorehashfunctions.AhashfunctionH(m)createsasmall,
fixed-sized block of data, known as a message digest or hash value, from a
messagem.Hashfunctionsworkbytakingamessage,splittingitintoblocks,
andprocessingtheblockstoproduceann-bithash.H mustbecollisionresis-
tant—that is,itmustbeinfeasibletofind anm′ ≠ msuchthat H(m) = H(m′).
Now, if H(m) = H(m′), we know that m = m′—that is, we know that the
message has not been modified. Common message-digest functions include
MD5 (now considered insecure), which produces a 128-bit hash, and SHA-1,
whichoutputsa160-bithash.Messagedigestsareusefulfordetectingchanged
messagesbut are not useful as authenticators. For example, H(m)can be sent
alongwithamessage;butifHisknown,thensomeonecouldmodifymtom′
and recompute H(m′), and the message modification would not be detected.
Therefore,wemustauthenticateH(m).
Thefirstmaintypeofauthenticationalgorithmusessymmetricencryption.
Inamessage-authenticationcode(MAC),acryptographicchecksumisgener-
ated from the message using a secret key. AMAC provides a way to securely
authenticate short values. If we use it to authenticate H(m) for an H that is
collisionresistant,thenweobtainawaytosecurelyauthenticatelongmessages
by hashing them first. Note that k is needed to compute both S and V , so
k k
anyoneabletocomputeonecancomputetheother.
The second main type of authentication algorithm is a digital-signature
algorithm,andtheauthenticatorsthusproducedarecalleddigitalsignatures.
Digital signatures are very useful in that they enable anyone to verify the
authenticityofthemessage.Inadigital-signaturealgorithm,itiscomputation-
allyinfeasibletoderivek fromk .Thus,k isthepublickey,andk istheprivate
s v v s
key.
ConsiderasanexampletheRSAdigital-signaturealgorithm.Itissimilarto
theRSAencryptionalgorithm,butthekeyuseisreversed.Thedigitalsignature
ofamessageisderivedbycomputingS ks(m)=H(m)k s modN.Thekeyk sagain
is a pair ⟨d,N⟩, where N is the product of two large, randomly chosen prime
?
numbers p and q. The verification algorithm is then V kv(m,a)=ak v modN =
H(m)), where k satisfies k k mod(p − 1)(q − 1) = 1. Digital signatures (as is
v v s
the case with many aspects of cryptography) can be used on other entities644 Chapter16 Security
than messages. For example creators of programs can “sign their code” via
a digital signature to validate that the code has not been modified between
itspublicationanditsinstallationonacomputer.Codesigninghasbecomea
verycommonsecurityimprovementmethodonmanysystems.
Note that encryption and authentication may be used together or sepa-
rately.Sometimes,forinstance,wewantauthenticationbutnotconfidentiality.
Forexample,acompanycouldprovideasoftwarepatchandcould“sign”that
patchtoprovethatitcamefromthecompanyandthatithasn’tbeenmodified.
Authentication is a component of many aspects of security. For example,
digitalsignaturesarethecoreofnonrepudiation,whichsuppliesproofthatan
entityperformedanaction.Atypicalexampleofnonrepudiationinvolvesthe
fillingoutofelectronicformsasanalternativetothesigningofpapercontracts.
Nonrepudiation assures that a person filling out an electronic form cannot
denythathedidso.
16.4.1.4 KeyDistribution
Certainly, a good part of the battle between cryptographers (those inventing
ciphers) and cryptanalysts (those trying to break them) involves keys. With
symmetricalgorithms,bothpartiesneedthekey,andnooneelseshouldhave
it. The delivery of the symmetric key is a huge challenge. Sometimes it is
performedout-of-band.For example,if Walter wanted to communicate with
Rebeccasecurely,theycouldexchangeakeyviaapaperdocumentoraconver-
sationandthenhavethecommunicationelectronically.Thesemethodsdonot
scale well, however. Also consider the key-management challenge. Suppose
LucywantedtocommunicatewithN otherusersprivately.Lucywouldneed
Nkeysand,formoresecurity,wouldneedtochangethosekeysfrequently.
Thesearetheveryreasonsforeffortstocreateasymmetrickeyalgorithms.
Not only can the keys be exchanged in public, but a given user, say Audra,
needs only one private key, no matter how many other people she wants to
communicatewith.Thereisstillthematterofmanagingapublickeyforeach
recipient of the communication, but since public keys need not be secured,
simplestoragecanbeusedforthatkeyring.
Unfortunately, even the distribution of public keys requires some care.
Considertheman-in-the-middleattackshowninFigure16.9.Here,theperson
who wants to receive an encrypted message sends out his public key, but an
attackeralsosendsher“bad”publickey(whichmatchesherprivatekey).The
personwhowantstosendtheencryptedmessageknowsnobetterandsouses
thebadkeytoencryptthemessage.Theattackerthenhappilydecryptsit.
The problemisone of authentication—what we needisproofofwho (or
what) owns a public key. One way to solve that problem involves the use
of digital certificates. Adigital certificat is a public key digitally signed by
a trusted party. The trusted party receives proof of identification from some
entity and certifies that the public key belongs to that entity. But how do
we know we can trust the certifier? These certificat authorities have their
publickeysincludedwithinwebbrowsers(andotherconsumersofcertificates)
beforetheyaredistributed.Thecertificateauthoritiescanthenvouchforother
authorities (digitally signing the public keys of these other authorities), and
soon,creatingaweboftrust.Thecertificatescanbedistributedinastandard16.4 CryptographyasaSecurityTool 645
write message m
encryption encryption
key k algorithm
bad
E
3.
E
kbad(
m)
decryption decryption
keyk algorithm
bad
D
read message m
decryption decryption
keyk algorithm
d
D
keykbad
keyke
2.
Public
1.
Public
attacker
Figure16.9 Aman-in-the-middleattackonasymmetriccryptography.4
X.509digitalcertificateformatthatcanbeparsedbycomputer.Thisschemeis
usedforsecurewebcommunication,aswediscussinSection16.4.3.
16.4.2 Implementation of Cryptography
Networkprotocolsaretypicallyorganizedinlayers,witheachlayeractingas
a client of the one below it. That is, when one protocol generates a message
to send to its protocol peer on another machine, it hands its message to the
protocolbelowitinthenetwork-protocolstackfordeliverytoitspeeronthat
machine.Forexample,inanIPnetwork,TCP(atransport-layerprotocol)actsas
aclientofIP(anetwork-layerprotocol):TCPpacketsarepasseddowntoIPfor
deliverytotheIPpeerattheotherendoftheconnection.IPencapsulatestheTCP
packetinanIPpacket,whichitsimilarlypassesdowntothedata-linklayerto
betransmittedacrossthenetworktoitspeeronthedestinationcomputer.This
IPpeerthendeliverstheTCPpacketuptotheTCPpeeronthatmachine.Seven
4LorelynMedina/Shutterstock.646 Chapter16 Security
suchlayersareincludedintheOSImodel,mentionedearlieranddescribedin
detailinSection19.3.2.
Cryptography can be inserted at almost any layer in network protocol
stacks. TLS (Section 16.4.3), for example, provides security at the transport
layer.Network-layersecuritygenerallyhasbeenstandardizedonIPSec,which
defines IP packet formats that allow the insertion of authenticators and the
encryption of packet contents. IPSec uses symmetric encryption and uses the
InternetKeyExchange(IKE)protocolforkeyexchange.IKEisbasedonpublic-
keyencryption.IPSechaswidelyusedasthebasisforvirtualprivatenetworks
(VPNs),inwhichalltrafficbetweentwoIPSecendpointsisencryptedtomakea
privatenetworkoutofonethatwouldotherwisebepublic.Numerousproto-
colsalsohavebeendevelopedforusebyapplications,suchasPGPforencrypt-
inge-mail;inthistypeofscheme,theapplicationsthemselvesmustbecoded
toimplementsecurity.
Whereiscryptographicprotectionbestplacedinaprotocolstack?Ingen-
eral,thereisnodefinitiveanswer.Ontheonehand,moreprotocolsbenefitfrom
protections placed lower in the stack. For example, since IPpackets encapsu-
lateTCPpackets,encryptionofIPpackets(usingIPSec,forexample)alsohides
the contents of the encapsulated TCP packets. Similarly, authenticators on IP
packetsdetectthemodificationofcontainedTCPheaderinformation.
On the other hand, protection at lower layers in the protocol stack may
give insufficient protection to higher-layer protocols. For example, an appli-
cation server that accepts connections encrypted with IPSec might be able to
authenticatetheclientcomputersfromwhichrequestsarereceived.However,
to authenticate a user at a client computer, the server may need to use an
application-levelprotocol—theusermayberequiredtotypeapassword.Also
consider the problem of e-mail. E-mail delivered via the industry-standard
SMTPprotocol isstoredandforwarded,frequentlymultipletimes,beforeitis
delivered. Each of these transmissions could go over a secure or an insecure
network.Fore-mailtobesecure,thee-mailmessageneedstobeencryptedso
thatitssecurityisindependentofthetransportsthatcarryit.
Unfortunately,likemanytools,encryptioncanbeusednotonlyfor“good”
butalsofor“evil.”Theransomwareattacksdescribedearlier,forexample,are
basedonencryption.Asmentioned,theattackersencryptinformationonthe
target system and render it inaccessible to the owner. The idea is to force the
ownertopayaransomtogetthekeyneededtodecryptthedata.Preventionof
suchattackstakestheformofbettersystemandnetworksecurityandawell-
executedbackupplansothatthecontentsofthefilescanberestoredwithout
thekey.
16.4.3 An Example: TLS
Transport Layer Security (TLS) is a cryptographic protocol that enables two
computerstocommunicatesecurely—thatis,sothateachcanlimitthesender
and receiver of messages to the other. It is perhaps the most commonly
used cryptographic protocol on the Internet today, since it is the standard
protocol by which web browsers communicate securely with web servers.
For completeness, we should note that TLS evolved from SSL (Secure Sock-
ets Layer), which was designed by Netscape. It is described in detail in
https://tools.ietf.org/html/rfc5246.16.4 CryptographyasaSecurityTool 647
TLSisacomplexprotocolwithmanyoptions.Here,wepresentonlyasingle
variationofit.Eventhen,wedescribeitinaverysimplifiedandabstractform,
so as to maintain focus on its use of cryptographic primitives. What we are
abouttoseeisacomplexdanceinwhichasymmetriccryptographyisusedso
thataclientandaservercanestablishasecuresessionkeythatcanbeusedfor
symmetricencryptionofthesessionbetweenthetwo—allofthiswhileavoid-
ingman-in-the-middleandreplayattacks.Foraddedcryptographicstrength,
thesessionkeysareforgottenonceasessioniscompleted.Anothercommuni-
cationbetweenthetwowillrequiregenerationofnewsessionkeys.
The TLS protocol is initiated by a client c to communicate securely with a
server. Prior to the protocol’s use, the server s is assumed to have obtained a
certificate, denoted cert, from certification authority CA. This certificate is a
s
structurecontainingthefollowing:
• Various attributes (attrs) of the server, such as its unique distinguished
nameanditscommon(DNS)name
• TheidentityofaasymmetricencryptionalgorithmE()fortheserver
• Thepublickeyk ofthisserver
e
• Avalidityinterval(interval)duringwhichthecertificateshouldbeconsid-
eredvalid
• Adigitalsignatureaonthe aboveinformationmadebythe CA—that is,
a=S (⟨attrs,E ,interval⟩)
kCA ke
Inaddition,priortotheprotocol’suse,theclientispresumedtohaveobtained
thepublicverificationalgorithmV forCA.Inthecaseoftheweb,theuser’s
kCA
browserisshippedfromitsvendorcontainingtheverificationalgorithmsand
publickeysofcertaincertificationauthorities.Theusercandeletetheseoradd
others.
Whencconnectstos,itsendsa28-byterandomvaluen totheserver,which
c
respondswitharandomvaluen ofitsown,plusitscertificatecert .Theclient
s s
verifies that V (⟨ attrs, E , interval⟩, a) = true and that the current time is
kCA ke
in the validity interval interval. If both of these tests are satisfied, the server
hasproveditsidentity.Thentheclientgeneratesarandom46-bytepremaster
secretpmsandsendscpms=E (pms)totheserver.Theserverrecoverspms
ke
= D (cpms). Now both the client and the server are in possession of n , n ,
kd c s
andpms,andeachcancomputeashared48-bytemastersecret ms=H(n ,n ,
c s
pms).Onlytheserverandclientcancomputems,sinceonlytheyknowpms.
Moreover,thedependenceofmsonn andn ensuresthatmsisafreshvalue
c s
—that is, a session key that has not been used in a previous communication.
Atthispoint,theclientandtheserverbothcomputethefollowingkeysfrom
thems:
• Asymmetricencryptionkeyk𝖼𝗋𝗒𝗉𝗍 forencryptingmessagesfromtheclient
cs
totheserver
• Asymmetricencryptionkeyk𝖼𝗋𝗒𝗉𝗍 forencryptingmessagesfromtheserver
sc
totheclient
• AMACgenerationkeyk𝗆𝖺𝖼forgeneratingauthenticatorsonmessagesfrom
cs
theclienttotheserver648 Chapter16 Security
• AMACgenerationkeyk𝗆𝖺𝖼forgeneratingauthenticatorsonmessagesfrom
sc
theservertotheclient
Tosendamessagemtotheserver,theclientsends
c=E k𝖼𝗋𝗒𝗉𝗍(⟨m,S k𝗆𝖺𝖼(m)⟩).
cs cs
Uponreceivingc,theserverrecovers
⟨m,a⟩=D k𝖼𝗋𝗒𝗉𝗍(c)
cs
andacceptsmifV (m,a)=true.Similarly,tosendamessagemtotheclient,
k𝗆𝖺𝖼
cs
theserversends
c=E k𝖼𝗋𝗒𝗉𝗍(⟨m,S k𝗆𝖺𝖼(m)⟩)
sc sc
andtheclientrecovers
⟨m,a⟩=D k𝖼𝗋𝗒𝗉𝗍(c)
sc
andacceptsmifV (m,a)=true.
k𝗆𝖺𝖼
sc
Thisprotocolenablestheservertolimittherecipientsofitsmessagestothe
clientthatgeneratedpmsandtolimitthesendersofthemessagesitacceptsto
that same client. Similarly, the client can limit the recipients of the messages
itsendsandthe sendersofthe messagesitacceptstothepartythat knows k
d
(that is, the party that can decryptcpms). In many applications, such as web
transactions,theclientneedstoverifytheidentityofthepartythatknowsk .
d
Thisisonepurposeofthecertificatecert .Inparticular,theattrsfieldcontains
s
informationthattheclientcanusetodeterminetheidentity—forexample,the
domainname—oftheserverwithwhichitiscommunicating.Forapplications
in which the server also needs information about the client, TLS supports an
optionbywhichaclientcansendacertificatetotheserver.
InadditiontoitsuseontheInternet,TLSisbeingusedforawidevarietyof
tasks.Forexample,wementionedearlierthatIPSeciswidelyusedasthebasis
forvirtualprivatenetworks,orVPNs.IPSecVPNsnowhaveacompetitorinTLS
VPNs.IPSecisgoodforpoint-to-pointencryptionoftraffic—say,betweentwo
companyoffices.TLSVPNsaremoreflexiblebutnotasefficient,sotheymight
beusedbetweenanindividualemployeeworkingremotelyandthecorporate
office.
16.5 User Authentication
Our earlier discussion of authentication involves messages and sessions. But
what about users?Ifasystemcannot authenticateauser,thenauthenticating
thatamessagecamefromthatuserispointless.Thus,amajorsecurityproblem
for operating systems is user authentication. The protectionsystemdepends
on the ability to identify the programs and processes currently executing,
whichinturndependsontheabilitytoidentifyeachuserofthesystem.Users
normally identify themselves, but how do we determine whether a user’s
identity is authentic? Generally, user authentication is based on one or more
of three things: the user’s possession of something (a key or card), the user’s
knowledgeofsomething(auseridentifierandpassword),oranattributeofthe
user(fingerprint,retinapattern,orsignature).16.5 UserAuthentication 649
16.5.1 Passwords
The most common approach to authenticating a user identity is the use of
passwords. When the user identifies herself by user ID or account name, she
isaskedforapassword.Iftheuser-suppliedpasswordmatchesthepassword
storedinthesystem,thesystemassumesthattheaccountisbeingaccessedby
theownerofthataccount.
Passwords are often used to protect objects in the computer system, in
the absence of more complete protection schemes. They can be considered a
special case of either keys or capabilities. For instance, a password may be
associated with each resource (such as a file). Whenever a requestis made to
usetheresource,thepasswordmustbegiven.Ifthepasswordiscorrect,access
isgranted.Differentpasswordsmaybeassociatedwithdifferentaccessrights.
For example, different passwords may be used for reading files, appending
files,andupdatingfiles.
In practice, most systems require only one password for a user to gain
theirfullrights.Althoughmorepasswordstheoreticallywouldbemoresecure,
suchsystemstendnottobeimplementedduetotheclassictrade-offbetween
securityandconvenience.Ifsecuritymakessomethinginconvenient,thenthe
securityisfrequentlybypassedorotherwisecircumvented.
16.5.2 Password Vulnerabilities
Passwords are extremely common because they are easy to understand and
use. Unfortunately, passwords can often be guessed, accidentally exposed,
sniffed(readbyaneavesdropper),orillegallytransferredfromanauthorized
usertoanunauthorizedone,asweshownext.
There are three common ways to guess a password. One way is for the
intruder (either human or program) to know the user or to have information
abouttheuser.Alltoofrequently,peopleuseobviousinformation(suchasthe
namesoftheircatsorspouses)astheirpasswords.Anotherwayistousebrute
force, trying enumeration—or all possible combinations of valid password
characters (letters, numbers, and punctuation on some systems)—until the
passwordisfound.Shortpasswordsareespeciallyvulnerabletothismethod.
For example, a four-character password provides only 10,000 variations. On
average, guessing 5,000 times would produce a correct hit. A program that
could try a password every millisecond would take only about 5 seconds to
guessafour-characterpassword.Enumerationislesssuccessfulwheresystems
allow longer passwords that include both uppercase and lowercase letters,
alongwithnumbersandallpunctuationcharacters.Ofcourse,usersmusttake
advantage of the large password space and must not, for example, use only
lowercase letters. The third, common method is dictionary attacks where all
words,wordvariations,andcommonpasswordsaretried.
Inadditiontobeingguessed,passwordscanbeexposedasaresultofvisual
or electronic monitoring. An intruder can look over the shoulder of a user
(shoulder surfin ) when the user is logging in and can learn the password
easily by watching the keyboard. Alternatively, anyone with access to the
networkonwhichacomputerresidescanseamlesslyaddanetworkmonitor,
allowing him to sniff, or watch, all data being transferred on the network,
includinguserIDsandpasswords.Encryptingthedatastreamcontainingthe
password solves this problem. Even such a system could have passwords650 Chapter16 Security
stolen, however. For example, if a file is used to contain the passwords, it
could be copied for off-system analysis. Or consider a Trojan-horse program
installed on the system that captures every keystroke before sending it on to
the application. Another common method to grab passwords, specially debit
card passcodes, is installing physical devices where the codes are used and
recordingwhattheuserdoes,forexamplea“skimmer”atanATMmachineor
adeviceinstalledbetweenthekeyboardandthecomputer.
Exposureisaparticularlysevereproblemifthepasswordiswrittendown
where it can be read or lost. Some systems force users to select hard-to-
remember or long passwords, or to change their password frequently, which
may cause a user to record the password or to reuse it. As a result, such sys-
tems provide much less security than systems that allow users to select easy
passwords!
The final type of password compromise, illegal transfer, is the result of
human nature. Most computer installations have a rule that forbids users to
share accounts. This rule is sometimes implemented for accounting reasons
butisoftenaimedatimprovingsecurity.Forinstance,supposeoneuserIDis
shared by several users, and a security breach occurs from that user ID. It is
impossible to know who was using the ID at the time the break occurred or
evenwhethertheuserwasanauthorizedone.WithoneuserperuserID,any
usercanbequestioneddirectlyaboutuseoftheaccount;inaddition,theuser
might notice something different about the account and detect the break-in.
Sometimes, users break account-sharing rules to help friends or to circum-
ventaccounting, and thisbehavior canresultinasystem’sbeingaccessedby
unauthorizedusers—possiblyharmfulones.
Passwords can be either generated by the system or selected by a user.
System-generatedpasswordsmaybedifficulttoremember,andthususersmay
writethemdown.Asmentioned,however,user-selectedpasswordsareoften
easytoguess(theuser’snameorfavoritecar,forexample).Somesystemswill
checkaproposedpassword foreaseofguessingor crackingbeforeaccepting
it.Somesystemsalsoagepasswords,forcinguserstochangetheirpasswords
at regular intervals (every three months, for instance). This method is not
foolproofeither,becauseuserscaneasilytogglebetweentwopasswords.The
solution,asimplementedonsomesystems,istorecordapasswordhistoryfor
eachuser.Forinstance,thesystemcouldrecordthelastN passwordsandnot
allowtheirreuse.
Severalvariantsonthesesimplepasswordschemescanbeused.Forexam-
ple, the password can be changed more frequently. At the extreme, the pass-
word is changed from session to session. Anew password is selected (either
by the system or by the user) at the end of each session, and that password
mustbeusedforthenextsession.Insuchacase,evenifapasswordisusedby
anunauthorizedperson,thatpersoncanuseitonlyonce.Whenthelegitimate
usertriestouseanow-invalid passwordatthenext session,he discoversthe
securityviolation.Stepscanthenbetakentorepairthebreachedsecurity.
16.5.3 Securing Passwords
One problem with all these approaches is the difficulty of keeping the pass-
word secret within the computer. How can the system store a password
securelyyetallowitsuse forauthentication when theuserpresentsher pass-16.5 UserAuthentication 651
STRONGANDEASYTOREMEMBERPASSWORDS
Itis extremelyimportanttousestrong(hardtoguessandhardtoshoulder
surf) passwords on critical systems like bank accounts. It is also important
to not use the same password on lots of systems, as one less important,
easilyhackedsystemcouldrevealthepasswordyouuseonmoreimportant
systems. Agood technique is to generate your password by using the first
letter of each word of an easily remembered phrase using both upper and
lower characters with a number or punctuation mark thrown in for good
measure.Forexample,thephrase“Mygirlfriend’snameisKatherine”might
yieldthepassword“Mgn.isK!”.Thepasswordishardtocrackbuteasyforthe
usertoremember.Amoresecuresystemwouldallowmorecharactersinits
passwords.Indeed,asystemmightalsoallowpasswordstoincludethespace
character,sothatausercouldcreateapassphrasewhichiseasytoremember
butdifficulttobreak.
word?TheUNIXsystemusessecurehashingtoavoidthenecessityofkeeping
itspasswordlistsecret.Becausethepasswordishashedratherthanencrypted,
it is impossible for the system to decrypt the stored value and determine the
originalpassword.
Hashfunctionsareeasytocompute,buthard(ifnotimpossible)toinvert.
Thatis,givenavaluex,itiseasytocomputethehashfunctionvaluef(x).Given
a function value f(x), however, it is impossible to compute x. This function
is used to encode all passwords. Only encoded passwords are stored. When
a user presents a password, it is hashed and compared against the stored
encodedpassword.Evenifthestoredencodedpasswordisseen,itcannot be
decoded,sothepasswordcannotbedetermined.Thus,thepasswordfiledoes
notneedtobekeptsecret.
Thedrawbacktothismethodisthatthesystemnolongerhascontrolover
the passwords. Although the passwords are hashed, anyone with a copy of
the password file can run fast hash routines against it—hashing each word
inadictionary,forinstance,andcomparingtheresultsagainstthepasswords.
If the user has selected a password that is also a word in the dictionary, the
password is cracked. On sufficiently fast computers, or even on clusters of
slowcomputers,suchacomparisonmaytakeonlyafewhours.Furthermore,
becausesystemsusewell-knownhashing algorithms,anattackermightkeep
acacheofpasswordsthathavebeencrackedpreviously.
Forthesereasons,systemsincludea“salt,”orrecordedrandomnumber,in
thehashingalgorithm.Thesaltvalueisaddedtothepasswordtoensurethat
if two plaintext passwords are the same, they result in different hash values.
In addition, the salt value makes hashing a dictionary ineffective, because
each dictionary term would need to be combined with each salt value for
comparison to the stored passwords. Newer versions of UNIX also store the
hashedpasswordentriesinafilereadableonlybythesuperuser.Theprograms
thatcomparethehashtothestoredvaluerunsetuidtoroot,sotheycanread
thisfile,butotheruserscannot.652 Chapter16 Security
16.5.4 One-Time Passwords
Toavoidtheproblemsofpasswordsniffingandshouldersurfing,asystemcan
use a set of paired passwords. When a session begins, the system randomly
selectsandpresentsonepartofapasswordpair;theusermustsupplytheother
part. Inthis system,the user is challenged and must respond withthe correct
answertothatchallenge.
Thisapproachcanbegeneralizedtotheuseofanalgorithmasapassword.
In this scheme, the system and the user share a symmetric password. The
passwordpwisnevertransmittedoveramediumthatallowsexposure.Rather,
thepasswordisusedasinputtoafunction,alongwithachallengechpresented
by the system. The user then computes the function H(pw,ch). The result of
this function is transmitted as the authenticator to the computer. Because the
computer also knows pw and ch, it can perform the same computation. If the
results match, the user is authenticated. The next time the user needs to be
authenticated, another ch is generated, and the same steps ensue. This time,
theauthenticatorisdifferent.Suchalgorithmicpasswordsarenotsusceptible
toreuse.Thatis,ausercantypeinapassword,andnoentityinterceptingthat
passwordwillbeabletoreuseit.Thisone-timepasswordsystemisoneofonly
afewwaystopreventimproperauthenticationduetopasswordexposure.
One-time password systems are implementedin various ways. Commer-
cial implementations use hardware calculators with a display or a display
and numeric keypad. These calculators generally take the shape of a credit
card, a key-chain dongle,or a USB device.Software running on computers or
smartphones provides the user with H(pw,ch); pw can be input by the user
or generated by the calculator in synchronization with the computer. Some-
times, pw is just a personal identificatio number (PIN). The output of any
of these systems shows the one-time password. Aone-time password gener-
ator that requires input by the user involves two-factor authentication. Two
different types of components are needed in this case—for example, a one-
timepasswordgeneratorthatgeneratesthecorrectresponseonlyifthePINis
valid.Two-factorauthenticationoffersfarbetterauthenticationprotectionthan
single-factorauthenticationbecauseitrequires“somethingyouhave”aswell
as“somethingyouknow.”
16.5.5 Biometrics
Yetanother variationontheuseofpasswordsforauthenticationinvolvesthe
useofbiometricmeasures.Palm-orhand-readersarecommonlyusedtosecure
physical access—for example, access to a data center. These readers match
stored parameters against what is being read from hand-reader pads. The
parameters can include a temperature map, as well as finger length, finger
width, and line patterns.Thesedevicesarecurrently toolargeand expensive
tobeusedfornormalcomputerauthentication.
Fingerprintreadershavebecomeaccurateandcost-effective.Thesedevices
readfingerridgepatternsandconvertthemintoasequenceofnumbers.Over
time, they can store a set of sequences to adjust for the location of the finger
on the reading pad and other factors. Software can then scan a finger on the
padandcompareitsfeatureswiththesestoredsequencestodetermineifthey
match.Ofcourse,multipleuserscanhaveprofilesstored,andthescannercan
differentiate among them. Avery accurate two-factor authentication scheme16.6 ImplementingSecurityDefenses 653
can result from requiring a password as well as a user name and fingerprint
scan.Ifthisinformationisencryptedintransit,thesystemcanbeveryresistant
tospoofingorreplayattack.
Multifactorauthenticationisbetterstill.Considerhowstrongauthentica-
tioncanbewithaUSBdevicethatmustbepluggedintothesystem,aPIN,anda
fingerprintscan.Exceptforhavingtoplaceone’sfingeronapadandplugthe
USBintothesystem,thisauthenticationmethodisnolessconvenientthanthat
usingnormalpasswords.Recall,though,thatstrongauthenticationbyitselfis
notsufficienttoguaranteetheIDoftheuser.Anauthenticatedsessioncanstill
behijackedifitisnotencrypted.
16.6 Implementing Security Defenses
Justastherearemyriadthreatstosystemandnetworksecurity,therearemany
securitysolutions.Thesolutionsrangefromimprovedusereducation,through
technology,towritingbettersoftware.Mostsecurityprofessionalssubscribeto
the theory of defense in depth, which states that more layers of defense are
betterthanfewerlayers.Ofcourse,thistheoryappliestoanykindofsecurity.
Consider the security of a house without a door lock, with a door lock, and
withalockandanalarm.Inthissection,welookatthemajormethods,tools,
and techniques that can be used to improve resistance to threats. Note that
somesecurity-improvingtechniquesaremoreproperlypartofprotectionthan
securityandarecoveredinChapter17.
16.6.1 Security Policy
Thefirst steptowardimprovingthesecurityofanyaspectofcomputingisto
haveasecuritypolicy.Policiesvarywidelybutgenerallyincludeastatement
of what is being secured. For example, a policy might state that all outside-
accessibleapplicationsmusthaveacodereviewbeforebeingdeployed,orthat
usersshouldnotsharetheirpasswords,orthatallconnectionpointsbetweena
companyandtheoutsidemusthaveportscansruneverysixmonths.Without
a policy in place, it is impossible for users and administrators to know what
ispermissible,whatisrequired,andwhatisnotallowed.Thepolicyisaroad
maptosecurity,andifasiteistryingtomovefromlesssecuretomoresecure,
itneedsamaptoknowhowtogetthere.
Once the security policy is in place, the people it affects should know it
well. It should be their guide. The policy should also be a living document
thatisreviewedandupdatedperiodicallytoensurethatitisstillpertinentand
stillfollowed.
16.6.2 Vulnerability Assessment
How can we determine whether a security policy has been correctly imple-
mented? The best way is to execute a vulnerability assessment. Such assess-
ments can cover broad ground, from social engineering through risk assess-
menttoportscans.Riskassessment,forexample,attemptstovaluetheassets
oftheentityinquestion(aprogram,amanagementteam,asystem,orafacil-
ity) and determine the odds that a security incident will affect the entity and654 Chapter16 Security
decrease its value. When the odds of suffering a loss and the amount of the
potentiallossareknown,avaluecanbeplacedontryingtosecuretheentity.
The core activity of most vulnerability assessments is a penetration test,
in which the entity is scanned for known vulnerabilities. Because this book
is concerned with operating systems and the software that runs on them, we
concentrateonthoseaspectsofvulnerabilityassessment.
Vulnerabilityscanstypicallyaredoneattimeswhencomputeruseisrela-
tivelylow,tominimizetheirimpact.Whenappropriate,theyaredoneontest
systems rather than production systems, because they can induce unhappy
behaviorfromthetargetsystemsornetworkdevices.
Ascan within an individual system can check a variety of aspects of the
system:
• Shortoreasy-to-guesspasswords
• Unauthorizedprivilegedprograms,suchassetuidprograms
• Unauthorizedprogramsinsystemdirectories
• Unexpectedlylong-runningprocesses
• Improperdirectoryprotectionsonuserandsystemdirectories
• Improperprotectionsonsystemdatafiles,suchasthepasswordfile,device
files,ortheoperating-systemkernelitself
• Dangerous entries in the program search path (for example, the Trojan
horse discussed in Section 16.2.1), such as the current directory and any
easily-writtendirectoriessuchas/tmp
• Changestosystemprogramsdetectedwithchecksumvalues
• Unexpectedorhiddennetworkdaemons
Any problems found by a security scan can be either fixed automatically or
reportedtothemanagersofthesystem.
Networked computers are much more susceptible to security attacks
than are standalone systems. Rather than attacks from a known set of access
points,suchasdirectlyconnectedterminals,wefaceattacksfromanunknown
and large set of access points—a potentially severe security problem. To a
lesserextent,systemsconnectedtotelephonelinesviamodemsarealsomore
exposed.
In fact, the U.S. government considers a system to be only as secure as
its most far-reaching connection. For instance, a top-secret system may be
accessed only from within a building also considered top-secret. The system
losesitstop-secretratingifanyformofcommunicationcanoccuroutsidethat
environment. Some government facilities take extreme security precautions.
The connectors that plug a terminal into the secure computer are locked in a
safeintheofficewhentheterminalisnotinuse.ApersonmusthaveproperID
togainaccess tothebuildingand heroffice,mustknow aphysicallock com-
bination,andmustknowauthenticationinformationforthecomputeritselfto
gainaccesstothecomputer—anexampleofmultifactorauthentication.
Unfortunately for system administrators and computer-security profes-
sionals, it is frequently impossible to lock a machine in a room and disallow16.6 ImplementingSecurityDefenses 655
allremoteaccess.Forinstance,theInternetcurrentlyconnectsbillionsofcom-
putersanddevicesandhas become amission-critical,indispensableresource
formanycompaniesandindividuals.IfyouconsidertheInternetaclub,then,
as in any club with millions of members, there are many good members and
somebadmembers.Thebadmembershavemanytoolstheycanusetoattempt
togainaccesstotheinterconnectedcomputers.
Vulnerability scans can be applied to networks to address some of the
problems with network security. The scans search a network for ports that
respondtoarequest.Ifservicesareenabledthatshouldnotbe,accesstothem
canbe blocked,ortheycan be disabled.The scans thendeterminethe details
of the application listening on that port and try to determine if it has any
knownvulnerabilities.Testingthosevulnerabilitiescandetermineifthesystem
ismisconfiguredorlacksneededpatches.
Finally,though,considertheuseofportscannersinthehandsofanattacker
ratherthansomeonetryingtoimprovesecurity.Thesetoolscouldhelpattack-
ersfindvulnerabilitiestoattack.(Fortunately,itispossibletodetectportscans
through anomaly detection, as we discuss next.) It is a general challenge to
securitythat the same tools can be used for good and for harm. In fact, some
people advocate security through obscurity, stating that no tools should be
written to test security, because such tools can be used to find (and exploit)
securityholes.Othersbelievethatthisapproachtosecurityisnotavalidone,
pointingout,forexample,thatattackerscouldwritetheirowntools.Itseems
reasonable that security through obscurity be considered one of the layers of
securityonlysolongasitisnottheonlylayer.Forexample,acompanycould
publish its entire network configuration, but keeping that information secret
makes it harder for intruders to know what to attack. Even here, though, a
companyassumingthatsuchinformationwillremainasecrethasafalsesense
ofsecurity.
16.6.3 Intrusion Prevention
Securing systems and facilities is intimately linked to intrusion detection
and prevention. Intrusion prevention, as its name suggests, strives to detect
attemptedorsuccessfulintrusionsintocomputersystemsandtoinitiateappro-
priate responses to the intrusions. Intrusion prevention encompasses a wide
arrayoftechniquesthatvaryonanumberofaxes,includingthefollowing:
• Thetimeatwhichdetectionoccurs.Detectioncanoccurinrealtime(while
theintrusionisoccurring)orafterthefact.
• The types of inputs examined to detect intrusive activity. These may
include user-shell commands, process system calls, and network packet
headers or contents. Some forms of intrusion might be detected only by
correlatinginformationfromseveralsuchsources.
• Therangeofresponsecapabilities.Simpleformsofresponseincludealert-
ing an administrator to the potential intrusion or somehow halting the
potentially intrusive activity—for example, killing a process engaged in
suchactivity.Inasophisticatedformofresponse,asystemmighttranspar-
entlydivertanintruder’sactivitytoahoneypot—afalseresourceexposed656 Chapter16 Security
to the attacker. The resource appears real to the attacker and enables the
systemtomonitorandgaininformationabouttheattack.
Thesedegreesoffreedominthedesignspacefordetectingintrusionshave
yielded a wide range of solutions, known as intrusion-prevention systems
(IPS). IPSs act as self-modifying firewalls, passing traffic unless an intrusion
isdetected(atwhichpointthattrafficisblocked).
But just what constitutes an intrusion? Defining a suitable specification
of intrusion turns out to be quite difficult, and thus automatic IPSs today
typically settle for one of two less ambitious approaches. In the first, called
signature-based detection, system input or network traffic is examined for
specificbehaviorpatterns(orsignatures)knowntoindicateattacks.Asimple
example of signature-based detection is scanning network packets for the
string “/etc/passwd” targeted for a UNIX system. Another example is virus-
detectionsoftware,whichscansbinariesornetworkpacketsforknownviruses.
The second approach, typically called anomaly detection, attempts
through various techniques to detect anomalous behavior within computer
systems. Of course, not all anomalous system activity indicates an intrusion,
but the presumption is that intrusions often induce anomalous behavior. An
exampleofanomalydetectionismonitoringsystemcallsofadaemonprocess
to detect whether the system-call behavior deviates from normal patterns,
possibly indicating that a buffer overflow has been exploited in the daemon
to corrupt its behavior. Another example is monitoring shell commands to
detectanomalouscommandsforagivenuserordetectingananomalouslogin
timeforauser,eitherofwhichmayindicatethatanattackerhassucceededin
gainingaccesstothatuser’saccount.
Signature-based detection and anomaly detection can be viewed as two
sidesofthesamecoin.Signature-baseddetectionattemptstocharacterizedan-
gerous behaviors and to detect when one of these behaviors occurs, whereas
anomalydetectionattemptstocharacterizenormal(ornondangerous)behav-
iorsandtodetectwhensomethingotherthanthesebehaviorsoccurs.
ThesedifferentapproachesyieldIPSswithverydifferentproperties,how-
ever.Inparticular,anomalydetectioncanfindpreviouslyunknownmethodsof
intrusion (so-called zero-day attacks). Signature-based detection, in contrast,
will identify only known attacks that can be codified in a recognizable pat-
tern.Thus,newattacksthatwerenotcontemplatedwhenthesignatureswere
generated will evade signature-based detection. This problem is well known
tovendorsofvirus-detectionsoftware,whomustreleasenewsignatureswith
greatfrequencyasnewvirusesaredetectedmanually.
Anomalydetectionisnotnecessarilysuperiortosignature-baseddetection,
however. Indeed, a significant challenge for systems that attempt anomaly
detection is to benchmark “normal” system behavior accurately. If the sys-
tem has already been penetrated when it is benchmarked, then the intrusive
activity may be included in the “normal” benchmark. Even if the system is
benchmarked cleanly, without influence from intrusive behavior, the bench-
mark must give a fairly complete picture of normal behavior. Otherwise, the
number of false positives (false alarms) or, worse, false negatives (missed
intrusions)willbeexcessive.
To illustrate the impact of even a marginally high rate of false alarms,
consideraninstallationconsistingofahundredUNIXworkstationsfromwhich16.6 ImplementingSecurityDefenses 657
security-relevant events are recorded for purposes of intrusion detection. A
smallinstallationsuchasthiscouldeasilygenerateamillionauditrecordsper
day.Onlyoneortwomightbeworthyofanadministrator’sinvestigation.Ifwe
suppose,optimistically,thateachactualattackisreflectedintenauditrecords,
wecanroughlycomputetherateofoccurrenceofauditrecordsreflectingtruly
intrusiveactivityasfollows:
2intrusions ⋅10 records
day intrusion
= 0.00002.
records
106
day
Interpreting this as a “probability of occurrence of intrusive records,” we
denote it as P(I); that is, event I is the occurrence of a record reflecting truly
intrusivebehavior.SinceP(I) = 0.00002,wealsoknowthatP(¬I) = 1−P(I) =
0.99998.NowweletAdenotetheraisingofanalarmbyanIDS.AnaccurateIDS
should maximize both P(I|A) and P(¬I|¬A)—that is, the probabilities that an
alarmindicatesanintrusionandthatnoalarmindicatesnointrusion.Focusing
onP(I|A)forthemoment,wecancomputeitusingBayes’theorem:
P(I)⋅P(A|I)
P(I|A) =
P(I)⋅P(A|I)+P(¬I)⋅P(A|¬I)
0.00002⋅P(A|I)
=
0.00002⋅P(A|I)+0.99998⋅P(A|¬I)
Now consider the impact of the false-alarm rate P(A|¬I) on P(I|A). Even
with a very good true-alarm rate of P(A|I) = 0.8, a seemingly good false-
alarm rate of P(A|¬I) = 0.0001 yields P(I|A) ≈ 0.14. That is, fewer than one
in every seven alarms indicates a real intrusion! In systems where a security
administrator investigates each alarm, a high rate of false alarms—called a
“Christmas tree effect”—is exceedingly wasteful and will quickly teach the
administratortoignorealarms.
ThisexampleillustratesageneralprincipleforIPSs:forusability,theymust
offer an extremely low false-alarm rate. Achieving a sufficiently low false-
alarm rate is an especially serious challenge for anomaly-detection systems,
asmentioned,becauseofthedifficultiesofadequatelybenchmarking normal
systembehavior.However,researchcontinues toimproveanomaly-detection
techniques.Intrusion-detectionsoftwareisevolvingtoimplementsignatures,
anomalyalgorithms,andotheralgorithmsandtocombinetheresultstoarrive
atamoreaccurateanomaly-detectionrate.
16.6.4 Virus Protection
Aswehaveseen,virusescananddowreakhavoconsystems.Protectionfrom
viruses thus is an important security concern. Antivirus programs are often
used to provide this protection. Some of these programs are effective against
only particular known viruses. They work by searching all the programs on
a system for the specific pattern of instructions known to make up the virus.658 Chapter16 Security
When they find a known pattern, they remove the instructions, disinfecting
the program. Antivirus programs may have catalogs of thousands of viruses
forwhichtheysearch.
Both viruses and antivirus software continue to become more sophisti-
cated.Somevirusesmodifythemselvesastheyinfectothersoftwaretoavoid
the basic pattern-match approach of antivirus programs. Antivirus programs
in turn now look for families of patterns rather than a single pattern to iden-
tifyavirus.Infact,someantivirusprogramsimplementavarietyofdetection
algorithms.Theycandecompresscompressedvirusesbeforecheckingforasig-
nature.Somealsolookforprocessanomalies.Aprocessopeninganexecutable
fileforwritingissuspicious,forexample,unlessitisacompiler.Anotherpop-
ular technique is to run a program in a sandbox (Section 17.11.3), which is a
controlledoremulatedsectionofthesystem.Theantivirussoftwareanalyzes
thebehaviorofthecodeinthesandboxbeforelettingitrununmonitored.Some
antivirusprogramsalsoputupacompleteshieldratherthanjustscanningfiles
withinafilesystem.Theysearchbootsectors,memory,inboundandoutbound
e-mail,filesastheyaredownloaded,filesonremovabledevicesormedia,and
soon.
The best protection against computer viruses is prevention, or the prac-
tice of safe computing. Purchasing unopened software from vendors and
avoidingfreeorpiratedcopiesfrompublicsourcesordiskexchangeofferthe
safest route to preventing infection. However, even new copies of legitimate
software applications are not immune to virus infection: in a few cases, dis-
gruntled employees of a software company have infected the master copies
of software programs to do economic harm to the company. Likewise, hard-
waredevicescancomefromthefactorypre-infectedforyourconvenience.For
macro viruses, one defense is to exchange Microsoft Word documents in an
alternative file format called rich text format (RTF). Unlike the native Word
format,RTFdoesnotincludethecapabilitytoattachmacros.
Another defense is to avoid opening any e-mail attachments from
unknown users. Unfortunately, history has shown that e-mail vulnerabilities
appear as fast as they are fixed. For example, in 2000, the love bug virus
became very widespread by traveling in e-mail messages that pretended to
be love notes sent by friends of the receivers. Once a receiver opened the
attached Visual Basic script, the virus propagated by sending itself to the
first addresses in the receiver’s e-mail contact list. Fortunately, except for
clogginge-mailsystemsandusers’inboxes,itwasrelativelyharmless.Itdid,
however, effectively negate the defensive strategy of opening attachments
only from people known to the receiver. Amore effective defense method is
to avoid opening any e-mail attachment that contains executable code. Some
companies now enforce this as policy by removing all incoming attachments
toe-mailmessages.
Another safeguard, although it does not prevent infection, does permit
early detection. Auser must begin by completely reformatting the hard disk,
especiallythebootsector,whichisoftentargetedforviralattack.Onlysecure
software is uploaded, and a signature of each program is taken via a secure
message-digestcomputation.Theresultingfilenameandassociatedmessage-
digest list must then be kept free from unauthorized access. Periodically, or
each time a program is run, the operating system recomputes the signature16.6 ImplementingSecurityDefenses 659
andcomparesitwiththesignatureontheoriginallist;anydifferencesserveasa
warningofpossibleinfection.Thistechniquecanbecombinedwithothers.For
example,ahigh-overheadantivirusscan,suchasasandbox,canbeused;and
ifaprogrampassesthetest,asignaturecanbecreatedforit.Ifthesignatures
match the next time the program is run, it does not need to be virus-scanned
again.
16.6.5 Auditing, Accounting, and Logging
Auditing,accounting,andloggingcandecreasesystemperformance,butthey
areusefulinseveralareas,including security.Logging can be generalor spe-
cific.Allsystem-callexecutionscanbeloggedforanalysisofprogrambehavior
(or misbehavior). More typically, suspicious events are logged. Authentica-
tion failures and authorization failures can tell us quite a lot about break-in
attempts.
Accounting is another potential tool in a security administrator’s kit. It
can be used to find performance changes, which in turn can reveal security
problems.OneoftheearlyUNIXcomputerbreak-inswasdetectedbyCliffStoll
whenhewasexaminingaccountinglogsandspottedananomaly.
16.6.6 Firewalling to Protect Systems and Networks
Weturnnexttothequestionofhowatrustedcomputercanbeconnectedsafely
toanuntrustworthynetwork.Onesolutionistheuseofafirewalltoseparate
trustedanduntrustedsystems.Afirewal isacomputer,appliance,process,or
routerthatsitsbetweenthetrustedandtheuntrusted.Anetworkfirewalllimits
networkaccessbetweenthemultiplesecuritydomainsandmonitorsandlogs
all connections. It can also limit connections based on source or destination
address,sourceordestinationport,ordirectionoftheconnection.Forinstance,
webserversuseHTTPtocommunicatewithwebbrowsers.Afirewalltherefore
may allow only HTTP to pass from all hosts outside the firewall to the web
serverwithinthefirewall.Thefirstworm,theMorrisInternetworm,usedthe
fingerprotocoltobreakintocomputers,sofingerwouldnotbeallowedto
pass,forexample.
In fact, anetwork firewall can separatea network intomultipledomains.
A common implementation has the Internet as the untrusted domain; a
semitrusted and semisecure network, called the demilitarized zone (DMZ),
as another domain; and a company’s computers as a third domain (Figure
16.10). Connections are allowed from the Internet to the DMZ computers and
from the company computers to the Internet but are not allowed from the
InternetorDMZcomputerstothecompanycomputers.Optionally,controlled
communications may be allowed between the DMZ and one company
computerormore.Forinstance,awebserverontheDMZmayneedtoquerya
database serveron the corporate network. With afirewall, however, access is
contained,andanyDMZsystemsthatarebrokenintostillareunabletoaccess
thecompanycomputers.
Of course, a firewall itself must be secure and attack-proof. Otherwise,
its ability to secure connections can be compromised. Furthermore, firewalls
do not prevent attacks that tunnel, or travel within protocols or connections660 Chapter16 Security
Internet access from company’s
computers
Internet company computers
DMZ access from Internet access between DMZ and
firewall
company’s computers
DMZ
Figure16.10 Domainseparationviafirewall.
that the firewall allows. Abuffer-overflow attack to a web server will not be
stoppedbythefirewall,forexample,becausetheHTTPconnectionisallowed;
itisthecontentsoftheHTTPconnectionthathousetheattack.Likewise,denial-
of-serviceattackscanaffectfirewallsasmuchasanyothermachines.Another
vulnerabilityoffirewallsisspoofing,inwhichanunauthorizedhostpretends
tobeanauthorizedhostbymeetingsomeauthorizationcriterion.Forexample,
ifafirewallruleallowsaconnectionfromahostandidentifiesthathostbyits
IPaddress,thenanotherhostcouldsendpacketsusingthatsameaddressand
beallowedthroughthefirewall.
Inadditiontothemostcommonnetworkfirewalls,thereareother,newer
kindsoffirewalls,eachwithitsprosandcons.Apersonalfirewal isasoftware
layer either included with the operating system or added as an application.
Ratherthanlimitingcommunicationbetweensecuritydomains,itlimitscom-
munication to (and possibly from) a given host. Auser could add a personal
firewall to her PC so that a Trojan horse would be denied access to the net-
work to which the PC is connected, for example. An application proxy fire
wallunderstandstheprotocolsthatapplicationsspeakacrossthenetwork.For
example,SMTPisusedformailtransfer.Anapplicationproxyacceptsaconnec-
tionjustasanSMTPserverwouldandtheninitiatesaconnectiontotheoriginal
destinationSMTPserver.It can monitor the traffic as it forwards the message,
watching for and disabling illegal commands, attempts to exploit bugs, and
soon.Somefirewallsaredesignedforonespecificprotocol.AnXMLfirewal,
for example, has the specific purpose of analyzing XML traffic and blocking
disallowedormalformedXML.System-callfirewallssitbetweenapplications
and the kernel, monitoring system-call execution. For example, in Solaris 10,
the “least privilege” feature implements a list of more than fifty system calls
that processes may or may not be allowed to make. Aprocess that does not
needtospawnotherprocessescanhavethatabilitytakenaway,forinstance.16.6 ImplementingSecurityDefenses 661
16.6.7 Other Solutions
IntheongoingbattlebetweenCPUdesigners,operatingsystemimplementers,
andhackers,oneparticulartechniquehasbeenhelpfultodefendagainstcode
injection.Tomountacode-injectionattack,hackersmustbeabletodeducethe
exact address in memory of their target. Normally, this may not be difficult,
since memory layout tends tobe predictable.An operating systemtechnique
called Address Space Layout Randomization (ASLR) attempts to solve this
problembyrandomizingaddressspaces—thatis,puttingaddressspaces,such
as the starting locations of the stack and heap, in unpredictable locations.
Address randomization, although not foolproof, makes exploitation consid-
erably more difficult. ASLR is a standard feature in many operating systems,
includingWindows,Linux,andmacOS.
In mobile operating systems such as iOS and Android,an approach often
adoptedistoplacetheuserdataandthesystemfilesintotwoseparateparti-
tions.Thesystempartitionismountedread-only,whereasthedatapartitionis
read–write. This approach has numerous advantages, not the least of which
is greater security: the system partition files cannot easily be tampered with,
bolsteringsystemintegrity.AndroidtakesthisastepfurtherbyusingLinux’s
dm-verity mechanism to cryptographically hash the system partition and
detectanymodifications.
16.6.8 Security Defenses Summarized
Byapplyingappropriatelayersofdefense,wecankeepsystemssafefromall
but the most persistent attackers. In summary, these layers may include the
following:
• Educate users about safe computing—don’t attach devices of unknown
origin to the computer, don’t share passwords, use strong passwords,
avoid falling for social engineering appeals, realize that an e-mail is not
necessarilyaprivatecommunication,andsoon
• Educate users about how to prevent phishing attacks—don’t click on e-
mailattachmentsorlinksfromunknown(orevenknown)senders;authen-
ticate(forexample,viaaphonecall)thatarequestislegitimate.
• Usesecurecommunicationwhenpossible.
• Physicallyprotectcomputerhardware.
• Configuretheoperatingsystemtominimizetheattacksurface;disableall
unusedservices.
• Configure systemdaemons,privilegesapplications,and servicestobe as
secureaspossible.
• Usemodernhardwareandsoftware,astheyarelikelytohaveup-to-date
securityfeatures.
• Keepsystemsandapplicationsuptodateandpatched.
• Only run applications from trusted sources (such as those that are code
signed).662 Chapter16 Security
• Enable logging and auditing; review the logs periodically, or automate
alerts.
• Install and use antivirus software on systems susceptible to viruses, and
keepthesoftwareuptodate.
• Usestrongpasswordsandpassphrases,anddon’trecordthemwherethey
couldbefound.
• Use intrusion detection, firewalling, and other network-based protection
systemsasappropriate.
• For importantfacilities,use periodicvulnerabilityassessmentsand other
testingmethodstotestsecurityandresponsetoincidents.
• Encryptmass-storagedevices,andconsiderencryptingimportantindivid-
ualfilesaswell.
• Haveasecuritypolicyforimportantsystemsandfacilities,andkeepitup
todate
16.7 An Example: Windows 10
MicrosoftWindows10isageneral-purposeoperatingsystemdesignedtosup-
port a variety of security features and methods. In this section, we examine
features that Windows 10 uses to perform security functions. For more infor-
mationandbackgroundonWindows,seeAppendixB.
The Windows 10 security model is based on the notion of user accounts.
Windows 10 allows the creation of any number of user accounts, which can
begroupedinanymanner.Accesstosystemobjectscanthenbepermittedor
denied as desired. Users are identified to the system by a unique security ID.
Whenauserlogson,Windows10createsasecurityaccesstokenthatincludes
the security ID for the user, security IDs for any groups of which the user is
a member, and a list of any special privileges that the user has. Examples
of special privileges include backing up files and directories, shutting down
the computer,logging on interactively,and changing the systemclock. Every
process that Windows 10 runs on behalf of a user will receive a copy of the
accesstoken.ThesystemusesthesecurityIDsintheaccesstokentopermitor
denyaccesstosystemobjectswhenevertheuser,oraprocessonbehalfofthe
user,attemptstoaccesstheobject.Authenticationofauseraccountistypically
accomplishedviaausernameandpassword,althoughthemodulardesignof
Windows 10 allows the developmentof custom authentication packages. For
example,aretinal(oreye)scannermightbeusedtoverifythattheuseriswho
shesayssheis.
Windows 10 uses the idea of a subject to ensure that programs run by a
userdonotgetgreateraccesstothesystemthantheuserisauthorizedtohave.
A subject is used to track and manage permissions for each program that a
user runs. It is composed of the user’s access token and the program acting
onbehalfoftheuser.SinceWindows 10operateswithaclient–servermodel,
two classes of subjects are used to control access: simple subjects and server
subjects. An example of a simple subject is the typical application program
thatauserexecutesaftershelogson.Thesimplesubjectisassignedasecurity16.7 AnExample:Windows10 663
context based on the security access token of the user. A server subject is a
processimplementedasaprotectedserverthatusesthesecuritycontextofthe
clientwhenactingontheclient’sbehalf.
As mentioned in Section 16.6.6, auditing is a useful security technique.
Windows 10 has built-in auditing that allows many common security threats
tobemonitored.Examplesincludefailureauditingforloginandlogoffevents
to detect random password break-ins, success auditing for login and logoff
eventstodetectloginactivityatstrangehours,successandfailurewrite-access
auditingforexecutablefilestotrackavirusoutbreak,andsuccessandfailure
auditingforfileaccesstodetectaccesstosensitivefiles.
WindowsVistaaddedmandatoryintegritycontrol,whichworksbyassign-
inganintegritylabeltoeachsecurableobjectandsubject.Inorderforagiven
subjecttohaveaccesstoanobject,itmusthavetheaccessrequestedinthedis-
cretionaryaccess-controllist,anditsintegritylabelmustbeequaltoorhigher
thanthatofthesecuredobject(forthegivenoperation).Theintegritylabelsin
Windows7are:untrusted,low,medium,high,andsystem.Inaddition,three
access mask bits are permitted for integrity labels: NoReadUp, NoWriteUp,
andNoExecuteUp.NoWriteUpisautomaticallyenforced,soalower-integrity
subject cannot perform a write operation on a higher-integrity object. How-
ever, unless explicitly blocked by the security descriptor, it can perform read
orexecuteoperations.
For securable objects without an explicit integrity label, a default label of
mediumisassigned.Thelabelforagivensubjectisassignedduringlogon.For
instance, a nonadministrative user will have an integritylabel of medium.In
additiontointegritylabels,Windows Vista alsoaddedUserAccount Control
(UAC), which represents an administrative account (not the built-in Admin-
istrators account) with two separate tokens. One, for normal usage, has the
built-inAdministratorsgroupdisabledandhasanintegritylabelofmedium.
The other, for elevated usage, has the built-in Administrators group enabled
andanintegritylabelofhigh.
SecurityattributesofanobjectinWindows10aredescribedbyasecurity
descriptor.ThesecuritydescriptorcontainsthesecurityIDoftheownerofthe
object(whocanchangetheaccesspermissions),agroupsecurityIDusedonly
bythePOSIXsubsystem,adiscretionaryaccess-controllistthatidentifieswhich
users or groups are allowed (and which are explicitly denied) access, and a
system access-control list that controls which auditing messages the system
willgenerate.Optionally,thesystemaccess-controllistcansettheintegrityof
theobjectandidentifywhichoperationstoblockfromlower-integritysubjects:
read,write(alwaysenforced),orexecute.Forexample,thesecuritydescriptor
of the file foo.bar might have owner gwen and this discretionary access-
controllist:
• ownergwen—allaccess
• groupcs—read–writeaccess
• usermaddie—noaccess
In addition, it might have a system access-control list that tells the system to
auditwritesbyeveryone,alongwithanintegritylabelofmediumthatdenies
read,write,andexecutetolower-integritysubjects.664 Chapter16 Security
An access-control list is composed of access-control entries that contain
the security ID of the individual or group being granted access and an
access mask that defines all possible actions on the object, with a value of
AccessAllowedorAccessDeniedforeachaction.FilesinWindows10mayhave
the following access types: ReadData, WriteData, AppendData, Execute,
ReadExtendedAttribute, WriteExtendedAttribute, ReadAttributes,
and WriteAttributes. We can see how this allows a fine degree of control
overaccesstoobjects.
Windows 10 classifies objects as either container objects or noncontainer
objects. Container objects, such as directories, can logically contain other
objects.Bydefault,whenanobjectiscreatedwithinacontainerobject,thenew
objectinheritspermissionsfromtheparentobject.Similarly,iftheusercopiesa
filefromonedirectorytoanewdirectory,thefilewillinheritthepermissionsof
the destinationdirectory.Noncontainerobjectsinherit noother permissions.
Furthermore, if a permission is changed on a directory, the new permissions
do not automatically apply to existing files and subdirectories; the user may
explicitlyapplythemifhesodesires.
ThesystemadministratorcanusetheWindows10PerformanceMonitorto
helpherspotapproachingproblems.Ingeneral,Windows10doesagoodjob
ofprovidingfeaturestohelpensureasecurecomputingenvironment.Manyof
thesefeaturesarenot enabledby default,however,which maybeone reason
forthemyriadsecuritybreachesonWindows10systems.Anotherreasonisthe
vastnumberofservicesWindows10startsatsystemboottimeandthenumber
ofapplicationsthattypicallyareinstalledonaWindows10system.Forareal
multiuserenvironment,thesystemadministratorshouldformulateasecurity
planandimplementit,usingthefeaturesthatWindows10providesandother
securitytools.
OnefeaturedifferentiatingsecurityinWindows10fromearlierversionsis
codesigning.SomeversionsofWindows10makeitmandatory—applications
that are not properly signed by their authors will not execute—while other
versionsmakeitoptionalorleaveittotheadministratortodeterminewhatto
dowithunsignedapplications.
16.8 Summary
• Protection is an internal problem. Security, in contrast, must consider
boththecomputersystemandtheenvironment—people,buildings,busi-
nesses,valuableobjects,andthreats—withinwhichthesystemisused.
• Thedatastoredinthecomputersystemmustbeprotectedfromunautho-
rizedaccess,maliciousdestructionoralteration,andaccidentalintroduc-
tion of inconsistency. It is easier to protect against accidental loss of data
consistencythantoprotectagainstmaliciousaccesstothedata.Absolute
protectionoftheinformationstoredinacomputersystemfrommalicious
abuse is not possible; but the cost to the perpetrator can be made suffi-
ciently high to deter most, if not all, attempts to access that information
withoutproperauthority.
• Several types of attacks can be launched against programs and against
individual computers or the masses. Stack- and buffer-overflow tech-FurtherReading 665
niques allow successful attackers to change their level of system access.
Viruses and malware require human interaction, while worms are self-
perpetuating, sometimes infecting thousands of computers. Denial-of-
serviceattackspreventlegitimateuseoftargetsystems.
• Encryption limits the domain of receivers of data, while authentication
limits the domain of senders.Encryptionis usedto provideconfidential-
ity of data being stored or transferred. Symmetric encryption requires a
sharedkey,whileasymmetricencryptionprovidesapublickeyandapri-
vate key. Authentication, when combined with hashing, can prove that
datahavenotbeenchanged.
• User authentication methods are used to identify legitimate users of a
system.Inadditiontostandarduser-nameandpasswordprotection,sev-
eral authentication methods are used. One-time passwords, for example,
changefromsessiontosessiontoavoidreplayattacks.Two-factorauthen-
ticationrequirestwoformsofauthentication,suchasahardwarecalcula-
torwithanactivationPIN,oronethatpresentsadifferentresponsebased
on the time. Multifactor authentication uses three or more forms. These
methodsgreatlydecreasethechanceofauthenticationforgery.
• Methods of preventing or detecting security incidents include an up-to-
datesecuritypolicy,intrusion-detectionsystems,antivirussoftware,audit-
ing and logging of system events, system-call monitoring, code signing,
sandboxing,andfirewalls.
Further Reading
Informationaboutvirusesandwormscanbefoundathttp://www.securelist.
com,aswellasin[Ludwig(1998)]and[Ludwig(2002)].Anotherwebsitecon-
tainingup-to-datesecurityinformationishttp://www.eeye.com/resources/se
curity-center/research.Apaperonthedangersofacomputermonoculturecan
befoundathttp://cryptome.org/cyberinsecurity.htm.
The first paper discussing least privilege is a Multics overview:
https://pdfs.semanticscholar.org/1c8d/06510ad449ad24fbdd164f8008cc730
cab47.pdf).
For the original article that explored buffer overflow attacks, see
http://phrack.org/issues/49/14.html. For the development version control
systemgit,seehttps://github.com/git/.
[C. Kaufman (2002)] and [Stallings and Brown (2011)] explore the use
of cryptography in computer systems. Discussions concerning protection of
digitalsignaturesareofferedby[Akl(1983)],[Davies(1983)],[Denning(1983)],
and [Denning (1984)]. Complete cryptography information is presented in
[Schneier(1996)]and[KatzandLindell(2008)].
Asymmetrickeyencryptionisdiscussedathttps://www-ee.stanford.edu/
hellman/publications/24.pdf). The TLS cryptographic protocol is described in
detail at https://tools.ietf.org/html/rfc5246. The nmap network scanning tool
is from http://www.insecure.org/nmap/. For more information on port scans666 Chapter16 Security
andhowtheyarehidden,seehttp://phrack.org/issues/49/15.html.Nessusisa
commercialvulnerabilityscannerbutcanbeusedforfreewithlimitedtargets:
https://www.tenable.com/products/nessus-home.
Bibliography
[Akl(1983)] S. G. Akl, “Digital Signatures: ATutorial Survey”, Computer, Vol-
ume16,Number2(1983),pages15–24.
[C.Kaufman(2002)] M. S. C. Kaufman, R. Perlman, Network Security: Private
CommunicationinaPublicWorld,SecondEdition,PrenticeHall(2002).
[Davies(1983)] D.W.Davies,“ApplyingtheRSADigitalSignaturetoElectronic
Mail”,Computer,Volume16,Number2(1983),pages55–62.
[Denning(1983)] D.E.Denning,“ProtectingPublicKeysandSignatureKeys”,
Computer,Volume16,Number2(1983),pages27–35.
[Denning(1984)] D.E.Denning,“DigitalSignatureswithRSAandOtherPub-
lic-Key Cryptosystems”, Communications of the ACM, Volume 27, Number 4
(1984),pages388–392.
[KatzandLindell(2008)] J.KatzandY.Lindell,IntroductiontoModernCryptog-
raphy,Chapman&Hall/CRCPress(2008).
[Ludwig(1998)] M. Ludwig, The Giant Black Book of Computer Viruses, Second
Edition,AmericanEaglePublications(1998).
[Ludwig(2002)] M. Ludwig, The Little Black Book of Email Viruses, American
EaglePublications(2002).
[Schneier(1996)] B.Schneier,AppliedCryptography,SecondEdition,JohnWiley
andSons(1996).
[StallingsandBrown(2011)] W. Stallings and L. Brown, Computer Security:
PrinciplesandPractice,SecondEdition,PrenticeHall(2011).Exercises EX-52
Chapter 16 Exercises
16.1 Buffer-overflowattackscanbeavoidedbyadoptingabetterprogram-
mingmethodologyorbyusingspecialhardwaresupport.Discussthese
solutions.
16.2 Apasswordmaybecomeknowntootherusersinavarietyofways.Is
there a simple method for detecting that such an event has occurred?
Explainyouranswer.
16.3 Whatisthepurposeofusinga“salt”alongwithauser-providedpass-
word?Whereshouldthesaltbestored,andhowshoulditbeused?
16.4 Thelistofallpasswordsiskeptintheoperatingsystem.Thus,ifauser
manages to read this list, password protection is no longer provided.
Suggest a scheme that will avoid this problem. (Hint: Use different
internalandexternalrepresentations.)
16.5 An experimental addition to UNIX allows a user to connect a watch-
dog program to a file. The watchdog is invokedwhenever a program
requests access to the file. The watchdog then either grants or denies
access to the file. Discuss two pros and two cons of using watchdogs
forsecurity.
16.6 DiscussameansbywhichmanagersofsystemsconnectedtotheInter-
net could design their systems to limit or eliminate the damage done
by worms. What are the drawbacks of making the change that you
suggest?
16.7 Makealistofsixsecurityconcerns forabank’s computersystem.For
each item on your list, state whether this concern relates to physical,
human,oroperating-systemsecurity.
16.8 What are two advantages of encrypting data stored in the computer
system?
16.9 What commonly used computer programs are prone to man-in-the-
middleattacks?Discusssolutionsforpreventingthisformofattack.
16.10 Comparesymmetricandasymmetricencryptionschemes,anddiscuss
thecircumstancesunderwhichadistributedsystemwoulduseoneor
theother.
16.11 Why doesn’t D kd,N(E ke,N(m)) provide authentication of the sender? To
whatusescansuchanencryptionbeput?
16.12 Discuss how the asymmetric encryption algorithm can be used to
achievethefollowinggoals.
a. Authentication: the receiver knows that only the sender could
havegeneratedthemessage.
b. Secrecy:onlythereceivercandecryptthemessage.
c. Authentication and secrecy: only the receiver can decrypt the
message,andthereceiverknowsthatonlythesendercouldhave
generatedthemessage.EX-53
16.13 Consider a system that generates 10 million audit records per day.
Assume that, on average, there are 10 attacks per day on this system
and each attack is reflected in 20 records. If the intrusion-detection
system has a true-alarm rate of 0.6 and a false-alarm rate of 0.0005,
whatpercentageofalarmsgeneratedbythesystemcorrespondstoreal
intrusions?
16.14 MobileoperatingsystemssuchasiOSandAndroidplacetheuserdata
and the system files into two separate partitions. Asidefrom security,
whatisanadvantageofthatseparation?17
CHAPTER
Protection
In Chapter 16, we addressed security, which involves guarding computer
resourcesagainstunauthorizedaccess,maliciousdestructionoralteration,and
accidentalintroductionofinconsistency.Inthischapter,weturntoprotection,
which involves controlling the access of processes and users to the resources
definedbyacomputersystem.
Theprocessesinanoperatingsystemmustbeprotectedfromoneanother’s
activities.Toprovidethisprotection,wecanusevariousmechanismstoensure
thatonlyprocessesthathavegainedproperauthorizationfromtheoperating
systemcanoperateonthefiles,memorysegments,CPU,networking,andother
resourcesofasystem.Thesemechanismsmustprovideameansforspecifying
thecontrolstobeimposed,togetherwithameansofenforcement.
CHAPTER OBJECTIVES
• Discuss the goals and principles of protection in a modern computer
system.
• Explain how protection domains, combined with an access matrix, are
usedtospecifytheresourcesaprocessmayaccess.
• Examinecapability-andlanguage-basedprotectionsystems.
• Describehowprotectionmechanismscanmitigatesystemattacks.
17.1 Goals of Protection
Ascomputersystemshavebecomemoresophisticatedandpervasiveintheir
applications,theneedtoprotecttheirintegrityhasalsogrown.Protectionwas
originally conceived as an adjunct to multiprogramming operating systems,
sothatuntrustworthyusersmightsafelyshareacommonlogicalnamespace,
suchasadirectoryoffiles,oracommonphysicalnamespace,suchasmemory.
Modernprotectionconceptshaveevolvedtoincreasethereliabilityofanycom-
plex system that makes use of shared resources and is connected to insecure
communicationsplatformssuchastheInternet.
667668 Chapter17 Protection
Weneedtoprovideprotectionforseveralreasons.Themostobviousisthe
needtopreventthemischievous,intentionalviolationofanaccessrestriction
byauser.Ofmoregeneralimportance,however,istheneedtoensurethateach
processinasystemusessystemresourcesonlyinwaysconsistentwithstated
policies.Thisrequirementisanabsoluteoneforareliablesystem.
Protectioncanimprovereliabilitybydetectinglatenterrorsattheinterfaces
between component subsystems. Early detection of interface errors can often
prevent contamination of a healthy subsystem by a malfunctioning subsys-
tem. Also, an unprotected resource cannot defend against use (or misuse) by
an unauthorized or incompetent user. Aprotection-oriented system provides
meanstodistinguishbetweenauthorizedandunauthorizedusage.
Theroleofprotectioninacomputersystemistoprovideamechanismfor
the enforcement of the policies governing resource use. These policies can be
established in a variety of ways. Some are fixed in the design of the system,
while others are formulated by the management of a system. Still others are
defined by individual users to protect resources they “own.” A protection
system,then,musthavetheflexibilitytoenforceavarietyofpolicies.
Policies for resource use may vary by application, and they may change
over time. For these reasons, protection is no longer the concern solely of
the designer of an operating system. The application programmer needs to
useprotectionmechanismsaswell,toguardresourcescreatedandsupported
by an application subsystem against misuse. In this chapter, we describe the
protectionmechanisms the operatingsystemshould provide,but application
designerscanusethemaswellindesigningtheirownprotectionsoftware.
Note that mechanisms are distinct from policies. Mechanisms determine
howsomethingwillbedone;policiesdecidewhatwillbedone.Theseparation
of policy and mechanism is important for flexibility. Policies are likely to
change from place to place or time to time. In the worst case, every change
inpolicywouldrequireachangeintheunderlyingmechanism.Usinggeneral
mechanismsenablesustoavoidsuchasituation.
17.2 Principles of Protection
Frequently, a guiding principle can be used throughout a project, such as
the design of an operating system. Following this principle simplifies design
decisionsandkeepsthesystemconsistentandeasytounderstand.Akey,time-
tested guiding principle for protection is the principle of least privilege. As
discussedinChapter16,thisprincipledictatesthatprograms,users,andeven
systemsbegivenjustenoughprivilegestoperformtheirtasks.
Consider one of the tenets of UNIX—that a user should not run as root.
(In UNIX, only the root user can execute privileged commands.) Most users
innatelyrespectthat,fearinganaccidentaldeleteoperationforwhichthereis
nocorrespondingundelete.Becauserootisvirtuallyomnipotent,thepotential
for human error when a user acts as root is grave, and its consequences far
reaching.
Now consider that rather than human error, damage may result from
maliciousattack. Aviruslaunched by an accidental click on an attachment is
one example. Another is a buffer overflow or other code-injection attack that
is successfully carried out against a root-privileged process (or, in Windows,17.3 ProtectionRings 669
aprocesswithadministratorprivileges).Eithercasecouldprovecatastrophic
forthesystem.
Observingtheprincipleofleastprivilegewouldgivethesystemachance
tomitigatetheattack—ifmaliciouscodecannotobtainrootprivileges,thereis
achancethatadequatelydefinedpermissionsmayblockall,oratleastsome,
ofthedamagingoperations.Inthissense,permissionscanactlikeanimmune
systemattheoperating-systemlevel.
The principle of least privilege takes many forms, which we examine in
more detail later in the chapter. Another important principle, often seen as a
derivative of the principle of least privilege, is compartmentalization. Com-
partmentalizationistheprocessofprotectingeachindividualsystemcompo-
nentthroughtheuseofspecificpermissionsandaccessrestrictions.Then,ifa
component is subverted, another line of defense will “kick in” and keep the
attacker from compromising the system any further. Compartmentalization
is implemented in many forms—from network demilitarized zones (DMZs)
throughvirtualization.
Thecarefuluseofaccessrestrictionscanhelpmakeasystemmoresecure
andcanalsobebeneficialinproducinganaudittrail,whichtracksdivergences
from allowed accesses. An audit trail is a hard record in the system logs. If
monitored closely, it can reveal early warnings of an attack or (if its integrity
ismaintaineddespiteanattack)providecluesastowhichattackvectorswere
used,aswellasaccuratelyassessthedamagecaused.
Perhaps most importantly, no single principle is a panacea for security
vulnerabilities.Defenseindepthmustbe used:multiplelayersofprotection
should be applied one on top of the other (think of a castle with a garrison,
a wall, and a moat to protect it). At the same time, of course, attackers use
multiplemeanstobypassdefenseindepth,resultinginanever-escalatingarms
race.
17.3 Protection Rings
As we’ve seen, the main component of modern operating systems is the ker-
nel,which manages access to systemresourcesand hardware. The kernel,by
definition,isatrustedandprivilegedcomponentandthereforemustrunwith
ahigherlevelofprivilegesthanuserprocesses.
To carry out this privilege separation, hardware support is required.
Indeed, all modern hardware supports the notion of separate execution
levels,thoughimplementationsvarysomewhat.Apopularmodelofprivilege
separation is that of protection rings. In this model, fashioned after Bell
–LaPadula (https://www.acsac.org/2005/papers/Bell.pdf), execution is
defined as a set of concentric rings, with ring i providing a subset of the
functionality of ring j for any j < i. The innermost ring, ring 0, thus provides
thefullsetofprivileges.ThispatternisshowninFigure17.1.
When the system boots, it boots to the highest privilege level. Code at
thatlevelperformsnecessaryinitializationbeforedroppingtoalessprivileged
level.Inordertoreturntoahigherprivilegelevel,codeusuallycallsaspecial
instruction,sometimesreferredtoasagate,whichprovidesaportalbetween
rings.Thesyscallinstruction(inIntel)isoneexample.Callingthisinstruction
shiftsexecutionfromusertokernelmode.Aswehaveseen,executingasystem670 Chapter17 Protection
ring 0
ring 1
(cid:129) (cid:129) (cid:129) ring N – 1
Figure17.1 Protection-ringstructure.
callwillalwaystransferexecutiontoapredefinedaddress,allowingthecaller
tospecifyonlyarguments(includingthesystemcallnumber),andnotarbitrary
kernel addresses. In this way, the integrity of the more privileged ring can
generallybeassured.
Anotherwayofendingupinamoreprivilegedringisontheoccurrenceof
aprocessortraporaninterrupt.Wheneitheroccurs,executionisimmediately
transferredintothehigher-privilegering.Onceagain,however,theexecution
inthehigher-privilegeringispredefinedandrestrictedtoawell-guardedcode
path.
Intelarchitecturesfollowthismodel,placingusermodecodeinring3and
kernelmodecodeinring0.Thedistinctionismadebytwobitsinthespecial
EFLAGSregister.Accesstothisregisterisnotallowedinring3—thusprevent-
ingamaliciousprocessfromescalatingprivileges.Withtheadventofvirtual-
ization,Inteldefinedanadditionalring(-1)toallowforhypervisors,orvirtual
machinemanagers,whichcreateandrunvirtualmachines.Hypervisorshave
morecapabilitiesthanthekernelsoftheguestoperatingsystems.
TheARMprocessor’sarchitectureinitiallyallowedonlyUSRandSVCmode,
foruserandkernel(supervisor)mode,respectively.InARMv7processors,ARM
introducedTrustZone(TZ),whichprovidedanadditionalring.Thismostpriv-
ileged execution environment also has exclusive access to hardware-backed
cryptographicfeatures,suchastheNFCSecureElementandanon-chip cryp-
tographickey,thatmakehandlingpasswordsandsensitiveinformationmore
secure.Eventhekernelitselfhasnoaccesstotheon-chipkey,anditcanonly
request encryption and decryption services from the TrustZone environment
(by means of a specializedinstruction, SecureMonitor Call (SMC)), which is
onlyusablefromkernelmode.Aswithsystemcalls,thekernelhas noability
todirectlyexecutetospecificaddressesintheTrustZone—only topassargu-
ments via registers. Android uses TrustZone extensively as of Version 5.0, as
showninFigure17.2.
Correctly employing a trusted execution environment means that, if the
kernel is compromised, an attacker can’t simply retrieve the key from kernel
memory. Moving cryptographic services to a separate, trusted environment17.4 DomainofProtection 671
Figure17.2 AndroidusesofTrustZone.
alsomakesbrute-forceattackslesslikelytosucceed.(AsdescribedinChapter
16, these attacks involve trying all possible combinations of valid password
charactersuntilthepasswordisfound.)Thevariouskeysusedbythesystem,
from the user’s password to the system’s own, are stored in the on-chip key,
whichisonlyaccessibleinatrustedcontext.Whenakey—say,apassword—
isentered,itisverifiedviaarequesttotheTrustZoneenvironment.Ifakeyis
notknownandmustbeguessed,theTrustZoneverifiercanimposelimitations
—bycappingthenumberofverificationattempts,forexample.
Inthe64-bitARMv8architecture,ARMextendeditsmodeltosupportfour
levels, called “exception levels,” numbered EL0 through EL3. User mode runs
in EL0, and kernel mode in EL1. EL2 is reserved for hypervisors, and EL3 (the
mostprivileged)isreservedforthesecuremonitor(theTrustZonelayer).Any
oneoftheexceptionlevelsallowsrunningseparateoperatingsystemssideby
side,asshowninFigure17.3.
Notethatthesecuremonitorrunsatahigherexecutionlevelthangeneral-
purposekernels,whichmakesittheperfectplacetodeploycodethatwillcheck
the kernels’ integrity. This functionality is included in Samsung’s Realtime
KernelProtection(RKP)forAndroidandApple’sWatchTower(alsoknownas
KPP,forKernelPatchProtection)foriOS.
17.4 Domain of Protection
Rings of protection separate functions into domains and order them hierar-
chically. A generalization of rings is using domains without a hierarchy. A
computer system can be treated as a collection of processes and objects. By672 Chapter17 Protection
Figure17.3 ARMarchitecture.
objects,wemeanbothhardwareobjects(suchastheCPU,memorysegments,
printers,disks,andtapedrives)andsoftwareobjects(suchasfiles,programs,
andsemaphores).Eachobjecthasauniquenamethatdifferentiatesitfromall
otherobjectsinthesystem,andeachcanbeaccessedonlythroughwell-defined
andmeaningfuloperations.Objectsareessentiallyabstractdatatypes.
The operations that are possible depend on the object. For example, on a
CPU, we can only execute. Memory words can be read and written, whereas
aDVD-ROMcanonlyberead.Tapedrivescanberead,written,andrewound.
Datafilescanbecreated,opened,read,written,closed,anddeleted;program
filescanberead,written,executed,anddeleted.
Aprocess should be allowed to access only those objects for which it has
authorization. Furthermore, at any time, a process should be able to access
only those objects that it currently requires to complete its task. This second
requirement,the need-to-knowprinciple,is usefulinlimiting the amount of
damagea faultyprocess or an attackercan cause inthe system.For example,
when process p invokes procedure A(), the procedure should be allowed to
accessonlyitsownvariablesandtheformalparameterspassedtoit;itshould
notbeabletoaccessallthevariablesofprocessp.Similarly,considerthecasein
which processpinvokesacompilertocompileaparticularfile.Thecompiler
should not be able to access files arbitrarily but should have access only to a
well-definedsubsetoffiles(suchasthesourcefile,outputobjectfile,andsoon)
related to the file to be compiled. Conversely,the compiler may have private
files used for accounting or optimization purposes that process p should not
beabletoaccess.
Incomparingneed-to-knowwithleastprivilege,itmaybeeasiesttothink
ofneed-to-knowasthepolicyandleastprivilegeasthemechanismforachiev-
ing this policy. For example, in file permissions, need-to-know might dictate
that a user have read access but not write or execute access to a file. The
principle of least privilege would require that the operating system provide
amechanismtoallowreadbutnotwriteorexecuteaccess.17.4 DomainofProtection 673
17.4.1 Domain Structure
Tofacilitatethesortofschemejustdescribed,aprocessmayoperatewithina
protectiondomain,whichspecifiestheresourcesthattheprocessmayaccess.
Each domain defines a set of objects and the types of operations that may be
invoked on each object. The ability to execute an operation on an object is
an access right. Adomain is a collection of access rights, each of which is an
orderedpair<object-name, rights-set>.Forexample,ifdomainDhasthe
access right <file F, {read,write}>, then a process executing in domain D
canbothreadandwritefileF.Itcannot,however,performanyotheroperation
onthatobject.
Domains may share access rights. For example, in Figure 17.4, we have
threedomains:D ,D ,andD .Theaccessright<O ,{print}>issharedbyD
1 2 3 4 2
andD ,implyingthat aprocessexecutingineitherofthesetwodomainscan
3
print object O . Note that a process must be executing in domain D to read
4 1
andwriteobjectO ,whileonlyprocessesindomainD mayexecuteobjectO .
1 3 1
The association between a process and a domain may be either static, if
the set of resources available to the process is fixed throughout the process’s
lifetime, or dynamic. As might be expected, establishing dynamic protection
domainsismorecomplicatedthanestablishingstaticprotectiondomains.
Iftheassociationbetweenprocessesanddomainsisfixed,andwewantto
adheretotheneed-to-knowprinciple,thenamechanismmustbeavailableto
changethecontentofadomain.Thereasonstemsfromthefactthataprocess
may execute in two different phases and may, for example, need read access
inonephaseandwriteaccessinanother.Ifadomainisstatic,wemustdefine
thedomaintoincludebothreadandwriteaccess.However,thisarrangement
providesmorerightsthanareneededineachofthetwophases,sincewehave
readaccessinthephasewhereweneedonlywriteaccess,andviceversa.Thus,
theneed-to-knowprincipleisviolated.Wemustallowthecontentsofadomain
to be modified so that the domain always reflects the minimum necessary
accessrights.
If the association is dynamic, a mechanism is available to allow domain
switching,enablingtheprocesstoswitchfromonedomaintoanother.Wemay
alsowanttoallowthecontentofadomaintobechanged.Ifwecannotchange
the content of a domain, we can provide the same effect by creating a new
domainwiththechangedcontentandswitchingtothatnewdomainwhenwe
wanttochangethedomaincontent.
D D D
1 2 3
< O , {read, write} >
<
<
O O3 1,
,
{ {r ee xa ed c,
u
w ter }i t >e} > < O 2, {write} > < O 4, {print} > <
<
O
O
31 ,, {{ re ex ae dc }u >te} >
2
Figure17.4 Systemwiththreeprotectiondomains.674 Chapter17 Protection
Adomaincanberealizedinavarietyofways:
• Each user may be a domain. In this case, the set of objects that can be
accessed depends on the identity of the user. Domain switching occurs
whentheuserischanged—generallywhenoneuserlogsoutandanother
userlogsin.
• Each process may be a domain. In this case, the set of objects that can be
accesseddependsontheidentityoftheprocess.Domainswitchingoccurs
whenone processsendsamessagetoanother processandthenwaits for
aresponse.
• Eachproceduremaybeadomain.Inthiscase,thesetofobjectsthatcanbe
accessedcorrespondstothelocalvariablesdefinedwithintheprocedure.
Domainswitchingoccurswhenaprocedurecallismade.
WediscussdomainswitchingingreaterdetailinSection17.5.
Considerthestandarddual-mode(kernel–usermode)modelofoperating-
systemexecution.Whenaprocessisinkernelmode,itcanexecuteprivileged
instructions and thus gain complete control of the computer system. In con-
trast,whenaprocessexecutesinusermode,itcaninvokeonlynonprivileged
instructions. Consequently,itcan executeonly within itspredefinedmemory
space. These two modes protect the operating system (executing in kernel
domain) from the user processes (executing in user domain). In a multipro-
grammed operating system, two protection domains are insufficient, since
usersalsowanttobeprotectedfromoneanother.Therefore,amoreelaborate
scheme is needed. We illustrate such a scheme by examining two influential
operating systems—UNIX and Android—to see how they implement these
concepts.
17.4.2 Example: UNIX
Asnotedearlier,inUNIX,therootusercanexecuteprivilegedcommands,while
other users cannot. Restricting certain operations to the root user can impair
other users in their everyday operations, however. Consider, for example, a
userwhowantstochangehispassword.Inevitably,thisrequiresaccesstothe
passworddatabase(commonly,/etc/shadow),whichcanonlybeaccessedby
root. Asimilar challenge is encountered when setting a scheduled job (using
theatcommand)—doing sorequiresaccesstoprivilegeddirectoriesthatare
beyondthereachofanormaluser.
The solution to this problem is the setuid bit. In UNIX, an owner identi-
fication and a domain bit, known as the setuid bit, are associated with each
file. The setuid bit may or may not be enabled. When the bit is enabled on
an executable file (through chmod +s), whoever executesthe file temporarily
assumestheidentityofthefileowner.Thatmeansifausermanagestocreatea
filewiththeuserID“root”andthesetuidbitenabled,anyonewhogainsaccess
toexecutethefilebecomesuser“root”forthedurationoftheprocess’slifetime.
If that strikes you as alarming, it is with good reason. Because of their
potential power, setuid executable binaries are expected to be both sterile
(affecting only necessary files under specific constraints) and hermetic (for
example, tamperproof and impossible to subvert). Setuid programs need to17.5 AccessMatrix 675
beverycarefullywrittentomaketheseassurances.Returningtotheexample
of changing passwords, the passwd command is setuid-root and will indeed
modifythepassworddatabase,butonlyiffirstpresentedwiththeuser’svalid
password, and it will then restrict itself to editing the password of that user
andonlythatuser.
Unfortunately,experiencehasrepeatedlyshownthatfewsetuidbinaries,if
any,fulfillbothcriteriasuccessfully.Timeandagain,setuidbinarieshavebeen
subverted—some through race conditions and others through code injection
—yieldinginstantrootaccesstoattackers.Attackersarefrequentlysuccessful
inachievingprivilegeescalationinthisway.Methodsofdoingsoarediscussed
inChapter16.Limitingdamagefrombugsinsetuidprogramsisdiscussedin
Section17.8.
17.4.3 Example: Android Application IDs
InAndroid,distinctuserIDsareprovidedonaper-applicationbasis.Whenan
applicationisinstalled,theinstallddaemonassignsitadistinctuserID(UID)
and group ID (GID), along with a private data directory (/data/data/<app-
name>)whoseownershipisgrantedtothisUID/GIDcombinationalone.Inthis
way, applications on the device enjoy the same level of protection provided
byUNIXsystemstoseparateusers.Thisisaquickandsimplewaytoprovide
isolation,security,andprivacy.Themechanismisextendedbymodifyingthe
kerneltoallowcertainoperations(suchasnetworkingsockets)onlytomem-
bersofaparticularGID(forexample,AID INET,3003).Afurtherenhancement
by Android is todefine certain UIDs as “isolated,”which preventsthem from
initiatingRPCrequeststoanybutabareminimumofservices.
17.5 Access Matrix
The general model of protection can be viewed abstractly as a matrix, called
an access matrix. The rows of the access matrix represent domains, and the
columns representobjects. Each entry in the matrix consists of a set of access
rights. Because the column defines objects explicitly, we can omit the object
namefromtheaccessright.Theentryaccess(i,j)definesthesetofoperations
thataprocessexecutingindomainD caninvokeonobjectO.
i j
Toillustratetheseconcepts,weconsidertheaccessmatrixshowninFigure
17.5.Therearefourdomainsandfourobjects—threefiles(F ,F ,F )andone
1 2 3
laser printer. A process executing in domain D can read files F and F . A
1 1 3
process executing in domain D has the same privileges as one executing in
4
domain D ; but in addition, it can also write onto files F and F . The laser
1 1 3
printercanbeaccessedonlybyaprocessexecutingindomainD .
2
Theaccess-matrixschemeprovidesuswiththemechanismforspecifyinga
varietyofpolicies.Themechanismconsistsofimplementingtheaccessmatrix
andensuringthatthesemanticpropertieswehaveoutlinedhold.Morespecif-
ically, we must ensure that a process executing in domain D can access only
i
thoseobjectsspecifiedinrowi,andthenonlyasallowedbytheaccess-matrix
entries.
The access matrix can implement policy decisions concerning protection.
Thepolicydecisionsinvolvewhichrightsshouldbeincludedinthe(i,j)thentry.676 Chapter17 Protection
object
F F F printer
1 2 3
domain
D read read
1
D print
2
D read execute
3
read read
D
4 write write
Figure17.5 Accessmatrix.
We must also decide the domain in which each process executes. This last
policyisusuallydecidedbytheoperatingsystem.
Theusersnormallydecidethecontentsoftheaccess-matrixentries.When
ausercreatesanewobjectO,thecolumnO isaddedtotheaccessmatrixwith
j j
theappropriateinitializationentries,asdictatedby thecreator.Theusermay
decidetoentersomerightsinsomeentriesincolumnjandotherrightsinother
entries,asneeded.
The access matrix provides an appropriate mechanism for defining and
implementing strict control for both static and dynamic association between
processesanddomains.Whenweswitchaprocessfromonedomaintoanother,
we are executing an operation (switch) on an object (the domain). We can
control domain switching by including domains among the objects of the
accessmatrix.Similarly,whenwechangethecontentoftheaccessmatrix,we
are performing an operation on an object: the access matrix. Again, we can
controlthesechangesbyincludingtheaccessmatrixitselfasanobject.Actually,
since each entry in the access matrix can be modified individually, we must
considereachentryintheaccessmatrixasanobjecttobeprotected.Now,we
need to consider only the operations possible on these new objects (domains
andtheaccessmatrix)anddecidehowwewantprocessestobeabletoexecute
theseoperations.
Processesshouldbeabletoswitchfromonedomaintoanother.Switching
fromdomainD todomainD isallowedifandonlyiftheaccessrightswitch∈
i j
access(i,j).Thus,inFigure17.6,aprocessexecutingindomainD canswitch
2
todomainD ortodomainD .AprocessindomainD canswitchtoD ,and
3 4 4 1
oneindomainD canswitchtoD .
1 2
Allowing controlled change in the contents of the access-matrix entries
requiresthree additionaloperations: copy, owner,and control.We examine
theseoperationsnext.
Theabilitytocopyanaccessrightfromonedomain(orrow)oftheaccess
matrix to another is denoted by an asterisk (*) appended to the access right.
The copy right allows the access right to be copied only within the column
(that is, for the object) for which the right is defined. For example, in Figure
17.7(a),aprocessexecutingindomainD cancopythereadoperationintoany
2
entryassociatedwithfileF .Hence,theaccessmatrixofFigure17.7(a)canbe
2
modifiedtotheaccessmatrixshowninFigure17.7(b).17.5 AccessMatrix 677
object
F F F laser D D D D
1 2 3 printer 1 2 3 4
domain
D read read switch
1
D print switch switch
2
D read execute
3
D read read switch
4 write write
Figure17.6 AccessmatrixofFigure17.5withdomainsasobjects.
Thisschemehastwoadditionalvariants:
1. Arightiscopiedfromaccess(i,j)toaccess(k,j);itisthenremovedfrom
access(i,j).Thisactionisatransferofaright,ratherthanacopy.
2. Propagation of the copy right may be limited. That is, when the right
R∗ is copiedfromaccess(i,j)toaccess(k,j),only theright R (not R∗ ) is
created.AprocessexecutingindomainD cannotfurthercopytheright
k
R.
A system may select only one of these three copy rights, or it may provide
allthreebyidentifyingthemasseparaterights:copy,transfer,andlimited
copy.
object
F F F
1 2 3
domain
D execute write*
1
D execute read* execute
2
D execute
3
(a)
object
F F F
1 2 3
domain
D execute write*
1
D execute read* execute
2
D execute read
3
(b)
Figure17.7 Accessmatrixwithcopyrights.678 Chapter17 Protection
Wealsoneedamechanismtoallowadditionofnewrightsandremovalof
somerights.Theownerrightcontrolstheseoperations.Ifaccess(i,j)includes
the owner right, then a process executing in domain D can add and remove
i
anyrightinanyentryincolumnj.Forexample,inFigure17.8(a),domainD
1
is the owner of F and thus can add and delete any valid right in column F .
1 1
Similarly,domainD istheowner ofF andF andthus canaddandremove
2 2 3
any valid right within these two columns. Thus, the access matrix of Figure
17.8(a)canbemodifiedtotheaccessmatrixshowninFigure17.8(b).
The copy and owner rights allow a process to change the entries in a
column. A mechanism is also needed to change the entries in a row. The
controlrightisapplicableonlytodomainobjects.Ifaccess(i,j)includesthe
control right, then a process executing indomain D can removeany access
i
right from row j. For example, suppose that, in Figure 17.6, we include the
control right in access(D , D ). Then, a process executing in domain D
2 4 2
couldmodifydomainD ,asshowninFigure17.9.
4
Thecopyandownerrightsprovideuswithamechanismtolimittheprop-
agation of access rights. However, they do not give us the appropriate tools
forpreventingthepropagation(ordisclosure)ofinformation.Theproblemof
guaranteeingthatnoinformationinitiallyheldinanobjectcanmigrateoutside
ofitsexecutionenvironmentiscalledtheconfinemen problem.Thisproblem
isingeneralunsolvable(seethebibliographicalnotesattheendofthechapter).
object
F F F
1 2 3
domain
D owner write
1 execute
read*
D read* owner
2 owner
write
D execute
3
(a)
object
F F F
1 2 3
domain
D owner write
1 execute
owner read*
D read* owner
2
write* write
D write write
3
(b)
Figure17.8 Accessmatrixwithownerrights.17.6 ImplementationoftheAccessMatrix 679
object F F F laser D D D D
1 2 3 printer 1 2 3 4
domain
D read read switch
1
D print switch switch
2 control
D read execute
3
D write write switch
4
Figure17.9 ModifiedaccessmatrixofFigure17.6.
These operations on the domains and the access matrix are not in them-
selvesimportant,buttheyillustratetheabilityoftheaccess-matrixmodeltolet
usimplementandcontroldynamicprotectionrequirements.Newobjectsand
new domains can be created dynamically and included in the access-matrix
model.However,wehaveshownonlythatthebasicmechanismexists.System
designersandusersmustmakethepolicydecisionsconcerningwhichdomains
aretohaveaccesstowhichobjectsinwhichways.
17.6 Implementation of the Access Matrix
Howcantheaccessmatrixbeimplementedeffectively?Ingeneral,thematrix
will be sparse; that is, most of the entries will be empty. Although data-
structuretechniquesareavailableforrepresentingsparsematrices,theyarenot
particularlyusefulforthisapplication,becauseofthewayinwhichtheprotec-
tionfacilityisused.Here,we first describeseveralmethodsof implementing
theaccessmatrixandthencomparethemethods.
17.6.1 Global Table
The simplest implementation of the access matrix is a global table consisting
of a set of ordered triples <domain, object, rights-set>. Whenever an
operation M is executed on an object O within domain D, the global table
j i
is searched for a triple <D, O, R >, with M ∈ R . If this triple is found, the
i j k k
operationisallowedtocontinue;otherwise,anexception(orerror)condition
israised.
Thisimplementationsuffersfromseveraldrawbacks.Thetableisusually
large and thus cannot be kept in main memory, so additional I/O is needed.
Virtualmemorytechniquesareoftenusedformanagingthistable.Inaddition,
it is difficult to take advantage of special groupings of objects or domains.
For example, if everyone can read a particular object, this object must have
aseparateentryineverydomain.
17.6.2 Access Lists for Objects
Each column in the access matrix can be implemented as an access list for
oneobject,asdescribedinSection13.4.2.Obviously,theemptyentriescanbe680 Chapter17 Protection
discarded.Theresultinglistforeachobjectconsistsoforderedpairs<domain,
rights-set>,whichdefinealldomainswithanonemptysetofaccessrights
forthatobject.
This approach can be extendedeasily to define a list plus a default set of
accessrights.WhenanoperationMonanobjectO isattemptedindomainD,
j i
wesearchtheaccesslistforobjectO,lookingforanentry<D,R >withM∈
j i k
R .Iftheentryisfound,weallowtheoperation;ifitisnot,wecheckthedefault
k
set.IfMisinthedefaultset,weallowtheaccess.Otherwise,accessisdenied,
andanexceptionconditionoccurs.Forefficiency,wemaycheckthedefaultset
firstandthensearchtheaccesslist.
17.6.3 Capability Lists for Domains
Rather than associating the columns of the access matrix with the objects as
access lists, we can associate each row with its domain. Acapability list for
a domain is a list of objects together with the operations allowed on those
objects.Anobjectisoftenrepresentedby itsphysicalnameor address,called
a capability. To execute operation M on object O, the process executes the
j
operationM,specifyingthecapability(orpointer)forobjectO asaparameter.
j
Simplepossessionofthecapabilitymeansthataccessisallowed.
The capability list is associated with a domain, but it is never directly
accessible to a process executing in that domain. Rather, the capability list
is itself a protected object, maintained by the operating system and accessed
by the user only indirectly. Capability-based protection relies on the fact that
the capabilities are never allowed to migrate into any address space directly
accessiblebyauserprocess(wheretheycouldbemodified).Ifallcapabilities
aresecure,theobjecttheyprotectisalsosecureagainstunauthorizedaccess.
Capabilitieswereoriginallyproposedasakindofsecurepointer,tomeet
theneedforresourceprotectionthatwasforeseenasmultiprogrammedcom-
putersystemscameofage.Theideaofaninherentlyprotectedpointerprovides
afoundationforprotectionthatcanbeextendeduptotheapplicationlevel.
Toprovideinherentprotection,wemustdistinguishcapabilitiesfromother
kindsofobjects,andtheymustbeinterpretedbyanabstractmachineonwhich
higher-level programs run. Capabilities are usually distinguished from other
datainoneoftwoways:
• Each object has a tag to denote whether it is a capability or accessible
data.Thetagsthemselvesmustnotbedirectlyaccessiblebyanapplication
program. Hardware or firmware support may be used to enforce this
restriction. Although only one bit is necessary to distinguish between
capabilities and other objects, more bits are often used. This extension
allows all objects to be tagged with their types by the hardware. Thus,
the hardware can distinguish integers, floating-point numbers, pointers,
Booleans,characters,instructions,capabilities,anduninitializedvaluesby
theirtags.
• Alternatively,theaddressspaceassociatedwithaprogramcanbesplitinto
twoparts.Onepartisaccessibletotheprogramandcontainstheprogram’s
normaldataandinstructions.Theotherpart,containingthecapabilitylist,
isaccessibleonlybytheoperatingsystem.Asegmentedmemoryspaceis
usefultosupportthisapproach.17.6 ImplementationoftheAccessMatrix 681
Severalcapability-basedprotectionsystemshavebeendeveloped;wedescribe
them briefly in Section 17.10. The Mach operating system also uses a version
ofcapability-basedprotection;itisdescribedinAppendixD.
17.6.4 A Lock–Key Mechanism
Thelock–keyschemeisacompromisebetweenaccesslistsandcapabilitylists.
Eachobjecthasalistofuniquebitpatternscalledlocks.Similarly,eachdomain
has a list of unique bit patterns called keys. Aprocess executing in a domain
canaccessanobjectonlyifthatdomainhasakeythatmatchesoneofthelocks
oftheobject.
Aswithcapabilitylists,thelistofkeysforadomainmustbemanagedby
theoperatingsystemonbehalfofthedomain.Usersarenotallowedtoexamine
ormodifythelistofkeys(orlocks)directly.
17.6.5 Comparison
Asyoumightexpect,choosingatechniqueforimplementinganaccessmatrix
involvesvarious trade-offs.Using aglobal table is simple;however, the table
can be quite large and often cannot take advantage of special groupings of
objects or domains. Access lists correspond directly to the needs of users.
When a user creates an object, he can specify which domains can access the
object,aswellaswhatoperationsareallowed.However,becauseaccess-right
information for a particular domain is not localized, determining the set of
accessrightsforeachdomainisdifficult.Inaddition,everyaccesstotheobject
must be checked, requiring a search of the access list. In a large system with
longaccesslists,thissearchcanbetimeconsuming.
Capability lists do not correspond directly tothe needs of users,but they
areusefulforlocalizinginformationforagivenprocess.Theprocessattempt-
ingaccessmustpresentacapabilityforthataccess.Then,theprotectionsystem
needs only to verify that the capability is valid. Revocation of capabilities,
however,maybeinefficient(Section17.7).
Thelock–keymechanism,asmentioned,isacompromisebetweenaccess
lists and capability lists. The mechanism can be both effective and flexible,
depending on the length of the keys. The keys can be passed freely from
domaintodomain.Inaddition,accessprivilegescanbeeffectivelyrevokedby
thesimpletechniqueofchangingsomeofthelocksassociatedwiththeobject
(Section17.7).
Most systems use a combination of access lists and capabilities. When a
process first tries to access an object, the access list is searched. If access is
denied, an exception condition occurs. Otherwise, a capability is created and
attachedtotheprocess.Additionalreferencesusethecapabilitytodemonstrate
swiftlythataccessisallowed.Afterthelastaccess,thecapabilityisdestroyed.
ThisstrategywasusedintheMULTICSsystemandintheCALsystem.
As an example of how such a strategy works, consider a file system in
which each file has an associated access list. When a process opens a file, the
directorystructureissearchedtofindthefile,accesspermissionischecked,and
buffers are allocated. All this information is recorded in a new entry in a file
tableassociatedwiththeprocess.Theoperationreturnsanindexintothistable
forthenewlyopenedfile.Alloperationsonthefilearemadebyspecification
oftheindexintothefiletable.Theentryinthefiletablethenpointstothefile682 Chapter17 Protection
anditsbuffers.Whenthefileisclosed,thefile-tableentryisdeleted.Sincethe
file table is maintained by the operating system, the user cannot accidentally
corrupt it. Thus, the user can access only those files that have been opened.
Since access is checked when the file is opened, protection is ensured. This
strategyisusedintheUNIXsystem.
Therighttoaccessmuststillbecheckedoneachaccess,andthefile-table
entry has a capability only for the allowed operations. If a file is opened for
reading, then a capability for read access is placed in the file-table entry. If
anattemptismadetowriteontothefile,thesystemidentifiesthisprotection
violationbycomparingtherequestedoperationwiththecapabilityinthefile-
tableentry.
17.7 Revocation of Access Rights
In a dynamic protection system, we may sometimes need to revoke access
rightstoobjectssharedbydifferentusers.Variousquestionsaboutrevocation
mayarise:
• Immediate versus delayed. Does revocation occur immediately, or is it
delayed?Ifrevocationisdelayed,canwefindoutwhenitwilltakeplace?
• Selective versus general. When an access right to an object is revoked,
does it affect all the users who have an access right to that object, or can
wespecifyaselectgroupofuserswhoseaccessrightsshouldberevoked?
• Partialversustotal.Canasubsetoftherightsassociatedwithanobjectbe
revoked,ormustwerevokeallaccessrightsforthisobject?
• Temporary versus permanent. Can access be revoked permanently (that
is,therevokedaccessrightwillneveragainbeavailable),orcanaccessbe
revokedandlaterbeobtainedagain?
Withanaccess-listscheme,revocationiseasy.Theaccesslistissearchedfor
anyaccessrightstoberevoked,andtheyaredeletedfromthelist.Revocation
isimmediateandcanbegeneralorselective,totalorpartial,andpermanentor
temporary.
Capabilities,however,present amuch more difficult revocation problem,
asmentionedearlier.Sincethecapabilitiesaredistributedthroughoutthesys-
tem,wemustfindthembeforewecanrevokethem.Schemesthatimplement
revocationforcapabilitiesincludethefollowing:
• Reacquisition.Periodically,capabilitiesaredeletedfromeachdomain.Ifa
processwantstouseacapability,itmayfindthatthatcapabilityhasbeen
deleted.Theprocessmaythentrytoreacquirethecapability.Ifaccesshas
beenrevoked,theprocesswillnotbeabletoreacquirethecapability.
• Back-pointers.Alistof pointersismaintained witheach object,pointing
toallcapabilitiesassociatedwiththatobject.Whenrevocationisrequired,
wecan followthesepointers,changing thecapabilitiesasnecessary.This
scheme was adopted in the MULTICS system. It is quite general, but its
implementationiscostly.17.8 Role-BasedAccessControl 683
• Indirection. The capabilities point indirectly, not directly, to the objects.
Each capability points to a unique entry in a global table, which in turn
pointstotheobject.Weimplementrevocationbysearchingtheglobaltable
for the desired entry and deleting it. Then, when an access is attempted,
the capability is found to point to an illegal table entry. Table entries can
bereusedforothercapabilitieswithoutdifficulty,sinceboththecapability
andthetableentrycontaintheuniquenameoftheobject.Theobjectfora
capabilityanditstableentrymustmatch.Thisschemewasadoptedinthe
CALsystem.Itdoesnotallowselectiverevocation.
• Keys.Akeyisauniquebitpatternthatcanbeassociatedwithacapability.
This key is defined when the capability is created, and it can be neither
modifiednorinspectedbytheprocessthatownsthecapability.Amaster
key is associated with each object; it can be defined or replaced with
the set-key operation. When a capability is created, the current value
of the master key is associated with the capability. When the capability
is exercised, its key is compared with the master key. If the keys match,
the operation is allowed to continue; otherwise, an exception condition
is raised. Revocation replaces the master key with a new value via the
set-keyoperation,invalidatingallpreviouscapabilitiesforthisobject.
Thisschemedoesnotallowselectiverevocation,sinceonlyonemaster
key is associatedwith each object.Ifwe associate a listof keyswith each
object,thenselectiverevocationcanbeimplemented.Finally,wecangroup
all keys into one global table of keys. A capability is valid only if its
key matches some key in the global table. We implement revocation by
removing the matching key from the table. With this scheme, a key can
beassociatedwithseveralobjects,andseveralkeyscanbeassociatedwith
eachobject,providingmaximumflexibility.
Inkey-basedschemes,theoperationsofdefiningkeys,insertingthem
intolists,anddeletingthemfromlistsshouldnotbeavailabletoallusers.
Inparticular,itwouldbereasonabletoallowonlytheownerofanobjectto
setthekeysforthatobject.Thischoice,however,isapolicydecisionthat
theprotectionsystemcanimplementbutshouldnotdefine.
17.8 Role-Based Access Control
InSection13.4.2,wedescribedhowaccesscontrolscanbeusedonfileswithin
afilesystem.Eachfileanddirectoryisassignedanowner,agroup,orpossibly
a list of users, and for each of those entities, access-control information is
assigned. A similar function can be added to other aspects of a computer
system.AgoodexampleofthisisfoundinSolaris10andlaterversions.
Theideaistoadvancetheprotectionavailableintheoperatingsystemby
explicitlyaddingtheprincipleofleastprivilegeviarole-basedaccesscontrol
(RBAC). This facility revolves around privileges. A privilege is the right to
execute a system call or to use an option within that system call (such as
opening a file with write access). Privileges can be assigned to processes,
limitingthemtoexactlytheaccesstheyneedtoperformtheirwork.Privileges
andprogramscanalsobeassignedtoroles.Usersareassignedrolesorcantake
roles based on passwords assigned to the roles. In this way, a user can take a684 Chapter17 Protection
user 1
role 1
privileges 1
privileges 2
executes with role 1 privileges
process
Figure17.10 Role-basedaccesscontrolinSolaris10.
rolethatenablesaprivilege,allowingtheusertorunaprogramtoaccomplish
a specific task, as depictedin Figure 17.10. This implementationof privileges
decreasesthesecurityriskassociatedwithsuperusersandsetuidprograms.
NoticethatthisfacilityissimilartotheaccessmatrixdescribedinSection
17.5. This relationship is further explored in the exercises at the end of the
chapter.
17.9 Mandatory Access Control (MAC)
Operatingsystemshavetraditionallyuseddiscretionaryaccesscontrol(DAC)
as a means of restricting access to files and other system objects. With DAC,
access is controlled based on the identities of individual users or groups. In
UNIX-basedsystem,DACtakestheformoffilepermissions(settablebychmod,
chown, and chgrp), whereas Windows (and some UNIX variants) allow finer
granularitybymeansofaccess-controllists(ACLs).
DACs, however, have proved insufficient over the years. Akey weakness
lies in their discretionary nature, which allows the owner of a resource to set
ormodifyitspermissions.Anotherweaknessistheunlimitedaccessallowed
for the administrator or root user. As we have seen, this designcan leave the
system vulnerable to both accidental and malicious attacks and provides no
defensewhenhackersobtainrootprivileges.
The need arose, therefore, for a stronger form of protection, which was
introducedintheformofmandatoryaccesscontrol(MAC).MACisenforcedas
asystempolicythateventherootusercannotmodify(unlessthepolicyexplic-
itly allows modifications or the system is rebooted, usually into an alternate
configuration). The restrictions imposed by MAC policy rules are more pow-
erful than the capabilities of the root user and can be usedto make resources
inaccessibletoanyonebuttheirintendedowners.17.10 Capability-BasedSystems 685
Modern operating systems all provide MAC along with DAC, although
implementations differ. Solaris was among the first to introduce MAC, which
was part of Trusted Solaris (2.5). FreeBSD made DAC part of its TrustedBSD
implementation (FreeBSD 5.0). The FreeBSD implementation was adopted by
Apple in macOS 10.5 and has served as the substrate over which most of the
security features of MAC and iOS are implemented. Linux’s MAC implemen-
tation is part of the SELinux project, which was devised by the NSA, and has
been integrated into most distributions. Microsoft Windows joined the trend
withWindowsVista’sMandatoryIntegrityControl.
AttheheartofMACistheconceptoflabels.Alabelisanidentifier(usually
a string) assigned to an object (files, devices, and the like). Labels may also
be applied to subjects (actors, such as processes). When a subject request to
performoperationsontheobjects.Whensuchrequestsaretobeservedbythe
operating system, it first performs checks defined in a policy, which dictates
whetherornotagivenlabelholdingsubjectisallowedtoperformtheoperation
onthelabeledobject.
As a brief example, consider a simple set of labels, ordered according to
levelofprivilege:“unclassified,”“secret,”and“topsecret.”Auserwith“secret”
clearancewillbeabletocreatesimilarlylabeledprocesses,whichwillthenhave
accessto“unclassified”and“secret”files,butnotto“topsecret”files.Neither
theusernoritsprocesseswouldevenbeawareoftheexistenceof“topsecret”
files, since the operating system would filter them out of all file operations
(for example, they would not be displayed when listing directory contents).
User processes would similarly be protected themselves in this way, so that
an"unclassified"processwouldnotbeabletoseeorperformIPCrequeststoa
“secret”(or“topsecret”)process.Inthisway,MAClabelsareanimplementation
oftheaccessmatrixdescribedearlier.
17.10 Capability-Based Systems
Theconceptofcapability-basedprotectionwasintroducedintheearly1970s.
TwoearlyresearchsystemswereHydraandCAP.Neithersystemwaswidely
used, but both provided interesting proving grounds for protection theories.
Formoredetailsonthesesystems,seeSectionA.14.1andSectionA.14.2.Here,
weconsidertwomorecontemporaryapproachestocapabilities.
17.10.1 Linux Capabilities
LinuxusescapabilitiestoaddressthelimitationsoftheUNIXmodel,whichwe
describedearlier.ThePOSIX standardsgroupintroducedcapabilitiesinPOSIX
1003.1e. Although POSIX.1e was eventually withdrawn, Linux was quick to
adoptcapabilitiesinVersion2.2andhascontinuedtoaddnewdevelopments.
In essence, Linux’s capabilities “slice up” the powers of root into distinct
areas, each represented by a bit in a bitmask, as shown in Figure 17.11. Fine-
grainedcontroloverprivilegedoperationscanbeachievedbytogglingbitsin
thebitmask.
Inpractice,threebitmasksareused—denotingthecapabilitiespermitted,
effective,andinheritable.Bitmaskscanapplyonaper-processoraper-thread
basis.Furthermore,oncerevoked,capabilitiescannotbereacquired.Theusual686 Chapter17 Protection
I C
W
Figure17.11 CapabilitiesinPOSIX.1e.
sequenceofeventsisthataprocessorthreadstartswiththefullsetofpermitted
capabilitiesandvoluntarilydecreasesthatsetduringexecution.Forexample,
afteropeninganetworkport,athreadmightremovethatcapabilitysothatno
furtherportscanbeopened.
You can probably see that capabilities are a direct implementation of the
principleofleastprivilege.Asexplainedearlier,thistenetofsecuritydictates
that an application or user must be given only those rights than are required
foritsnormaloperation.
Android(whichisbasedonLinux)alsoutilizescapabilities,whichenable
systemprocesses(notably,“systemserver”),toavoidrootownership,instead
selectivelyenablingonlythoseoperationsrequired.
The Linux capabilities model is a great improvement over the traditional
UNIX model, but it still is inflexible. For one thing, using a bitmap with a bit
representing each capability makes it impossible to add capabilities dynami-
callyandrequiresrecompilingthekerneltoaddmore.Inaddition,thefeature
appliesonlytokernel-enforcedcapabilities.
17.10.2 Darwin Entitlements
Apple’s system protection takes the form of entitlements. Entitlements are
declaratory permissions—XML property list stating which permissions are
claimed as necessary by the program (see Figure 17.12). When the process
attemptsaprivilegedoperation(inthe figure,loadingakernelextension),its17.11 OtherProtectionImprovementMethods 687
<!DOCTYPEplistPUBLIC"-//Apple//DTDPLIST1.0//EN"
"http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>com.apple.private.kernel.get-kext-info
<true/>
<key>com.apple.rootless.kext-management
<true/>
</dict>
</plist>
Figure17.12 AppleDarwinentitlements
entitlementsarechecked,andonlyiftheneededentitlementsarepresentisthe
operationallowed.
To prevent programs from arbitrarily claiming an entitlement, Apple
embeds the entitlements in the code signature (explained in Section 17.11.4).
Once loaded, a process has no way of accessing its code signature. Other
processes(andthekernel)caneasilyquerythesignature,andinparticularthe
entitlements. Verifying an entitlement is therefore a simple string-matching
operation. In this way, only verifiable, authenticated apps may claim
entitlements. All system entitlements (com.apple.*) are further restricted to
Apple’sownbinaries.
17.11 Other Protection Improvement Methods
As the battle to protect systems from accidental and malicious damage esca-
lates, operating-system designers are implementing more types of protection
mechanisms at more levels. This section surveys some important real-world
protectionimprovements.
17.11.1 System Integrity Protection
AppleintroducedinmacOS10.11anewprotectionmechanismcalledSystem
IntegrityProtection(SIP). Darwin-based operatingsystemsuseSIPtorestrict
access to system files and resources in such a way that even the root user
cannottamperwiththem.SIPusesextendedattributesonfilestomarkthemas
restrictedandfurtherprotectssystembinariessothattheycannotbedebugged
orscrutinized,muchlesstamperedwith.Mostimportantly,onlycode-signed
kernelextensionsarepermitted,andSIPcanfurtherbeconfiguredtoallowonly
code-signedbinariesaswell.
UnderSIP,althoughrootisstillthemostpowerfuluserinthesystem,itcan
dofarlessthanbefore.Therootusercanstillmanageotherusers’files,aswell
asinstallandremoveprograms,butnotinanywaythatwouldreplaceormod-
ifyoperating-systemcomponents.SIPisimplementedasaglobal,inescapable688 Chapter17 Protection
screen on all processes, with the only exceptions allowed for system bina-
ries (for example, fsck, or kextload, as shown in Figure 17.12), which are
specificallyentitledforoperationsfortheirdesignatedpurpose.
17.11.2 System-Call Filtering
Recall from Chapter 2 that monolithic systems place all of the functionality
ofthe kernelintoasinglefile that runs ina singleaddressspace.Commonly,
general-purposeoperating-systemkernelsaremonolithic,andtheyarethere-
fore implicitlytrusted as secure. The trust boundary, therefore,rests between
kernelmodeandusermode—atthesystemlayer.Wecanreasonablyassume
thatanyattempttocompromisethesystem’sintegritywillbemadefromuser
modebymeansofasystemcall.Forexample,anattackercantrytogainaccess
byexploitinganunprotectedsystemcall.
Itisthereforeimperativetoimplementsomeformofsystem-callfiltering.
To accomplish this, we can add code to the kernel to perform an inspection
at the system-call gate, restricting a caller to a subset of system calls deemed
safe or required for that caller’s function. Specific system-call profiles can be
constructedforindividualprocesses.TheLinuxmechanismSECCOMP-BPFdoes
justthat,harnessingtheBerkeleyPacketFilterlanguagetoloadacustompro-
filethroughLinux’sproprietaryprctlsystemcall.This filteringisvoluntary
but can be effectively enforced if called from within a run-time library when
it initializes or from within the loader itself before it transfers control to the
program’sentrypoint.
A second form of system-call filtering goes deeper still and inspects the
arguments of each system call. This form of protection is considered much
stronger, as even apparently benign system calls can harbor serious vulner-
abilities.ThiswasthecasewithLinux’sfastmutex(futex)systemcall.Arace
condition in its implementation led to an attacker-controlled kernel memory
overwrite and total system compromise. Mutexes are a fundamental compo-
nent of multitasking, and thus the system call itself could not be filtered out
entirely.
Achallengeencounteredwithbothapproachesiskeepingthemasflexible
as possible while at the same time avoiding the need to rebuild the kernel
when changes or new filters are required—a common occurrence due to the
differingneedsofdifferentprocesses.Flexibilityisespeciallyimportantgiven
theunpredictablenatureofvulnerabilities.Newvulnerabilitiesarediscovered
everydayandmaybeimmediatelyexploitablebyattackers.
Oneapproachtomeetingthischallengeistodecouplethefilterimplemen-
tation from the kernel itself. The kernel need only contain a set of callouts,
which can then be implemented in a specialized driver (Windows), kernel
module (Linux), or extension (Darwin). Because an external, modular com-
ponent provides the filtering logic, it can be updated independently of the
kernel. This component commonly makes use of a specialized profiling lan-
guagebyincludingabuilt-ininterpreterorparser.Thus, theprofileitselfcan
bedecoupledfromthecode,providingahuman-readable,editableprofileand
further simplifying updates. It is also possible for the filtering component to
callatrusteduser-modedaemonprocesstoassistwithvalidationlogic.17.11 OtherProtectionImprovementMethods 689
17.11.3 Sandboxing
Sandboxinginvolvesrunningprocessesinenvironmentsthatlimitwhatthey
can do. In a basic system, a process runs with the credentials of the user that
started it and has access to all things that the user can access. If run with
system privileges such as root, the process can literally do anything on the
system. It is almost always the case that a process does not need full user or
systemprivileges.Forexample,doesawordprocessorneedtoacceptnetwork
connections? Does a network service that provides the time of day need to
accessfilesbeyondaspecificset?
Thetermsandboxingreferstothepracticeofenforcingstrictlimitationson
aprocess.Ratherthangivethatprocessthefullsetofsystemcallsitsprivileges
wouldallow,weimposeanirremovablesetofrestrictionsontheprocessinthe
early stages of its startup—well before the execution of its main() function
andoftenasearlyasitscreationwiththeforksystemcall.Theprocessisthen
renderedunabletoperformanyoperationsoutsideitsallowedset.Inthisway,
itispossibletopreventtheprocessfromcommunicatingwithanyothersystem
component,resultingintightcompartmentalizationthatmitigatesanydamage
tothesystemeveniftheprocessiscompromised.
Therearenumerousapproachestosandboxing.Javaand.net,forexample,
imposesandboxrestrictionsatthelevelofthevirtualmachine.Othersystems
enforcesandboxingaspartoftheirmandatoryaccesscontrol(MAC)policy.An
exampleisAndroid,whichdrawsonanSELinuxpolicyenhancedwithspecific
labelsforsystempropertiesandserviceendpoints.
Sandboxingmayalsobeimplementedasacombinationofmultiplemech-
anisms.AndroidhasfoundSELinuxusefulbutlacking,becauseitcannoteffec-
tivelyrestrict individual system calls. The latest Android versions (“Nougat”
and“O”)useanunderlyingLinuxmechanismcalledSECCOMP-BPF,mentioned
earlier, to apply system-call restrictions through the use of a specialized sys-
temcall.TheCrun-timelibraryinAndroid(“Bionic”)callsthissystemcallto
imposerestrictionsonallAndroidprocessesandthird-partyapplications.
Amongthemajorvendors,Applewasthefirsttoimplementsandboxing,
which appeared in macOS 10.5 (“Tiger”) as “Seatbelt”. Seatbelt was “opt-in”
rather than mandatory, allowing but not requiring applications to use it. The
ApplesandboxwasbasedondynamicprofileswrittenintheSchemelanguage,
which provided the ability to control not just which operations were to be
allowed or blocked but also their arguments. This capability enabled Apple
tocreatedifferentcustom-fitprofilesforeachbinaryonthesystem,apractice
thatcontinuestothisday.Figure17.13depictsaprofileexample.
Apple’ssandboxinghasevolvedconsiderablysinceitsinception.Itisnow
used in the iOS variants, where it serves (along with code signing) as the
chief protection against untrusted third-party code. In iOS, and starting with
macOS 10.8, the macOS sandbox is mandatory and is automatically enforced
forallMac-storedownloadedapps.Morerecently,asmentionedearlier,Apple
adopted the System Integrity Protection (SIP), used in macOS 10.11 and later.
SIPis,ineffect,asystem-wide“platformprofile.”Appleenforcesitstartingat
systembootonallprocessesinthesystem.Onlythoseprocessesthatareenti-
tled can perform privileged operations, and those are code-signed by Apple
andthereforetrusted.690 Chapter17 Protection
(version 1)
(deny default)
(allow file-chroot)
(allow file-read-metadata (literal "/var"))
(allow sysctl-read)
(allow mach-per-user-lookup)
(allow mach-lookup)
(global-name "com.apple.system.logger")
Figure17.13 AsandboxprofileofaMacOSdaemondenyingmostoperations.
17.11.4 Code Signing
At a fundamental level, how can a system “trust” a program or script? Gen-
erally, if the item came as part of the operating system, it should be trusted.
Butwhatiftheitemischanged?Ifit’schangedbyasystemupdate,thenagain
it’s trustworthy, but otherwise it should not be executable or should require
specialpermission(fromtheuseroradministrator)beforeitisrun.Toolsfrom
thirdparties,commercialorotherwise,aremoredifficulttojudge.Howcanwe
be surethe tool wasn’t modified on its way fromwhere it was createdtoour
systems?
Currently,codesigningisthebesttoolintheprotectionarsenalforsolving
theseproblems.Codesigningisthedigitalsigningofprogramsandexecuta-
blestoconfirmthattheyhavenotbeenchangedsincetheauthorcreatedthem.
Itusesacryptographichash(Section16.4.1.3)totestforintegrityandauthen-
ticity. Code signing is used for operating-system distributions, patches, and
third-partytoolsalike.Someoperatingsystems,includingiOS,Windows,and
macOS, refuse to run programs that fail their code-signing check. It can also
enhance system functionality in other ways. For example, Apple can disable
allprogramswrittenforanow-obsoleteversionofiOSbystoppingitssigning
ofthoseprogramswhentheyaredownloadedfromtheAppStore.
17.12 Language-Based Protection
To the degree that protection is provided in computer systems, it is usually
achieved through an operating-system kernel, which acts as a security agent
to inspect and validate each attempt to access a protected resource. Since
comprehensive access validation may be a source of considerable overhead,
eitherwemustgiveithardwaresupporttoreducethecostofeachvalidation,
orwemustallowthesystemdesignertocompromisethegoalsofprotection.
Satisfying all these goals is difficult if the flexibility to implement protection
policies is restricted by the support mechanisms provided or if protection
environments are made larger than necessary to secure greater operational
efficiency.
Asoperatingsystemshavebecomemorecomplex,andparticularlyasthey
haveattemptedtoprovidehigher-leveluserinterfaces,thegoalsofprotection17.12 Language-BasedProtection 691
have become much more refined. The designers of protection systems have
drawnheavilyonideasthatoriginatedinprogramminglanguagesandespe-
cially on the concepts of abstract data types and objects. Protection systems
are now concerned not only with the identity of a resource to which access
is attempted but also with the functional nature of that access. In the newest
protectionsystems,concernforthefunctiontobeinvokedextendsbeyondaset
of system-definedfunctions, such as standard file-access methods, to include
functionsthatmaybeuser-definedaswell.
Policies for resource use may also vary, depending on the application,
and they may be subject to change over time. For these reasons, protection
can no longer be considered a matter of concern only to the designer of an
operatingsystem.Itshouldalsobeavailableasatoolforusebytheapplication
designer,sothatresourcesofanapplicationsubsystemcanbeguardedagainst
tamperingortheinfluenceofanerror.
17.12.1 Compiler-Based Enforcement
Atthispoint,programminglanguagesenterthepicture.Specifyingthedesired
control of access to a shared resource in a system is making a declarative
statement about the resource. This kind of statement can be integrated into
a language by an extension of its typing facility. When protection is declared
alongwithdatatyping,thedesignerofeachsubsystemcanspecifyitsrequire-
mentsforprotection,aswellasitsneedforuseofotherresourcesinasystem.
Suchaspecificationshouldbegivendirectlyasaprogramiscomposed,andin
the language in which the programitselfis stated.This approach has several
significantadvantages:
1. Protection needs are simply declared, rather than programmed as a
sequenceofcallsonproceduresofanoperatingsystem.
2. Protectionrequirementscanbestatedindependentlyofthefacilitiespro-
videdbyaparticularoperatingsystem.
3. The means for enforcement need not be provided by the designer of a
subsystem.
4. A declarative notation is natural because access privileges are closely
relatedtothelinguisticconceptofdatatype.
A variety of techniques can be provided by a programming-language
implementationtoenforceprotection,butanyofthesemustdependonsome
degreeof supportfrom anunderlying machine and itsoperating system.For
example,supposealanguageisusedtogeneratecodetorunontheCambridge
CAPsystem(SectionA.14.2).Onthissystem,everystoragereferencemadeon
theunderlyinghardwareoccursindirectlythroughacapability.Thisrestriction
preventsanyprocessfromaccessingaresourceoutsideofitsprotectionenvi-
ronment at any time. However, a program may impose arbitrary restrictions
onhowaresourcecanbeusedduringexecutionofaparticularcodesegment.
We can implementsuch restrictionsmost readilyby using the software capa-
bilitiesprovidedbyCAP.Alanguageimplementationmightprovidestandard
protected procedures to interpret software capabilities that would realize the
protection policies that could be specified in the language. This scheme puts692 Chapter17 Protection
policy specification at the disposal of the programmers, while freeing them
fromimplementingitsenforcement.
Even if a system does not provide a protection kernel as powerful as
those of Hydra (Section A.14.1) or CAP, mechanisms are still available for
implementingprotectionspecificationsgiveninaprogramminglanguage.The
principal distinction is that the security of this protection will not be as great
as that supported by a protection kernel, because the mechanism must rely
on more assumptions about the operational state of the system. A compiler
can separate references for which it can certify that no protection violation
couldoccurfromthoseforwhichaviolationmightbepossible,anditcantreat
themdifferently.Thesecurityprovidedbythisformofprotectionrestsonthe
assumptionthatthecodegeneratedbythecompilerwillnotbemodifiedprior
toorduringitsexecution.
What,then,aretherelativemeritsofenforcementbasedsolelyonakernel,
asopposedtoenforcementprovidedlargelybyacompiler?
• Security. Enforcement by a kernel provides a greater degree of security
of the protection system itself than does the generation of protection-
checking code by a compiler. In a compiler-supported scheme, security
rests on correctness of the translator, on some underlying mechanism of
storage management that protects the segments from which compiled
code is executed, and, ultimately, on the security of files from which a
programisloaded.Someoftheseconsiderationsalsoapplytoasoftware-
supported protection kernel, but to a lesser degree, since the kernel may
reside in fixed physical storage segments and may be loaded only from
a designated file. With a tagged-capability system, in which all address
computationisperformedeitherbyhardwareorbyafixedmicroprogram,
even greater security is possible. Hardware-supported protection is also
relativelyimmune to protectionviolations that might occur as a resultof
eitherhardwareorsystemsoftwaremalfunction.
• Flexibility.Therearelimitstotheflexibilityofaprotectionkernelinimple-
mentingauser-definedpolicy,althoughitmaysupplyadequatefacilities
for the system to provide enforcement of its own policies. With a pro-
gramming language, protection policy can be declared and enforcement
providedasneededbyanimplementation.Ifalanguagedoesnotprovide
sufficient flexibility, it can be extended or replaced with less disturbance
thanwouldbecausedbythemodificationofanoperating-systemkernel.
• Efficienc .Thegreatestefficiencyisobtainedwhenenforcementofprotec-
tionissupporteddirectlybyhardware(ormicrocode).Insofarassoftware
support is required, language-based enforcement has the advantage that
static access enforcement can be verified off-line at compile time. Also,
sinceanintelligentcompilercantailortheenforcementmechanismtomeet
thespecifiedneed,thefixedoverheadofkernelcallscanoftenbeavoided.
In summary, the specification of protection in a programming language
allows the high-level description of policies for the allocation and use of
resources. A language implementation can provide software for protection
enforcementwhenautomatichardware-supportedcheckingisunavailable.In17.12 Language-BasedProtection 693
addition,itcaninterpretprotectionspecificationstogeneratecallsonwhatever
protectionsystemisprovidedbythehardwareandtheoperatingsystem.
One way of making protection available to the application program is
throughtheuseofasoftwarecapabilitythatcouldbeusedasanobjectofcom-
putation.Inherentinthisconceptistheideathatcertainprogramcomponents
mighthavetheprivilegeofcreatingorexaminingthesesoftwarecapabilities.
Acapability-creatingprogramwouldbeabletoexecuteaprimitiveoperation
that would seal a data structure, rendering the latter’s contents inaccessible
to any program components that did not hold either the seal or the unseal
privilege.Suchcomponentsmightcopy thedatastructureorpassitsaddress
to other program components, but they could not gain access to its contents.
The reason for introducing such software capabilities is to bring a protection
mechanism intothe programming language. The only problem with the con-
cept as proposed is that the use of the seal and unseal operations takes a
proceduralapproachtospecifyingprotection.Anonproceduralordeclarative
notationseemsapreferablewaytomakeprotectionavailabletotheapplication
programmer.
Whatisneededisasafe,dynamicaccess-controlmechanismfordistribut-
ingcapabilitiestosystemresourcesamonguserprocesses.Tocontributetothe
overallreliabilityofasystem,theaccess-controlmechanismshouldbesafeto
use.Tobeusefulinpractice,itshouldalsobereasonablyefficient.Thisrequire-
menthasledtothedevelopmentofanumberoflanguageconstructsthatallow
the programmer to declare various restrictions on the use of a specific man-
agedresource.(Seethebibliographicalnotesforappropriatereferences.)These
constructsprovidemechanismsforthreefunctions:
1. Distributingcapabilitiessafelyandefficientlyamongcustomerprocesses.
Inparticular,mechanismsensurethatauserprocesswillusethemanaged
resourceonlyifitwasgrantedacapabilitytothatresource.
2. Specifyingthetypeofoperationsthataparticularprocessmayinvokeon
an allocated resource (for example, a reader of a file should be allowed
only to read the file, whereas a writer should be able both to read and
to write). It should not be necessary to grant the same set of rights to
everyuser process, and it should be impossible for a process to enlarge
itssetofaccessrights,exceptwiththeauthorizationoftheaccess-control
mechanism.
3. Specifyingtheorderinwhichaparticularprocessmayinvokethevarious
operationsofaresource(forexample,afilemustbeopenedbeforeitcan
beread).Itshouldbepossibletogivetwoprocessesdifferentrestrictions
on the order in which they can invoke the operations of the allocated
resource.
Theincorporationofprotectionconceptsintoprogramminglanguages,as
apracticaltoolforsystemdesign,isinitsinfancy.Protectionwilllikelybecome
a matter of greater concern to the designers of new systems with distributed
architectures and increasingly stringent requirements on data security. Then
the importance of suitable language notations in which to express protection
requirementswillberecognizedmorewidely.694 Chapter17 Protection
17.12.2 Run-Time-Based Enforcement—Protection in Java
BecauseJavawasdesignedtoruninadistributedenvironment,theJavavirtual
machine—orJVM—hasmanybuilt-inprotectionmechanisms.Javaprograms
arecomposedofclasses, eachofwhichisacollectionofdatafieldsandfunc-
tions (called methods) that operate on those fields. The JVM loads a class in
response to a request to create instances (or objects) of that class. One of the
most novel and useful features of Java is its support for dynamically load-
ing untrusted classes over a network and for executing mutually distrusting
classeswithinthesameJVM.
Because of these capabilities, protection is a paramount concern. Classes
runninginthesameJVMmaybefromdifferentsourcesandmaynotbeequally
trusted.Asaresult,enforcingprotectionatthegranularityoftheJVMprocess
is insufficient. Intuitively,whether a request to open a file should be allowed
will generally depend on which class has requested the open. The operating
systemlacksthisknowledge.
Thus,suchprotectiondecisionsarehandledwithintheJVM.WhentheJVM
loads a class, it assigns the class to a protection domain that gives the per-
missions of that class. The protection domain to which the class is assigned
dependsontheURLfromwhichtheclasswasloadedandanydigitalsignatures
on the class file. (Digital signatures are covered in Section 16.4.1.3.) Aconfig-
urable policy file determines the permissions granted to the domain (and its
classes).Forexample,classesloadedfromatrustedservermightbeplacedin
aprotectiondomainthatallowsthemtoaccessfilesintheuser’shomedirec-
tory,whereasclassesloadedfromanuntrustedservermighthavenofileaccess
permissionsatall.
It can be complicated for the JVM to determine what class is responsible
for a request to access a protected resource. Accesses are often performed
indirectly, through system libraries or other classes. For example, consider a
class that is not allowed to open network connections. It could call a system
library to request the load of the contents of a URL. The JVM must decide
whether or not to open a network connection for this request. But which
class should be used to determine if the connection should be allowed, the
applicationorthesystemlibrary?
ThephilosophyadoptedinJavaistorequirethelibraryclasstoexplicitly
permit a network connection. More generally, in order to access a protected
resource,somemethodinthecallingsequencethatresultedintherequestmust
explicitlyasserttheprivilegetoaccesstheresource.Bydoingso,thismethod
takesresponsibilityfortherequest.Presumably,itwillalsoperformwhatever
checks are necessary to ensure the safety of the request. Of course, not every
methodisallowedtoassertaprivilege;amethodcanassertaprivilegeonlyif
itsclassisinaprotectiondomainthatisitselfallowedtoexercisetheprivilege.
This implementation approach is called stack inspection. Every thread
in the JVM has an associated stack of its ongoing method invocations. When
a caller may not be trusted, a method executes an access request within a
doPrivilegedblocktoperformtheaccesstoaprotectedresourcedirectlyor
indirectly.doPrivileged()isastaticmethodintheAccessControllerclass
thatispassedaclasswitharun()methodtoinvoke.WhenthedoPrivileged
block is entered,the stack frame for this method is annotated to indicate this
fact.Then,thecontentsoftheblockareexecuted.Whenanaccesstoaprotected17.12 Language-BasedProtection 695
protection untrusted
URL loader networking
domain: applet
socket
none *.lucent.com:80, connect any
permission:
class: gui: get(URL u): open(Addr a):
… … …
get(url); doPrivileged { checkPermission
open(addr); open(‘proxy.lucent.com:80’); (a, connect);
…
} connect (a);
<request u from proxy> …
…
Figure17.14 Stackinspection.
resourceissubsequentlyrequested,eitherbythismethodoramethoditcalls,
acalltocheckPermissions()isusedtoinvokestackinspectiontodetermine
if the request should be allowed. The inspection examines stack frames on
the calling thread’s stack, starting from the most recently added frame and
workingtowardtheoldest.IfastackframeisfirstfoundthathasthedoPriv-
ileged() annotation, then checkPermissions() returns immediately and
silently,allowing the access. Ifa stack frame is first found for which access is
disallowedbasedontheprotectiondomainofthemethod’sclass,thencheck-
Permissions()throwsanAccessControlException.Ifthestackinspection
exhausts the stack without finding either type of frame, then whether access
isalloweddependsontheimplementation(someimplementationsoftheJVM
mayallowaccess,whileotherimplementationsmaynot).
Stack inspection is illustrated in Figure 17.14. Here, the gui() method of
a class in the untrusted applet protection domain performs two operations,
first a get() and then an open(). The former is an invocation of the get()
methodofaclassintheURLloader protectiondomain,whichispermittedto
open()sessionstositesinthelucent.comdomain,inparticularaproxyserver
proxy.lucent.comforretrievingURLs.Forthisreason,theuntrustedapplet’s
get()invocationwillsucceed:thecheckPermissions()callinthenetwork-
inglibraryencountersthestackframeoftheget()method,whichperformed
itsopen()inadoPrivilegedblock.However,theuntrustedapplet’sopen()
invocation will result in an exception, because the checkPermissions()call
findsnodoPrivilegedannotationbeforeencounteringthestackframeofthe
gui()method.
Of course, for stack inspection to work, a program must be unable to
modify the annotations on its own stack frame or to otherwise manipulate
stack inspection. This is one of the most important differences between Java
and many other languages (including C++). AJava program cannot directly
access memory; it can manipulate only an object for which it has a reference.
Referencescannotbeforged,andmanipulationsaremadeonlythroughwell-
defined interfaces. Compliance is enforced through a sophisticated collection
ofload-timeandrun-timechecks.Asaresult,anobjectcannotmanipulateits
run-time stack, because it cannot get a reference to the stack or other compo-
nentsoftheprotectionsystem.696 Chapter17 Protection
Moregenerally,Java’sload-timeandrun-timechecksenforcetypesafetyof
Javaclasses.Typesafetyensuresthatclassescannottreatintegersaspointers,
writepasttheendofanarray,orotherwiseaccessmemoryinarbitraryways.
Rather, a program can access an object only via the methods defined on that
object by its class. This is the foundation of Java protection, since it enables a
class to effectively encapsulate and protect its data and methods from other
classes loaded in the same JVM. For example, a variable can be defined as
private so that only the class that contains it can access it or protected so
thatitcanbeaccessedonlybytheclassthatcontainsit,subclassesofthatclass,
orclassesinthesamepackage.Typesafetyensuresthattheserestrictionscan
beenforced.
17.13 Summary
• System protection features are guided by the principle of need-to-know
andimplementmechanismstoenforcetheprincipleofleastprivilege.
• Computer systems contain objects that must be protected from misuse.
Objects may be hardware (such as memory, CPU time, and I/O devices)
orsoftware(suchasfiles,programs,andsemaphores).
• An access right is permission to perform an operation on an object. A
domainisasetofaccessrights.Processesexecuteindomainsandmayuse
any of the access rights in the domain to access and manipulate objects.
Duringitslifetime,aprocessmaybeeitherboundtoaprotectiondomain
orallowedtoswitchfromonedomaintoanother.
• Acommonmethodofsecuringobjectsistoprovideaseriesofprotection
rings,eachwithmoreprivilegesthanthelast.ARM,forexample,provides
four protection levels. The most privileged, TrustZone, is callable only
fromkernelmode.
• The access matrix is a general model of protection that provides a mech-
anism for protection without imposing a particular protection policy on
the system or its users. The separation of policy and mechanism is an
importantdesignproperty.
• The access matrix is sparse. It is normally implemented either as access
listsassociatedwitheachobjectorascapabilitylistsassociatedwitheach
domain. We can include dynamic protection in the access-matrix model
by considering domains and the access matrix itself as objects. Revoca-
tion of access rights in a dynamic protection model is typically easier to
implementwithanaccess-listschemethanwithacapabilitylist.
• Realsystemsaremuchmorelimitedthan thegeneralmodel.OlderUNIX
distributionsarerepresentative,providingdiscretionaryaccesscontrolsof
read,write,andexecutionprotectionseparatelyfortheowner,group,and
generalpublicforeachfile.Moremodernsystemsareclosertothegeneral
model, or at least provide a variety of protection features to protect the
systemanditsusers.
• Solaris 10 and beyond, among other systems, implement the principle
of least privilege via role-based access control, a form of access matrix.Bibliography 697
Anotherprotectionextensionismandatoryaccesscontrol,aformofsystem
policyenforcement.
• Capability-basedsystemsofferfiner-grainedprotectionthanoldermodels,
providingspecificabilitiestoprocessesby“slicingup”thepowersofroot
intodistinctareas.OthermethodsofimprovingprotectionincludeSystem
IntegrityProtection,system-callfiltering,sandboxing,andcodesigning.
• Language-basedprotectionprovidesfiner-grainedarbitrationofrequests
andprivilegesthantheoperatingsystemisabletoprovide.Forexample,a
singleJavaJVMcanrunseveralthreads,eachinadifferentprotectionclass.
It enforces the resource requests through sophisticated stack inspection
andviathetypesafetyofthelanguage.
Further Reading
TheconceptofacapabilityevolvedfromIliffe’sandJodeit’scodewords,which
wereimplementedintheRiceUniversitycomputer([IliffeandJodeit(1962)]).
Thetermcapabilitywasintroducedby[DennisandHorn(1966)].
Theprincipleofseparationofpolicyandmechanismwasadvocatedbythe
designerofHydra([Levinetal.(1975)]).
The use of minimal operating-system support to enforce protection was
advocated by the Exokernel Project ([Ganger et al. (2002)], [Kaashoek et al.
(1997)]).
The access-matrix model of protection between domains and objects was
developed by [Lampson (1969)] and [Lampson (1971)]. [Popek (1974)] and
[Saltzer and Schroeder (1975)] provided excellent surveys on the subject of
protection.
ThePosixcapabilitystandardandthewayitwasimplementedinLinuxis
described in https://www.usenix.org/legacy/event/usenix03/tech/freenix03/
full papers/gruenbacher/gruenbacher html/main.html
Details on POSIX.1e and its Linux implementation are provided in
https://www.usenix.org/legacy/event/usenix03/tech/freenix03/fullpapers/gr
uenbacher/gruenbacher html/main.html.
Bibliography
[DennisandHorn(1966)] J.B.DennisandE.C.V.Horn,“ProgrammingSeman-
ticsforMultiprogrammedComputations”,CommunicationsoftheACM,Volume
9,Number3(1966),pages143–155.
[Gangeretal.(2002)] G.R.Ganger,D.R.Engler,M.F.Kaashoek,H.M.Briceno,
R.Hunt,andT.Pinckney,“FastandFlexibleApplication-LevelNetworkingon
ExokernelSystems”,ACMTransactionsonComputerSystems,Volume20,Number
1(2002),pages49–83.
[IliffeandJodeit(1962)] J.K.IliffeandJ.G.Jodeit,“ADynamicStorageAlloca-
tionSystem”,ComputerJournal,Volume5,Number3(1962),pages200–209.698 Chapter17 Protection
[Kaashoeketal.(1997)] M. F. Kaashoek, D. R. Engler, G. R. Ganger, H. M.
Briceno,R.Hunt,D.Mazieres,T.Pinckney,R.Grimm,J.Jannotti,andK.Macken-
zie, “Application Performanceand Flexibility on ExokernelSystems”, Proceed-
ingsoftheACMSymposiumonOperatingSystemsPrinciples(1997),pages52–65.
[Lampson(1969)] B.W.Lampson,“DynamicProtectionStructures”,Proceedings
oftheAFIPSFallJointComputerConference(1969),pages27–38.
[Lampson(1971)] B. W. Lampson, “Protection”, Proceedings of the Fifth Annual
PrincetonConferenceonInformationSystemsScience(1971),pages437–443.
[Levinetal.(1975)] R. Levin, E. S. Cohen, W. M. Corwin, F. J. Pollack, and
W.A.Wulf, “Policy/MechanismSeparationinHydra”,ProceedingsoftheACM
SymposiumonOperatingSystemsPrinciples(1975),pages132–140.
[Popek(1974)] G.J.Popek,“ProtectionStructures”,Computer,Volume7,Num-
ber6(1974),pages22–33.
[SaltzerandSchroeder(1975)] J. H. Saltzer and M. D. Schroeder, “The Protec-
tionofInformationinComputerSystems”,ProceedingsoftheIEEE(1975),pages
1278–1308.Exercises EX-54
Chapter 17 Exercises
17.11 Theaccess-controlmatrixcanbeusedtodeterminewhetheraprocess
can switch from, say, domain A to domain B and enjoy the access
privileges of domain B. Is this approach equivalent to including the
accessprivilegesofdomainBinthoseofdomainA?
17.12 Consideracomputersysteminwhichcomputergamescanbeplayed
by students only between 10 P.M. and 6 A.M., by faculty members
between5P.M.and8A.M.,andbythecomputercenterstaffatalltimes.
Suggestaschemeforimplementingthispolicyefficiently.
17.13 What hardware features does a computer system need for efficient
capability manipulation?Canthesefeaturesbeusedfor memorypro-
tection?
17.14 Discuss the strengths and weaknesses of implementing an access
matrixusingaccessliststhatareassociatedwithobjects.
17.15 Discuss the strengths and weaknesses of implementing an access
matrixusingcapabilitiesthatareassociatedwithdomains.
17.16 Explainwhyacapability-basedsystemprovidesgreaterflexibilitythan
aring-protectionschemeinenforcingprotectionpolicies.
17.17 Whatistheneed-to-knowprinciple?Whyisitimportantforaprotec-
tionsystemtoadheretothisprinciple?
17.18 Discuss which of the following systems allow module designers to
enforcetheneed-to-knowprinciple.
a. Ring-protectionscheme
b. JVM’sstack-inspectionscheme
17.19 Describe how the Java protection model would be compromised if a
Javaprogramwereallowedtodirectlyaltertheannotationsofitsstack
frame.
17.20 How are the access-matrix facility and the role-based access-control
facilitysimilar?Howdotheydiffer?
17.21 Howdoestheprincipleofleastprivilegeaidinthecreationofprotec-
tionsystems?
17.22 How can systems that implement the principle of least privilege still
haveprotectionfailuresthatleadtosecurityviolations?Part Eight
Advanced Topics
Virtualization permeates all aspects of computing. Virtual machines are
oneinstanceofthistrend.Generally,withavirtualmachine,guestoperat-
ingsystemsandapplicationsruninanenvironmentthatappearstothem
tobenativehardware.Thisenvironmentbehavestowardthemasnative
hardwarewouldbutalsoprotects,manages,andlimitsthem.
A distributed system is a collection of processors that do not share
memory or a clock. Instead, each processor has its own local memory,
andtheprocessorscommunicatewithoneanotherthroughalocal-area
or wide-area computer network. Computer networks allow disparate
computing devices to communicate by adopting standard communica-
tionprotocols.Distributedsystemsofferseveralbenefits:theygiveusers
accesstomoreoftheresourcesmaintainedbythesystem,boostcom-
putationspeed,andimprovedataavailabilityandreliability.18
CHAPTER
Virtual Machines
The term virtualization has many meanings, and aspects of virtualization
permeate all aspects of computing. Virtual machines are one instance of this
trend.Generally,withavirtualmachine,guestoperatingsystemsandapplica-
tions run in an environment that appears to them to be native hardware and
that behaves toward them as native hardware would but that also protects,
manages,andlimitsthem.
Thischapterdelvesintotheuses,features,andimplementationofvirtual
machines. Virtual machines can be implemented in several ways, and this
chapterdescribestheseoptions.Oneoptionistoaddvirtualmachinesupport
tothekernel.Becausethatimplementationmethodisthemostpertinenttothis
book,weexploreitmostfully.Additionally,hardwarefeaturesprovidedbythe
CPUandevenbyI/Odevicescansupportvirtualmachineimplementation,so
wediscusshowthosefeaturesareusedbytheappropriatekernelmodules.
CHAPTER OBJECTIVES
• Explorethehistoryandbenefitsofvirtualmachines.
• Discussthevariousvirtualmachinetechnologies.
• Describethemethodsusedtoimplementvirtualization.
• Identifythemostcommonhardwarefeaturesthatsupportvirtualizationand
explainhowtheyareusedbyoperating-systemmodules.
• Discusscurrentvirtualizationresearchareas.
18.1 Overview
The fundamental idea behind a virtual machine is to abstract the hardware
of a single computer (the CPU, memory, disk drives, network interface cards,
and so forth) into several different execution environments, thereby creating
the illusion that each separate environment is running on its own private
computer.Thisconceptmayseemsimilartothelayeredapproachofoperating
systemimplementation(seeSection2.8.2),andinsomewaysitis.Inthecaseof
701702 Chapter18 VirtualMachines
virtualization,thereisalayerthatcreatesavirtualsystemonwhichoperating
systemsorapplicationscanrun.
Virtualmachineimplementationsinvolveseveralcomponents.Atthebase
is the host, the underlying hardware system that runs the virtual machines.
The virtual machine manager (VMM) (also known as a hypervisor) creates
andrunsvirtualmachinesbyprovidinganinterfacethatisidenticaltothehost
(exceptinthecaseofparavirtualization,discussedlater).Eachguestprocessis
providedwithavirtualcopyofthehost(Figure18.1).Usually,theguestprocess
isinfactanoperatingsystem.Asinglephysicalmachinecanthusrunmultiple
operatingsystemsconcurrently,eachinitsownvirtualmachine.
Take a moment to note that with virtualization, the definition of “operat-
ing system” once again blurs. For example, consider VMM software such as
VMware ESX. This virtualization software is installed on the hardware, runs
whenthehardwareboots,andprovidesservicestoapplications.Theservices
includetraditionalones,suchasschedulingandmemorymanagement,along
with new types, such as migration of applications between systems. Further-
more,theapplicationsare,infact,guestoperatingsystems.IstheVMwareESX
VMManoperatingsystemthat,inturn,runsotheroperatingsystems?Certainly
itactslikeanoperatingsystem.Forclarity,however,wecallthecomponentthat
providesvirtualenvironmentsaVMM.
TheimplementationofVMMsvariesgreatly.Optionsincludethefollowing:
• Hardware-based solutions that provide support for virtual machine cre-
ation and management via firmware. These VMMs, which are commonly
foundinmainframeandlargetomidsizedservers,aregenerallyknownas
type0hypervisors.IBMLPARsandOracleLDOMsareexamples.
processes
processes
processes processes
programming
kernel kernel kernel
interface
VM1 VM2 VM3
kernel
virtual machine
manager
hardware
hardware
(a) (b)
Figure18.1 Systemmodels.(a)Nonvirtualmachine.(b)Virtualmachine.18.2 History 703
INDIRECTION
“Allproblemsincomputersciencecanbesolvedbyanotherlevelofindirec-
tion”—DavidWheeler
“. . . except for the problem of too many layers of indirection.”—Kevlin
Henney
• Operating-system-like software built to provide virtualization, including
VMware ESX (mentioned above), Joyent SmartOS, and Citrix XenServer.
TheseVMMsareknownastype1hypervisors.
• General-purpose operating systems that provide standard functions as
wellasVMMfunctions,includingMicrosoftWindowsServerwithHyperV
and Red Hat Linux with the KVM feature. Because such systems have a
featuresetsimilartotype1hypervisors,theyarealsoknownastype1.
• Applications that run on standard operating systems but provide VMM
features to guest operating systems. These applications, which include
VMware Workstation and Fusion, Parallels Desktop, and Oracle Virtual-
Box,aretype2hypervisors.
• Paravirtualization, a technique in which the guest operating system is
modifiedtoworkincooperationwiththeVMMtooptimizeperformance.
• Programming-environmentvirtualization, in which VMMs do not virtu-
alize real hardware but instead create an optimized virtual system. This
techniqueisusedbyOracleJavaandMicrosoft.Net.
• Emulatorsthatallowapplicationswrittenforonehardwareenvironment
torunonaverydifferenthardwareenvironment,suchasadifferenttype
ofCPU.
• Application containment, which is not virtualization at all but rather
providesvirtualization-likefeaturesbysegregatingapplicationsfromthe
operating system. Oracle Solaris Zones, BSD Jails, and IBM AIX WPARs
“contain”applications,makingthemmoresecureandmanageable.
The variety of virtualization techniques in use today is a testament to
the breadth, depth, and importance of virtualization in modern computing.
Virtualization is invaluable for data-center operations, efficient application
development,andsoftwaretesting,amongmanyotheruses.
18.2 History
Virtual machines first appeared commercially on IBM mainframes in 1972.
VirtualizationwasprovidedbytheIBMVMoperatingsystem.Thissystemhas
evolved and is still available. In addition, many of its original concepts are
foundinothersystems,makingitworthexploring.704 Chapter18 VirtualMachines
IBM VM/370 divided a mainframe into multiple virtual machines, each
running its own operating system. A major difficulty with the VM approach
involved disk systems. Suppose that the physical machine had three disk
drives but wanted to support seven virtual machines. Clearly, it could not
allocate a disk drive to each virtual machine. The solution was to provide
virtualdisks—termedminidisksinIBM’sVMoperatingsystem.Theminidisks
wereidenticaltothesystem’sharddisksinallrespectsexceptsize.Thesystem
implementedeachminidiskbyallocatingasmanytracksonthephysicaldisks
astheminidiskneeded.
Once the virtualmachines were created,users could runany of the oper-
ating systems or software packages that were available on the underlying
machine. For the IBM VM system, a user normally ran CMS—a single-user
interactiveoperatingsystem.
For many years after IBM introduced this technology, virtualization
remained in its domain. Most systems could not support virtualization.
However, a formal definition of virtualization helped to establish system
requirements and a target for functionality. The virtualization requirements
calledfor:
• Fidelity.AVMMprovidesanenvironmentforprogramsthatisessentially
identicaltotheoriginalmachine.
• Performance. Programs running within that environment show only
minorperformancedecreases.
• Safety.TheVMMisincompletecontrolofsystemresources.
Theserequirementsstillguidevirtualizationeffortstoday.
By the late 1990s, Intel 80x86 CPUs had become common, fast, and rich
in features. Accordingly, developers launched multiple efforts to implement
virtualization on that platform. Both Xen and VMware created technologies,
still used today, to allow guest operating systems to run on the 80x86. Since
that time, virtualization has expanded to include all common CPUs, many
commercial and open-source tools, and many operating systems. For exam-
ple, the open-source VirtualBox project (http://www.virtualbox.org) provides
a program that runs on Intel x86 and AMD 64 CPUs and on Windows, Linux,
macOS, and Solaris host operating systems. Possible guest operating systems
include many versions of Windows, Linux, Solaris, and BSD, including even
MS-DOSandIBMOS/2.
18.3 Benefits and Features
Severaladvantagesmakevirtualizationattractive.Mostofthemarefundamen-
tallyrelatedtotheabilitytosharethesamehardwareyetrunseveraldifferent
executionenvironments(thatis,differentoperatingsystems)concurrently.
One important advantage of virtualization is that the host system is pro-
tected from the virtual machines, just as the virtual machines are protected
from each other. Avirus inside a guest operating system might damage that
operatingsystembutisunlikelytoaffectthehostortheotherguests.Because18.3 Benefit andFeatures 705
each virtual machine is almost completely isolated from all other virtual
machines,therearealmostnoprotectionproblems.
A potential disadvantage of isolation is that it can prevent sharing of
resources.Twoapproachestoprovidingsharinghavebeenimplemented.First,
it is possible to share a file-system volume and thus to share files. Second, it
is possible to define a network of virtual machines, each of which can send
information over the virtual communications network. The network is mod-
eledafter physical communication networks but is implementedin software.
Of course, the VMM is free to allow any number of its guests to use physical
resources,suchasaphysicalnetworkconnection(withsharingprovidedbythe
VMM), in which case the allowed guests could communicate with each other
viathephysicalnetwork.
Onefeaturecommontomostvirtualizationimplementationsistheability
to freeze, or suspend, a running virtual machine. Many operating systems
provide that basic feature for processes, but VMMs go one step further and
allow copies and snapshots to be made of the guest. The copy can be used
to create a new VM or to move a VM from one machine to another with its
currentstateintact.Theguestcanthenresumewhereitwas,asifonitsoriginal
machine,creatingaclone.Thesnapshotrecordsapointintime,andtheguest
canberesettothatpointifnecessary(forexample,ifachange wasmadebut
is no longer wanted). Often, VMMs allow many snapshots to be taken. For
example,snapshotsmightrecordaguest’sstateeverydayforamonth,making
restorationtoanyofthosesnapshotstatespossible.Theseabilitiesareusedto
goodadvantageinvirtualenvironments.
Avirtualmachinesystemisaperfectvehicleforoperating-systemresearch
anddevelopment.Normally,changing anoperatingsystemisadifficulttask.
Operating systems are large and complex programs, and a change in one
part may cause obscure bugs to appear in some other part. The power of
the operating system makes changing it particularly dangerous. Because the
operatingsystemexecutesinkernelmode,awrongchangeinapointercould
cause an error that would destroy the entire file system. Thus, it is necessary
totestallchangestotheoperatingsystemcarefully.
Of course, the operating system runs on and controls the entire machine,
so the system must be stopped and taken out of use while changes are made
and tested.This period is commonly called system-development time. Since
itmakesthesystemunavailabletousers,system-developmenttimeonshared
systemsisoftenscheduledlateatnightoronweekends,whensystemloadis
low.
Avirtual-machine system can eliminatemuch of this latterproblem. Sys-
tem programmers are given their own virtual machine, and system develop-
mentisdoneonthevirtualmachineinsteadofonaphysicalmachine.Normal
system operation is disrupted only when a completed and tested change is
readytobeputintoproduction.
Another advantage of virtual machines for developers is that multiple
operatingsystemscanrunconcurrently onthedeveloper’sworkstation.This
virtualized workstation allows for rapid porting and testing of programs in
varying environments. In addition, multiple versions of a program can run,
eachinitsownisolatedoperatingsystem,withinonesystem.Similarly,quality-
assuranceengineerscantesttheirapplicationsinmultipleenvironmentswith-
outbuying,powering,andmaintainingacomputerforeachenvironment.706 Chapter18 VirtualMachines
A major advantage of virtual machines in production data-center use is
system consolidation, which involves taking two or more separate systems
andrunningtheminvirtualmachinesononesystem.Suchphysical-to-virtual
conversions result in resource optimization, since many lightly used systems
canbecombinedtocreateonemoreheavilyusedsystem.
Consider,too,thatmanagementtoolsthatarepartoftheVMMallowsystem
administrators to manage many more systems than they otherwise could.
A virtual environment might include 100 physical servers, each running 20
virtual servers. Without virtualization, 2,000 servers would require several
systemadministrators.Withvirtualizationanditstools,thesameworkcanbe
managedbyoneortwoadministrators.Oneofthetoolsthatmakethispossible
is templating, in which one standard virtual machine image, including an
installedandconfiguredguestoperatingsystemandapplications,issavedand
used as a source for multiple running VMs. Other features include managing
thepatchingofallguests,backingupandrestoringtheguests,andmonitoring
theirresourceuse.
Virtualizationcanimprovenotonlyresourceutilizationbutalsoresource
management.SomeVMMsincludealivemigrationfeaturethatmovesarun-
ningguestfromonephysicalservertoanotherwithoutinterruptingitsopera-
tionoractivenetworkconnections.Ifaserverisoverloaded,livemigrationcan
thusfreeresourcesonthesourcehostwhilenotdisruptingtheguest.Similarly,
when host hardware must be repaired or upgraded, guests can be migrated
to other servers, the evacuated host can be maintained, and then the guests
can be migrated back. This operation occurs without downtime and without
interruptiontousers.
Think about the possible effects of virtualizationon how applications are
deployed. If a system can easily add, remove, and move a virtual machine,
thenwhyinstallapplicationsonthatsystemdirectly?Instead,theapplication
could be preinstalled on a tuned and customized operating system in a vir-
tualmachine.Thismethodwouldofferseveralbenefitsforapplicationdevel-
opers. Application management would become easier, less tuning would be
required,andtechnicalsupportoftheapplicationwouldbemorestraightfor-
ward.Systemadministratorswouldfindtheenvironmenteasiertomanageas
well.Installationwouldbesimple,andredeployingtheapplicationtoanother
system would be much easier than the usual steps of uninstalling and rein-
stalling. For widespread adoption of this methodology to occur, though, the
formatofvirtualmachines must bestandardizedsothat any virtualmachine
willrunonanyvirtualizationplatform.The“OpenVirtualMachineFormat”is
an attempt to providesuch standardization, and it could succeed in unifying
virtualmachineformats.
Virtualization has laid the foundation for many other advances in com-
puterfacilityimplementation,management,andmonitoring.Cloudcomput-
ing, for example, is made possible by virtualization in which resources such
asCPU,memory,andI/OareprovidedasservicestocustomersusingInternet
technologies. By using APIs, a program can tell a cloud computing facility to
create thousands of VMs, all running a specific guest operating system and
application, that others can access via the Internet. Many multiuser games,
photo-sharingsites,andotherwebservicesusethisfunctionality.
In the area of desktop computing, virtualization is enabling desktop and
laptop computer users to connect remotely to virtual machines located in18.4 BuildingBlocks 707
remote data centers and access their applications as if they were local. This
practicecan increasesecurity,becausenodataarestoredonlocaldisksatthe
user’s site. The cost of the user’s computing resource may also decrease.The
usermusthavenetworking,CPU,andsomememory,butallthatthesesystem
componentsneedtodoisdisplayanimageoftheguestasitsrunsremotely(via
aprotocolsuchasRDP).Thus,theyneednotbeexpensive,high-performance
components.Otherusesofvirtualizationaresuretofollowasitbecomesmore
prevalentandhardwaresupportcontinuestoimprove.
18.4 Building Blocks
Although the virtual machine concept is useful, it is difficult to implement.
Much work is required to provide an exact duplicate of the underlying
machine. This is especially a challenge on dual-mode systems, where the
underlyingmachinehasonlyusermodeandkernelmode.Inthissection,we
examine the building blocks that are needed for efficient virtualization. Note
thatthesebuildingblocksarenotrequiredbytype0hypervisors,asdiscussed
inSection18.5.2.
The ability to virtualize depends on the features provided by the CPU. If
the features are sufficient, then it is possible to write a VMM that provides
a guest environment. Otherwise, virtualization is impossible. VMMs use sev-
eral techniques to implement virtualization, including trap-and-emulate and
binary translation. We discuss each of these techniques in this section, along
withthehardwaresupportneededtosupportvirtualization.
As you read the section, keep in mind that an important concept found
inmostvirtualizationoptionsisthe implementationofa virtualCPU(VCPU).
The VCPU does not execute code. Rather, it represents the state of the CPU as
theguestmachinebelievesittobe.Foreachguest,theVMMmaintainsaVCPU
representingthatguest’scurrentCPUstate.Whentheguestiscontext-switched
onto a CPU by the VMM, information from the VCPU is used to load the right
context,muchasageneral-purposeoperatingsystemwouldusethePCB.
18.4.1 Trap-and-Emulate
Onatypicaldual-modesystem,thevirtualmachineguestcanexecuteonlyin
usermode(unlessextrahardwaresupportisprovided).Thekernel,ofcourse,
runs in kernel mode, and it is not safe to allow user-level code to run in
kernelmode.Justasthephysicalmachinehastwomodes,somustthevirtual
machine.Consequently,wemusthaveavirtualusermodeandavirtualkernel
mode, both of which run in physical user mode. Those actions that cause a
transfer from user mode to kernel mode on a real machine (such as a system
call,aninterrupt,oranattempttoexecuteaprivilegedinstruction)mustalso
cause a transfer from virtual user mode to virtual kernel mode in the virtual
machine.
How can such a transfer be accomplished? The procedure is as follows:
When the kernel in the guest attempts to execute a privileged instruction,
that is an error (because the system is in user mode) and causes a trap to the
VMMintherealmachine.TheVMMgainscontrolandexecutes(or“emulates”)
the action that was attempted by the guest kernel on the part of the guest. It708 Chapter18 VirtualMachines
privileged instruction
guest user mode
operating
system
VMM kernel mode
emulate action VCPU
VMM
trap return
user processes
update
Figure18.2 Trap-and-emulatevirtualizationimplementation.
thenreturnscontroltothevirtualmachine.Thisiscalledthetrap-and-emulate
methodandisshowninFigure18.2.
With privileged instructions, time becomes an issue. All nonprivileged
instructions run natively on the hardware, providing the same performance
forguestsasnativeapplications.Privilegedinstructionscreateextraoverhead,
however, causing the guest to run more slowly than it would natively. In
addition, the CPU is being multiprogrammed among many virtual machines,
whichcanfurtherslowdownthevirtualmachinesinunpredictableways.
This problem has been approached in various ways. IBM VM, for exam-
ple, allows normal instructions for the virtual machines to execute directly
on the hardware. Only the privileged instructions (needed mainly for I/O)
mustbeemulatedandhenceexecutemoreslowly.Ingeneral,withtheevolu-
tionofhardware,theperformanceoftrap-and-emulatefunctionalityhasbeen
improved, and cases in which it is needed have been reduced. For example,
manyCPUsnowhaveextramodesaddedtotheirstandarddual-modeopera-
tion.TheVCPUneednotkeeptrackofwhatmodetheguestoperatingsystemis
in,becausethephysicalCPUperformsthatfunction.Infact,someCPUsprovide
guest CPU state management in hardware, so the VMM need not supply that
functionality,removingtheextraoverhead.
18.4.2 Binary Translation
Some CPUs do not have a clean separation of privileged and nonprivileged
instructions.Unfortunatelyforvirtualizationimplementers,theIntelx86CPU
line is one of them. No thought was given to running virtualization on the
x86 when it was designed. (In fact, the first CPU in the family—the Intel
4004,releasedin1971—was designedtobethecoreofacalculator.)Thechip
has maintained backward compatibility throughout its lifetime, preventing
changes that would have made virtualization easier through many genera-
tions.18.4 BuildingBlocks 709
Let’s consider an example of the problem. The command popf loads the
flagregisterfromthecontentsofthestack.IftheCPUisinprivilegedmode,all
of the flags are replacedfrom the stack. If the CPU is in user mode, then only
someflagsarereplaced,andothersareignored.Becausenotrapisgenerated
ifpopfisexecutedinusermode,thetrap-and-emulateprocedureisrendered
useless.Otherx86instructionscausesimilarproblems.Forthepurposesofthis
discussion,wewillcallthissetofinstructionsspecialinstructions.Asrecently
as1998,usingthetrap-and-emulatemethodtoimplementvirtualizationonthe
x86wasconsideredimpossiblebecauseofthesespecialinstructions.
Thispreviouslyinsurmountableproblemwassolvedwiththeimplemen-
tationofthebinarytranslationtechnique.Binarytranslationisfairlysimplein
conceptbutcomplexinimplementation.Thebasicstepsareasfollows:
1. If the guest VCPU is in user mode, the guest can run its instructions
nativelyonaphysicalCPU.
2. IftheguestVCPUisinkernelmode,thentheguestbelievesthatitisrun-
ninginkernelmode.TheVMMexamineseveryinstructiontheguestexe-
cutesinvirtualkernelmodebyreadingthenextfewinstructionsthatthe
guestisgoingtoexecute,basedontheguest’sprogramcounter.Instruc-
tionsotherthanspecialinstructionsarerunnatively.Specialinstructions
are translated into a new set of instructions that perform the equivalent
task—forexample,changingtheflagsintheVCPU.
BinarytranslationisshowninFigure18.3.Itisimplementedbytranslation
code within the VMM. The code readsnative binary instructions dynamically
fromtheguest,ondemand,andgeneratesnativebinarycodethatexecutesin
placeoftheoriginalcode.
user processes
(VMM reads instructions)
special instruction
guest user mode
operating
system
VMM kernel mode
translate
VCPU
execute translation
VMM
return
update
Figure18.3 Binarytranslationvirtualizationimplementation.710 Chapter18 VirtualMachines
The basic method of binary translation just described would execute
correctly but perform poorly. Fortunately, the vast majority of instructions
wouldexecutenatively.Buthowcouldperformancebeimprovedfortheother
instructions? We can turn to a specific implementation of binary translation,
theVMwaremethod,toseeonewayofimprovingperformance.Here,caching
provides the solution. The replacement code for each instruction that needs
tobetranslatediscached.Alllaterexecutionsofthatinstructionrunfromthe
translationcacheandneednotbetranslatedagain.Ifthecacheislargeenough,
thismethodcangreatlyimproveperformance.
Let’s consider another issue in virtualization: memory management,
specifically the page tables. How can the VMM keep page-table state both for
gueststhatbelievetheyaremanagingthepagetablesandfortheVMMitself?
Acommonmethod,usedwithbothtrap-and-emulateandbinary translation,
is to use nested page tables (NPTs). Each guest operating system maintains
one or more page tables to translate from virtual to physical memory. The
VMMmaintainsNPTstorepresenttheguest’spage-tablestate,justasitcreates
a VCPU to represent the guest’s CPU state. The VMM knows when the guest
tries to change its page table, and it makes the equivalent change in the NPT.
When the guest is on the CPU, the VMM puts the pointer to the appropriate
NPTintotheappropriateCPUregistertomakethattabletheactivepagetable.
If the guest needs to modify the page table (for example, fulfilling a page
fault), then that operation must be intercepted by the VMM and appropriate
changesmadetothenestedandsystempagetables.Unfortunately,theuseof
NPTs can cause TLB misses to increase, and many other complexities need to
beaddressedtoachievereasonableperformance.
Although it might seem that the binary translation method creates large
amounts of overhead, it performed well enough to launch a new industry
aimedatvirtualizingIntelx86-basedsystems.VMwaretestedtheperformance
impact of binary translation by booting one such system, Windows XP, and
immediately shutting it down while monitoring the elapsed time and the
numberoftranslationsproducedbythebinarytranslationmethod.Theresult
was 950,000 translations, taking 3 microseconds each, for a total increase of
3seconds (about 5percent)overnativeexecutionof Windows XP. Toachieve
thatresult,developersusedmanyperformanceimprovementsthatwedonot
discusshere.Formoreinformation,consultthebibliographicalnotesattheend
ofthischapter.
18.4.3 Hardware Assistance
Withoutsomelevelofhardwaresupport,virtualizationwouldbeimpossible.
The more hardware support available within a system, the more feature-rich
andstablethevirtualmachinescanbeandthebettertheycanperform.Inthe
Intelx86CPUfamily,Inteladdednewvirtualizationsupport(theVT-xinstruc-
tions)insuccessivegenerationsbeginning in2005. Now,binary translationis
nolongerneeded.
In fact, all major general-purpose CPUs now provide extended hardware
supportforvirtualization.Forexample,AMDvirtualizationtechnology(AMD-
V)hasappearedinseveralAMDprocessorsstartingin2006.Itdefinestwonew
modes of operation—host and guest—thus moving from a dual-mode to a18.4 BuildingBlocks 711
multimodeprocessor.TheVMMcanenablehostmode,definethecharacteris-
ticsofeachguestvirtualmachine,andthenswitchthesystemtoguestmode,
passing control of the system to a guest operating system that is running in
thevirtualmachine.Inguestmode,thevirtualizedoperatingsystemthinksit
isrunning onnativehardwareandseeswhateverdevicesareincludedinthe
host’sdefinitionoftheguest.Iftheguesttriestoaccessavirtualizedresource,
thencontrolispassedtotheVMMtomanagethatinteraction.Thefunctionality
inIntelVT-xissimilar,providingrootand nonroot modes,equivalenttohost
and guest modes. Both provide guest VCPU state data structures to load and
saveguestCPUstateautomaticallyduringguestcontextswitches.Inaddition,
virtual machine control structures (VMCSs) are provided to manage guest
and host state, as well as various guest execution controls, exit controls, and
informationaboutwhyguestsexitbacktothehost.Inthelattercase,forexam-
ple, a nested page-table violation caused by an attempt to access unavailable
memorycanresultintheguest’sexit.
AMD and Intel have also addressed memory management in the virtual
environment.WithAMD’sRVIandIntel’sEPTmemory-managementenhance-
ments, VMMs no longer need to implement software NPTs. In essence, these
CPUs implement nested page tables in hardware to allow the VMM to fully
controlpagingwhiletheCPUsacceleratethetranslationfromvirtualtophys-
ical addresses. The NPTs add a new layer, one representing the guest’s view
of logical-to-physical address translation. The CPU page-table walking func-
tion (traversing the data structure to find the desireddata) includes this new
layerasnecessary,walkingthroughtheguesttabletotheVMMtabletofindthe
physicaladdressdesired.ATLBmissresultsinaperformancepenalty,because
more tables (the guest and host page tables) must be traversed to complete
the lookup. Figure 18.4 shows the extra translation work performed by the
hardwaretotranslatefromaguestvirtualaddresstoafinalphysicaladdress.
I/O is another area improved by hardware assistance. Consider that the
standard direct-memory-access (DMA) controller accepts a target memory
address and a source I/O device and transfers data between the two without
operating-system action. Without hardware assistance, a guest might try to
set up a DMAtransfer that affects the memory of the VMM or other guests. In
CPUsthatprovidehardware-assistedDMA(suchasIntelCPUswithVT-d),even
DMAhas a level of indirection. First, the VMM sets up protection domains to
telltheCPUwhichphysicalmemorybelongstoeachguest.Next,itassignsthe
I/O devices to the protection domains, allowing them direct access to those
memory regions and only those regions. The hardware then transforms the
addressinaDMArequestissuedbyanI/Odevicetothehostphysicalmemory
address associated with the I/O. In this manner, DMA transfers are passed
throughbetweenaguestandadevicewithoutVMMinterference.
Similarly,interruptsmustbedeliveredtotheappropriateguestandmust
not be visible to other guests. By providing an interrupt remapping feature,
CPUs with virtualization hardware assistance automatically deliver an inter-
rupt destined for a guest to a core that is currently running a thread of that
guest. That way, the guest receives interrupts without any need for the VMM
to intercede in their delivery. Without interrupt remapping, malicious guests
couldgenerateinterruptsthatcouldbeusedtogaincontrolofthehostsystem.
(Seethebibliographicalnotesattheendofthischapterformoredetails.)712 Chapter18 VirtualMachines
erutcurts
atad
elbat
egap
detsen
MMV
guest virtual address
kernel paging data
structures
guest physical address
PML4 directory ptr directory table offset
PML4E
PDPTE
PDE
PTE
phy addr
host physical address
tseug
1
5
2 3 4
1 1 2 2 3 3 4
4 5
Figure18.4 Nestedpagetables.
ARM architectures, specifically ARM v8 (64-bit) take a slightly different
approachtohardwaresupportofvirtualization.Theyprovideanentireexcep-
tionlevel—EL2—whichisevenmoreprivilegedthanthatofthekernel(EL1).
This allows the running of a secluded hypervisor, with its own MMU access
and interrupt trapping. To allow for paravirtualization, a special instruction
(HVC) is added. It allows the hypervisor to be called from guest kernels. This
instructioncanonlybecalledfromwithinkernelmode(EL1).
An interesting side effect of hardware-assisted virtualization is that it
allowsforthecreationofthinhypervisors.AgoodexampleismacOS’shyper-
visor framework (“HyperVisor.framework”), which is an operating-system-
supplied library that allows the creation of virtual machines in a few lines of18.5 TypesofVMsandTheirImplementations 713
code.Theactualworkisdoneviasystemcalls,whichhavethekernelcallthe
privilegedvirtualizationCPUinstructionsonbehalfofthehypervisorprocess,
allowingmanagementofvirtualmachineswithoutthehypervisorneedingto
loadakernelmoduleofitsowntoexecutethosecalls.
18.5 Types of VMs and Their Implementations
We’venowlookedatsomeofthetechniquesusedtoimplementvirtualization.
Next,weconsiderthemajortypesofvirtualmachines,theirimplementation,
their functionality, and how they use the building blocks just described to
create a virtual environment. Of course, the hardware on which the virtual
machines are running can cause great variation in implementation methods.
Here,wediscusstheimplementationsingeneral,withtheunderstandingthat
VMMstakeadvantageofhardwareassistancewhereitisavailable.
18.5.1 The Virtual Machine Life Cycle
Let’sbeginwiththevirtualmachinelifecycle.Whateverthehypervisortype,
at the time a virtual machine is created, its creator gives the VMM certain
parameters. These parameters usually include the number of CPUs, amount
ofmemory,networkingdetails,andstoragedetailsthattheVMMwilltakeinto
account when creating the guest. For example, a user might want to create a
new guest with two virtual CPUs, 4 GB of memory, 10 GB of disk space, one
networkinterfacethatgetsitsIPaddressviaDHCP,andaccesstotheDVDdrive.
The VMM then creates the virtual machine with those parameters. In the
case of a type 0 hypervisor, the resources are usually dedicated.In this situa-
tion, if there are not two virtual CPUs available and unallocated, the creation
requestinourexamplewillfail.Forotherhypervisortypes,theresourcesare
dedicatedorvirtualized,dependingonthetype.Certainly,anIPaddresscan-
not be shared, but the virtual CPUs are usually multiplexed on the physical
CPUs as discussed in Section 18.6.1. Similarly, memory management usually
involves allocating more memory to guests than actually exists in physical
memory.ThisismorecomplicatedandisdescribedinSection18.6.2.
Finally, when the virtual machine is no longer needed, it can be deleted.
When this happens, the VMM first frees up any used disk space and then
removes the configuration associated with the virtual machine, essentially
forgettingthevirtualmachine.
These steps are quite simple compared with building, configuring, run-
ning, and removing physical machines. Creating a virtual machine from an
existingonecanbeaseasyasclickingthe“clone”buttonandprovidinganew
nameandIPaddress.Thiseaseofcreationcanleadtovirtualmachinesprawl,
whichoccurswhentherearesomanyvirtualmachinesonasystemthattheir
use,history,andstatebecomeconfusinganddifficulttotrack.
18.5.2 Type 0 Hypervisor
Type0hypervisorshaveexistedformanyyearsundermanynames,including
“partitions” and “domains.” They are a hardware feature, and that brings its
own positives and negatives. Operating systems need do nothing special to
takeadvantageoftheirfeatures.TheVMMitselfisencodedinthefirmwareand714 Chapter18 VirtualMachines
guest guest guest guest guest
guest 1 guest 2 guest 3 guest 4
CPUs CPUs CPUs CPUs
memory memory memory memory
hypervisor (in firmware) I/O
Figure18.5 Type0hypervisor.
loadedatboottime.Inturn,itloadstheguestimagestorunineachpartition.
Thefeaturesetofatype0hypervisortendstobesmallerthanthoseoftheother
typesbecauseitisimplementedinhardware.Forexample,asystemmightbe
split into four virtual systems, each with dedicated CPUs, memory, and I/O
devices. Each guest believes that it has dedicated hardware because it does,
simplifyingmanyimplementationdetails.
I/Opresentssomedifficulty,becauseitisnoteasytodedicateI/Odevices
toguestsiftherearenotenough.WhatifasystemhastwoEthernetportsand
more than two guests, for example? Either all guests must get their own I/O
devices, or the system must provided I/O device sharing. In these cases, the
hypervisormanagessharedaccessorgrantsalldevicestoacontrolpartition.
Inthecontrolpartition,aguestoperatingsystemprovidesservices(suchasnet-
working)viadaemonstootherguests,andthehypervisorroutesI/Orequests
appropriately. Some type 0 hypervisors are even more sophisticated and can
movephysicalCPUsandmemorybetweenrunningguests.Inthesecases,the
guestsareparavirtualized,awareofthevirtualizationandassistinginitsexe-
cution.Forexample,aguestmustwatchforsignalsfromthehardwareorVMM
thatahardwarechangehasoccurred,probeitshardwaredevicestodetectthe
change,andaddorsubtractCPUsormemoryfromitsavailableresources.
Because type 0 virtualization is very close to raw hardware execution, it
shouldbeconsideredseparatelyfromtheothermethodsdiscussedhere.Atype
0hypervisorcanrunmultipleguestoperatingsystems(oneineachhardware
partition).Allofthoseguests,becausetheyarerunningonrawhardware,can
inturnbeVMMs.Essentially,eachguestoperatingsysteminatype0hypervisor
is a native operating system with a subset of hardware made available to it.
Because of that, each can have its own guest operating systems (Figure 18.5).
Othertypesofhypervisorsusuallycannot providethis virtualization-within-
virtualizationfunctionality.
18.5.3 Type 1 Hypervisor
Type1hypervisorsarecommonlyfoundincompanydatacentersandare,ina
sense,becoming“thedata-centeroperatingsystem.”Theyarespecial-purpose
operatingsystemsthatrunnativelyonthehardware,butratherthanproviding18.5 TypesofVMsandTheirImplementations 715
system calls and other interfaces for running programs, they create, run, and
manage guest operating systems. In addition to running on standard hard-
ware,theycanrunontype0hypervisors,butnotonothertype1hypervisors.
Whatever the platform, guests generally do not know they are running on
anythingbutthenativehardware.
Type1hypervisorsruninkernelmode,takingadvantageofhardwarepro-
tection.WherethehostCPUallows,theyusemultiplemodestogiveguestoper-
atingsystemstheirowncontrolandimprovedperformance.Theyimplement
devicedriversforthehardwaretheyrunon,sincenoothercomponentcould
doso.Becausetheyareoperatingsystems,theymustalsoprovideCPUschedul-
ing, memory management, I/O management, protection, and even security.
Frequently,theyprovideAPIs,butthoseAPIssupportapplicationsinguestsor
externalapplicationsthatsupplyfeatureslikebackups,monitoring,andsecu-
rity.Manytype1hypervisorsareclosed-sourcecommercialofferings,suchas
VMwareESX,whilesomeareopensourceorhybridsofopenandclosedsource,
suchasCitrixXenServeranditsopenXencounterpart.
By using type 1 hypervisors, data-center managers can control and man-
age the operating systems and applications in new and sophisticated ways.
Animportantbenefitistheabilitytoconsolidatemoreoperatingsystemsand
applicationsontofewersystems.Forexample,ratherthanhavingtensystems
runningat10percentutilizationeach,adatacentermighthaveoneserverman-
agetheentireload.Ifutilizationincreases,guestsandtheirapplicationscanbe
movedtoless-loadedsystemslive,withoutinterruptionofservice.Usingsnap-
shotsandcloning,thesystemcansavethestatesofguestsandduplicatethose
states—amucheasiertaskthanrestoringfrombackupsorinstallingmanually
or via scripts and tools. The price of this increased manageability is the cost
oftheVMM(ifitisacommercialproduct),theneedtolearnnewmanagement
toolsandmethods,andtheincreasedcomplexity.
Anothertypeoftype1hypervisorincludesvariousgeneral-purposeoper-
atingsystemswithVMMfunctionality.Here,anoperatingsystemsuchasRed-
Hat EnterpriseLinux,Windows, or Oracle Solarisperformsits normal duties
aswellasprovidingaVMM allowingotheroperatingsystemstorunasguests.
Becauseoftheirextraduties,thesehypervisorstypicallyprovidefewervirtual-
izationfeaturesthanothertype1hypervisors.Inmanyways,theytreataguest
operating system as just another process, but they provide special handling
whentheguesttriestoexecutespecialinstructions.
18.5.4 Type 2 Hypervisor
Type 2 hypervisors are less interesting to us as operating-system explorers,
becausethereisverylittleoperating-systeminvolvementintheseapplication-
level virtual machine managers. This type of VMM is simply another process
run and managed by the host, and even the host does not know that virtual-
izationishappeningwithintheVMM.
Type2hypervisorshavelimitsnotassociatedwithsomeoftheothertypes.
For example, a user needs administrative privileges to access many of the
hardware assistance features of modern CPUs. If the VMM is being run by a
standard user without additional privileges,the VMM cannot take advantage
ofthesefeatures.Duetothislimitation,aswellastheextraoverheadofrunning716 Chapter18 VirtualMachines
request consumer request producer
private pointer shared pointer
in Xen updated by guest OS
response producer
shared pointer response consumer
updated by private pointer
Xen in guest OS
request queue - descriptors queued by the VM but not yet accepted by Xen
outstanding descriptors - descriptor slots awaiting a response from Xen
response queue - descriptors returned by Xen in response to serviced requests
unused descriptors
Figure18.6 XenI/Oviasharedcircularbuffer.1
ageneral-purposeoperatingsystemaswellasguestoperatingsystems,type2
hypervisorstendtohavepooreroverallperformancethantype0ortype1.
As is often the case, the limitations of type 2 hypervisors also provide
some benefits. They run on a variety of general-purpose operating systems,
andrunningthemrequiresnochangestothehostoperatingsystem.Astudent
canuseatype2hypervisor,forexample,totestanon-nativeoperatingsystem
without replacing the native operating system. In fact, on an Apple laptop,
a student could have versions of Windows, Linux, Unix, and less common
operatingsystemsallavailableforlearningandexperimentation.
18.5.5 Paravirtualization
As we’ve seen, paravirtualization works differently than the other types of
virtualization.Ratherthantrytotrickaguestoperatingsystemintobelieving
it has a system to itself, paravirtualization presents the guest with a system
thatissimilarbutnotidenticaltotheguest’spreferredsystem.Theguestmust
be modifiedtorunon theparavirtualizedvirtualhardware.The gain for this
extraworkismoreefficientuseofresourcesandasmallervirtualizationlayer.
The Xen VMM became the leader in paravirtulization by implementing
severaltechniquestooptimizetheperformanceofguestsaswellasofthehost
system.Forexample,asmentionedearlier,someVMMspresentvirtualdevices
togueststhatappeartoberealdevices.Insteadoftakingthatapproach,theXen
VMMpresentedcleanandsimpledeviceabstractionsthatallowefficientI/Oas
wellasgoodI/O-relatedcommunicationbetweentheguestandtheVMM.For
1Barham, Paul. “Xen and the Art of Virtualization”. SOSP’03 Proceedingsof the Nineteenth ACM
SymposiumonOperatingSystemsPrinciples,p164-177.(cid:2)c2003AssociationforComputingMachinery,
Inc18.5 TypesofVMsandTheirImplementations 717
eachdeviceusedbyeachguest,therewasacircularbuffersharedbytheguest
andtheVMMviasharedmemory.Readandwritedataareplacedinthisbuffer,
asshowninFigure18.6.
For memory management, Xen did not implement nested page tables.
Rather,eachguesthaditsownsetofpagetables,settoread-only.Xenrequired
theguesttouseaspecificmechanism,ahypercallfromtheguesttothehyper-
visorVMM, whenapage-tablechange was needed.This meantthat theguest
operatingsystem’skernelcodemusthavebeenchangedfromthedefaultcode
totheseXen-specificmethods.Tooptimizeperformance,Xenallowedtheguest
to queue up multiple page-table changes asynchronously via hypercalls and
then checked to ensure that the changes were complete before continuing
operation.
Xen allowed virtualization of x86 CPUs without the use of binary trans-
lation,insteadrequiringmodificationsintheguestoperatingsystemslikethe
onedescribedabove.Overtime,Xenhastakenadvantageofhardwarefeatures
supportingvirtualization.Asaresult,itnolongerrequiresmodifiedguestsand
essentiallydoesnotneedtheparavirtualizationmethod.Paravirtualizationis
stillusedinothersolutions,however,suchastype0hypervisors.
18.5.6 Programming-Environment Virtualization
Another kind of virtualization, based on a different execution model, is the
virtualizationofprogrammingenvironments.Here,aprogramminglanguage
is designed to run within a custom-built virtualized environment. For exam-
ple, Oracle’s Java has many features that depend on its running in the Java
virtual machine (JVM), including specific methods for security and memory
management.
Ifwedefinevirtualizationasincludingonlyduplicationofhardware,thisis
notreallyvirtualizationatall.Butweneednotlimitourselvestothatdefinition.
Instead,wecandefineavirtualenvironment,basedonAPIs,thatprovidesaset
offeatureswewanttohaveavailableforaparticularlanguageandprograms
writteninthatlanguage.JavaprogramsrunwithintheJVMenvironment,and
theJVMiscompiledtobeanativeprogramonsystemsonwhichitruns.This
arrangementmeansthatJavaprogramsarewrittenonceandthencanrunon
any system (including all of the major operating systems) on which a JVM is
available. The same can be said of interpreted languages, which run inside
programsthatreadeachinstructionandinterpretitintonativeoperations.
18.5.7 Emulation
Virtualizationisprobablythemostcommonmethodforrunningapplications
designedforoneoperatingsystemonadifferentoperatingsystem,butonthe
same CPU. This method works relatively efficiently because the applications
werecompiledfortheinstructionsetthatthetargetsystemuses.
Butwhatifanapplicationoroperatingsystemneedstorunonadifferent
CPU? Here, it is necessary to translate all of the source CPU’s instructions so
thattheyareturnedintotheequivalentinstructionsofthetargetCPU.Suchan
environmentisnolongervirtualizedbutratherisfullyemulated.
Emulation is useful when the host system has one system architecture
and the guest system was compiled for a different architecture. For example,718 Chapter18 VirtualMachines
suppose a company has replaced its outdated computer system with a new
systembutwouldliketocontinuetoruncertainimportantprogramsthatwere
compiled for the old system. The programs could be run in an emulator that
translateseachoftheoutdatedsystem’sinstructionsintothenativeinstruction
setofthe newsystem.Emulationcan increasethe lifeofprogramsand allow
ustoexploreoldarchitectureswithouthavinganactualoldmachine.
As may be expected, the major challenge of emulation is performance.
Instruction-set emulation may run an order of magnitude slower than native
instructions, because it may take ten instructions on the new system to read,
parse,and simulateaninstructionfromtheoldsystem.Thus,unlessthenew
machine is ten times faster than the old, the program running on the new
machine will run more slowly than it did on its native hardware. Another
challengeforemulatorwritersisthatitisdifficulttocreateacorrectemulator
because,inessence,thistaskinvolveswritinganentireCPUinsoftware.
In spite of these challenges, emulation is very popular, particularly in
gamingcircles.Manypopularvideogameswerewrittenforplatformsthatare
no longer in production. Users who want to run those games frequently can
findanemulatorofsuchaplatformandthenrunthegameunmodifiedwithin
theemulator.Modernsystemsaresomuchfasterthanoldgameconsolesthat
eventheAppleiPhonehasgameemulatorsandgamesavailabletorunwithin
them.
18.5.8 Application Containment
Thegoalofvirtualizationinsomeinstancesistoprovideamethodtosegregate
applications, manage their performance and resource use, and create an easy
waytostart,stop,move,andmanagethem.Insuchcases,perhapsfull-fledged
virtualization is not needed. If the applications are all compiled for the same
operatingsystem,thenwedonotneedcompletevirtualizationtoprovidethese
features.Wecaninsteaduseapplicationcontainment.
Consider one example of application containment. Starting with version
10,OracleSolarishasincludedcontainers,orzones,thatcreateavirtuallayer
between the operating system and the applications. In this system, only one
kernel is installed, and the hardware is not virtualized. Rather, the operating
systemanditsdevicesarevirtualized,providingprocesseswithinazonewith
the impression that they are the only processes on the system. One or more
containers can be created, and each can have its own applications, network
stacks,networkaddressandports,useraccounts,andsoon.CPUandmemory
resources can be divided among the zones and the system-wide processes.
Each zone, in fact, can run its own scheduler to optimize the performance of
itsapplicationsontheallottedresources.Figure18.7showsaSolaris10system
withtwocontainersandthestandard“global”userspace.
Containers are much lighter weight than other virtualization methods.
That is, they use fewer system resources and are faster to instantiate and
destroy,moresimilartoprocessesthanvirtualmachines.Forthisreason,they
are becoming more commonly used, especially in cloud computing. FreeBSD
was perhaps the first operating system to include a container-like feature
(called “jails”), and AIX has a similar feature. Linux added the LXC container
feature in 2014. It is now included in the common Linux distributions via18.6 VirtualizationandOperating-SystemComponents 719
user programs user programs user programs
system programs system programs system programs
CPU resources network addresses network addresses
memory resources device access device access
CPU resources CPU resources
memory resources memory resources
zone 1 zone 2
virtual platform
global zone device management
zone management
Solaris kernel
network addresses
…
device device
Figure18.7 Solaris10withtwozones.
a flag in the clone() system call. (The source code for LXCis available at
https://linuxcontainers.org/lxc/downloads.)
Containersarealsoeasytoautomateandmanage,leadingtoorchestration
tools likedocker and Kubernetes.Orchestrationtools are means of automat-
ing and coordinating systems and services. Their aim is to make it simple to
run entire suites of distributed applications, just as operating systems make
it simple to run a single program. These tools offer rapid deployment of
full applications, consisting of many processes within containers, and also
offer monitoring and other administration features. For more on docker, see
https://www.docker.com/what-docker.InformationaboutKubernetescanbe
foundathttps://kubernetes.io/docs/concepts/overview/what-is-kubernetes.
18.6 Virtualization and Operating-System Components
Thus far, we have explored the building blocks of virtualization and the var-
ious types of virtualization. In this section, we take a deeper dive into the
operating-system aspects of virtualization, including how the VMM provides
core operating-system functions like scheduling, I/O, and memory manage-
ment.Here,weanswerquestionssuchasthese:HowdoVMMsscheduleCPU
use when guest operating systems believe they have dedicated CPUs? How
can memory management work when many guests require large amounts of
memory?720 Chapter18 VirtualMachines
18.6.1 CPU Scheduling
A system with virtualization, even a single-CPU system, frequently acts like
a multiprocessor system. The virtualization software presents one or more
virtual CPUs to each of the virtual machines running on the system and then
schedulestheuseofthephysicalCPUsamongthevirtualmachines.
Thesignificantvariationsamongvirtualizationtechnologiesmakeitdiffi-
culttosummarizetheeffectofvirtualizationonscheduling.First,let’sconsider
thegeneralcaseofVMMscheduling.TheVMMhasanumberofphysicalCPUs
available and a number of threads to run on those CPUs. The threads can be
VMMthreadsorguestthreads.Guestsareconfiguredwithacertainnumberof
virtualCPUsatcreationtime,andthatnumbercanbeadjustedthroughoutthe
lifeoftheVM.WhenthereareenoughCPUstoallocatetherequestednumberto
eachguest,theVMMcantreattheCPUsasdedicatedandscheduleonlyagiven
guest’sthreadsonthatguest’sCPUs.Inthissituation,theguestsactmuchlike
nativeoperatingsystemsrunningonnativeCPUs.
Ofcourse,inothersituations,theremaynotbeenoughCPUstogoaround.
The VMM itself needs some CPU cycles for guest management and I/O man-
agementandcanstealcyclesfromtheguestsbyschedulingitsthreadsacross
all of the system CPUs, but the impact of this action is relativelyminor. More
difficultisthecaseofovercommitment,inwhichtheguestsareconfiguredfor
moreCPUsthanexistinthesystem.Here,aVMMcanusestandardscheduling
algorithmstomakeprogressoneachthreadbutcanalsoaddafairnessaspectto
thosealgorithms.Forexample,iftherearesixhardwareCPUsandtwelveguest-
allocatedCPUs,theVMMcanallocateCPUresourcesproportionally,givingeach
guesthalfoftheCPUresourcesitbelievesithas.TheVMMcanstillpresentall
twelvevirtualCPUstotheguests,butinmappingthemontophysicalCPUs,the
VMMcanuseitsschedulertodistributethemappropriately.
Evengivenaschedulerthatprovidesfairness,anyguestoperating-system
scheduling algorithm that assumes a certain amount of progress in a given
amountoftimewillmostlikelybenegativelyaffectedbyvirtualization.Con-
sideratime-sharingoperatingsystemthattriestoallot100millisecondstoeach
timeslicetogiveusersareasonableresponsetime.Within avirtualmachine,
thisoperatingsystemreceivesonlywhatCPUresourcesthevirtualizationsys-
tem gives it. A100-millisecond time slice may take much more than 100 mil-
lisecondsofvirtualCPUtime.Dependingonhowbusythesystemis,thetime
slicemaytakeasecondormore,resultinginverypoorresponsetimesforusers
loggedintothatvirtualmachine.Theeffectonareal-timeoperatingsystemcan
beevenmoreserious.
Thenetoutcomeofsuchschedulingisthatindividualvirtualizedoperating
systems receive only a portion of the available CPU cycles, even though they
believe they are receiving all of the cycles and indeed are scheduling all of
thecycles.Commonly,thetime-of-dayclocksinvirtualmachinesareincorrect
because timers take longer to trigger than they would on dedicated CPUs.
Virtualizationcanthusundothescheduling-algorithmeffortsoftheoperating
systemswithinvirtualmachines.
Tocorrectforthis,theVMMmakesanapplicationavailableforeachtypeof
operatingsystemthatthesystemadministratorcaninstallintotheguests.This
application corrects clock drift and can have other functions, such as virtual
devicemanagement.18.6 VirtualizationandOperating-SystemComponents 721
18.6.2 Memory Management
Efficient memory use in general-purposeoperating systems is a major key to
performance.Invirtualizedenvironments,therearemoreusersofmemory(the
guestsandtheirapplications,aswellastheVMM),leadingtomorepressureon
memory use. Further adding to this pressure is the fact that VMMs typically
overcommit memory, so that the total memory allocated to guests exceeds
the amount that physically exists in the system. The extra need for efficient
memory use is not lost on the implementers of VMMs, who take extensive
measurestoensuretheoptimaluseofmemory.
Forexample,VMwareESXusesseveralmethodsofmemorymanagement.
Before memory optimization can occur, the VMM must establish how much
real memory each guest should use. To do that, the VMM first evaluates each
guest’s maximum memory size. General-purpose operating systems do not
expecttheamountofmemoryinthesystemtochange,soVMMsmustmaintain
theillusionthattheguesthasthatamountofmemory.Next,theVMMcomputes
atargetreal-memoryallocationforeachguestbasedontheconfiguredmemory
forthat guestand other factors,such as overcommitmentand systemload.It
thenusesthethreelow-levelmechanismslistedbelowtoreclaimmemoryfrom
theguests
1. Recall that a guest believes it controls memory allocation via its page-
tablemanagement,whereasinrealitytheVMMmaintains anestedpage
tablethattranslatestheguestpagetabletotherealpagetable.TheVMM
canusethisextralevelofindirectiontooptimizetheguest’suseofmem-
ory without the guest’s knowledge or help. One approach is to provide
doublepaging.Here,theVMMhasitsownpage-replacementalgorithms
and loads pages into a backing store that the guest believes is physical
memory.Ofcourse,theVMMknowslessabouttheguest’smemoryaccess
patterns than the guest does, so its paging is less efficient, creating per-
formance problems. VMMs do use this method when other methods are
notavailableorarenotprovidingenoughfreememory.However,itisnot
thepreferredapproach.
2. A common solution is for the VMM to install in each guest a pseudo–
devicedriverorkernelmodulethattheVMMcontrols.(Apseudo–device
driverusesdevice-driverinterfaces,appearingtothekerneltobeadevice
driver, but does not actually control a device. Rather, it is an easy way
to add kernel-mode code without directly modifying the kernel.) This
balloon memory manager communicates with the VMM and is told to
allocate or deallocate memory. If told to allocate, it allocates memory
and tells the operating system to pin the allocated pages into physical
memory.Recallthatpinninglocksapageintophysicalmemorysothatit
cannotbemovedorpagedout.Totheguest,thesepinnedpagesappear
to decrease the amount of physical memory it has available, creating
memory pressure. The guest then may free up other physical memory
to be sure it has enough free memory. Meanwhile, the VMM, knowing
thatthepagespinnedbytheballoonprocesswillneverbeused,removes
thosephysicalpagesfromtheguestandallocatesthemtoanotherguest.
At the same time, the guest is using its own memory-management and
paging algorithms to manage the available memory, which is the most722 Chapter18 VirtualMachines
efficient option. If memory pressure within the entire system decreases,
theVMMwilltelltheballoonprocesswithintheguesttounpinandfree
someorallofthememory,allowingtheguestmorepagesforitsuse.
3. AnothercommonmethodforreducingmemorypressureisfortheVMM
to determine if the same page has been loaded more than once. If this
is the case, the VMM reduces the number of copies of the page to one
and maps the other users of the page to that one copy. VMware, for
example, randomly samples guest memory and creates a hash for each
page sampled.That hash value is a “thumbprint” of the page. The hash
ofeverypageexaminediscomparedwithotherhashesstoredinahash
table.Ifthereisamatch,thepagesarecomparedbytebybytetoseeifthey
reallyareidentical.Ifthey are,one pageisfreed,and itslogicaladdress
is mapped to the other’s physical address. This technique might seem
at first tobe ineffective,but consider that guests runoperating systems.
Ifmultipleguestsrunthesameoperatingsystem,thenonlyonecopyof
theactiveoperating-systempagesneedbeinmemory.Similarly,multiple
guestscouldberunningthesamesetofapplications,againalikelysource
ofmemorysharing.
The overall effect of these mechanisms is to enable guests to behave and
performasiftheyhadthefullamountofmemoryrequested,althoughinreality
theyhaveless.
18.6.3 I/O
In the area of I/O, hypervisors have some leeway and can be less concerned
with how they represent the underlying hardware to their guests. Because
of the wide variation in I/O devices, operating systems are used to dealing
withvaryingandflexibleI/Omechanisms.Forexample,anoperatingsystem’s
device-driver mechanism provides a uniform interface to the operating sys-
tem whatever the I/O device. Device-driver interfaces are designed to allow
third-partyhardwaremanufacturerstoprovidedevicedriversconnectingtheir
devices to the operating system. Usually, device drivers can be dynamically
loadedandunloaded.Virtualizationtakesadvantageofthisbuilt-inflexibility
byprovidingspecificvirtualizeddevicestoguestoperatingsystems.
As describedin Section18.5, VMMs vary greatlyin how they provideI/O
to their guests. I/O devices may be dedicated to guests, for example, or the
VMM may have device drivers onto which it maps guest I/O. The VMM may
alsoprovideidealizeddevicedriversto guests.Inthis case, the guestseesan
easy-to-controldevice,butinrealitythatsimpledevicedrivercommunicatesto
theVMM,whichsendstherequeststoamorecomplicatedrealdevicethrough
amorecomplexrealdevicedriver.I/Oinvirtualenvironmentsiscomplicated
andrequirescarefulVMMdesignandimplementation.
Consider the case of a hypervisor and hardware combination that allows
devicestobededicatedtoaguestandallowstheguesttoaccessthosedevices
directly. Of course, a device dedicated to one guest is not available to any
other guests, but this direct access can still be useful in some circumstances.
The reasonto allowdirectaccess is toimproveI/O performance.The less the
hypervisor has to do to enable I/O for its guests, the faster the I/O can occur.
With type 0 hypervisors that provide direct device access, guests can often18.6 VirtualizationandOperating-SystemComponents 723
run at the same speed as native operating systems. When type 0 hypervisors
insteadprovideshareddevices,performancemaysuffer.
With direct device access in type 1 and 2 hypervisors, performance can
be similar to that of native operating systems if certain hardware support
is present. The hardware needs to provide DMA pass-through with facilities
likeVT-d, as well as direct interruptdelivery(interrupts going directly tothe
guests). Given how frequently interrupts occur, it should be no surprise that
the guests on hardware without these features have worse performance than
iftheywererunningnatively.
Inadditiontodirectaccess,VMMs providesharedaccess todevices.Con-
sideradiskdrivetowhichmultipleguestshaveaccess.TheVMMmustprovide
protection while the device is being shared, assuring that a guest can access
only the blocks specified in the guest’s configuration. In such instances, the
VMM must be part of every I/O, checking it for correctness as well as routing
thedatatoandfromtheappropriatedevicesandguests.
In the area of networking, VMMs also have work to do. General-purpose
operating systemstypically have one Internet protocol (IP) address,although
they sometimes have more than one—for example, to connect to a manage-
mentnetwork,backupnetwork,andproductionnetwork.Withvirtualization,
eachguestneedsatleastoneIPaddress,becausethatistheguest’smainmode
of communication. Therefore, a server running a VMM may have dozens of
addresses,and the VMM acts asa virtualswitch toroute the network packets
totheaddressedguests.
The guests can be “directly” connected to the network by an IP address
thatisseenbythebroadernetwork(thisisknownasbridging).Alternatively,
theVMM can provideanetwork addresstranslation (NAT)address.The NAT
address is local to the server on which the guest is running, and the VMM
provides routing between the broader network and the guest. The VMM also
provides firewalling to guard connections between guests within the system
andbetweenguestsandexternalsystems.
18.6.4 Storage Management
An important question in determining how virtualization works is this: If
multiple operating systems have been installed, what and where is the boot
disk?Clearly,virtualizedenvironmentsneedtoapproachstoragemanagement
differently than do native operating systems. Even the standard multiboot
methodofslicingthebootdiskintopartitions,installingabootmanagerinone
partition,andinstallingeachotheroperatingsysteminanotherpartitionisnot
sufficient,becausepartitioninghaslimitsthatwouldpreventitfromworking
fortensorhundredsofvirtualmachines.
Onceagain,thesolutiontothisproblemdependsonthetypeofhypervisor.
Type 0 hypervisors often allow root disk partitioning, partly because these
systems tend to run fewer guests than other systems. Alternatively, a disk
manager may be part of the control partition, and that disk manager may
providediskspace(includingbootdisks)totheotherpartitions.
Type 1 hypervisors store the guest root disk (and configuration informa-
tion) in one or more files in the file systems provided by the VMM. Type 2
hypervisorsstorethesameinformationinthehostoperatingsystem’sfilesys-
tems. In essence, a disk image, containing all of the contents of the root disk724 Chapter18 VirtualMachines
oftheguest,iscontainedinonefileintheVMM.Asidefromthepotentialper-
formance problems that causes, this is a clever solution, because it simplifies
copyingandmovingguests.Iftheadministratorwantsaduplicateoftheguest
(for testing, for example), she simply copies the associated disk image of the
guestandtellstheVMMaboutthenewcopy.Bootingthenewvirtualmachine
brings up an identical guest. Moving a virtual machine from one system to
anotherthatrunsthesameVMMisassimpleashaltingtheguest,copyingthe
imagetotheothersystem,andstartingtheguestthere.
Guests sometimes need more disk space than is available in their root
disk image. For example, a nonvirtualized database server might use several
file systems spread across many disks to store various parts of the database.
Virtualizingsuchadatabaseusuallyinvolvescreatingseveralfilesandhaving
theVMMpresentthosetotheguestasdisks.Theguestthenexecutesasusual,
withtheVMMtranslatingthediskI/Orequestscomingfromtheguestintofile
I/Ocommandstothecorrectfiles.
Frequently, VMMs provide a mechanism to capture a physical system as
it is currently configured and convert it to a guest that the VMM can manage
andrun.Thisphysical-to-virtual(P-to-V)conversionreadsthediskblocksof
the physical system’s disks and stores them in files on the VMM’s system or
on shared storage that the VMM can access. VMMs also provide a virtual-to-
physical (V-to-P) procedure for converting a guest to a physical system. This
procedureissometimesneededfordebugging:aproblemcouldbecausedby
the VMM or associated components, and the administrator could attempt to
solvetheproblembyremovingvirtualizationfromtheproblemvariables.V-to-
Pconversioncantakethefilescontainingalloftheguestdataandgeneratedisk
blocksonaphysicaldisk,recreatingtheguestasanativeoperatingsystemand
applications.Oncethetestingisconcluded,theoriginalsystemcanbereused
forotherpurposeswhenthevirtualmachinereturnstoservice,orthevirtual
machinecanbedeletedandtheoriginalsystemcancontinuetorun.
18.6.5 Live Migration
One feature not found in general-purpose operating systems but found in
type 0 and type 1 hypervisors is the live migration of a running guest from
onesystemtoanother.Wementionedthiscapabilityearlier.Here,weexplore
the details of how live migration works and why VMMs can implement it
relatively easily while general-purpose operating systems, in spite of some
researchattempts,cannot.
First, let’s consider how live migration works. A running guest on one
system is copied to another system running the same VMM. The copy occurs
with so little interruption of service that users logged in to the guest, as well
asnetworkconnectionstotheguest,continuewithoutnoticeableimpact.This
ratherastonishingabilityisverypowerfulinresourcemanagementandhard-
ware administration. After all, compare it with the steps necessary without
virtualization: we must warn users, shut down the processes, possibly move
thebinaries,andrestarttheprocessesonthenewsystem.Onlythencanusers
accesstheservicesagain.Withlivemigration,wecandecreasetheloadonan
overloadedsystemormakehardwareorsystemchangeswithnodiscernable
disruptionforusers.18.6 VirtualizationandOperating-SystemComponents 725
Livemigrationismadepossiblebythewell-definedinterfacebetweeneach
guestandtheVMMandthelimitedstatetheVMMmaintainsfortheguest.The
VMMmigratesaguestviathefollowingsteps:
1. The source VMM establishes a connection with the target VMM and con-
firmsthatitisallowedtosendaguest.
2. ThetargetcreatesanewguestbycreatinganewVCPU,newnestedpage
table,andotherstatestorage.
3. Thesourcesendsallread-onlymemorypagestothetarget.
4. The source sends all read–write pages to the target, marking them as
clean.
5. The source repeats step 4, because during that step some pages were
probably modified by the guest and are now dirty.These pages need to
besentagainandmarkedagainasclean.
6. When the cycle of steps 4 and 5 becomes very short, the source VMM
freezestheguest,sendstheVCPU’sfinalstate,otherstatedetails,andthe
finaldirtypages,andtellsthetargettostartrunningtheguest.Oncethe
targetacknowledgesthattheguestisrunning,thesourceterminatesthe
guest.
ThissequenceisshowninFigure18.8.
Weconcludethisdiscussionwithafewinterestingdetailsandlimitations
concerninglivemigration.First,fornetworkconnectionstocontinueuninter-
rupted,thenetworkinfrastructureneedstounderstandthataMACaddress—
thehardwarenetworkingaddress—canmovebetweensystems.Beforevirtu-
alization, this didnot happen, as the MAC addresswas tiedtophysical hard-
ware. With virtualization, the MAC must be movable for existing networking
connections to continue without resetting. Modern network switches under-
standthisandroutetrafficwherevertheMACaddressis,evenaccommodating
amove.
0 – running 1 – establish
guest source
3 – send R/O pages
4 – send R/W pages
5 – send dirty pages (repeatedly)
guest target running
ecruos
MMV
7 – terminate
guest source
tegrat
MMV
2 – create
guest target
6 – running
guest target
Figure18.8 Livemigrationofaguestbetweentwoservers.726 Chapter18 VirtualMachines
Alimitationoflivemigrationisthatnodiskstateistransferred.Onereason
livemigrationispossibleisthatmostoftheguest’sstateismaintainedwithin
the guest—for example, open file tables, system-call state, kernel state, and
so on. Because disk I/O is much slower than memory access, however, and
used disk space is usually much larger than used memory, disks associated
with the guest cannot be moved as part of a live migration. Rather, the disk
must be remote to the guest, accessed over the network. In that case, disk
access state is maintained within the guest, and network connections are all
that matter to the VMM. The network connections are maintained during the
migration,soremotediskaccesscontinues.Typically,NFS,CIFS,oriSCSIisused
to store virtual machine images and any other storage a guest needs access
to. These network-based storage accesses simply continue when the network
connectionsarecontinuedoncetheguesthasbeenmigrated.
Live migration makes it possible to manage data centers in entirely new
ways.Forexample,virtualizationmanagementtoolscanmonitoralltheVMMs
in an environment and automatically balance resource use by moving guests
between the VMMs. These tools can also optimize the use of electricity and
coolingbymigratingallguestsoffselectedserversifotherserverscanhandle
theloadandpoweringdowntheselectedserversentirely.Iftheloadincreases,
thetoolscanpoweruptheserversandmigrateguestsbacktothem.
18.7 Examples
Despite the advantages of virtual machines, they received little attention for
a number of years after they were first developed. Today, however, virtual
machines are coming into greater use as a means of solving system compat-
ibilityproblems.Inthissection,weexploretwopopularcontemporaryvirtual
machines:theVMwareWorkstationandtheJavavirtualmachine.Thesevirtual
machines can typically run on top of operating systems of any of the design
typesdiscussedinearlierchapters.
18.7.1 VMware
VMwareWorkstationisapopularcommercialapplicationthatabstractsIntel
x86 and compatible hardware into isolated virtual machines. VMware Work-
stationisaprimeexampleofaType2hypervisor.Itrunsasanapplicationona
hostoperatingsystemsuchasWindowsorLinuxandallowsthishostsystem
torunseveraldifferentguestoperating systemsconcurrently asindependent
virtualmachines.
ThearchitectureofsuchasystemisshowninFigure18.9.Inthisscenario,
Linuxisrunningasthehostoperatingsystem,andFreeBSD,WindowsNT,and
Windows XParerunning as guestoperating systems.Attheheart of VMware
isthevirtualizationlayer,whichabstractsthephysicalhardwareintoisolated
virtualmachinesrunningasguestoperatingsystems.Eachvirtualmachinehas
itsownvirtualCPU,memory,diskdrives,networkinterfaces,andsoforth.
The physical disk that the guest owns and manages is really just a file
withinthefilesystemofthehostoperatingsystem.Tocreateanidenticalguest,
we can simply copy the file. Copying the file to another location protects the
guestagainstadisasterattheoriginalsite.Movingthefiletoanotherlocation18.7 Examples 727
application application application application
guest operating guest operating guest operating
system system system
(free BSD) (Windows NT) (Windows XP)
virtual CPU virtual CPU virtual CPU
virtual memory virtual memory virtual memory
virtual devices virtual devices virtual devices
virtualization layer
host operating system
(Linux)
hardware
CPU memory I/O devices
Figure18.9 VMwareWorkstationarchitecture.
moves the guest system. Such capabilities, as explained earlier, can improve
theefficiencyofsystemadministrationaswellassystemresourceuse.
18.7.2 The Java Virtual Machine
Java is a popular object-oriented programming language introduced by Sun
Microsystems in 1995. In addition to a language specification and a large
API library, Java provides a specification for a Java virtual machine, or JVM.
Java therefore is an example of programming-environment virtualization, as
discussedinSection18.5.6.
Java objects are specified with the class construct; a Java program con-
sists of one or more classes. For each Java class, the compiler produces an
architecture-neutralbytecodeoutput(.class)filethatwillrunonanyimple-
mentationoftheJVM.
The JVM is a specification for an abstract computer. It consists of a class
loaderandaJavainterpreterthatexecutesthearchitecture-neutralbytecodes,
as diagrammed in Figure 18.10. The class loader loads the compiled .class
files from both the Java program and the Java API for execution by the Java
interpreter. After a class is loaded, the verifier checks that the .class file is
validJavabytecodeandthatitdoesnotoverfloworunderflowthestack.Italso
ensures that the bytecode does not perform pointer arithmetic, which could
provideillegalmemoryaccess. Ifthe class passesverification, it is runby the
Javainterpreter.TheJVMalsoautomaticallymanagesmemorybyperforming
garbagecollection—thepracticeofreclaimingmemoryfromobjectsnolonger
inuseandreturningittothesystem.Muchresearchfocusesongarbagecollec-
tionalgorithmsforincreasingtheperformanceofJavaprogramsinthevirtual
machine.728 Chapter18 VirtualMachines
Java program Java API
class loader
.class files .class files
Java
interpreter
host system
(Windows, Linux, etc.)
Figure18.10 TheJavavirtualmachine.
The JVM may be implemented in software on top of a host operating
system, such as Windows, Linux, or macOS, or as part of a web browser.
Alternatively,theJVMmaybeimplementedinhardwareonachipspecifically
designed to run Java programs. If the JVM is implemented in software, the
Java interpreter interprets the bytecode operations one at a time. A faster
software technique is to use a just-in-time (JIT) compiler. Here, the first time
aJavamethodisinvoked,thebytecodesforthemethodareturnedintonative
machinelanguageforthehostsystem.Theseoperationsarethencachedsothat
subsequent invocations of a method are performed using the native machine
instructions, and the bytecode operations need not be interpreted all over
again.RunningtheJVMinhardwareispotentiallyevenfaster.Here,aspecial
JavachipexecutestheJavabytecodeoperationsasnativecode,thusbypassing
theneedforeitherasoftwareinterpreterorajust-in-timecompiler.
18.8 Virtualization Research
Asmentionedearlier,machinevirtualizationhasenjoyedgrowingpopularity
inrecentyearsasameansofsolvingsystemcompatibilityproblems.Research
has expanded to cover many other uses of machine virtualization, including
support for microservices running on library operating systems and secure
partitioning of resources in embedded systems. Consequently, quite a lot of
interesting,activeresearchisunderway.
Frequently, in the context of cloud computing, the same application
is run on thousands of systems. To better manage those deployments,
they can be virtualized. But consider the execution stack in that case—the
application on top of a service-rich general-purpose operating system within
a virtual machine managed by a hypervisor. Projects like unikernels, built
onlibraryoperatingsystems,aimtoimproveefficiencyandsecurityinthese
environments.Unikernelsarespecializedmachineimages,usingoneaddress
space, that shrink the attack surface and resource footprint of deployed
applications. In essence, they compile the application, the system libraries it
calls, and the kernel services it uses into a single binary that runs within a
virtual environment (or even on bare metal). While research into changing
howoperatingsystemkernels,hardware,andapplicationsinteractisnotnew
(see https://pdos.csail.mit.edu/6.828/2005/readings/engler95exokernel.pdf,18.9 Summary 729
for example), cloud computing and virtualization have created renewed
interestinthearea.Seehttp://unikernel.orgformoredetails.
The virtualization instructions in modern CPUs have given rise to a new
branchofvirtualizationresearchfocusingnotonmoreefficientuseofhardware
butratheronbettercontrolofprocesses.Partitioninghypervisorspartitionthe
existingmachinephysicalresourcesamongstguests,therebyfullycommitting
rather than overcommitting machine resources. Partitioning hypervisors can
securelyextend the features of an existing operating system viafunctionality
inanotheroperatingsystem(runinaseparateguestVMdomain),runningon
a subset of machine physical resources. This avoids the tedium of writing an
entire operating system from scratch. For example,a Linux system that lacks
real-timecapabilitiesforsafety-andsecurity-criticaltaskscanbeextendedwith
alightweight real-timeoperating systemrunning inits own virtual machine.
Traditionalhypervisorshavehigheroverheadthanrunningnativetasks,soa
newtypeofhypervisorisneeded.
Eachtaskrunswithinavirtualmachine,butthehypervisoronlyinitializes
thesystemandstartsthetasksandisnotinvolvedwithcontinuingoperation.
Eachvirtualmachinehasitsownallocatedhardwareandisfreetomanagethat
hardware without interference from the hypervisor. Because the hypervisor
doesnotinterrupttaskoperationsandisnotcalledbythetasks,thetaskscan
havereal-timeaspectsandcanbemuchmoresecure.
Within the class of partitioning hypervisors are the Quest-V, eVM,
Xtratum and Siemens Jailhouse projects. These are separation hypervisors
(see http://www.csl.sri.com/users/rushby/papers/sosp81.pdf) that use
virtualization to partition separate system components into a chip-level
distributed system. Secure shared memory channels are then implemented
using hardware extended page tables so that separate sandboxed guests
can communicate with one another. The targets of these projects are
areas such as robotics, self-driving cars, and the Internet of Things. See
https://www.cs.bu.edu/richwest/papers/west-tocs16.pdfformoredetails.
18.9 Summary
• Virtualization is a method for providing a guest with a duplicate of a
system’sunderlyinghardware.Multipleguestscanrunonagivensystem,
eachbelievingthatitisthenativeoperatingsystemandisinfullcontrol.
• Virtualization started as a method to allow IBM to segregate users and
providethemwiththeirownexecutionenvironmentsonIBMmainframes.
Sincethen, thanks toimprovementsinsystemandCPUperformanceand
innovativesoftwaretechniques,virtualizationhasbecomeacommonfea-
ture in datacenters and evenon personal computers.Because of its pop-
ularity,CPUdesignershaveaddedfeaturestosupportvirtualization.This
snowball effectislikelytocontinue, withvirtualizationanditshardware
supportincreasingovertime.
• The virtual machine manager, or hypervisor,creates and runs the virtual
machine.Type0hypervisorsareimplementedinthehardwareandrequire
modifications to the operating system to ensure proper operation. Some730 Chapter18 VirtualMachines
type 0 hypervisors offer an example of paravirtualization, in which the
operatingsystemisawareofvirtualizationandassistsinitsexecution.
• Type 1 hypervisors provide the environment and features needed to cre-
ate, run, and manage guest virtual machines. Each guest includes all of
the software typically associated with a full native system, including the
operatingsystem,devicedrivers,applications,useraccounts,andsoon.
• Type 2 hypervisors are simply applications that run on other operating
systems, which do not know that virtualization is taking place. These
hypervisors do not have hardware or host support so must perform all
virtualizationactivitiesinthecontextofaprocess.
• Programming-environment virtualization is part of the design of a pro-
gramming language. The language specifies a containing application in
which programs run, and this application provides services to the pro-
grams.
• Emulationisusedwhenahostsystemhasonearchitectureandtheguest
was compiled for a different architecture. Every instruction the guest
wants to execute must be translated from its instruction set to that of
the native hardware. Although this method involves some performance
penalty,itisbalancedbytheusefulnessofbeingabletorunoldprograms
onnewer,incompatiblehardwareorrungamesdesignedforoldconsoles
onmodernhardware.
• Implementing virtualization is challenging, especially when hardware
supportisminimal.Themorefeaturesprovidedbythesystem,theeasier
virtualizationistoimplementandthebettertheperformanceoftheguests.
• VMMs take advantage of whatever hardware support is available when
optimizing CPU scheduling, memory management, and I/O modules to
provideguestswithoptimumresourceusewhileprotectingtheVMMfrom
theguestsandtheguestsfromoneanother.
• Currentresearchisextendingtheusesofvirtualization.Unikernelsaimto
increase efficiency and decrease security attack surface by compiling an
application, its libraries, and the kernel resources the application needs
intoonebinarywithoneaddressspacethatrunswithinavirtualmachine.
Partitioning hypervisors provide secure execution, real-time operation,
andotherfeaturestraditionallyonlyavailabletoapplicationsrunningon
dedicatedhardware.
Further Reading
TheoriginalIBMvirtualmachineisdescribedin[MeyerandSeawright(1970)].
[Popek and Goldberg (1974)] established the characteristics that help define
VMMs. Methods of implementing virtual machines are discussed in [Agesen
etal.(2010)].
Intel x86 hardware virtualization support is described in [Neiger et al.
(2006)]. AMD hardware virtualization support is described in a white paper
availableathttp://developer.amd.com/assets/NPT-WP-1%201-final-TM.pdf.Bibliography 731
Memory management in VMware is described in [Waldspurger (2002)].
[Gordon et al. (2012)] propose a solution to the problem of I/O overhead in
virtualized environments. Some protection challenges and attacks in virtual
environmentsarediscussedin[WojtczukandRuthkowska(2011)].
Forearlyworkonalternativekerneldesigns,seehttps://pdos.csail.mit.edu
/6.828/2005/readings/engler95exokernel.pdf. For more on unikernels, see
[West et al. (2016)] and http://unikernel.org. Partitioning hypervisors are dis-
cussed in http://ethdocs.org/en/latest/introduction/what-is-ethereum.html,
andhttps://lwn.net/Articles/578295and[Madhavapeddyetal.(2013)].Quest-
V,aseparationhypervisor,isdetailedinhttp://www.csl.sri.com/users/rushby/
papers/sosp81.pdfandhttps://www.cs.bu.edu/richwest/papers/west-tocs16
.pdf.
Theopen-sourceVirtualBoxprojectisavailablefromhttp://www.virtualbox
.org.ThesourcecodeforLXCisavailableathttps://linuxcontainers.org/lxc/dow
nloads.
Formoreondocker,seehttps://www.docker.com/what-docker.Informa-
tionaboutKubernetescanbefoundathttps://kubernetes.io/docs/concepts/ov
erview/what-is-kubernetes.
Bibliography
[Agesenetal.(2010)] O. Agesen, A. Garthwaite, J. Sheldon, and P. Subrah-
manyam,“TheEvolutionofanx86VirtualMachineMonitor”,Proceedingsofthe
ACMSymposiumonOperatingSystemsPrinciples(2010),pages3–18.
[Gordonetal.(2012)] A.Gordon,N.A.N.Har’El,M.Ben-Yehuda,A.Landau,
A.Schuster,andD.Tsafrir,“ELI:Bare-metalPerformanceforI/OVirtualization”,
ProceedingsoftheInternationalConferenceonArchitecturalSupportforProgramming
LanguagesandOperatingSystems(2012),pages411–422.
[Madhavapeddyetal.(2013)] A.Madhavapeddy,R.Mirtier,C.Rotsos,D.Scott,
B.Singh,T.Gazagnaire,S.Smith,S.Hand,andJ.Crowcroft,“Unikernels:Library
OperatingSystemsfortheCloud”(2013).
[MeyerandSeawright(1970)] R. A. Meyer and L. H. Seawright, “A Virtual
Machine Time-Sharing System”, IBM Systems Journal, Volume 9, Number 3
(1970),pages199–218.
[Neigeretal.(2006)] G.Neiger,A.Santoni,F.Leung,D.Rodgers,andR.Uhlig,
“IntelVirtualizationTechnology:HardwareSupportforEfficientProcessorVir-
tualization”,IntelTechnologyJournal,Volume10,(2006).
[PopekandGoldberg(1974)] G.J.PopekandR.P.Goldberg,“FormalRequire-
mentsforVirtualizableThirdGenerationArchitectures”,Communicationsofthe
ACM,Volume17,Number7(1974),pages412–421.
[Waldspurger(2002)] C. Waldspurger, “Memory Resource Management in
VMware ESX Server”,Operating Systems Review, Volume 36, Number 4 (2002),
pages181–194.
[Westetal.(2016)] R. West, Y. Li, E. Missimer, and M. Danish, “AVirtualized
SeparationKernelforMixedCriticalitySystems”,Volume34,(2016).732 Chapter18 VirtualMachines
[WojtczukandRuthkowska(2011)] R. Wojtczuk and J. Ruthkowska, “Follow-
ing the White Rabbit: Software Attacks Against Intel VT-d Technology”, The
InvisibleThingsLab’sblog(2011).EX-55
Chapter 18 Exercises
18.1 Describethethreetypesoftraditionalhypervisors.
18.2 Describefourvirtualization-likeexecutionenvironments,andexplain
howtheydifferfrom“true”virtualization.
18.3 Describefourbenefitsofvirtualization.
18.4 Why are VMMs unable to implement trap-and-emulate-based virtual-
ization on some CPUs? Lacking the ability to trap and emulate, what
methodcanaVMMusetoimplementvirtualization?
18.5 Whathardwareassistanceforvirtualizationcanbeprovidedbymod-
ernCPUs?
18.6 Why is livemigration possible in virtual environmentsbut much less
possibleforanativeoperatingsystem?Networks and
19
CHAPTER
Distributed
Systems
Updatedby SarahDiesburg
Adistributed system is a collection of processors that do not share memory
oraclock.Instead,eachnodehasitsownlocalmemory.Thenodescommuni-
cate with one another through various networks, such as high-speed buses.
Distributed systems are more relevant than ever, and you have almost cer-
tainly used some sort of distributed service. Applications of distributed sys-
temsrangefromprovidingtransparentaccesstofilesinsideanorganization,to
large-scalecloudfileandphotostorageservices,tobusinessanalysisoftrends
onlargedatasets,toparallelprocessingofscientificdata,andmore.Infact,the
mostbasicexampleofadistributedsystemisonewearealllikelyveryfamiliar
with—theInternet.
In this chapter, we discuss the general structure of distributed systems
and the networks that interconnect them. We also contrast the main differ-
encesinthetypesandrolesofcurrentdistributedsystemdesigns.Finally,we
investigatesomeofthebasicdesignsanddesignchallengesofdistributedfile
systems.
CHAPTER OBJECTIVES
• Explaintheadvantagesofnetworkedanddistributedsystems.
• Provideahigh-leveloverviewofthenetworksthatinterconnectdistributed
systems.
• Definetherolesandtypesofdistributedsystemsinusetoday.
• Discussissuesconcerningthedesignofdistributedfilesystems.
19.1 Advantages of Distributed Systems
Adistributed system is a collection of loosely coupled nodes interconnected
by a communication network. From the point of view of a specific node in
a distributed system, the rest of the nodes and their respective resources are
remote,whereasitsownresourcesarelocal.
733734 Chapter19 NetworksandDistributedSystems
site A site C
server
network
resources
communication
client
site B
Figure19.1 Aclient-serverdistributedsystem.
The nodes in a distributed system may vary in size and function. They
may include small microprocessors, personal computers, and large general-
purpose computer systems. These processors are referred to by a number of
names, such as processors, sites, machines, and hosts, depending on the context
in which they are mentioned. We mainly use site to indicate the location of a
machine and node to refer to a specific system at a site. Nodes can exist in a
client–serverconfiguration,apeer-to-peerconfiguration,orahybridofthese.In
thecommonclient-serverconfiguration,onenodeatonesite,theserver,hasa
resource that another node, the client (or user), would like to use. Ageneral
structure of a client–server distributed system is shown in Figure 19.1. In a
peer-to-peer configuration, there are no servers or clients. Instead, the nodes
shareequalresponsibilitiesandcanactasbothclientsandservers.
Whenseveralsitesareconnectedtooneanotherbyacommunicationnet-
work,usersatthevarioussiteshavetheopportunitytoexchangeinformation.
At a low level,messages are passed between systems, much as messagesare
passed between processes in the single-computer message system discussed
inSection3.4.Givenmessagepassing,allthehigher-levelfunctionalityfound
instandalonesystemscanbeexpandedtoencompassthedistributedsystem.
Suchfunctionsincludefilestorage,executionofapplications,andremotepro-
cedurecalls(RPCs).
There are three major reasons for building distributed systems: resource
sharing, computational speedup, and reliability. In this section, we briefly
discusseachofthem.
19.1.1 Resource Sharing
Ifanumberofdifferentsites(withdifferentcapabilities)areconnectedtoone
another, then a user at one site may be able to use the resources available
at another. For example, a user at site A may query a database located at
site B. Meanwhile, a user at site B may access a file that resides at site A. In
general, resource sharing in a distributed system provides mechanisms for19.2 NetworkStructure 735
sharingfilesatremotesites,processinginformationinadistributeddatabase,
printingfilesatremotesites,usingremotespecializedhardwaredevicessuch
asasupercomputeroragraphicsprocessingunit(GPU),andperformingother
operations.
19.1.2 Computation Speedup
If a particular computation can be partitioned into subcomputations that can
run concurrently, then a distributed system allows us to distribute the sub-
computations among the various sites.The subcomputations can be runcon-
currently and thus providecomputation speedup.This is especially relevant
when doing large-scale processing of big data sets (such as analyzing large
amounts of customer data for trends). In addition, if a particular site is cur-
rently overloaded with requests, some of them can be moved or rerouted to
other,morelightlyloadedsites.Thismovementofjobsiscalledloadbalancing
andiscommonamongdistributedsystemnodesandotherservicesprovided
ontheInternet.
19.1.3 Reliability
Ifonesitefailsinadistributedsystem,theremainingsitescancontinueoper-
ating, giving the systembetter reliability.If the systemis composed of multi-
ple large autonomous installations (that is, general-purpose computers), the
failure of one of them should not affect the rest. If, however, the system is
composedofdiversifiedmachines,eachofwhichisresponsibleforsomecru-
cial system function (such as the web server or the file system), then a single
failure may halt the operation of the whole system. In general, with enough
redundancy (in both hardware and data), the system can continue operation
evenifsomeofitsnodeshavefailed.
The failure of a node or site must be detected by the system, and appro-
priate action may be needed to recover from the failure. The system must no
longerusetheservicesofthatsite.Inaddition,ifthefunctionofthefailedsite
canbetakenoverbyanothersite,thesystemmustensurethatthetransferof
function occurs correctly. Finally, when the failed site recovers or is repaired,
mechanismsmustbeavailabletointegrateitbackintothesystemsmoothly.
19.2 Network Structure
To completely understand the roles and types of distributed systems in use
today,weneedtounderstandthenetworksthatinterconnectthem.Thissection
servesas anetwork primertointroduce basicnetworking concepts and chal-
lengesastheyrelatetodistributedsystems.Therestofthechapterspecifically
discussesdistributedsystems.
Therearebasicallytwotypesofnetworks:local-areanetworks(LAN)and
wide-areanetworks(WAN).Themaindifferencebetweenthetwoisthewayin
whichtheyaregeographicallydistributed.Local-areanetworksarecomposed
of hosts distributed over small areas (such as a single building or a number
ofadjacentbuildings),whereaswide-areanetworksarecomposedofsystems
distributed over a large area (such as the United States). These differences736 Chapter19 NetworksandDistributedSystems
Router WAN Link
Wireless Access
Point
LAN WAN
Figure19.2 Local-areanetwork.
imply major variations in the speed and reliability of the communications
networks,andtheyarereflectedinthedistributedsystemdesign.
19.2.1 Local-Area Networks
Local-area networks emerged in the early 1970s as a substitute for large
mainframe computer systems. For many enterprises, it is more economi-
cal to have a number of small computers, each with its own self-contained
applications, than to have a single large system. Because each small com-
puteris likelytoneed afull complement ofperipheraldevices(such as disks
and printers), and because some form of data sharing is likely to occur in a
single enterprise, it was a natural step to connect these small systems into a
network.
LANs, as mentioned, are usually designed to cover a small geographical
area, and they are generally used in an office or home environment. All the
sitesinsuchsystemsareclosetooneanother,sothecommunicationlinkstend
tohaveahigherspeedandlowererrorratethantheircounterpartsinwide-area
networks.
A typical LAN may consist of a number of different computers (includ-
ing workstations, servers, laptops, tablets, and smartphones), various shared
peripheral devices (such as printers and storage arrays), and one or more
routers (specialized network communication processors) that provide access
toothernetworks(Figure19.2).EthernetandWiFiarecommonlyusedtocon-
struct LANs. Wireless access points connect devices to the LAN wirelessly, and
theymayormaynotberoutersthemselves.
Ethernet networks are generally found in businesses and organizations
in which computers and peripherals tend to be nonmobile. These networks
use coaxial, twisted pair, and/or fiber optic cables to send signals. An Ethernet
networkhasnocentralcontroller,becauseitisamultiaccessbus,sonewhosts
canbeaddedeasilytothenetwork.TheEthernetprotocolisdefinedbytheIEEE
802.3 standard. Typical Ethernet speeds using common twisted-pair cabling19.2 NetworkStructure 737
canvaryfrom 10Mbpstoover10Gbps, withothertypesofcabling reaching
speedsof100Gbps.
WiFi is now ubiquitous and either supplements traditional Ethernet net-
works or exists by itself. Specifically, WiFi allows us to construct a network
withoutusingphysicalcables.Eachhosthasawirelesstransmitterandreceiver
that it uses to participate in the network. WiFi is defined by the IEEE 802.11
standard.Wirelessnetworks are popular in homes and businesses, as well as
publicareassuchaslibraries,Internetcafes,sportsarenas,andevenbusesand
airplanes.WiFispeedscanvaryfrom11Mbpstoover400Mbps.
Both the IEEE 802.3 and 802.11 standards are constantly evolving. For the
latestinformationaboutvariousstandardsandspeeds,seethereferencesatthe
endofthechapter.
19.2.2 Wide-Area Networks
Wide-areanetworksemergedinthelate1960s,mainlyasanacademicresearch
project to provide efficient communication among sites, allowing hardware
andsoftwaretobesharedconveniently andeconomically byawidecommu-
nityof users.Thefirst WAN tobe designedand developedwas the ARPANET.
Begunin1968,theARPANEThasgrownfromafour-siteexperimentalnetwork
to a worldwide network of networks, the Internet (also known as the World
WideWeb),comprisingmillionsofcomputersystems.
Sites in a WAN are physically distributed over a large geographical area.
Typical links are telephone lines, leased (dedicated data) lines, optical cable,
microwave links, radio waves, and satellite channels. These communication
links are controlled by routers (Figure 19.3) that are responsible for directing
traffictoother routersand networksand transferringinformationamong the
varioussites.
For example, the Internet WAN enables hosts at geographically separate
sites to communicate with one another. The host computers typically differ
from one another in speed, CPU type, operating system, and so on. Hosts are
user processes
network host
host operating system
communication
subsystem
(network)
R
H network host
H R R
H
R
router
H
Figure19.3 Communicationprocessorsinawide-areanetwork.738 Chapter19 NetworksandDistributedSystems
generally on LANs, which are, in turn, connected to the Internet via regional
networks. The regional networks are interlinked with routers to form the
worldwide network. Residences can connect to the Internet by either tele-
phone, cable, or specialized Internet service providers that install routers to
connect the residences to central services. Of course, there are other WANs
besidestheInternet.Acompany,forexample,mightcreateitsownprivateWAN
forincreasedsecurity,performance,orreliability.
WANs are generally slower than LANs, although backbone WAN connec-
tionsthatlinkmajorcitiesmayhaveveryfasttransferratesthroughfiberoptic
cables. In fact, many backbone providers have fiber optic speeds of 40 Gbps
or 100 Gbps. (It is generally the links from local Internet Service Providers
(ISPs)tohomesorbusinessesthatslowthingsdown.)However,WANlinksare
beingconstantlyupdatedtofastertechnologiesasthedemandformorespeed
continuestogrow.
Frequently, WANs and LANs interconnect, and it is difficult to tell where
oneendsandtheotherstarts.Considerthecellularphonedatanetwork.Cell
phones are used for both voice and data communications. Cell phones in a
given area connect via radio waves to a cell tower that contains receivers
and transmitters. This part of the network is similar to a LAN except that the
cell phones do not communicate with each other (unless two people talking
or exchanging data happen to be connected to the same tower). Rather, the
towers are connected to other towers and to hubs that connect the tower
communications to land lines or other communication media and route the
packetstowardtheirdestinations.ThispartofthenetworkismoreWAN-like.
Oncetheappropriatetowerreceivesthepackets,itusesitstransmitterstosend
themtothecorrectrecipient.
19.3 Communication Structure
Nowthatwehavediscussedthephysicalaspectsofnetworking,weturntothe
internalworkings.
19.3.1 Naming and Name Resolution
Thefirstissueinnetworkcommunicationinvolvesthenamingofthesystems
inthenetwork.ForaprocessatsiteAtoexchangeinformationwithaprocess
at site B, each must be able to specify the other. Within a computer system,
eachprocesshasaprocessidentifier,andmessagesmaybeaddressedwiththe
process identifier. Because networked systems share no memory, however, a
hostwithinthesysteminitiallyhasnoknowledgeabouttheprocessesonother
hosts.
Tosolvethisproblem,processesonremotesystemsaregenerallyidentified
bythepair<hostname,identifier>,wherehostnameisanameuniquewithin
the network and identifie is a process identifier or other unique number
withinthathost.Ahostnameisusuallyanalphanumericidentifier,ratherthan
anumber,tomakeiteasierforuserstospecify.Forinstance,siteAmighthave
hostsnamedprogram,student,faculty,andcs.Thehostnameprogramiscertainly
easiertorememberthanthenumerichostaddress128.148.31.100.19.3 CommunicationStructure 739
Names are convenient for humans to use, but computers prefer numbers
forspeedandsimplicity.Forthisreason,theremustbeamechanismtoresolve
the host name into a host-id that describes the destination system to the net-
working hardware. This mechanism is similar to the name-to-address bind-
ing that occurs during program compilation, linking, loading, and execution
(Chapter9).Inthecaseofhostnames,twopossibilitiesexist.First,everyhost
may have a data file containing the names and numeric addresses of all the
otherhostsreachableonthenetwork(similartobindingatcompiletime).The
problemwiththismodelisthat addingorremovingahostfromthenetwork
requires updating the data files on all the hosts. In fact, in the early days of
the ARPANET there was a canonical host file that was copied to every system
periodically.Asthenetworkgrew,however,thismethodbecameuntenable.
The alternative is to distribute the information among systems on the
network.Thenetworkmust thenuseaprotocoltodistributeand retrievethe
information. This scheme is like execution-time binding. The Internet uses a
domain-namesystem(DNS)forhost-nameresolution.
DNSspecifiesthenamingstructureofthehosts,aswellasname-to-address
resolution.HostsontheInternetarelogicallyaddressedwithmultipartnames
known as IP addresses. The parts of an IP address progress from the most
specific to the most general, with periods separating the fields. For instance,
eric.cs.yale.edureferstohostericintheDepartmentofComputerScienceatYale
Universitywithinthetop-leveldomainedu.(Othertop-leveldomainsinclude
comforcommercialsitesandorgfororganizations,aswellasadomainforeach
countryconnectedtothenetworkforsystemsspecifiedbycountryratherthan
organizationtype.)Generally,thesystemresolvesaddressesbyexaminingthe
host-namecomponentsinreverseorder.Eachcomponenthasanameserver—
simplyaprocessonasystem—thatacceptsanameandreturnstheaddressof
the name serverresponsiblefor that name. As the final step,the name server
for the host in question is contacted, and a host-id is returned. For example,
arequestmadebyaprocessonsystemAtocommunicatewitheric.cs.yale.edu
wouldresultinthefollowingsteps:
1. ThesystemlibraryorthekernelonsystemAissuesarequesttothename
server for the edu domain, asking for the address of the name server
for yale.edu. The name server for the edu domain must be at a known
address,sothatitcanbequeried.
2. The edu name server returns the address of the host on which the
yale.edunameserverresides.
3. System A then queries the name server at this address and asks about
cs.yale.edu.
4. An address is returned. Now, finally, a request to that address for
eric.cs.yale.edureturnsanInternetaddresshost-idforthathost(for
example,128.148.31.100).
Thisprotocolmayseeminefficient,butindividualhostscachetheIPaddresses
they have already resolved to speed the process. (Of course, the contents of
these caches must be refreshed over time in case the name server is moved740 Chapter19 NetworksandDistributedSystems
/**
* Usage: java DNSLookUp <IP name>
* i.e. java DNSLookUp www.wiley.com
*/
public class DNSLookUp {
public static void main(String[] args) {
InetAddress hostAddress;
try {
hostAddress = InetAddress.getByName(args[0]);
System.out.println(hostAddress.getHostAddress());
}
catch (UnknownHostException uhe) {
System.err.println("Unknown host: " + args[0]);
}
}
}
Figure19.4 JavaprogramillustratingaDNSlookup.
or its address changes.) In fact, the protocol is so important that it has been
optimized many times and has had many safeguards added. Consider what
would happen if the primary edu name server crashed. It is possible that
no edu hosts would be able to have their addresses resolved, making them
all unreachable! The solution is to use secondary, backup name servers that
duplicatethecontentsoftheprimaryservers.
Beforethedomain-nameservicewasintroduced,allhostsontheInternet
needed to have copies of a file (mentioned above) that contained the names
and addresses of each host on the network. All changes to this file had to
be registeredat one site (host SRI-NIC), and periodicallyall hosts had to copy
the updated file from SRI-NIC to be able to contact new systems or find hosts
whose addresses had changed. Under the domain-name service, each name-
server site is responsible for updating the host information for that domain.
For instance, any host changes at YaleUniversityare theresponsibilityof the
nameserverforyale.eduandneednotbereportedanywhereelse.DNSlookups
willautomaticallyretrievetheupdatedinformationbecausetheywillcontact
yale.edu directly. Domains may contain autonomous subdomains to further
distributetheresponsibilityforhost-nameandhost-idchanges.
Java provides the necessary API to design a program that maps IP names
toIPaddresses.TheprogramshowninFigure19.4ispassedanIPname(such
aseric.cs.yale.edu)onthecommandlineandeitheroutputstheIPaddressofthe
hostorreturnsamessageindicatingthatthehostnamecouldnotberesolved.
AnInetAddressisaJavaclassrepresentinganIPnameoraddress.Thestatic
method getByName() belonging to the InetAddress class is passed a string
representationofan IPname, and itreturnsthe correspondingInetAddress.
The program then invokes the getHostAddress() method, which internally
usesDNStolookuptheIPaddressofthedesignatedhost.19.3 CommunicationStructure 741
Generally, the operating system is responsible for accepting from its pro-
cessesamessagedestinedfor<hostname,identifier>andfortransferringthat
message to the appropriate host. The kernel on the destination host is then
responsiblefortransferringthemessagetotheprocessnamedbytheidentifier.
ThisprocessisdescribedinSection19.3.4.
19.3.2 Communication Protocols
When we are designing a communication network, we must deal with the
inherentcomplexityofcoordinatingasynchronousoperationscommunicating
in a potentially slow and error-prone environment. In addition, the systems
on the network must agree on a protocol or a set of protocols for determin-
ing host names, locating hosts on the network, establishing connections, and
so on. We can simplify the design problem (and related implementation) by
partitioningtheproblemintomultiplelayers.Eachlayeronone systemcom-
municates with the equivalent layer on other systems. Typically, each layer
has its own protocols, and communication takes place between peer layers
using a specific protocol. The protocols may be implemented in hardware or
software.Forinstance,Figure19.5showsthelogicalcommunicationsbetween
twocomputers,withthethreelowest-levellayersimplementedinhardware.
TheInternationalStandardsOrganizationcreatedtheOpenSystemsInter-
connection(OSI)modelfordescribingthevariouslayersofnetworking.While
theselayersarenotimplementedinpractice,theyareusefulforunderstanding
hownetworkinglogicallyworks,andwedescribethembelow:
• Layer1:Physicallayer.Thephysicallayerisresponsibleforhandlingboth
themechanical andtheelectricaldetailsofthephysicaltransmissionofa
bit stream. At the physical layer, the communicating systems must agree
ontheelectricalrepresentationofabinary 0and1,sothatwhendataare
sentasastreamofelectricalsignals,thereceiverisabletointerpretthedata
computer A computer B
AP AP
application layer A-L (7)
presentation layer P-L (6)
session layer S-L (5)
transport layer T-L (4)
network layer N-L (3)
link layer L-L (2)
physical layer P-L (1)
data network
network environment
OSI environment
real systems environment
Figure19.5 TwocomputerscommunicatingviatheOSInetworkmodel.742 Chapter19 NetworksandDistributedSystems
properlyasbinarydata.Thislayerisimplementedinthehardwareofthe
networkingdevice.Itisresponsiblefordeliveringbits.
• Layer 2: Data-link layer. The data-link layer is responsible for handling
frames,orfixed-lengthpartsofpackets,includinganyerrordetectionand
recoverythatoccurinthephysicallayer.Itsendsframesbetweenphysical
addresses.
• Layer3:Networklayer.Thenetworklayerisresponsibleforbreakingmes-
sagesintopackets,providingconnectionsbetweenlogicaladdresses,and
routing packets in the communication network, including handling the
addressesofoutgoingpackets,decodingtheaddressesofincomingpack-
ets,andmaintainingroutinginformationforproperresponsetochanging
loadlevels.Routersworkatthislayer.
• Layer4:Transportlayer.Thetransportlayerisresponsiblefortransferof
messagesbetweennodes,maintainingpacketorder,and controllingflow
toavoidcongestion.
• Layer5:Sessionlayer.Thesessionlayerisresponsibleforimplementing
sessions,orprocess-to-processcommunicationprotocols.
• Layer 6: Presentation layer. The presentation layer is responsible for
resolving the differences in formats among the various sites in the net-
work,includingcharacterconversionsandhalfduplex–fullduplexmodes
(characterechoing).
• Layer7: Applicationlayer.The applicationlayeris responsiblefor inter-
actingdirectlywithusers.Thislayerdealswithfiletransfer,remote-login
protocols, and electronic mail, as well as with schemas for distributed
databases.
Figure19.6summarizestheOSIprotocolstack—asetofcooperatingpro-
tocols—showingthephysicalflowofdata.Asmentioned,logicallyeachlayer
ofaprotocolstackcommunicateswiththeequivalentlayeronothersystems.
Butphysically,amessagestartsatorabovetheapplicationlayerandispassed
through each lower level in turn. Each layer may modify the message and
include message-header data for the equivalent layer on the receiving side.
Ultimately, the message reaches the data-network layer and is transferred as
one or more packets (Figure 19.7). The data-link layer of the target system
receivesthesedata,andthemessageismovedupthroughtheprotocolstack.It
isanalyzed,modified,andstrippedofheadersasitprogresses.Itfinallyreaches
theapplicationlayerforusebythereceivingprocess.
TheOSImodelformalizessomeoftheearlierworkdoneinnetworkproto-
colsbutwasdevelopedinthelate1970sandiscurrentlynotinwidespreaduse.
Perhaps the most widely adopted protocol stack is the TCP/IP model (some-
timescalledtheInternetmodel),whichhasbeenadoptedbyvirtuallyallInternet
sites.TheTCP/IPprotocolstackhasfewerlayersthantheOSImodel.Theoreti-
cally,becauseitcombinesseveralfunctionsineachlayer,itismoredifficultto
implement but more efficient than OSI networking. The relationship between
theOSIandTCP/IPmodelsisshowninFigure19.8.
TheTCP/IPapplicationlayeridentifiesseveralprotocolsinwidespreaduse
in the Internet, including HTTP, FTP, SSH, DNS, and SMTP. The transport layer19.3 CommunicationStructure 743
end-user application process
distributed information
services
file transfer, access, and management;
document and message interchange, application layer
job transfer and manipulation
syntax-independent message
interchange service
transfer-syntax negotiation
presentation layer
data-representation transformations
dialog and synchronization
session layer
control for application entities
network-independent
message-interchange service
end-to-end message transfer
(connection management, error control, transport layer
fragmentation, flow control)
network routing, addressing,
network layer
call setup and clearing
data-link control
link layer
(framing, data transparency, error control)
mechanical and electrical
physical layer
network-interface connections
physical connection to
network termination equipment
data-communication network
Figure19.6 TheOSIprotocolstack.
identifiestheunreliable,connectionlessuserdatagramprotocol(UDP)andthe
reliable, connection-oriented transmission control protocol (TCP). The Inter-
net protocol (IP) is responsible for routing IP datagrams, or packets, through
the Internet. The TCP/IP model does not formally identify a link or physical
layer, allowing TCP/IP traffic to run across any physical network. In Section
19.3.3,weconsidertheTCP/IPmodelrunningoveranEthernetnetwork.
Security should be a concern in the design and implementation of any
modern communication protocol. Both strong authentication and encryption
are neededfor secure communication. Strong authentication ensures that the
sender and receiver of a communication are who or what they are supposed
tobe.Encryptionprotectsthecontentsofthecommunicationfromeavesdrop-
ping. Weak authentication and clear-text communication are still very com-
mon, however, for a variety of reasons. When most of the common protocols
weredesigned,securitywasfrequentlylessimportantthanperformance,sim-744 Chapter19 NetworksandDistributedSystems
data-link-layer header
network-layer header
transport-layer header
session-layer header
presentation layer
application layer
message
data-link-layer trailer
Figure19.7 AnOSInetworkmessage.
plicity,andefficiency.Thislegacyisstillshowingitselftoday,asaddingsecurity
toexistinginfrastructureisprovingtobedifficultandcomplex.
Strongauthenticationrequiresamultistephandshakeprotocolorauthen-
ticationdevices,addingcomplexitytoaprotocol.Astotheencryptionrequire-
ment, modern CPUs can efficiently perform encryption, frequently including
cryptographicaccelerationinstructionssosystemperformanceisnotcompro-
mised. Long-distance communication can be made secure by authenticating
OSI TCP/IP
HTTP, DNS, Telnet
application
SMTP, FTP
presentation not defined
session not defined
transport TCP-UDP
network IP
data link not defined
physical not defined
Figure19.8 TheOSIandTCP/IPprotocolstacks.19.3 CommunicationStructure 745
the endpoints and encrypting the stream of packets in a virtual private net-
work,asdiscussedinSection16.4.2.LANcommunicationremainsunencrypted
atmostsites,butprotocolssuchasNFSVersion4,whichincludesstrongnative
authenticationandencryption,shouldhelpimproveevenLANsecurity.
19.3.3 TCP/IP Example
Next,weaddressnameresolutionandexamineitsoperationwithrespecttothe
TCP/IPprotocolstackontheInternet.Thenweconsidertheprocessingneeded
totransferapacketbetweenhostsondifferentEthernetnetworks.Webaseour
description on the IPV4 protocols, which are the type most commonly used
today.
InaTCP/IPnetwork,everyhosthasanameandanassociatedIPaddress(or
host-id).Bothofthesestringsmustbeunique;andsothatthenamespacecan
bemanaged,theyaresegmented.Asdescribedearlier,thenameishierarchical,
describing the host name and then the organization with which the host is
associated.Thehost-idissplitintoanetworknumberandahostnumber.The
proportionofthesplitvaries,dependingonthesizeofthenetwork.Oncethe
Internetadministratorsassignanetworknumber,thesitewiththatnumberis
freetoassignhost-ids.
Thesendingsystemchecksitsroutingtablestolocatearoutertosendthe
frameonitsway.Thisroutingtableiseitherconfiguredmanuallybythesystem
administratororispopulatedbyoneofseveralroutingprotocols,suchasthe
BorderGatewayProtocol(BGP).Theroutersusethenetworkpartofthehost-
id to transfer the packet from its source network to the destination network.
Thedestinationsystemthenreceivesthepacket.Thepacketmaybeacomplete
message,oritmayjustbeacomponentofamessage,withmorepacketsneeded
beforethemessagecanbereassembledandpassedtotheTCP/UDP(transport)
layerfortransmissiontothedestinationprocess.
Withinanetwork,howdoesapacketmovefromsender(hostorrouter)to
receiver?EveryEthernetdevicehasauniquebytenumber,calledthemedium
accesscontrol(MAC)address,assignedtoitforaddressing.Twodevicesona
LAN communicate with each other only with this number. If a system needs
tosenddatatoanothersystem,thenetworkingsoftwaregeneratesanaddress
resolution protocol (ARP) packet containing the IPaddressof the destination
system.ThispacketisbroadcasttoallothersystemsonthatEthernetnetwork.
A broadcast uses a special network address (usually, the maximum
address) to signal that all hosts should receive and process the packet. The
broadcast is not re-sent by routers in between different networks, so only
systems on the local network receive it. Only the system whose IP address
matches the IP address of the ARP request responds and sends back its MAC
address to the system that initiated the query. For efficiency, the host caches
the IP–MAC address pair in an internal table. The cache entries are aged, so
thatanentryiseventuallyremovedfromthecacheifanaccesstothatsystem
is not required within a given time. In this way, hosts that are removed from
a network are eventually forgotten. For added performance, ARP entries for
heavilyusedhostsmaybepinnedintheARPcache.
Once an Ethernetdevicehas announced its host-id and address,commu-
nication can begin. Aprocess may specify the name of a host with which to
communicate. Networking software takes that name and determines the IP
address of the target, using a DNS lookup or an entry in a local hosts file746 Chapter19 NetworksandDistributedSystems
bytes
7 preamble—start of packet each byte pattern 10101010
1 start of frame delimiter pattern 10101011
2 or 6 destination address Ethernet address or broadcast
2 or 6 source address Ethernet address
2 length of data section length in bytes
0–1500 data message data
0–46 pad (optional) message must be > 63 bytes long
4 frame checksum for error detection
Figure19.9 AnEthernetpacket.
where translations can be manually stored. The message is passed from the
application layer, through the software layers, and to the hardware layer. At
the hardware layer, the packet has the Ethernet address at its start; a trailer
indicatestheendofthepacketandcontainsachecksumfordetectionofpacket
damage (Figure 19.9). The packet is placed on the network by the Ethernet
device. The data section of the packet may contain some or all of the data of
theoriginalmessage,butitmayalsocontainsomeoftheupper-levelheaders
that compose the message. In other words, all parts of the original message
mustbesentfromsourcetodestination,andallheadersabovethe802.3layer
(data-linklayer)areincludedasdataintheEthernetpackets.
If the destination is on the same local network as the source, the system
can look initsARPcache, find the Ethernetaddressofthe host,and place the
packetonthewire.ThedestinationEthernetdevicethenseesitsaddressinthe
packetandreadsinthepacket,passingituptheprotocolstack.
Ifthedestinationsystemisonanetworkdifferentfromthatofthesource,
the source system finds an appropriate router on its network and sends the
packet there. Routers then pass the packet along the WAN until it reaches its
destinationnetwork.Therouterthatconnectsthedestinationnetworkchecks
its ARP cache, finds the Ethernet number of the destination, and sends the
packet to that host. Through all of these transfers, the data-link-layer header
maychangeastheEthernetaddressofthenextrouterinthechainisused,but
the other headers of the packet remain the same until the packet is received
andprocessedbytheprotocolstackandfinallypassedtothereceivingprocess
bythekernel.
19.3.4 Transport Protocols UDP and TCP
OnceahostwithaspecificIPaddressreceivesapacket,itmustsomehowpass
ittothecorrectwaitingprocess.ThetransportprotocolsTCPandUDPidentify
thereceiving(andsending)processesthroughtheuseofaportnumber.Thus,19.3 CommunicationStructure 747
a host with a single IP address can have multiple server processes running
and waiting for packets as long as each server process specifies a different
portnumber.Bydefault,manycommonservicesusewell-knownportnumbers.
SomeexamplesincludeFTP(21),SSH(22),SMTP(25),andHTTP(80).Forexam-
ple,ifyouwishtoconnecttoan“http”websitethroughyourwebbrowser,your
browserwillautomaticallyattempttoconnecttoport80ontheserverbyusing
thenumber80astheportnumberintheTCPtransportheader.Foranextensive
listofwell-knownports,logintoyourfavoriteLinuxorUNIXmachineandtake
alookatthefile/etc/services.
The transport layer can accomplish more than just connecting a network
packettoarunningprocess.Itcanalso,ifdesired,addreliabilitytoanetwork
packet stream. To explain how, we next outline some general behavior of the
transportprotocolsUDPandTCP.
19.3.4.1 UserDatagramProtocol
The transport protocol UDPis unreliable in that it is a bare-bones extension to
IP with the addition of a port number. In fact, the UDP header is very simple
and contains only four fields: source port number, destination port number,
length,andchecksum.PacketsmaybesentquicklytoadestinationusingUDP.
However, since there are no guarantees of delivery in the lower layers of the
networkstack,packetsmaybecomelost.Packetscanalsoarriveatthereceiver
out of order. It is up to the application to figure out these error cases and to
adjust(ornotadjust).
Figure 19.10 illustrates a common scenario involving loss of a packet
between a client and a server using the UDPprotocol. Note that this protocol
is known as a connectionless protocol because there is no connection setup at
thebeginningofthetransmissiontosetupstate—theclientjuststartssending
data.Similarly,thereisnoconnectionteardown.
The client begins by sending some sort of request for information to the
server. The server then responds by sending four datagrams, or packets, to
the client. Unfortunately, one of the packets is dropped by an overwhelmed
router. The client must either make do with only three packets or use logic
programmed into the application to request the missing packet. Thus, we
inital request
for data
server starts sending
data to client
time
dropped packet!
V X
V V
client server
Figure19.10 ExampleofaUDPdatatransferwithdroppedpacket.748 Chapter19 NetworksandDistributedSystems
needtouseadifferenttransportprotocolifwewantanyadditionalreliability
guaranteestobehandledbythenetwork.
19.3.4.2 TransmissionControlProtocol
TCPisatransportprotocolthatisbothreliableandconnection-oriented.Inaddi-
tiontospecifyingportnumberstoidentifysendingandreceivingprocesseson
different hosts, TCP provides an abstraction that allows a sending process on
one host to send an in-order, uninterrupted byte stream across the network to
a receivingprocesson another host. It accomplishes these things through the
followingmechanisms:
• Wheneverahost sendsapacket,thereceivermustsendanacknowledg-
mentpacket,orACK,tonotifythesenderthatthepacketwasreceived.If
the ACK is not received before a timer expires, the sender will send that
packetagain.
• TCP introduces sequence numbers into the TCP header of every packet.
Thesenumbersallowthereceiverto(1)putpacketsinorderbeforesending
datauptotherequestingprocessand(2)beawareofpacketsmissingfrom
thebytestream.
• TCPconnections areinitiatedwithaseriesofcontrolpacketsbetweenthe
sender and the receiver (often called a three-way handshake) and closed
gracefully with control packets responsible for tearing down the connec-
tion.Thesecontrolpacketsallowboththesenderandthereceivertosetup
andremovestate.
Figure19.11demonstratesapossibleexchangeusingTCP(withconnection
setupandtear-downomitted).Aftertheconnection has beenestablished,the
client sends a request packet to the server with the sequence number 904.
UnliketheserverintheUDPexample,theservermustthensendanACKpacket
backtotheclient.Next,theserverstartssendingitsownstreamofdatapackets
startingwithadifferentsequencenumber.TheclientsendsanACKpacketfor
eachdatapacketitreceives.Unfortunately,thedatapacketwiththesequence
number 127 is lost, and no ACK packet is sent by the client. The sender times
out waiting for the ACK packet, so it must resend data packet 127. Later in
the connection, the server sends the data packet with the sequence number
128, but the ACK is lost. Since the server does not receive the ACK it must
resenddatapacket128.Theclientthenreceivesaduplicatepacket.Becausethe
client knows that it previously receiveda packet with that sequence number,
itthrowstheduplicateaway.However,itmustsendanother ACKback tothe
servertoallowtheservertocontinue.
In the actual TCP specification, an ACK isn’t required for each and every
packet. Instead, the receiver can send a cumulative ACK to ACK a series of
packets. The server can also send numerous data packets sequentially before
waitingforACKs,totakeadvantageofnetworkthroughput.
TCP also helps regulate the flow of packets through mechanisms called
flowcontrolandcongestioncontrol.Flowcontrolinvolvespreventingthesender
from overrunning the capacity of the receiver.For example, the receiver may19.4 NetworkandDistributedOperatingSystems 749
inital request
for data
Data,
seq
= 904
time
DA aC taK
,
f so er
q
9 =0 4 126 s de ar tv ae tr
o
s t ca lir ets
n
tsending
V
ACK for 126
Data,
Xseq =
127
timeout waiting
for ACK
retransmit
Data,
seq =
127
ACK for 127
Data,
seq =
128
timeout waiting
for ACK
ACK for 128 retransmit
Data,
X
seq =
128
ACK for 128
V V
client server
Figure19.11 ExampleofaTCPdatatransferwithdroppedpackets.
have a slower connection or may have slower hardware components (like a
slower network card or processor). Flow-control state can be returned in the
ACK packets of the receiver to alert the sender to slow down or speed up.
Congestion control attempts to approximate the state of the networks (and
generallytherouters)betweenthesenderandthereceiver.Ifarouterbecomes
overwhelmedwithpackets,itwilltendtodropthem.Droppingpacketsresults
in ACK timeouts, which results in more packets saturating the network. To
preventthiscondition,thesendermonitorstheconnectionfordroppedpackets
by noticing how many packets are not acknowledged. If there are too many
droppedpackets, the sender will slow down the rate at which it sends them.
This helps ensure that the TCP connection is being fair to other connections
happeningatthesametime.
ByutilizingareliabletransportprotocollikeTCP,adistributedsystemdoes
notneedextralogictodealwithlostorout-of-orderpackets.However,TCPis
slowerthanUDP.
19.4 Network and Distributed Operating Systems
In this section, we describe the two general categories of network-oriented
operatingsystems:networkoperatingsystemsanddistributedoperatingsys-750 Chapter19 NetworksandDistributedSystems
tems.Networkoperatingsystemsaresimplertoimplementbutgenerallymore
difficult for users to access and use than are distributed operating systems,
whichprovidemorefeatures.
19.4.1 Network Operating Systems
A network operating system provides an environment in which users can
access remote resources (implementing resource sharing) by either logging
in to the appropriate remote machine or transferring data from the remote
machinetotheirownmachines.Currently,allgeneral-purposeoperatingsys-
tems, and even embedded operating systems such as Android and iOS, are
networkoperatingsystems.
19.4.1.1 RemoteLogin
An important function of a network operating system is to allow users to
log in remotely. The Internet provides the ssh facility for this purpose. To
illustrate, suppose that a user at Westminster College wishes to compute on
kristen.cs.yale.edu, a computer located at Yale University.To do so, the
user must have a valid account on that machine. To log in remotely, the user
issuesthecommand
ssh kristen.cs.yale.edu
This command results in the formation of an encrypted socket connection
between the local machine at Westminster College and the kris-
ten.cs.yale.edu computer. After this connection has been established,
the networking software creates a transparent, bidirectional link so that all
charactersenteredbytheuseraresenttoaprocessonkristen.cs.yale.edu
and all the output from that process is sent back to the user. The process on
theremotemachineaskstheuserfor aloginnameandapassword.Once the
correctinformationhasbeenreceived,theprocessactsasaproxyfortheuser,
whocancomputeontheremotemachinejustasanylocalusercan.
19.4.1.2 RemoteFileTransfer
Another major function of a network operating system is to provide a mech-
anism for remote fil transfer from one machine to another. In such an envi-
ronment, each computer maintains its own local file system. If a user at one
site(say,Kurtatalbion.edu)wantstoaccessafileownedbyBeccalocatedon
another computer (say, at colby.edu), then the file must be copied explicitly
fromthecomputeratColbyinMainetothecomputeratAlbioninMichigan.
The communication is one-directional and individual, such that other users
at those sites wishing to transfer a file, say Sean at colby.edu to Karen at
albion.edu,mustlikewiseissueasetofcommands.
TheInternetprovidesamechanismforsuchatransferwiththefiletransfer
protocol(FTP)andthemoreprivatesecurefiletransferprotocol(SFTP).Suppose
that userCarlaat wesleyan.eduwants tocopy afile thatis ownedby Owen
atkzoo.edu.Theusermustfirstinvokethesftpprogrambyexecuting
sftp owen@kzoo.edu19.4 NetworkandDistributedOperatingSystems 751
The program then asks the user for a login name and a password. Once the
correctinformationhasbeenreceived,theusercanuseaseriesofcommands
touploadfiles,downloadfiles,andnavigatetheremotefilesystemstructure.
Someofthesecommandsare:
• get—Transferafilefromtheremotemachinetothelocalmachine.
• put—Transferafilefromthelocalmachinetotheremotemachine.
• lsordir—Listfilesinthecurrentdirectoryontheremotemachine.
• cd—Changethecurrentdirectoryontheremotemachine.
Therearealsovariouscommandstochangetransfermodes(forbinaryorASCII
files)andtodetermineconnectionstatus.
19.4.1.3 CloudStorage
Basic cloud-based storage applications allow users to transfer files much as
with FTP. Users can upload files to a cloud server,download files to the local
computer,andsharefileswithothercloud-serviceusersviaaweblinkorother
sharingmechanismthroughagraphicalinterface.Commonexamplesinclude
DropboxandGoogleDrive.
Animportant pointabout SSH, FTP,and cloud-basedstorageapplications
is that they require the user to change paradigms. FTP, for example, requires
theusertoknowacommandsetentirelydifferentfromthenormaloperating-
systemcommands.WithSSH, theusermustknowappropriatecommands on
theremotesystem.Forinstance,auseronaWindowsmachinewhoconnects
remotelytoaUNIXmachinemustswitchtoUNIXcommandsforthedurationof
theSSHsession.(Innetworking,asessionisacompleteroundofcommunica-
tion,frequentlybeginningwithalogintoauthenticateandendingwithalogoff
toterminatethecommunication.)Withcloud-basedstorageapplications,users
may have to log into the cloud service (usually through a web browser) or
native application and then use a series of graphical commands to upload,
download,orsharefiles.Obviously,userswouldfinditmoreconvenientnotto
berequiredtouseadifferentsetofcommands.Distributedoperatingsystems
aredesignedtoaddressthisproblem.
19.4.2 Distributed Operating Systems
In a distributed operating system, users access remote resources in the same
way they access local resources. Data and process migration from one site to
another is under the control of the distributed operating system. Depending
on the goals of the system, it can implement data migration, computation
migration,processmigration,oranycombinationthereof.
19.4.2.1 DataMigration
SupposeauseronsiteAwantstoaccessdata(suchasafile)thatresideatsite
B.Thesystemcantransferthedatabyoneoftwobasicmethods.Oneapproach
todatamigrationistotransfertheentirefiletositeA.Fromthatpointon,all
access to the file is local. When the user no longer needs access to the file, a
copy of the file (if it has been modified) is sent back to site B. Even if only a752 Chapter19 NetworksandDistributedSystems
modestchangehasbeenmadetoalargefile,allthedatamustbetransferred.
ThismechanismcanbethoughtofasanautomatedFTPsystem.Thisapproach
wasusedintheAndrewfilesystem,butitwasfoundtobetooinefficient.
The other approach is to transfer to site Aonly those portions of the file
thatareactuallynecessaryfortheimmediatetask.Ifanotherportionisrequired
later,anothertransferwilltakeplace.Whentheusernolongerwantstoaccess
thefile,anypartofitthathasbeenmodifiedmustbesentbacktositeB.(Note
the similarity to demand paging.) Most modern distributed systems use this
approach.
Whichever method is used, data migration includes more than the mere
transfer of data from one site to another. The system must also perform var-
ious data translations if the two sites involved are not directly compatible
(for instance, ifthey use differentcharacter-code representationsor represent
integerswithadifferentnumberororderofbits).
19.4.2.2 ComputationMigration
Insomecircumstances,wemaywanttotransferthecomputation,ratherthan
thedata,acrossthesystem;thisprocessiscalledcomputationmigration.For
example, consider a job that needs to access various large files that reside at
differentsites,toobtainasummaryofthosefiles.Itwouldbemoreefficientto
access thefilesatthesiteswheretheyresideand returnthedesiredresultsto
thesitethatinitiatedthecomputation.Generally,ifthetimetotransferthedata
islongerthanthetimetoexecutetheremotecommand,theremotecommand
shouldbeused.
Such a computation can be carried out in different ways. Suppose that
processPwantstoaccessafileatsiteA.Accesstothefileiscarriedoutatsite
AandcouldbeinitiatedbyanRPC.AnRPCusesnetworkprotocolstoexecute
a routine on a remote system (Section 3.8.2). Process P invokes a predefined
procedure at site A. The procedure executes appropriately and then returns
theresultstoP.
Alternatively,processPcansendamessagetositeA.Theoperatingsystem
at site A then creates a new process Q whose function is to carry out the
designatedtask.WhenprocessQcompletesitsexecution,itsendstheneeded
resultbacktoPviathemessagesystem.Inthisscheme,processPmayexecute
concurrently with process Q. In fact, it may have several processes running
concurrentlyonseveralsites.
Either method could be used to access several files (or chunks of files)
residingatvarioussites.OneRPCmightresultintheinvocationofanotherRPC
oreveninthetransferofmessagestoanothersite.Similarly,processQcould,
duringthecourseofitsexecution,sendamessagetoanothersite,whichinturn
wouldcreateanotherprocess.Thisprocessmighteithersendamessageback
toQorrepeatthecycle.
19.4.2.3 ProcessMigration
A logical extension of computation migration is process migration. When a
processissubmittedforexecution,itisnotalwaysexecutedatthesiteatwhich
itisinitiated.Theentireprocess,orpartsofit,maybeexecutedatdifferentsites.
Thisschememaybeusedforseveralreasons:19.5 DesignIssuesinDistributedSystems 753
• Loadbalancing.Theprocesses(orsubprocesses)maybedistributedacross
thesitestoeventheworkload.
• Computation speedup. If a single process can be divided into a number
ofsubprocessesthatcanrunconcurrentlyondifferentsitesornodes,then
thetotalprocessturnaroundtimecanbereduced.
• Hardware preference. The process may have characteristics that make it
moresuitableforexecutiononsomespecializedprocessor(suchasmatrix
inversiononaGPU)thanonamicroprocessor.
• Softwarepreference.Theprocessmayrequiresoftwarethatisavailableat
onlyaparticularsite,andeitherthesoftwarecannotbemoved,oritisless
expensivetomovetheprocess.
• Dataaccess.Justasincomputationmigration,ifthedatabeingusedinthe
computationarenumerous,itmaybemoreefficienttohaveaprocessrun
remotely (say, on a server that hosts a large database) than to transfer all
thedataandruntheprocesslocally.
We use two complementary techniques to move processes in a computer
network.Inthefirst,thesystemcanattempttohidethefactthattheprocesshas
migratedfromtheclient.Theclientthenneednotcodeherprogramexplicitly
to accomplish the migration. This method is usually employed for achieving
load balancing and computation speedup among homogeneous systems, as
theydonotneeduserinputtohelpthemexecuteprogramsremotely.
The other approach is to allow (or require) the user to specify explicitly
how the process should migrate. This method is usually employed when the
processmustbemovedtosatisfyahardwareorsoftwarepreference.
You have probably realized that the World Wide Web has many aspects
of a distributed computing environment. Certainly it provides data migra-
tion (between a web server and a web client). It also provides computation
migration. For instance, a web client could trigger a database operation on a
web server. Finally, with Java, Javascript, and similar languages, it provides
aform ofprocessmigration:Javaappletsand Javascriptscriptsare sentfrom
theservertotheclient,wheretheyareexecuted.Anetworkoperatingsystem
providesmostofthesefeatures,butadistributedoperatingsystemmakesthem
seamlessandeasilyaccessible.Theresultisapowerfulandeasy-to-usefacility
—oneofthereasonsforthehugegrowthoftheWorldWideWeb.
19.5 Design Issues in Distributed Systems
Thedesignersofadistributedsystemmusttakeanumberofdesignchallenges
intoaccount.Thesystemshouldberobustsothatitcanwithstandfailures.The
system should also be transparent to users in terms of both file location and
user mobility. Finally, the system should be scalable to allow the addition of
more computation power, more storage, or more users. We briefly introduce
theseissueshere.Inthenextsection,weputthemincontextwhenwedescribe
thedesignsofspecificdistributedfilesystems.754 Chapter19 NetworksandDistributedSystems
19.5.1 Robustness
Adistributed system may suffer from various types of hardware failure. The
failureofalink,ahost,orasiteandthelossofamessagearethemostcommon
types.Toensurethatthesystemisrobust,wemustdetectanyofthesefailures,
reconfigure the system so that computation can continue, and recover when
thefailureisrepaired.
Asystemcanbefaulttolerantinthatitcantolerateacertainleveloffailure
and continue to function normally. The degree of fault tolerance depends on
the design of the distributed system and the specific fault. Obviously, more
faulttoleranceisbetter.
We use the term fault tolerance in a broad sense. Communication faults,
certainmachinefailures,storage-devicecrashes,anddecaysofstoragemedia
shouldallbetoleratedtosomeextent.Afault-tolerantsystemshouldcontinue
to function, perhaps in a degraded form, when faced with such failures. The
degradation can affect performance, functionality, or both. It should be pro-
portional,however,tothefailuresthatcausedit.Asystemthatgrindstoahalt
whenonlyoneofitscomponentsfailsiscertainlynotfaulttolerant.
Unfortunately,faulttolerancecanbedifficultandexpensivetoimplement.
Atthenetworklayer,multipleredundantcommunicationpathsandnetwork
devices such as switches and routers are needed to avoid a communication
failure.Astoragefailurecan cause lossof theoperating system,applications,
ordata.Storageunitscanincluderedundanthardwarecomponentsthatauto-
maticallytakeoverfromeachotherincaseoffailure.Inaddition,RAIDsystems
canensurecontinuedaccesstothedataevenintheeventofoneormorestorage
devicefailures(Section11.8).
19.5.1.1 FailureDetection
Inanenvironmentwithnosharedmemory,wegenerallycannot differentiate
among link failure, site failure, host failure, and message loss. We can usu-
ally detect only that one of these failures has occurred. Once a failure has
been detected, appropriate action must be taken. What action is appropriate
dependsontheparticularapplication.
Todetectlinkandsitefailure,weuseaheartbeatprocedure.Supposethat
sitesAandBhaveadirectphysicallinkbetweenthem.Atfixedintervals,the
sitessendeachotheranI-am-upmessage.IfsiteAdoesnotreceivethismessage
within a predeterminedtime period, it can assume that site B has failed,that
thelinkbetweenAandBhasfailed,orthatthemessagefromBhasbeenlost.At
thispoint,siteAhastwochoices.Itcanwaitforanothertimeperiodtoreceive
anI-am-upmessagefromB,oritcansendanAre-you-up?messagetoB.
IftimegoesbyandsiteAstillhasnotreceivedanI-am-upmessage,orifsite
AhassentanAre-you-up?messageandhasnotreceivedareply,theprocedure
canberepeated.Again,theonlyconclusionthatsiteAcandrawsafelyisthat
sometypeoffailurehasoccurred.
SiteAcantrytodifferentiatebetweenlinkfailureandsitefailurebysend-
inganAre-you-up?messagetoBbyanotherroute(ifoneexists).IfandwhenB
receivesthismessage,itimmediatelyrepliespositively.Thispositivereplytells
AthatBisupandthatthefailureisinthedirectlinkbetweenthem.Sincewe
donotknowinadvancehowlongitwilltakethemessagetotravelfromAtoB
andback,wemustuseatime-outscheme.AtthetimeAsendstheAre-you-up?19.5 DesignIssuesinDistributedSystems 755
message, it specifies a time interval during which it is willing to wait for the
replyfromB.IfAreceivesthereplymessagewithinthattimeinterval,thenit
cansafelyconcludethatBisup.Ifnot,however(thatis,ifatime-outoccurs),
then A may conclude only that one or more of the following situations has
occurred:
• SiteBisdown.
• Thedirectlink(ifoneexists)fromAtoBisdown.
• ThealternativepathfromAtoBisdown.
• The message has been lost. (Although the use of areliable transport pro-
tocolsuchasTCPshouldeliminatethisconcern.)
SiteAcannot,however,determinewhichoftheseeventshasoccurred.
19.5.1.2 Reconfiguratio
Suppose that site A has discovered, through the mechanism just described,
that a failure has occurred. It must then initiate a procedure that will allow
thesystemtoreconfigureandtocontinueitsnormalmodeofoperation.
• IfadirectlinkfromAtoBhasfailed,thisinformationmustbebroadcastto
everysiteinthesystem,sothatthevariousroutingtablescanbeupdated
accordingly.
• Ifthesystembelievesthatasitehasfailed(becausethatsitecannolonger
be reached), then all sites in the system must be notified, so that they
will no longer attempt to use the services of the failed site. The failure
of a site that serves as a central coordinator for some activity (such as
deadlockdetection)requirestheelectionofanewcoordinator.Notethat,
if the site has not failed (that is, if it is up but cannot be reached), then
we may have the undesirable situation in which two sites serve as the
coordinator.Whenthenetworkispartitioned,thetwocoordinators(each
for its own partition) may initiate conflicting actions. For example, if the
coordinatorsareresponsibleforimplementingmutualexclusion,wemay
have a situation in which two processes are executing simultaneously in
theircriticalsections.
19.5.1.3 RecoveryfromFailure
When a failed link or site is repaired, it must be integrated into the system
gracefullyandsmoothly.
• SupposethatalinkbetweenAandBhasfailed.Whenitisrepaired,both
AandBmustbenotified.Wecanaccomplishthisnotificationbycontinu-
ouslyrepeatingtheheartbeatproceduredescribedinSection19.5.1.1.
• Suppose that site B has failed. When it recovers, it must notify all other
sitesthatitisupagain.SiteBthenmayhavetoreceiveinformationfrom
theothersitestoupdateitslocaltables.Forexample,itmayneedrouting-
table information, a list of sites that are down, undelivered messages, a756 Chapter19 NetworksandDistributedSystems
transaction log of unexecuted transactions, and mail. If the site has not
failedbutsimplycannotbereached,thenitstillneedsthisinformation.
19.5.2 Transparency
Making the multiple processors and storage devices in a distributed system
transparent to the users has been a key challenge to many designers. Ide-
ally, a distributed system should look to its users like a conventional, cen-
tralizedsystem.Theuserinterfaceofatransparentdistributedsystemshould
not distinguish between local and remote resources. That is, users should be
able to access remoteresources as though these resources were local, and the
distributed system should be responsible for locating the resources and for
arrangingfortheappropriateinteraction.
Anotheraspectoftransparencyisusermobility.Itwouldbeconvenientto
allowuserstologintoanymachineinthesystemratherthanforcingthemto
useaspecificmachine.Atransparentdistributedsystemfacilitatesusermobil-
ity by bringing over a user’s environment (for example, home directory) to
whereverhelogsin.ProtocolslikeLDAPprovideanauthenticationsystemfor
local,remote,andmobileusers.Oncetheauthenticationiscomplete,facilities
likedesktopvirtualizationallowuserstoseetheirdesktopsessionsatremote
facilities.
19.5.3 Scalability
Still another issue is scalability—the capability of a system to adapt to
increased service load. Systems have bounded resources and can become
completelysaturatedunderincreasedload.Forexample,withrespecttoafile
system,saturationoccurseitherwhenaserver’sCPUrunsatahighutilization
rate or when disks’ I/O requests overwhelm the I/O subsystem. Scalability
is a relative property, but it can be measured accurately. A scalable system
reacts more gracefully to increased load than does a nonscalable one. First,
its performance degrades more moderately; and second, its resources reach
a saturated state later. Even perfect design however cannot accommodate
an ever-growing load. Adding new resources might solve the problem, but
it might generate additional indirect load on other resources (for example,
adding machines to a distributed system can clog the network and increase
service loads). Even worse, expanding the system can call for expensive
design modifications. A scalable system should have the potential to grow
without these problems. In a distributed system, the ability to scale up
gracefully is of special importance, since expanding a network by adding
new machines or interconnecting two networks is commonplace. In short, a
scalable design should withstand high service load, accommodate growth of
theusercommunity,andallowsimpleintegrationofaddedresources.
Scalabilityisrelatedtofaulttolerance,discussedearlier.Aheavilyloaded
componentcanbecomeparalyzedandbehavelikeafaultycomponent.Inaddi-
tion, shifting the load from a faulty component to that component’s backup
cansaturatethelatter.Generally,havingspareresourcesisessentialforensur-
ing reliability as well as for handling peak loads gracefully. Thus, the multi-
pleresourcesinadistributedsystemrepresentaninherentadvantage,giving
the system a greater potential for fault tolerance and scalability. However,19.6 DistributedFileSystems 757
inappropriatedesigncanobscurethispotential.Fault-toleranceandscalability
considerationscallforadesigndemonstratingdistributionofcontrolanddata.
Scalability can also be related to efficient storage schemes. For example,
manycloudstorageprovidersusecompressionordeduplicationtocutdown
ontheamountofstorageused.Compressionreducesthesizeofafile.Forexam-
ple,aziparchivefilecanbegeneratedoutofafile(orfiles)byexecutingazip
command, which runs a lossless compression algorithm over the data speci-
fied. (Lossless compression allows original data to be perfectly reconstructed
from compressed data.) The result is a file archive that is smaller than the
uncompressedfile.Torestorethefiletoitsoriginalstate,auserrunssomesort
ofunzipcommandovertheziparchivefile.Deduplicationseekstolowerdata
storagerequirementsbyremovingredundantdata.Withthistechnology,only
oneinstanceofdataisstoredacrossanentiresystem(evenacrossdataowned
by multipleusers).Bothcompressionand deduplicationcan be performedat
thefilelevelortheblocklevel,andtheycanbeusedtogether.Thesetechniques
can be automatically built into a distributed system to compress information
withoutusersexplicitlyissuingcommands,therebysavingstoragespaceand
possiblycuttingdownonnetworkcommunicationcostswithoutaddinguser
complexity.
19.6 Distributed File Systems
Although the World Wide Web is the predominant distributed system in use
today,itisnottheonlyone.Anotherimportantandpopularuseofdistributed
computingisthedistributedfil system,orDFS.
To explain the structure of a DFS, we need to define the terms service,
server, and client in the DFS context. Aservice is a software entity running on
one or more machines and providing a particular type of function to clients.
A server is the service software running on a single machine. A client is a
processthatcaninvokeaserviceusingasetofoperationsthatformitsclient
interface. Sometimes a lower-level interface is defined for the actual cross-
machineinteraction;itistheintermachineinterface.
Using this terminology, we say that a file system provides file services to
clients. Aclient interface for a file service is formed by a set of primitive file
operations,suchascreateafile,deleteafile,readfromafile,andwritetoafile.
The primary hardware component that a file server controls is a set of local
secondary-storagedevices(usually,harddisksorsolid-statedrives)onwhich
files are stored and from which they are retrieved according to the clients’
requests.
ADFS is a file system whose clients, servers, and storage devices are dis-
persedamongthemachinesofadistributedsystem.Accordingly,serviceactiv-
ity has to be carried out across the network. Instead of a single centralized
data repository, the system frequently has multiple and independent storage
devices. As you will see, the concrete configuration and implementation of a
DFS may vary from system to system. In some configurations, serversrun on
dedicatedmachines.Inothers,amachinecanbebothaserverandaclient.
The distinctive features of a DFS are the multiplicity and autonomy of
clients and servers in the system. Ideally, though, a DFS should appear to its
clientstobeaconventional,centralizedfilesystem.Thatis,theclientinterface758 Chapter19 NetworksandDistributedSystems
of a DFSshould not distinguishbetweenlocal and remote files. It is up to the
DFStolocatethefilesandtoarrangeforthetransportofthedata.Atransparent
DFS—like the transparent distributed systems mentioned earlier—facilitates
usermobilitybybringingauser’senvironment(forexample,theuser’shome
directory)towherevertheuserlogsin.
The most important performance measure of a DFS is the amount of time
neededtosatisfyservicerequests.Inconventional systems,this timeconsists
of storage-access time and a small amount of CPU-processing time. In a DFS,
however, a remote access has the additional overhead associated with the
distributed structure. This overhead includes the time to deliver the request
to a server, as well as the time to get the response across the network back
totheclient.Foreachdirection,inadditiontothetransferoftheinformation,
there is the CPU overhead of running the communication protocol software.
The performance of a DFS can be viewed as another dimension of the DFS’s
transparency.Thatis,theperformanceofanidealDFSwouldbecomparableto
thatofaconventionalfilesystem.
ThebasicarchitectureofaDFSdependsonitsultimategoals.Twowidely
usedarchitecturalmodelswediscussherearetheclient–servermodelandthe
cluster-basedmodel.Themaingoalofaclient–serverarchitectureistoallow
transparent file sharing among one or more clients as if the files were stored
locallyontheindividualclientmachines.ThedistributedfilesystemsNFSand
OpenAFSareprimeexamples.NFSisthemostcommonUNIX-basedDFS.Ithas
severalversions,andherewerefertoNFSVersion3unlessotherwisenoted.
Ifmanyapplicationsneedtoberuninparallelonlargedatasetswithhigh
availability and scalability, the cluster-based model is more appropriate than
theclient–servermodel.Twowell-knownexamplesaretheGooglefilesystem
andtheopen-sourceHDFS,whichrunsaspartoftheHadoopframework.
19.6.1 The Client–Server DFS Model
Figure 19.12 illustrates a simple DFS client–server model. The server stores
bothfilesand metadataonattachedstorage.Insomesystems,morethanone
server can be used to store different files. Clients are connected to the server
through a network and can request access to files in the DFS by contacting
the server through a well-known protocol such as NFS Version 3. The server
client
server
client
network
client
Figure19.12 Client–serverDFSmodel.19.6 DistributedFileSystems 759
isresponsibleforcarryingoutauthentication,checkingtherequestedfileper-
missions,and,ifwarranted,deliveringthefiletotherequestingclient.Whena
clientmakeschangestothefile,theclientmustsomehowdeliverthosechanges
to the server (which holds the master copy of the file). The client’s and the
server’sversionsofthefileshouldbekeptconsistentinawaythatminimizes
networktrafficandtheserver’sworkloadtotheextentpossible.
The networkfilesystem (NFS) protocolwas originallydevelopedby Sun
Microsystems as an open protocol, which encouraged early adoption across
differentarchitecturesandsystems.Fromthebeginning,thefocusofNFSwas
simpleandfastcrashrecoveryinthefaceofserverfailure.Toimplementthis
goal, the NFS server was designed to be stateless; it does not keep track of
which client is accessing which file or of things such as open file descriptors
and file pointers. This means that, whenever a client issues a file operation
(say, to read a file), that operation has to be idempotent in the face of server
crashes.Idempotentdescribesanoperationthatcanbeissuedmorethanonce
yetreturnthesameresult.Inthecaseofareadoperation,theclientkeepstrack
of the state (such as the file pointer) and can simply reissue the operation if
theserverhascrashedandcomebackonline.YoucanreadmoreabouttheNFS
implementationinSection15.8.
TheAndrewfil system(OpenAFS)wascreatedatCarnegieMellonUni-
versitywithafocusonscalability.Specifically,theresearcherswantedtodesign
aprotocolthatwouldallowtheservertosupportasmanyclientsaspossible.
Thismeantminimizingrequestsandtraffictotheserver.Whenaclientrequests
a file, the file’s contents are downloaded from the server and stored on the
client’slocalstorage.Updatestothefilearesenttotheserverwhenthefileis
closed,andnewversionsofthefilearesenttotheclientwhenthefileisopened.
Incomparison,NFSisquitechattyandwillsendblockreadandwriterequests
totheserverasthefileisbeingusedbyaclient.
Both OpenAFS and NFS are meant to be used in addition to local file sys-
tems.Inotherwords,youwouldnotformataharddrivepartitionwiththeNFS
filesystem.Instead,ontheserver,youwouldformatthepartitionwithalocal
filesystemofyourchoosing,suchasext4,andexporttheshareddirectoriesvia
theDFS.Intheclient,youwouldsimplyattachtheexporteddirectoriestoyour
file-system tree. In this way, the DFS can be separated from responsibility for
thelocalfilesystemandcanconcentrateondistributedtasks.
TheDFSclient–servermodel,bydesign,maysufferfromasinglepointof
failureiftheservercrashes.Computerclusteringcanhelpresolvethisproblem
byusingredundantcomponentsandclusteringmethodssuchthatfailuresare
detectedandfailingovertoworkingcomponentscontinuesserveroperations.
Inaddition,theserverpresentsabottleneckforallrequestsforbothdataand
metadata,whichresultsinproblemsofscalabilityandbandwidth.
19.6.2 The Cluster-Based DFS Model
Astheamountofdata,I/Oworkload,andprocessingexpands,sodoestheneed
foraDFStobefault-tolerantandscalable.Largebottleneckscannotbetolerated,
and system component failures must be expected. Cluster-based architecture
wasdevelopedinparttomeettheseneeds.
Figure19.13illustratesasamplecluster-basedDFSmodel.Thisisthebasic
modelpresentedbytheGooglefilesystem(GFS)andtheHadoopdistributed760 Chapter19 NetworksandDistributedSystems
client file chunk
data server
client file chunk
network
data server file
file chunk
data server
metadata
server
Figure19.13 Anexampleofacluster-basedDFSmodel
fil system (HDFS). One or more clients are connected via a network to a
mastermetadataserverandseveraldataserversthathouse“chunks”(orpor-
tions) of files. The metadata server keeps a mapping of which data servers
hold chunks of which files, as well as a traditional hierarchical mapping of
directoriesandfiles.Eachfilechunkisstoredonadataserverandisreplicated
acertainnumberoftimes(forexample,threetimes)toprotectagainstcompo-
nentfailureandforfasteraccesstothedata(serverscontainingthereplicated
chunkshavefastaccesstothosechunks).
To obtain access to a file, a client must first contact the metadata server.
Themetadataserverthenreturnstotheclienttheidentitiesofthedataservers
thatholdtherequestedfilechunks.Theclientcanthencontacttheclosestdata
server(orservers)toreceivethefileinformation.Differentchunksofthefilecan
bereadorwrittentoinparalleliftheyarestoredondifferentdataservers,and
themetadataservermayneedtobecontactedonlyonceintheentireprocess.
Thismakesthemetadataserverlesslikelytobeaperformancebottleneck.The
metadata server is also responsible for redistributing and balancing the file
chunksamongthedataservers.
GFSwasreleasedin2003tosupportlargedistributeddata-intensiveappli-
cations.ThedesignofGFSwasinfluencedbyfourmainobservations:
• Hardwarecomponentfailuresarethenormratherthantheexceptionand
shouldberoutinelyexpected.
• Filesstoredonsuchasystemareverylarge.
• Mostfilesarechangedbyappendingnewdatatotheendofthefilerather
thanoverwritingexistingdata.
• Redesigning the applications and file system API increases the system’s
flexibility.
Consistent with the fourth observation, GFS exports its own API and requires
applicationstobeprogrammedwiththisAPI.19.7 DFSNamingandTransparency 761
Shortly after developing GFS, Google developed a modularized software
layer called MapReduce to sit on top of GFS. MapReduce allows developers
to carry out large-scale parallel computations more easily and utilizes the
benefitsofthelower-layerfilesystem.Later,HDFSandtheHadoopframework
(which includes stackable modules like MapReduce on top of HDFS) were
createdbasedonGoogle’swork.LikeGFSandMapReduce,Hadoopsupports
the processing of large data sets in distributed computing environments. As
suggestedearlier,thedriveforsuchaframeworkoccurredbecausetraditional
systemscouldnotscaletothecapacityandperformanceneededby“bigdata”
projects(atleastnotatreasonableprices).Examplesofbigdataprojectsinclude
crawling and analyzing social media, customer data, and large amounts of
scientificdatapointsfortrends.
19.7 DFS Naming and Transparency
Namingisamappingbetweenlogicalandphysicalobjects.Forinstance,users
deal with logical data objects represented by file names, whereas the system
manipulatesphysicalblocksofdatastoredondisktracks.Usually,auserrefers
to a file by a textual name. The latter is mapped to a lower-level numerical
identifier that in turn is mapped to disk blocks. This multilevel mapping
provides users with an abstraction of a file that hides the details of how and
whereonthediskthefileisstored.
InatransparentDFS,anewdimensionisaddedtotheabstraction:thatof
hidingwhereinthenetworkthefileislocated.Inaconventionalfilesystem,the
rangeofthenamingmappingisanaddresswithinadisk.InaDFS,thisrange
is expanded to include the specific machine on whose disk the file is stored.
Going one step further with the concept of treating files as abstractions leads
tothepossibilityoffil replication.Givenafilename,themappingreturnsa
setofthelocationsofthisfile’sreplicas.Inthisabstraction,boththeexistence
ofmultiplecopiesandtheirlocationsarehidden.
19.7.1 Naming Structures
We need to differentiate two related notions regarding name mappings in a
DFS:
1. Locationtransparency.Thenameofafiledoesnotrevealanyhintofthe
file’sphysicalstoragelocation.
2. Location independence. The name of a file need not be changed when
thefile’sphysicalstoragelocationchanges.
Bothdefinitions relatetothe levelof naming discussedpreviously,since files
have different names at different levels (that is, user-level textual names and
system-levelnumericalidentifiers).Alocation-independentnamingschemeis
adynamicmapping,sinceitcanmapthesamefilenametodifferentlocations
attwodifferenttimes.Therefore,locationindependenceisastrongerproperty
thanlocationtransparency.
Inpractice,mostofthecurrentDFSsprovideastatic,location-transparent
mappingforuser-levelnames.Somesupportfil migration—thatis,changing
thelocationofafileautomatically,providinglocationindependence.OpenAFS762 Chapter19 NetworksandDistributedSystems
supportslocationindependenceandfilemobility,forexample.HDFSincludes
filemigrationbutdoessowithoutfollowingPOSIXstandards,providingmore
flexibility in implementation and interface. HDFS keeps track of the location
of data but hides this information from clients. This dynamic location trans-
parency allows the underlying mechanism to self-tune. In another example,
Amazon’sS3cloudstoragefacilityprovidesblocksofstorageondemandvia
APIs,placingthestoragewhereitseesfitandmovingthedataasnecessaryto
meetperformance,reliability,andcapacityrequirements.
A few aspects can further differentiate location independence and static
locationtransparency:
• Divorceofdatafromlocation,asexhibitedbylocationindependence,pro-
vides a better abstraction for files. A file name should denote the file’s
most significant attributes, which are its contents rather than its loca-
tion. Location-independent files can be viewedas logical data containers
that are not attached to a specific storage location. If only static location
transparencyissupported,thefilenamestilldenotesaspecific,although
hidden,setofphysicaldiskblocks.
• Staticlocationtransparencyprovidesuserswithaconvenientwaytoshare
data.Userscanshareremotefilesbysimplynamingthefilesinalocation-
transparent manner, as though the files were local. Dropbox and other
cloud-basedstoragesolutionsworkthisway.Locationindependencepro-
motessharingthestoragespaceitself,aswellasthedataobjects.Whenfiles
canbemobilized,theoverall,system-widestoragespacelookslikeasingle
virtualresource.Apossiblebenefitistheabilitytobalance theutilization
ofstorageacrossthesystem.
• Locationindependenceseparatesthenaminghierarchyfromthestorage-
devices hierarchy and from the intercomputer structure. By contrast, if
static location transparency is used (although names are transparent),
we can easily expose the correspondence between component units and
machines.Themachinesareconfiguredinapatternsimilartothenaming
structure. This configuration may restrict the architecture of the system
unnecessarilyandconflictwithotherconsiderations.Aserverinchargeof
arootdirectoryisanexampleofastructurethatisdictatedbythenaming
hierarchyandcontradictsdecentralizationguidelines.
Once the separation of name and location has been completed, clients
can access files residing on remote server systems. In fact, these clients may
be diskless and rely on servers to provide all files, including the operating-
system kernel. Special protocols are needed for the boot sequence, however.
Consider the problem of getting the kernel to a diskless workstation. The
diskless workstation has no kernel, so it cannot use the DFS code to retrieve
thekernel.Instead,aspecialbootprotocol,storedinread-onlymemory(ROM)
ontheclient,isinvoked.Itenablesnetworkingandretrievesonlyonespecial
file (the kernel or boot code) from a fixed location. Once the kernel is copied
overthenetworkandloaded,itsDFSmakesalltheotheroperating-systemfiles
available. The advantages of diskless clients are many, including lower cost
(becausetheclientmachinesrequirenodisks)andgreaterconvenience(when
an operating-system upgrade occurs, only the server needs to be modified).19.7 DFSNamingandTransparency 763
The disadvantages are the added complexity of the boot protocols and the
performancelossresultingfromtheuseofanetworkratherthanalocaldisk.
19.7.2 Naming Schemes
TherearethreemainapproachestonamingschemesinaDFS.Inthesimplest
approach, a file is identified by some combination of its host name and local
name, which guarantees a unique system-wide name. In Ibis, for instance, a
file is identified uniquely by the name host:local-name, where local-name is a
UNIX-likepath.TheInternetURLsystemalsousesthisapproach.Thisnaming
scheme is neither location transparent nor location independent. The DFS is
structuredasacollectionofisolatedcomponentunits,eachofwhichisanentire
conventional file system. Component units remain isolated, although means
areprovidedtorefertoremotefiles.Wedonotconsiderthisschemeanyfurther
here.
The second approach was popularized by NFS. NFS provides a means to
attach remote directories to local directories, thus giving the appearance of a
coherentdirectorytree.EarlyNFSversionsallowedonly previouslymounted
remotedirectoriestobeaccessedtransparently.Theadventoftheautomount
feature allowed mounts to be done on demand based on a table of mount
pointsandfile-structurenames.Componentsareintegratedtosupporttrans-
parent sharing, but this integration is limited and is not uniform, because
eachmachinemayattachdifferentremotedirectoriestoitstree.Theresulting
structureisversatile.
We can achieve total integration of the component file systems by using
a third approach. Here, a single global name structure spans all the files in
the system. OpenAFS provides a single global namespace for the files and
directoriesitexports,allowingasimilaruserexperienceacrossdifferentclient
machines.Ideally,thecomposedfile-systemstructureisthesameasthestruc-
tureofaconventionalfilesystem.Inpractice,however,themanyspecialfiles
(forexample,UNIXdevicefilesandmachine-specificbinarydirectories)make
thisgoaldifficulttoattain.
Toevaluatenamingstructures,welookattheiradministrativecomplexity.
Themostcomplexandmostdifficult-to-maintainstructureistheNFSstructure.
Becauseanyremotedirectorycanbeattachedanywhereonthelocaldirectory
tree, the resulting hierarchy can be highly unstructured. If a server becomes
unavailable, some arbitrary set of directories on different machines becomes
unavailable. In addition, a separate accreditation mechanism controls which
machine is allowed to attach which directory to its tree. Thus, a user might
beabletoaccessaremotedirectorytreeononeclientbutbedeniedaccesson
anotherclient.
19.7.3 Implementation Techniques
Implementation of transparent naming requires a provision for the mapping
of a file name to the associated location. To keep this mapping manageable,
wemustaggregatesetsoffilesintocomponentunitsandprovidethemapping
onacomponent-unit basisratherthanonasingle-filebasis.This aggregation
servesadministrativepurposesaswell.UNIX-likesystemsusethehierarchical
directory tree to provide name-to-location mapping and to aggregate files
recursivelyintodirectories.764 Chapter19 NetworksandDistributedSystems
Toenhancetheavailabilityofthecrucialmappinginformation,wecanuse
replication,localcaching,orboth.Aswenoted,locationindependencemeans
that the mapping changes over time. Hence, replicating the mapping makes
a simple yet consistent update of this information impossible. To overcome
thisobstacle,wecanintroducelow-level,location-independentfileidentifiers.
(OpenAFSusesthisapproach.)Textualfilenamesaremappedtolower-levelfile
identifiersthatindicatetowhichcomponentunitthefilebelongs.Theseiden-
tifiersarestilllocationindependent.Theycanbereplicatedandcachedfreely
without being invalidated by migration of component units. The inevitable
priceistheneedforasecondlevelofmapping,whichmapscomponentunitsto
locationsandneedsasimpleyetconsistentupdatemechanism.Implementing
UNIX-like directory trees using these low-level, location-independent identi-
fiers makes the whole hierarchy invariant under component-unit migration.
Theonlyaspectthatdoeschangeisthecomponent-unitlocationmapping.
A common way to implement low-level identifiers is to use structured
names.Thesenamesarebitstringsthatusuallyhavetwoparts.Thefirstpart
identifiesthecomponentunittowhichthefilebelongs;thesecondpartidenti-
fiestheparticularfilewithintheunit.Variantswithmorepartsarepossible.The
invariant of structured names, however, is that individual parts of the name
areuniqueatalltimesonlywithinthecontextoftherestoftheparts.Wecan
obtainuniquenessatalltimesbytakingcarenottoreuseanamethatisstillin
use,by addingsufficiently morebits (this methodis usedinOpenAFS), or by
using a timestamp as one part of the name (as was done in Apollo Domain).
Anotherwaytoviewthisprocessisthat wearetakingalocation-transparent
system, such as Ibis, and adding another level of abstraction to produce a
location-independentnamingscheme.
19.8 Remote File Access
Next, let’s consider a user who requests access to a remote file. The server
storing the file has been located by the naming scheme, and now the actual
datatransfermusttakeplace.
Onewaytoachievethistransferisthrougharemote-servicemechanism,
whereby requestsfor accesses are deliveredto the server,the server machine
performstheaccesses,andtheirresultsareforwardedbacktotheuser.Oneof
themostcommonwaysofimplementingremoteserviceistheRPCparadigm,
whichwediscussedinChapter3.Adirectanalogyexistsbetweendisk-access
methodsinconventionalfilesystemsandtheremote-servicemethodinaDFS:
usingtheremote-servicemethodisanalogoustoperformingadiskaccessfor
eachaccessrequest.
Toensurereasonableperformanceofaremote-servicemechanism,wecan
useaformofcaching.Inconventionalfilesystems,therationaleforcachingis
toreducediskI/O(therebyincreasingperformance),whereasinDFSs,thegoal
istoreducebothnetworktrafficanddiskI/O.Inthefollowingdiscussion,we
describetheimplementationofcachinginaDFSandcontrastitwiththebasic
remote-serviceparadigm.
19.8.1 Basic Caching Scheme
Theconceptofcachingissimple.Ifthedataneededtosatisfytheaccessrequest
are not already cached, then a copy of the data is brought from the server to19.8 RemoteFileAccess 765
the client system. Accesses are performed on the cached copy. The idea is to
retainrecentlyaccesseddiskblocksinthecache,sothatrepeatedaccessestothe
same information can be handled locally, without additional network traffic.
A replacement policy (for example, the least-recently-used algorithm) keeps
thecachesizebounded.Nodirectcorrespondenceexistsbetweenaccessesand
traffic to the server. Files are still identified with one master copy residing at
the server machine, but copies (or parts) of the file are scattered in different
caches. When a cached copy is modified, the changes need to be reflected on
the master copy to preservethe relevant consistency semantics. The problem
of keeping the cached copies consistent with the master file is the cache-
consistency problem, which we discuss in Section 19.8.4. DFS caching could
just as easily be called network virtual memory. It acts similarly to demand-
pagedvirtualmemory,exceptthatthebackingstoreusuallyisaremoteserver
rather than a local disk. NFS allows the swap space to be mounted remotely,
so it actually can implement virtual memory over a network, though with a
resultingperformancepenalty.
The granularity of the cached data in a DFS can vary from blocks of a file
to an entire file. Usually, more data are cached than are needed to satisfy a
single access, so that many accesses can be served by the cached data. This
procedureismuchlikediskread-ahead(Section14.6.2).OpenAFScachesfiles
in large chunks (64 KB). The other systems discussed here support caching
of individual blocks driven by client demand. Increasing the caching unit
increasesthehitratio,butitalsoincreasesthemisspenalty,becauseeachmiss
requiresmoredatatobetransferred.Itincreasesthepotentialforconsistency
problemsaswell.Selectingtheunitofcachinginvolvesconsideringparameters
suchasthenetworktransferunitandtheRPCprotocolserviceunit(ifanRPC
protocol is used). The network transfer unit (for Ethernet, a packet) is about
1.5KB,solargerunitsofcacheddataneedtobedisassembledfordeliveryand
reassembledonreception.
Block size and total cache size are obviously of importance for block-
caching schemes. In UNIX-like systems, common block sizes are 4 KB and 8
KB.Forlargecaches(over1MB),largeblocksizes(over8KB)arebeneficial.For
smallercaches,largeblocksizesarelessbeneficialbecausetheyresultinfewer
blocksinthecacheandalowerhitratio.
19.8.2 Cache Location
Where should the cached data be stored—on disk or in main memory? Disk
cacheshaveoneclearadvantageovermain-memorycaches:theyarereliable.
Modifications tocached dataare lost ina crash if the cache is kept in volatile
memory. Moreover, if the cached data are kept on disk, they are still there
duringrecovery,andthereisnoneedtofetchthemagain.Main-memorycaches
haveseveraladvantagesoftheirown,however:
• Main-memorycachespermitworkstationstobediskless.
• Datacanbeaccessedmorequicklyfromacacheinmainmemorythanfrom
oneonadisk.
• Technology is moving toward larger and less expensive memory. The
resulting performance speedup is predicted to outweigh the advantages
ofdiskcaches.766 Chapter19 NetworksandDistributedSystems
• The server caches (used to speed up disk I/O) will be in main memory
regardlessofwhereusercachesarelocated;ifweusemain-memorycaches
ontheusermachine,too,wecanbuildasinglecachingmechanismforuse
bybothserversandusers.
Many remote-access implementations can be thought of as hybrids of
caching andremoteservice.InNFS,forinstance,theimplementationisbased
on remote service but is augmented with client- and server-side memory
cachingforperformance.Thus,toevaluatethetwomethods,wemustevaluate
thedegreetowhicheithermethodisemphasized.TheNFSprotocolandmost
implementationsdonotprovidediskcaching(butOpenAFSdoes).
19.8.3 Cache-Update Policy
Thepolicyusedtowritemodifieddatablocksbacktotheserver’smastercopy
has a critical effect on the system’s performance and reliability. The simplest
policyistowritedatathroughtodiskassoonastheyareplacedinanycache.
The advantage of a write-through policy is reliability: little information is
lost when a client system crashes. However, this policy requires each write
accesstowaituntiltheinformationissenttotheserver,soitcausespoorwrite
performance.Cachingwithwrite-throughisequivalenttousingremoteservice
forwriteaccessesandexploitingcachingonlyforreadaccesses.
An alternative is the delayed-write policy, also known as write-back
caching,wherewedelayupdatestothemastercopy.Modificationsarewritten
to the cache and then are written through to the server at a later time. This
policyhastwoadvantagesoverwrite-through.First,becausewritesaremade
tothecache,writeaccessescompletemuchmorequickly.Second,datamaybe
overwritten before they are written back, in which case only the last update
needs to be written at all. Unfortunately, delayed-write schemes introduce
reliability problems, since unwritten data are lost whenever a user machine
crashes.
Variationsofthedelayed-writepolicydifferinwhenmodifieddatablocks
areflushedtotheserver.Onealternativeistoflushablockwhenitisaboutto
beejectedfromtheclient’scache.Thisoptioncanresultingoodperformance,
but some blocks can reside in the client’s cache a long time before they are
written back to the server. A compromise between this alternative and the
write-throughpolicyistoscanthecacheatregularintervalsandtoflushblocks
that have been modified since the most recent scan, just as UNIX scans its
local cache. NFS uses the policy for file data, but once a write is issued to the
server during a cache flush, the write must reach the server’s disk before it
is considered complete. NFS treats metadata (directory data and file-attribute
data)differently.Anymetadatachangesareissuedsynchronouslytotheserver.
Thus, file-structurelossand directory-structurecorruptionareavoidedwhen
aclientortheservercrashes.
Yet another variation on delayed write is to write data back to the server
when the file is closed.Thiswrite-on-close policy is used inOpenAFS. In the
case of files that are open for short periods or are modified rarely, this policy
does not significantly reduce network traffic. In addition, the write-on-close
policy requires the closing process to delay while the file is written through,19.9 FinalThoughtsonDistributedFileSystems 767
whichreducestheperformanceadvantagesofdelayedwrites.Forfilesthatare
openforlongperiodsandaremodifiedfrequently,however,theperformance
advantagesofthispolicyoverdelayedwritewithmorefrequentflushing are
apparent.
19.8.4 Consistency
Aclient machine is sometimes faced with the problem of deciding whether a
locallycachedcopyofdataisconsistentwiththemastercopy(andhencecan
beused).Iftheclientmachinedeterminesthatitscacheddataareoutofdate,
itmustcacheanup-to-datecopyofthedatabeforeallowingfurtheraccesses.
Therearetwoapproachestoverifyingthevalidityofcacheddata:
1. Client-initiated approach. The client initiates a validity check in which
it contacts the server and checks whether the local data are consistent
withthemastercopy.Thefrequencyofthevaliditycheckingisthecruxof
thisapproachanddeterminestheresultingconsistencysemantics.Itcan
rangefromacheck beforeeveryaccess toacheck only onfirstaccess to
afile(onfileopen,basically).Everyaccesscoupledwithavaliditycheck
is delayed, compared with an access served immediately by the cache.
Alternatively,checks can be initiated at fixed time intervals.Depending
on its frequency, the validity check can load both the network and the
server.
2. Server-initiatedapproach.Theserverrecords,foreachclient,thefiles(or
partsoffiles)thatitcaches.Whentheserverdetectsapotentialinconsis-
tency, it must react. Apotential for inconsistency occurs when two dif-
ferentclientsinconflictingmodescacheafile.IfUNIXsemantics(Section
15.7)isimplemented,wecanresolvethepotentialinconsistencybyhav-
ingtheserverplayanactiverole.Theservermustbenotifiedwhenever
afileisopened,andtheintendedmode(readorwrite)mustbeindicated
for every open. The server can then act when it detects that a file has
been opened simultaneously in conflicting modes by disabling caching
forthatparticularfile.Actually,disablingcachingresultsinswitchingto
aremote-servicemodeofoperation.
In a cluster-based DFS, the cache-consistency issue is made more compli-
cated by the presence of a metadata server and several replicated file data
chunksacrossseveraldataservers.UsingourearlierexamplesofHDFSandGFS,
wecancomparesomedifferences.HDFSallowsappend-onlywriteoperations
(norandomwrites)andasinglefilewriter,whileGFSdoesallowrandomwrites
withconcurrentwriters.Thisgreatlycomplicateswriteconsistencyguarantees
forGFSwhilesimplifyingthemforHDFS.
19.9 Final Thoughts on Distributed File Systems
ThelinebetweenDFSclient–serverandcluster-basedarchitecturesisblurring.
The NFS Version 4.1 specification includes a protocol for a parallel version of
NFScalledpNFS,butasofthiswriting,adoptionisslow.768 Chapter19 NetworksandDistributedSystems
GFS, HDFS, and other large-scale DFSs export a non-POSIX API, so they
cannot transparently map directories to regular user machines as NFS and
OpenAFS do. Rather, for systems to access these DFSs, they need client code
installed.However,othersoftwarelayersarerapidlybeingdevelopedtoallow
NFS to be mounted on top of such DFSs. This is attractive, as it would take
advantageofthescalabilityandotheradvantagesofcluster-basedDFSswhile
stillallowingnativeoperating-systemutilitiesanduserstoaccessfilesdirectly
ontheDFS.
As of this writing, the open-source HDFS NFS Gateway supports NFS Ver-
sion 3 and works as a proxy between HDFS and the NFS server software.
SinceHDFScurrentlydoesnotsupportrandomwrites,theHDFSNFSGateway
also does not support this capability. That means a file must be deleted and
recreated from scratch even if only one byte is changed. Commercial organi-
zations and researchers are addressing this problem and building stackable
frameworksthatallowstackingofaDFS,parallelcomputingmodules(suchas
MapReduce),distributeddatabases,andexportedfilevolumesthroughNFS.
One other type of file system, less complex than a cluster-based DFS but
more complex than a client–server DFS, is a clustered file system (CFS) or
parallelfilesystem(PFS).ACFStypicallyrunsoveraLAN.Thesesystemsare
important and widely used and thus deserve mention here, though we do
not cover them in detail. Common CFSs include Lustre and GPFS, although
there are many others. ACFS essentially treats N systems storing data and Y
systems accessing that data as a single client–server instance. Whereas NFS,
for example, has per-server naming, and two separate NFS servers generally
provide two different naming schemes, a CFS knits various storage contents
on various storage devices on various servers into a uniform, transparent
name space. GPFS has its own file-system structure, but Lustre uses existing
file systems such as ZFS for file storage and management. To learn more, see
http://lustre.org.
Distributed file systems are in common use today, providing file sharing
within LANs, within cluster environments, and across WANs. The complexity
ofimplementingsuchasystemshouldnotbeunderestimated,especiallycon-
sidering that the DFS must be operating-system independent for widespread
adoptionandmustprovideavailabilityandgoodperformanceinthepresence
oflongdistances,commodityhardwarefailures,sometimesfrailnetworking,
andever-increasingusersandworkloads.
19.10 Summary
• Adistributedsystemis acollectionofprocessorsthat donot sharemem-
oryoraclock.Instead,eachprocessorhasitsownlocal memory,and the
processors communicate with one another through various communica-
tionlines,suchas high-speedbuses andthe Internet.Theprocessors ina
distributedsystemvaryinsizeandfunction.
• Adistributedsystemprovidestheuserwithaccesstoallsystemresources.
Access to a shared resource can be provided by data migration, compu-
tationmigration,orprocessmigration.Theaccesscanbespecifiedbythe
userorimplicitlysuppliedbytheoperatingsystemandapplications.PracticeExercises 769
• Protocolstacks,asspecifiedbynetworklayeringmodels,addinformation
toamessagetoensurethatitreachesitsdestination.
• Anamingsystem(suchasDNS)mustbeusedtotranslatefromahostname
toanetworkaddress,andanotherprotocol(suchasARP)maybeneeded
totranslatethenetworknumbertoanetworkdeviceaddress(anEthernet
address,forinstance).
• If systems are located on separate networks, routers are needed to pass
packetsfromsourcenetworktodestinationnetwork.
• The transport protocols UDP and TCP direct packets to waiting processes
through the use of unique system-wide port numbers. In addition, the
TCPprotocol allows the flow of packets to become a reliable,connection-
orientedbytestream.
• There are many challenges to overcome for a distributedsystem to work
correctly. Issues include naming of nodes and processes in the system,
fault tolerance, error recovery, and scalability. Scalability issues include
handling increased load, being fault tolerant, and using efficient storage
schemes,includingthepossibilityofcompressionand/ordeduplication.
• ADFS is a file-service system whose clients, servers, and storage devices
aredispersedamongthesitesofadistributedsystem.Accordingly,service
activity has to be carried out across the network; instead of a single cen-
tralizeddatarepository,therearemultipleindependentstoragedevices.
• There are two main types of DFS models: the client–server model and
the cluster-based model. The client-server model allows transparent file
sharing among one or more clients. The cluster-based model distributes
thefilesamongoneormoredataserversandisbuiltforlarge-scaleparallel
dataprocessing.
• Ideally, a DFS should look to its clients like a conventional, centralized
filesystem(althoughitmaynotconformexactlytotraditionalfile-system
interfacessuchasPOSIX).Themultiplicityanddispersionofitsserversand
storagedevicesshouldbetransparent.AtransparentDFSfacilitatesclient
mobility by bringing the client’s environment to the site where the client
logsin.
• There are several approaches to naming schemes in a DFS. In the sim-
plest approach, files are named by some combination of their host name
and local name, which guarantees a unique system-wide name. Another
approach,popularizedbyNFS,providesameanstoattachremotedirecto-
riestolocaldirectories,thusgivingtheappearanceofacoherentdirectory
tree.
• Requests to access a remote file are usually handled by two complemen-
tary methods. With remote service, requests for accesses are deliveredto
the server. The server machine performs the accesses, and the results are
forwardedbacktotheclient.Withcaching,ifthedataneededtosatisfythe
access request are not already cached, then a copy of the data is brought
from theservertothe client.Accessesareperformedonthe cached copy.
The problemofkeepingthe cached copiesconsistent with themasterfile
isthecache-consistencyproblem.770 Chapter19 NetworksandDistributedSystems
Practice Exercises
19.1 Why would it be a bad idea for routers to pass broadcast packets
betweennetworks?Whatwouldbetheadvantagesofdoingso?
19.2 Discuss the advantages and disadvantages of caching name transla-
tionsforcomputerslocatedinremotedomains.
19.3 Whataretwoformidableproblemsthatdesignersmustsolvetoimple-
mentanetworksystemthathasthequalityoftransparency?
19.4 To build a robust distributed system, you must know what kinds of
failurescanoccur.
a. Listthreepossibletypesoffailureinadistributedsystem.
b. Specify which of the entries in your list also are applicable to a
centralizedsystem.
19.5 Isitalwayscrucialtoknowthatthemessageyouhavesenthasarrived
at its destination safely? If your answer is “yes,” explain why. If your
answeris“no,”giveappropriateexamples.
19.6 Adistributed system has two sites, Aand B. Consider whether site A
candistinguishamongthefollowing:
a. Bgoesdown.
b. ThelinkbetweenAandBgoesdown.
c. B is extremely overloaded, and its response time is 100 times
longerthannormal.
What implications does your answer have for recovery in distributed
systems?
Further Reading
[Peterson and Davie (2012)] and [Kurose and Ross (2017)] provide general
overviewsofcomputernetworks.TheInternetanditsprotocolsaredescribed
in[Comer(2000)].CoverageofTCP/IPcanbefoundin[FallandStevens(2011)]
and [Stevens (1995)]. UNIX network programming is described thoroughly in
[Stevenetal.(2003)].
EthernetandWiFistandardsandspeedsareevolvingquickly.CurrentIEEE
802.3Ethernetstandardscanbefoundathttp://standards.ieee.org/about/get/
802/802.3.html. Current IEEE 802.11 Wireless LAN standards can be found at
http://standards.ieee.org/about/get/802/802.11.html.
Sun’s network file system (NFS) is described by [Callaghan (2000)]. Infor-
mationaboutOpenAFSisavailablefromhttp://www.openafs.org.
Information on the Google file system can be found in [Ghe-
mawat et al. (2003)]. The Google MapReduce method is described in
http://research.google.com/archive/mapreduce.html. The Hadoop dis-
tributedfilesystemisdiscussedin[K.ShvachkoandChansler(2010)],andthe
Hadoopframeworkisdiscussedinhttp://hadoop.apache.org/.
TolearnmoreaboutLustre,seehttp://lustre.org.Bibliography 771
Bibliography
[Callaghan(2000)] B.Callaghan,NFSIllustrated,Addison-Wesley(2000).
[Comer(2000)] D.Comer,InternetworkingwithTCP/IP,VolumeI,FourthEdition,
PrenticeHall(2000).
[FallandStevens(2011)] K.FallandR.Stevens,TCP/IPIllustrated,Volume1:The
Protocols,SecondEdition,JohnWileyandSons(2011).
[Ghemawatetal.(2003)] S. Ghemawat, H. Gobioff, and S.-T. Leung, “The
Google File System”, Proceedings of the ACM Symposium on Operating Systems
Principles(2003).
[K.ShvachkoandChansler(2010)] S. R. K. Shvachko, H. Kuang and
R.Chansler,“TheHadoopDistributedFileSystem”(2010).
[KuroseandRoss(2017)] J.KuroseandK.Ross,ComputerNetworking—ATop–
DownApproach,SeventhEdition,Addison-Wesley(2017).
[PetersonandDavie(2012)] L.L.PetersonandB.S.Davie,ComputerNetworks:
ASystemsApproacm,FifthEdition,MorganKaufmann(2012).
[Stevenetal.(2003)] R.Steven,B.Fenner,andA.Rudoff,UnixNetworkProgram-
ming,Volume1:TheSocketsNetworkingAPI,ThirdEdition,JohnWileyandSons
(2003).
[Stevens(1995)] R. Stevens, TCP/IP Illustrated, Volume 2: The Implementation,
Addison-Wesley(1995).Exercises EX-56
Chapter 19 Exercises
19.7 What is the difference between computation migration and process
migration?Whichiseasiertoimplement,andwhy?
19.8 Even though the OSI model of networking specifies seven layers of
functionality, most computer systems use fewer layers to implement
a network. Why do they use fewer layers? What problems could the
useoffewerlayerscause?
19.9 ExplainwhydoublingthespeedofthesystemsonanEthernetsegment
mayresultindecreasednetworkperformancewhentheUDPtransport
protocolisused.Whatchangescouldhelpsolvethisproblem?
19.10 What are the advantages of using dedicated hardware devices for
routers?Whatarethedisadvantagesofusingthesedevicescompared
withusinggeneral-purposecomputers?
19.11 Inwhatwaysisusinganameserverbetterthanusingstatichosttables?
What problems or complications are associated with name servers?
What methods could you use to decrease the amount of traffic name
serversgeneratetosatisfytranslationrequests?
19.12 Nameserversareorganizedinahierarchicalmanner.Whatisthepur-
poseofusingahierarchicalorganization?
19.13 The lowerlayersoftheOSI networkmodelprovidedatagramservice,
with no delivery guarantees for messages. Atransport-layer protocol
such as TCPis used to provide reliability. Discuss the advantages and
disadvantages of supporting reliable message delivery at the lowest
possiblelayer.
19.14 RuntheprogramshowninFigure19.4anddeterminetheIPaddresses
ofthefollowinghostnames:
• www.wiley.com
• www.cs.yale.edu
• www.apple.com
• www.westminstercollege.edu
• www.ietf.org
19.15 A DNS name can map to multiple servers, such as www.google.com.
However,ifweruntheprogramshowninFigure19.4,wegetonlyone
IP address. Modify the program to display all the server IP addresses
insteadofjustone.
19.16 The original HTTP protocol used TCP/IP as the underlying network
protocol.Foreachpage,graphic,orapplet,aseparateTCPsessionwas
constructed,used,andtorndown.Becauseoftheoverheadofbuilding
and destroying TCP/IP connections, performance problems resulted
from this implementation method. Would using UDP rather than TCP
beagoodalternative?Whatotherchangescouldyoumaketoimprove
HTTPperformance?EX-57
19.17 What are the advantages and the disadvantages of making the com-
puternetworktransparenttotheuser?
19.18 WhatarethebenefitsofaDFScomparedwithafilesysteminacentral-
izedsystem?
19.19 Foreachofthefollowingworkloads,identifywhetheracluster-based
oraclient–serverDFSmodelwouldhandletheworkloadbest.Explain
youranswers.
• Hostingstudentfilesinauniversitylab.
• ProcessingdatasentbytheHubbletelescope.
• Sharingdatawithmultipledevicesfromahomeserver.
19.20 DiscusswhetherOpenAFSandNFSprovidethefollowing:(a)location
transparencyand(b)locationindependence.
19.21 Under what circumstances would a client prefer a location-
transparent DFS? Under what circumstances would she prefer a
location-independentDFS?Discussthereasonsforthesepreferences.
19.22 What aspects of a distributed system would you select for a system
runningonatotallyreliablenetwork?
19.23 Compareandcontrastthetechniquesofcachingdiskblockslocally,on
aclientsystem,andremotely,onaserver.
19.24 Which scheme would likely result in a greater space saving on a
multiuser DFS: file-level deduplication or block-level deduplication?
Explainyouranswer.
19.25 What typesofextrametadatainformationwouldneedtobestoredin
aDFSthatusesdeduplication?Part Nine
Case Studies
Wenowintegratetheconceptsdescribedearlierinthisbookbyexamin-
ingreal operating systems. We cover two such systems in detail—Linux
andWindows10.
We chose Linux for several reasons: it is popular, it is freely available,
and it represents a full-featured UNIX system. This gives a student of
operatingsystemsanopportunitytoread—andmodify—real operating-
systemsourcecode.
WithWindows10,thestudentcanexamineamodernoperatingsys-
temwhosedesignandimplementationaredrasticallydifferentfromthose
of UNIX.Thisoperating system from Microsoft isvery popularas a desk-
topoperatingsystem,butitcanalsobeusedasanoperatingsystemfor
mobiledevices.Windows10hasamoderndesignandfeaturesalookand
feelverydifferentfromearlieroperatingsystemsproducedbyMicrosoft.20
CHAPTER
The Linux System
Updatedby RobertLove
Thischapterpresentsanin-depthexaminationoftheLinuxoperatingsystem.
By examining a complete,real system, we can see how the concepts we have
discussedrelatebothtooneanotherandtopractice.
LinuxisavariantofUNIXthathasgainedpopularityoverthelastseveral
decades, powering devices as small as mobile phones and as large as room-
fillingsupercomputers.Inthischapter,welookatthehistoryanddevelopment
ofLinuxandcovertheuserandprogrammerinterfacesthatLinuxpresents—
interfacesthatoweagreatdealtotheUNIXtradition.Wealsodiscussthedesign
andimplementationoftheseinterfaces.Linuxisarapidlyevolvingoperating
system. This chapter describes developments through the Linux 4.12 kernel,
whichwasreleasedin2017.
CHAPTER OBJECTIVES
• Explore the history of the UNIX operating system from which Linux is
derivedandtheprinciplesuponwhichLinux’sdesignisbased.
• Examine the Linux process and thread models and illustrate how Linux
schedulesthreadsandprovidesinterprocesscommunication.
• LookatmemorymanagementinLinux.
• ExplorehowLinuximplementsfilesystemsandmanagesI/Odevices.
20.1 Linux History
LinuxlooksandfeelsmuchlikeanyotherUNIXsystem;indeed,UNIXcompat-
ibility has been a major design goal of the Linux project. However, Linux is
muchyoungerthanmostUNIXsystems.Itsdevelopmentbeganin1991,when
a Finnish university student, Linus Torvalds, began creating a small but self-
containedkernelforthe80386processor,thefirsttrue32-bitprocessorinIntel’s
rangeofPC-compatibleCPUs.
775776 Chapter20 TheLinuxSystem
Earlyinitsdevelopment,theLinuxsourcecodewasmadeavailablefree—
bothatnocostandwithminimaldistributionalrestrictions—ontheInternet.
Asaresult,Linux’shistoryhasbeenoneofcollaborationbymanydevelopers
fromallaroundtheworld,correspondingalmostexclusivelyovertheInternet.
From an initial kernel that partially implemented a small subset of the UNIX
systemservices,theLinuxsystemhasgrowntoincludeallofthefunctionality
expectedofamodernUNIXsystem.
In its early days, Linux development revolved largely around the central
operating-systemkernel—thecore,privilegedexecutivethatmanagesallsys-
tem resources and interacts directly with the computer hardware. We need
much more than this kernel, of course, to produce a full operating system.
WethusneedtomakeadistinctionbetweentheLinuxkernelandacomplete
Linux system. The Linux kernel is an original piece of software developed
fromscratchbytheLinuxcommunity.TheLinuxsystem,asweknowittoday,
includes a multitude of components, some written from scratch, others bor-
rowed from other developmentprojects, and still others createdin collabora-
tionwithotherteams.
ThebasicLinuxsystemisastandardenvironmentforapplicationsanduser
programming, but it does not enforce any standard means of managing the
available functionality as a whole. As Linux has matured, a need has arisen
for another layer of functionality on top of the Linux system. This need has
beenmetbyvariousLinuxdistributions.ALinuxdistributionincludesallthe
standard components of the Linux system, plus a set of administrative tools
to simplify the initial installation and subsequent upgrading of Linux and to
manage installation and removal of other packages on the system. A mod-
ern distribution also typically includes tools for management of file systems,
creation and management of user accounts, administration of networks, web
browsers,wordprocessors,andsoon.
20.1.1 The Linux Kernel
The first Linux kernel released to the public was version 0.01, dated May 14,
1991. It had no networking, ran only on 80386-compatible Intel processors
and PC hardware, and had extremely limited device-driver support. The vir-
tual memory subsystem was also fairly basic and included no support for
memory-mappedfiles;however,eventhisearlyincarnationsupportedshared
pages withcopy-on-write and protectedaddressspaces. The only file system
supported was the Minix file system, as the first Linux kernels were cross-
developedonaMinixplatform.
Thenextmilestone,Linux1.0,wasreleasedonMarch14,1994.Thisrelease
culminatedthreeyearsofrapiddevelopmentoftheLinuxkernel.Perhapsthe
single biggest new feature was networking: 1.0 included support for UNIX’s
standard TCP/IP networking protocols, as well as a BSD-compatible socket
interfacefornetworkingprogramming.Device-driversupportwasaddedfor
running IPover Ethernet or (viathe PPPor SLIPprotocols) over seriallines or
modems.
The1.0kernelalsoincludedanew,muchenhancedfilesystemwithoutthe
limitations of the original Minix file system, and it supported a range of SCSI
controllersforhigh-performancediskaccess.Thedevelopersextendedthevir-20.1 LinuxHistory 777
tualmemorysubsystemtosupportpagingtoswapfilesandmemorymapping
of arbitrary files (but only read-only memory mapping was implemented in
1.0).
Arangeofextrahardwaresupportwasincludedinthisrelease.Although
stillrestrictedtotheIntelPCplatform,hardwaresupporthadgrowntoinclude
floppy-diskandCD-ROMdevices,aswellassoundcards,arangeofmice,and
internationalkeyboards.Floating-pointemulationwasprovidedinthekernel
for 80386 users who had no 80387 math coprocessor. System V UNIX-style
interprocess communication (IPC), including shared memory, semaphores,
andmessagequeues,wasimplemented.
Atthispoint,developmentstartedonthe1.1kernelstream,butnumerous
bug-fixpatcheswerereleasedsubsequentlyfor1.0.Apatternwasadoptedas
the standard numbering convention for Linux kernels. Kernels with an odd
minor-version number, such as 1.1 or 2.5, are development kernels; even-
numbered minor-version numbers are stable production kernels. Updates
for the stable kernels are intended only as remedial versions, whereas the
developmentkernelsmayincludenewerandrelativelyuntestedfunctionality.
Aswewillsee,thispatternremainedineffectuntilversion3.
InMarch1995,the1.2kernelwasreleased.Thisreleasedidnotoffernearly
thesameimprovementinfunctionalityasthe1.0release,butitdidsupporta
much wider variety of hardware, including the new PCI hardware bus archi-
tecture.DevelopersaddedanotherPC-specificfeature—supportforthe80386
CPU’s virtual 8086 mode—to allow emulation of the DOS operating system
for PC computers. They also updated the IP implementation with support
for accounting and firewalling.Simplesupport for dynamically loadableand
unloadablekernelmoduleswassuppliedaswell.
The1.2kernelwasthefinalPC-onlyLinuxkernel.Thesourcedistribution
for Linux 1.2 included partially implemented support for SPARC, Alpha, and
MIPSCPUs,butfullintegrationoftheseotherarchitecturesdidnotbeginuntil
afterthestable1.2kernelwasreleased.
The Linux1.2releaseconcentrated onwiderhardwaresupportand more
complete implementations of existing functionality. Much new functionality
was under developmentat the time, but integration of the new code into the
main kernel source code was deferred until after the stable 1.2 kernel was
released. As a result, the 1.3 development stream saw a great deal of new
functionalityaddedtothekernel.
ThisworkwasreleasedinJune1996asLinuxversion2.0.Thisreleasewas
givenamajor version-number increment because of twomajor new capabili-
ties: support for multiple architectures, including a 64-bit native Alpha port,
and symmetric multiprocessing (SMP) support. Additionally, the memory-
management code was substantially improved to provide a unified cache
for file-system data independent of the caching of block devices. As a result
of this change, the kernel offered greatly increased file-system and virtual-
memory performance. For the first time, file-system caching was extended
to networked file systems, and writable memory-mapped regions were also
supported. Other major improvements included the addition of internal ker-
nelthreads,amechanismexposingdependenciesbetweenloadablemodules,
supportfortheautomaticloadingofmodulesondemand,file-systemquotas,
andPOSIX-compatiblereal-timeprocess-schedulingclasses.778 Chapter20 TheLinuxSystem
Improvements continued with the release of Linux 2.2 in 1999. Aport to
UltraSPARCsystemswasadded.Networkingwasenhancedwithmoreflexible
firewalling, improved routing and traffic management, and support for TCP
large window and selective acknowledgement. Acorn, Apple, and NT disks
could now be read, and NFS was enhanced with a new kernel-mode NFS
daemon.Signalhandling,interrupts,andsomeI/Owerelockedatafinerlevel
thanbeforetoimprovesymmetricmultiprocessor(SMP)performance.
Advances in the 2.4 and 2.6 releases of the kernel included increased
support for SMP systems, journaling file systems, and enhancements to the
memory-managementandblockI/Osystems.Thethreadschedulerwasmod-
ifiedinversion2.6,providinganefficientO(1)schedulingalgorithm.Inaddi-
tion,the2.6kernelwaspreemptive,allowingathreadstobepreemptedeven
whilerunninginkernelmode.
Linuxkernelversion3.0wasreleasedinJuly2011.Themajorversionbump
from 2 to 3 occurred to commemorate the twentieth anniversary of Linux.
Newfeaturesincludeimprovedvirtualizationsupport,anewpagewrite-back
facility, improvements to the memory-management system, and yet another
newthreadscheduler—theCompletelyFairScheduler(CFS).
Linux kernel version 4.0 was released in April 2015. This time the major
version bump was entirely arbitrary; Linux kernel developers simply grew
tired of ever-larger minor versions. Today Linux kernel versions do not sig-
nifyanythingotherthanreleaseordering.The4.0kernelseriesprovidedsup-
portfornewarchitectures,improvedmobilefunctionality,andmanyiterative
improvements.Wefocusonthisnewestkernelintheremainderofthischapter.
20.1.2 The Linux System
As we noted earlier,the Linux kernelforms the core of the Linux project,but
other components make up a complete Linux operating system.Whereas the
Linux kernel is composed entirely of code written from scratch specifically
for the Linux project, much of the supporting software that makes up the
Linux system is not exclusive to Linux but is common to a number of UNIX-
likeoperatingsystems.Inparticular,Linuxusesmanytoolsdevelopedaspart
of Berkeley’s BSD operating system, MIT’s X Window System, and the Free
SoftwareFoundation’sGNUproject.
This sharing of tools has worked in both directions. The main system
libraries of Linux were originated by the GNU project, but the Linux commu-
nitygreatlyimprovedthelibrariesbyaddressingomissions,inefficiencies,and
bugs. Other components, such as the GNU C compiler (gcc), were alreadyof
sufficientlyhighqualitytobeuseddirectlyinLinux.Thenetworkadministra-
tiontoolsunderLinuxwerederivedfromcodefirstdevelopedfor4.3BSD,but
morerecentBSDderivatives,suchasFreeBSD,haveborrowedcodefromLinux
in return. Examplesof this sharing include the Intel floating-point-emulation
mathlibraryandthePCsound-hardwaredevicedrivers.
TheLinuxsystemasawholeismaintainedbyaloosenetworkofdevelop-
ers collaborating over the Internet, with small groups or individuals having
responsibility for maintaining the integrity of specific components. A small
number of public Internet file-transfer-protocol (FTP) archive sites act as de
factostandardrepositoriesforthesecomponents.TheFileSystemHierarchy20.1 LinuxHistory 779
Standard document is also maintained by the Linux community as a means
of ensuring compatibility across the various system components. This stan-
dardspecifiestheoveralllayoutofastandardLinuxfilesystem;itdetermines
underwhichdirectorynamesconfigurationfiles,libraries,systembinaries,and
run-timedatafilesshouldbestored.
20.1.3 Linux Distributions
In theory, anybody can install a Linux system by fetching the latest revisions
ofthenecessarysystemcomponentsfromtheftpsitesandcompilingthem.In
Linux’searlydays,thisispreciselywhataLinuxuserhadtodo.AsLinuxhas
matured, however, various individuals and groups have attempted to make
this job less painful by providing standard, precompiled sets of packages for
easyinstallation.
These collections, or distributions, include much more than just the basic
Linux system. They typically include extra system-installation and manage-
mentutilities,aswellasprecompiledandready-to-installpackagesofmanyof
thecommonUNIX tools,suchas news servers,webbrowsers,text-processing
andeditingtools,andevengames.
The first distributions managed these packages by simply providing a
meansofunpackingallthefilesintotheappropriateplaces.Oneoftheimpor-
tant contributions of modern distributions, however, is advanced package
management.Today’sLinuxdistributionsincludeapackage-trackingdatabase
thatallowspackagestobeinstalled,upgraded,orremovedpainlessly.
The SLS distribution, dating back to the early days of Linux, was the first
collection of Linux packages that was recognizable as a complete distribu-
tion.Althoughitcould beinstalledas asingleentity,SLSlackedthepackage-
management tools now expected of Linux distributions. The Slackware dis-
tribution represented a great improvement in overall quality, even though it
also had poor package management. In fact, it is still one of the most widely
installeddistributionsintheLinuxcommunity.
Since Slackware’s release, many commercial and noncommercial Linux
distributionshavebecomeavailable.RedHatandDebianareparticularlypop-
ulardistributions;thefirstcomesfromacommercialLinuxsupportcompany
andthesecondfromthefree-softwareLinuxcommunity.Othercommercially
supportedversionsofLinuxincludedistributionsfromCanonicalandSuSE,
andmanyothers.TherearetoomanyLinuxdistributionsincirculationforus
to list all of them here. The variety of distributions does not prevent Linux
distributionsfrombeingcompatible,however.TheRPMpackagefileformatis
used, or at least understood, by the majority of distributions, and commer-
cial applications distributed in this format can be installed and run on any
distributionthatcanacceptRPMfiles.
20.1.4 Linux Licensing
The Linux kernel is distributed under version 2.0 of the GNU General Public
License(GPL),thetermsofwhicharesetoutbytheFreeSoftwareFoundation.
Linuxisnotpublic-domainsoftware.Publicdomainimpliesthattheauthors
have waived copyright rights in the software, but copyright rights in Linux
code are stillheld by the code’s various authors. Linux isfree software, how-780 Chapter20 TheLinuxSystem
ever,inthesensethatpeoplecancopyit,modifyit,useitinanymannerthey
want,andgiveaway(orsell)theirowncopies.
The main implication of Linux’s licensing terms is that nobody using
Linux, or creating a derivativeof Linux (a legitimate exercise), can distribute
thederivativewithoutincludingthesourcecode.Softwarereleasedunderthe
GPLcannot be redistributedas a binary-only product. If you release software
that includes any components covered by the GPL, then, under the GPL, you
must make source code available alongside any binary distributions. (This
restrictiondoesnotprohibitmaking—orevenselling—binarysoftwaredistri-
butions,aslongasanybodywhoreceivesbinariesisalsogiventheopportunity
togettheoriginatingsourcecodeforareasonabledistributioncharge.)
20.2Design Principles
Initsoveralldesign,Linuxresemblesother traditional,nonmicrokernel UNIX
implementations. It is a multiuser, preemptively multitasking system with a
full set of UNIX-compatible tools. Linux’s file system adheres to traditional
UNIX semantics, and the standard UNIX networking model is fully imple-
mented. The internal details of Linux’s design have been influenced heavily
bythehistoryofthisoperatingsystem’sdevelopment.
Although Linux runs on a wide variety of platforms, it was originally
developed exclusively on PC architecture. Agreat deal of that early develop-
ment was carried out by individual enthusiasts rather than by well-funded
developmentorresearchfacilities,sofromthestartLinuxattemptedtosqueeze
as much functionality as possible from limited resources. Today, Linux can
runhappilyonamultiprocessormachinewithhundredsofgigabytesofmain
memory and many terabytes of disk space, but it is still capable of operating
usefullyinunder16-MBofRAM.
As PCs became more powerful and as memory and hard disks became
cheaper,theoriginal,minimalistLinuxkernelsgrewtoimplementmoreUNIX
functionality. Speedand efficiency are still important design goals, but much
recent and current work on Linux has concentrated on a third major design
goal: standardization. One of the prices paid for the diversityof UNIX imple-
mentations currently available is that source code written for one may not
necessarily compile or run correctly on another. Even when the same system
callsarepresentontwodifferentUNIXsystems,theydonotnecessarilybehave
inexactlythe sameway. The POSIX standardscomprisea setofspecifications
fordifferentaspectsofoperating-systembehavior.TherearePOSIXdocuments
for common operating-system functionality and for extensions such as pro-
cess threads and real-time operations. Linux is designed to comply with the
relevantPOSIXdocuments,andatleasttwoLinuxdistributionshaveachieved
officialPOSIXcertification.
Becauseitgivesstandardinterfacestoboththeprogrammerandtheuser,
LinuxpresentsfewsurprisestoanybodyfamiliarwithUNIX.Wedonotdetail
these interfaces here. The sections on the programmer interface (Section C.3)
anduserinterface(SectionC.4)ofBSDapplyequallywelltoLinux.Bydefault,
however, the Linux programming interface adheres to SVR4 UNIX semantics,
ratherthantoBSDbehavior.Aseparatesetoflibrariesisavailabletoimplement
BSDsemanticsinplaceswherethetwobehaviorsdiffersignificantly.20.2 DesignPrinciples 781
Many other standards exist in the UNIX world, but full certification of
Linux with respect to these standards is sometimes slowed because certifica-
tionisoftenavailableonlyforafee,andtheexpenseinvolvedincertifyingan
operating system’s compliance with most standards is substantial. However,
supportingawidebaseofapplicationsisimportantforanyoperatingsystem,
so implementation of standards is a major goal for Linux development,even
without formal certification. In addition to the basic POSIX standard, Linux
currently supports the POSIX threading extensions—Pthreads—and a subset
ofthePOSIXextensionsforreal-timeprocesscontrol.
20.2.1 Components of a Linux System
TheLinuxsystemiscomposedofthreemainbodiesofcode,inlinewithmost
traditionalUNIXimplementations:
1. Kernel. The kernel is responsible for maintaining all the important
abstractions of the operating system, including such things as virtual
memoryandprocesses.
2. Systemlibraries.Thesystemlibrariesdefineastandardsetoffunctions
throughwhichapplicationscaninteractwiththekernel.Thesefunctions
implementmuchoftheoperating-systemfunctionalitythatdoesnotneed
thefullprivilegesofkernelcode.Themostimportantsystemlibraryisthe
Clibrary,knownaslibc.InadditiontoprovidingthestandardClibrary,
libc implements the user mode side of the Linux system call interface,
aswellasothercriticalsystem-levelinterfaces.
3. System utilities. The system utilities are programs that perform indi-
vidual,specializedmanagementtasks.Somesystemutilitiesareinvoked
justoncetoinitializeandconfiguresomeaspectofthesystem.Others—
known as daemons in UNIX terminology—run permanently, handling
such tasks as responding to incoming network connections, accepting
logonrequestsfromterminals,andupdatinglogfiles.
Figure 20.1 illustrates the various components that make up a full Linux
system.Themostimportantdistinctionhereisbetweenthekernelandevery-
thing else. All the kernel code executes in the processor’s privileged mode
system- user
user
management utility compilers
processes
programs programs
system shared libraries
Linux kernel
loadable kernel modules
Figure20.1 ComponentsoftheLinuxsystem.782 Chapter20 TheLinuxSystem
with full access to all the physical resources of the computer. Linux refers to
thisprivilegedmodeaskernelmode.UnderLinux,nousercodeisbuiltinto
the kernel. Any operating-system-support code that does not need to run in
kernelmodeisplacedintothesystemlibrariesandrunsinusermode.Unlike
kernelmode,usermodehasaccessonlytoacontrolledsubsetofthesystem’s
resources.
Although various modern operating systems have adopted a message-
passing architecture for their kernel internals, Linux retains UNIX’s historical
model: the kernel is created as a single, monolithic binary. The main reason
is performance. Because all kernel code and data structures are kept in a sin-
gle address space, no context switches are necessary when a thread calls an
operating-system function or when a hardware interrupt is delivered. More-
over,thekernelcanpassdataandmakerequestsbetweenvarioussubsystems
usingrelativelycheapCfunctioninvocationandnotmorecomplicatedinter-
processcommunication (IPC).Thissingleaddressspacecontains notonly the
core scheduling and virtual memory code but all kernel code, including all
devicedrivers,filesystems,andnetworkingcode.
Eventhoughallthekernelcomponentssharethissamemeltingpot,there
is still room for modularity. In the same way that user applications can load
shared libraries at run time to pull in a needed piece of code, so the Linux
kernel can load (and unload) modules dynamically at run time. The kernel
does not need to know in advance which modules may be loaded—they are
trulyindependentloadablecomponents.
TheLinuxkernelformsthecoreoftheLinuxoperatingsystem.Itprovides
all the functionality necessary to manage processes and run threads, and it
providessystem services to give arbitrated and protectedaccess to hardware
resources.Thekernelimplementsallthefeaturesrequiredtoqualifyasanoper-
atingsystem.Onitsown,however,theoperatingsystemprovidedbytheLinux
kernel is not a complete UNIX system. It lacks much of the functionality and
behavior of UNIX, and the features that it does provide are not necessarily in
theformatinwhichaUNIXapplicationexpectsthemtoappear.Theoperating-
system interface visibleto running applications is not maintained directlyby
thekernel.Rather,applicationsmakecallstothesystemlibraries,whichinturn
calltheoperating-systemservicesasnecessary.
The systemlibraries providemany typesof functionality. At the simplest
level,theyallowapplicationstomakesystemcallstotheLinuxkernel.Making
a system call involves transferring control from unprivileged user mode to
privileged kernel mode; the details of this transfer vary from architecture to
architecture.Thelibrariestakecareofcollectingthesystem-callargumentsand,
ifnecessary,arrangingthoseargumentsinthespecialformnecessarytomake
thesystemcall.
Thelibrariesmayalsoprovidemorecomplexversionsofthebasicsystem
calls. For example, the C language’s buffered file-handling functions are all
implementedinthesystemlibraries,providingmoreadvancedcontroloffile
I/Othanthebasickernelsystemcalls.Thelibrariesalsoprovideroutinesthat
donotcorrespondtosystemcallsatall,suchassortingalgorithms,mathemat-
ical functions, and string-manipulation routines. All the functions necessary
tosupport the running of UNIX or POSIX applications areimplementedin the
systemlibraries.20.3 KernelModules 783
The Linuxsystemincludesawidevarietyofuser-modeprograms—both
systemutilitiesanduserutilities.Thesystemutilitiesincludealltheprograms
necessarytoinitializeandthenadministerthesystem,suchasthosetosetup
networkinginterfacesandtoaddandremoveusersfromthesystem.Userutil-
itiesarealsonecessarytothebasicoperationofthesystembutdonotrequire
elevatedprivilegestorun.Theyincludesimplefile-managementutilitiessuch
as those to copy files, create directories, and edit text files. One of the most
important user utilities is the shell, the standard command-line interface on
UNIX systems. Linux supports many shells; the most common is the bourne-
againshell(bash).
20.3Kernel Modules
TheLinuxkernelhastheabilitytoloadandunloadarbitrarysectionsofkernel
codeondemand.Theseloadablekernelmodulesruninprivilegedkernelmode
and as a consequence have full access to all the hardware capabilities of the
machineonwhichtheyrun.Intheory,thereisnorestrictiononwhatakernel
moduleisallowedtodo.Amongotherthings,akernelmodulecanimplement
adevicedriver,afilesystem,oranetworkingprotocol.
Kernelmodulesareconvenientforseveralreasons.Linux’ssourcecodeis
free, so anybody wanting to write kernel code is able to compile a modified
kernelandtorebootintothatnewfunctionality.However,recompiling,relink-
ing,andreloadingtheentirekernelisacumbersomecycletoundertakewhen
youaredevelopinganewdriver.Ifyouusekernelmodules,youdonothave
tomakeanewkerneltotestanewdriver—thedrivercanbecompiledonits
ownandloadedintothealreadyrunningkernel.Ofcourse,onceanewdriver
iswritten,itcanbedistributedasamodulesothatotheruserscanbenefitfrom
itwithouthavingtorebuildtheirkernels.
This latter point has another implication. Because it is covered by the
GPLlicense,theLinuxkernelcannotbereleasedwithproprietarycomponents
addedtoitunlessthosenewcomponentsarealsoreleasedundertheGPLand
the source code for them is made available on demand. The kernel’s module
interfaceallowsthirdpartiestowriteanddistribute,ontheirownterms,device
driversorfilesystemsthatcouldnotbedistributedundertheGPL.
KernelmodulesallowaLinuxsystemtobesetupwithastandardminimal
kernel, without any extra device drivers built in. Any device drivers that the
user needs can be either loaded explicitly by the system at startup or loaded
automatically by the system on demand and unloaded when not in use. For
example,amousedrivercanbeloadedwhenaUSBmouseispluggedintothe
systemandunloadedwhenthemouseisunplugged.
ThemodulesupportunderLinuxhasfourcomponents:
1. The module-management system allows modules to be loaded into
memoryandtocommunicatewiththerestofthekernel.
2. The module loader and unloader, which are user-mode utilities, work
withthemodule-managementsystemtoloadamoduleintomemory.784 Chapter20 TheLinuxSystem
3. The driver-registration system allows modules to tell the rest of the
kernelthatanewdriverhasbecomeavailable.
4. A conflict-resolutio mechanism allows different device drivers
to reserve hardware resources and to protect those resources from
accidentalusebyanotherdriver.
20.3.1 Module Management
Loadingamodulerequiresmorethanjustloadingitsbinarycontentsintoker-
nelmemory.Thesystemmustalsomakesurethatany referencesthemodule
makestokernelsymbolsorentrypointsareupdatedtopointtothecorrectloca-
tionsinthekernel’saddressspace.Linuxdealswiththisreferenceupdatingby
splittingthejobofmoduleloadingintotwoseparatesections:themanagement
ofsectionsofmodulecodeinkernelmemoryandthehandlingofsymbolsthat
modulesareallowedtoreference.
Linuxmaintainsaninternalsymboltableinthekernel.Thissymboltable
doesnotcontainthefullsetofsymbolsdefinedinthekernelduringthelatter’s
compilation;rather,asymbolmustbeexplicitlyexported.Thesetofexported
symbols constitutes a well-defined interface by which a module can interact
withthekernel.
Although exporting symbols from a kernel function requires an explicit
requestbytheprogrammer,nospecialeffortisneededtoimportthosesymbols
intoamodule.Amodulewriterjust usesthestandardexternallinking ofthe
Clanguage.Anyexternalsymbolsreferencedbythemodulebutnotdeclared
byitaresimplymarkedasunresolvedinthefinalmodulebinaryproducedby
the compiler. When a module is to be loaded into the kernel, a system utility
first scans the module for these unresolved references. All symbols that still
needtoberesolvedarelookedupinthekernel’ssymboltable,andthecorrect
addressesofthosesymbolsinthecurrentlyrunningkernelaresubstitutedinto
themodule’scode.Onlythenisthemodulepassedtothekernelforloading.If
thesystemutilitycannotresolveallreferencesinthemodulebylookingthem
upinthekernel’ssymboltable,thenthemoduleisrejected.
The loading of the moduleis performedin two stages.First, the module-
loader utility asks the kernel to reserve a continuous area of virtual kernel
memory for the module. The kernel returns the address of the memory allo-
cated, and the loader utility can use this address to relocate the module’s
machinecodetothecorrectloadingaddress.Asecondsystemcallthenpasses
the module, plus any symbol table that the new module wants to export, to
thekernel.Themoduleitselfisnowcopiedverbatimintothepreviouslyallo-
cated space, and the kernel’s symbol table is updated with the new symbols
forpossibleusebyothermodulesnotyetloaded.
The final module-management component is the module requester. The
kernel defines a communication interface to which a module-management
programcanconnect.Withthisconnectionestablished,thekernelwillinform
the management process whenever a process requests a device driver, file
system, or network service that is not currently loaded and will give the
managertheopportunitytoloadthatservice.Theoriginalservicerequestwill
completeoncethemoduleisloaded.Themanagerprocessregularlyqueriesthe
kerneltoseewhetheradynamicallyloadedmoduleisstillinuseandunloads
thatmodulewhenitisnolongeractivelyneeded.20.3 KernelModules 785
20.3.2 Driver Registration
Onceamoduleisloaded,itremainsnomorethananisolatedregionofmemory
until it lets the rest of the kernel know what new functionality it provides.
The kernel maintains dynamic tables of all known drivers and provides a
set of routines to allow drivers to be added to or removed from these tables
at any time. The kernel makes sure that it calls a module’s startup routine
when that module is loaded and calls the module’s cleanup routine before
that module is unloaded. These routines are responsible for registering the
module’sfunctionality.
A module may register many types of functionality; it is not limited to
only one type. For example, a device driver might want to register two sep-
aratemechanismsforaccessingthedevice.Registrationtablesinclude,among
others,thefollowingitems:
• Device drivers. These drivers include character devices (such as print-
ers, terminals, and mice), block devices (including all disk drives), and
networkinterfacedevices.
• File systems. The file system may be anything that implements Linux’s
virtualfilesystemcallingroutines.Itmightimplementaformatforstoring
filesonadisk,butitmightequallywellbeanetworkfilesystem,suchas
NFS,oravirtualfilesystemwhosecontentsaregeneratedondemand,such
asLinux’s/procfilesystem.
• Networkprotocols.Amodulemayimplementanentirenetworkingproto-
col,suchasTCP,orsimplyanewsetofpacket-filteringrulesforanetwork
firewall.
• Binary format. This format specifies a way of recognizing, loading, and
executinganewtypeofexecutablefile.
Inaddition,amodulecanregisteranewsetofentriesinthesysctland/proc
tables,toallowthatmoduletobeconfigureddynamically(Section20.7.4).
20.3.3 Conflict Resolution
CommercialUNIXimplementationsareusuallysoldtorunonavendor’sown
hardware. One advantage of a single-supplier solution is that the software
vendorhas a good ideaabout what hardware configurations are possible.PC
hardware,however,comesinavastnumberofconfigurations,withlargenum-
bers of possible drivers for devices such as network cards and video display
adapters.Theproblemofmanagingthehardwareconfigurationbecomesmore
severewhenmodulardevicedriversaresupported,sincethecurrentlyactive
setofdevicesbecomesdynamicallyvariable.
Linux provides a central conflict-resolution mechanism to help arbitrate
accesstocertainhardwareresources.Itsaimsareasfollows:
• Topreventmodulesfromclashingoveraccesstohardwareresources
• Topreventautoprobes—device-driverprobesthatauto-detectdevicecon-
figuration—frominterferingwithexistingdevicedrivers786 Chapter20 TheLinuxSystem
• To resolve conflicts among multiple drivers trying to access the same
hardware—as,forexample,whenboththeparallelprinterdriverandthe
parallellineIP(PLIP)networkdrivertrytotalktotheparallelport
To these ends, the kernel maintains lists of allocated hardware resources.
The PC has alimitednumber ofpossibleI/O ports(addressesinitshardware
I/Oaddressspace),interruptlines,andDMAchannels.Whenanydevicedriver
wantstoaccesssucharesource,itisexpectedtoreservetheresourcewiththe
kerneldatabasefirst.Thisrequirementincidentallyallowsthesystemadmin-
istrator to determine exactly which resources have been allocated by which
driveratanygivenpoint.
A module is expected to use this mechanism to reserve in advance any
hardwareresourcesthatitexpectstouse.Ifthereservationisrejectedbecause
the resource is not present or is already in use, then it is up to the module
to decide how to proceed. It may fail in its initialization attempt and request
that it beunloadedif itcannot continue, or itmay carry on, using alternative
hardwareresources.
20.4Process Management
Aprocess is the basic context in which all user-requested activity is serviced
withintheoperatingsystem.TobecompatiblewithotherUNIXsystems,Linux
must use a process model similar to those of other versions of UNIX. Linux
operates differently from UNIX in a few key places, however. In this section,
we review the traditional UNIX process model (Section C.3.2) and introduce
Linux’sthreadingmodel.
20.4.1 The fork() and exec() Process Model
ThebasicprincipleofUNIXprocessmanagementistoseparateintotwosteps
two operations that are usually combined into one: the creation of a new
process and the running of a new program. Anew process is created by the
fork()systemcall,andanewprogramisrunafteracalltoexec().Theseare
two distinctly separate functions. We can create a new process with fork()
without running a new program—the new subprocess simply continues to
execute exactly the same program, at exactly the same point, that the first
(parent)processwasrunning.Inthesameway,runninganewprogramdoes
notrequirethatanewprocessbecreatedfirst.Anyprocessmaycallexec()at
any time. Anew binary object is loadedinto the process’s address space and
thenewexecutablestartsexecutinginthecontextoftheexistingprocess.
This model has the advantage of great simplicity. It is not necessary to
specifyeverydetailoftheenvironmentofanewprograminthesystemcallthat
runsthatprogram.Thenewprogramsimplyrunsinitsexistingenvironment.
Ifaparentprocesswishestomodifytheenvironmentinwhichanewprogram
istoberun,itcanforkandthen,stillrunningtheoriginalexecutableinachild
process,makeanysystemcallsitrequirestomodifythatchildprocessbefore
finallyexecutingthenewprogram.
Under UNIX, then, a process encompasses all the information that the
operatingsystemmustmaintaintotrackthecontextofasingleexecutionofa20.4 ProcessManagement 787
singleprogram.UnderLinux,wecanbreakdownthiscontextintoanumberof
specificsections.Broadly,processpropertiesfallintothreegroups:theprocess
identity,environment,andcontext.
20.4.1.1 ProcessIdentity
Aprocessidentityconsistsmainlyofthefollowingitems:
• Process ID (PID). Each process has a unique identifier. The PID is used to
specifytheprocesstotheoperatingsystemwhen anapplicationmakesa
systemcalltosignal,modify,orwaitfortheprocess.Additionalidentifiers
associate the process with a process group (typically, a tree of processes
forkedbyasingleusercommand)andloginsession.
• Credentials.EachprocessmusthaveanassociateduserIDandoneormore
groupIDs(usergroupsarediscussedinSection13.4.2)thatdeterminethe
rightsofaprocesstoaccesssystemresourcesandfiles.
• Personality.ProcesspersonalitiesarenottraditionallyfoundonUNIXsys-
tems,butunderLinuxeachprocesshasanassociatedpersonalityidentifier
thatcanslightlymodifythesemanticsofcertainsystemcalls.Personalities
are primarily used by emulation libraries to request that system calls be
compatiblewithcertainvarietiesofUNIX.
• Namespace. Each process is associated with a specific view of the file-
system hierarchy, called its namespace. Most processes share a com-
mon namespace and thus operate on a shared file-system hierarchy. Pro-
cesses and their children can, however, have different namespaces, each
with a unique file-system hierarchy—their own root directory and set of
mountedfilesystems.
Mostoftheseidentifiersareunderthelimitedcontroloftheprocessitself.The
process group and session identifiers can be changed if the process wants to
startanewgrouporsession.Itscredentialscanbechanged,subjecttoappro-
priatesecuritychecks.However,theprimaryPIDofaprocessisunchangeable
anduniquelyidentifiesthatprocessuntiltermination.
20.4.1.2 ProcessEnvironment
Aprocess’s environment is inherited from its parent and is composed of two
null-terminatedvectors:theargumentvectorandtheenvironmentvector.The
argumentvectorsimplyliststhecommand-lineargumentsusedtoinvokethe
runningprogram;itconventionallystartswiththenameoftheprogramitself.
Theenvironmentvectorisalistof“ NAME=VALUE”pairsthatassociatesnamed
environment variables with arbitrary textual values. The environment is not
held in kernel memory but is stored in the process’s own user-mode address
spaceasthefirstdatumatthetopoftheprocess’sstack.
The argument and environment vectors are not altered when a new pro-
cess is created.The new child process will inherit the environment of its par-
ent. However,a completelynew environment is set up when a new program
is invoked. On calling exec(), a process must supply the environment for
the new program. The kernel passes these environment variables to the next788 Chapter20 TheLinuxSystem
program, replacing the process’s current environment. The kernel otherwise
leavestheenvironmentandcommand-linevectorsalone—theirinterpretation
isleftentirelytotheuser-modelibrariesandapplications.
Thepassingofenvironmentvariablesfromoneprocesstothenextandthe
inheritingofthesevariablesbythechildrenofaprocessprovideflexibleways
topassinformationtocomponentsoftheuser-modesystemsoftware.Various
importantenvironmentvariableshaveconventionalmeaningstorelatedparts
of the system software. For example, the TERM variable is set up to name the
type ofterminal connected toa user’s login session. Many programs use this
variabletodeterminehowtoperformoperationsontheuser’sdisplay,suchas
moving the cursor and scrolling a region of text. Programs with multilingual
support use the LANG variable to determine the language in which to display
systemmessagesforprogramsthatincludemultilingualsupport.
Theenvironment-variablemechanismcustom-tailorstheoperatingsystem
on a per-process basis. Users can choose their own languages or select their
owneditorsindependentlyofoneanother.
20.4.1.3 ProcessContext
The process identity and environment properties are usually set up when a
process is created and not changed until that process exits. A process may
choose to change some aspects of its identity if it needs to do so, or it may
alter its environment. In contrast, process context is the state of the running
program at any one time; it changes constantly. Process context includes the
followingparts:
• Schedulingcontext.Themostimportantpartoftheprocesscontextisits
schedulingcontext—theinformationthattheschedulerneedstosuspend
and restart the process. This information includes saved copies of all the
process’s registers. Floating-point registers are stored separately and are
restoredonlywhenneeded.Thus,processesthatdonotusefloating-point
arithmeticdonotincur theoverheadofsavingthatstate.Thescheduling
contextalsoincludesinformationaboutschedulingpriorityandaboutany
outstanding signals waiting to be delivered to the process. A key part
of the scheduling context is the process’s kernel stack, a separate area of
kernel memory reserved for use by kernel-mode code. Both system calls
andinterruptsthatoccurwhiletheprocessisexecutingwillusethisstack.
• Accounting. The kernel maintains accounting information about the
resources currently being consumed by each process and the total
resourcesconsumedbytheprocessinitsentirelifetimesofar.
• File table. The file table is an array of pointers to kernel file structures
representingopenfiles.Whenmakingfile-I/Osystemcalls,processesrefer
to files by an integer,known as a fil descriptor (fd), that the kernel uses
toindexintothistable.
• File-systemcontext.Whereasthefiletableliststheexistingopenfiles,the
file-system context applies to requests to open new files. The file-system
context includes the process’s root directory, current working directory,
andnamespace.20.4 ProcessManagement 789
• Signal-handlertable.UNIXsystemscandeliverasynchronoussignalstoa
process in response to various external events. The signal-handler table
defines the action to take in response to a specific signal. Valid actions
include ignoring the signal, terminatingthe process,and invoking arou-
tineintheprocess’saddressspace.
• Virtual memory context. The virtual memory context describes the full
contentsofaprocess’sprivateaddressspace;wediscussitinSection20.6.
20.4.2 Processes and Threads
Linux provides the fork() system call, which duplicates a process without
loading a new executable image. Linux also provides the ability to create
threadsviatheclone()systemcall.Linuxdoesnotdistinguishbetweenpro-
cesses and threads, however. In fact, Linux generally uses the term task—
rather than process or thread—when referring to a flow of control within a
program.Theclone()systemcallbehavesidenticallytofork(),exceptthat
it accepts as arguments a set of flags that dictate what resources are shared
between the parent and child (whereas a process created with fork() shares
noresourceswithitsparent).Theflagsinclude:
flag meaning
CLONE_FS File-system information is shared.
CLONE_VM The same memory space is shared.
CLONE_SIGHAND Signal handlers are shared.
CLONE_FILES The set of open files is shared.
Thus,ifclone()ispassedtheflagsCLONE FS,CLONE VM,CLONE SIGHAND,
and CLONE FILES, the parent and child tasks will share the same file-system
information(suchasthecurrentworkingdirectory),thesamememoryspace,
thesamesignalhandlers,andthesamesetofopenfiles.Usingclone()inthis
fashionisequivalenttocreatingathreadinothersystems,sincetheparenttask
sharesmostofitsresourceswithitschildtask.Ifnoneoftheseflagsissetwhen
clone()isinvoked,however,theassociatedresourcesarenotshared,resulting
infunctionalitysimilartothatofthefork()systemcall.
Thelackofdistinctionbetweenprocessesandthreadsispossiblebecause
Linux does not hold a process’s entire context within the main process data
structure. Rather, it holds the context within independent subcontexts. Thus,
a process’s file-system context, file-descriptor table, signal-handler table, and
virtualmemorycontextareheldinseparatedatastructures.Theprocessdata
structuresimplycontainspointerstotheseotherstructures,soanynumberof
processescaneasilyshareasubcontextbypointingtothesamesubcontextand
incrementingareferencecount.
Theargumentstotheclone()systemcalltellitwhichsubcontextstocopy
andwhichtoshare.Thenewprocessisalwaysgivenanewidentityandanew
schedulingcontext—thesearetheessentialsofaLinuxprocess.Accordingto
thearguments passed,however,the kernelmay eithercreatenewsubcontext
data structures initialized so as to be copies of the parent’s or set up the new
process to use the same subcontext data structures being used by the parent.790 Chapter20 TheLinuxSystem
The fork() system call is nothing more than a special case of clone() that
copiesallsubcontexts,sharingnone.
20.5Scheduling
SchedulingisthejobofallocatingCPUtimetodifferenttaskswithinanoperat-
ing system. Linux, like all UNIX systems, supports preemptive multitasking.
Insuchasystem,theprocessschedulerdecideswhichthreadrunsandwhen.
Makingthesedecisionsinawaythatbalancesfairnessandperformanceacross
manydifferentworkloadsisoneofthemorecomplicatedchallengesinmodern
operatingsystems.
Normally,wethinkofschedulingastherunningandinterruptingofuser
threads,but anotheraspectofscheduling isalsoimportantinLinux:therun-
ning of the various kernel tasks. Kernel tasks encompass both tasks that are
requested by a running thread and tasks that execute internally on behalf of
thekernelitself,suchastasksspawnedbyLinux’sI/Osubsystem.
20.5.1 Thread Scheduling
Linuxhastwoseparateprocess-schedulingalgorithms.Oneisatime-sharing
algorithm for fair, preemptivescheduling among multiplethreads.The other
is designed for real-time tasks, where absolute priorities are more important
thanfairness.
The scheduling algorithm used for routine time-sharing tasks received a
majoroverhaulwithversion2.6ofthekernel.Earlierversionsranavariation
ofthetraditionalUNIXschedulingalgorithm.Thisalgorithmdoesnotprovide
adequatesupportforSMPsystems,doesnotscalewellasthenumberoftaskson
thesystemgrows,anddoesnotmaintainfairnessamonginteractivetasks,par-
ticularlyonsystemssuchasdesktopsandmobiledevices.Thethreadscheduler
wasfirstoverhauledwithversion2.5ofthekernel.Version2.5implementeda
schedulingalgorithmthatselectswhichtasktoruninconstanttime—known
as O(1)—regardless of the number of tasks or processors in the system. The
new scheduler also provided increased support for SMP, including processor
affinityandloadbalancing.Thesechanges,whileimprovingscalability,didnot
improve interactive performance or fairness—and, in fact, made these prob-
lemsworseundercertainworkloads.Consequently,thethreadschedulerwas
overhauledasecondtime,withLinuxkernelversion2.6.Thisversionushered
intheCompletelyFairScheduler(CFS).
The Linux scheduler is a preemptive, priority-based algorithm with two
separate priority ranges: a real-time range from 0 to 99 and a nice value
ranging from −20 to 19. Smaller nice values indicate higher priorities. Thus,
byincreasingthenicevalue,youaredecreasingyourpriorityandbeing“nice”
totherestofthesystem.
CFSisasignificantdeparturefromthetraditionalUNIXprocessscheduler.
In the latter, the core variables in the scheduling algorithm are priority and
time slice. The time slice is the length of time—the slice of the processor
—that a thread is afforded. Traditional UNIX systems give processes a fixed
timeslice,perhapswithaboostorpenaltyforhigh-orlow-priorityprocesses,20.5 Scheduling 791
respectively. A process may run for the length of its time slice, and higher-
priorityprocessesrunbeforelower-priorityprocesses.Itisasimplealgorithm
that many non-UNIX systems employ. Such simplicity worked well for early
time-sharingsystemsbuthasprovedincapableofdeliveringgoodinteractive
performanceandfairnessontoday’smoderndesktopsandmobiledevices.
CFS introduced a new scheduling algorithm called fair scheduling that
eliminatestimeslicesinthetraditionalsense.Insteadoftimeslices,allthreads
are allotted a proportion of the processor’s time. CFS calculates how long a
thread should run as a function of the total number of runnable threads. To
start,CFSsaysthatifthereareNrunnablethreads,theneachshouldbeafforded
1∕Noftheprocessor’stime.CFSthenadjuststhisallotmentbyweightingeach
thread’sallotmentbyitsnicevalue.Threadswiththedefaultnicevaluehave
aweightof1—theirpriorityisunchanged.Threadswithasmallernicevalue
(higher priority) receive a higher weight, while threads with a larger nice
value (lower priority) receive a lower weight. CFS then runs each thread for
a“timeslice”proportionaltotheprocess’sweightdividedbythetotalweight
ofallrunnableprocesses.
Tocalculatetheactuallengthoftimeathreadruns,CFSreliesonaconfig-
urablevariablecalledtargetlatency,whichistheintervaloftimeduringwhich
every runnable task should run at least once. For example, assume that the
target latency is 10 milliseconds. Further assume that we have two runnable
threads of the same priority. Each of these threads has the same weight and
therefore receives the same proportion of the processor’s time. In this case,
withatargetlatencyof10milliseconds,thefirstprocessrunsfor5milliseconds,
thentheotherprocessrunsfor5milliseconds,thenthefirstprocessrunsfor5
millisecondsagain,andsoforth.Ifwehave10runnablethreads,thenCFSwill
runeachforamillisecondbeforerepeating.
But what if we had, say, 1,000 threads? Each thread would run for 1
microsecond if we followed the procedure just described. Due to switching
costs,schedulingthreadsforsuchshortlengthsoftimeisinefficient.CFScon-
sequentlyreliesonasecondconfigurablevariable,theminimumgranularity,
which is a minimum length of time any thread is allotted the processor. All
threads, regardless of the target latency, will run for at least the minimum
granularity.Inthismanner,CFSensuresthatswitchingcostsdonotgrowunac-
ceptablylargewhenthenumberofrunnablethreadsincreasessignificantly.In
doingso,itviolatesitsattemptsatfairness.Intheusualcase,however,thenum-
ber of runnable threads remains reasonable, and both fairness and switching
costsaremaximized.
Withtheswitchtofairscheduling,CFSbehavesdifferentlyfromtraditional
UNIX process schedulers in several ways. Most notably, as we have seen, CFS
eliminates the concept of a static time slice. Instead, each thread receives a
proportion of the processor’s time. How long that allotment is depends on
howmanyotherthreadsarerunnable.Thisapproachsolvesseveralproblems
in mapping priorities to time slices inherent in preemptive, priority-based
schedulingalgorithms.Itispossible,ofcourse,tosolvetheseproblemsinother
wayswithoutabandoningtheclassicUNIXscheduler.CFS,however,solvesthe
problemswithasimplealgorithmthatperformswelloninteractiveworkloads
suchasmobiledeviceswithoutcompromisingthroughputperformanceonthe
largestofservers.792 Chapter20 TheLinuxSystem
20.5.2 Real-Time Scheduling
Linux’s real-time scheduling algorithm is significantly simpler than the fair
scheduling employed for standard time-sharing threads. Linux implements
the two real-time scheduling classes required by POSIX.1b: first-come, first-
served (FCFS) and round-robin (Section 5.3.1 and Section 5.3.3, respectively).
Inbothcases,eachthreadhasapriorityinadditiontoitsschedulingclass.The
scheduleralwaysrunsthethreadwiththehighestpriority.Amongthreadsof
equalpriority,itrunsthethreadthathasbeenwaitinglongest.Theonlydiffer-
ence between FCFS and round-robin scheduling is that FCFS threads continue
to run until they either exit or block, whereas a round-robin thread will be
preemptedafterawhileandwillbemovedtotheendoftheschedulingqueue,
soround-robinthreadsofequalprioritywillautomaticallytime-shareamong
themselves.
Linux’s real-time scheduling is soft—rather than hard—real time. The
scheduler offers strict guarantees about the relative priorities of real-time
threads,butthekerneldoesnotofferanyguaranteesabouthowquicklyareal-
timethreadwillbescheduledoncethatthreadbecomesrunnable.Incontrast,
a hard real-time system can guarantee a minimum latency between when a
threadbecomesrunnableandwhenitactuallyruns.
20.5.3 Kernel Synchronization
The way the kernel schedules its own operations is fundamentally different
from the way it schedules threads. Arequest for kernel-mode execution can
occur in two ways. A running program may request an operating-system
service, either explicitly via a system call or implicitly—for example, when
apagefaultoccurs.Alternatively,adevicecontrollermaydeliverahardware
interrupt that causes the CPU to start executing a kernel-defined handler for
thatinterrupt.
Theproblemforthekernelisthatallthesetasksmaytrytoaccessthesame
internal data structures. If one kernel task is in the middle of accessing some
data structure when an interrupt service routine executes, then that service
routinecannotaccessormodifythesamedatawithoutriskingdatacorruption.
This fact relates to the idea of critical sections—portions of code that access
shareddataandthusmustnotbeallowedtoexecuteconcurrently.Asaresult,
kernel synchronization involves much more than just thread scheduling. A
framework is required that allows kernel tasks to run without violating the
integrityofshareddata.
Prior to version 2.6, Linux was a nonpreemptive kernel, meaning that a
thread running in kernel mode could not be preempted—even if a higher-
priority thread became available to run. With version 2.6, the Linux kernel
became fully preemptive. Now, a task can be preempted when it is running
inthekernel.
The Linux kernel provides spinlocks and semaphores (as well as reader–
writerversionsofthesetwolocks)forlockinginthekernel.OnSMPmachines,
thefundamentallockingmechanismisaspinlock,andthekernelisdesignedso
thatspinlocksareheldforonlyshortdurations.Onsingle-processormachines,
spinlocks are not appropriate for use and are replaced by enabling and dis-
ablingkernelpreemption.Thatis,ratherthanholdingaspinlock,thetaskdis-20.5 Scheduling 793
ableskernelpreemption.Whenthetaskwouldotherwisereleasethespinlock,
itenableskernelpreemption.Thispatternissummarizedbelow:
single processor multiple processors
Disable kernel preemption. Acquire spin lock.
Enable kernel preemption. Release spin lock.
Linux uses an interesting approach to disable and enable kernel preemp-
tion.Itprovidestwosimplekernelinterfaces—preempt disable()andpre-
empt enable(). In addition, the kernel is not preemptible if a kernel-mode
task is holding a spinlock. To enforce this rule, each task in the system has
a thread-info structure that includes the field preempt count, which is a
counterindicating thenumberoflocksbeing heldby thetask.Thecounter is
incrementedwhenalockisacquiredanddecrementedwhenalockisreleased.
If the value of preempt count for the task currently running is greater than
zero,itisnotsafetopreemptthekernel,asthistaskcurrentlyholdsalock.If
the count is zero, the kernel can safely be interrupted, assuming there are no
outstandingcallstopreempt disable().
Spinlocks—alongwiththeenablinganddisablingofkernelpreemption—
areusedinthekernelonlywhenthelockisheldforshortdurations.Whena
lockmustbeheldforlongerperiods,semaphoresareused.
The second protection technique used by Linux applies to critical sec-
tionsthat occur ininterruptserviceroutines.Thebasic toolistheprocessor’s
interrupt-controlhardware.Bydisablinginterrupts(orusingspinlocks)during
acriticalsection,thekernelguaranteesthatitcanproceedwithouttheriskof
concurrentaccesstoshareddatastructures.
However, there is a penalty for disabling interrupts. On most hardware
architectures, interrupt enable and disable instructions are not cheap. More
importantly, as long as interrupts remain disabled, all I/O is suspended, and
any device waiting for servicing will have to wait until interrupts are reen-
abled;thus,performancedegrades.Toaddressthisproblem,theLinuxkernel
usesasynchronizationarchitecturethatallowslongcriticalsectionstorunfor
their entire duration without having interrupts disabled. This ability is espe-
ciallyusefulinthenetworking code.Aninterruptinanetwork devicedriver
cansignalthearrivalofanentirenetworkpacket,whichmayresultinagreat
deal of code being executed to disassemble, route, and forward that packet
withintheinterruptserviceroutine.
Linuximplementsthisarchitecturebyseparatinginterruptserviceroutines
intotwosections:thetophalfandthebottomhalf.Thetophalf isthestandard
interrupt service routine that runs with recursive interrupts disabled. Inter-
ruptsofthesamenumber(orline)aredisabled,butotherinterruptsmayrun.
The bottom half of a service routine is run, with all interrupts enabled, by
a miniature scheduler that ensures that bottom halves never interrupt them-
selves.Thebottom-halfschedulerisinvokedautomaticallywheneveraninter-
ruptserviceroutineexits.
Thisseparationmeansthatthekernelcancompleteanycomplexprocess-
ing that has to be done in response to an interrupt without worrying about
beinginterrupteditself.Ifanotherinterruptoccurswhileabottomhalfisexe-794 Chapter20 TheLinuxSystem
cuting, thenthat interruptcan requestthatthe samebottom halfexecute,but
theexecutionwillbedeferreduntiltheonecurrentlyrunningcompletes.Each
executionofthebottomhalfcanbeinterruptedbyatophalfbutcanneverbe
interruptedbyasimilarbottomhalf.
The top-half/bottom-half architecture is completed by a mechanism for
disabling selected bottom halves while executing normal, foreground kernel
code. The kernel can code critical sections easily using this system. Interrupt
handlerscan code theircritical sectionsas bottom halves;and when thefore-
ground kernel wants to enter a critical section, it can disable any relevant
bottom halves to prevent any other critical sections from interrupting it. At
the end of the critical section, the kernel can reenable the bottom halves and
runanybottom-halftasksthathavebeenqueuedbytop-halfinterruptservice
routinesduringthecriticalsection.
Figure 20.2 summarizes the various levels of interrupt protection within
thekernel.Eachlevelmaybeinterruptedbycoderunningatahigherlevelbut
willneverbeinterruptedbycoderunningatthesameoralowerlevel.Except
foruser-modecode,userthreadscanalwaysbepreemptedbyanotherthread
whenatime-sharingschedulinginterruptoccurs.
20.5.4 Symmetric Multiprocessing
The Linux 2.0 kernel was the first stable Linux kernel to support symmetric
multiprocessor (SMP) hardware, allowing separatethreads toexecutein par-
allelonseparateprocessors.TheoriginalimplementationofSMPimposedthe
restrictionthatonlyoneprocessoratatimecouldbeexecutingkernelcode.
In version 2.2 of the kernel, a single kernel spinlock (sometimes termed
BKLfor “big kernel lock”) was created to allow multiple threads (running on
differentprocessors)tobeactiveinthekernelconcurrently.However,theBKL
providedaverycoarseleveloflockinggranularity,resultinginpoorscalability
to machines with many processors and threads. Later releases of the kernel
made the SMP implementation more scalable by splitting this single kernel
spinlockintomultiplelocks,eachofwhichprotectsonlyasmallsubsetofthe
kernel’sdatastructures.SuchspinlocksweredescribedinSection20.5.3.
The3.0and4.0kernelsprovidedadditionalSMPenhancements,including
ever-finer locking, processor affinity, load-balancing algorithms, and support
forhundredsoreventhousandsofphysicalprocessorsinasinglesystem.
top-half interrupt handlers
bottom-half interrupt handlers
kernel-system service routines (preemptible)
user-mode programs (preemptible)
ytiroirp
gnisaercni
Figure20.2 Interruptprotectionlevels.20.6 MemoryManagement 795
20.6Memory Management
MemorymanagementunderLinuxhastwocomponents.Thefirstdealswith
allocating and freeing physical memory—pages, groups of pages, and small
blocksofRAM.Thesecondhandlesvirtualmemory,whichismemory-mapped
intotheaddressspaceofrunningprocesses.Inthissection,wedescribethese
two components and then examine the mechanisms by which the loadable
components of a new program are brought into a process’s virtual memory
inresponsetoanexec()systemcall.
20.6.1 Management of Physical Memory
Due to specific hardware constraints, Linux separates physical memory into
fourdifferentzones,orregions:
• ZONE DMA
• ZONE DMA32
• ZONE NORMAL
• ZONE HIGHMEM
These zones are architecture specific. For example, on the Intel x86-32
architecture, certain ISA (industry standard architecture) devices can only
accessthelower16-MBofphysicalmemoryusingDMA.Onthesesystems,the
first16-MBofphysicalmemorycompriseZONE DMA.Onothersystems,certain
devicescanonlyaccessthefirst4-GBofphysicalmemory,despitesupporting
64-bitaddresses.Onsuchsystems,thefirst4GBofphysicalmemorycomprise
ZONE DMA32. ZONE HIGHMEM (for “high memory”) refers to physical memory
that is not mapped into the kernel address space. For example, on the 32-bit
Intel architecture (where 232 provides a 4-GB address space), the kernel is
mapped into the first 896 MB of the address space; the remaining memory
is referred to as high memory and is allocated from ZONE HIGHMEM. Finally,
ZONE NORMAL comprises everything else—the normal, regularly mapped
pages.Whetheranarchitecturehasagivenzonedependsonitsconstraints.A
modern, 64-bit architecture such as Intel x86-64 has a small 16-MB ZONE DMA
(for legacy devices) and all the rest of its memory in ZONE NORMAL, with no
“highmemory”.
TherelationshipofzonesandphysicaladdressesontheIntelx86-32archi-
tecture is shown in Figure 20.3. The kernel maintains a list of free pages for
zone physical memory
ZONE_DMA < 16 MB
ZONE_NORMAL 16 .. 896 MB
ZONE_HIGHMEM > 896 MB
Figure20.3 RelationshipofzonesandphysicaladdressesinIntelx86-32.796 Chapter20 TheLinuxSystem
eachzone.Whenarequestforphysicalmemoryarrives,thekernelsatisfiesthe
requestusingtheappropriatezone.
The primary physical-memory manager in the Linux kernel is the page
allocator. Each zone has its own allocator, which is responsible for allocating
andfreeingallphysicalpagesforthezoneandiscapableofallocatingranges
ofphysicallycontiguouspagesonrequest.Theallocatorusesabuddysystem
(Section10.8.1)tokeeptrackofavailablephysicalpages.Inthisscheme,adja-
cent units of allocatable memory are paired together (hence its name). Each
allocatable memory region has an adjacent partner or buddy. Whenever two
allocated partner regions are freed up, they are combined to form a larger
region—abuddyheap.Thatlargerregionalsohasapartner,withwhichitcan
combinetoformastilllargerfreeregion.Conversely,ifasmallmemoryrequest
cannotbesatisfiedbyallocationofanexistingsmallfreeregion,thenalarger
freeregionwillbesubdividedintotwopartnerstosatisfytherequest.Separate
linkedlistsareusedtorecordthefreememoryregionsofeachallowablesize.
Under Linux, the smallest size allocatable under this mechanism is a single
physicalpage.Figure20.4showsanexampleofbuddy-heapallocation.A4-KB
regionisbeingallocated,butthesmallestavailableregionis16KB.Theregion
isbrokenuprecursivelyuntilapieceofthedesiredsizeisavailable.
Ultimately,allmemoryallocationsintheLinuxkernelaremadeeitherstat-
ically,bydriversthatreserveacontiguousareaofmemoryduringsystemboot
time,ordynamically,bythepageallocator.However,kernelfunctionsdonot
havetousethebasicallocatortoreservememory.Severalspecializedmemory-
management subsystems use the underlying page allocator to manage their
own pools of memory. The most important are the virtual memory system,
described in Section 20.6.2; the kmalloc() variable-length allocator; the slab
allocator,usedforallocatingmemoryforkerneldatastructures;andthepage
cache,usedforcachingpagesbelongingtofiles.
Many components of the Linux operating system need to allocate entire
pagesonrequest,butoftensmallerblocksofmemoryarerequired.Thekernel
provides an additional allocator for arbitrary-sized requests, where the size
of a request is not known in advance and may be only a few bytes. Analo-
goustotheClanguage’smalloc()function,thiskmalloc()serviceallocates
entirephysicalpagesondemandbutthensplitsthemintosmallerpieces.The
8 KB 8 KB
16 KB
4 KB
8 KB
4 KB
Figure20.4 Splittingofmemoryinthebuddysystem.20.6 MemoryManagement 797
kernel objects caches slabs
3-KB
objects
physically
contiguous
pages
7-KB
objects
Figure20.5 SlaballocatorinLinux.
kernel maintains lists of pages in use by the kmalloc() service. Allocating
memory involves determining the appropriate list and either taking the first
free piece available on the list or allocating a new page and splitting it up.
Memoryregionsclaimedbythekmalloc()systemareallocatedpermanently
untiltheyarefreedexplicitlywithacorrespondingcalltokfree();thekmal-
loc()systemcannotreallocateorreclaimtheseregionsinresponsetomemory
shortages.
AnotherstrategyadoptedbyLinuxforallocatingkernelmemoryisknown
as slaballocation. Aslab isusedfor allocating memoryfor kerneldatastruc-
tures and is made up of one or more physically contiguous pages. A cache
consists of one or more slabs. There is a single cache for each unique kernel
data structure—for example, a cache for the data structure representing pro-
cessdescriptors,acacheforfileobjects,acacheforinodes,andsoforth.Each
cacheispopulatedwithobjectsthatareinstantiationsofthekerneldatastruc-
ture the cache represents. For example, the cache representing inodes stores
instances of inode structures, and the cache representing process descriptors
storesinstancesofprocessdescriptorstructures.Therelationshipamongslabs,
caches,andobjectsisshowninFigure20.5.Thefigureshowstwokernelobjects
3 KB in size and three objects 7 KB in size. These objects are stored in the
respectivecachesfor3-KBand7-KBobjects.
The slab-allocation algorithm uses caches to store kernel objects. When a
cacheiscreated,anumberofobjectsareallocatedtothecache.Thenumberof
objects in the cache depends on the size of the associated slab. For example,
a 12-KB slab (made up of three contiguous 4-KB pages) could store six 2-KB
objects. Initially,all the objects in the cache aremarked asfree. When a new
object for a kernel data structure is needed, the allocator can assign any free
objectfromthecachetosatisfytherequest.Theobjectassignedfromthecache
ismarkedasused.
Let’s consider a scenario in which the kernel requests memory from the
slab allocator for an object representing a process descriptor. In Linux sys-
tems,aprocessdescriptorisofthetypestruct task struct,whichrequires798 Chapter20 TheLinuxSystem
approximately 1.7 KB of memory. When the Linux kernel creates a new task,
itrequeststhenecessarymemoryforthestruct task structobjectfromits
cache. The cache will fulfill the request using a struct task struct object
thathasalreadybeenallocatedinaslabandismarkedasfree.
InLinux,aslabmaybeinoneofthreepossiblestates:
1. Full.Allobjectsintheslabaremarkedasused.
2. Empty.Allobjectsintheslabaremarkedasfree.
3. Partial.Theslabconsistsofbothusedandfreeobjects.
The slab allocator first attempts to satisfy the request with a free object in a
partial slab. If none exists, a free object is assigned from an empty slab. If no
empty slabs are available, a new slab is allocated from contiguous physical
pages and assigned to a cache; memory for the object is allocated from this
slab.
TwoothermainsubsystemsinLinuxdotheirownmanagementofphysical
pages: the page cache and the virtual memory system. These systems are
closelyrelatedtoeachother.Thepagecacheisthekernel’smaincacheforfiles
andisthemainmechanismthroughwhichI/Otoblockdevices(Section20.8.1)
isperformed.Filesystemsofalltypes,including thenativeLinuxdisk-based
file systems and the NFS networked file system, perform their I/O through
the page cache. The page cache stores entire pages of file contents and is not
limitedtoblockdevices.Itcanalsocachenetworkeddata.Thevirtualmemory
system manages the contents of each process’s virtual address space. These
two systems interact closely with each other because reading a page of data
intothepagecacherequiresmappingpagesinthepagecacheusingthevirtual
memorysystem.Inthefollowingsection,welookatthevirtualmemorysystem
ingreaterdetail.
20.6.2 Virtual Memory
The Linux virtual memory system is responsible for maintaining the address
spaceaccessibletoeachprocess.Itcreatespagesofvirtualmemoryondemand
and manages loading those pages from disk and swapping them back out to
disk as required. Under Linux, the virtual memory manager maintains two
separateviewsofaprocess’saddressspace:asasetofseparateregionsandas
asetofpages.
The first view of an address space is the logical view, describing instruc-
tionsthatthevirtualmemorysystemhasreceivedconcerningthelayoutofthe
addressspace.Inthisview,theaddressspaceconsistsofasetofnonoverlap-
pingregions,eachregionrepresentingacontinuous,page-alignedsubsetofthe
addressspace.Eachregionisdescribedinternallybyasinglevm area struct
structurethatdefinesthepropertiesoftheregion,includingtheprocess’sread,
write,andexecutepermissionsintheregionaswellasinformationaboutany
filesassociatedwiththeregion.Theregionsforeachaddressspacearelinked
intoabalancedbinarytreetoallowfastlookupoftheregioncorrespondingto
anyvirtualaddress.
The kernel also maintains a second, physical view of each address space.
This view is stored in the hardware page tables for the process. The page-
tableentriesidentifytheexactcurrentlocationofeachpageofvirtualmemory,20.6 MemoryManagement 799
whether it is on disk or in physical memory. The physical view is managed
by a set of routines, which are invoked from the kernel’s software-interrupt
handlerswheneveraprocesstriestoaccessapagethatisnotcurrentlypresent
in the page tables. Each vm area struct in the address-space description
contains a field pointing to a table of functions that implement the key page-
management functionality for any givenvirtual memory region. All requests
to read or write an unavailable page are eventually dispatched to the appro-
priatehandlerinthefunctiontableforthevm area struct,sothatthecentral
memory-management routines do not have to know the details of managing
eachpossibletypeofmemoryregion.
20.6.2.1 VirtualMemoryRegions
Linux implements several types of virtual memory regions. One property
that characterizes virtual memory is the backing store for the region, which
describes where the pages for the region come from. Most memory regions
are backed either by a file or by nothing. A region backed by nothing is the
simplesttypeofvirtualmemoryregion.Sucharegionrepresentsdemand-zero
memory:whenaprocesstriestoreadapageinsucharegion,itissimplygiven
backapageofmemoryfilledwithzeros.
A region backed by a file acts as a viewport onto a section of that file.
Whenevertheprocesstriestoaccessapagewithinthatregion,thepagetableis
filledwiththeaddressofapagewithinthekernel’spagecachecorresponding
totheappropriateoffsetinthefile.Thesamepageofphysicalmemoryisused
byboththepagecacheandtheprocess’spagetables,soanychangesmadeto
the file by the file system are immediately visible to any processes that have
mapped that file into their address space. Any number of processes can map
thesameregionofthesamefile,andtheywillallendupusingthesamepage
ofphysicalmemoryforthepurpose.
A virtual memory region is also defined by its reaction to writes. The
mapping of a regioninto the process’s addressspace can be either private or
shared.Ifaprocesswritestoaprivatelymappedregion,thenthepagerdetects
that a copy-on-write is necessary to keep the changes local to the process. In
contrast,writestoasharedregionresultinupdatingoftheobjectmappedinto
thatregion,sothatthechangewillbevisibleimmediatelytoanyotherprocess
thatismappingthatobject.
20.6.2.2 LifetimeofaVirtualAddressSpace
The kernel creates a new virtual address space in two situations: when a
process runs a new program with the exec() system call and when a new
process is created by the fork() system call. The first case is easy. When a
newprogramisexecuted,theprocessisgivenanew,completelyemptyvirtual
addressspace.Itisuptotheroutinesforloadingtheprogramtopopulatethe
addressspacewithvirtualmemoryregions.
The second case, creating a new process with fork(), involves creating
a complete copy of the existing process’s virtual address space. The kernel
copies the parent process’s vm area struct descriptors, then creates a new
setofpagetablesforthechild.Theparent’spagetablesarecopieddirectlyinto
thechild’s,andthereferencecountofeachpagecoveredisincremented.Thus,800 Chapter20 TheLinuxSystem
afterthe fork, theparent and childshare the samephysical pagesofmemory
intheiraddressspaces.
Aspecialcaseoccurswhenthecopyingoperationreachesavirtualmemory
region that is mapped privately. Any pages to which the parent process has
written within such a region are private, and subsequent changes to these
pages by eitherthe parent or the child must not update the page inthe other
process’s address space. When the page-table entries for such regions are
copied,theyaresettobereadonlyandaremarkedforcopy-on-write.Aslong
asneitherprocessmodifiesthesepages,thetwoprocessessharethesamepage
ofphysicalmemory.However,ifeitherprocesstriestomodifyacopy-on-write
page,thereferencecountonthepageischecked.Ifthepageisstillshared,then
theprocesscopiesthepage’scontentstoabrand-newpageofphysicalmemory
andusesitscopyinstead.Thismechanismensuresthatprivatedatapagesare
sharedbetweenprocesseswheneverpossibleandcopiesaremadeonlywhen
absolutelynecessary.
20.6.2.3 SwappingandPaging
Animportanttaskforavirtualmemorysystemistorelocatepagesofmemory
from physical memory out to disk when that memory is needed. Early UNIX
systems performed this relocation by swapping out the contents of entire
processes at once, but modern versions of UNIX rely more on paging—the
movement of individual pages of virtual memory between physical memory
and disk. Linux does not implement whole-process swapping; it uses the
newerpagingmechanismexclusively.
The paging system can be divided into two sections. First, the policy
algorithmdecideswhichpagestowriteouttobackingstoreandwhentowrite
them.Second,the pagingmechanismcarriesout thetransfer and pagesdata
backintophysicalmemorywhentheyareneededagain.
Linux’s pageout policy uses a modified version of the standard clock
(or second-chance) algorithm described in Section 10.4.5.2. Under Linux, a
multiple-pass clock is used, and every page has an age that is adjusted on
each pass of the clock. The age is more precisely a measure of the page’s
youthfulness, or how much activity the page has seen recently. Frequently
accessed pages will attain a higher age value, but the age of infrequently
accessedpageswilldroptowardzerowitheachpass.Thisagevaluingallows
the pager to select pages to page out based on a least frequently used (LFU)
policy.
The paging mechanism supports paging both to dedicated swap devices
andpartitionsandtonormalfiles,althoughswappingtoafileissignificantly
slower due to the extra overhead incurred by the file system. Blocks are allo-
cated from the swap devices according to a bitmap of used blocks, which is
maintainedinphysicalmemoryatalltimes.Theallocatorusesanext-fitalgo-
rithmtotrytowriteoutpagestocontinuousrunsofsecondarystorageblocks
forimprovedperformance.Theallocatorrecordsthefactthatapagehasbeen
pagedout tostorageby using afeatureofthe pagetableson modernproces-
sors:thepage-tableentry’spage-not-presentbitisset,allowingtherestofthe
page-tableentrytobefilledwithanindexidentifyingwherethepagehasbeen
written.20.6 MemoryManagement 801
20.6.2.4 KernelVirtualMemory
Linux reserves for its own internal use a constant, architecture-dependent
regionofthevirtualaddressspaceofeveryprocess.Thepage-tableentriesthat
map to these kernel pages are marked as protected, so that the pages are not
visibleormodifiablewhentheprocessorisrunninginusermode.Thiskernel
virtualmemoryareacontainstworegions.Thefirstisastaticareathatcontains
page-tablereferencestoeveryavailablephysicalpageofmemoryinthesystem,
so that a simple translation from physical to virtual addresses occurs when
kernelcodeisrun.Thecoreofthekernel,alongwithallpagesallocatedbythe
normalpageallocator,residesinthisregion.
The remainder of the kernel’s reserved section of address space is not
reservedforanyspecificpurpose.Page-tableentriesinthisaddressrangecan
be modified by the kernel to point to any other areas of memory. The kernel
providesapairoffacilitiesthatallowkernelcodetousethisvirtualmemory.
The vmalloc() function allocates an arbitrary number of physical pages of
memorythatmaynotbephysicallycontiguousintoasingleregionofvirtually
contiguouskernelmemory.Thevremap()functionmapsasequenceofvirtual
addressestopointtoanareaofmemoryusedbyadevicedriverformemory-
mappedI/O.
20.6.3 Execution and Loading of User Programs
The Linux kernel’s execution of user programs is triggered by a call to the
exec()systemcall.Thisexec()callcommands thekerneltorunanewpro-
gramwithinthecurrentprocess,completelyoverwritingthecurrentexecution
contextwiththeinitialcontextofthenewprogram.Thefirstjobofthissystem
service is to verify that the calling process has permission rights to the file
beingexecuted.Oncethatmatterhasbeenchecked,thekernelinvokesaloader
routinetostartrunningtheprogram.Theloaderdoesnotnecessarilyloadthe
contents of the program file into physical memory, but it does at least set up
themappingoftheprogramintovirtualmemory.
There is no single routine in Linux for loading a new program. Instead,
Linux maintains a table of possible loader functions, and it gives each such
function the opportunity to try loading the given file when an exec() sys-
temcallismade.Theinitialreasonforthisloadertablewasthat,betweenthe
releasesofthe1.0and1.2kernels,thestandardformatforLinux’sbinaryfiles
waschanged.OlderLinuxkernelsunderstoodthea.outformatforbinaryfiles
—a relatively simple format common on older UNIX systems. Newer Linux
systems use the more modern ELF format, now supported by most current
UNIXimplementations.ELFhasanumberofadvantagesovera.out,including
flexibilityand extendability.Newsections can be addedtoan ELF binary (for
example,toaddextradebugginginformation)withoutcausingtheloaderrou-
tinestobecomeconfused.Byallowingregistrationofmultipleloaderroutines,
LinuxcaneasilysupporttheELFanda.outbinaryformatsinasinglerunning
system.
In Section 20.6.3.1 and Section 20.6.3.2, we concentrate exclusivelyon the
loadingandrunningofELF-formatbinaries.Theprocedureforloadinga.out
binariesissimplerbutsimilarinoperation.802 Chapter20 TheLinuxSystem
20.6.3.1 MappingofProgramsintoMemory
UnderLinux,thebinaryloaderdoesnotloadabinaryfileintophysicalmem-
ory. Rather, the pages of the binary file are mapped into regions of virtual
memory.Onlywhentheprogramtriestoaccessagivenpagewillapagefault
resultintheloadingofthatpageintophysicalmemoryusingdemandpaging.
It is the responsibility of the kernel’s binary loader to set up the initial
memorymapping.AnELF-formatbinaryfileconsistsofaheaderfollowedby
severalpage-alignedsections.TheELFloaderworksbyreadingtheheaderand
mappingthesectionsofthefileintoseparateregionsofvirtualmemory.
Figure20.6showsthetypicallayoutofmemoryregionssetupbytheELF
loader. In a reserved region at one end of the address space sits the kernel,
in its own privileged region of virtual memory inaccessible to normal user-
modeprograms.Therestofvirtualmemoryisavailabletoapplications,which
can use the kernel’s memory-mapping functions to create regions that map a
portionofafileorthatareavailableforapplicationdata.
The loader’s job is to set up the initial memory mapping to allow the
executionoftheprogramtostart.Theregionsthatneedtobeinitializedinclude
thestackandtheprogram’stextanddataregions.
The stack iscreatedatthe top of theuser-modevirtualmemory;itgrows
downwardtowardlower-numberedaddresses.Itincludescopiesoftheargu-
mentsandenvironmentvariablesgiventotheprogramintheexec()system
call. The other regions are created near the bottom end of virtual memory.
Thesectionsofthebinaryfilethatcontainprogramtextorread-onlydataare
mappedintomemoryasawrite-protectedregion.Writableinitializeddataare
mappednext;thenanyuninitializeddataaremappedinasaprivatedemand-
zeroregion.
kernel virtual memory memory invisible to user-mode code
stack
memory-mapped region
memory-mapped region
memory-mapped region
the ‘brk’ pointer
run-time data
uninitialized data
initialized data
program text
forbidden region
Figure20.6 MemorylayoutforELFprograms.20.7 FileSystems 803
Directly beyond these fixed-sized regions is a variable-sized region that
programs can expand as needed to hold data allocated at run time. Each
processhasapointer,brk,thatpointstothecurrentextentofthisdataregion,
andprocessescanextendorcontracttheirbrkregionwithasinglesystemcall
—sbrk().
Oncethesemappingshavebeensetup,theloaderinitializestheprocess’s
program-counter register with the starting point recorded in the ELF header,
andtheprocesscanbescheduled.
20.6.3.2 StaticandDynamicLinking
Oncetheprogramhasbeenloadedandhasstartedrunning,allthenecessary
contentsofthebinaryfilehavebeenloadedintotheprocess’svirtualaddress
space. However, most programs also need to run functions from the system
libraries, and these library functions must also be loaded. In the simplest
case, the necessary library functions are embedded directly in the program’s
executable binary file. Such a program is statically linked to its libraries, and
staticallylinkedexecutablescancommencerunningassoonastheyareloaded.
The main disadvantage of static linking is that every program generated
mustcontaincopiesofexactlythesamecommonsystemlibraryfunctions.Itis
muchmoreefficient,intermsofbothphysicalmemoryanddisk-spaceusage,
to load the system libraries into memory only once. Dynamic linking allows
thattohappen.
Linuximplementsdynamiclinkinginusermodethroughaspeciallinker
library. Every dynamically linked program contains a small, statically linked
functionthatiscalledwhentheprogramstarts.Thisstaticfunctionjustmaps
thelinklibraryintomemoryandrunsthecodethatthefunctioncontains.The
linklibrarydeterminesthedynamiclibrariesrequiredbytheprogramandthe
namesofthevariablesandfunctionsneededfromthoselibrariesbyreadingthe
informationcontained insections of theELFbinary. Itthenmapsthelibraries
intothemiddleofvirtualmemoryandresolvesthereferencestothesymbols
containedinthoselibraries.Itdoesnotmatterexactlywhereinmemorythese
shared libraries are mapped: they are compiled into position-independent
code(PIC),whichcanrunatanyaddressinmemory.
20.7File Systems
LinuxretainsUNIX’sstandardfile-systemmodel.InUNIX,afiledoesnothave
to be an object stored on disk or fetched over a network from a remote file
server. Rather, UNIX files can be anything capable of handling the input or
outputofastreamofdata.Devicedriverscanappearasfiles,andinterprocess-
communication channels or network connections also look like files to the
user.
TheLinuxkernelhandlesallthesetypesoffilesby hidingtheimplemen-
tationdetailsofanysinglefiletypebehindalayerofsoftware,thevirtualfile
system(VFS). Here,we first cover the virtualfilesystemand then discussthe
standardLinuxfilesystem—ext3.804 Chapter20 TheLinuxSystem
20.7.1 The Virtual File System
The LinuxVFS isdesignedaround object-orientedprinciples.Ithas twocom-
ponents: a set of definitions that specify what file-system objects are allowed
tolooklikeandalayerofsoftwaretomanipulatetheobjects.TheVFSdefines
fourmainobjecttypes:
• Aninodeobjectrepresentsanindividualfile.
• Afil objectrepresentsanopenfile.
• Asuperblockobjectrepresentsanentirefilesystem.
• Adentryobjectrepresentsanindividualdirectoryentry.
For each of these four object types, the VFS defines a set of operations.
Every object of one of these types contains a pointer to a function table. The
function table lists the addresses of the actual functions that implement the
definedoperationsforthatobject.Forexample,anabbreviatedAPIforsomeof
thefileobject’soperationsincludes:
• int open(. . .) — Openafile.
• ssize t read(. . .) — Readfromafile.
• ssize t write(. . .) — Writetoafile.
• int mmap(. . .) — Memory-mapafile.
The complete definition of the file object is specified in the struct
file operations, which is located in the file /usr/include/linux/fs.h.
An implementation of the file object (for a specific file type) is required to
implementeachfunctionspecifiedinthedefinitionofthefileobject.
TheVFSsoftwarelayercanperformanoperationononeofthefile-system
objects by calling the appropriate function from the object’s function table,
without having to know in advance exactly what kind of object it is dealing
with.TheVFSdoesnotknow,orcare,whetheraninoderepresentsanetworked
file,adiskfile, anetwork socket,or adirectoryfile.The appropriatefunction
forthatfile’sread()operationwillalwaysbeatthesameplaceinitsfunction
table,andtheVFSsoftwarelayerwillcallthatfunctionwithoutcaringhowthe
dataareactuallyread.
Theinodeandfileobjectsarethemechanismsusedtoaccessfiles.Aninode
objectisadatastructurecontainingpointerstothediskblocksthatcontainthe
actualfilecontents,andafileobjectrepresentsapointofaccesstothedatain
anopenfile.Athreadcannotaccessaninode’scontentswithoutfirstobtaining
afileobjectpointingtotheinode.Thefileobjectkeepstrackofwhereinthefile
theprocessiscurrentlyreadingorwriting,tokeeptrackofsequentialfileI/O.It
alsoremembersthe permissions(for example,reador write)requestedwhen
the file was opened and tracks the thread’s activity if necessary to perform
adaptiveread-ahead,fetchingfiledataintomemorybeforethethreadrequests
thedata,toimproveperformance.
File objects typically belong to a single process, but inode objects do not.
There is one file object for every instance of an open file, but always only a20.7 FileSystems 805
single inode object. Even when a file is no longer in use by any process, its
inodeobjectmaystillbecachedbytheVFStoimproveperformanceifthefile
isusedagaininthenearfuture.Allcachedfiledataarelinkedontoalistinthe
file’sinodeobject.Theinodealsomaintainsstandardinformationabout each
file,suchastheowner,size,andtimemostrecentlymodified.
Directoryfilesaredealtwithslightlydifferentlyfromotherfiles.TheUNIX
programming interface defines a number of operations on directories, such
as creating, deleting, and renaming a file in a directory. The system calls for
thesedirectoryoperationsdonotrequirethattheuseropenthefilesconcerned,
unlike the case for reading or writing data. The VFS therefore defines these
directoryoperationsintheinodeobject,ratherthaninthefileobject.
The superblock object represents a connected set of files that form a
self-contained file system. The operating-system kernel maintains a single
superblock object for each disk device mounted as a file system and for each
networked file system currently connected. The main responsibility of the
superblockobjectistoprovideaccesstoinodes.TheVFSidentifieseveryinode
byauniquefile-system/inodenumberpair,anditfindstheinodecorrespond-
ingtoaparticularinodenumberbyaskingthesuperblockobjecttoreturnthe
inodewiththatnumber.
Finally,adentryobjectrepresentsadirectoryentry,whichmayincludethe
nameofadirectoryinthepathnameofafile(suchas/usr)ortheactualfile
(suchasstdio.h).Forexample,thefile/usr/include/stdio.hcontainsthe
directory entries (1) /, (2) usr, (3) include, and (4) stdio.h. Each of these
valuesisrepresentedbyaseparatedentryobject.
As an example of how dentry objects are used, consider the situ-
ation in which a thread wishes to open the file with the pathname
/usr/include/stdio.h using an editor. Because Linux treats directory
names as files, translating this path requires first obtaining the inode for the
root—/. The operating system must then read through this file to obtain
the inode for the file include. It must continue this thread until it obtains
the inode for the file stdio.h. Because path-name translation can be a
time-consuming task, Linux maintains a cache of dentry objects, which is
consultedduringpath-nametranslation.Obtainingtheinodefromthedentry
cacheisconsiderablyfasterthanhavingtoreadtheon-diskfile.
20.7.2 The Linux ext3 File System
The standard on-disk file system used by Linux is called ext3, for historical
reasons. Linux was originally programmed with a Minix-compatible file sys-
tem,toeaseexchangingdatawiththeMinixdevelopmentsystem,butthatfile
systemwasseverelyrestrictedby14-characterfile-namelimitsandamaximum
file-systemsizeof64-MB.TheMinixfilesystemwassupersededbyanewfile
system,whichwaschristenedtheextendedfilesystem(extfs).Alaterredesign
toimproveperformanceandscalabilityandtoaddafewmissingfeaturesled
tothesecondextendedfilesystem(ext2).Furtherdevelopmentaddedjournal-
ing capabilities, and the system was renamed the third extended file system
(ext3).Linuxkerneldevelopersthenaugmentedext3withmodernfile-system
featuressuchasextents.Thisnewfilesystemiscalledthefourthextendedfile
system(ext4).Therestofthissectiondiscussesext3,however,sinceitremains806 Chapter20 TheLinuxSystem
themost-deployedLinuxfilesystem.Mostofthediscussionappliesequallyto
ext4.
Linux’sext3hasmuchincommonwiththeBSDFastFileSystem(FFS)(Sec-
tionC.7.7).Itusesasimilarmechanismforlocatingthedatablocksbelonging
toaspecificfile,storingdata-blockpointersinindirectblocksthroughout the
file systemwith up to three levelsof indirection. As inFFS, directory files are
stored on disk just like normal files, although their contents are interpreted
differently. Each block in a directory file consists of a linked list of entries. In
turn, each entry contains the length of the entry, the name of a file, and the
inodenumberoftheinodetowhichthatentryrefers.
The main differences between ext3 and FFS lie in their disk-allocation
policies.InFFS,thediskisallocatedtofilesinblocksof8KB.Theseblocksare
subdivided into fragments of 1 KB for storage of small files or partially filled
blocks at the ends of files. In contrast, ext3 does not use fragments at all but
performsallitsallocationsinsmallerunits.Thedefaultblocksizeonext3varies
asafunctionofthetotalsizeofthefilesystem.Supportedblocksizesare1,2,
4,and8KB.
Tomaintain high performance,the operating systemmust try toperform
I/O operations in large chunks whenever possible by clustering physically
adjacentI/Orequests.Clusteringreducestheper-requestoverheadincurredby
devicedrivers,disks,anddisk-controllerhardware.Ablock-sizedI/Orequest
sizeistoosmalltomaintaingoodperformance,soext3usesallocationpolicies
designed to place logically adjacent blocks of a file into physically adjacent
blocksondisk,sothatitcansubmitanI/Orequestforseveraldiskblocksasa
singleoperation.
Theext3allocationpolicyworksasfollows:AsinFFS,anext3filesystemis
partitionedintomultiplesegments.Inext3,thesearecalledblockgroups.FFS
uses the similar concept of cylinder groups, where each group corresponds
to a single cylinder of a physical disk. (Note that modern disk-drivetechnol-
ogy packs sectors onto the disk at different densities, and thus with different
cylinder sizes, depending on how far the disk head is from the center of the
disk. Therefore, fixed-sized cylinder groups do not necessarily correspond to
thedisk’sgeometry.)
When allocating a file, ext3 must first select the block group for that file.
Fordatablocks,itattemptstoallocatethefiletotheblockgrouptowhichthe
file’sinodehasbeenallocated.Forinodeallocations,itselectstheblockgroup
inwhichthefile’sparentdirectoryresidesfornondirectoryfiles.Directoryfiles
are not kept together but rather are dispersedthroughout the available block
groups.Thesepoliciesaredesignednotonlytokeeprelatedinformationwithin
the same block group but also to spread out the disk load among the disk’s
blockgroupstoreducethefragmentationofanyoneareaofthedisk.
Withinablock group,ext3triestokeepallocations physicallycontiguous
if possible, reducing fragmentation if it can. It maintains a bitmap of all free
blocks in a block group. When allocating the first blocks for a new file, it
startssearchingforafreeblockfromthebeginningoftheblockgroup.When
extendingafile,itcontinuesthesearchfromtheblockmostrecentlyallocated
to the file. The search is performed in two stages. First, ext3 searches for an
entire free byte in the bitmap; if it fails to find one, it looks for any free bit.
Thesearchforfreebytesaimstoallocatediskspaceinchunksofatleasteight
blockswherepossible.20.7 FileSystems 807
Onceafreeblockhasbeenidentified,thesearchisextendedbackwarduntil
an allocated block is encountered. When a free byte is found in the bitmap,
this backward extension prevents ext3 from leaving a hole between the most
recentlyallocatedblockinthepreviousnonzerobyteandthezerobytefound.
Oncethenextblocktobeallocatedhasbeenfoundbyeitherbitorbytesearch,
ext3 extends the allocation forward for up to eight blocks and preallocates
theseextrablockstothefile.Thispreallocationhelpstoreducefragmentation
during interleaved writes to separate files and also reduces the CPU cost of
diskallocationbyallocatingmultipleblockssimultaneously.Thepreallocated
blocksarereturnedtothefree-spacebitmapwhenthefileisclosed.
Figure 20.7 illustrates the allocation policies. Each row represents a
sequence of set and unset bits in an allocation bitmap, indicating used and
freeblocksondisk.Inthefirstcase,ifwecanfindanyfreeblockssufficiently
nearthestartofthesearch,thenweallocatethemnomatterhowfragmented
they may be. The fragmentation is partially compensated for by the fact that
the blocks are close together and can probably all be read without any disk
seeks.Furthermore,allocatingthemalltoonefileisbetterinthelongrunthan
allocatingisolatedblockstoseparatefilesoncelargefreeareasbecomescarce
ondisk.Inthesecondcase,wehavenotimmediatelyfoundafreeblockclose
by,sowesearchforwardfor anentirefreebyteinthe bitmap.Ifweallocated
that byte as a whole, we would end up creating a fragmented area of free
space between it and the allocation preceding it. Thus, before allocating, we
backuptomakethisallocationflushwiththeallocationprecedingit,andthen
weallocateforwardtosatisfythedefaultallocationofeightblocks.
allocating scattered free blocks
allocating continuous free blocks
block selected
block in use bit boundary
by allocator
free block bitmap search byte boundary
Figure20.7 ext3block-allocationpolicies.808 Chapter20 TheLinuxSystem
20.7.3 Journaling
The ext3 file system supports a popular feature called journaling, whereby
modifications to the file system are written sequentially to a journal. Aset of
operations that performs a specific task is a transaction. Once a transaction
is written to the journal, it is considered to be committed. Meanwhile, the
journal entries relating to the transaction are replayed across the actual file-
system structures. As the changes are made, a pointer is updated to indicate
whichactionshavecompletedandwhicharestillincomplete.Whenanentire
committedtransactioniscompleted,itisremovedfromthejournal.Thejour-
nal,which isactually acircularbuffer,maybeinaseparatesectionofthefile
system, or it may even be on a separate disk spindle. It is more efficient, but
morecomplex,tohaveitunderseparateread–writeheads,therebydecreasing
headcontentionandseektimes.
Ifthesystemcrashes,sometransactionsmayremaininthejournal.Those
transactions were never completed to the file system even though they were
committedbytheoperatingsystem,sotheymustbecompletedoncethesystem
recovers. The transactions can be executed from the pointer until the work is
complete,andthe file-systemstructuresremainconsistent.The onlyproblem
occurs when a transaction has been aborted—that is, it was not committed
before the system crashed. Any changes from those transactions that were
applied to the file system must be undone, again preserving the consistency
ofthefilesystem.Thisrecoveryisallthatisneededafteracrash,eliminating
allproblemswithconsistencychecking.
Journalingfilesystemsmayperformsomeoperationsfasterthannonjour-
nalingsystems,asupdatesproceedmuchfasterwhentheyareappliedtothe
in-memoryjournalratherthandirectlytotheon-diskdatastructures.Therea-
sonforthisimprovementisfoundintheperformanceadvantageofsequential
I/O over random I/O. Costly synchronous random writes to the file system
areturnedintomuchlesscostlysynchronoussequentialwritestothefilesys-
tem’sjournal.Thosechanges,inturn,arereplayedasynchronouslyviarandom
writes to the appropriate structures. The overall result is a significant gain in
performanceoffile-systemmetadata-orientedoperations,suchasfilecreation
anddeletion.Duetothisperformanceimprovement,ext3canbeconfiguredto
journalonlymetadataandnotfiledata.
20.7.4 The Linux Proc File System
The flexibility of the Linux VFS enables us to implement a file system that
doesnotstoredatapersistentlyatallbutratherprovidesaninterfacetosome
otherfunctionality.TheLinux/procfilesystemisanexampleofafilesystem
whosecontentsarenotactuallystoredanywherebutarecomputedondemand
accordingtouserfileI/Orequests.
A/procfilesystemisnotuniquetoLinux.UNIXv8introduceda/procfile
systemanditsusehasbeenadoptedandexpandedintomanyotheroperating
systems.Itisanefficientinterfacetothekernel’sprocessnamespaceandhelps
with debugging. Each subdirectory of the file system corresponded not to a
directoryonanydiskbutrathertoanactiveprocessonthecurrentsystem.A
listing of the file system reveals one directory per process, with the directory20.7 FileSystems 809
name being the ASCII decimal representation of the process’s unique process
identifier(PID).
Linuximplementssucha/procfilesystembutextendsitgreatlybyadding
a number of extra directoriesand text files under the file system’s root direc-
tory. These new entries correspond to various statistics about the kernel and
the associated loaded drivers. The /proc file system provides a way for pro-
grams to access this information as plain text files; the standard UNIX user
environment provides powerful tools to process such files. For example, in
thepast,thetraditionalUNIXpscommandforlistingthestatesofallrunning
processeshasbeenimplementedasaprivilegedprocessthatreadstheprocess
state directly from the kernel’s virtual memory. Under Linux, this command
is implemented as an entirely unprivileged program that simply parses and
formatstheinformationfrom/proc.
The /proc file system must implement two things: a directory structure
andthefilecontentswithin.BecauseaUNIXfilesystemisdefinedasasetoffile
anddirectoryinodesidentifiedbytheirinodenumbers,the/procfilesystem
mustdefineauniqueandpersistentinodenumberforeachdirectoryandthe
associatedfiles.Oncesuchamappingexists,thefilesystemcanusethisinode
number to identify just what operation is required when a user tries to read
from a particular file inode or to perform a lookup in a particular directory
inode. When data are read from one of these files, the /proc file system will
collecttheappropriateinformation,formatitintotextualform,andplaceitinto
therequestingprocess’sreadbuffer.
The mapping from inode number to information type splits the inode
numberintotwofields.InLinux,aPIDis16bitsinsize,butaninodenumber
is32bits.Thetop16bitsoftheinodenumberareinterpretedasaPID,andthe
remaining bits define what type of information is being requestedabout that
process.
A PID of zero is not valid, so a zero PID field in the inode number is
takentomeanthatthisinodecontainsglobal—ratherthanprocess-specific—
information.Separateglobalfilesexistin/proctoreportinformationsuchas
thekernelversion,freememory,performancestatistics,anddriverscurrently
running.
Notalltheinodenumbersinthisrangearereserved.Thekernelcanallocate
new /proc inode mappings dynamically, maintaining a bitmap of allocated
inode numbers. It also maintains a tree data structure of registered global
/proc file-system entries. Each entry contains the file’s inode number, file
name, and access permissions, along with the special functions used to gen-
eratethefile’scontents.Driverscanregisterandderegisterentriesinthistree
atanytime,andaspecialsectionofthetree—appearingunderthe/proc/sys
directory—isreservedforkernelvariables.Filesunderthistreearemanaged
byasetofcommonhandlersthatallowbothreadingandwritingofthesevari-
ables,soasystemadministratorcantunethevalueofkernelparameterssimply
bywritingoutthenewdesiredvaluesinASCIIdecimaltotheappropriatefile.
To allow efficient access to these variables from within applications, the
/proc/syssubtreeismadeavailablethroughaspecialsystemcall,sysctl(),
thatreadsandwritesthesamevariablesinbinary,ratherthanintext,without
theoverheadofthefilesystem.sysctl()isnotanextrafacility;itsimplyreads
the/procdynamicentrytreetoidentifythevariablestowhichtheapplication
isreferring.810 Chapter20 TheLinuxSystem
user application
block
file system character network
device file
device file socket
I/O scheduler
line protocol
TTY driver
discipline driver
SCSI manager
block
character network
device
SCSI device device device
driver
driver driver driver
Figure20.8 Device-driverblockstructure.
20.8Input and Output
Totheuser,theI/OsysteminLinuxlooksmuchlikethatinanyUNIXsystem.
Thatis,totheextentpossible,alldevicedriversappearasnormalfiles.Users
can open an access channel to a device in the same way they open any other
file—devicescanappearasobjectswithinthefilesystem.Thesystemadmin-
istratorcancreatespecialfileswithinafilesystemthatcontainreferencestoa
specificdevicedriver,andauseropeningsuchafilewillbeabletoreadfrom
andwritetothedevicereferenced.Byusingthenormalfile-protectionsystem,
which determineswho canaccess which file,the administratorcan setaccess
permissionsforeachdevice.
Linuxsplitsalldevicesintothreeclasses:blockdevices,characterdevices,
andnetworkdevices.Figure20.8illustratestheoverallstructureofthedevice-
driversystem.
Blockdevicesincludealldevicesthatallowrandomaccesstocompletely
independent,fixed-sizedblocksofdata,includingharddisksandfloppydisks,
CD-ROMsandBlu-raydiscs,andflashmemory.Blockdevicesaretypicallyused
to store file systems, but direct access to a block device is also allowed so
that programs can create and repair the file system that the device contains.
Applications can also access these block devices directly if they wish. For
example, a database application may prefer to perform its own fine-tuned
layoutofdataontoadiskratherthanusingthegeneral-purposefilesystem.
Characterdevicesincludemostotherdevices,suchasmiceandkeyboards.
The fundamental difference between block and character devices is random
access—block devices are accessed randomly, while character devices are
accessed serially.For example,seeking to a certain position in a file might be
supportedforaDVDbutmakesnosenseforapointingdevicesuchasamouse.
Network devices are dealt with differently from block and character
devices.Users cannot directlytransfer data to network devices.Instead, they
must communicate indirectly by opening a connection to the kernel’s net-
workingsubsystem.Wediscusstheinterfacetonetworkdevicesseparatelyin
Section20.10.
20.8.1 Block Devices
Blockdevicesprovidethemaininterfacetoalldiskdevicesinasystem.Perfor-
mance is particularly important for disks, and the block-device system must20.8 InputandOutput 811
provide functionality to ensure that disk access is as fast as possible. This
functionalityisachievedthroughtheschedulingofI/Ooperations.
Inthecontextofblockdevices,ablockrepresentstheunitwithwhichthe
kernelperformsI/O.Whenablockisreadintomemory,itisstoredinabuffer.
The request manager is the layer of software that manages the reading and
writingofbuffercontentstoandfromablock-devicedriver.
Aseparate list of requests is kept for each block-device driver. Tradition-
ally,theserequestshavebeenscheduledaccordingtoaunidirectional-elevator
(C-SCAN) algorithm that exploits the order in which requests are inserted in
andremovedfromthelists.Therequestlistsaremaintainedinsortedorderof
increasing starting-sector number. When a request is accepted for processing
byablock-devicedriver,itisnotremovedfromthelist.Itisremovedonlyafter
theI/Oiscomplete,atwhichpointthedrivercontinueswiththenextrequest
inthelist,evenifnewrequestshavebeeninsertedinthelistbeforetheactive
request.AsnewI/Orequestsaremade,therequestmanagerattemptstomerge
requestsinthelists.
Linux kernel version 2.6 introduced a new I/O scheduling algorithm.
Althoughasimpleelevatoralgorithmremainsavailable,thedefaultI/Osched-
uler is now the Completely Fair Queueing (CFQ) scheduler. The CFQ I/O
scheduleris fundamentally differentfrom elevator-basedalgorithms. Instead
ofsortingrequestsintoalist,CFQmaintainsasetoflists—bydefault,onefor
eachprocess.Requestsoriginatingfromaprocessgointhatprocess’slist.For
example,iftwoprocessesareissuingI/Orequests,CFQwillmaintaintwosep-
aratelistsofrequests,oneforeachprocess.Thelistsaremaintainedaccording
totheC-SCANalgorithm.
CFQservicesthelistsdifferentlyaswell.WhereatraditionalC-SCANalgo-
rithmisindifferenttoaspecificprocess,CFQserviceseachprocess’slistround-
robin. It pulls a configurable number of requests (by default, four) from each
listbeforemovingontothenext.Thismethodresultsinfairnessattheprocess
level—each process receives an equal fraction of the disk’s bandwidth. The
resultisbeneficialwithinteractiveworkloadswhereI/Olatencyisimportant.
Inpractice,however,CFQperformswellwithmostworkloads.
20.8.2 Character Devices
Acharacter-device drivercan be almost any devicedriverthat doesnot offer
randomaccesstofixedblocksofdata.Anycharacter-devicedriversregistered
to the Linux kernel must also register a set of functions that implement the
fileI/O operations that the drivercan handle.The kernelperforms almost no
preprocessing of a file read or write request to a character device. It simply
passes the request to the device in question and lets the device deal with the
request.
The main exception to this rule is the special subset of character-device
drivers that implement terminal devices. The kernel maintains a standard
interfacetothesedriversby meansofasetoftty structstructures.Eachof
these structures providesbuffering and flow control on the data stream from
theterminaldeviceandfeedsthosedatatoalinediscipline.
A line discipline is an interpreter for the information from the terminal
device.Themostcommonlinedisciplineisthettydiscipline,whichgluesthe
terminal’sdatastreamontothestandardinputandoutputstreamsofauser’s
runningprocesses,allowingthoseprocessestocommunicatedirectlywiththe812 Chapter20 TheLinuxSystem
user’sterminal.Thisjobiscomplicatedbythefactthatseveralsuchprocesses
mayberunningsimultaneously,andthettylinedisciplineisresponsiblefor
attaching and detaching the terminal’s input and output from the various
processes connected to it as those processes are suspended or awakened by
theuser.
Other line disciplines also are implementedthat have nothing to do with
I/O to a user process. The PPP and SLIP networking protocols are ways of
encoding a networking connection over a terminal device such as a serial
line.TheseprotocolsareimplementedunderLinuxasdriversthatatoneend
appear to the terminal system as line disciplines and at the other end appear
to the networking system as network-device drivers. After one of these line
disciplineshasbeenenabledonaterminaldevice,anydataappearingonthat
terminalwillberouteddirectlytotheappropriatenetwork-devicedriver.
20.9Interprocess Communication
Linux provides a rich environment for processes to communicate with each
other. Communication may be just a matter of letting another process know
that some event has occurred, or it may involve transferring data from one
processtoanother.
20.9.1 Synchronization and Signals
The standard Linux mechanism for informing a process that an event has
occurred is the signal. Signals can be sent from any process to any other
process,withrestrictionsonsignalssenttoprocessesownedbyanother user.
However, a limited number of signals is available, and they cannot carry
information. Onlythefact thatasignalhas occurredisavailabletoaprocess.
Signalsarenotgeneratedonlybyprocesses.Thekernelalsogeneratessignals
internally.Forexample,itcansendasignaltoaserverprocesswhendataarrive
on a network channel, to a parent process when a child terminates, or to a
waitingprocesswhenatimerexpires.
Internally, the Linux kernel does not use signals to communicate with
processes running in kernel mode. If a kernel-mode process is expecting an
event to occur, it will not use signals to receive notification of that event.
Rather,communicationaboutincomingasynchronouseventswithinthekernel
takes place through the use of scheduling states and wait queue structures.
Thesemechanismsallowkernel-modeprocessestoinformoneanotherabout
relevantevents,and theyalsoalloweventstobe generatedby devicedrivers
orbythenetworkingsystem.Wheneveraprocesswantstowaitforsomeevent
to complete, it places itself on a wait queue associated with that event and
tellstheschedulerthatitisnolongereligibleforexecution.Oncetheeventhas
completed,everyprocessonthewaitqueuewillbeawakened.Thisprocedure
allows multiple processes to wait for a single event. For example, if several
processesaretryingtoreadafilefrom adisk,thentheywillallbe awakened
oncethedatahavebeenreadintomemorysuccessfully.
Although signals have always been the main mechanism for commu-
nicating asynchronous events among processes, Linux also implements the
semaphoremechanismofSystemVUNIX.Aprocesscanwaitonasemaphore
aseasilyasitcanwaitforasignal,butsemaphoreshavetwoadvantages:large20.10 NetworkStructure 813
numbersofsemaphorescanbesharedamongmultipleindependentprocesses,
and operations on multiple semaphores can be performed atomically. Inter-
nally,thestandardLinuxwaitqueuemechanismsynchronizes processesthat
arecommunicatingwithsemaphores.
20.9.2 Passing of Data among Processes
Linuxoffersseveralmechanismsforpassingdataamongprocesses.Thestan-
dardUNIXpipemechanismallowsachildprocesstoinheritacommunication
channelfromitsparent;datawrittentooneendofthepipecanbereadatthe
other. Under Linux, pipes appear as just another type of inode to virtual file
system software, and each pipe has a pair of wait queues to synchronize the
readerandwriter.UNIXalsodefinesasetofnetworkingfacilitiesthatcansend
streamsofdatatobothlocaland remoteprocesses.Networkingiscoveredin
Section20.10.
Another process communications method, shared memory, offers an
extremelyfastwaytocommunicatelargeorsmallamountsofdata.Anydata
written by one process to a shared memory region can be read immediately
by any other process that has mapped that region into its address space.
The main disadvantage of shared memory is that, on its own, it offers no
synchronization. A process can neither ask the operating system whether a
pieceofsharedmemoryhasbeenwrittentonorsuspendexecutionuntilsuch
a write occurs. Shared memory becomes particularly powerful when used
in conjunction with another interprocess-communication mechanism that
providesthemissingsynchronization.
Ashared-memoryregioninLinuxisapersistentobjectthatcanbecreated
or deleted by processes. Such an object is treated as though it were a small,
independent address space. The Linux paging algorithms can elect to page
shared-memory pages out to disk, just as they can page out a process’s data
pages. The shared-memory object acts as a backing store for shared-memory
regions,justasafilecanactasabackingstoreforamemory-mappedmemory
region. When a file is mapped into a virtual address space region, then any
pagefaultsthatoccurcausetheappropriatepageofthefiletobemappedinto
virtualmemory.Similarly,shared-memorymappingsdirectpagefaultstomap
inpagesfromapersistentshared-memoryobject.Alsojustasforfiles,shared-
memory objects remember their contents even if no processes are currently
mappingthemintovirtualmemory.
20.10 Network Structure
Networking is a key area of functionality for Linux. Not only does Linux
supportthestandardInternetprotocolsusedformostUNIX-to-UNIXcommuni-
cations,butitalsoimplementsanumberofprotocolsnativetoother,non-UNIX
operatingsystems.Inparticular,sinceLinuxwasoriginallyimplementedpri-
marily on PCs, rather than on large workstations or on server-class systems,
it supports many of the protocols typically used on PC networks, such as
AppleTalkandIPX.
Internally,networkingintheLinuxkernelisimplementedbythreelayers
ofsoftware:814 Chapter20 TheLinuxSystem
1. Thesocketinterface
2. Protocoldrivers
3. Network-devicedrivers
User applications perform all networking requests through the socket
interface. This interface is designed to look like the 4.3 BSD socket layer, so
thatanyprogramsdesignedtomakeuseofBerkeleysocketswillrunonLinux
withoutanysource-codechanges.ThisinterfaceisdescribedinSectionC.9.1.
TheBSDsocketinterfaceissufficientlygeneraltorepresentnetworkaddresses
forawiderangeofnetworkingprotocols.ThissingleinterfaceisusedinLinux
toaccessnotjustthoseprotocolsimplementedonstandardBSDsystemsbutall
theprotocolssupportedbythesystem.
The next layer of software is the protocol stack, which is similar in orga-
nization to BSD’s own framework. Whenever any networking data arrive at
thislayer,eitherfromanapplication’ssocketorfromanetwork-devicedriver,
thedataareexpectedtohavebeentaggedwithanidentifierspecifyingwhich
network protocol they contain. Protocols can communicate with one another
iftheydesire;forexample,withintheInternetprotocolset,separateprotocols
managerouting,errorreporting,andreliableretransmissionoflostdata.
The protocol layer may rewrite packets, create new packets, split
or reassemble packets into fragments, or simply discard incoming data.
Ultimately,once the protocol layer has finished processing a set ofpackets, it
passesthem on, eitherupward tothe socket interfaceifthe dataare destined
for a local connection or downward to a device driver if the data need to be
transmitted remotely. The protocol layer decides to which socket or device it
willsendthepacket.
All communication between the layers of the networking stack is per-
formed by passing single skbuff (socket buffer) structures. Each of these
structures contains a set of pointers into a single continuous area of memory,
representing a buffer inside which network packets can be constructed. The
valid data in a skbuff do not need to start at the beginning of the skbuff’s
buffer,and theydonot needtoruntotheend.The networking codecanadd
datatoortrimdatafromeitherendofthepacket,aslongastheresultstillfits
intotheskbuff.Thiscapacityisespeciallyimportantonmodernmicroproces-
sors,whereimprovementsinCPUspeedhavefaroutstrippedtheperformance
of main memory. The skbuff architecture allows flexibility in manipulating
packetheadersandchecksumswhileavoidinganyunnecessarydatacopying.
ThemostimportantsetofprotocolsintheLinuxnetworkingsystemisthe
TCP/IP protocol suite. This suite comprises a number of separate protocols.
The IPprotocol implementsrouting betweendifferenthosts anywhere on the
network.OntopoftheroutingprotocolaretheUDP,TCP,andICMPprotocols.
The UDP protocol carries arbitrary individual datagrams between hosts. The
TCPprotocolimplementsreliableconnectionsbetweenhostswithguaranteed
in-order delivery of packets and automatic retransmission of lost data. The
ICMPprotocolcarriesvariouserrorandstatusmessagesbetweenhosts.
Eachpacket(skbuff)arrivingatthenetworkingstack’sprotocolsoftware
is expected to be already tagged with an internal identifier indicating the
protocol to which the packet is relevant. Different networking-device drivers20.10 NetworkStructure 815
encodetheprotocoltypeindifferentways;thus,theprotocolforincomingdata
mustbeidentifiedinthedevicedriver.Thedevicedriverusesahashtableof
knownnetworking-protocolidentifierstolookuptheappropriateprotocoland
passesthepackettothatprotocol.Newprotocolscanbeaddedtothehashtable
askernel-loadablemodules.
Incoming IP packets are delivered to the IP driver. The job of this layer
is to perform routing. After deciding where the packet is to be sent, the IP
driver forwards the packet to the appropriate internal protocol driver to be
deliveredlocallyorinjectsitbackintoaselectednetwork-device-driverqueue
to be forwarded to another host. It performs the routing decision using two
tables: the persistent forwarding information base (FIB) and a cache of recent
routing decisions. The FIB holds routing-configuration information and can
specifyroutes basedeither ona specificdestinationaddressor on awildcard
representingmultipledestinations.TheFIBisorganizedasasetofhashtables
indexedbydestinationaddress;thetablesrepresentingthemostspecificroutes
are always searched first. Successful lookups from this table are added to
the route-caching table, which caches routes only by specific destination. No
wildcardsarestoredinthecache,solookupscanbemadequickly.Anentryin
theroutecacheexpiresafterafixedperiodwithnohits.
At various stages, the IP software passes packets to a separate section of
codeforfirewal management—selectivefilteringofpacketsaccordingtoarbi-
trarycriteria,usuallyforsecuritypurposes.Thefirewallmanagermaintainsa
numberofseparatefirewal chainsandallowsaskbufftobematchedagainst
anychain.Chainsarereservedforseparatepurposes:oneisusedforforwarded
packets,oneforpacketsbeinginputtothishost,andonefordatageneratedat
this host. Each chain is held as an orderedlist of rules, where a rule specifies
one of a number of possible firewall-decision functions plus some arbitrary
dataformatchingpurposes.
Two other functions performed by the IP driver are disassembly and
reassemblyoflargepackets.Ifanoutgoingpacketistoolargetobequeuedto
adevice,itissimplysplitupintosmallerfragments,whichareallqueuedto
thedriver.Atthereceivinghost,thesefragmentsmustbereassembled.TheIP
drivermaintainsanipfragobjectforeachfragmentawaitingreassemblyand
anipqforeachdatagrambeingassembled.Incoming fragmentsarematched
againsteachknownipq.Ifamatchisfound,thefragmentisaddedtoit;oth-
erwise,anewipqis created.Once the final fragment has arrivedfor aipq,a
completelynewskbuffisconstructedtoholdthenewpacket,andthispacket
ispassedbackintotheIPdriver.
Packets identified by the IPas destined for this host are passed on to one
of the other protocol drivers. The UDP and TCP protocols share a means of
associating packets with source and destination sockets: each connected pair
of sockets is uniquely identified by its source and destination addresses and
by the source and destination port numbers. The socket lists are linked to
hashtableskeyedonthesefouraddressandportvaluesforsocketlookupon
incomingpackets.TheTCPprotocolhastodealwithunreliableconnections,so
it maintains ordered lists of unacknowledged outgoing packets to retransmit
after a timeout and of incoming out-of-order packets to be presented to the
socketwhenthemissingdatahavearrived.816 Chapter20 TheLinuxSystem
20.11 Security
Linux’ssecuritymodeliscloselyrelatedtotypicalUNIXsecuritymechanisms.
Thesecurityconcernscanbeclassifiedintwogroups:
1. Authentication.Makingsurethatnobodycanaccessthesystemwithout
firstprovingthatshehasentryrights
2. Accesscontrol.Providingamechanismforcheckingwhetherauserhas
the right to access a certain object and preventing access to objects as
required
20.11.1 Authentication
Authentication in UNIX has typically been performed through the use of a
publiclyreadablepasswordfile.Auser’spasswordiscombinedwitharandom
“salt”value,andtheresultisencodedwithaone-waytransformationfunction
and stored in the password file. The use of the one-way function means that
theoriginalpasswordcannotbededucedfromthepasswordfileexceptbytrial
and error. When a user presents a password to the system, the password is
recombinedwiththesaltvaluestoredinthepasswordfileandpassedthrough
the same one-way transformation. If the result matches the contents of the
passwordfile,thenthepasswordisaccepted.
Historically, UNIX implementations of this mechanism have had several
drawbacks.Passwordswereoftenlimitedtoeightcharacters,andthenumber
of possible salt values was so low that an attacker could easily combine a
dictionary of commonly used passwords with every possible salt value and
have a good chance of matching one or more passwords in the password
file, gaining unauthorized access to any accounts compromised as a result.
Extensions to the password mechanism have been introduced that keep the
encrypted password secret in a file that is not publicly readable, that allow
longerpasswords,orthatusemoresecuremethodsofencodingthepassword.
Otherauthenticationmechanismshavebeenintroducedthatlimittheperiods
duringwhich auserispermittedtoconnect tothesystem.Also,mechanisms
exist to distribute authentication information to all the related systems in a
network.
AnewsecuritymechanismhasbeendevelopedbyUNIXvendorstoaddress
authentication problems. The pluggable authentication modules (PAM) sys-
tem is based on a shared library that can be used by any system component
thatneedstoauthenticateusers.Animplementationofthissystemisavailable
underLinux.PAMallowsauthenticationmodulestobeloadedondemandas
specified in a system-wide configuration file. If a new authentication mecha-
nismisaddedatalaterdate,itcanbeaddedtotheconfiguration file,andall
systemcomponentswillimmediatelybeabletotakeadvantageofit.PAMmod-
ules can specify authentication methods, account restrictions, session-setup
functions,andpassword-changingfunctions(sothat,whenuserschangetheir
passwords, all the necessary authentication mechanisms can be updated at
once).20.11 Security 817
20.11.2 Access Control
AccesscontrolunderUNIXsystems,includingLinux,isperformedthroughthe
useofuniquenumericidentifiers.Auseridentifier(UID)identifiesasingleuser
orasinglesetofaccessrights.Agroupidentifier(GID)isanextraidentifierthat
canbeusedtoidentifyrightsbelongingtomorethanoneuser.
Access control is applied to various objects in the system. Every file
available in the system is protected by the standard access-control mecha-
nism. In addition, other shared objects, such as shared-memory sections and
semaphores,employthesameaccesssystem.
Every object in a UNIX system under user and group access control has a
singleUIDandasingleGIDassociatedwithit.Userprocessesalsohaveasingle
UID,buttheymayhavemorethanoneGID.Ifaprocess’sUIDmatchestheUID
of an object, then the process has user rights or owner rights to that object.
Ifthe UIDs do not match but any GID of the process matches the object’s GID,
thengrouprightsareconferred;otherwise,theprocesshasworldrightstothe
object.
Linuxperformsaccesscontrolbyassigningobjectsaprotectionmaskthat
specifies which access modes—read, write, or execute—are to be granted to
processes with owner, group, or world access. Thus, the owner of an object
mighthavefullread,write,andexecuteaccesstoafile;otherusersinacertain
groupmightbegivenreadaccessbutdeniedwriteaccess;andeverybodyelse
mightbegivennoaccessatall.
The only exception is the privilegedroot UID. Aprocess with this special
UIDisgrantedautomaticaccesstoanyobjectinthesystem,bypassingnormal
access checks. Such processes are also granted permission to perform privi-
leged operations, such as reading any physical memory or opening reserved
network sockets. This mechanism allows the kernel to prevent normal users
fromaccessingtheseresources:mostofthekernel’skeyinternalresourcesare
implicitlyownedbytherootUID.
LinuximplementsthestandardUNIXsetuidmechanismdescribedinSec-
tion C.3.2. This mechanism allows a program to run with privilegesdifferent
from those of the user running the program. For example, the lpr program
(whichsubmitsajobtoaprintqueue)hasaccesstothesystem’sprintqueues
evenif the user running that program does not. The UNIX implementationof
setuiddistinguishesbetweenaprocess’srealand effectiveUID. Thereal
UIDisthatoftheuserrunningtheprogram;theeffectiveUIDisthatofthefile’s
owner.
Under Linux, this mechanism is augmented in two ways. First, Linux
implements the POSIX specification’s saved user-id mechanism, which
allowsaprocesstodropandreacquireitseffectiveUIDrepeatedly.Forsecurity
reasons,aprogrammaywanttoperformmostofitsoperationsinasafemode,
waivingtheprivilegesgrantedbyitssetuidstatus;butitmaywishtoperform
selected operations with all its privileges. Standard UNIX implementations
achievethiscapacityonlybyswappingtherealandeffectiveUIDs.Whenthis
isdone,thepreviouseffectiveUIDisremembered,buttheprogram’srealUID
doesnotalwayscorrespondtotheUIDoftheuserrunningtheprogram.Saved
UIDs allow a process to set its effective UID to its real UID and then return to818 Chapter20 TheLinuxSystem
the previous value of its effective UID without having to modify the real UID
atanytime.
The second enhancement provided by Linux is the addition of a process
characteristic that grants just a subset of the rights of the effective UID. The
fsuid and fsgid process properties are used when access rights are granted
to files. The appropriate property is set every time the effective UID or GID is
set.However,thefsuidandfsgidcanbesetindependentlyoftheeffectiveids,
allowing aprocesstoaccess files onbehalfofanother userwithout taking on
the identity of that other user in any other way. Specifically, server processes
can use this mechanism to serve files to a certain user without becoming
vulnerabletobeingkilledorsuspendedbythatuser.
Finally, Linux provides a mechanism for flexible passing of rights from
one programtoanother—a mechanism that has become common in modern
versions of UNIX. When a local network socket has been set up between any
two processes on the system, either of those processes may send to the other
process a file descriptor for one of its open files; the other process receives a
duplicate file descriptor for the same file. This mechanism allows a client to
passaccesstoasinglefileselectivelytosomeserverprocesswithoutgranting
that process any other privileges.For example, it is no longer necessary for a
print server to be able to read all the files of a user who submits a new print
job.Theprintclientcansimplypasstheserverfiledescriptorsforanyfilesto
beprinted,denyingtheserveraccesstoanyoftheuser’sotherfiles.
20.12 Summary
• Linuxisamodern,freeoperatingsystembasedonUNIXstandards.Ithas
been designed to run efficiently and reliably on common PC hardware;
it also runs on a variety of other platforms, such as mobile phones. It
provides a programming interface and user interface compatible with
standardUNIXsystemsandcanrunalargenumberofUNIXapplications,
includinganincreasingnumberofcommerciallysupportedapplications.
• Linux has not evolved in a vacuum. A complete Linux system includes
manycomponentsthatweredevelopedindependentlyofLinux.Thecore
Linux operating-system kernel is entirely original, but it allows much
existingfreeUNIXsoftwaretorun,resultinginanentireUNIX-compatible
operatingsystemfreefromproprietarycode.
• The Linux kernel is implemented as a traditional monolithic kernel for
performance reasons, but it is modular enough in design to allow most
driverstobedynamicallyloadedandunloadedatruntime.
• Linuxisamultiusersystem,providingprotectionbetweenprocessesand
runningmultipleprocessesaccordingtoatime-sharingscheduler.Newly
createdprocessescanshareselectivepartsoftheirexecutionenvironment
withtheirparentprocesses,allowingmultithreadedprogramming.
• Interprocesscommunication issupportedby both SystemVmechanisms
—message queues, semaphores, and shared memory—and BSD’s socket
interface. Multiple networking protocols can be accessed simultaneously
throughthesocketinterface.FurtherReading 819
• Thememory-managementsystemusespagesharingandcopy-on-writeto
minimizetheduplicationofdatasharedbydifferentprocesses.Pagesare
loadedondemandwhentheyarefirstreferencedandarepagedbackout
tobackingstoreaccordingtoanLFUalgorithmifphysicalmemoryneeds
tobereclaimed.
• To the user, the file system appears as a hierarchical directory tree that
obeysUNIXsemantics.Internally,Linuxusesanabstractionlayertoman-
age multiple file systems. Device-oriented, networked, and virtual file
systems are supported. Device-oriented file systems access disk storage
throughapagecachethatisunifiedwiththevirtualmemorysystem.
Practice Exercises
20.1 Dynamicallyloadablekernelmodulesgiveflexibilitywhendriversare
added to a system, but do they have disadvantages too? Under what
circumstanceswouldakernelbecompiledintoasinglebinaryfile,and
when would it be better to keep it split into modules? Explain your
answer.
20.2 Multithreadingisacommonlyusedprogrammingtechnique.Describe
three different ways to implement threads, and compare these three
methodswiththeLinuxclone()mechanism.Whenmightusingeach
alternativemechanismbebetterorworsethanusingclones?
20.3 The Linux kernel does not allow paging out of kernel memory. What
effect does this restriction have on the kernel’s design? What are two
advantagesandtwodisadvantagesofthisdesigndecision?
20.4 Discussthreeadvantagesofdynamic(shared)linkageoflibrariescom-
paredwithstaticlinkage.Describetwocasesinwhichstaticlinkageis
preferable.
20.5 Comparetheuseofnetworkingsocketswiththeuseofsharedmemory
asamechanismforcommunicatingdatabetweenprocessesonasingle
computer.Whataretheadvantagesofeachmethod?Whenmighteach
bepreferred?
20.6 Atonetime,UNIXsystemsuseddisk-layoutoptimizationsbasedonthe
rotation position of disk data, but modern implementations, includ-
ing Linux, simply optimize for sequential data access. Why do they
do so? Of what hardware characteristics does sequential access take
advantage?Whyisrotationaloptimizationnolongersouseful?
Further Reading
The Linux system is a product of the Internet; as a result, much of the avail-
able documentation on Linux is available in some form on the Internet. The
followingkeysitesreferencemostoftheusefulinformationavailable:820 Chapter20 TheLinuxSystem
• The Linux Cross-Reference Page (LXR) (http://lxr.linux.no) maintains cur-
rent listings of the Linux kernel, browsable via the web and fully cross-
referenced.
• TheKernelHackers’GuideprovidesahelpfuloverviewoftheLinuxkernel
componentsandinternalsandislocatedathttp://tldp.org/LDP/tlk/tlk.html.
• The Linux Weekly News (LWN) (http://lwn.net) provides weekly Linux-
relatednews,includingaverywellresearchedsubsectiononLinuxkernel
news.
ManymailinglistsdevotedtoLinuxarealsoavailable.Themostimportant
are maintained by a mailing-list manager that can be reached at the e-mail
address majordomo@vger.rutgers.edu. Send e-mail to this address with the
single line“help” in the mail’s body for information on how to access the list
serverandtosubscribetoanylists.
Finally, the Linux system itself can be obtained over the Internet. Com-
plete Linux distributions are available from the home sites of the compa-
nies concerned, and the Linux community also maintains archives of current
system components at several places on the Internet. The most important is
ftp://ftp.kernel.org/pub/linux.
In addition to investigating Internet resources, you can read about the
internalsoftheLinuxkernelin[Mauerer(2008)]and[Love(2010)].
The/procfilesystemwasintroducedin
http://lucasvr.gobolinux.org/etc/Killian84-Procfs-USENIX.pdf, and expanded
in
http://https://www.usenix.org/sites/default/files/usenixwinter91 faulkner.pdf.
Bibliography
[Love(2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[Mauerer(2008)] W.Mauerer,ProfessionalLinux KernelArchitecture,JohnWiley
andSons(2008).Exercises EX-58
Chapter 20 Exercises
20.7 What are the advantages and disadvantages of writing an operating
systeminahigh-levellanguage,suchasC?
20.8 Inwhatcircumstancesisthesystem-callsequencefork()exec()most
appropriate?Whenisvfork()preferable?
20.9 What sockettypeshouldbeusedtoimplementanintercomputerfile-
transfer program?What type should be usedfor aprogram that peri-
odically tests to see whether another computer is up on the network?
Explainyouranswer.
20.10 Linuxrunsonavarietyofhardwareplatforms.WhatstepsmustLinux
developerstake to ensure that the system is portable to different pro-
cessors and memory-management architectures and to minimize the
amountofarchitecture-specifickernelcode?
20.11 Whataretheadvantagesanddisadvantagesofmakingonlysomeofthe
symbolsdefinedinsideakernelaccessibletoaloadablekernelmodule?
20.12 Whataretheprimarygoalsoftheconflict-resolutionmechanismused
bytheLinuxkernelforloadingkernelmodules?
20.13 Discusshowtheclone()operationsupportedbyLinuxisusedtosup-
portbothprocessesandthreads.
20.14 Would you classify Linux threads as user-level threads or as kernel-
levelthreads?Supportyouranswerwiththeappropriatearguments.
20.15 What extracosts areincurredin thecreationand scheduling ofapro-
cess,comparedwiththecostofaclonedthread?
20.16 HowdoesLinux’sCompletelyFairScheduler(CFS)provideimproved
fairnessoveratraditionalUNIXprocessscheduler?Whenisthefairness
guaranteed?
20.17 WhatarethetwoconfigurablevariablesoftheCompletelyFairSched-
uler(CFS)?Whataretheprosandcons ofsettingeachofthemtovery
smallandverylargevalues?
20.18 TheLinuxschedulerimplements“soft”real-timescheduling.Whatfea-
tures necessary for certain real-time programming tasks are missing?
Howmighttheybeaddedtothekernel?Whatarethecosts(downsides)
ofsuchfeatures?
20.19 Underwhatcircumstanceswouldauserprocessrequestanoperation
thatresultsintheallocationofademand-zeromemoryregion?
20.20 What scenarios would cause a page of memory to be mapped into
a user program’s address space with the copy-on-write attribute
enabled?
20.21 InLinux,sharedlibrariesperformmanyoperationscentraltotheoper-
ating system. What is the advantage of keeping this functionality out
ofthekernel?Arethereanydrawbacks?Explainyouranswer.EX-59
20.22 What arethebenefitsofajournaling filesystemsuchasLinux’s ext3?
What arethe costs?Why doesext3providethe optiontojournal only
metadata?
20.23 ThedirectorystructureofaLinuxoperatingsystemcouldincludefiles
corresponding to several different file systems, including the Linux
/procfilesystem.Howmighttheneedtosupportdifferentfile-system
typesaffectthestructureoftheLinuxkernel?
20.24 In what ways does the Linux setuid feature differ from the setuid
featureSVR4?
20.25 TheLinuxsourcecodeisfreelyandwidelyavailableovertheInternet
and from CD-ROM vendors. What are three implications of this avail-
abilityforthesecurityoftheLinuxsystem?21
CHAPTER
Windows 10
Updatedby AlexIonescu
The Microsoft Windows 10 operating system is a preemptive multitasking
client operating system for microprocessors implementing the Intel IA-32,
AMD64,ARM,andARM64instructionsetarchitectures(ISAs).Microsoft’scorre-
spondingserveroperatingsystem,WindowsServer2016,isbasedonthesame
code as Windows 10 but supports only the 64-bit AMD64 ISAs. Windows 10
is the latest in a series of Microsoft operating systems based on its NT code,
which replacedthe earliersystems based on Windows 95/98. In this chapter,
wediscussthekeygoalsofWindows10,thelayeredarchitectureofthesystem
that has made it so easy to use, the file system, the networking features, and
theprogramminginterface.
CHAPTER OBJECTIVES
• Explore the principles underlying Windows 10’s design and the specific
componentsofthesystem.
• ProvideadetaileddiscussionoftheWindows10filesystem.
• IllustratethenetworkingprotocolssupportedinWindows10.
• DescribetheinterfaceavailableinWindows10tosystemandapplication
programmers.
• DescribetheimportantalgorithmsimplementedwithWindows10.
21.1 History
Inthemid-1980s,MicrosoftandIBMcooperatedtodeveloptheOS/2operating
system, which was written in assembly language for single-processor Intel
80286 systems. In 1988, Microsoft decided to end the joint effort with IBM
and develop its own “new technology” (or NT) portable operating system to
821822 Chapter21 Windows10
supportboththeOS/2andPOSIXapplicationprogramminginterfaces(APIs).In
October1988,DaveCutler,thearchitectoftheDECVAX/VMSoperatingsystem,
washiredandgiventhecharterofbuildingMicrosoft’snewoperatingsystem.
Originally, the team planned to use the OS/2 API as NT’s native environ-
ment,butduringdevelopment,NTwaschangedtouseanew32-bitWindows
API(calledWin32),basedonthepopular16-bitAPIusedinWindows 3.0.The
first versions of NT were Windows NT 3.1 and Windows NT 3.1 Advanced
Server. (At that time, 16-bit Windows was at Version 3.1.) Windows NT Ver-
sion 4.0 adopted the Windows 95 user interface and incorporated Internet
web-serverandweb-browsersoftware.Inaddition,user-interfaceroutinesand
all graphics code were moved into the kernel to improve performance (with
the sideeffectofdecreasedsystemreliabilityand significant loss ofsecurity).
Although previous versions of NT had been ported to other microprocessor
architectures (including a brief 64-bit port to Alpha AXP 64), the Windows
2000version,releasedinFebruary2000,supportedonlyIA-32-compatiblepro-
cessors due to marketplace factors. Windows 2000 incorporated significant
changes. It added Active Directory (an X.500-based directory service), better
networking and laptop support, support for plug-and-play devices, a dis-
tributedfilesystem,andsupportformoreprocessorsandmorememory.
21.1.1 Windows XP, Vista, and 7
InOctober2001,WindowsXPwasreleasedasbothanupdatetotheWindows
2000desktopoperatingsystemandareplacementforWindows95/98.InApril
2003,theservereditionofWindowsXP(calledWindowsServer2003)became
available.WindowsXPupdatedthegraphicaluserinterface(GUI)withavisual
design that took advantage of more recent hardware advances and many
new ease-of-use features. Numerous features were added to automatically
repair problems in applications and the operating system itself. Because of
thesechanges,WindowsXPprovidedbetternetworkinganddeviceexperience
(including zero-configuration wireless, instant messaging, streaming media,
and digital photography/video). Windows Server 2003 provided dramatic
performanceimprovementsforlargemultiprocessorssystems,aswellasbetter
reliabilityandsecuritythanearlierWindowsoperatingsystems.
The long-awaited update to Windows XP, called Windows Vista, was
released in January 2007, but it was not well received. Although Windows
VistaincludedmanyimprovementsthatlatercontinuedintoWindows7,these
improvements were overshadowed by Windows Vista’s perceived sluggish-
ness and compatibility problems. Microsoft responded to criticisms of Win-
dowsVistabyimprovingitsengineeringprocessesandworkingmoreclosely
withthemakersofWindowshardwareandapplications.
The result was Windows 7, which was released in October 2009, along
with corresponding server edition called Windows Server 2008 R2. Among
the significant engineering changes was the increased use of event tracing
rather than counters or profiling to analyze system behavior. Tracing runs
constantly in the system, watching hundreds of scenarios execute. Scenarios
include process startup and exit, file copy, and web-page load, for example.
When one of these scenarios fails, or when it succeeds but does not perform
well,thetracescanbeanalyzedtodeterminethecause.21.1 History 823
21.1.2 Windows 8
Three years later, in October 2012—amid an industry-wide pivot toward
mobile computing and the world of apps—Microsoft released Windows 8,
which represented the most significant change to the operating system since
WindowsXP.Windows8includedanewuserinterface(namedMetro)anda
newprogrammingmodelAPI(namedWinRT).Italsoincludedanewwayof
managingapplications(whichranunderanewsandboxmechanism)through
apackagesystemthatexclusivelysupportedthenewWindowsStore,acom-
petitortotheAppleAppStoreandtheAndroidStore.Additionally,Windows
8includedaplethoraofsecurity,boot,andperformanceimprovements.Atthe
sametime,supportfor“subsystems,”aconceptwe’lldescribefurtherlaterin
thechapter,wasremoved.
To support the new mobile world, Windows 8 was ported to the 32-bit
ARM ISAfor the first time and included multiple changes to the power man-
agement and hardware extensibility features of the kernel (discussed later
in this chapter). Microsoft marketed two versions of this port. One version,
calledWindowsRT,ranbothWindowsStore–packagedapplicationsandsome
Microsoft-branded “classic” applications,such as Notepad,InternetExplorer,
andmostimportantly,Office.Theotherversion,calledWindowsPhone,could
onlyrunWindowsStore–packagedapplications.
For the first time ever, Microsoft released its own branded mobile hard-
ware,underthe“Surface”brand,whichincludedtheSurfaceRT,atabletdevice
that exclusively ran the Windows RT operating system. Abit later, Microsoft
boughtNokiaandbeganreleasingMicrosoft-brandedphonesaswell,running
WindowsPhone.
Unfortunately,Windows8wasamarketfailure,forseveralreasons.Onthe
onehand,Metrofocusedonatablet-orientedinterfacethatforcedusersaccus-
tomedtoolderWindowsoperatingsystemstocompletelychangethewaythey
worked on their desktop computers. Windows 8, for example, replaced the
startmenuwithtouchscreenfeatures,replacedshortcutswithanimated“tiles,”
andofferedlittleornokeyboardinputsupport.Ontheotherhand,thedearth
ofapplicationsintheWindowsStore,whichwastheonlywaytoobtainapps
for Microsoft’s phone and tablet, led to the market failure of these devicesas
well,causingthecompanytoeventuallyphaseouttheSurfaceRTdeviceand
writeofftheNokiapurchase.
Microsoftquicklysoughttoaddressmanyoftheseissueswiththerelease
of Windows 8.1 in October 2013. This release addressed many of the usabil-
ity flaws of Windows 8 on nonmobile devices, bringing back more usability
through a traditional keyboard and mouse, and provided ways to avoid the
tile-basedMetrointerface.Italsocontinuedtoimproveonthemanysecurity,
performance,andreliabilitychangesintroducedinWindows8.Althoughthis
releasewasbetterreceived,thecontinuedlackofapplicationsintheWindows
Store was a problem for the operating system’s mobile market penetration,
while desktop and server application programmers felt abandoned due to a
lackofimprovementsintheirarea.
21.1.3 Windows 10
With the release of Windows 10 in July 2015 and its server companion,
Windows Server 2016, in October 2016, Microsoft shifted to a “Windows-824 Chapter21 Windows10
as-a-Service” (WaaS) model (with included periodic functionality improve-
ments).Windows10receivesmonthlyincrementalimprovementscalled“fea-
ture rollups,” as well as eight-month feature releases called “updates.” Addi-
tionally, each upcoming release is made available to the public through the
Windows Insider Program, or WIP, which releases versions on an almost
weeklybasis.LikecloudservicesandwebsitessuchasFacebookandGoogle,
thenewoperatingsystemuseslivetelemetry(sendingdebuginformationback
to Microsoft) and tracing to dynamically enable and disable certain features
for A/B testing (comparing how version “A” executes compared to similar
version “B”), tries out new features while watching for compatibility issues,
and aggressively adds or removes support for modern or legacy hardware.
These dynamic configuration and testing features are what make this release
an“as-a-service”implementation.
Windows10reintroducedthestartmenu,restoredkeyboardsupport,and
deemphasizedfull-screenapplicationsandlivetiles.Fromtheuser’sperspec-
tive, these changes brought back the ease of use that users expected from
Windows-based desktop operating systems. Additionally, Metro (which was
renamedModern)wasredesignedsothatWindowsStore–packagedapplica-
tionscouldberunontheregulardesktopsidebysidewithlegacyapplications.
Finally, a new mechanism called the Windows Desktop Bridge made it pos-
sibletoplaceWin32applicationsintheWindows Store,mitigatingthelackof
applicationswrittenspecificallyforthenewersystems.Meanwhile,Microsoft
added support for C++11, C++14, and C++17 in the Visual Studio product,
andmanynewAPIswereaddedtothetraditionalWin32programmingAPI.A
relatedchangeinWindows10wasthereleaseoftheUnifiedWindowsPlatform
(UWP)architecture,whichallowsapplicationstobewritteninsuchawaythat
theycanexecuteonWindowsforDesktop,WindowsforIoT,XBOXOne,Win-
dowsPhone,andWindows10MixedReality(previouslyknownasWindows
Holographic).
Windows10alsoreplacedtheconceptofmultiplesubsystems,whichhad
been removed in Windows 8 (as mentioned earlier), with a new mechanism
calledPicoProviders.Thismechanismallowsunmodifiedbinariesbelonging
toadifferentoperatingsystemtorunnativelyonWindows10.Inthe“Anniver-
saryUpdate”releasedinAugust2016,thisfunctionality was usedtoprovide
theWindowsSubsystemforLinux,whichcanbeusedtorunLinuxELFbinaries
inanentirelyunmodifiedUbuntuuser-spaceenvironment.
In response to increased competitive pressures in the mobile and cloud-
computing worlds, Microsoft also made power, performance, and scalability
improvementsinWindows10,enablingittorunonalargernumberofdevices.
In fact, a version called Windows 10 IoT Edition is specifically designed for
environments such as the Raspberry Pi, while support for cloud-computing
technologies such as containerization is built in through Docker for Win-
dows.InWindows10,theMicrosoftHyper-Vvirtualizationtechnologyisalso
built in,providingadditionalsecurityand nativesupportfor running virtual
machines.AspecialversionofWindowsServer,calledWindowsServerNano,
was also released. This extremely low-overhead server operating system is
suitedforcontainerizedapplicationsandothercloud-computingusages.
Windows 10 is a multiuser operating system, supporting simultaneous
access through distributed services or through multiple instances of the GUI21.1 History 825
via Windows Terminal Services. The server editions of Windows 10 support
simultaneous terminal server sessions from Windows desktop systems. The
desktopeditionsofterminalservermultiplexthekeyboard,mouse,andmon-
itor between virtual terminal sessions for each logged-on user. This feature,
calledfastuserswitching,allowsuserstopreempteachotherattheconsoleof
aPCwithouthavingtologoffandlogon.
Let’sreturnbrieflytodevelopmentsintheWindowsGUI.Wenotedearlier
that the GUI implementation moved into kernel mode in Windows NT 4.0 to
improveperformance.Furtherperformancegainsweremadewiththecreation
ofanewuser-modecomponentinWindowsVista,calledtheDesktopWindow
Manager(DWM).DWMprovidestheWindowsinterfacelookandfeelontopof
theWindowsDirectXgraphicsoftware.DirectXcontinuestoruninthekernel,
asdoesthecode(Win32k)implementingWindows’windowingandgraphics
model(UserandGDI).Windows7madesubstantialchangestotheDWM,sig-
nificantlyreducingitsmemoryfootprintandimprovingitsperformance,while
Windows 10 made further improvements, especially in the areas of perfor-
manceandsecurity.Furthermore,WindowsDirectX11and12includeGPGPU
mechanisms (general-purpose computing on GPU hardware) through Direct-
Compute,andmanypartsofWindowshavebeenupdatedtotakeadvantageof
thishigh-performancegraphicsmodel.Throughanewrenderinglayercalled
CoreUI, even legacy applications can now take advantage of DirectX-based
rendering(creationofthefinalscreencontents).
Windows XP was the first version of Windows to ship a 64-bit version
(for the IA64 in 2003 and the AMD64 in 2005). Internally, the native NT file
system (NTFS) and many of the Win32 APIs have always used 64-bit integers
where appropriate. The major extension to 64-bit in Windows XP was meant
assupportforlargevirtualaddresses.Inaddition,64-biteditionsofWindows
support much larger physical memory, with the latest Windows Server 2016
release supporting up to 24 TB of RAM. By the time Windows 7 shipped,
the AMD64 ISAhad become available on almost all CPUs from both Intel and
AMD.Inaddition,bythattime,physicalmemoryonclientsystemsfrequently
exceededthe4-GBlimitoftheIA-32.Asaresult,the64-bitversionofWindows
10 is now almost exclusively installed on client systems, apart from IoT and
mobile systems. Because the AMD64 architecture supports high-fidelity IA-32
compatibility at the level of individual processes, 32- and 64-bit applications
can be freely mixed in a single system. Interestingly, a similar pattern is now
emerging on mobile systems. Apple iOS is the first mobile operating system
to support the ARM64 architecture, which is the 64-bit ISA extension of ARM
(alsocalledAArch64).AfutureWindows10releasewillalsoofficiallyshipwith
an ARM64 port designed for a new class of hardware, with compatibility for
IA-32 architecture applications achieved through emulation and dynamic JIT
recompilation.
IntherestofourdescriptionofWindows10,wedonotdistinguishbetween
the client editions and the corresponding server editions. They are based on
the same core components and run the same binary files for the kernel and
mostdrivers.Similarly,althoughMicrosoftshipsavarietyofdifferenteditions
ofeachreleasetoaddressdifferentmarketpricepoints,fewofthedifferences
betweeneditionsarereflectedinthecoreofthesystem.Inthischapter,wefocus
primarilyonthecorecomponentsofWindows10.826 Chapter21 Windows10
21.2 Design Principles
Microsoft’s design goals for Windows included security, reliability, compati-
bility, high performance, extensibility, portability, and international support.
Someadditionalgoals,suchasenergyefficiencyanddynamicdevicesupport,
haverecentlybeenaddedtothislist.Next,wediscusseachofthesegoalsand
howeachisachievedinWindows10.
21.2.1 Security
Windows Vista and later security goals requiredmore than just adherence to
the design standards that had enabled Windows NT 4.0 to receive a C2 secu-
rity classification from the U.S. government. (A C2 classification signifies a
moderate level of protection from defective software and malicious attacks.
Classifications were defined by the Department of Defense Trusted Com-
puterSystemEvaluationCriteria,alsoknownastheOrangeBook.)Extensive
codereviewandtestingwerecombinedwithsophisticatedautomaticanalysis
toolstoidentifyandinvestigatepotentialdefectsthatmightrepresentsecurity
vulnerabilities. Additionally, bug bounty participation programs allow exter-
nal researchersand security professionals to identify, and submit, previously
unknown security issues in Windows. In exchange, they receive monetary
payment as well as credit in monthly security rollups, which are released by
MicrosofttokeepWindows10assecureaspossible.
Windowstraditionallybasedsecurityondiscretionaryaccesscontrols.Sys-
temobjects,includingfiles,registrykeys,andkernelsynchronization objects,
are protected by access-control lists (ACLs) (see Section 13.4.2). ACLs are vul-
nerabletouserandprogrammererrors,however,aswellastothemostcom-
mon attacks on consumer systems, in which the user is tricked into running
code,oftenwhilebrowsingtheWeb.WindowsVistaintroducedamechanism
called integrity levels that acts as a rudimentary capability system for con-
trollingaccess.Objectsandprocessesaremarkedashavingno,low,medium,
orhighsystemintegrity.Theintegrityleveldetermineswhatrightstheobjects
and processes will have. For example, Windows does not allow a process to
modifyanobjectwithahigherintegritylevel(basedonitsmandatorypolicy),
nomatterwhatthesettingoftheACL.Additionally,aprocesscannotreadthe
memoryofahigher-integrityprocess,nomattertheACL.
Windows 10 further strengthened the security model by introducing a
combination of attribute-based access control (ABAC) and claim-based access
control (CABC). Both features are used to implement dynamic access control
(DAC)onservereditions,aswellastosupportthecapability-basedsystemused
by Windows Store applications and by Modern and packaged applications.
With attributes and claims, system administrators need not rely on a user’s
name (or the group the user belongs to) as the only means that the security
system can use to filter access to objects such as files. Properties of the user
—such as, say, seniority in the organization, salary, and so on—can also be
considered.Thesepropertiesareencodedasattributes,whicharepairedwith
conditionalaccesscontrolentriesintheACL,suchas“Seniority>=10Years.”
Windowsusesencryptionaspartofcommonprotocolssuchasthoseused
tocommunicatesecurelywithwebsites.Encryptionisalsousedtoprotectuser
filesstoredonsecondarystorage.Windows7andlaterversionsallowusersto21.2 DesignPrinciples 827
easilyencryptentirevolumes,aswellasremovablestoragedevicessuchasUSB
flashdrives,withafeaturecalledBitLocker.Ifa computerwith anencrypted
volumeisstolen,thethieveswillneedverysophisticatedtechnology(suchas
an electron microscope) to gain access to any of the computer’s files, and it
willbeimpossibleforthemtodosoiftheuserhasalsoconfiguredanexternal
USB-basedtoken(unlesstheUSBtokenwasalsostolen).
These types of security features focus on user and data security, but they
are vulnerable to highly privileged programs that parse arbitrary content
and that can be tricked due to programming errors into executing malicious
code. Therefore, Windows also includes security measures often referred to
as“exploitmitigations.”Thesemeasuresincludewide-scopemitigationssuch
as address-space layout randomization (ASLR), Data Execution Prevention
(DEP),Control-FlowGuard(CFG),andArbitraryCodeGuard(ACG),aswellas
narrow-scope(targeted)mitigationsspecifictovariousexploitationtechniques
(whichareoutsidethescopeofthischapter).
Since2001,chipsfrombothIntelandAMDhaveallowedmemorypagesto
be marked so that they cannot contain executable instruction code. The Win-
dows DEPfeature marks stacks and memory heaps (as well as all other data-
only allocations) so that they cannot be used to execute code. This prevents
attacksinwhichaprogrambugallowsabuffertooverflowandthenistricked
intoexecutingthecontentsofthebuffer.Additionally,startingwithWindows
8.1,allkerneldata-onlymemoryallocationshavebeenmarkedsimilarly.
Because DEP prevents attacker-controlled data from being executed as
code, malicious developers moved on to code reuse attacks, in which exist-
ing executable code inside the program is reused in unexpected ways. (Only
certain parts of the code are executed, and the flow is redirected from one
instruction stream to another.) ASLR thwarts many forms of such attacks by
randomizingthelocationofexecutable(anddata)regionsofmemory,making
it harder for code-reuse attacks to know where existing code is located. This
safeguardmakesitlikelythatasystemunderattackbyaremoteattackerwill
failorcrash.
Nomitigationisperfect,however,andASLRisnoexception.Forexample,
itmaybeineffectiveagainstlocalattacks(inwhichsomeapplicationistricked
intoloadingcontentfromsecondarystorage,forexample),aswellasso-called
information leak attacks (in which a program is tricked into revealing part
of its address space). To address such problems, Windows 8.1 introduced a
technologycalledCFG,whichwasmuchimprovedinWindows10.CFGworks
withthecompiler,thelinker,theloader,andthememorymanagertovalidate
thedestinationaddressofanyindirectbranch(suchasacallorjump)againsta
listofvalidfunctionprologues.Ifaprogramistrickedintoredirectingcontrol
flowelsewherethroughsuchaninstruction,itcrashes.
Ifattackerscannotbringexecutabledataintoanattack,norreuseexisting
code,theymayattempttocauseaprogramtoallocate,onitsown,executable
and writeable code, which can then be filled by the attacker. Alternatively,
the attackers might modify existing writeable data and mark it as executable
data.Windows10’sACGmitigationprohibitseitheroftheseoperations.Once
executable code is loaded, it can never be modified again, and once data is
loaded,itcanneverbemarkedasexecutable.
Windows 10 has over thirty security mitigations in addition to those
describedhere.Thissetofsecurityfeatureshasmadetraditionalattacksmore828 Chapter21 Windows10
difficult, perhaps explaining in part why crimeware applications, such as
adware, credit card fraudware, and ransomware, have become so prevalent.
These types of attacks rely on users to willingly and manually cause harm
to their own computers (such as by double-clicking on applications against
warning, or inputting their credit card number in a fake banking page). No
operatingsystemcanbedesignedtomilitateagainstthegullibilityandcurios-
ityofhumanbeings.Recently,Microsofthasstartedworkingdirectlywithchip
manufacturers,suchasIntel,tobuildsecuritymitigationsdirectlyintotheISA.
One such mitigation, for example, is Control-flo Enforcement Technology
(CET), which is a hardware implementation of CFG that also protects against
return-oriented-programming(ROP)attacksbyusinghardwareshadowstacks.
Ashadowstack contains thesetofreturnaddressesasstoredwhenaroutine
is called. The addresses are checked for a mismatch before the return is exe-
cuted.Amismatchmeansthestackhasbeencompromisedandactionshould
betaken.
Another important aspect of security is integrity. Windows offers several
digitalsignaturefacilitiesaspartofitscodeintegrityfeatures.Windowsuses
digital signatures to sign operating system binaries so that it can verify that
thefileswereproducedbyMicrosoftoranotherknowncompany.Innon-IA-32
versionsofWindows,thecodeintegritymoduleisactivatedatboottoensure
that all the loadedmodulesinthe kernel have validsignatures,assuring that
theyhavenotbeentamperedwith.Additionally,ARMversionsofWindows8
extendthecodeintegritymodulewithuser-modecodeintegritychecks,which
validate that all user programs have been signed by Microsoft or delivered
through the Windows Store. A special version of Windows 10 (Windows 10
S,mostlymeantfortheeducationmarket)providessimilarsigningcheckson
allIA-32andAMD64systems.DigitalsignaturesarealsousedaspartofCode
IntegrityGuard,whichallowsapplicationstodefendthemselvesagainstload-
ing executable code from secondary storage that has not been appropriately
signed.Forexample,anattackermightreplacethird-partybinarywithhisown,
butthedigitalsignaturewouldfail,andCodeIntegrityGuardwouldnotload
thebinaryintotheprocesses’addressspace.
Finally, enterprise versions of Windows 10 make it possible to opt in to a
new security feature called Device Guard. This mechanism allows organiza-
tionstocustomizethedigitalsigningrequirementsoftheircomputersystems,
aswellasblacklistandwhitelistindividualsigningcertificatesorevenbinary
hashes. For example, an organization could choose to allow only user-mode
programssignedbyMicrosoft,Google,orAdobetolaunchontheirenterprise
computers.
21.2.2 Reliability
Windowsmaturedgreatlyasanoperatingsysteminitsfirsttenyears,leading
toWindows2000.Atthesametime,itsreliabilityincreasedduetosuchfactors
asmaturityinthesourcecode,extensivestresstestingofthesystem,improved
CPU architectures, and automatic detection of many serious errors in drivers
from both Microsoft and third parties. Windows has subsequently extended
thetoolsforachievingreliabilitytoincludeautomaticanalysisofsourcecode
forerrors,teststodetectvalidationfailures,andanapplicationversionofthe21.2 DesignPrinciples 829
driver verifier that applies dynamic checking for many common user-mode
programming errors. Other improvements in reliability have resulted from
moving more code out of the kernel and into user-mode services. Windows
providesextensivesupportforwritingdriversinusermode.Systemfacilities
thatwereonceinthekernelandarenowinusermodeincludetherendererfor
third-partyfontsandmuchofthesoftwarestackforaudio.
OneofthemostsignificantimprovementsintheWindowsexperiencecame
from adding memory diagnostics as an option at boot time. This addition is
especiallyvaluablebecausesofewconsumerPCshaveerror-correctingmem-
ory. Bad RAM that lacks error correction and detection can change the data
it stores—a change undetected by the hardware. The result is frustratingly
erraticbehaviorinthesystem.Theavailabilityofmemorydiagnosticscanwarn
usersofaRAMproblem.Windows10tookthisevenfurtherbyintroducingrun-
timememorydiagnostics.Ifamachineencountersakernel-modecrashmore
thanfivetimesinarow,andthecrashescannotbepinpointedtoaspecificcause
orcomponent,thekernelwilluseidleperiodstomovememorycontents,flush
system caches, and write repeated memory-testing patterns in all memory—
alltopreemptivelydiscoverifRAMisdamaged.Userscanthenbeinformedof
anyissueswithouttheneedtorebootintothememorydiagnosticstoolatboot
time.
Windows7alsointroducedafault-tolerantmemoryheap.Theheaplearns
fromapplicationcrashesandautomaticallyadjustsmemoryoperationscarried
outbyanapplicationthathascrashed.Thismakestheapplicationmorereliable
even if it contains common bugs such as using memory after freeing it or
accessing past the end of the allocation. Because such bugs can be exploited
byattackers,Windows7alsoincludesamitigationfordeveloperstoblockthis
featureandimmediatelycrashanyapplicationwithheapcorruption.Thisisa
verypracticalrepresentationofthedichotomythatexistsbetweentheneedsof
securityandtheneedsofuserexperience.
AchievinghighreliabilityinWindowsisparticularlychallengingbecause
almosttwobillionsystemsrunWindows.Evenreliabilityproblemsthataffect
only asmallpercentageofthesesystemsstillimpacttremendousnumbers of
users.ThecomplexityoftheWindowsecosystemalsoaddstothechallenges.
Millionsofinstancesofapplications,drivers,andothersoftwareareconstantly
being downloaded and run on Windows systems. Of course, there is also a
constant stream of malware attacks. As Windows itself has become harder to
attackdirectly,exploitsincreasinglytargetpopularapplications.
To cope with these challenges, Microsoft is increasingly relying on com-
munications from customer machines to collect data from the ecosystem.
Machines are sampled to see how they are performing, what software they
are running, and what problems they are encountering. They automatically
send data to Microsoft when their software, their drivers, or the kernel itself
crashes or hangs. Featuresare measuredto indicatehow oftenthey areused.
Legacy behavior (methods no longer recommended for use by Microsoft) is
sometimes disabled, and alerts are sent if attempts are made to use it again.
The result is that Microsoft is building an ever-improving picture of what is
happening in the Windows ecosystem that allows continuous improvements
throughsoftwareupdatesaswellasprovidingdatatoguidefuturereleasesof
Windows.830 Chapter21 Windows10
21.2.3 Windows and Application Compatibility
As mentioned, Windows XP was both an update of Windows 2000 and a
replacementforWindows95/98.Windows2000focusedprimarilyoncompat-
ibility for business applications. The requirements for Windows XP included
much higher compatibility with the consumer applications that ran on Win-
dows 95/98. Application compatibility is difficult to achieve, for several rea-
sons.Forexample,applicationsmaycheckforaspecificversionofWindows,
may depend to some extent on the quirks of the implementation of APIs, or
may have latent application bugs that were masked in the previous system.
Applications may also have been compiled for a different instruction set or
have different expectations when run on today’s multi-gigahertz, multicore
systems.Windows10continuestofocusoncompatibilityissuesbyimplement-
ingseveralstrategiestorunapplicationsdespiteincompatibilities.
Like Windows XP, Windows 10 has a compatibility layer, called the shim
engine, that sits between applications and the Win32 APIs. This engine can
make Windows 10 look (almost) bug-for-bug compatible with previous ver-
sions of Windows. Windows 10 ships with a shim database of over 6,500
entries, describing particular quirks and tweaks that must be made for older
applications. Furthermore, through the Application Compatibility Toolkit,
users and administrators can build their own shim databases. Windows 10’s
SwitchBranch mechanism allows developers to choose which Windows ver-
sion they’d like the Win32 API to emulate, including all the quirks and/or
bugsofapreviousAPI.TheTask Manager’s“OperatingSystemContext”col-
umn shows what SwitchBranch operating-system version each application is
runningunder.
Windows10,likeearlierNTreleases,maintainssupportforrunningmany
16-bit applications using a thunking, or conversion, layer—called Windows-
on-Windows-32 (WoW32)—that translates16-bit API calls intoequivalent32-
bitcalls.Similarly,the64-bitversionofWindows10providesathunkinglayer,
WoW64, that translates 32-bit API calls into native 64-bit calls. Finally, the
ARM64versionofWindows10providesadynamicJITrecompiler,translating
IA-32code,calledWoWA64.
TheoriginalWindowssubsystemmodelallowsmultipleoperating-system
personalitiestobesupported,aslongastheapplicationsarerebuiltasPortable
Executable (PE) applications with a Microsoft compiler such as Visual Stu-
dio and source code is available. As noted earlier, although the API designed
for Windows is the Win32API, some earlier editions of Windows supported a
POSIXsubsystem.POSIXisastandardspecificationforUNIXthatallowsUNIX-
compatible software to be recompiled and run without modification on any
POSIX-compatible operating system. Unfortunately, as Linux has matured, it
hasdriftedfartherandfartherawayfromPOSIXcompatibility,andmanymod-
ern Linux applications now rely on Linux-specific system calls and improve-
mentstoglibcthatarenotstandardized.Additionally,itbecomesimpractical
toaskusers(orevenenterprises)torecompilewithVisualStudioeverysingle
Linuxapplicationthatthey’dliketouse.Indeed,compilerdifferencesamong
GCC, CLang, and Microsoft’s C/C++ compiler often make doing so impossi-
ble.Therefore,eventhoughthesubsystemmodelstillexistsatanarchitectural
level,theonlysubsystemonWindowsgoingforwardwillbetheWin32subsys-
temitself,andcompatibilitywithotheroperatingsystemsisachievedthrough
anewmodelthatusesPicoProvidersinstead.21.2 DesignPrinciples 831
This significantly more powerful modelextendsthe kernelviathe ability
to forward, or proxy, every system call, exception, fault, thread creation and
termination,andprocesscreation,alongwithafewotherinternaloperations,
toasecondaryexternaldriver(thePicoProvideritself).Thissecondarydriver
nowbecomestheownerofallsuchoperations.WhilestillusingWindows10’s
scheduler and memory manager (similar to a microkernel), it can implement
its own ABI, system-call interface, executable file format parser, page fault
handling,caching,I/Omodel,securitymodel,andmore.
Windows10includesonesuchPicoProvider,calledLxCore,thatisamulti-
megabytereimplementationoftheLinuxkernel.(NotethatitisnotLinux,and
it does not share any code with Linux.) This driver is used by the “Windows
Subsystem for Linux” feature, which can be used to load unmodified Linux
ELFbinarieswithouttheneedforsourcecodeorrecompilationasPEbinaries.
Windows10userscanrunanunmodifiedUbuntuuser-modefilesystem(and,
morerecently,OpenSUSEand CentOS), servicingitwiththe apt-getpackage
management command and running packages as normal. Note that the ker-
nel reimplementation is not complete—many system calls are missing, as is
accesstomostdevices,sincenoLinuxkerneldriverscanload.Notably,while
networking is fully supported,as wellas serial devices,no GUI/frame-buffer
accessispossible.
As a final compatibility measure, Windows 8.1 and later versions also
include the Hyper-V for Client feature. This allows applications to get bug-
for-bugcompatibilitywithWindowsXP,Linux,andevenDOSbyrunningthese
operatingsystemsinsideavirtualmachine.
21.2.4 Performance
Windows was designed to provide high performance on desktop systems
(whicharelargelyconstrainedbyI/Operformance),serversystems(wherethe
CPUisoftenthebottleneck),andlargemultithreadedandmultiprocessorenvi-
ronments (where locking performance and cache-line management are keys
toscalability).Tosatisfyperformancerequirements,NTusedavarietyoftech-
niques, such as asynchronous I/O, optimized protocols for networks, kernel-
based graphics rendering, and sophisticated caching of file-system data. The
memory-managementandsynchronizationalgorithmsweredesignedwithan
awarenessoftheperformanceconsiderationsrelatedtocachelinesandmulti-
processors.
Windows NT was designed for symmetrical multiprocessing (SMP); on a
multiprocessorcomputer,severalthreadscanrunatthesametime,eveninthe
kernel.OneachCPU,WindowsNTusespriority-basedpreemptivescheduling
of threads. Except while executing in the dispatcher or at interrupt level,
threads in any process running in Windows can be preempted by higher-
prioritythreads.Thus,thesystemrespondsquickly(seeChapter5).
Windows XP further improved performance by reducing the code-path
lengthincriticalfunctionsandimplementingmorescalablelockingprotocols,
suchasqueuedspinlocksandpushlocks.(Pushlocksarelikeoptimizedspin-
lockswithread–writelockfeatures.)Thenewlockingprotocolshelpedreduce
systembuscyclesandincludedlock-freelistsandqueues,atomicread–modify
–write operations (like interlocked increment), and other advanced syn-
chronization techniques. These changes were needed because Windows XP832 Chapter21 Windows10
addedsupportforsimultaneousmultithreading(SMT),aswellasamassively
parallel pipelining technology that Intel had commercialized under the mar-
ketingnameHyperThreading.Becauseofthisnewtechnology,averagehome
machinescouldappeartohavetwoprocessors.Afewyearslater,theintroduc-
tionofmulticoresystemsmademultiprocessorsystemsthenorm.
Next,WindowsServer2003,targetedtowardlargemultiprocessorservers,
was released, using even better algorithms and making a shift toward per-
processordatastructures,locks,andcaches,aswellasusingpagecoloringand
supportingNUMAmachines. (Page coloring isaperformance optimizationto
ensure that accesses to contiguous pages in virtual memory optimize use of
the processor cache.) Windows XP 64-bit Edition was based on the Windows
Server2003kernelsothatearly64-bitadopterscouldtakeadvantageofthese
improvements.
BythetimeWindows7wasdeveloped,severalmajorchangeshadcometo
computing.ThenumberofCPUsandtheamountofphysicalmemoryavailable
inthelargestmultiprocessorshadincreasedsubstantially,soquitealotofeffort
wasputintofurtherimprovingoperating-systemscalability.
TheimplementationofmultiprocessingsupportinWindowsNTusedbit-
maskstorepresentcollectionsofprocessorsandtoidentify,forexample,which
set of processors a particular thread could be scheduled on. These bitmasks
weredefinedasfittingwithinasinglewordofmemory,limitingthenumberof
processorssupportedwithinasystemto64ona64-bitsystemand32ona32-bit
system.Thus,Windows7addedtheconceptofprocessorgroupstorepresent
acollectionofupto64processors.Multipleprocessorgroupscouldbecreated,
accommodating a total of more than 64 processors. Note that Windows calls
a schedulable portion of a processor’s execution unit a logical processor, as
distinct from a physical processor or core. When we refer to a “processor” or
“ CPU” in this chapter, we really mean a “logical processor” from Windows’s
pointofview.Windows7supporteduptofourprocessorgroups,foratotalof
256logicalprocessors,whileWindows10nowsupportsupto20groups,with
atotalofnomorethan640logicalprocessors(therefore,notallgroupscanbe
fullyfilled).
All these additional CPUs created a great deal of contention for the locks
usedforschedulingCPUsandmemory.Windows7broketheselocksapart.For
example,beforeWindows7,asinglelockwasusedbytheWindowsscheduler
to synchronize access to the queues containing threads waiting for events.In
Windows 7, each object has its own lock, allowing the queues to be accessed
concurrently. Similarly, the global object manager lock, the cache manager
VACBlock,andthememorymanagerPFNlockformerlysynchronizedaccessto
large,globaldatastructures.Allweredecomposedintomorelocksonsmaller
data structures. Also, many execution paths in the scheduler were rewritten
to be lock-free. This change resulted in improved scalability performance for
Windows7evenonsystemswith256logicalCPUs.
Other changes were due to the increasing importance of support for par-
allel computing. For years, the computer industry has been dominated by
Moore’sLaw(seeSection1.1.3),leadingtohigherdensitiesoftransistorsthat
manifest themselves as faster clock rates for each CPU. Moore’s Law contin-
ues to hold true, but limits have been reached that prevent CPU clock rates
fromincreasingfurther.Instead,transistorsarebeingusedtobuildmoreand
more CPUs into each chip. New programming models for achieving paral-21.2 DesignPrinciples 833
lel execution, such as Microsoft’s Concurrency RunTime (ConcRT) and Par-
allel Processing Library (PPL), as well as Intel’s Threading Building Blocks
(TBB),arebeingusedtoexpressparallelisminC++programs.Additionally,a
vendor-neutralstandardcalledOpenMPissupportedbyalmostallcompilers.
AlthoughMoore’sLawhasgovernedcomputingforfortyyears,itnowseems
that Amdahl’s Law, which governs parallel computing (see Section 4.2), will
rulethefuture.
Finally, power considerations have complicated design decisions around
high-performance computing—especially in mobile systems, where battery
life might trump performance needs, but also in cloud/serverenvironments,
where the cost of electricity might outweigh the need for the fastest possi-
ble computational result. Accordingly, Windows 10 now supports features
that may sometimes sacrifice raw performance for better power efficiency.
Examplesinclude CoreParking, which puts an idlesysteminto asleepstate,
and Heterogeneous Multi Processing (HMP), which allocates tasks efficiently
amongcores.
Tosupporttask-basedparallelism,theAMD64portsofWindows7andlater
versions provide a new form of user-mode scheduling (UMS). UMS allows
programs to be decomposed into tasks, and the tasks are then scheduled on
theavailableCPUsbyaschedulerthatoperatesinusermoderatherthaninthe
kernel.
The advent of multiple CPUs on the smallest computers is only part of
theshifttakingplacetoparallelcomputing.Graphicsprocessingunits(GPUs)
accelerate the computational algorithms needed for graphics by using SIMD
architecturestoexecuteasingleinstructionformultipledataatthesametime.
This has given rise to the use of GPUs for general computing, not just graph-
ics. Operating-system support for software like OpenCL and CUDA is allow-
ing programs to take advantage of the GPUs. Windows supports the use of
GPUs through software in its DirectX graphics support. This software, called
DirectCompute,allowsprogramstospecifycomputationalkernelsusingthe
“high-level shader language” programming model used by SIMD hardware.
ThecomputationalkernelsrunveryquicklyontheGPUandreturntheirresults
tothemaincomputationrunningontheCPU.InWindows10,thenativegraph-
ics stack and many new Windows applications make use of DirectCompute,
and new versions of Task Manager track GPU processor and memory usage,
with DirectX now having its own GPU thread scheduler and GPU memory
manager.
21.2.5 Extensibility
Extensibility refers to the capability of an operating system to keep up with
advances in computing technology. To facilitate change over time, the devel-
opers implemented Windows using a layered architecture. The lowest-level
kernel“executive”runsinkernelmodeandprovidesthebasicsystemservices
and abstractions that support shared use of the system. On top of the execu-
tive,severalservicesoperateinusermode.Amongthemweretheenvironment
subsystems that emulated different operating systems, which are deprecated
today.Eveninthekernel,Windowsusesalayeredarchitecture,withloadable
driversin the I/O system, so new file systems, new kindsof I/O devices,and
new kinds of networking can be added while the system is running. Drivers834 Chapter21 Windows10
environment subsystems system processes services applications
session user
csrss SCM wininit winlogon spooler svchost
manager processes
subsystem dlls
ntdll.dll
user mode
kernel mode
executive window
I/O manager
manager
security configur- plug and
file system mo ab nj ae gct er reference mp aro nc ae gs es r mp ao nw ager er ation ALPC play mm ae nm ao gr ey r graphic
cache monitor manager manager device
manager drivers
device
drivers
network kernel
drivers
hardware abstraction layer (HAL) HAL extensions
Hyper-V hypervisor
hardware
Figure21.1 Windowsblockdiagram.
aren’t limited to providing I/O functionality, however. As we’ve seen, a Pico
Provider is also a type of loadable driver (as are most anti-malware drivers).
Through Pico Providers and the modular structure of the system, additional
operatingsystemsupportcanbeaddedwithoutaffectingtheexecutive.Figure
Figure21.1showsthearchitectureoftheWindows10kernelandsubsystems.
Windowsalsousesaclient–servermodelliketheMachoperatingsystem
andsupportsdistributedprocessingthroughremoteprocedurecalls(RPCs)as
defined by the Open Software Foundation. These RPCs take advantage of an
executive component, called the advanced local procedure call (ALPC), that
implements highly scalable communication between separate processes on a
local machine. A combination of TCP/IP packets and named pipes over the
SMBprotocolisusedforcommunicationbetweenprocessesacrossanetwork.
Ontopof RPC,Windows implementstheDistributedCommonObject Model
(DCOM)infrastructure,aswellastheWindowsManagementInstrumentation
(WMI) and Windows Remote Management (WinRM) mechanism, all of which
canbeusedtorapidlyextendthesystemwithnewservicesandmanagement
capabilities.
21.2.6 Portability
AnoperatingsystemisportableifitcanbemovedfromoneCPUarchitecture
toanotherwithrelativelyfewchanges.Windowswasdesignedtobeportable.
LiketheUNIXoperatingsystem,WindowsiswrittenprimarilyinCandC++.
Thereisrelativelylittlearchitecture-specificsourcecodeandverylittleassem-21.2 DesignPrinciples 835
blycode.PortingWindowstoanewarchitecturemostlyaffectstheWindows
kernel, since the user-mode code in Windows is almost exclusively written
to be architecture independent. To port Windows, the kernel’s architecture-
specificcodemustberewrittenforthetargetCPU,andsometimesconditional
compilationisneededinotherpartsofthekernelbecauseofchangesinmajor
data structures, such as the page-table format. The entire Windows system
mustthenberecompiledforthenewCPUinstructionset.
OperatingsystemsaresensitivenotonlytoCPUarchitecturebutalsotoCPU
support chips and hardware boot programs. The CPU and support chips are
collectivelyknownasthechipset.Thesechipsetsandtheassociatedbootcode
determinehowinterruptsaredelivered,describethephysicalcharacteristicsof
eachsystem,andprovideinterfacestodeeperaspectsoftheCPUarchitecture,
such as error recovery and power management. It would be burdensome to
have to port Windows to each type of support chip as well as to each CPU
architecture.Instead,Windowsisolatesmostofthechipset-dependentcodein
adynamiclinklibrary(DLL),calledthehardware-abstractionlayer(HAL),that
isloadedwiththekernel.
The Windows kernel depends on the HAL interfaces rather than on the
underlying chipset details. This allows the single set of a kernel and driver
binariesforaparticularCPUtobeusedwithdifferentchipsetssimplybyload-
ingadifferentversionoftheHAL.Originally,tosupportthemanyarchitectures
that Windows ran on, and the many computer companies and designs in the
market, over 450 different HALs existed. Over time, the advent of standards
such as the AdvancedConfiguration and Power Interface (ACPI), the increas-
ingsimilarityofcomponentsavailableinthemarketplace,andthemergingof
computermanufacturersledtochanges;today,theAMD64portofWindows10
comeswithasingleHAL.Interestingly,though,nosuchdevelopmentshaveyet
occurredinthemarketformobiledevices.Today,Windowssupportsalimited
numberofARMchipsets—andmusthavetheappropriateHALcodeforeachof
them.ToavoidgoingbacktoamodelofmultipleHALs,Windows8introduced
theconceptofHALExtensions,whichareDLLsthatareloadeddynamicallyby
theHALbasedonthedetectedSoC(systemonachip)components,suchasthe
interruptcontroller,timermanager,andDMAcontroller.
Over the years, Windows has been ported to a number of different CPU
architectures:IntelIA-32-compatible32-bitCPUs,AMD64-compatibleandIA64
64-bit CPUs, and DEC Alpha, DEC Alpha AXP64, MIPS, and PowerPC CPUs.
MostoftheseCPUarchitecturesfailedintheconsumerdesktopmarket.When
Windows 7shipped,only theIA-32 and AMD64 architectureswere supported
on client computers, along with AMD64 on servers. With Windows 8, 32-bit
ARMwasadded,andWindows10nowsupportsARM64aswell.
21.2.7 International Support
Windows was designed for international and multinational use. It provides
support for different locales via the national-language-support (NLS) API.
The NLS API provides specialized routines to format dates, time, and money
in accordance with national customs. String comparisons are specialized to
account for varying character sets. UNICODE is Windows’s native character
code, specifically in its UTL-16LE encoding format (which is different from836 Chapter21 Windows10
Linux’s and the Web’s standard UTF-8). Windows supports ANSI characters
by converting them to UNICODE characters before manipulating them (8-bit
to16-bitconversion).
System text strings are kept in resource tables inside files that can be
replacedtolocalizethesystemfordifferentlanguages.BeforeWindowsVista,
Microsoft shipped these resource tables inside the DLLs themselves, which
meant that different executable binaries existed for each different version of
Windowsandonlyonelanguagewasavailableatasingletime.WithWindows
Vista’s multiple user interface (MUI) support, multiple locales can be used
concurrently, which is important to multilingual individuals and businesses.
Thiswasachievedbymovingalloftheresourcetablesintoseparate.muifiles
that live in the appropriate language directory alongside the .dll file, with
supportintheloadertopicktheappropriatefilebasedonthecurrentlyselected
language.
21.2.8 Energy Efficiency
Increasing energy efficiency causes batteries to last longer for laptops and
Internet-onlynetbooks,savessignificantoperatingcostsforpowerandcooling
ofdatacenters,andcontributes togreeninitiativesaimedatlowering energy
consumption by businesses and consumers. For some time, Windows has
implementedseveralstrategiesfordecreasingenergyuse.TheCPUsaremoved
tolowerpowerstates—forexample,byloweringclockfrequency—whenever
possible. In addition, when a computer is not being actively used, Windows
mayputtheentirecomputerintoalow-powerstate(sleep)ormayevensaveall
ofmemorytosecondarystorageandshutthecomputeroff(hibernation).When
theuserreturns,thecomputerpowersupandcontinuesfromitspreviousstate,
sotheuserdoesnotneedtorebootandrestartapplications.
ThelongeraCPUcanstayunused,themoreenergycanbesaved.Because
computersaresomuchfasterthanhumanbeings,alotofenergycanbesaved
justwhilehumansarethinking.Theproblemisthatmanyprogramsarepolled
to wait for activity, and software timers are frequently expiring, keeping the
CPUfromstayingidlelongenoughtosavemuchenergy.
Windows7extendsCPUidletimebydeliveringclock-tickinterruptsonly
tologicalCPU0andallothercurrentlyactiveCPUs(skippingidleones)andby
coalescing eligiblesoftware timersintosmallernumbers ofevents.Onserver
systems, it also “parks” entire CPUs when systems are not heavily loaded.
Additionally,timerexpirationisnotdistributed,andasingleCPUistypically
in charge of handling all software timer expirations. A thread that was run-
ning on, say, logical CPU 3 does not cause CPU 3 to wake up and service this
expirationifitiscurrentlyidlewhenanother,nonsleepingCPUcouldhandleit
instead.
While these measures helped, they were not enough to increase battery
life in mobile systems such as phones, which have a fraction of the battery
capacityoflaptops.Windows8thusintroducedanumberoffeaturestofurther
optimizebatterylife.First,theWinRTprogrammingmodeldoesnotallowfor
precisetimerswithaguaranteedexpirationtime.Alltimersregisteredthrough
the new API are candidates for coalescing, unlike Win32 timers,which had to
bemanuallyoptedin.Next,theconceptofadynamictickwasintroduced,in21.2 DesignPrinciples 837
whichCPU0isnolongertheclockowner,andthelast-activeCPUtakesonthis
responsibility.
More significantly, the entire Metro/Modern/UWP application model
deliveredthroughtheWindowsStoreincludesafeature,theProcessLifetime
Manager (PLM), that automatically suspends all of the threads in a process
that has been idle for more than a few seconds. This not only mitigates the
constant polling behavior of many applications, but also removes the ability
forUWPapplicationstodotheirownbackgroundwork(suchasqueryingthe
GPS location), forcing them to deal with a system of brokers that efficiently
coalesce audio, location, download, and other requests and can cache data
whiletheprocessissuspended.
Finally, using a new component called the Desktop Activity Moderator
(DAM), Windows 8 and later versions support a new type of system state
calledConnectedStandby.Imagineputtingacomputertosleep—thisaction
takes several seconds, after which everything on the computer appears to
disappear,withallthehardwareturningoff.Pressingabuttononthekeyboard
wakesupthecomputer,whichtakesafewadditionalseconds,andeverything
resumes. On a phone or tablet, however, putting the device to sleep is not
expected to take seconds—users want their screen to turn off immediately.
But if Windows merely turned off the screen, all programs would continue
running, and legacy Win32 applications, lacking a PLM and timer coalescing,
wouldcontinuetopoll,perhapsevenwakingupthescreenagain.Batterylife
woulddrainsignificantly.
ConnectedStandbyaddressesthisproblembyvirtuallyfreezingthecom-
puterwhenthepowerbuttonispressedorthescreenturnsoff—withoutreally
puttingthecomputertosleep.Thehardwareclockisstopped,allprocessesand
servicesaresuspended,andalltimerexpirationsaredelayed30minutes.The
net effect, even though the computer is still running, is that it runs in such a
almost-totalstateofidlenessthattheprocessorandperipheralscaneffectively
run in their lowest power state. Special hardware and firmware are required
tofullysupportthismode;forexample,theSurface-brandedtablethardware
includesthiscapability.
21.2.9 Dynamic Device Support
Early in the history of the PC industry, computer configurations were fairly
static, although new devices might occasionally be plugged into the serial,
printer, or game ports on the back of a computer. The next steps toward
dynamicconfigurationofPCswerelaptopdocksandPCMCIAcards.Usingsuch
a device, a PC could quickly be connected to or disconnected from a full set
of peripherals. Contemporary PCs are designed to enable users to plug and
unplugahugehostofperipheralsfrequently.
Support for dynamic configuration of devices is continually evolving in
Windows. The system can automatically recognize devices when they are
pluggedinandcanfind,install,andloadtheappropriatedrivers—oftenwith-
outuserintervention.Whendevicesareunplugged,thedriversautomatically
unload, and system execution continues without disrupting other software.
Additionally, Windows Update permits downloading of third-party drivers838 Chapter21 Windows10
directlythroughMicrosoft,avoidingtheusageofinstallationDVDsorhaving
theuserscourthemanufacturer’swebsite.
Beyondperipherals,WindowsServeralsosupportsdynamichot-addand
hot-replace of CPUs and RAM, as well as dynamic hot-remove of RAM. These
features allow the components to be added, replaced, or removed without
systeminterruption.While oflimiteduseinphysical servers,thistechnology
iskeytodynamicscalabilityincloudcomputing,especiallyinInfrastructure-
as-a-Service (IaaS) and cloud computing environments. In these scenarios,
a physical machine can be configured to support a limited number of its
processors based on a service fee, which can then be dynamically upgraded,
withoutrequiringareboot,throughacompatiblehypervisorsuchasHyper-V
andasimplesliderintheowner’suserinterface.
21.3 System Components
The architecture of Windows is a layered system of modules operating at
specific privilege levels, as shown earlier in Figure 21.1. By default, these
privilegelevelsarefirstimplementedbytheprocessor(providinga“vertical”
privilegeisolationbetweenusermodeandkernelmode).Windows10canalso
use its Hyper-V hypervisor to provide an orthogonal (logically independent)
security model through Virtual Trust Levels (VTLs). When users enable this
feature, the system operates in a Virtual Secure Mode (VSM). In this mode,
the layered privileged system now has two implementations, one called the
Normal World, or VTL 0, and one called the Secure World, or VTL 1. Within
eachoftheseworlds,wefindausermodeandakernelmode.
Let’slookatthisstructureinsomewhatmoredetail.
• IntheNormalWorld,inkernelmodeare(1)theHALanditsextensionsand
(2)thekernelanditsexecutive,whichloaddriversandDLLdependencies.
Inusermodeareacollectionofsystemprocesses,theWin32environment
subsystem,andvariousservices.
• In the Secure World, if VSM is enabled, are a secure kernel and executive
(withinwhichasecuremicro-HALisembedded).Acollectionofisolated
Trustlets(discussedlater)runinsecureusermode.
• Finally,thebottommostlayerinSecureWorldrunsinaspecialprocessor
mode (called, for example, VMX Root Mode on Intel processors), which
containstheHyper-Vhypervisorcomponent,whichuseshardwarevirtu-
alizationtoconstructtheNormal-to-Secure-Worldboundary.(Theuser-to-
kernelboundaryisprovidedbytheCPUnatively.)
Oneofthechiefadvantagesofthistypeofarchitectureisthatinteractions
betweenmodules,andbetweenprivilegelevels,arekeptsimple,andthatiso-
lationneedsandsecurityneedsarenotnecessarilyconflatedthroughprivilege.
Forexample,asecure,protectedcomponentthatstorespasswordscanitselfbe
unprivileged.In the past, operating-system designerschose to meet isolation
needsbymakingthesecurecomponenthighlyprivileged,butthisresultsina
netlossforthesecurityofthesystemwhenthiscomponentiscompromised.
Theremainderofthissectiondescribestheselayersandsubsystems.21.3 SystemComponents 839
21.3.1 Hyper-V Hypervisor
ThehypervisoristhefirstcomponentinitializedonasystemwithVSMenabled,
which happens as soon as the user enables the Hyper-V component. It is
used both to provide hardware virtualization features for running separate
virtual machines and to provide the VTL boundary and related access to the
hardware’sSecondLevelAddressTranslation(SLAT)functionality (discussed
shortly). The hypervisor uses a CPU-specific virtualization extension, such as
AMD’sPacifica(SVMX)orIntel’sVanderpool(VT-x),tointerceptanyinterrupt,
exception, memory access, instruction, port, or register access that it chooses
anddeny,modify,orredirecttheeffect,source,ordestinationoftheoperation.
It also provides a hypercall interface, which enables it to communicate with
the kernel in VTL 0, the secure kernel in VTL 1, and all other running virtual
machinekernelsandsecurekernels.
21.3.2 Secure Kernel
Thesecurekernelactsasthekernel-modeenvironmentofisolated(VTL1)user-
modeTrustletapplications(applicationsthatimplementpartsoftheWindows
securitymodel).Itprovidesthesamesystem-callinterfacethatthekerneldoes,
so that all interrupts, exceptions, and attempts to enter kernel mode from a
VTL1Trustletresultinenteringthesecurekernelinstead.However,thesecure
kernelisnotinvolvedincontextswitching,threadscheduling,memoryman-
agement, interprocess-communication, or any of the other standard kernel
tasks.Additionally,nokernel-modedriversarepresentinVTL1.Inanattempt
to reduce the attack surface of the Secure World, these complex implementa-
tionsremaintheresponsibilityofNormalWorldcomponents.Thus,thesecure
kernel acts as a type of “proxy kernel” that hands off the management of its
resources,paging,scheduling,andmore,totheregularkernelservicesinVTL
0.ThisdoesmaketheSecureWorldvulnerabletodenial-of-serviceattacks,but
thatisareasonabletradeoffofthesecuritydesign,whichvaluesdataprivacy
andintegrityoverserviceguarantees.
Inadditiontoforwardingsystemcalls,thesecurekernel’sotherresponsi-
bilityisprovidingaccesstothehardwaresecrets,thetrustedplatformmodule
(TPM), and code integritypoliciesthat werecapturedat boot. With this infor-
mation, Trustlets can encrypt and decrypt data with keys that the Normal
World cannot obtain and can sign and attest (co-sign by Microsoft) reports
with integrity tokens that cannot be faked or replicatedoutside of the Secure
World. Using a CPU feature called Second Level Address Translation (SLAT),
thesecurekernelalsoprovidestheabilitytoallocatevirtualmemoryinsucha
way that the physical pages backing it cannot be seenat all from the Normal
World.Windows10usesthesecapabilitiestoprovideadditionalprotectionof
enterprisecredentialsthroughafeaturecalledCredentialGuard.
Furthermore,whenDeviceGuard(mentionedearlier)isactivated,ittakes
advantage of VTL1 capabilities by moving all digital signature checking into
thesecurekernel.Thismeansthatevenifattackedthroughasoftwarevulner-
ability,thenormalkernelcannotbeforcedtoloadunsigneddrivers,astheVTL
1boundarywouldhavetobebreachedforthattooccur.OnaDeviceGuard–
protectedsystem,forakernel-modepageinVTL0tobeauthorizedforexecu-
tion,thekernelmustfirstaskpermissionfromthesecurekernel,andonlythe
securekernelcangrantthispageexecutableaccess.Moresecuredeployments840 Chapter21 Windows10
(suchasinembeddedorhigh-risksystems)canrequirethislevelofsignature
validationforuser-modepagesaswell.
Additionally, work is being done to allow special classes of hardware
devices,suchasUSBwebcamsandsmartcardreaders,tobedirectlymanaged
byuser-modedriversrunninginVTL1(usingtheUMDFframeworkdescribed
later), allowing biometric data to be securely captured in VTL 1 without any
componentintheNormalWorldbeingabletointerceptit.Currently,theonly
TrustletsallowedarethosethatprovidetheMicrosoft-signedimplementation
of Credential Guard and virtual-TPM support. Newer versions of Windows
10 will also support VSM Enclaves, which will allow validly signed (but not
necessarily Microsoft-signed) third-party code wishing to perform its own
cryptographiccalculations todoso. Softwareenclaveswill allowregularVTL
0applicationsto“callinto”anenclave,whichwillrunexecutablecodeontop
ofinputdataandreturnpresumablyencryptedoutputdata.
Formoreinformationonthesecurekernel,seehttps://blogs.technet.micro
soft.com/ash/2016/03/02/windows-10-device-guard-and-credential-guard-d
emystified/.
21.3.3 Hardware-Abstraction Layer
The HAL is the layer of software that hides hardware chipset differences
from upper levels of the operating system. The HAL exports a virtual hard-
ware interface that is used by the kernel dispatcher, the executive, and the
device drivers. Only a single version of each device driver is required for
eachCPUarchitecture,nomatterwhatsupportchipsmightbepresent.Device
drivers map devices and access them directly, but the chipset-specific details
ofmappingmemory,configuringI/Obuses,settingupDMA,andcopingwith
motherboard-specificfacilitiesareallprovidedbytheHALinterfaces.
21.3.4 Kernel
The kernel layer of Windows has the following main responsibilities: thread
schedulingandcontextswitching,low-levelprocessorsynchronization,inter-
rupt and exception handling, and switching between user mode and kernel
mode through the system-call interface. Additionally, the kernel layer imple-
mentstheinitialcodethattakesoverfromthebootloader,formalizingthetran-
sitionintotheWindows operatingsystem.Italsoimplementsthe initialcode
thatsafelycrashesthekernelincaseofanunexpectedexception,assertion,or
otherinconsistency.ThekernelismostlyimplementedintheClanguage,using
assemblylanguageonlywhenabsolutelynecessarytointerfacewiththelowest
levelofthehardwarearchitectureandwhendirectregisteraccessisneeded.
21.3.4.1 Dispatcher
Thedispatcherprovidesthefoundationfortheexecutiveandthesubsystems.
Most of the dispatcher is never paged out of memory, and its execution is
never preempted.Its main responsibilitiesare thread scheduling and context
switching,implementationofsynchronizationprimitives,timermanagement,
softwareinterrupts(asynchronousanddeferredprocedurecalls),interproces-
sorinterrupts(IPIs)andexceptiondispatching.Italsomanageshardwareand21.3 SystemComponents 841
softwareinterruptprioritizationunderthesystemofinterruptrequestlevels
(IRQLs).
21.3.4.2 SwitchingBetweenUser-ModeandKernel-ModeThreads
WhattheprogrammerthinksofasathreadintraditionalWindowsisactually
athreadwithtwomodesofexecution:auser-modethread(UT)andakernel-
mode thread (KT). The thread has two stacks, one for UT execution and the
other for KT. AUT requests a system service by executing an instruction that
causesatraptokernelmode.Thekernellayerrunsatraphandlerthatswitches
UT stack to its KT sister and changes CPU mode to kernel. When thread in KT
mode has completed its kernel execution and is ready to switch back to the
correspondingUT,thekernellayeriscalledtomaketheswitchtotheUT,which
continues its execution in user mode. The KT switch also happens when an
interruptoccurs.
Windows 7 modifies the behavior of the kernel layer to support user-
mode scheduling of the UTs. User-mode schedulers in Windows 7 support
cooperative scheduling. A UT can explicitly yield to another UT by calling
the user-mode scheduler; it is not necessary to enter the kernel. User-mode
schedulingisexplainedinmoredetailinSection21.7.3.7.
InWindows,thedispatcherisnotaseparatethreadrunninginthekernel.
Rather,thedispatchercodeisexecutedbytheKTcomponentofaUTthread.A
threadgoesintokernelmodeinthesamecircumstancesthat,inotheroperating
systems, cause a kernel thread to be called. These same circumstances will
cause the KT to run through the dispatcher code after its other operations,
determiningwhichthreadtorunnextonthecurrentcore.
21.3.4.3 Threads
Likemanyothermodernoperatingsystems,Windowsusesthreadsasthekey
schedulable unit of executable code, with processes serving as containers of
threads.Therefore,eachprocessmusthaveatleastonethread,andeachthread
has its own scheduling state,including actual priority,processor affinity, and
CPUusageinformation.
There are eight possible thread states: initializing, ready, deferred-
ready, standby, running, waiting, transition, and terminated. ready
indicatesthatthethreadiswaitingtoexecute,whiledeferred-readyindicates
thatthethreadhasbeenselectedtorunonaspecificprocessorbuthasnotyet
beenscheduled.Athreadisrunningwhenitisexecutingonaprocessorcore.It
runsuntilitispreemptedbyahigher-prioritythread,untilitterminates,until
its allotted execution time (quantum) ends, or until it waits on a dispatcher
object, such as an event signaling I/O completion. If a thread is preempting
another thread on a different processor, it is placed in the standby state on
thatprocessor,whichmeansitisthenextthreadtorun.
Preemptionisinstantaneous—thecurrentthreaddoesnotgetachanceto
finish its quantum. Therefore, the processor sends a software interrupt—in
this case, a deferred procedure call (DPC)—to signal to the other processor
thatathreadisinthestandbystateandshouldbeimmediatelypickedupfor
execution.Interestingly,athreadinthestandbystatecanitselfbepreempted
if yet another processor finds an even higher-priority thread to run in this
processor. At that point, the new higher-priority thread will go to standby,842 Chapter21 Windows10
andthepreviousthreadwillgotothereadystate.Athreadisinthewaiting
state when it is waiting for a dispatcher object to be signaled. Athread is in
thetransitionstatewhileitwaitsfor resourcesnecessaryforexecution;for
example,itmaybewaitingforitskernelstacktobepagedinfromsecondary
storage.Athreadenterstheterminatedstatewhenitfinishesexecution,anda
threadbeginsintheinitializingstateasitisbeingcreated,beforebecoming
readyforthefirsttime.
The dispatcher uses a 32-level priority scheme to determine the order of
thread execution. Priorities are divided into two classes: variable class and
staticclass. The variableclass contains threadshaving prioritiesfrom 1to15,
andthestaticclasscontainsthreadswithprioritiesrangingfrom16to31.The
dispatcherusesalinkedlistforeachschedulingpriority;thissetoflistsiscalled
thedispatcherdatabase.Thedatabaseusesabitmaptoindicatethepresence
ofatleastoneentryinthelistassociatedwiththepriorityofthebit’sposition.
Therefore,insteadof having totraversethe setof lists from highest tolowest
until it finds a thread that is ready to run, the dispatcher can simply find the
listassociatedwiththehighestbitset.
Prior to Windows Server 2003, the dispatcher database was global,
resulting in heavy contention on large CPU systems. In Windows Server2003
and later versions, the global database was broken apart into per-processor
databases, with per-processor locks. With this new model, a thread will only
be in the database of its ideal processor. It is thus guaranteed to have a
processoraffinity that includesthe processoronwhose databaseitis located.
Thedispatchercannowsimplypickthefirstthreadinthelistassociatedwith
the highest bit set and does not have to acquire a global lock. Dispatching
is therefore a constant-time operation, parallelizable across all CPUs on the
machine.
On a single-processor system, if no ready thread is found, the dispatcher
executes a special thread called the idle thread, whose role is to begin the
transitiontooneoftheCPU’sinitialsleepstates.Priorityclass0isreservedfor
theidlethread.Onamultiprocessorsystem,beforeexecutingtheidlethread,
the dispatcher looks at the dispatcher databases of other nearby processors,
taking caching topologies and NUMAnode distances into consideration. This
operationrequiresacquiringthelocksofotherprocessorcoresinordertosafely
inspecttheirlists.Ifnothreadcanbestolenfromanearbycore,thedispatcher
looksatthenextnearestcore,andsoon.Ifnothreadscanbestolenatall,then
the processorexecutesthe idlethread.Therefore,inamultiprocessorsystem,
eachCPUwillhaveitsownidlethread.
Puttingeachthreadononlythedispatcherdatabaseofitsidealprocessor
causes alocality problem.Imagine aCPUexecutingathreadat priority2ina
CPU-bound way, while another CPU is executing a thread at priority 18, also
CPU-bound.Then,athreadatpriority17becomesready.Iftheidealprocessor
ofthisthreadisthefirstCPU,thethreadpreemptsthecurrentrunningthread.
ButiftheidealprocessoristhelatterCPU,itgoesintothereadyqueueinstead,
waiting for its turn to run (which won’t happen until the priority 17 thread
givesuptheCPUbyterminatingorenteringawaitstate).
Windows7introducedaload-balanceralgorithmtoaddressthissituation,
butitwasaheavy-handedanddisruptiveapproachtothelocalityissue.Win-
dows8andlaterversionssolvedtheprobleminamorenuancedway.Instead
ofaglobaldatabaseasinWindowsXPandearlierversions,oraper-processor21.3 SystemComponents 843
database as in Windows Server 2003 and later versions, the newer Windows
versions combine these approaches to form a shared ready queue among a
group of some, but not all, processors. The number of CPUs that form one
shared group depends on the topology of the system, as well as on whether
it is a server or client system. The number is chosen to keep contention low
onverylargeprocessorsystems,whileavoidinglocality(andthuslatencyand
contention)issuesonsmallerclientsystems.Additionally,processoraffinities
are still respected, so that a processor in a given group is guaranteed that all
threads in the shared ready queue are appropriate—it never needs to “skip”
overathread,keepingthealgorithmconstanttime.
Windowshasatimerexpireevery15millisecondstocreateaclock“tick”to
examinesystemstates,updatethetime,anddootherhousekeeping.Thattick
isreceivedbythethreadoneverynon-idlecore.Theinterrupthandler(being
run by the thread, now in KT mode) determines if the thread’s quantum has
expired. When a thread’s time quantum runs out, the clock interrupt queues
a quantum-end DPC to the processor. Queuing the DPC results in a software
interruptwhentheprocessorreturnstonormalinterruptpriority.Thesoftware
interruptcausesthethreadtorundispatchercodeinKTmodetoreschedulethe
processortoexecutethenextreadythreadatthepreemptedthread’spriority
levelinaround-robinfashion.Ifnootherthreadatthislevelisready,alower-
priority ready thread is not chosen, because a higher-priority ready thread
already exists—the one that exhausted its quantum in the first place. In this
situation, the quantum is simply restored to its default value, and the same
threadexecutesonceagain.Therefore,Windowsalwaysexecutesthehighest-
priorityreadythread.
When a variable-priority thread is awakened from a wait operation, the
dispatchermayboostitspriority.Theamountoftheboostdependsonthetype
of wait associated with the thread. If the wait was due to I/O, then the boost
dependsonthedeviceforwhichthethreadwaswaiting.Forexample,athread
waiting for sound I/O would get a large priority increase, whereas a thread
waitingforadiskoperationwouldgetamoderateone.Thisstrategyenables
I/O-bound threads to keep the I/O devices busy while permitting compute-
boundthreadstousespareCPUcyclesinthebackground.
Anothertypeofboostisappliedtothreadswaitingonmutex,semaphore,
or event synchronization objects. This boost is usually a hard-coded value
of one priority level, although kernel drivers have the option of making a
different change. (For example, the kernel-mode GUI code applies a boost of
twoprioritylevelstoallGUIthreadswakinguptoprocesswindowmessages.)
This strategy is used to reduce the latency between when a lock or other
notification mechanism is signaledand when the next waiter in lineexecutes
inresponsetothestatechange.
In addition, the thread associated with the user’s active GUI window
receives a priority boost of two whenever it wakes up for any reason, on top
ofany other existingboost, toenhance itsresponsetime.Thisstrategy,called
theforegroundpriorityseparationboost,tendstogivegoodresponsetimesto
interactivethreads.
Finally,WindowsServer2003addedalock-handoffboostforcertainclasses
oflocks,suchascriticalsections.Thisboostissimilartothemutex,semaphore,
andeventboost,exceptthatittracksownership.Insteadofboostingthewaking
thread by a hard-coded value of one priority level, it boosts to one priority844 Chapter21 Windows10
levelabovethatofthecurrentowner(theonereleasingthelock).Thishelpsin
situationswhere,forexample,athreadatpriority12isreleasingamutex,but
thewaitingthreadisatpriority8.Ifthewaitingthreadreceivesaboostonlyto
9, itwill not be able topreemptthereleasingthread.Butifitreceivesaboost
to13,itcanpreemptandinstantlyacquirethecriticalsection.
Becausethreadsmayrunwithboostedprioritieswhentheywakeupfrom
waits,thepriorityofathreadisloweredattheendofeveryquantumaslong
as the thread is above its base (initial) priority. This is done according to the
followingrule:ForI/Othreadsandthreadsboostedduetowakingupbecause
of an event, mutex, or semaphore, one priority level is lost at quantum end.
For threads boosted due to the lock-handoff boost or the foreground priority
separationboost,theentirevalueoftheboostislost.Threadsthathavereceived
boosts of both types will obey both of these rules (losing one level of the
first boost, as wellas the entiretyof the second boost). Lowering the thread’s
prioritymakessurethattheboostisappliedonlyforlatencyreductionandfor
keepingI/Odevicesbusy,nottogiveundueexecutionpreferencetocompute-
boundthreads.
21.3.4.4 ThreadScheduling
Scheduling occurs when a thread enters the ready or waiting state, when a
threadterminates,orwhenanapplicationchangesathread’sprocessoraffinity.
As we have seen throughout the text, a thread could become ready at any
time.Ifahigher-prioritythreadbecomesreadywhilealower-prioritythreadis
running,thelower-prioritythreadispreemptedimmediately.Thispreemption
givesthehigher-prioritythreadinstantaccesstotheCPU,withoutwaitingon
thelower-prioritythread’squantumtocomplete.
Itisthelower-prioritythreaditself,performingsomeeventthatcausedit
to operate in the dispatcher, that wakes up the waiting thread and immedi-
ately context-switches to it while placing itself back in the ready state. This
modelessentiallydistributestheschedulinglogicthroughoutdozensofWin-
dows kernel functions and makes each currently running thread behave as
theschedulingentity.Incontrast,otheroperatingsystemsrelyonanexternal
“scheduler thread”triggeredperiodically based on a timer. The advantage of
theWindows approachislatency reduction,withthe cost ofaddedoverhead
insideeveryI/Oandotherstate-changingoperation,whichcausesthecurrent
threadtoperformschedulerwork.
Windows is not a hard-real-time operating system, however, because it
doesnotguaranteethatanythread,eventhehighest-priorityone,willstartto
executewithinaparticulartimelimitorhaveaguaranteedperiodofexecution.
Threads are blocked indefinitely while DPCs and interrupt service routines
(ISRs)arerunning(asfurtherdiscussedbelow),andtheycanbepreemptedat
anytimebyahigher-prioritythreadorbeforcedtoround-robinwithanother
threadofequalpriorityatquantumend.
Traditionally, the Windows scheduler uses sampling to measure CPU uti-
lization by threads. The system timer fires periodically, and the timer inter-
rupthandler takesnote ofwhat threadis currentlyscheduledand whether it
is executing in user or kernel mode when the interrupt occurred. This sam-
pling technique originally came about because either the CPU did not have a
high-resolution clock or the clock was too expensive or unreliable to access21.3 SystemComponents 845
frequently. Although efficient, sampling is inaccurate and leads to anomalies
such as charging the entire duration of the clock (15 milliseconds)to the cur-
rentlyrunningthread(orDPCorISR).Therefore,thesystemendsupcompletely
ignoring some number of milliseconds—say, 14.999—that could have been
spent idle, running other threads, running other DPCs and ISRs, or a combi-
nation of all of these operations. Additionally, because quantum is measured
basedonclockticks,thiscausestheprematureround-robinselectionofanew
thread,eventhoughthecurrentthreadmayhaverunforonlyafractionofthe
quantum.
Starting with Windows Vista, execution time is also tracked using the
hardware timestamp counter (TSC) included in all processors since the Pen-
tiumPro.UsingtheTSCresultsinmoreaccurateaccountingofCPUusage(for
applications that use it—note that Task Manager does not) and also causes
the scheduler not to switch out threads before they have run for a full quan-
tum. Additionally, Windows 7 and later versions track, and charge, the TSC
to ISRsand DPCs, resulting in more accurate “Interrupt Time” measurements
as well (again, for tools that use this new measurement).Becauseall possible
executiontimeisnowaccountedfor,itispossibletoaddittoidletime(which
is also tracked using the TSC) and accurately compute the exact number of
CPU cycles out of all possible CPU cycles in a given period (due to the fact
that modern processors have dynamically shifting frequencies), resulting in
cycle-accurateCPUusagemeasurements.ToolssuchasMicrosoft’sSysInternals
ProcessExplorerusethismechanismintheiruserinterface.
21.3.4.5 ImplementationofSynchronizationPrimitives
Windows uses a number of dispatcher objects to control dispatching and
synchronizationinthesystem.Examplesoftheseobjectsincludethefollowing:
• The event is used to record an event occurrence and to synchronize this
occurrencewithsomeaction.Notificationeventssignalallwaitingthreads,
andsynchronizationeventssignalasinglewaitingthread.
• The mutex provideskernel-mode or user-mode mutual exclusion associ-
atedwiththenotionofownership.
• Thesemaphoreactsasacounterorgatetocontrolthenumberofthreads
thataccessaresource.
• The thread is the entity that is scheduled by the kernel dispatcher. It is
associatedwithaprocess,whichencapsulatesavirtualaddressspace,list
ofopenresources,andmore.Thethreadissignaledwhenthethreadexits,
andtheprocess,whentheprocessexits(thatis,whenallofitsthreadshave
exited).
• The timer is used to keep track of time and to signal timeouts when
operations take too long and need to be interrupted or when a periodic
activity needs to be scheduled. Just like events, timers can operate in
notificationmode(signalall)orsynchronizationmode(signalone).
All of the dispatcher objects can be accessed from user mode via an open
operation that returns a handle. The user-mode code waits on handles to846 Chapter21 Windows10
synchronize with other threads as well as with the operating system (see
Section21.7.1).
21.3.4.6 InterruptRequestLevels(IRQLs)
Both hardware and software interrupts are prioritized and are serviced in
priorityorder.Thereare16interruptrequestlevels(IRQLs)onallWindowsISAs
except the legacy IA-32, which uses 32. The lowest level, IRQL0, is called the
PASSIVE LEVELandisthedefaultlevelatwhichallthreadsexecute,whetherin
kernelorusermode.ThenextlevelsarethesoftwareinterruptlevelsforAPCs
and DPCs. Levels 3 to 10 are used to represent hardware interrupts based on
selectionsmadebythePnPmanagerwiththehelpoftheHALandthePCI/ACPI
bus drivers.Finally, the uppermost levelsare reservedfor the clock interrupt
(usedforquantummanagement)andIPIdelivery.Thelastlevel,HIGH LEVEL,
blocksallmaskableinterruptsandistypicallyusedwhencrashingthesystem
inacontrolledmanner.
TheWindowsIRQLsaredefinedinFigure21.2.
21.3.4.7 SoftwareInterrupts:AsynchronousandDeferredProcedureCalls
The dispatcher implements two types of software interrupts: asynchronous
procedurecalls(APCs)anddeferredprocedurecalls(DPCs,mentionedearlier).
APCsareusedtosuspendorresumeexistingthreads,terminatethreads,deliver
notifications that an asynchronous I/O has completed, and extract or modify
thecontentsoftheCPUregisters(thecontext)fromarunningthread.APCsare
queued to specific threads and allow the system to execute both system and
user code within a process’s context. User-mode execution of an APC cannot
occur at arbitrary times, but only when the thread is waiting and is marked
alertable.Kernel-modeexecutionofanAPC,incontrast,instantaneouslyexe-
cutes in the context of a running thread because it is delivered as a software
interruptrunningatIRQL1(APC LEVEL),whichishigherthanthedefaultIRQL
0(PASSIVE LEVEL).Additionally,evenifathreadiswaitinginkernelmode,the
waitcanbebrokenbytheAPCandresumedoncetheAPCcompletesexecution.
interrupt levels types of interrupts
31 machine check or bus error
30 power fail
29 interprocessor notification (request another processor
to act; e.g., dispatch a process or update the TLB)
28 clock (used to keep track of time)
27 profile
3–26 traditional PC IRQ hardware interrupts
2 dispatch and deferred procedure call (DPC) (kernel)
1 asynchronous procedure call (APC)
0 passive
Figure21.2 Windowsx86interrupt-requestlevels(IRLQs).21.3 SystemComponents 847
DPCsareusedtopostponeinterruptprocessing.Afterhandlingallurgent
device-interrupt processing, the ISR schedules the remaining processing by
queuingaDPC.TheassociatedsoftwareinterruptrunsatIRQL2(DPC LEVEL),
whichislowerthanallotherhardware/I/Ointerruptlevels.Thus,DPCsdonot
block other device ISRs. In addition to deferring device-interrupt processing,
thedispatcherusesDPCstoprocesstimerexpirationsandtointerruptcurrent
threadexecutionattheendoftheschedulingquantum.
Because IRQL2 is higher than 0 (PASSIVE) and 1 (APC), execution of DPCs
prevents standard threads from running on the current processor and also
keeps APCs from signaling the completion of I/O. Therefore, it is important
forDPCroutinesnottotakeanextendedamountoftime.Asanalternative,the
executivemaintains a pool of worker threads. DPCs can queue work items to
theworkerthreads,wheretheywillbeexecutedusingnormalthreadschedul-
ingatIRQL0.BecausethedispatcheritselfrunsatIRQL2,andbecausepaging
operationsrequirewaitingonI/O(andthatinvolvesthedispatcher),DPCrou-
tines are restricted in that they cannot take page faults, call pageable system
services,ortakeany otheractionthatmightresultinanattempttowaitfora
dispatcherobject to be signaled.Unlike APCs, which are targetedto athread,
DPCroutinesmakenoassumptionsabout what processcontexttheprocessor
isexecuting,sincetheyexecuteinthesamecontextasthecurrentlyexecuting
thread,whichwasinterrupted.
21.3.4.8 Exceptions,Interrupts,andIPIs
The kernel dispatcher also provides trap handling for exceptions and
interrupts generated by hardware or software. Windows defines several
architecture-independentexceptions,including:
• Integerorfloating-pointoverflow
• Integerorfloating-pointdividebyzero
• Illegalinstruction
• Datamisalignment
• Privilegedinstruction
• Accessviolation
• Pagingfilequotaexceeded
• Debuggerbreakpoint
The trap handlers deal with the hardware-level exceptions (called traps) and
calltheelaborateexception-handlingcodeperformedbythekernel’sexception
dispatcher. The exception dispatcher creates an exception record containing
thereasonfortheexceptionandfindsanexceptionhandlertodealwithit.
Whenanexceptionoccursinkernelmode,theexceptiondispatchersimply
calls a routine to locate the exception handler. If no handler is found, a fatal
systemerroroccursandtheuserisleftwiththeinfamous“bluescreenofdeath”
thatsignifiessystemfailure.InWindows10,thisisnowafriendlier“sadface
ofsorrow”withaQRcode,butthebluecolorremains.848 Chapter21 Windows10
Exceptionhandlingismorecomplexforuser-modeprocesses,becausethe
Windows error reporting (WER) service sets up an ALPC error port for every
process, on top of the Win32 environment subsystem, which sets up an ALPC
exception port for every process it creates. (For details on ports, see Section
21.3.5.4.)Furthermore,ifaprocessisbeingdebugged,itgetsadebuggerport.
If a debugger port is registered,the exception handler sends the exception to
theport.Ifthedebuggerportisnotfoundordoesnothandlethatexception,the
dispatcherattemptstofindanappropriateexceptionhandler.Ifnoneexists,it
contactsthedefaultunhandledexceptionhandler,whichwillnotifyWERofthe
processcrashsothatacrashdumpcanbegeneratedandsenttoMicrosoft.If
thereisahandler,butitrefusestohandletheexception,thedebuggeriscalled
againtocatchtheerrorfordebugging.Ifnodebuggerisrunning,amessageis
senttotheprocess’sexceptionporttogivetheenvironmentsubsystemachance
to react to the exception. Finally, a message is sent to WER through the error
port,inthecasewheretheunhandledexceptionhandlermay nothavehada
chancetodoso,andthenthekernelsimplyterminatestheprocesscontaining
thethreadthatcausedtheexception.
WERwilltypicallysendtheinformationbacktoMicrosoftforfurtheranal-
ysis,unlesstheuserhasoptedoutorisusingalocalerror-reportingserver.In
somecases,Microsoft’sautomatedanalysismaybeabletorecognizetheerror
immediatelyandsuggestafixorworkaround.
Theinterruptdispatcherinthekernelhandlesinterruptsbycallingeither
aninterruptserviceroutine(ISR)suppliedbyadevicedriverorakerneltrap-
handlerroutine.Theinterruptisrepresentedbyaninterruptobjectthat con-
tains all the information needed to handle the interrupt. Using an interrupt
object makes it easy to associate interrupt-service routines with an interrupt
withouthavingtoaccesstheinterrupthardwaredirectly.
Differentprocessorarchitectureshavedifferenttypesandnumbersofinter-
rupts. For portability, the interrupt dispatcher maps the hardware interrupts
intoastandardset.
The kernel uses an interrupt-dispatch table to bind each interrupt level
toaserviceroutine.Inamultiprocessorcomputer,Windowskeepsaseparate
interrupt-dispatch table (IDT) for each processor core, and each processor’s
IRQLcanbesetindependentlytomaskoutinterrupts.Allinterruptsthatoccur
at a level equal to or less than the IRQL of a processor are blocked until the
IRQLisloweredbyakernel-levelthreadorbyanISRreturningfrominterrupt
processing.Windowstakesadvantageofthispropertyandusessoftwareinter-
ruptstodeliverAPCsandDPCs,toperformsystemfunctionssuchassynchro-
nizing threads with I/O completion, to start thread execution, and to handle
timers.
21.3.5 Executive
The Windows executive provides a set of services that all environment sub-
systems use. To give you a good basic overview, we discuss the following
services here: object manager, virtual memory manager, process manager,
advanced local procedure call facility, I/O manager, cache manager, security
reference monitor, plug-and-play and power managers, registry, and startup.
Note,though,thattheWindowsexecutiveincludesmorethantwodozenser-
vicesintotal.21.3 SystemComponents 849
Theexecutiveisorganizedaccordingtoobject-orienteddesignprinciples.
An object type in Windows is a system-defined data type that has a set of
attributes(datavalues)andasetofmethods(forexample,functionsoropera-
tions)thathelpdefineitsbehavior.Anobjectisaninstanceofanobjecttype.
Theexecutiveperformsitsjobbyusingasetofobjectswhoseattributesstore
thedataandwhosemethodsperformtheactivities.
21.3.5.1 ObjectManager
For managing kernel-mode entities, Windows uses a generic set of interfaces
that are manipulated by user-mode programs. Windows calls these entities
objects, and the executive component that manipulates them is the object
manager. Examples of objects are files, registry keys, devices, ALPC ports,
drivers, mutexes, events, processes, and threads. As we saw earlier, some of
these, such as mutexes and processes, are dispatcher objects, which means
that threads can block inthe dispatcherwaiting for any ofthese objects tobe
signaled.Additionally,mostofthenon-dispatcherobjectsincludeaninternal
dispatcherobject,whichissignaledbytheexecutiveservicecontrollingit.For
example,fileobjectshaveaneventobjectembedded,whichissignaledwhen
afileismodified.
User-modeandkernel-modecodecanaccesstheseobjectsusinganopaque
value called a handle, which is returned by many APIs. Each process has a
handle table containing entries that track the objects used by the process.
There is a “system process” (see Section 21.3.5.11) that has its own handle
table,which isprotectedfromusercode andis usedwhen kernel-modecode
is manipulating handles. The handle tables in Windows are representedby a
treestructure, which can expand from holding 1,024 handles to holding over
16million.Inadditiontousinghandles,kernel-modecodecanalsoaccessan
object by using referenced pointer, which it must obtain by calling a special
API.Whenhandlesareused,theymusteventuallybeclosed,toavoidkeeping
anactivereferenceontheobject.Similarly,whenkernelcodeusesareferenced
pointer,itmustuseaspecialAPItodropthereference.
A handle can be obtained by creating an object, by opening an existing
object,byreceivingaduplicatedhandle,orbyinheritingahandlefromaparent
process. To work around the issue that developers may forget to close their
handles,alloftheopenhandlesofaprocessareimplicitlyclosedwhenitexits
or is terminated. However, since kernel handles belong to the system-wide
handletable,whenadriverunloads,itshandlesarenotautomaticallyclosed,
andthiscanleadtoresourceleaksonthesystem.
Since the object manager is the only entity that generates object handles,
itisthenaturalplacetocentralizecallingthesecurityreferencemonitor(SRM)
(see Section 21.3.5.7) to check security. When an attempt is made to open an
object, the object manager calls the SRM to check whether a process or thread
hastherighttoaccesstheobject.Iftheaccesscheckissuccessful,theresulting
rights(encodedas an access mask)arecached inthe handle table.Therefore,
the opaque handle both represents the object in the kernel and identifies the
accessthatwasgrantedtotheobject.Thisimportantoptimizationmeansthat
wheneverafileiswrittento(whichcouldhappenhundredsoftimesasecond),
securitychecksarecompletelyskipped,sincethehandleisalreadyencodedas850 Chapter21 Windows10
a“write”handle.Conversely,ifahandleisa“read”handle,attemptstowrite
tothefilewouldinstantlyfail,withoutrequiringasecuritycheck.
Theobjectmanageralsoenforcesquotas,suchasthemaximumamountof
memory a process may use, by charging a process for the memory occupied
by all its referenced objects and refusing to allocate more memory when the
accumulatedchargesexceedtheprocess’squota.
Because objects can be referenced through handles from user and kernel
mode,andreferencedthroughpointersfromkernelmode,theobjectmanager
hastokeeptrackoftwocountsforeachobject:thenumberofhandlesforthe
objectandthenumberofreferences.Thehandlecountisthenumberofhandles
thatrefertotheobjectinallofthehandletables(includingthesystemhandle
table).Thereferencecountisthesumofallhandles(whichcountasreferences)
plus all pointer references done by kernel-mode components. The count is
incrementedwheneveranewpointerisneededbythekerneloradriverand
decremented when the component is done with the pointer. The purpose of
thesereferencecountsistoensurethatanobjectisnotfreedwhileitstillhasa
reference,butcanstillreleasesomeofitsdata(suchasthenameandsecurity
descriptor)whenallhandlesareclosed(sincekernel-modecomponentsdon’t
needthisinformation).
The object manager maintains the Windows internal name space. In con-
trasttoUNIX,whichrootsthesystemnamespaceinthefilesystem,Windows
usesanabstractobjectmanagernamespacethatisonlyvisibleinmemoryor
throughspecializedtoolssuchasthedebugger.Insteadoffile-systemdirecto-
ries,thehierarchy ismaintained by aspecial kindof object calleda directory
object that contains a hash bucket of other objects (including other directory
objects).Notethatsomeobjectsdon’thavenames(suchasthreads),andeven
forotherobjects,whetheranobjecthasanameisuptoitscreator.Forexample,
aprocesswouldonlynameamutexifitwantedotherprocessestofind,acquire,
orinquireaboutthestateofthemutex.
Because processes and threads are created without names, they are
referenced through a separate numerical identifier, such as a process ID
(PID) or thread (TID). The object manager also supports symbolic links
in the name space. As an example, DOS drive letters are implemented
using symbolic links; ∖Global??∖C: is a symbolic link to the device object
∖Device∖HarddiskVolumeN,representingamountedfile-systemvolumeinthe
∖Devicedirectory.
Each object, as mentioned earlier, is an instance of an object type. The
object type specifies how instances are to be allocated, how data fields are to
be defined, and how the standard set of virtual functions used for all objects
aretobeimplemented.Thestandardfunctionsimplementoperationssuchas
mappingnamestoobjects,closinganddeleting,andapplyingsecuritychecks.
Functions that are specific to a particular type of object are implemented by
systemservices designedto operate on that particular object type, not by the
methodsspecifiedintheobjecttype.
The parse() function is the most interesting of the standard object func-
tions.Itallowstheimplementationofanobjecttooverridethedefaultnaming
behavior of the object manager (which is to use the virtual object directo-
ries).Thisabilityisusefulforobjectsthathavetheirowninternalnamespace,
especiallywhenthenamespacemightneedtoberetainedbetweenboots.The21.3 SystemComponents 851
I/Omanager(forfileobjects)andtheconfigurationmanager(forregistrykey
objects)arethemostnotableusersofparsefunctions.
Returning to our Windows naming example, device objects used to rep-
resent file-system volumes provide a parse function. This allows a name like
∖Global??∖C:∖foo∖bar.docto be interpreted as the file ∖foo∖bar.doc on the
volume represented by the device object HarddiskVolume2.We can illustrate
how naming, parse functions, objects, and handles work together by looking
atthestepstoopenthefileinWindows:
1. AnapplicationrequeststhatafilenamedC:∖foo∖bar.docbeopened.
2. The object manager finds the device object HarddiskVolume2, looks up
the parse procedure (for example, IopParseDevice) from the object’s
type, and invokes it with the file’s name relative to the root of the file
system.
3. IopParseDevice()looksupthefilesystemthatownsthevolumeHard-
DiskVolume2and then calls into the file system, which looks up how to
access∖foo∖bar.doconthevolume,performingitsowninternalparsing
ofthefoodirectorytofindthebar.docfile.Thefilesystemthenallocates
afileobjectandreturnsittotheI/Omanager’sparseroutine.
4. When the file system returns, the object manager allocates an entry for
thefileobjectinthehandletableforthecurrentprocessand returnsthe
handletotheapplication.
If the file cannot successfully be opened, IopParseDevice returns an error
indicationtotheapplication.
21.3.5.2 VirtualMemoryManager
The executive component that manages the virtual address space, physical
memoryallocation, and paging is the memory manager (MM). The design of
the MM assumes that the underlying hardware supports virtual-to-physical
mapping,apagingmechanism,andtransparentcachecoherenceonmultipro-
cessor systems, as well as allowing multiple page-table entries to map to the
same physical page frame. The MM in Windows uses a page-based manage-
mentschemebasedonthepagesizessupportedbyhardware(4KB,2MB,and
1 GB). Pages of data allocated to a process that are not in physical memory
areeitherstoredinthe pagingfile onsecondary storageormappeddirectly
to a regular file on a local or remote file system. Apage can also be marked
zero-fill-on-demand,whichinitializesthepagewithzerosbeforeitismapped,
thuserasingthepreviouscontents.
On32-bitprocessorssuchasIA-32andARM,eachprocesshasa4-GBvirtual
addressspace.Bydefault,theupper2GBaremostlyidenticalforallprocesses
andareusedbyWindowsinkernelmodetoaccesstheoperating-systemcode
and data structures. For 64-bit architectures such as the AMD64 architecture,
Windowsprovidesa256-TBper-processvirtualaddressspace,dividedintotwo
128-TBregionsforusermodeandkernelmode.(Theserestrictionsarebasedon
hardwarelimitationsthatwillsoonbelifted.Intelhasannouncedthatitsfuture852 Chapter21 Windows10
processorswillsupportupto128PBofvirtualaddressspace,outofthe16EB
theoreticallyavailable.)
The availability of the kernel’s code in each process’s address space is
important, and commonly found in many other operating systems as well.
Generally, virtual memory is used to map the kernel code into the address
spaceofeachprocess.Then,whensayasystemcallisexecutedoraninterrupt
is received, the context switch to allow the current core to run that code is
lighter-weightthanitwouldotherwisebewithoutthismapping.Specificially,
nomemory-managementregistersneedtobesavedandrestored,andthecache
doesnotgetinvalidated.Thenetresultismuchfastermovementbetweenuser
and kernel code, compared to older architectures that keep kernel memory
separateandnotavailablewithintheprocessaddressspace.
TheWindowsMMusesatwo-stepprocesstoallocatevirtualmemory.The
firststepreservesoneormorepagesofvirtualaddressesintheprocess’svirtual
address space. The second step commits the allocation by assigning virtual
memoryspace(physicalmemoryorspaceinthepagingfiles).Windowslimits
theamountofvirtualmemoryspaceaprocessconsumesbyenforcingaquota
oncommittedmemory.Aprocessde-commitsmemorythatitisnolongerusing
to free up virtual memory space for use by other processes. The APIs used
to reserve virtual addresses and commit virtual memory take a handle on a
process object as a parameter. This allows one process to control the virtual
memoryofanother.
Windows implementssharedmemorybydefiningasectionobject.After
gettingahandletoasectionobject,aprocessmapsthememoryofthesectionto
arangeofaddresses,calledaview.Aprocesscanestablishaviewoftheentire
section or only the portion it needs. Windows allows sections to be mapped
notjustintothecurrentprocessbutintoanyprocessforwhichthecallerhasa
handle.
Sectionscanbeusedinmanyways.Asectioncanbebackedbysecondary
storageeitherinthesystem-pagingfileorinaregularfile(amemory-mapped
file).Asectioncanbebased,meaningthatitappearsatthesamevirtualaddress
for all processes attempting to access it. Sections can also represent physical
memory, allowing a 32-bit process to access more physical memory than can
fit in its virtual addressspace. Finally, the memory protectionof pages in the
sectioncanbesettoreadonly,read–write,read–write–execute,executeonly,
noaccess,orcopy-on-write.
Let’slookmorecloselyatthelasttwooftheseprotectionsettings:
• A no-access page raises an exception if accessed. The exception can be
used, for example, to check whether a faulty program iterates beyond
the end of an array or simply to detect that the program attempted to
access virtual addresses that are not committed to memory. User- and
kernel-mode stacks use no-access pages as guard pages to detect stack
overflows.Anotheruseistolookforheapbufferoverruns.Boththeuser-
modememoryallocatorandthespecialkernelallocatorusedbythedevice
verifier can be configured to map each allocation onto the end of a page,
followed by a no-access page to detect programming errors that access
beyondtheendofanallocation.21.3 SystemComponents 853
• The copy-on-write mechanism enables the MM to use physical memory
more efficiently. When two processes want independent copies of data
from the same section object, the MM places a single shared copy into
virtual memory and activates the copy-on-write property for that region
ofmemory.Ifoneoftheprocessestriestomodifydatainacopy-on-write
page,theMMmakesaprivatecopyofthepagefortheprocess.
The virtual address translation on most modern processors uses a multi-
level page table. For IA-32 (operating in Physical Address Extension, or PAE,
mode)andAMD64processors,eachprocesshasapagedirectorythatcontains
512 page-directory entries (PDEs), each 8 bytes in size. Each PDE points to a
PTEtablethatcontains512page-tableentries(PTEs),each8bytesinsize.Each
PTEpointstoa4-KBpageframeinphysicalmemory.Foravarietyofreasons,
thehardwarerequiresthatthepagedirectoriesorPTEtablesateachlevelofa
multilevelpagetableoccupyasinglepage.Thus,thenumberofPDEsorPTEs
thatfitinapagedetermineshowmanyvirtualaddressesaretranslatedbythat
page.SeeFigure21.3foradiagramofthisstructure.
Thestructuredescribedsofarcanbeusedtorepresentonly1GBofvirtual
address translation. For IA-32, a second page-directory level is needed, con-
tainingonlyfourentries,asshowninthediagram.On64-bitprocessors,more
entriesareneeded.ForAMD64,theprocessorcanfillalltheremainingentries
in the second page-directory level and thus obtain 512 GB of virtual address
space.Therefore,tosupportthe 256 TBthat arerequired,the processorneeds
athirdpage-directorylevel(calledthePML4),whichalsohas512entries,each
pointing to the lower-level directory. As mentioned earlier, future processors
announcedbyIntelwillsupport128PB,requiringafourthpage-directorylevel
(PML5). Thanks tothis hierarchical mechanism, the total sizeofall page-table
pages neededto fully representa 32-bit virtual addressspace for a process is
page directory pointer table
pointer 0 pointer 1 pointer 2 pointer 3
page page page page page page
directory directory directory directory directory directory
entry 0 0 entry 511 entry 0 3 entry 511
page table page page table page table page page table
entry 0 table 0 entry 511 entry 0 table 511 entry 511
4 KB 4 KB 4 KB 4 KB
page page page page
Figure21.3 Page-tablelayout.854 Chapter21 Windows10
31 0
PTR PDE index PTE index page offset
Figure21.4 Virtual-to-physicaladdresstranslationonIA-32.
only8MB.Additionally,theMMallocatespagesofPDEsandPTEsasneededand
movespage-tablepagestosecondarystoragewhennotinuse,sothattheactual
physicalmemoryoverheadofthepagingstructuresforeachprocessisusually
approximately2KB.Thepage-tablepagesarefaultedbackintomemorywhen
referenced.
We next consider how virtual addresses are translated into physical
addresses on IA-32-compatible processors. A 2-bit value can represent the
values0,1,2,3.A9-bitvaluecanrepresentvaluesfrom0to511;a12-bitvalue,
values from 0 to 4,095. Thus, a 12-bit value can select any byte within a 4-KB
page of memory. A9-bit value can represent any of the 512 PDEs or PTEs in a
pagedirectoryorPTE-tablepage.AsshowninFigure21.4,translatingavirtual
address pointer to a byte address in physical memory involves breaking the
32-bitpointerintofourvalues,startingfromthemostsignificantbits:
• Two bits are used to index into the four PDEs at the top level of the page
table.TheselectedPDEwillcontainthephysicalpagenumberforeachof
thefourpage-directorypagesthatmap1GBoftheaddressspace.
• NinebitsareusedtoselectanotherPDE,thistimefromasecond-levelpage
directory. This PDE will contain the physical page numbers of up to 512
PTE-tablepages.
• Nine bits are used to select one of 512 PTEs from the selected PTE-table
page.TheselectedPTEwillcontainthephysicalpagenumberforthebyte
weareaccessing.
• Twelvebitsareusedasthebyteoffsetintothepage.Thephysicaladdress
ofthebyteweareaccessingisconstructedbyappendingthelowest12bits
ofthevirtualaddresstotheendofthephysicalpagenumberwefoundin
theselectedPTE.
Note that the number of bits in a physical address may be different from
the number of bits in a virtual address. For example, when PAE is enabled
(the only mode supported by Windows 8 and later versions), the IA-32 MMU
is extended to the larger 64-bit PTE size, while the hardware supports 36-bit
physical addresses, granting access to up to 64 GB of RAM, even though a
single process can only map an address space up to 4 GB in size. Today, on
the AMD64 architecture,serverversionsof Windows support very,very large
physical addresses—more than we can possibly use or even buy (24 TB as of
thelatestrelease).(Ofcourse,atonetimetime4GBseemedoptimisticallylarge
forphysicalmemory.)21.3 SystemComponents 855
To improve performance, the MM maps the page-directory and PTE-table
pages into the same contiguous region of virtual addresses in every process.
Thisself-mapallowstheMMtousethesamepointertoaccessthecurrentPDE
orPTEcorrespondingtoaparticularvirtualaddressnomatterwhatprocessis
running. The self-map for the IA-32 takes a contiguous 8-MB region of kernel
virtualaddressspace;theAMD64self-mapoccupies512GB.Althoughtheself-
map occupies significant address space, it does not require any additional
virtualmemorypages.Italsoallowsthepagetable’spagestobeautomatically
pagedinandoutofphysicalmemory.
Inthecreationofaself-map,oneofthePDEsinthetop-levelpagedirectory
refers to the page-directory page itself, forming a “loop” in the page-table
translations.Thevirtualpagesareaccessediftheloopisnottaken,thePTE-table
pages are accessed if the loop is taken once, the lowest-level page-directory
pagesareaccessediftheloopistakentwice,andsoforth.
Theadditionallevelsofpagedirectoriesusedfor64-bitvirtualmemoryare
translatedinthesamewayexceptthatthevirtualaddresspointerisbrokenup
intoevenmorevalues.FortheAMD64,Windowsusesfourfulllevels,eachof
whichmaps512pages,or9+9+9+9+12=48bitsofvirtualaddress.
To avoid the overhead of translating everyvirtual addressby looking up
thePDEandPTE,processorsusetranslationlook-asidebuffer(TLB)hardware,
whichcontainsanassociativememorycacheformappingvirtualpagestoPTEs.
TheTLBispartofthememory-managementunit(MMU)withineachprocessor.
The MMU needs to “walk” (navigate the data structures of) the page table in
memoryonlywhenaneededtranslationismissingfromtheTLB.
The PDEs and PTEs contain more than just physical page numbers. They
alsohavebitsreservedforoperating-systemuseandbitsthatcontrolhowthe
hardwareusesmemory,suchaswhetherhardwarecachingshouldbeusedfor
eachpage.Inaddition,theentriesspecifywhatkindsofaccessareallowedfor
bothuserandkernelmodes.
APDEcanalsobemarkedtosaythatitshouldfunctionasaPTEratherthan
aPDE.OnaIA-32,thefirst11bitsofthevirtualaddresspointerselectaPDEin
thefirsttwolevelsoftranslation.IftheselectedPDEismarkedtoactasaPTE,
thentheremaining21bitsofthepointerareusedastheoffsetofthebyte.This
resultsin a 2-MB size for the page. Mixing and matching 4-KB and 2-MB page
sizeswithinthepagetableiseasyfortheoperatingsystemandcansignificantly
improve the performance of some programs. The improvement results from
reducinghowoftentheMMUneedstoreloadentriesintheTLB,sinceonePDE
mapping2MBreplaces512PTEs,eachmapping4KB.NewerAMD64hardware
evensupports1-GBpages,whichoperateinasimilarfashion.
Managingphysicalmemorysothat2-MBpagesareavailablewhenneeded
is difficult, as they may continually be broken up into 4-KB pages, causing
external fragmentation of memory. Also, the large pages can result in very
significant internal fragmentation. Because of these problems, it is typically
onlyWindowsitself,alongwithlargeserverapplications,thatuselargepages
toimprovetheperformanceoftheTLB.Theyarebettersuitedtodosobecause
operating-systemandserverapplicationsstartrunningwhenthesystemboots,
beforememoryhasbecomefragmented.
Windows manages physical memory by associating each physical page
with one of seven states: free, zeroed, modified, standby, bad, transition, or
valid.856 Chapter21 Windows10
• Afreepageisanavailablepagethathasstaleoruninitializedcontent.
• A zeroed page is a free page that has been zeroed out and is ready for
immediateusetosatisfyzero-on-demandfaults.
• Amodified page has been written by a process and must be sent to sec-
ondarystoragebeforeitisusablebyanotherprocess.
• A standby page is a copy of information already stored on secondary
storage. Standby pages may be pages that were not modified, modified
pages that have already been written to secondary storage, or pages that
wereprefetchedbecausetheywereexpectedtobeusedsoon.
• Abadpageisunusablebecauseahardwareerrorhasbeendetected.
• Atransition page is on its way from secondary storage to a page frame
allocatedinphysicalmemory.
• Avalidpageeitherispartoftheworkingsetofoneormoreprocessesand
is contained within these processes’ page tables, or is being used by the
systemdirectly(suchastostorethenonpagedpool).
While valid pages are contained in processes’ page tables, pages in other
statesarekeptinseparatelistsaccordingtostatetype.Additionally,toimprove
performance and protect against aggressive recycling of the standby pages,
Windows Vista and later versions implement eight prioritized standby lists.
Thelistsareconstructedbylinkingthecorrespondingentriesinthepageframe
number (PFN) database, which includes an entry for each physical memory
page.ThePFNentriesalsoincludeinformationsuchasreferencecounts,locks,
andNUMAinformation.NotethatthePFNdatabaserepresentspagesofphys-
icalmemory,whereasthePTEsrepresentpagesofvirtualmemory.
When the valid bit in a PTE is zero, hardware ignores all the other bits,
andtheMMcandefinethemforitsownuse.Invalidpagescanhaveanumber
of states represented by bits in the PTE. Page-file pages that have never been
faultedinaremarkedzero-on-demand.Pagesmappedthroughsectionobjects
encode a pointer to the appropriate section object. PTEs for pages that have
beenwrittentothepagefilecontainenoughinformationtolocatethepageon
secondarystorage,andsoforth.Thestructureofthepage-filePTEisshownin
Figure21.5.TheT,P,andVbitsareallzeroforthistypeofPTE.ThePTEincludes
5 bits for page protection, 32 bits for page-file offset, and 4 bits to select the
pagingfile.Therearealso20bitsreservedforadditionalbookkeeping.
Windows uses a per-working-set, least recently used (LRU) replacement
policytotakepagesfromprocessesasappropriate.Whenaprocessisstarted,it
isassignedadefaultminimumworking-setsize,atwhichpointtheMMstartsto
tracktheageofthepagesineachworkingset.Theworkingsetofeachprocess
is allowed to grow until the amount of remaining physical memory starts to
run low. Eventually, when the available memory runs critically low, the MM
trimstheworkingsettoremoveolderpages.
Theageofapagedependsnotonhowlongithasbeeninmemorybuton
whenitwaslastreferenced.TheMMmakesthisdeterminationbyperiodically
passingthroughtheworkingsetofeachprocessandincrementingtheagefor
pages that have not been marked in the PTE as referencedsince the last pass.
Whenitbecomesnecessarytotrimtheworkingsets,theMMusesheuristicsto21.3 SystemComponents 857
63 32
page-file offset
31 0
page
T P prot V
file
Figure21.5 Page-filepage-tableentry.Thevalidbitiszero.
decidehowmuchtotrimfromeachprocessandthenremovestheoldestpages
first.
Aprocesscanhaveitsworkingsettrimmedevenwhenplentyofmemoryis
available,ifitwasgivenahardlimit onhowmuchphysicalmemoryitcould
use. In Windows 7 and later versions, the MM also trims processes that are
growingrapidly,evenifmemoryisplentiful.Thispolicychangesignificantly
improvedtheresponsivenessofthesystemforotherprocesses.
Windows tracks working sets not only for user-mode processes but also
forvariouskernel-moderegions,whichincludethefilecacheandthepageable
kernelheap.Pageablekernelanddrivercodeanddatahavetheirownworking
sets, as does each TS session. The distinct working sets allow the MM to use
differentpoliciestotrimthedifferentcategoriesofkernelmemory.
The MM does not fault in only the page immediately needed. Research
showsthatthememoryreferencingofathreadtendstohavealocality prop-
erty. That is, when a page is used, it is likely that adjacent pages will be
referenced in the near future. (Think of iterating over an array or fetching
sequentialinstructionsthatformtheexecutablecodeforathread.)Becauseof
locality, when the MM faults in a page, it also faults in a few adjacent pages.
This prefetching tends to reduce the total number of page faults and allows
readstobeclusteredtoimproveI/Operformance.
In addition to managing committed memory, the MM manages each pro-
cess’s reserved memory, or virtual address space. Each process has an asso-
ciated tree that describes the ranges of virtual addresses in use and what the
usesare.ThisallowstheMMtofaultinpage-tablepagesasneeded.IfthePTE
for a faulting address is uninitialized, the MM searches for the address in the
process’streeofvirtualaddressdescriptors(VADs)andusesthisinformation
tofillinthePTEandretrievethepage.Insomecases,aPTE-tablepagemaynot
exist;suchapagemustbetransparentlyallocatedandinitializedbytheMM.In
othercases,thepagemaybesharedaspartofasectionobject,andtheVADwill
containapointertothatsectionobject.Thesectionobjectcontainsinformation
onhowtofindthesharedvirtualpagesothatthePTEcanbeinitializedtopoint
toitdirectly.
StartingwithVista,theWindowsMMincludesacomponentcalledSuper-
Fetch.Thiscomponentcombinesauser-modeservicewithspecializedkernel-858 Chapter21 Windows10
mode code,including a file-systemfilter, tomonitor all paging operations on
thesystem.Eachsecond,theservicequeriesatraceofallsuchoperationsand
uses a variety of agents to monitor application launches, fast user switches,
standby/sleep/hibernate operations, and more as a means of understanding
thesystem’susagepatterns.Withthisinformation,itbuildsastatisticalmodel,
usingMarkovchains,ofwhichapplicationstheuserislikelytolaunchwhen,in
combination with what other applications, and what portions of these appli-
cations will be used. For example, SuperFetch can train itself to understand
that the user launches Microsoft Outlook in the mornings mostly to read e-
mail but composes e-mails later,after lunch. It can also understand that once
Outlookisinthebackground,VisualStudioislikelytobelaunchednext,and
thatthetexteditorisgoingtobeinhighdemand,withthecompilerdemanded
a littleless frequently,the linker evenless frequently,and the documentation
codehardlyever.Withthisdata,SuperFetchwillprepopulatethestandbylist,
making low-priority I/O reads from secondary storage at idle times to load
what it thinks the user is likely to do next (or another user, if it knows a fast
userswitchislikely).Additionally,byusingtheeightprioritizedstandbylists
thatWindowsoffers,eachsuchprefetchedpagedcanbecachedatalevelthat
matches the statistical likelihood that it will be needed. Thus, unlikely-to-be-
demanded pages can cheaply and quickly be evicted by an unexpected need
forphysicalmemory,whilelikely-to-be-demanded-soonpagescanbekeptin
placeforlonger.Indeed,SuperFetchmayevenforcethesystemtotrimworking
setsofotherprocessesbeforetouchingsuchcachedpages.
SuperFetch’s monitoring does create considerable system overhead. On
mechanical(rotational)drives,whichhaveseektimesinthemilliseconds,this
costisbalancedbythebenefitofavoidinglatenciesandmultiseconddelaysin
applicationlaunchtimes.Onserversystems,however,suchmonitoringisnot
beneficial,giventherandommultiuserworkloadsandthefactthatthroughput
is more important than latency. Further, the combined latency improvements
and bandwidth on systems with fast, efficient nonvolatile memory, such as
SSDs, make the monitoring less beneficial for those systems as well. In such
situations,SuperFetchdisablesitself,freeingupafewspareCPUcycles.
Windows10bringsanotherlargeimprovementtotheMMbyintroducing
a component called the compression store manager. This component creates
a compressed store of pages in the working set of the memory compression
process, which is a type of system process. When shareable pages go on the
standby listand availablememory is low (or certainother internal algorithm
decisions are made), pages on the list will be compressed instead of evicted.
This can also happen to modified pages targeted for eviction to secondary
storage—both by reducing memory pressure, perhaps avoiding the write in
the first place, and by causing the written pages to be compressed, thus con-
suming less page file space and taking less I/O to page out. On today’s fast
multiprocessorsystems,oftenwithbuilt-inhardwarecompressionalgorithms,
the small CPU penalty is highly preferable to the potential secondary storage
I/Ocost.
21.3.5.3 ProcessManager
TheWindowsprocessmanagerprovidesservicesforcreating,deleting,inter-
rogating, and managing processes, threads, and jobs. It has no knowledge21.3 SystemComponents 859
aboutparent–childrelationshipsorprocesshierarchies,althoughitcangroup
processesinjobs, and the latter can have hierarchies that must then be main-
tained.Theprocessmanagerisalsonotinvolvedintheschedulingofthreads,
other than setting the priorities and affinities of the threads in their owner
processes.Additionally,through jobs, the process manager can effect various
changes in scheduling attributes (such as throttling ratios and quantum val-
ues)onthreads.Threadschedulingproper,however,takesplaceinthekernel
dispatcher.
Each process contains one or more threads. Processes themselves can be
collected into larger units called job objects. The original use of job objects
was to place limits on CPU usage, working-set size, and processor affinities
that control multiple processes at once. Job objects were thus used to man-
agelargedata-centermachines.InWindowsXPandlaterversions,jobobjects
were extended to provide security-related features, and a number of third-
partyapplicationssuchasGoogleChromebeganusingjobsforthispurpose.In
Windows8,amassivearchitecturalchangeallowedjobstoinfluenceschedul-
ing through generic CPU throttling as well as per-user-session-aware fairness
throttling/balancing.InWindows10,throttlingsupportwasextendedtosec-
ondarystorageI/OandnetworkI/Oaswell.Additionally,Windows8allowed
job objects to nest, creating hierarchies of limits, ratios, and quotas that the
systemmustaccuratelycompute.Additionalsecurityandpowermanagement
featuresweregiventojobobjectsaswell.
As a result, all Windows Store applications and all UWP application
processes run in jobs. The DAM, introduced earlier, implements Connected
Standby support using jobs. Finally, Windows 10’s support for Docker
Containers, a key part of its cloud offerings, uses job objects, which it calls
silos. Thus, jobs have gone from being an esoteric data-center resource
managementfeaturetoacoremechanismoftheprocessmanagerformultiple
features.
Due to Windows’s layered architecture and the presence of environment
subsystems,processcreationisquitecomplex.Anexampleofprocesscreation
in the Win32 environment under Windows 10 is as follows. Note that the
launching of UWP “Modern” Windows Store applications (which are called
packagedapplications,or“AppX”)issignificantlymorecomplexandinvolves
factorsoutsidethescopeofthisdiscussion.
1. AWin32applicationcallsCreateProcess().
2. Anumberofparameterconversionsandbehavioralconversionsaredone
fromtheWin32worldtotheNTworld.
3. CreateProcess() then calls the NtCreateUserProcess() API in the
process manager of the NT executive to actually create the process and
itsinitialthread.
4. The process manager calls the object manager to create a process object
andreturnstheobjecthandletoWin32.Itthencallsthememorymanager
to initialize the address space of the new process, its handle table, and
other key data structures, such as the process environment block (PEBL)
(whichcontainsinternalprocessmanagementdata).860 Chapter21 Windows10
5. The process manager calls the object manager again to create a thread
object and returns the handle to Win32. It then calls the memory man-
ager to create the thread environment block (TEB) and the dispatcher
to initialize the scheduling attributes of the thread, setting its state to
initializing.
6. The process manager creates the initial thread startup context (which
will eventually point to the main() routine of the application), asks the
schedulertomarkthethreadasready,andthenimmediatelysuspends
it,puttingitintoawaitingstate.
7. Amessageis sent to the Win32 subsystem to notify it that the process is
beingcreated.ThesubsystemperformsadditionalWin32-specificworkto
initializetheprocess,suchascomputingitsshutdownlevelanddrawing
theanimatedhourglassor“donut”mousecursor.
8. Back in CreateProcess(), inside the parent process, the
ResumeThread() API is called to wake up the process’s initial thread.
Controlreturnstotheparent.
9. Now, inside the initial thread of the new process, the user-mode link
loadertakescontrol (insidentdll.dll,which isautomatically mapped
intoallprocesses).Itloadsallthelibrarydependencies(DLLs)oftheappli-
cation,createsitsinitialheap,setsupexceptionhandlingandapplication
compatibility options, and eventually calls the main() function of the
application.
TheWindows APIs formanipulatingvirtualmemoryandthreadsand for
duplicating handles take a process handle, so their subsystem and other ser-
vices, when notified of process creation, can perform operations on behalf of
the new process without having toexecute directlyin the new process’s con-
text.WindowsalsosupportsaUNIXfork()styleofprocesscreation.Anumber
offeatures—includingprocessreflectio ,whichisusedbytheWindowserror
reporting(WER)infrastructureduringprocesscrashes,aswellastheWindows
subsystem for Linux’s implementationof the Linux fork() API—depend on
thiscapability.
ThedebuggersupportintheprocessmanagerincludestheAPIstosuspend
and resume threads and to create threads that begin in suspended mode.
Therearealsoprocess-managerAPIsthatgetandsetathread’sregistercontext
and access another process’s virtual memory. Threads can be created in the
current process; they can also be injected into another process. The debugger
makesuseofthreadinjectiontoexecutecodewithinaprocessbeingdebugged.
Unfortunately,theabilitytoallocate,manipulate,andinjectbothmemoryand
threadsacrossprocessesisoftenmisusedbymaliciousprograms.
While running in the executive, a thread can temporarily attach to a dif-
ferent process. Thread attach is used by kernel worker threads that need to
executeinthecontextoftheprocessoriginatingaworkrequest.Forexample,
theMMmightusethreadattachwhenitneedsaccesstoaprocess’sworkingset
orpagetables,andtheI/Omanagermightuseitinupdatingthestatusvariable
inaprocessforasynchronousI/Ooperations.21.3 SystemComponents 861
21.3.5.4 FacilitiesforClient–ServerComputing
Like many other modern operating systems, Windows uses a client–server
model throughout, primarily as a layering mechanism, which allows putting
common functionality into a “service” (the equivalent of a daemon in UNIX
terms), as well as splitting out content-parsing code (such as a PDF reader or
Web browser) from system-action-capable code (such as the Web browser’s
capability to save a file on secondary storage or the PDF reader’s ability to
print out a document). For example, on a recent Windows 10 operating sys-
tem, opening the New York Times website with the Microsoft Edge browser
will likely result in 12 to 16 different processes in a complex organization of
“broker,”“renderer/parser,”“JITTer,”services,andclients.
The most basic such “server” on a Windows computer is the Win32 envi-
ronmentsubsystem,whichistheserverthatimplementstheoperating-system
personality of the Win32 API inherited from the Windows 95/98 days. Many
otherservices,suchasuserauthentication,networkfacilities,printerspooling,
Webservices,networkfilesystems,andplug-and-play,arealsoimplemented
usingthismodel.Toreducethememoryfootprint,multipleservicesareoften
collectedintoafewprocessesrunningthesvchost.exeprogram.Eachservice
isloadedasadynamic-linklibrary(DLL),whichimplementstheservicebyrely-
ingonuser-modethread-poolfacilitiestosharethreadsandwaitformessages
(see Section 21.3.5.3). Unfortunately, this pooling originally resulted in poor
user experience in troubleshooting and debugging runaway CPU usage and
memoryleaks,anditweakenedtheoverallsecurityofeachservice.Therefore,
inrecentversionsofWindows10,ifthesystemhasover2GBofRAM,eachDLL
servicerunsinitsownindividualsvchost.exeprocess.
InWindows,therecommendedparadigmforimplementingclient–server
computing is to use RPCs to communicate requests, because of their inher-
ent security, serialization services, and extensibility features. The Win32 API
supports the Microsoft standard of the DCE-RPC protocol, called MS-RPC, as
describedinSection21.6.2.7.
RPCusesmultipletransports(forexample,namedpipesandTCP/IP)that
can be used to implement RPCs between systems. When an RPC occurs only
between a client and a server on the local system, ALPC can be used as the
transport.Furthermore,becauseRPCisheavyweightandhasmultiplesystem-
level dependencies (including the WINXXIII environment subsystem itself),
manynativeWindowsservices,aswellasthekernel,directlyuseALPC,which
isnotavailable(norsuitable)forthird-partyprogrammers.
ALPC is a message-passing mechanism similar to UNIX domain sockets
andMachIPC.Theserverprocesspublishesagloballyvisibleconnection-port
object. When a client wants services from the server, it opens a handle to the
server’s connection-port object and sends a connection request to the port. If
theserveracceptstheconnection,thenALPCcreatesapairofcommunication-
portobjects,providingtheclient’sconnectAPIwithitshandletothepair,and
thenprovidingtheserver’sacceptAPIwiththeotherhandletothepair.
At this point, messages can be sent across communication ports as either
datagrams,whichbehavelikeUDPandrequirenoreply,orrequests,which
must receive a reply. The client and server can then use either synchronous
messaging, in which one side is always blocking (waiting for a request or
expecting a reply), or asynchronous messaging, in which the thread-pool862 Chapter21 Windows10
mechanism can be used to perform work whenever a request or reply is
received, without the need for a thread to block for a message. For servers
located in kernel mode, communication ports also support a callback mech-
anism, which allows an immediate switch to the kernel side (KT) of the user-
modethread(UT),immediatelyexecutingtheserver’shandlerroutine.
WhenanALPCmessageissent,oneoftwomessage-passingtechniquescan
bechosen.
1. Thefirsttechniqueissuitableforsmalltomedium-sizedmessages(below
64KB).Inthiscase,theport’skernelmessagequeueisusedasintermedi-
atestorage,andthemessagesarecopiedfromoneprocess,tothekernel,
to the other process. The disadvantage of this technique is the double
buffering,aswellasthefactthatmessagesremaininkernelmemoryuntil
theintendedreceiverconsumesthem.Ifthereceiverishighlycontended
or currently unavailable, this may result in megabytes of kernel-mode
memorybeinglockedup.
2. The second technique is for larger messages. In this case, a shared-
memorysectionobjectiscreatedfortheport.Messagessentthroughthe
port’s message queue contain a “message attribute,” called a data view
attribute, that refers to the section object. The receiving side “exposes”
thisattribute,resultinginavirtualaddressmappingofthesectionobject
and a sharing of physical memory. This avoids the need to copy large
messages or to buffer them in kernel-mode memory. The sender places
dataintothesharedsection,andthereceiverseesthemdirectly,assoon
asitconsumesamessage.
Manyotherpossiblewaysofimplementingclient–servercommunication
exist, such as by using mailslots, pipes, sockets, section objects paired with
events, window messages, and more. Each one has its uses, benefits, and
disadvantages.RPCandALPCremainthemostfullyfeatured,safe,secure,and
feature-rich mechanisms for such communication, however, and they are the
mechanismsusedbythevastmajorityofWindowsprocessesandservices.
21.3.5.5 I/OManager
TheI/Omanagerisresponsibleforalldevicedriversonthesystem,aswellas
forimplementinganddefiningthecommunicationmodelthatallowsdrivers
tocommunicate with eachother,with thekernel,andwith user-modeclients
and consumers. Additionally, as in UNIX-based operating systems, I/O is
alwaystargetedtoafil object,evenifthedeviceisnotafilesystem.TheI/O
manager in Windows allows device drivers to be “filtered” by other drivers,
creating a device stack through which I/O flows and which can be used to
modify, extend, or enhance the original request. Therefore, the I/O manager
alwayskeepstrackofwhichdevicedriversandfilterdriversareloaded.
Duetotheimportanceoffile-systemdrivers,theI/Omanagerhasspecial
supportforthemandimplementsinterfacesforloadingandmanagingfilesys-
tems.ItworkswiththeMMtoprovidememory-mappedfileI/Oandcontrols
the Windows cache manager, which handles caching for the entire I/O sys-
tem.TheI/Omanagerisfundamentallyasynchronous,providingsynchronous
I/O by explicitly waiting for an I/O operation to complete. The I/O manager21.3 SystemComponents 863
providesseveralmodelsofasynchronousI/Ocompletion,includingsettingof
events,updatingofastatusvariableinthecallingprocess,deliveryofAPCsto
initiatingthreads,anduseofI/Ocompletionports,whichallowasinglethread
to process I/O completions from many other threads. It also manages buffers
forI/Orequests.
Device drivers are arranged in a list for each device (called a driver or
I/O stack). Adriver is represented in the system as a driver object. Because
asingledrivercanoperateonmultipledevices,thedriversarerepresentedin
the I/O stack by a device object, which contains a link to the driver object.
Additionally,nonhardware driverscan use deviceobjects as a way to expose
differentinterfaces.Asanexample,thereareTCP6,UDP6,UDP,TCP,RawIp,and
RawIp6 deviceobjects owned by the TCP/IPdriverobject, even though these
don’trepresentphysicaldevices.Similarly,eachvolumeonsecondarystorage
isitsowndeviceobject,ownedbythevolumemanagerdriverobject.
Onceahandleisopenedtoadeviceobject,theI/Omanageralwayscreates
afileobjectandreturnsafilehandleinsteadofadevicehandle.Itthenconverts
the requests it receives (such as create, read, and write) into a standard form
calledanI/Orequestpacket(IRP).ItforwardstheIRPtothefirstdriverinthe
targeted I/O stack for processing. After a driver processes the IRP, it calls the
I/O manager either to forward the IRP to the next driver in the stack or, if all
processingisfinished,tocompletetheoperationrepresentedbytheIRP.
The I/O request may be completed in a context different from the one in
which it was made. For example, if a driver is performing its part of an I/O
operationandisforcedtoblockforanextendedtime,itmayqueuetheIRPto
a worker thread to continue processing in the system context. In the original
thread, the driver returns a status indicating that the I/O request is pending
so that the thread can continue executing in parallel with the I/O operation.
An IRP may also be processed in interrupt-service routines and completed in
anarbitraryprocesscontext. Becausesomefinal processing mayneedtotake
place inthe context that initiatedthe I/O, the I/O manager uses an APC todo
finalI/O-completionprocessingintheprocesscontextoftheoriginatingthread.
The I/O stack model is very flexible. As a driver stack is built, vari-
ous drivers have the opportunity to insert themselves into the stack as filte
drivers. Filter drivers can examine and potentially modify each I/O opera-
tion. Volume snapshotting (shadow copies) and disk encryption (BitLocker)
are two built-in examples of functionality implemented using filter drivers
that execute above the volume manager driver in the stack. File-system filter
driversexecuteabovethefilesystemandhavebeenusedtoimplementfunc-
tionalities such as hierarchical storage management, single instancing of files
for remote boot, and dynamic format conversion. Third parties also use file-
systemfilterdriverstoimplementanti-malwaretools.Duetothelargenumber
of file-system filters, Windows Server 2003 and later versions now include a
filte managercomponent, which actsasthesolefile-systemfilterand which
loadsminifilter orderedbyspecificaltitudes(relativepriorities).Thismodel
allowsfilterstotransparentlycachedataandrepeatedquerieswithouthaving
toknowabouteachother’srequests.Italsoprovidesstricterloadordering.
Device drivers for Windows are written to the Windows Driver Model
(WDM) specification. This model lays out all the requirements for device
drivers, including how to layer filter drivers, share common code for han-864 Chapter21 Windows10
dlingpowerandplug-and-playrequests,buildcorrectcancellationlogic,and
soforth.
Because of the richness of the WDM, writing a full WDM devicedriverfor
each new hardware device can involve a great deal of work. In some cases,
theport/miniportmodelmakesitunnecessarytodothisforcertainhardware
devices.Withinarangeofdevicesthatrequiresimilarprocessing,suchasaudio
drivers, storage controllers, or Ethernet controllers, each instance of a device
shares a common driver for that class, called a port driver. The port driver
implementsthestandardoperationsfortheclassandthencallsdevice-specific
routinesinthedevice’sminiportdrivertoimplementdevice-specificfunction-
ality.Thephysical-linklayerofthenetworkstackisimplementedinthisway,
with the ndis.sys port driver implementing much of the generic network
processing functionality and calling out to the network miniport drivers for
specifichardwarecommandsrelatedtosendingandreceivingnetworkframes
(suchasEthernet).
Similarly,theWDMincludesaclass/miniclassmodel.Here,acertainclass
ofdevicescanbeimplementedinagenericway byasingleclassdriver,with
callouts to a miniclass for specific hardware functionality. For example, the
Windows disk driver is a class driver, as are drivers for CD/DVDs and tape
drives.The keyboardand mouse driverareclass driversas well.Thesetypes
of devices don’t need a miniclass, but the battery class driver, for example,
doesrequireaminiclassforeachofthevariousexternaluninterruptiblepower
supplies(UPSs)soldbyvendors.
Even with the port/miniport and class/miniclass model, significant
kernel-facing code must be written. And this model is not useful for custom
hardware or for logical (nonhardware) drivers. Starting with Windows 2000
Service Pack 4, kernel-mode drivers can be written using the Kernel-Mode
Driver Framework (KMDF), which provides a simplified programming
model for drivers on top of WDM. Another option is the User-Mode Driver
Framework(UMDF),whichallowsdriverstobewritteninusermodethrough
areflecto driverinthekernelthatforwardstherequeststhroughthekernel’s
I/O stack. These two frameworks make up the Windows Driver Foundation
model, which has reached Version 2.1 in Windows 10 and contains a fully
compatible API between KMDF and UMDF. It has been fully open-sourced on
GitHub.
Becausemanydriversdonotneedtooperateinkernelmode,anditiseasier
todevelopanddeploydriversinusermode,UMDFisstronglyrecommended
fornewdrivers.Italsomakesthesystemmorereliable,becauseafailureina
user-modedriverdoesnotcauseakernel(system)crash.
21.3.5.6 CacheManager
Inmanyoperatingsystems,cachingisdonebytheblockdevicesystem,usually
at the physical/block level.Instead, Windows providesa centralizedcaching
facilitythatoperatesatthelogical/virtualfilelevel.Thecachemanagerworks
closely with the MM to provide cache services for all components under the
controloftheI/Omanager.Thismeansthatthecachecanoperateonanything
fromremotefilesonanetworksharetologicalfilesonacustomfilesystem.The
size of the cache changes dynamically according to how much free memory
is available in the system; it can grow as large as 2 TB on a 64-bit system.21.3 SystemComponents 865
The cache manager maintains a private working set rather than sharing the
systemprocess’sworkingset,whichallowstrimmingtopageoutcachedfiles
moreeffectively.Tobuildthecache,thecachemanagermemory-mapsfilesinto
kernelmemory and then uses special interfaces to the MM tofault pages into
or trim them from this private working set, which lets it take advantage of
additionalcachingfacilitiesprovidedbythememorymanager.
The cache is divided into blocks of 256 KB. Each cache block can hold a
view(thatis,amemory-mappedregion)ofafile.Eachcacheblockisdescribed
by a virtualaddress controlblock (VACB) that storesthe virtualaddressand
file offset for the view, as well as the number of processes using the view.
The VACBs reside in arrays maintained by the cache manager, and there are
arraysforcriticalaswellaslow-prioritycacheddatatoimproveperformance
insituationsofmemorypressure.
When the I/O manager receives a file’s user-level read request, the I/O
managersendsanIRPtotheI/Ostackforthevolumeonwhichthefileresides.
Forfilesthataremarkedascacheable,thefilesystemcallsthecachemanager
to look up the requested data in its cached file views. The cache manager
calculates which entry of that file’s VACB indexarray corresponds tothe byte
offset of the request. The entry either points to the view in the cache or is
invalid. If it is invalid, the cache manager allocates a cache block (and the
correspondingentryintheVACBarray)andmapstheviewintothecacheblock.
The cache manager then attempts to copy data from the mapped file to the
caller’sbuffer.Ifthecopysucceeds,theoperationiscompleted.
If the copy fails, it does so because of a page fault, which causes the MM
tosendanoncachedreadrequesttotheI/Omanager.TheI/Omanagersends
anotherrequestdownthedriverstack,thistimerequestingapagingoperation,
whichbypassesthecachemanagerandreadsthedatafromthefiledirectlyinto
thepageallocatedforthecachemanager.Uponcompletion,theVACBissetto
pointatthepage.Thedata,nowinthecache,arecopiedtothecaller’sbuffer,
and the original I/O request is completed. Figure 21.6 shows an overview of
theseoperations.
Whenpossible,forsynchronousoperationsoncachedfiles,I/Oishandled
bythefastI/Omechanism.ThismechanismparallelsthenormalIRP-basedI/O
process
I/O I/O manager
cached I/O
cache manager file system
data copy noncached I/O
page fault
VM manager disk driver
Figure21.6 FileI/O.866 Chapter21 Windows10
butcallsintothedriverstackdirectlyratherthanpassingdownanIRP,which
saves memory and time. Because no IRP is involved, the operation should
not block for an extended period of time and cannot be queued to a worker
thread. Therefore, when the operation reaches the file system and calls the
cachemanager,theoperationfailsiftheinformationisnotalreadyinthecache.
TheI/OmanagerthenattemptstheoperationusingthenormalIRPpath.
Akernel-levelreadoperationissimilar,exceptthatthedatacanbeaccessed
directly from the cache rather than being copied to a buffer in user space.
To use file-system metadata (data structures that describe the file system),
the kernel uses the cache manager’s mapping interface to read the metadata.
To modify the metadata, the file system uses the cache manager’s pinning
interface.Pinningapagelocksthepageintoaphysical-memorypageframeso
thattheMMmanagercannotmovethepageorpageitout.Afterupdatingthe
metadata,thefilesystemasksthecachemanagertounpinthepage.Amodified
pageismarkeddirty,andsotheMMflushesthepagetosecondarystorage.
Toimproveperformance,thecachemanagerkeepsasmallhistoryofread
requestsandfromthishistoryattemptstopredictfuturerequests.Ifthecache
manager finds a pattern in the previous three requests, such as sequential
access forward or backward, it prefetches data into the cache before the next
requestis submittedby the application.In this way,the applicationmay find
itsdataalreadycachedandnotneedtowaitforsecondarystorageI/O.
The cache manager is also responsible for telling the MM to flush the
contents of the cache. The cache manager’s default behavior is write-back
caching:itaccumulateswritesfor4to5secondsandthenwakesupthecache-
writerthread.Whenwrite-throughcachingisneeded,aprocesscansetaflag
whenopeningthefile,orcancallanexplicitcache-flushfunction.
Afast-writingprocesscouldpotentiallyfillallthefreecachepagesbefore
the cache-writer thread had a chance to wake up and flush the pages to sec-
ondarystorage.Thecachewriterpreventsaprocessfromfloodingthesystem
in the following way. When the amount of free cache memory becomes low,
thecachemanagertemporarilyblocksprocessesattemptingtowritedataand
wakesthecache-writerthreadtoflushpagestosecondarystorage.Ifthefast-
writing process is actually a network redirector for a network file system,
blocking it for too long could cause network transfers to time out and be
retransmitted. This retransmission would waste network bandwidth. To pre-
vent such waste, network redirectors can instruct the cache manager to limit
thebacklogofwritesinthecache.
Because a network file system needs to move data between secondary
storage and the network interface, the cache manager also provides a DMA
interface to move the data directly. Moving data directly avoids the need to
copydatathroughanintermediatebuffer.
21.3.5.7 SecurityReferenceMonitor
Centralizing management of system entities in the object manager enables
Windows touse auniform mechanism toperformrun-timeaccess validation
and audit checks for every user-accessible entity in the system. Additionally,
even entities not managed by the object manager may have access to the API
routinesforperformingsecuritychecks.Wheneverathreadopensahandleto
a protected data structure (such as an object), the security reference monitor21.3 SystemComponents 867
(SRM) checks the effective security token and the object’s security descriptor,
which contains two access-control lists—the discretionary access control list
(DACL) and the systemaccess control list (SACL)—to see whether the process
has the necessary access rights. The effective security token is typically the
tokenofthethread’sprocess,butitcanalsobethetokenofthethreaditself,as
describedbelow.
Each process has an associated security token. When the login process
(lsass.exe) authenticates a user, the security token is attached to the user’s
first process (userinit.exe) and copied for each of its child processes. The
tokencontainsthesecurityidentity(SID)oftheuser,theSIDsofthegroupsthe
userbelongsto,theprivilegestheuserhas,theintegrityleveloftheprocess,the
attributesandclaimsassociatedwiththeuser,andanyrelevantcapabilities.By
default,threadsdon’thavetheirownexplicittokens,causingthemtosharethe
commontokenoftheprocess.However,usingamechanismcalledimperson-
ation,athreadrunninginaprocesswithasecuritytokenbelongingtooneuser
can set a thread-specific token belonging to another user to impersonate that
user.Atthispoint,theeffectivetokenbecomesthetokenofthethread,andall
operations,quotas,andlimitationsaresubjecttothatuser’stoken.Thethread
canlaterchooseto“revert”toitsoldidentitybyremovingthethread-specific
token,sothattheeffectivetokenisonceagainthatoftheprocess.
This impersonation facility is fundamental to the client–server model,
where services must act on behalf of a variety of clients with different secu-
rity IDs. The right to impersonate a user is most often delivered as part of a
connectionfromaclientprocesstoaserverprocess.Impersonationallowsthe
servertoaccesssystemservicesasifitweretheclientinordertoaccessorcreate
objectsandfilesonbehalfoftheclient.Theserverprocessmustbetrustworthy
andmustbecarefullywrittentoberobustagainstattacks.Otherwise,oneclient
could take over a serverprocess and then impersonateany user who made a
subsequent client request. Windows provides APIs to support impersonation
at the ALPC (and thus RPC and DCOM) layer, the named pipe layer, and the
Winsocklayer.
The SRM is also responsible for manipulating the privileges in security
tokens.Specialprivilegesarerequiredforuserstochangethesystemtime,load
adriver,orchangefirmwareenvironmentvariables.Additionally,certainusers
canhavepowerfulprivilegesthatoverridedefaultaccesscontrolrules.These
includeuserswhomustperformbackuporrestoreoperationsonfilesystems
(allowingthemtobypassread/writerestrictions),debugprocesses(allowing
themtobypasssecurityfeatures),andsoforth.
Theintegritylevelofthecodeexecutinginaprocessisalsorepresentedby
atoken.Integritylevelsareatypeofmandatorylabelingmechanism,asmen-
tionedearlier.Bydefault,aprocesscannot modifyanobjectwithanintegrity
levelhigherthanthatofthecodeexecutingintheprocess,whateverotherper-
missions have beengranted.Inaddition,it cannot readfrom another process
objectatahigherintegritylevel.Objectscanalsoprotectthemselvesfromread
accessbymanuallychangingthemandatorypolicyassociatedwiththeirsecu-
ritydescriptor.Insideanobject(suchasafileoraprocess),theintegritylevelis
storedintheSACL,whichdistinguishesitfromtypicaldiscretionaryuserand
grouppermissions,storedintheDACL.
Integrity levels were introduced to make it harder for code to take over
a system by attacking external-content-parsing software, like a browser or868 Chapter21 Windows10
PDF reader, because such software is expected to run at a low integrity level.
For example, Microsoft Edge runs at “low integrity,” as do Adobe Reader
and Google Chrome. Aregular application, such as Microsoft Word, runs at
“mediumintegrity.”Finally,youcanexpectanapplicationrunbyanadminis-
tratororasetupprogramtorunat“highintegrity.”
Creatingapplicationstorunatlowerintegritylevelsplacesaburdenonthe
developerstoimplementthissecurityfeature,becausetheymustcreateaclient
–servermodeltosupportabrokerandparserorrenderer,asmentionedearlier.
Inordertostreamlinethissecuritymodel,Windows8introducedtheApplica-
tionContainer,oftenjustcalled“AppContainer,”whichisaspecialextension
of the token object. When running under an AppContainer, an application
automaticallyhasitsprocesstokenadjustedinthefollowingways:
1. The token’s integrity level is set to low. This means that the application
cannot write to or modify most objects (files, keys, processes) on the
system,norcanitreadfromanyotherprocessonthesystem.
2. All groups and the user SID are disabled (ignored) in the token. Let’s
saythattheapplicationwaslaunchedbyuserAnne,whobelongstothe
World group. Any files accessible to Anne or World will be inaccessible
tothisapplication.
3. Allprivilegesexceptahandfulareremovedfromthetoken.Thisprevents
powerfulsystemcallsorsystem-wideoperationsfrombeingpermitted.
4. AspecialAppContainerSIDisaddedtothetoken,whichcorrespondsto
theSHA-256hashoftheapplication’spackageidentifier.Thisistheonly
validsecurityidentifierinthetoken,soanyobjectwishingtobedirectly
accessible to this application needs to explicitly give the AppContainer
SIDreadorwriteaccess.
5. AsetofcapabilitySIDsareaddedtothetoken,basedontheapplication’s
manifest file. When the application is first installed, these capabilities
are shown to the user, who must agree to them before the application
isdeployed.
WecanseethattheAppContainermechanismchangesthesecuritymodel
from a discretionary system where access to protected resources is defined
by users and groups to a mandatory system where each application has its
ownuniquesecurityidentityandaccessoccursonaper-applicationbasis.This
separationofprivilegesandpermissionsisagreatleapforwardinsecurity,but
it places a potential burden on resource access. Capabilitiesand brokers help
toalleviatethisburden.
CapabilitiesareusedbysystembrokersimplementedbyWindowstoper-
formvariousactionsonbehalfofpackagedapplications.Forexample,assume
thatHarold’spackagedapplicationhasnoaccesstoHarold’sfilesystem,since
theHaroldSIDisdisabled.Inthissituation,abrokermightcheckforthePlay
User Media capability and allow the music player process to read any MP3
files located in Harold’s My Music directory. Thus, Harold will not be forced
tomarkallofhisfileswiththeAppContainerSIDofhisfavoritemediaplayer
application,aslongastheapplicationhasthePlay User Mediacapabilityand
Haroldagreedtoitwhenhedownloadedtheapplication.21.3 SystemComponents 869
Afinal responsibility of the SRM is logging security audit events. The ISO
standard Common Criteria (the international successor to the Orange Book
standarddevelopedbytheUnitedStatesDepartmentofDefense)requiresthat
asecuresystemhavetheabilitytodetectandlogallattemptstoaccesssystem
resources so that it can more easily trace attempts at unauthorized access.
BecausetheSRMisresponsibleformakingaccesschecks,itgeneratesmostof
theauditrecords,whicharethenwrittenbylsass.exeintothesecurity-event
log.
21.3.5.8 Plug-and-PlayManager
Theoperatingsystemusestheplug-and-play(PnP)managertorecognizeand
adapt to changes in hardware configuration. PnP devices use standard pro-
tocols to identify themselves to the system. The PnP manager automatically
recognizesinstalleddevicesanddetectschangesindevicesasthesystemoper-
ates. The manager also keeps track of hardware resources used by a device,
as well as potential resources that could be used, and takes care of loading
theappropriatedrivers.Thismanagementofhardwareresources—primarily
interrupts,DMAchannels,andI/Omemoryranges—hasthegoalofdetermin-
ingahardwareconfigurationinwhichalldevicesareabletooperatesuccess-
fully. The PnPmanager and the Windows Driver Model see drivers as either
bus drivers,whichdetectandenumeratethedevicesonabus(suchasPCIor
USB),orfunction drivers,whichimplementthefunctionalityofaparticular
deviceonthebus.
The PnP manager handles dynamic reconfiguration as follows. First, it
gets a list of devices from each bus driver. It loads the drivers and sends an
add-device request to the appropriate driver for each device. Working in
tandem with special resource arbiters owned by the various bus drivers,the
PnP manager then figures out the optimal resource assignments and sends
a start-device request to each driver specifying the resource assignments
fortherelateddevices.Ifadeviceneedstobereconfigured,thePnPmanager
sends a query-stop request, which asks the driver whether the device can
betemporarilydisabled.Ifthedrivercandisablethedevice,thenallpending
operations are completed, and new operations are prevented from starting.
Finally, the PnP manager sends a stop request and can then reconfigure the
devicewithanewstart-devicerequest.
The PnP manager also supports other requests. For example, query-
remove, which operates similarly to query-stop, is employed when a user
isgettingreadytoejectaremovabledevice,suchasaUSBstoragedevice.The
surprise-removerequestisusedwhenadevicefailsor,moreoften,whena
user removes a device without telling the system to stop it first. Finally, the
removerequesttellsthedrivertostopusingadevicepermanently.
Many programs in the system are interested in the addition or removal
ofdevices,sothePnPmanagersupportsnotifications.Suchanotification,for
example, gives the file manager the information it needs to update its list of
secondarystoragevolumeswhenanewstoragedeviceisattachedorremoved.
Installing devices can also result in starting new services on the system.
Previously, such services frequently set themselves up to run whenever the
system booted and continued to run even if the associated device was never
pluggedintothesystem,becausetheyhadtoberunninginordertoreceivethe870 Chapter21 Windows10
PnP notification. Windows 7 introduced a service-trigger mechanism in the
service control manager (SCM) (services.exe), which manages the system
services. With this mechanism, services can register themselves to start only
when SCM receives a notification from the PnP manager that the device of
interesthasbeenaddedtothesystem.
21.3.5.9 PowerManager
Windows works with the hardware to implementsophisticated strategiesfor
energy efficiency, as described in Section 21.2.8. The policies that drive these
strategiesareimplementedbythepowermanager.Thepowermanagerdetects
current system conditions, such as the load on CPUs or I/O devices, and
improves energy efficiency by reducing the performance and responsiveness
of the system when need is low. The power manager can also put the entire
systemintoaveryefficientsleep modeand can evenwriteall thecontents of
memorytosecondarystorageandturnoffthepowertoallowthesystemtogo
intohibernation.
Theprimaryadvantageofsleepisthatthesystemcanenterthatstatefairly
quickly,perhapsjustafewsecondsafterthelidclosesonalaptop.Thereturn
fromsleepisalsofairlyquick.Thepoweristurneddowntoalowlevelonthe
CPUsandI/Odevices,butthememorycontinuestobepoweredenoughthatits
contents are not lost. As noted earlier,however, on mobile devices,these few
secondsstilladduptoanunreasonableuserexperience,sothepowermanager
workswiththeDesktopActivityModeratortokickofftheConnectedStandby
state as soon as the screen is turned off. Connected Standby virtually freezes
thecomputerbutdoesnotreallyputthecomputertosleep.
Hibernation takes considerably longer to enter than sleep because the
entirecontentsofmemorymustbetransferredtosecondarystoragebeforethe
system is turned off. However, the fact that the system is, in fact, turned off
is a significant advantage. If there is a loss of power to the system, as when
the battery is swapped on a laptop or a desktop system is unplugged, the
saved system data will not be lost. Unlike shutdown, hibernation saves the
currentlyrunningsystemsoausercanresumewheresheleftoff.Furthermore,
because hibernation doesnot requirepower,asystemcan remaininhiberna-
tion indefinitely. Therefore, this feature is extremely useful on desktops and
server systems, and it is also used on laptops when the battery hits a critical
level(becauseputtingthesystemtosleepwhenthebatteryislowmightresult
inthelossofalldataifthebatteryrunsoutofpowerwhileinthesleepstate).
InWindows 7, the power manager alsoincludesa processorpower man-
ager(PPM),whichspecificallyimplementsstrategiessuchascoreparking,CPU
throttling and boosting, and more. In addition, Windows 8 introduced the
power framework (PoFX), which works with function drivers to implement
specificfunctionalpowerstates.Thismeansthatdevicescanexposetheirinter-
nalpowermanagement(clockspeeds,current/powerdraws,andsoforth)to
thesystem,whichcanthenusetheinformationforfine-grainedcontrolofthe
devices. Thus, for example, instead of simply turning a device on or off, the
systemcanturnspecificcomponentsonoroff.
Like the PnP manager, the power manager provides notifications to the
restofthesystemaboutchangesinthepowerstate.Someapplicationswantto
knowwhenthesystemisabouttobeshutdownsotheycanstartsavingtheir21.3 SystemComponents 871
statestosecondarystorage,and,asmentionedearlier,theDAMneedstoknow
whenthescreenisturnedoffandonagain.
21.3.5.10 Registry
Windowskeepsmuchofitsconfigurationinformationininternalrepositories
ofdata,calledhives,thataremanagedbytheWindowsconfigurationmanager,
commonlyknownastheregistry.Theconfigurationmanagerisimplemented
asacomponentoftheexecutive.
There are separate hives for system information, each user’s preferences,
software information, security, and boot options. Additionally, as part of
the new application and security model introduced by AppContainers and
UWPModern/Metropackaged applications inWindows 8, eachsuch applica-
tionhasitsownseparatehive,calledanapplicationhive.
Theregistryrepresentstheconfigurationstateineachhiveasahierarchical
namespaceofkeys(directories),eachofwhich can contain asetofarbitrarily
sized values. In the Win32 API, these values have a specific “type,” such as
UNICODE string, 32-bit integer, or untyped binary data, but the registry itself
treats all values the same, leaving it up to the higher API layers to infer a
structure based on type and size. Therefore, for example, nothing prevents a
“32-bitinteger”frombeinga999-byteUNICODEstring.
Intheory,newkeysandvaluesarecreatedandinitializedasnewsoftware
isinstalled,andthentheyaremodifiedtoreflectchangesintheconfiguration
of that software. In practice, the registry is often used as a general-purpose
database, as an interprocess-communication mechanism, and for many other
suchinventivepurposes.
Restarting applications, or even the system, every time a configuration
change was made would be a nuisance. Instead, programs rely on various
kinds of notifications, such as those provided by the PnP and power man-
agers, to learn about changes in the system configuration. The registry also
supplies notifications; threads can register to be notified when changes are
made to some part of the registry. The threads can thus detect and adapt to
configurationchangesrecordedintheregistry.Furthermore,registrykeysare
objectsmanagedbytheobjectmanager,andtheyexposeaneventobjecttothe
dispatcher.Thisallowsthreadstoputthemselvesinawaitingstateassociated
withtheevent,whichtheconfigurationmanagerwillsignalifthekey(orany
ofitsvalues)isevermodified.
Whenever significant changes are made to the system, such as when
updatestotheoperatingsystemordriversareinstalled,thereisadangerthat
the configuration data may be corrupted (for example, if a working driver is
replacedbyanonworkingdriveroranapplicationfailstoinstallcorrectlyand
leaves partial information in the registry). Windows creates a system restore
point before making such changes. The restore point contains a copy of the
hivesbeforethe change and canbe usedtoreturntothisversionofthehives
inordertogetacorruptedsystemworkingagain.
To improve the stability of the registry configuration, the registry also
implements a variety of “self-healing” algorithms, which can detect and fix
certain cases of registry corruption. Additionally, the registry internally uses
a two-phase commit transactional algorithm, which prevents corruption to
individualkeysorvaluesastheyarebeingupdated.Whilethesemechanisms872 Chapter21 Windows10
guaranteetheintegrityofsmallportionsoftheregistryorindividualkeysand
values,theyhavenotsupplantedthesystemrestorefacilityforrecoveringfrom
damage to the registry configuration caused by a failure during a software
installation.
21.3.5.11 Booting
The booting of a Windows PC begins when the hardware powers on and
firmware begins executing from ROM. In older machines, this firmware was
knownastheBIOS,butmoremodernsystemsuseUEFI(theUnifiedExtensible
FirmwareInterface),whichisfaster,ismoremodern,andmakesbetteruseof
thefacilitiesincontemporaryprocessors.Additionally,UEFIincludesafeature
called Secure Boot that provides integrity checks through digital signature
verification of all firmware and boot-time components. This digital signature
checkguaranteesthatonlyMicrosoft’sboot-timecomponentsandthevendor’s
firmwarearepresentatboottime,preventinganyearlythird-partycodefrom
loading.
Thefirmwarerunspower-onself-test(POST)diagnostics,identifiesmany
ofthedevicesattachedtothesystemandinitializesthemtoacleanpower-up
state, and then builds the descriptionused by ACPI. Next, the firmware finds
the system boot device, loads the Windows boot manager program (boot-
mgfw.efionUEFIsystems),andbeginsexecutingit.
In a machine that has been hibernating, the winresume.efi program is
loaded next. It restores the running system from secondary storage, and the
system continues execution at the point it had reached right before hibernat-
ing. In a machine that has been shut down, bootmgfw.efi performs further
initializationofthe systemand thenloadswinload.efi.This programloads
hal.dll, the kernel (ntoskrnl.exe) and its dependencies, and any drivers
needed in booting, and the system hive. winload then transfers execution to
thekernel.
The procedure is somewhat different on Windows 10 systems where Vir-
tual Secure Mode is enabled (and the hypervisor is turned on). Here, win-
load.efiwillinsteadloadhvloader.exeorhvloader.dll,whichinitializes
thehypervisorfirst.OnIntelsystems,thisishvix64.exe,whileAMDsystems
usehvax64.exe.ThehypervisorthensetsupVTL1(theSecureWorld)andVTL
0(theNormalWorld)andreturnstowinload.efi,whichnowloadsthesecure
kernel (securekernel.exe) and its dependencies. Then the secure kernel’s
entrypointiscalled,whichinitializesVTL1,afterwhichitreturnsbacktothe
loaderatVTL0,whichresumeswiththestepsdescribedabove.
Asthekernelinitializesitself,itcreatesseveralprocesses.Theidleprocess
serves as the container of all idle threads, so that system-wide CPU idle time
caneasilybecomputed.Thesystemprocesscontainsalloftheinternalkernel
workerthreadsandothersystemthreadscreatedbydriversforpolling,house-
keeping,andotherbackgroundwork.Thememorycompressionprocess,new
toWindows10,hasaworkingsetcomposedofcompressedstandbypagesused
bythestoremanagertoalleviatesystempressureandoptimizepaging.Finally,
ifVSMisenabled,thesecuresystemprocessrepresentsthefactthatthesecure
kernelisloaded.
The first user-mode process, which is also created by the kernel, is ses-
sion manager subsystem (SMSS), which is similar to the init (initialization)21.3 SystemComponents 873
process in UNIX. SMSS performs further initialization of the system, includ-
ing establishing the paging files and creating the initial user sessions. Each
session represents a logged-on user, except for session 0, which is used to
run system-wide background processes, such as lsass and services. Each
sessionisgivenitsowninstanceofanSMSSprocess,whichexitsoncetheses-
sioniscreated.Ineachofthesesessions,thisephemeralSMSSloadstheWin32
environment subsystem (csrss.exe) and its driver (win32k.sys). Then, in
each session other than 0, SMSS runs the winlogon process, which launches
logonui.Thisprocesscapturesusercredentialsinorderforlsasstologina
user,thenlaunchtheuserinitandexplorerprocess,whichimplementsthe
Windowsshell(startmenu,desktop,trayicons,notificationcenter,andsoon).
Thefollowinglistitemizessomeoftheseaspectsofbooting:
• SMSS completessysteminitializationand thenstartsup one SMSS for ses-
sion0andoneSMSSforthefirstloginsession(1).
• wininit runs in session 0 to initialize user mode and start lsass and
services.
• lsass,thesecuritysubsystem,implementsfacilitiessuchasauthentication
ofusers.IfusercredentialsareprotectedbyVSMthroughCredentialGuard,
thenlsaisoandbioisoarealsostartedasVTL1Trustletsbylsass.
• servicescontainstheservicecontrolmanager,orSCM,whichsupervises
all background activities in the system, including user-mode services. A
number of services will have registered to start when the system boots.
Otherswillbestartedonlyondemandorwhentriggeredbyaneventsuch
asthearrivalofadevice.
• csrss isthe Win32 environment subsystem process.It is started in every
session—mainly because it handles mouse and keyboard input, which
needstobeseparatedperuser.
• winlogonisrunineachWindowssessionotherthansession0tologona
userbylaunchinglogonui,whichpresentsthelogonuserinterface.
Starting with Windows XP, the system optimizes the boot process by
prefetchingpagesfromfilesonsecondarystoragebasedonpreviousbootsof
thesystem.Diskaccesspatternsatbootarealsousedtolayoutsystemfileson
disktoreducethenumberofI/Ooperationsrequired.Windows7reducedthe
processesnecessarytostartthesystembyallowingservicestostartonlywhen
needed,ratherthanatsystemstart-up.Windows 8furtherreducedboottime
by parallelizing all driver loads through a pool of worker threads in the PnP
subsystemandbysupportingUEFItomakeboot-timetransitionmoreefficient.
All of these approaches contributed to a dramatic reduction in system boot
time,buteventuallylittlefurtherimprovementwaspossible.
Toaddressboot-timeconcerns, especiallyonmobile systems,whereRAM
and cores are limited, Windows 8 also introduced Hybrid Boot. This feature
combineshibernation withasimplelogoffofthecurrentuser.Whentheuser
shutsdownthesystem,andallotherapplicationsandsessionshaveexited,the
system is returned to the logonui prompt and then is hibernated. When the
systemisturnedonagain,itresumesveryquicklytothelogonscreen,which874 Chapter21 Windows10
givesdriversachancetoreinitializedevicesandgivestheappearanceofafull
bootwhileworkisstilloccurring.
21.4 Terminal Services and Fast User Switching
Windows supports a GUI-based console that interfaces with the user viakey-
board, mouse, and display. Most systems also support audio and video. For
example,audioinputisusedbyCortana,Windows’svoice-recognitionandvir-
tualassistantsoftware,whichispoweredbymachinelearning.Cortanamakes
the system more convenient and can also increase its accessibility for users
withmotordisabilities.Windows7addedsupportformulti-touchhardware,
allowinguserstoinputdatabytouchingthescreenwithoneormorefingers.
Video-inputcapabilityisusedbothforaccessibilityandforsecurity:Windows
Hellois a securityfeature in which advanced 3D heat-sensing, face-mapping
camerasandsensorscanbeusedtouniquelyidentifytheuserwithoutrequir-
ingtraditionalcredentials.InnewerversionsofWindows10,eye-motionsens-
inghardware—inwhichmouseinputisreplacedbyinformationontheposi-
tionandgazeoftheeyeballs—canbeusedforaccessibility.Otherfutureinput
experiences will likely evolve from Microsoft’s HoloLens augmented-reality
product.
ThePCwas,ofcourse,envisionedasapersonalcomputer—aninherently
single-user machine. For some time, however, Windows has supported the
sharingofaPCamongmultipleusers.EachuserwhoisloggedonusingtheGUI
hasasessioncreatedtorepresenttheGUIenvironmenthewillbeusingandto
contain all the processes necessary to run his applications. Windows allows
multiple sessions to exist at the same time on a single machine. However,
clientversionsofWindowssupportonlyasingleconsole,consistingofallthe
monitors, keyboards, and mice connected to the PC. Only one session can be
connected to the console at a time. From the logon screen displayed on the
console, users can create new sessions or attach to an existing session. This
allows multiple users to share a single PC without having to log off and on
betweenusers.Microsoftcallsthisuseofsessionsfastuserswitching.macOS
hasasimilarfeature.
Auser on one PC can also create a new session or connect to an existing
sessiononanothercomputer,whichbecomesaremotedesktop.Theterminal
services feature (TS) makes the connection through a protocol called Remote
DesktopProtocol(RDP).Usersoftenemploythisfeaturetoconnecttoasession
on a work PC from a home PC. Remote desktops can also be used for remote
troubleshooting scenarios: a remote user can be invited to share a session
with the user logged on to the session on the console. The remote user can
watch the user’s actions and can even be given control of the desktop to
help resolve computing problems. This latter use of terminal services uses
the“mirroring”feature,wherethealternativeuserissharingthesamesession
insteadofcreatingaseparateone.
Many corporations use corporate systems maintained in data centers to
run all user sessions that access corporate resources, rather than allowing
userstoaccessthoseresourcesfromtheirPCs,byexclusivelydedicatingthese
machinesasterminalservers.Eachservercomputermayhandlehundredsof
remote-desktop sessions. This is a form of thin-client computing, in which21.5 FileSystem 875
individual computers rely on a server for many functions. Relying on data-
centerterminalserversimprovesthereliability,manageability,andsecurityof
corporatecomputingresources.
21.5 File System
The native file system in Windows is NTFS. It is used for all local volumes.
However,associatedUSBthumbdrives,flashmemoryoncameras,andexternal
storagedevicesmaybeformattedwiththe32-bitFATfilesystemforportability.
FAT is a much older file-system format that is understood by many systems
besides Windows, such as the software running on cameras. Adisadvantage
isthattheFATfilesystemdoesnotrestrictfileaccesstoauthorizedusers.The
onlysolutionforsecuringdatawithFATistorunanapplicationtoencryptthe
databeforestoringitonthefilesystem.
In contrast, NTFS uses ACLs to control access to individual files and sup-
portsimplicitencryptionofindividualfilesorentirevolumes(usingWindows
BitLocker feature). NTFS implements many other features as well, including
data recovery, fault tolerance, very large files and file systems, multiple data
streams,UNICODEnames,sparsefiles,journaling,volumeshadowcopies,and
filecompression.
21.5.1 NTFS Internal Layout
ThefundamentalentityinNTFSisthevolume.AvolumeiscreatedbytheWin-
dowslogicaldiskmanagementutilityandisbasedonalogicaldiskpartition.
Avolume may occupy aportion of a deviceor an entire device,or may span
several devices. The volume manager can protect the contents of the volume
withvariouslevelsofRAID.
NTFSdoesnotdealwithindividualsectorsofastoragedevicebutinstead
uses clusters as the units of storage allocation. The cluster size, which is a
power of 2, is configured when an NTFS file system is formatted. The default
cluster size is based on the volume size—4 KB for volumes larger than 2 GB.
Given the size of today’s storage devices, it may make sense to use cluster
sizeslargerthantheWindowsdefaultstoachievebetterperformance,although
theseperformancegainswillcomeattheexpenseofmoreinternalfragmenta-
tion.
NTFSuseslogicalcluster numbers(LCNs)asstorageaddresses.Itassigns
thembynumberingclustersfromthebeginningofthedevicetotheend.Using
this scheme, the system can calculate a physical storage offset (in bytes) by
multiplyingtheLCNbytheclustersize.
A file in NTFS is not a simple byte stream as it is in UNIX; rather, it is a
structured object consisting of typed attributes. Each attribute of a file is an
independentbytestreamthatcanbecreated,deleted,read,andwritten.Some
attribute types are standard for all files, including the file name (or names, if
thefilehasaliases,suchasanMS-DOSshort name),thecreationtime,andthe
securitydescriptorthatspecifiestheaccesscontrollist.Userdataarestoredin
dataattributes.
Mosttraditionaldatafileshaveanunnameddataattributethatcontainsall
the file’s data. However, additional data streams can be created with explicit
names. The IProp interfaces of the Component Object Model (discussed later876 Chapter21 Windows10
inthischapter)useanameddatastreamtostorepropertiesonordinaryfiles,
including thumbnails of images. In general, attributes can be added as nec-
essaryandareaccessedusinga file-name:attributesyntax.NTFSreturnsonly
thesizeoftheunnamedattributeinresponsetofile-queryoperations,suchas
whenrunningthedircommand.
EveryfileinNTFSisdescribedbyoneormorerecordsinanarraystoredina
specialfilecalledthemasterfiletable(MFT).Thesizeofarecordisdetermined
when the file system is created; it ranges from 1 to 4 KB. Small attributes
are stored in the MFT record itself and are called resident attributes. Large
attributes, such as the unnamed bulk data, are called nonresident attributes
and are stored in one or more contiguous extents on the device. Apointer to
eachextentisstoredintheMFTrecord.Forasmallfile,eventhedataattribute
may fit inside the MFT record. If a file has many attributes—or if it is highly
fragmented, so that many pointers are needed to point to all the fragments
—one record in the MFT might not be large enough. In this case, the file is
described by a record called the base fil record, which contains pointers to
overflowrecordsthatholdtheadditionalpointersandattributes.
EachfileinanNTFSvolumehasauniqueIDcalledafil reference.Thefile
reference is a 64-bit quantity that consists of a 48-bit file number and a 16-bit
sequencenumber.Thefilenumberistherecordnumber(thatis,thearrayslot)
inthe MFTthat describesthe file.Thesequencenumber is incrementedevery
time an MFT entry is reused. The sequence number enables NTFS to perform
internalconsistencychecks,suchascatchingastalereferencetoadeletedfile
aftertheMFTentryhasbeenreusedforanewfile.
21.5.1.1 NTFSB+Tree
AsinUNIX,theNTFSnamespaceisorganizedasahierarchyofdirectories.Each
directoryusesadatastructurecalledaB+treetostoreanindexofthefilenames
inthatdirectory.InaB+tree,thelengthofeverypathfromtherootofthetreeto
aleafisthesame,andthecostofreorganizingthetreeiseliminated.Theindex
root of a directory contains the top level of the B+ tree. For a large directory,
this top level contains pointers to disk extents that hold the remainder of the
tree. Each entry in the directory contains the name and file reference of the
file, as well as a copy of the update timestamp and file size taken from the
file’sresidentattributesintheMFT.Copiesofthisinformationarestoredinthe
directorysothatadirectorylistingcanbeefficientlygenerated.Becauseallthe
filenames,sizes,andupdatetimesareavailablefromthedirectoryitself,there
isnoneedtogathertheseattributesfromtheMFTentriesforeachofthefiles.
21.5.1.2 NTFSMetadata
TheNTFSvolume’smetadataareallstoredinfiles.ThefirstfileistheMFT.The
second file, which is used during recovery if the MFT is damaged, contains a
copy of the first 16 entries of the MFT. The next few files are also special in
purpose.Theyincludethefollowingfiles:
• Thelogfilerecordsallmetadataupdatestothefilesystem.
• Thevolumefilecontainsthenameofthevolume,theversionofNTFSthat
formatted the volume, and a bit that tells whether the volume may have21.5 FileSystem 877
beencorruptedandneedstobecheckedforconsistencyusingthechkdsk
program.
• Theattribute-definitio tableindicateswhichattributetypesareusedin
thevolumeandwhatoperationscanbeperformedoneachofthem.
• Therootdirectoryisthetop-leveldirectoryinthefile-systemhierarchy.
• Thebitmapfil indicateswhichclustersonavolumeareallocatedtofiles
andwhicharefree.
• Thebootfil containsthestartupcodeforWindowsandmustbelocatedat
aparticularsecondarystoragedeviceaddresssothatitcanbefoundeasily
byasimpleROMbootstraploader.Thebootfilealsocontainsthephysical
addressoftheMFT.
• Thebad-clusterfilekeepstrackofanybadareasonthevolume;NTFSuses
thisrecordforerrorrecovery.
Keeping all the NTFS metadata in actual files has a useful property. As
discussed in Section 21.3.5.6, the cache manager caches file data. Since all
the NTFS metadata reside in files, these data can be cached using the same
mechanismsusedforordinarydata.
21.5.2 Recovery
In many simple file systems, a power failure at the wrong time can damage
thefile-systemdatastructuressoseverelythattheentirevolumeisscrambled.
ManyUNIXfilesystems,includingUFSbutnotZFS,storeredundantmetadata
on the storage device, and they recover from crashes by using the fsck pro-
gram to check all the file-system data structures and restore them forcibly to
a consistent state. Restoring them often involves deleting damaged files and
freeing data clusters that had been written with user data but not properly
recordedinthefilesystem’smetadatastructures.Thischeckingcanbeaslow
processandcanresultinthelossofsignificantamountsofdata.
NTFStakesadifferentapproachtofile-systemrobustness.InNTFS,allfile-
systemdata-structureupdatesareperformedinsidetransactions.Beforeadata
structureisaltered,thetransactionwritesalogrecordthat contains redoand
undo information. Afterthe datastructure has been changed, the transaction
writesacommitrecordtothelogtosignifythatthetransactionsucceeded.
After a crash, the system can restore the file-system data structures to
a consistent state by processing the log records, first redoing the operations
for committed transactions (to be sure their changes reached the file system
datastructures)andthenundoingtheoperationsfortransactionsthatdidnot
commitsuccessfullybeforethecrash.Periodically(usuallyevery5seconds),a
checkpoint recordiswrittentothelog.The systemdoesnot needlogrecords
priortothecheckpointtorecoverfromacrash.Theycanbediscarded,sothe
logfiledoesnotgrowwithoutbounds.Thefirsttimeaftersystemstartupthat
anNTFSvolumeisaccessed,NTFSautomaticallyperformsfile-systemrecovery.
This scheme does not guarantee that all the user-file contents are correct
afteracrash.Itensuresonlythatthefile-systemdatastructures(themetadata
files)areundamagedandreflectsomeconsistentstatethatexistedpriortothe878 Chapter21 Windows10
crash.Itwouldbepossibletoextendthetransactionschemetocoveruserfiles,
andMicrosofttooksomestepstodothisinWindowsVista.
Thelogisstoredinthethirdmetadatafileatthebeginningofthevolume.
It is created with a fixed maximum size when the file system is formatted. It
hastwosections:theloggingarea,whichisacircularqueueoflogrecords,and
the restart area, which holds context information, such as the position in the
logging area where NTFS should start reading during a recovery. In fact, the
restart area holds two copies of its information, so recovery is still possible if
onecopyisdamagedduringthecrash.
The logging functionality is provided by the log-file service. In addition
towritingthelogrecordsandperformingrecoveryactions,thelog-fileservice
keepstrackofthefreespaceinthelogfile.Ifthefreespacegetstoolow,thelog-
fileservicequeuespendingtransactions,andNTFShaltsallnewI/Ooperations.
After the in-progress operations complete, NTFS calls the cache manager to
flushalldataandthenresetsthelogfileandperformsthequeuedtransactions.
21.5.3 Security
The security of an NTFS volume is derived from the Windows object model.
EachNTFSfilereferencesasecuritydescriptor,whichspecifiestheownerofthe
file,andanaccess-control list,which contains theaccess permissionsgranted
ordeniedtoeachuserorgrouplisted.EarlyversionsofNTFSusedaseparate
securitydescriptorasanattributeofeachfile.BeginningwithWindows2000,
the security-descriptor attribute points to a shared copy, with a significant
savings in storage space and caching space; many, many files have identical
securitydescriptors.
In normal operation, NTFS does not enforce permissions on traversal of
directories in file path names. However, for compatibility with POSIX, these
checks can be enabled. The latter option is inherently more expensive, since
modernparsingoffilepathnamesusesprefixmatchingratherthandirectory-
by-directoryparsingofpathnames.Prefixmatchingisanalgorithmthatlooks
upstringsinacacheandfindstheentrywiththelongestmatch—forexample,
anentryfor∖foo∖bar∖dirwouldbeamatchfor∖foo∖bar∖dir2∖dir3∖myfile.
The prefix-matching cache allows path-name traversal to begin much deeper
inthetree,savingmanysteps.Enforcingtraversalchecksmeansthattheuser’s
accessmustbecheckedateachdirectorylevel.Forinstance,ausermightlack
permission to traverse ∖foo∖bar, so starting at the access for ∖foo∖bar∖dir
wouldbeanerror.
21.5.4 Compression
NTFS can perform data compression on individual files or on all data files
in a directory. To compress a file, NTFS divides the file’s data into compres-
sion units, which are blocks of 16 contiguous clusters. When a compression
unit is written, a data-compression algorithm is applied.If the result fits into
fewerthan16clusters,thecompressedversionisstored.Whenreading,NTFS
can determine whether data have been compressed: if they have been, the
lengthofthestoredcompressionunitislessthan16clusters.Toimproveper-
formance when reading contiguous compression units, NTFS prefetches and
decompressesaheadoftheapplicationrequests.21.5 FileSystem 879
For sparse filesor files that contain mostly zeros,NTFSusesanother tech-
niquetosavespace.Clustersthatcontainonlyzerosbecausetheyhavenever
been written are not actually allocated or stored on storage devices. Instead,
gapsareleftinthesequenceofvirtual-clusternumbersstoredintheMFTentry
forthefile.Whenreadingafile,ifNTFSfindsagapinthevirtual-clusternum-
bers, it just zero-fills that portion of the caller’s buffer. This technique is also
usedbyUNIX.
21.5.5 Mount Points, Symbolic Links, and Hard Links
Mount points are a form of symbolic link specific to directories on NTFS that
wereintroducedinWindows2000.Theyprovideamechanismfororganizing
storagevolumesthat ismoreflexiblethantheuseofglobalnames(likedrive
letters).Amountpointisimplementedasasymboliclinkwithassociateddata
containingthetruevolumename.Ultimately,mountpointswillsupplantdrive
letterscompletely,buttherewillbealongtransitionduetothedependenceof
manyapplicationsonthedrive-letterscheme.
Windows Vista introduced support for a more general form of symbolic
links,similartothosefoundinUNIX.Thelinkscanbeabsoluteorrelative,can
point to objects that do not exist, and can point to both files and directories
evenacrossvolumes.NTFSalsosupportshardlinks,whereasinglefilehasan
entryinmorethanonedirectoryofthesamevolume.
21.5.6 Change Journal
NTFS keeps a journal describing all changes that have been made to the file
system.User-modeservicescanreceivenotificationsofchangestothejournal
and then identify what files have changed by reading from the journal. The
searchindexerserviceusesthechangejournaltoidentifyfilesthatneedtobe
re-indexed.The file-replication service uses it to identify files that need to be
replicatedacrossthenetwork.
21.5.7 Volume Shadow Copies
Windowsimplementsthecapabilityofbringingavolumetoaknownstateand
thencreatingashadowcopythatcanbeusedtobackupaconsistentviewof
thevolume.Thistechniqueisknownassnapshotsinsomeotherfilesystems.
Makingashadowcopyofavolumeisaformofcopy-on-write,whereblocks
modifiedafter theshadow copy is createdarestoredintheiroriginal form in
thecopy.Achievingaconsistentstateforthevolumerequiresthecooperation
of applications, since the system cannot know when the data used by the
application are in a stable state from which the application could be safely
restarted.
TheserverversionofWindowsusesshadowcopiestoefficientlymaintain
oldversionsoffilesstoredonfileservers.Thisallowsuserstoseedocuments
astheyexistedatearlierpointsintime.Ausercanthusrecoverfilesthatwere
accidentallydeletedorsimplylookatapreviousversionofthefile,allwithout
pullingoutbackupmedia.880 Chapter21 Windows10
21.6 Networking
Windows supports both peer-to-peer and client–server networking. It also
has facilities for network management. The networking components in Win-
dowsprovidedatatransport,interprocesscommunication,filesharingacross
anetwork,andtheabilitytosendprintjobstoremoteprinters.
21.6.1 Network Interfaces
TodescribenetworkinginWindows,wemustfirstmentiontwooftheinternal
networkinginterfaces:theNetworkDeviceInterfacespecificatio (NDIS)and
theTransportDriverInterface(TDI).TheNDISinterfacewasdevelopedin1989
byMicrosoftand3Comtoseparatenetworkadaptersfromtransportprotocols
so that either could be changed without affecting the other. NDIS resides at
the interface between the data-link and network layers in the ISO model and
enables many protocols to operate over many different network adapters. In
terms of the ISO model, the TDI is the interface between the transport layer
(layer4)andthesessionlayer(layer5).Thisinterfaceenablesanysession-layer
component to use any available transport mechanism. (Similar reasoning led
to the streams mechanism in UNIX.) The TDI supports both connection-based
andconnectionlesstransportandhasfunctionstosendanytypeofdata.
21.6.2 Protocols
Windows implements transport protocols as drivers. These drivers can be
loaded and unloaded from the system dynamically, although in practice the
system typically has to be rebooted after a change. Windows comes with
severalnetworkingprotocols.Next,wediscussanumberoftheseprotocols.
21.6.2.1 ServerMessageBlock
The Server Message Block (SMB) protocol was first introduced in MS-DOS
3.1. The system uses the protocol to send I/O requests over the network.
The SMB protocol has four message types. Session control messages are
commandsthatstartandendaredirectorconnectiontoasharedresourceatthe
server. Aredirector uses File messages to access files at the server. Printer
messages are used tosend datato a remoteprint queueand to receivestatus
informationfromthequeue,andMessagemessagesareusedtocommunicate
with another workstation. A version of the SMB protocol was published as
the Common Internet File System (CIFS) and is supported on a number of
operatingsystems.
21.6.2.2 TransmissionControlProtocol/InternetProtocol
Thetransmissioncontrolprotocol/Internetprotocol(TCP/IP)suitethatisused
on the Internet has become the de facto standard networking infrastructure.
Windows uses TCP/IP to connect to a wide variety of operating systems
and hardware platforms. The Windows TCP/IP package includes the simple
network-management protocol (SNMP), the dynamic host-configuration pro-
tocol(DHCP),andtheolderWindowsInternetnameservice(WINS).Windows
Vista introduced a new implementation of TCP/IP that supports both IPv4
andIPv6inthesamenetworkstack.Thisnewimplementationalsosupports21.6 Networking 881
offloadingofthenetworkstackontoadvancedhardwaretoachieveveryhigh
performanceforservers.
WindowsprovidesasoftwarefirewallthatlimitstheTCPportsthatcanbe
used by programs for network communication. Network firewalls are com-
monly implemented in routers and are a very important security measure.
Having a firewall built into the operating system makes a hardware router
unnecessary,anditalsoprovidesmoreintegratedmanagementandeasieruse.
21.6.2.3 Point-to-PointTunnelingProtocol
ThePoint-to-PointTunnelingProtocol(PPTP)isaprotocolprovidedbyWin-
dowstocommunicatebetweenremote-accessservermodulesrunningonWin-
dows server machines and other client systems that are connected over the
Internet. The remote-access servers can encrypt data sent over the connec-
tion, and they support multiprotocol virtual private networks (VPNs) on the
Internet.
21.6.2.4 HTTPProtocol
TheHTTPprotocolisusedtoget/putinformationusingtheWorldWideWeb.
Windows implements HTTP using a kernel-mode driver, so web servers can
operate with a low-overhead connection to the networking stack. HTTP is a
fairlygeneralprotocolthatWindowsmakesavailableasatransportoptionfor
implementingRPC.
21.6.2.5 Web-DistributedAuthoringandVersioningProtocol
Web-distributedauthoringandversioning(WebDAV)isanHTTP-basedproto-
col for collaborative authoring across a network. Windows builds a WebDAV
redirectorintothefilesystem.Beingbuiltdirectlyintothefilesystemenables
WebDAVtoworkwithotherfile-systemfeatures,suchasencryption.Personal
filescanthenbestoredsecurelyinapublicplace.BecauseWebDAVusesHTTP,
which is a get/put protocol, Windows has to cache the files locally so pro-
gramscanusereadandwriteoperationsonpartsofthefiles.
21.6.2.6 NamedPipes
Namedpipesareaconnection-orientedmessagingmechanism.Aprocesscan
usenamedpipestocommunicate withotherprocessesonthesamemachine.
Sincenamedpipesareaccessedthroughthefile-systeminterface,thesecurity
mechanismsusedforfileobjectsalsoapplytonamedpipes.TheSMBprotocol
supports named pipes, so named pipes can also be used for communication
betweenprocessesondifferentsystems.
The format of pipe names follows the Uniform Naming Convention
(UNC). A UNC name looks like a typical remote file name. The format is
∖∖server name∖share name∖x∖y∖z, where server name identifies a server
on the network; share name identifies any resource that is made available to
networkusers,suchasdirectories,files,namedpipes,andprinters;and∖x∖y∖z
isanormalfilepathname.882 Chapter21 Windows10
21.6.2.7 RemoteProcedureCalls
Remote procedure calls (RPCs), mentioned earlier, are client–server mecha-
nisms that enable an application on one machine to make a procedure call to
codeonanothermachine.Theclientcallsalocalprocedure—astubroutine—
whichpacksitsargumentsintoamessageandsendsthemacrossthenetwork
toaparticularserverprocess.Theclient-sidestubroutinethenblocks.Mean-
while, the server unpacks the message, calls the procedure, packs the return
resultsintoamessage,andsendsthembacktotheclientstub.Theclientstub
unblocks, receives the message, unpacks the results of the RPC, and returns
themtothecaller.Thispackingofargumentsissometimescalledmarshaling.
Theclientstubcodeandthedescriptorsnecessarytopackandunpacktheargu-
ments for an RPC are compiled from a specification written in the Microsoft
InterfaceDefinitio Language.
The Windows RPC mechanism follows the widely used distributed-
computing-environment standard for RPC messages, so programs written to
useWindowsRPCsarehighly portable.TheRPCstandardisdetailed.Ithides
many of the architectural differences among computers, such as the sizes
of binary numbers and the order of bytes and bits in computer words, by
specifyingstandarddataformatsforRPCmessages.
21.6.2.8 ComponentObjectModel
The Component Object Model (COM) is a mechanism for interprocess com-
munication that was developedfor Windows. ACOM object provides a well-
defined interface to manipulate the data in the object. For instance, COM is
theinfrastructureusedbyMicrosoft’sObjectLinkingandEmbedding(OLE)
technology for inserting spreadsheetsinto Microsoft Word documents. Many
WindowsservicesprovideCOMinterfaces.Inaddition,adistributedextension
calledDCOMcanbeusedoveranetworkutilizingRPCtoprovideatransparent
methodofdevelopingdistributedapplications.
21.6.3 Redirectors and Servers
InWindows, anapplicationcanuse theWindows I/OAPItoaccess filesfrom
aremotecomputerasthoughtheywerelocal,providedthat theremotecom-
puterisrunningaCIFSserversuchasthoseprovidedbyWindows.Aredirector
is the client-side object that forwards I/O requests to a remote system, where
theyaresatisfiedbyaserver.Forperformanceandsecurity,theredirectorsand
serversruninkernelmode.
Inmoredetail,accesstoaremotefileoccursasfollows:
1. TheapplicationcallstheI/Omanagertorequestthatafilebeopenedwith
afilenameinthestandardUNCformat.
2. The I/O manager builds an I/O request packet, as described in Section
21.3.5.5.
3. TheI/Omanagerrecognizesthattheaccessisforaremotefileandcallsa
drivercalledaMultipleUNCProvider(MUP).21.6 Networking 883
4. The MUP sends the I/O request packet asynchronously to all registered
redirectors.
5. Aredirector that can satisfy the request responds to the MUP. To avoid
askingalltheredirectorsthesamequestioninthefuture,theMUPusesa
cachetorememberwhichredirectorcanhandlethisfile.
6. Theredirectorsendsthenetworkrequesttotheremotesystem.
7. Theremote-systemnetworkdriversreceivetherequestandpassittothe
serverdriver.
8. Theserverdriverhandstherequesttotheproperlocalfile-systemdriver.
9. Theproperdevicedriveriscalledtoaccessthedata.
10. The results are returned to the server driver,which sends the data back
to the requesting redirector. The redirector then returns the data to the
callingapplicationviatheI/Omanager.
AsimilarprocessoccursforapplicationsthatusetheWin32networkAPI,rather
than the UNC services, except that a module called a multi-provider router is
usedinsteadofaMUP.
For portability, redirectors and servers use the TDI API for network trans-
port.Therequeststhemselvesareexpressedinahigher-levelprotocol,which
bydefaultistheSMBprotocoldescribedinSection21.6.2.Thelistofredirectors
ismaintainedinthesystemhiveoftheregistry.
21.6.3.1 DistributedFileSystem
UNC names are not always convenient, because multiple file servers may be
availabletoservethesamecontentandUNCnamesexplicitlyincludethename
oftheserver.Windowssupportsadistributedfile-syste (DFS)protocolthat
allowsanetworkadministratortoserveupfilesfrommultipleserversusinga
singledistributednamespace.
21.6.3.2 FolderRedirectionandClient-SideCaching
To improve the PC experience for users who frequently switch among com-
puters,Windowsallowsadministratorstogiveusersroamingprofile ,which
keepusers’preferencesandothersettingsonservers.Folderredirectionisthen
usedtoautomaticallystoreauser’sdocumentsandotherfilesonaserver.
This works well until one of the computers is no longer attached to the
network,aswhenausertakesalaptopontoanairplane.Togiveusersoff-line
access to their redirected files, Windows uses client-side caching (CSC). CSC
is also used when the computer is on-line to keep copies of the server files
on the local machine for better performance. The files are pushed up to the
serverastheyarechanged.Ifthecomputerbecomesdisconnected,thefilesare
stillavailable,and the updateofthe serveris deferreduntil the nexttimethe
computerisonline.884 Chapter21 Windows10
21.6.4 Domains
Manynetworkedenvironmentshavenaturalgroupsofusers,suchasstudents
inacomputerlaboratoryatschooloremployeesinonedepartmentinabusi-
ness. Frequently, we want all the members of the group to be able to access
sharedresourcesontheirvariouscomputersinthegroup.Tomanagetheglobal
accessrightswithinsuchgroups,Windowsusestheconceptofadomain.Pre-
viously, these domains had no relationship whatsoever to the domain-name
system (DNS) that maps Internet host names to IP addresses. Now, however,
theyarecloselyrelated.
Specifically,aWindowsdomainisagroupofWindowsworkstationsand
serversthatshareacommonsecuritypolicyanduserdatabase.SinceWindows
usestheKerberosprotocolfortrustandauthentication,aWindowsdomainis
the same thing as a Kerberos realm. Windows uses a hierarchical approach
for establishing trust relationships between related domains. The trust rela-
tionships are based on DNS and allow transitive trusts that can flow up and
down the hierarchy. This approach reduces the number of trusts requiredfor
n domains from n ∗ (n − 1) to O(n). The workstations in the domain trust
the domain controller to give correct information about the access rights of
each user (loaded into the user’s access token by lsaas). All users retain the
ability to restrict access to their own workstations, however, no matter what
anydomaincontrollermaysay.
21.6.5 Active Directory
Active Directory is the Windows implementation of Lightweight Directory-
Access Protocol (LDAP) services. Active Directory stores the topology infor-
mation about the domain, keeps the domain-based user and group accounts
andpasswords,andprovidesadomain-basedstoreforWindowsfeaturesthat
needit,suchasWindowsgrouppolicy.Administratorsusegrouppoliciesto
establish uniform standards for desktop preferences and software. For many
corporate information-technology groups, uniformity drastically reduces the
costofcomputing.
21.7 Programmer Interface
TheWin32APIisthefundamentalinterfacetothecapabilitiesofWindows.This
section describes five main aspects of the Win32API: access to kernel objects,
sharingofobjectsbetweenprocesses,processmanagement,interprocesscom-
munication,andmemorymanagement.
21.7.1 Access to Kernel Objects
The Windows kernel provides many services that application programs can
use. Application programs obtain these services by manipulating kernel
objects. A process gains access to a kernel object named XXX by calling the
CreateXXX function to open a handle to an instance of XXX. This handle is
unique to the process. Depending on which object is being opened, if the
Create() function fails, it may return 0, or it may return a special constant
named INVALID HANDLE VALUE.Aprocess can close any handle by calling the21.7 ProgrammerInterface 885
SECURITY ATTRIBUTES sa;
sa.nlength = sizeof(sa);
sa.lpSecurityDescriptor = NULL;
sa.bInheritHandle = TRUE;
HANDLE hSemaphore = CreateSemaphore(&sa, 1, 1, NULL);
WCHAR wszCommandline[MAX PATH];
StringCchPrintf(wszCommandLine, countof(wszCommandLine),
L"another process.exe %d", hSemaphore);
CreateProcess(L"another process.exe", wszCommandline,
NULL, NULL, TRUE, . . .);
Figure21.7 Codeenablingachildtoshareanobjectbyinheritingahandle.
CloseHandle()function,andthesystemmaydeletetheobjectifthecountof
handlesreferencingtheobjectinallprocessesdropstozero.
21.7.2 Sharing Objects Between Processes
Windows provides three ways to share objects between processes. The first
way is for a child process to inherit a handle to the object. When the parent
calls the CreateXXX function, the parent supplies a SECURITIES ATTRIBUTES
structure with the bInheritHandle field set to TRUE. This field creates an
inheritablehandle. Next,the child process iscreated,passing avalueof TRUE
to the CreateProcess() function’s bInheritHandle argument. Figure 21.7
shows a code sample that creates a semaphore handle inherited by a child
process.
Assuming the child process knows which handles are shared, the parent
andchildcanachieveinterprocesscommunicationthroughthesharedobjects.
In the example in Figure 21.7, the child process gets the value of the handle
from the first command-line argument and then shares the semaphore with
theparentprocess.
The second way to share objects is for one process to give the object a
namewhentheobjectiscreatedandforthesecondprocesstoopenthename.
This method has two drawbacks: Windows does not provide a way to check
whether an object with the chosen name already exists, and the object name
spaceisglobal,withoutregardtotheobjecttype.Forinstance,twoapplications
maycreateandshareasingleobjectnamed“foo”whentwodistinctobjects—
possiblyofdifferenttypes—weredesired.
Named objects have the advantage that unrelated processes can readily
sharethem.ThefirstprocesscallsoneoftheCreateXXXfunctionsandsupplies
a name as a parameter. The second process gets a handle to share the object
by calling OpenXXX() (or CreateXXX) with the same name, as shown in the
exampleinFigure21.8.
ThethirdwaytoshareobjectsisviatheDuplicateHandle()function.This
method requires some other method of interprocess communication to pass
theduplicatedhandle.Givena handletoa processand the valueofahandle
withinthatprocess,asecond processcangetahandletothesameobject and
thusshareit.AnexampleofthismethodisshowninFigure21.9.886 Chapter21 Windows10
// Process A
. . .
HANDLE hSemaphore = CreateSemaphore(NULL, 1, 1, L"MySEM1");
. . .
// Process B
. . .
HANDLE hSemaphore = OpenSemaphore(SEMAPHORE ALL ACCESS,
FALSE, L"MySEM1");
. . .
Figure21.8 Codeforsharinganobjectbynamelookup.
21.7.3 Process Management
InWindows,aprocessisaloadedinstanceofanapplicationandathreadisan
executable unit of code that can be scheduledby the kerneldispatcher. Thus,
a process contains one or more threads. A process is created when a thread
insomeotherprocesscallstheCreateProcess()API.Thisroutineloadsany
dynamiclinklibrariesusedbytheprocessand createsaninitialthreadinthe
process. Additional threads can be created by the CreateThread() function.
// Process A wants to give Process B access to a semaphore
// Process A
DWORD dwProcessBId; // must; from some IPC mechanism
HANDLE hSemaphore = CreateSemaphore(NULL, 1, 1, NULL);
HANDLE hProcess = OpenProcess(PROCESS DUP HANDLE, FALSE,
dwProcessBId);
HANDLE hSemaphoreCopy;
DuplicateHandle(GetCurrentProcess(), hSemaphore,
hProcess, &hSemaphoreCopy,
0, FALSE, DUPLICATE SAME ACCESS);
// send the value of the semaphore to Process B
// using a message or shared memory object
. . .
// Process B
HANDLE hSemaphore = // value of semaphore from message
// use hSemaphore to access the semaphore
. . .
Figure21.9 Codeforsharinganobjectbypassingahandle.21.7 ProgrammerInterface 887
Each thread is created with its own stack, which defaults to 1 MB unless
otherwisespecifiedinanargumenttoCreateThread().
21.7.3.1 SchedulingRule
Priorities in the Win32 environment are based on the native kernel (NT)
scheduling model, but not all priority values may be chosen. The Win32 API
usessixpriorityclasses:
1. IDLE PRIORITY CLASS(NTprioritylevel4)
2. BELOW NORMAL PRIORITY CLASS(NTprioritylevel6)
3. NORMAL PRIORITY CLASS(NTprioritylevel8)
4. ABOVE NORMAL PRIORITY CLASS(NTprioritylevel10)
5. HIGH PRIORITY CLASS(NTprioritylevel13)
6. REALTIME PRIORITY CLASS(NTprioritylevel24)
ProcessesaretypicallymembersoftheNORMAL PRIORITY CLASSunlessthe
parent of the process was of the IDLE PRIORITY CLASS or another class was
specified when CreateProcess was called. The priority class of a process is
the default for all threads that execute in the process. It can be changed with
the SetPriorityClass() function or by passing an argument to the start
command.Onlyuserswiththeincreaseschedulingpriorityprivilegecanmove
aprocessintotheREALTIME PRIORITY CLASS.Administratorsandpowerusers
havethisprivilegebydefault.
When a user is switching between interactive processes and workloads,
the system needs to schedule the appropriate threads so as to provide good
responsiveness,whichleadstoashorterquantumsofexecution.Yet,oncethe
user has chosen aparticular process, agood amount of throughput fromthis
particular process is also expected. For this reason, Windows has a special
schedulingruleforprocessesnotintheREALTIME PRIORITY CLASS.Windows
distinguishesbetweentheprocessassociatedwiththeforegroundwindowon
the screenand the other (background) processes.When aprocess moves into
theforeground,Windowsincreasestheschedulingquantumforallitsthreads
by a factor of 3; CPU-bound threads in the foreground process will run three
times longer than similar threads in background processes. Because server
systems always operate with a much larger quantum than client systems—
afactorof6—thisbehaviorisnotenabledforserversystems.Forbothtypesof
systems,however,the scheduling parameterscan be customized through the
appropriatesystemdialogorregistrykey.
21.7.3.2 ThreadPriorities
A thread starts with an initial priority determined by its class. The priority
canbealteredbytheSetThreadPriority()function. Thisfunctiontakesan
argumentthatspecifiesapriorityrelativetothebasepriorityofitsclass:
• THREAD PRIORITY LOWEST:base−2
• THREAD PRIORITY BELOW NORMAL:base−1888 Chapter21 Windows10
• THREAD PRIORITY NORMAL:base+0
• THREAD PRIORITY ABOVE NORMAL:base+1
• THREAD PRIORITY HIGHEST:base+2
Two other designations are also used to adjust the priority. Recall from
Section 21.3.4.3 that the kernel has two priority classes: 16–31 for the static
class and 1–15 for the variable class. THREAD PRIORITY IDLE sets the pri-
ority to 16 for static-priority threads and to 1 for variable-priority threads.
THREAD PRIORITY TIME CRITICAL sets the priority to 31 for real-time threads
andto15forvariable-prioritythreads.
The kernel adjusts the priority of a variable class thread dynamically
depending on whether the thread is I/O bound or CPU bound. The Win32
API providesamethodtodisablethisadjustmentviaSetProcessPriority-
Boost()andSetThreadPriorityBoost()functions.
21.7.3.3 ThreadSuspendandResume
Athreadcanbecreatedinasuspended stateorcanbeplacedinasuspended
statelaterbyuseoftheSuspendThread()function.Beforeasuspendedthread
can be scheduled by the kernel dispatcher, it must be moved out of the sus-
pended state by use of the ResumeThread() function. Both functions set a
countersothatifathreadissuspendedtwice,itmustberesumedtwicebefore
itcanrun.
21.7.3.4 ThreadSynchronization
Tosynchronizeconcurrentaccesstosharedobjectsbythreads,thekernelpro-
videssynchronizationobjects,suchassemaphoresandmutexes.Thesearedis-
patcherobjects,asdiscussedinSection21.3.4.3.Threadscanalsosynchronize
with kernelservicesoperating on kernel objects—such as threads,processes,
andfiles—becausethesearealsodispatcherobjects.Synchronizationwithker-
neldispatcherobjectscanbeachievedbyuseoftheWaitForSingleObject()
and WaitForMultipleObjects() functions; these functions wait for one or
moredispatcherobjectstobesignaled.
Anothermethodofsynchronizationisavailabletothreadswithinthesame
processthatwanttoexecutecodeexclusively.TheWin32criticalsectionobject
is a user-mode mutex object that can often be acquired and released without
enteringthekernel.Onamultiprocessor,aWin32critical sectionwillattempt
tospinwhilewaitingforacriticalsectionheldbyanotherthreadtobereleased.
Ifthespinningtakestoolong,theacquiringthreadwillallocateakernelmutex
andyielditsCPU.Criticalsectionsareparticularlyefficientbecausethekernel
mutex is allocated only when there is contention and then used only after
attempting to spin. Most mutexes in programs are never actually contended,
sothesavingsaresignificant.
Before using a critical section, some thread in the process must call
InitializeCriticalSection(). Each thread that wants to acquire the
mutex calls EnterCriticalSection() and then later calls LeaveCritical-
Section()toreleasethemutex.ThereisalsoaTryEnterCriticalSection()
function,whichattemptstoacquirethemutexwithoutblocking.21.7 ProgrammerInterface 889
For programs that want user-mode reader–writer locks rather than
mutexes, Win32 supports slim reader–writer (SRW) locks. SRW locks have
APIs similar to those for critical sections, such as InitializeSRWLock,
AcquireSRWLockXXX, and ReleaseSRWLockXXX, where XXX is either
Exclusive or Shared, depending on whether the thread wants write
access or only read access to the object protected by the lock. The Win32API
also supports condition variables, which can be used with either critical
sectionsorSRWlocks.
21.7.3.5 ThreadPool
Repeatedly creating and deleting threads can be expensive for applications
and services that perform small amounts of work in each instantiation. The
Win32threadpoolprovidesuser-modeprogramswiththreeservices:aqueue
towhichworkrequestsmaybesubmitted(viatheSubmitThreadpoolWork()
function),anAPIthatcanbeusedtobindcallbackstowaitablehandles(Regis-
terWaitForSingleObject()),andAPIstoworkwithtimers(CreateThread-
poolTimer()andWaitForThreadpoolTimerCallbacks())andtobindcall-
backstoI/Ocompletionqueues(BindIoCompletionCallback()).
The goal of using a thread pool is to increase performance and reduce
memoryfootprint.Threadsarerelativelyexpensive,andeachprocessorcanbe
executingonlyonethreadatatimenomatterhowmanythreadsareavailable.
Thethreadpoolattemptstoreducethenumberofrunnablethreadsbyslightly
delayingworkrequests(reusingeachthreadformanyrequests)whileprovid-
ingenoughthreadstoeffectivelyutilizethemachine’sCPUs.ThewaitandI/O-
and timer-callback APIs allow the thread pool to further reduce the number
of threads in a process, using far fewer threads than would be necessary if
a process were to devote separate threads to servicing each waitable handle,
timer,orcompletionport.
21.7.3.6 Fibers
A fibe is user-mode code that is scheduled according to a user-defined
schedulingalgorithm.Fibersarecompletelyauser-modefacility;thekernelis
notawarethattheyexist.ThefibermechanismusesWindowsthreadsasifthey
wereCPUs toexecute the fibers. Fibers arecooperativelyscheduled,meaning
that they are never preempted but must explicitly yield the thread on which
theyarerunning.Whenafiberyieldsathread,anotherfibercanbescheduled
onitbytherun-timesystem(theprogramminglanguagerun-timecode).
The system creates a fiber by calling either ConvertThreadToFiber()
or CreateFiber(). The primary difference between these functions is that
CreateFiber()doesnotbeginexecutingthefiberthatwascreated.Tobegin
execution, the application must call SwitchToFiber(). The application can
terminateafiberbycallingDeleteFiber().
Fibers are not recommended for threads that use Win32 APIs rather than
standardC-libraryfunctionsbecauseofpotentialincompatibilities.Win32user-
modethreadshaveathread-environmentblock(TEB)thatcontainsnumerous
per-threadfieldsusedbytheWin32APIs.FibersmustsharetheTEBofthethread
onwhichtheyarerunning.ThiscanleadtoproblemswhenaWin32interface
puts state information into the TEB for one fiber and then the information is890 Chapter21 Windows10
overwrittenbyadifferentfiber.FibersareincludedintheWin32APItofacilitate
the porting of legacy UNIX applications that were written for a user-mode
threadmodelsuchasPthreads.
21.7.3.7 User-ModeSchedulingUMSandConcRT
A new mechanism in Windows 7, user-mode scheduling (UMS), addressed
several limitations of fibers. As just noted, fibers are unreliable for executing
Win32APIs becausethey donot havetheirown TEBs. Whenathreadrunning
a fiber blocks in the kernel, the user scheduler loses control of the CPU for a
timeasthekerneldispatchertakesoverscheduling.Problemsmayresultwhen
fiberschangethekernelstateofathread,suchasthepriorityorimpersonation
token,orwhentheystartasynchronousI/O.
UMS provides an alternative model by recognizing that each Windows
thread is actually two threads: a kernel thread (KT) and a user thread (UT).
Each type of thread has its own stack and its own set of saved registers. The
KT and UT appear as a single thread to the programmer because UTs can
neverblockbutmustalwaysenterthekernel,whereanimplicitswitchtothe
corresponding KT takes place. UMS uses each UT’s TEB to uniquely identify
theUT.WhenaUTentersthekernel,anexplicitswitchismadetotheKTthat
correspondstotheUTidentifiedbythecurrentTEB.Thereasonthekerneldoes
not know which UT is running is that UTs can invokea user-modescheduler,
as fibers do. But in UMS, the scheduler switches UTs, including switching the
TEBs.
When a UT enters the kernel, its KT may block. When this happens, the
kernelswitchestoaschedulingthread,whichUMScallsaprimarythread,and
usesthisthreadtoreentertheuser-modeschedulersothatitcanpickanother
UTtorun.Eventually,ablockedKTwillcompleteitsoperationandbereadyto
returntousermode.SinceUMShasalreadyreenteredtheuser-modescheduler
to run a different UT, UMS queues the UT corresponding to the completed KT
toacompletionlistinusermode.Whentheuser-modeschedulerischoosing
anewUT toswitch to,it canexaminethe completionlistand treatany UT on
thelistasacandidateforscheduling.ThekeyfeaturesofUMSaredepictedin
Figure21.10.
Unlike fibers, UMS is not intended to be used directly by programmers.
Thedetailsofwritinguser-modeschedulerscanbeverychallenging,andUMS
doesnotincludesuchascheduler.Rather,theschedulerscomefromprogram-
ming language libraries that build on top of UMS. Microsoft Visual Studio
2010shippedwithConcurrencyRuntime(ConcRT),aconcurrentprogramming
framework for C++. ConcRT provides a user-mode scheduler together with
facilitiesfordecomposingprogramsintotasks,whichcanthenbescheduledon
theavailableCPUs.ConcRTprovidessupportforpar forstylesofconstructs,
aswellasrudimentaryresourcemanagementandtasksynchronizationprimi-
tives.However,asofVisualStudio2013,theUMSschedulingmodeisnolonger
availableinConcRT.Significantperformancemetricsshowedthattrueparallel
programs that are well written do not spend a large amount of time context-
switchingbetweentheirtasks.ThebenefitsthatUMSprovidedinthisspacedid
not outweigh the complexity of maintaining a separate scheduler—in some
cases,eventhedefaultNTschedulerperformedbetter.21.7 ProgrammerInterface 891
KT blocks
NTOS executive 0
KT 0 KT 1 KT 2 primary
trap code thread
thread parking
kernel
user
UT completion list
user-mode
UT
0 scheduler
only primary thread runs in user-mode
trap code switches to parked KT
KT blocks
__
primary returns to user-mode
KT unblocks and parks __ queue UT completion UT 1 UT 0
Figure21.10 User-modescheduling.
21.7.3.8 Winsock
WinsockistheWindowssocketsAPI.Winsockisasession-layerinterfacethatis
largelycompatiblewithBSDsocketsbuthassomeaddedWindowsextensions.
It provides a standardized interface to many transport protocols that may
have different addressing schemes, so that any Winsock application can run
onanyWinsock-compliantprotocolstack.Winsockunderwentamajorupdate
in Windows Vista to add tracing, IPv6 support, impersonation, new security
APIs,andmanyotherfeatures.
Winsock follows the Windows Open System Architecture (WOSA) model,
which provides a standard service provider interface (SPI) between applica-
tions and networking protocols. Applications can load and unload layered
protocols that build additional functionality, such as additional security, on
top of the transport protocol layers. Winsock supports asynchronous opera-
tionsandnotifications,reliablemulticasting,securesockets,andkernelmode
sockets.Italsosupportssimplerusagemodels,liketheWSAConnectByName()
function,whichacceptsthetargetasstringsspecifyingthenameorIPaddress
oftheserverandtheserviceorportnumberofthedestinationport.
21.7.4 IPC Using Windows Messaging
Win32 applications handle interprocess communication in several ways.
The typical high-performance way is by using local RPCs or named pipes.
Anotherisbyusingsharedkernelobjects,suchasnamedsectionobjects,anda
synchronizationobject,suchasanevent.YetanotherisbyusingtheWindows
messaging facility—an approach that is particularly popular for Win32
GUI applications. One thread can send a message to another thread or to a
windowbycallingPostMessage(),PostThreadMessage(),SendMessage(),
SendThreadMessage(),orSendMessageCallback().Postingamessageand
sendingamessagedifferinthisway:Thepostroutinesareasynchronous;they892 Chapter21 Windows10
return immediately,and the calling thread does not know when the message
isactuallydelivered.Thesendroutinesaresynchronous;theyblockthecaller
untilthemessagehasbeendeliveredandprocessed.
In addition to sending a message, a thread can send data with the mes-
sage. Since processes have separate address spaces, the data must be copied.
The system copies data by calling SendMessage()to send a message of type
WM COPYDATA with a COPYDATASTRUCT data structure that contains the length
andaddressofthedatatobetransferred.Whenthemessageissent,Windows
copiesthedatatoanewblockofmemoryandgivesthevirtualaddressofthe
newblocktothereceivingprocess.
Every Win32 GUI thread has its own input queue from which it receives
messages.IfaWin32applicationdoesnotcallGetMessage()tohandleevents
on its input queue, the queue fills up; and after about five seconds, the task
managermarkstheapplicationas“NotResponding.”Notethatmessagepass-
ingissubjecttotheintegritylevelmechanismintroducedearlier.Thus,apro-
cessmaynotsendamessagesuchasWM COPYDATAtoaprocesswithahigher
integritylevel,unlessaspecialWindowsAPIisusedtoremovetheprotection
(ChangeWindowMessageFilterEx).
21.7.5 Memory Management
TheWin32APIprovidesseveralwaysforanapplicationtousememory:virtual
memory,memory-mappedfiles,heaps,thread-localstorage,andAWEphysical
memory.
21.7.5.1 VirtualMemory
An application calls VirtualAlloc() to reserve or commit virtual memory
and VirtualFree() to de-commit or release the memory. These functions
enable the application to specify the virtual address at which the memory is
allocated. (Otherwise, a random address is selected, which is recommended
forsecurityreasons.)Thefunctionsoperateonmultiplesofthememorypage
size but, for historical reasons, always return memory allocated on a 64-KB
boundary. Examples of these functions appear in Figure 21.11. The Virtu-
alAllocEx()andVirtualFreeEx()functionscanbeusedtoallocateandfree
memory in aseparate process,while VirtualAllocExNuma()can be used to
leveragememorylocalityonNUMAsystems.
21.7.5.2 Memory-MappedFiles
Another way for an applicationto use memory is by memory-mappinga file
into its address space. Memory mapping is also a convenient way for two
processestosharememory:bothprocessesmapthesamefileintotheirvirtual
memory. Memory mapping is a multistage process, as you can see in the
exampleinFigure21.12.
Ifaprocesswantstomapsomeaddressspacejusttoshareamemoryregion
with another process, no file is needed. The process calls CreateFileMap-
ping()withafilehandleof0xffffffff,aparticularsize,and(optionally)a
name.Theresultingfile-mappingobjectcanbesharedbyinheritance,byname
lookup(ifitwasnamed),orbyhandleduplication.21.7 ProgrammerInterface 893
// reserve 16 MB at the top of our address space
PVOID pBuf = VirtualAlloc(NULL, 0x1000000,
MEM RESERVE | MEM TOP DOWN, PAGE READWRITE);
// commit the upper 8 MB of the allocated space
VirtualAlloc((LPVOID)((DWORD PTR)pBuf + 0x800000), 0x800000,
MEM COMMIT, PAGE READWRITE);
// do something with the memory
. . .
// now decommit the memory
VirtualFree((LPVOID)((DWORD PTR)pBuf + 0x800000), 0x800000,
MEM DECOMMIT);
// release all of the allocated address space
VirtualFree(pBuf, 0, MEM RELEASE);
Figure21.11 Codefragmentsforallocatingvirtualmemory.
21.7.5.3 Heaps
Heapsprovideathird way for applications touse memory,just as with mal-
loc() and free() in standard C or new() and delete() in C++. Aheap in
the Win32 environment is a region of pre-committed address space. When a
Win32processisinitialized,itiscreatedwithadefaultheap.SincemostWin32
// set the file mapping size to 8MB
DWORD dwSize = 0x800000;
// open the file or create it if it does not exist
HANDLE hFile = CreateFile(L"somefile.ext",
GENERIC READ | GENERIC WRITE,
FILE SHARE READ | FILE SHARE WRITE, NULL,
OPEN ALWAYS, FILE ATTRIBUTE NORMAL, NULL);
// create the file mapping
HANDLE hMap = CreateFileMapping(hFile,
PAGE READWRITE | SEC COMMIT, 0, dwSize, L"SHM 1");
// now get a view of the space mapped
PVOID pBuf = MapViewOfFile(hMap, FILE MAP ALL ACCESS,
0, 0, 0, dwSize);
// do something with the mapped file
. . .
// now unmap the file
UnmapViewOfFile(pBuf);
CloseHandle(hMap);
CloseHandle(hFile);
Figure21.12 Codefragmentsformemorymappingofafile.894 Chapter21 Windows10
applications are multithreaded, access to the heap is synchronized to protect
theheap’sspace-allocationdatastructuresfrombeingdamagedbyconcurrent
updatesbymultiplethreads.Theadvantageoftheheapisthatitcanbeused
tomakeallocationsassmallas1byte,becausetheunderlyingmemorypages
havealreadybeencommitted.Unfortunately,heapmemorycannotbeshared
or marked as read-only, because all heap allocations share the same pages.
However, by using HeapCreate(), a programmer can create his or her own
heap, which can be marked as read-only with HeapProtect(), created as an
executableheap,orevenallocatedonaspecificNUMAnode.
Win32providesseveralheap-managementfunctionssothataprocesscan
allocateandmanageaprivateheap.ThesefunctionsareHeapCreate(),Hea-
pAlloc(), HeapRealloc(), HeapSize(), HeapFree(), and HeapDestroy().
TheWin32APIalsoprovidestheHeapLock()andHeapUnlock()functionsto
enable a thread to gain exclusive access to a heap. Note that these functions
performonlysynchronization;theydonottruly“lock”pagesagainstmalicious
orbuggycodethatbypassestheheaplayer.
TheoriginalWin32heapwasoptimizedforefficientuseofspace.Thisledto
significantproblemswithfragmentationoftheaddressspaceforlargerserver
programs that ran for long periods of time. Anew low-fragmentation heap
(LFH) design introduced in Windows XP greatly reduced the fragmentation
problem. The heap manager in Windows 7 and later versions automatically
turns on LFH as appropriate. Additionally, the heap is a primary target of
attackers using vulnerabilities such as double-free, use-after-free, and other
memory-corruption-relatedattacks.EachversionofWindows,includingWin-
dows 10, has added more randomness, entropy, and security mitigations to
prevent attackers from guessing the ordering, size, location, and content of
heapallocations.
21.7.5.4 Thread-LocalStorage
Afourthwayforapplicationstousememoryisthroughathread-localstorage
(TLS) mechanism. Functions that rely on global or static data typically fail to
work properly in a multithreaded environment. For instance, the C run-time
function strtok() uses a static variable to keep track of its current position
while parsing a string. For two concurrent threads to execute strtok() cor-
rectly,theyneedseparatecurrent positionvariables.TLSprovidesawayto
maintain instances of variablesthat are global to the function being executed
butnotsharedwithanyotherthread.
TLS provides both dynamic and static methods of creating thread-local
storage.ThedynamicmethodisillustratedinFigure21.13.TheTLSmechanism
allocates global heap storage and attaches it to the thread environment block
(TEB) that Windows allocates to every user-mode thread. The TEB is readily
accessiblebyeachthreadandisusednotjustforTLSbutforalltheper-thread
stateinformationinusermode.
21.7.5.5 AWEMemory
AfinalwayforapplicationstousememoryisthroughtheAddressWindowing
Extension(AWE)functionality.Thismechanismallowsadevelopertodirectly21.8 Summary 895
// reserve a slot for a variable
DWORD dwVarIndex = T1sAlloc();
// make sure a slot was available
if (dwVarIndex == TLS OUT OF INDEXES)
return;
// set it to the value 10
T1sSetValue(dwVarIndex, (LPVOID)10);
// get the value
DWORD dwVar = (DWORD)(DWORD PTR)T1sGetValue(dwVarIndex);
// release the index
T1sFree(dwVarIndex);
Figure21.13 Codefordynamicthread-localstorage.
requestfreephysicalpagesofRAMfromthememorymanager(throughAllo-
cateUserPhysicalPages())and later commit virtual memory on top of the
physicalpagesusingVirtualAlloc().Byrequestingvariousregionsofphys-
ical memory (including scatter-gather support), a user-mode application can
accessmorephysicalmemorythanvirtualaddressspace;thisisusefulon32-bit
systems,whichmayhavemorethan4GBofRAM).Inaddition,theapplication
canbypassthememorymanager’scaching, paging,andcoloring algorithms.
Similar to UMS, AWE may thus offer a way for certain applications to extract
additional performance or customization beyond what Windows offers by
default.SQLServer,forexample,usesAWEmemory.
To use a thread-local static variable, the application declares the variable
asfollowstoensurethateverythreadhasitsownprivatecopy:
declspec(thread)DWORDcur pos = 0;
21.8 Summary
• Microsoft designedWindows tobean extensible,portableoperatingsys-
tem—oneabletotakeadvantageofnewtechniquesandhardware.
• Windowssupportsmultipleoperatingenvironmentsandsymmetricmul-
tiprocessing,includingboth32-bitand64-bitprocessorsand NUMAcom-
puters.
• Theuseofkernelobjectstoprovidebasicservices,alongwithsupportfor
client–server computing, enables Windows to support a wide variety of
applicationenvironments.
• Windows provides virtual memory, integrated caching, and preemptive
scheduling.896 Chapter21 Windows10
• Toprotectuserdataandguaranteeprogramintegrity,Windowssupports
elaborate security mechanisms and exploit mitigations and takes advan-
tageofhardwarevirtualization.
• Windows runs on a wide variety of computers, so users can choose and
upgradehardwaretomatchtheirbudgetsandperformancerequirements
withoutneedingtoaltertheapplicationstheyrun.
• By including internationalization features, Windows can run in a variety
ofcountriesandmanylanguages.
• Windows has sophisticated scheduling and memory-management algo-
rithmsforperformanceandscalability.
• Recent versions of Windows have added power management and fast
sleep and wake features, and decreased resource use in several areas to
bemoreusefulonmobilesystemssuchasphonesandtablets.
• The Windows volume manager and NTFS file system provide a sophisti-
catedsetoffeaturesfordesktopaswellasserversystems.
• The Win32API programming environment is feature rich and expansive,
allowingprogrammerstouseallofWindows’sfeaturesintheirprograms.
Practice Exercises
21.1 WhattypeofoperatingsystemisWindows?Describetwoofitsmajor
features.
21.2 ListthedesigngoalsofWindows.Describetwoindetail.
21.3 DescribethebootingprocessforaWindowssystem.
21.4 DescribethethreemainarchitecturallayersoftheWindowskernel.
21.5 Whatisthejoboftheobjectmanager?
21.6 Whattypesofservicesdoestheprocessmanagerprovide?
21.7 Whatisalocalprocedurecall?
21.8 WhataretheresponsibilitiesoftheI/Omanager?
21.9 What types of networking does Windows support? How does Win-
dows implement transport protocols? Describe two networking pro-
tocols.
21.10 HowistheNTFSnamespaceorganized?
21.11 HowdoesNTFShandledatastructures?HowdoesNTFSrecoverfrom
asystemcrash?Whatisguaranteedafterarecoverytakesplace?
21.12 HowdoesWindowsallocateusermemory?
21.13 Describesomeofthewaysinwhichanapplicationcanusememoryvia
theWin32API.FurtherReading 897
Further Reading
[Russinovichetal.(2017)]giveadeepoverviewofWindows10andconsider-
abletechnicaldetailaboutsysteminternalsandcomponents.
Bibliography
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).Exercises EX-60
Chapter 21 Exercises
21.14 Underwhatcircumstanceswouldoneusethedeferredprocedurecalls
facilityinWindows?
21.15 Whatisahandle,andhowdoesaprocessobtainahandle?
21.16 Describe the management scheme of the virtual memory manager.
HowdoestheVMmanagerimproveperformance?
21.17 Describeausefulapplicationoftheno-accesspagefacilityprovidedin
Windows.
21.18 Describe the three techniques used for communicating data in a local
procedurecall.Whatsettingsaremostconducivetotheapplicationof
thedifferentmessage-passingtechniques?
21.19 WhatmanagescachinginWindows?Howisthecachemanaged?
21.20 HowdoestheNTFSdirectorystructuredifferfromthedirectorystruc-
tureusedinUNIXoperatingsystems?
21.21 Whatisaprocess,andhowisitmanagedinWindows?
21.22 WhatisthefiberabstractionprovidedbyWindows?Howdoesitdiffer
fromthethreadabstraction?
21.23 How does user-mode scheduling (UMS) in Windows 7 differ from
fibers?Whataresometrade-offsbetweenfibersandUMS?
21.24 UMSconsidersathreadtohavetwoparts,aUTandaKT.Howmightit
beusefultoallowUTstocontinueexecutinginparallelwiththeirKTs?
21.25 What istheperformance trade-offofallowing KTs andUTs toexecute
ondifferentprocessors?
21.26 Whydoestheself-mapoccupylargeamountsofvirtualaddressspace
butnoadditionalvirtualmemory?
21.27 How does the self-mapmake it easy for the VMmanager tomovethe
page-tablepagestoandfromdisk?Wherearethepage-tablepageskept
ondisk?
21.28 When a Windows system hibernates, the system is powered off. Sup-
pose you changed the CPU or the amount of RAM on a hibernating
system.Doyouthinkthatwouldwork?Whyorwhynot?
21.29 Giveanexampleshowinghowtheuseofasuspendcountishelpfulin
suspendingandresumingthreadsinWindows.Part Ten
Appendices
ModernoperatingsystemssuchasLinux,macOS,andWindows10have
been influenced by earlier systems, and here we discuss some of the
olderandhighlyinfluentialoperatingsystems.
Some of these systems (such as the XDS-940 and the THE system)
were one-of-a-kind systems; others (such as OS/360) are widely used.
We briefly cover some of the older systems that are no longer in use.
We also provide comprehensive coverage of three additional systems:
Windows7,FreeBSD,andMach.Windows7remainsapopularoperating
system for many users. The FreeBSD system is another UNIX system.
However, whereas Linux combines features from several UNIX systems,
FreeBSD is based on the BSD model. FreeBSD source code, like Linux
source code, is freely available. Mach also provides compatibility with
BSDUNIX.WhatisespeciallyinterestingaboutBSDandMach isthat they
form the architecture of both iOS and macOS, two very popular modern
operatingsystems.Influential A
Appendix
Operating
Systems
Nowthatyouunderstandthefundamentalconceptsofoperatingsystems(CPU
scheduling,memorymanagement,processes,andsoon),weareinaposition
toexaminehowtheseconceptshavebeenappliedinseveralolderandhighly
influentialoperatingsystems.Someofthem(suchastheXDS-940andtheTHE
system)wereone-of-a-kindsystems;others(suchasOS/360)arewidelyused.
The order of presentation highlights the similarities and differences of the
systems;itisnotstrictlychronologicalororderedbyimportance.Theserious
studentofoperatingsystemsshouldbefamiliarwithallthesesystems.
Inthebibliographicalnotesattheendofthechapter,weincludereferences
tofurtherreadingabouttheseearlysystems.Thepapers,writtenbythedesign-
ersofthesystems,areimportantbothfortheirtechnicalcontentandfortheir
styleandflavor.
CHAPTER OBJECTIVES
• Explainhowoperating-systemfeaturesmigrateovertimefromlargecom-
putersystemstosmallerones.
(cid:129) Discussthefeaturesofseveralhistoricallyimportantoperatingsystems.
A.1 Feature Migration
Onereasontostudyearlyarchitecturesandoperatingsystemsisthatafeature
that once ran only on huge systems may eventually make its way into very
small systems. Indeed, an examination of operating systems for mainframes
and microcomputers shows that many features once available only on main-
frames have been adopted for microcomputers. The same operating-system
concepts are thus appropriate for various classes of computers: mainframes,
minicomputers,microcomputers,andhandhelds.Tounderstandmodernoper-
atingsystems,then,youneedtorecognizethethemeoffeaturemigrationand
thelonghistoryofmanyoperating-systemfeatures,asshowninFigureA.1.
AgoodexampleoffeaturemigrationstartedwiththeMultiplexedInforma-
tionandComputingServices(MULTICS)operatingsystem.MULTICSwasdevel-
12 AppendixA Influentia OperatingSystems
1950 1960 1970 1980 1990 2000 2010
MULTICS
mainframes
no compilers time distributed
software shared multiuser systems
batch multiprocessor
resident networked
fault tolerant
monitors
UNIX
minicomputers
no compilers
software
time multiuser multiprocessor
resident shared networked fault tolerant
monitors
clustered
UNIX
desktop computers
no compilers
software interactive multiprocessor
multiuser
networked
UNIX
handheld computers
no
compilers
software
interactive
networked LINUX
LINUX
smart phones
multiprocessor
networked
interactive
FigureA.1 Migrationofoperating-systemconceptsandfeatures.
opedfrom1965to1970attheMassachusettsInstituteofTechnology(MIT)asa
computingutility.Itranonalarge,complexmainframecomputer(theGE-645).
ManyoftheideasthatweredevelopedforMULTICSweresubsequentlyusedat
BellLaboratories(oneoftheoriginalpartnersinthedevelopmentofMULTICS)
inthe designofUNIX. The UNIX operatingsystemwas designedaround 1970
foraPDP-11minicomputer.Around1980,thefeaturesofUNIXbecamethebasis
for UNIX-like operating systems on microcomputers, and these features are
included in several more recent operating systems for microcomputers, such
as MicrosoftWindows, Windows XP,and themacOS operatingsystem.Linux
includessomeofthesesamefeatures,andtheycannowbefoundonPDAs.
A.2 Early Systems
Weturnourattentionnowtoahistoricaloverviewofearlycomputersystems.
We should note that the history of computing starts far before “computers”
withloomsandcalculators.Webeginourdiscussion,however,withthecom-
putersofthetwentiethcentury.
Before the 1940s, computing devices were designed and implemented to
performspecific,fixedtasks.Modifyingoneofthosetasksrequiredagreatdeal
ofeffortandmanuallabor.Allthatchangedinthe1940swhenAlanTuringand
JohnvonNeumann(andcolleagues),bothseparatelyandtogether,workedon
theideaofamoregeneral-purposestoredprogramcomputer.SuchamachineA.2 EarlySystems 3
has bothaprogramstoreand adatastore,wherethe programstoreprovides
instructionsaboutwhattodotothedata.
This fundamental computer concept quickly generated a number of
general-purpose computers, but much of the history of these machines is
blurredbytimeandthesecrecyoftheirdevelopmentduringWorldWarII.It
islikelythatthefirstworkingstored-programgeneral-purposecomputerwas
the Manchester Mark 1, which ran successfully in 1949. The first commercial
computer—the Ferranti Mark 1, which went on sale in 1951—was its
offspring.
Early computers were physically enormous machines run from consoles.
The programmer, who was also the operator of the computer system, would
writeaprogramandthenwouldoperateitdirectlyfromtheoperator’sconsole.
First,theprogramwouldbeloadedmanuallyintomemoryfromthefrontpanel
switches(one instructionatatime),frompapertape,orfrompunched cards.
Then the appropriate buttons would be pushed to set the starting address
and to start the execution of the program. As the program ran, the program-
mer/operatorcouldmonitoritsexecutionbythedisplaylightsontheconsole.
If errors were discovered, the programmer could halt the program, examine
the contents of memory and registers, and debug the program directly from
theconsole.Outputwasprintedorwaspunchedontopapertapeorcardsfor
laterprinting.
A.2.1 Dedicated Computer Systems
As time went on, additional software and hardware were developed. Card
readers, line printers, and magnetic tape became commonplace. Assemblers,
loaders, and linkers were designed to ease the programming task. Libraries
of common functions were created. Common functions could then be copied
into a new program without having to be written again, providing software
reusability.
TheroutinesthatperformedI/Owereespeciallyimportant.EachnewI/O
device had its own characteristics, requiring careful programming. Aspecial
subroutinecalledadevicedriver—waswrittenfor each I/Odevice.Adevice
driverknows how the buffers,flags, registers,control bits, and status bits for
a particular device should be used. Each type of device has its own driver.
A simple task, such as reading a character from a paper-tape reader, might
involvecomplexsequencesofdevice-specificoperations.Ratherthanwriting
the necessary code every time, the device driver was simply used from the
library.
Later,compilersforFORTRAN,COBOL,andotherlanguagesappeared,mak-
ingtheprogrammingtaskmucheasierbuttheoperationofthecomputermore
complex.ToprepareaFORTRANprogramforexecution,forexample,thepro-
grammer would first need to load the FORTRAN compiler into the computer.
Thecompilerwas normally kepton magnetictape,sothepropertapewould
needtobemountedonatapedrive.Theprogramwouldbereadthroughthe
card reader and written onto another tape. The FORTRAN compiler produced
assembly-language output, which then had to be assembled. This procedure
requiredmountinganothertapewiththeassembler.Theoutputoftheassem-
blerwouldneedtobelinkedtosupportinglibraryroutines.Finally,thebinary
objectformoftheprogramwouldbereadytoexecute.Itcouldbeloadedinto
memoryanddebuggedfromtheconsole,asbefore.4 AppendixA Influentia OperatingSystems
Asignificant amount ofsetup timecould be involvedintherunning ofa
job.Eachjobconsistedofmanyseparatesteps:
1. LoadingtheFORTRANcompilertape
2. Runningthecompiler
3. Unloadingthecompilertape
4. Loadingtheassemblertape
5. Runningtheassembler
6. Unloadingtheassemblertape
7. Loadingtheobjectprogram
8. Runningtheobjectprogram
If an error occurred during any step, the programmer/operator might have
to start over at the beginning. Each job step might involve the loading and
unloadingofmagnetictapes,papertapes,andpunchcards.
Thejobsetuptimewasarealproblem.Whiletapeswerebeingmountedor
the programmerwas operatingthe console, the CPUsat idle.Rememberthat,
in the early days, few computers were available, and they were expensive.A
computer might have cost millions of dollars, not including the operational
costs of power, cooling, programmers, and so on. Thus, computer time was
extremely valuable, and owners wanted their computers to be used as much
as possible. They needed high utilization to get as much as they could from
theirinvestments.
A.2.2 Shared Computer Systems
The solution was twofold. First, a professional computer operator was hired.
The programmer no longer operated the machine. As soon as one job was
finished,theoperatorcouldstartthenext.Sincetheoperatorhadmoreexperi-
ence with mounting tapes than a programmer, setup time was reduced. The
programmer provided whatever cards or tapes were needed, as well as a
short descriptionof how the jobwas to be run. Of course, the operator could
not debug an incorrect program at the console, since the operator would not
understand the program. Therefore, in the case of program error, a dump of
memoryandregisterswastaken,andtheprogrammerhadtodebugfromthe
dump. Dumping the memory and registers allowed the operator to continue
immediatelywiththenextjobbutlefttheprogrammerwiththemoredifficult
debuggingproblem.
Second,jobswithsimilarneedswerebatchedtogetherandrunthroughthe
computerasagrouptoreducesetuptime.Forinstance,supposetheoperator
receivedoneFORTRANjob,oneCOBOLjob,andanotherFORTRANjob.Ifsheran
theminthat order,she wouldhave tosetup forFORTRAN (loadthecompiler
tapesandsoon),thensetupforCOBOL,andthensetupforFORTRANagain.If
sheranthetwoFORTRANprogramsasabatch,however,shecouldsetuponly
onceforFORTRAN,savingoperatortime.A.2 EarlySystems 5
loader
monitor job sequencing
control card
interpreter
user
program
area
FigureA.2 Memorylayoutforaresidentmonitor.
Buttherewerestillproblems.Forexample,whenajobstopped,theoper-
ator would have to notice that it had stopped (by observing the console),
determine why it stopped (normal or abnormal termination), dump memory
andregister(ifnecessary),loadthe appropriatedevicewiththe nextjob, and
restart the computer. During this transition from one job to the next, the CPU
satidle.
Toovercomethisidletime,peopledevelopedautomaticjobsequencing.
With this technique, the first rudimentary operating systems were created.
A small program, called a resident monitor, was created to transfer control
automatically from one job to the next (Figure A.2). The resident monitor is
alwaysinmemory(orresident).
Whenthecomputerwasturnedon,theresidentmonitorwasinvoked,and
itwouldtransfercontroltoaprogram.Whentheprogramterminated,itwould
return control to the resident monitor, which would then go on to the next
program.Thus,theresidentmonitorwouldautomaticallysequencefromone
programtoanotherandfromonejobtoanother.
But how would the resident monitor know which program to execute?
Previously,theoperatorhadbeengivenashortdescriptionofwhatprograms
were to be run on what data. Control cards were introduced to provide this
information directly to the monitor. The idea is simple. In addition to the
program or data for a job, the programmer supplied control cards, which
contained directivesto the resident monitor indicating what program to run.
For example, a normal user program might require one of three programs to
run:theFORTRANcompiler(FTN),theassembler(ASM),ortheuser’sprogram
(RUN).Wecoulduseaseparatecontrolcardforeachofthese:
$FTN—ExecutetheFORTRANcompiler.
$ASM—Executetheassembler.
$RUN—Executetheuserprogram.
Thesecardstelltheresidentmonitorwhichprogramtorun.6 AppendixA Influentia OperatingSystems
We can use two additional control cards to define the boundaries of each
job:
$JOB—Firstcardofajob
$END—Finalcardofajob
Thesetwocardsmightbeusefulinaccountingforthemachineresourcesused
by the programmer. Parameters can be used to define the job name, account
numbertobecharged,andsoon.Othercontrolcardscanbedefinedforother
functions,suchasaskingtheoperatortoloadorunloadatape.
One problem with control cards is how to distinguish them from data or
programcards.Theusualsolutionistoidentifythembyaspecialcharacteror
pattern on the card. Several systems used the dollar-sign character ($) in the
firstcolumntoidentifyacontrolcard.Othersusedadifferentcode.IBM’sJob
ControlLanguage(JCL)usedslashmarks(//)inthefirsttwocolumns.Figure
A.3showsasamplecard-decksetupforasimplebatchsystem.
Aresidentmonitorthushasseveralidentifiableparts:
• The control-card interpreter is responsible for reading and carrying out
theinstructionsonthecardsatthepointofexecution.
• The loaderis invokedby the control-card interpretertoload systempro-
gramsandapplicationprogramsintomemoryatintervals.
• The device drivers are used by both the control-card interpreter and the
loader for the system’s I/O devices. Often, the system and application
programsarelinkedtothesesamedevicedrivers,providingcontinuityin
theiroperation,aswellassavingmemoryspaceandprogrammingtime.
Thesebatchsystemsworkfairlywell.Theresidentmonitorprovidesauto-
matic job sequencing as indicated by the control cards. When a control card
indicatesthataprogramistoberun,themonitorloadstheprogramintomem-
oryandtransferscontroltoit.Whentheprogramcompletes,ittransferscontrol
$END
data for program
$RUN
$LOAD
program to be compiled
$FTN
$JOB
FigureA.3 Carddeckforasimplebatchsystem.A.2 EarlySystems 7
back to the monitor, which reads the next control card, loads the appropriate
program,andsoon.Thiscycleisrepeateduntilallcontrolcardsareinterpreted
forthejob.Thenthemonitorautomaticallycontinueswiththenextjob.
The switch to batch systems with automatic job sequencing was made to
improveperformance. The problem, quite simply, is that humans are consid-
erablyslowerthancomputers.Consequently,itisdesirabletoreplacehuman
operation with operating-system software. Automatic job sequencing elimi-
natestheneedforhumansetuptimeandjobsequencing.
Evenwith this arrangement, however, the CPU is often idle.The problem
is the speed of the mechanical I/O devices, which are intrinsically slower
than electronic devices. Even a slow CPU works in the microsecond range,
with thousands of instructions executed per second. A fast card reader, in
contrast,mightread1,200cardsperminute(or20cardspersecond).Thus,the
differenceinspeedbetweentheCPUanditsI/Odevicesmaybethreeordersof
magnitudeormore.Overtime,ofcourse,improvementsintechnologyresulted
infasterI/Odevices.Unfortunately,CPUspeedsincreasedevenfaster,sothat
theproblemwasnotonlyunresolvedbutalsoexacerbated.
A.2.3 Overlapped I/O
One common solution to the I/O problem was to replace slow card readers
(input devices) and line printers (output devices) with magnetic-tape units.
Most computer systems in the late 1950s and early 1960s were batch systems
readingfromcardreadersandwritingtolineprintersorcardpunches.TheCPU
didnotreaddirectlyfromcards,however;instead,thecardswerefirstcopied
ontoamagnetictapeviaaseparatedevice.Whenthetapewassufficientlyfull,
itwastakendownandcarriedovertothecomputer.Whenacardwasneeded
forinputtoaprogram,theequivalentrecordwasreadfromthetape.Similarly,
outputwaswrittentothetape,andthecontentsofthetapewereprintedlater.
The card readers and line printers were operated off-line, rather than by the
maincomputer(FigureA.4).
An obvious advantage of off-line operation was that the main computer
was no longer constrained by the speed of the card readers and line printers
but was limited only by the speed of the much faster magnetic tape units.
The technique of using magnetic tape for all I/O could be applied with any
on-line
CPU
card reader line printer
(a)
on-line
CPU
card reader tape drives tape drives line printer
(b)
FigureA.4 OperationofI/Odevices(a)on-lineand(b)off-line.8 AppendixA Influentia OperatingSystems
similar equipment (such as card readers, card punches, plotters, paper tape,
andprinters).
The real gain in off-line operation comes from the possibility of using
multiple reader-to-tape and tape-to-printer systems for one CPU. If the CPU
can processinput twiceas fast asthe readercan readcards,thentworeaders
workingsimultaneouslycanproduceenoughtapetokeeptheCPUbusy.There
isadisadvantage,too,however—alongerdelayingettingaparticularjobrun.
Thejobmustfirstbereadontotape.Thenitmustwaituntilenoughadditional
jobsarereadontothetapeto“fill”it.Thetapemustthenberewound,unloaded,
hand-carriedtotheCPU,andmountedonafreetapedrive.Thisprocessisnot
unreasonable for batch systems, of course. Many similar jobs can be batched
ontoatapebeforeitistakentothecomputer.
Although off-line preparation of jobs continued for some time, it was
quicklyreplacedinmostsystems.Disksystemsbecamewidelyavailableand
greatly improved on off-line operation. One problem with tape systems was
that the card reader could not write onto one end of the tape while the CPU
read from the other. The entire tape had to be written before it was rewound
andread,becausetapesarebynaturesequential-accessdevices.Disksystems
eliminatedthisproblembybeingrandom-accessdevices.Becausetheheadis
movedfromoneareaofthedisktoanother,itcanswitchrapidlyfromthearea
on the disk being used by the card reader to store new cards to the position
neededbytheCPUtoreadthe“next”card.
Inadisksystem,cardsarereaddirectlyfromthecardreaderontothedisk.
Thelocationofcardimagesisrecordedinatablekeptbytheoperatingsystem.
When a job is executed, the operating system satisfies its requests for card-
reader input by reading from the disk. Similarly, when the job requests the
printertooutputaline,thatlineiscopiedintoasystembufferandiswritten
to the disk. When the job is completed, the output is actually printed. This
formofprocessingiscalledspooling(FigureA.5);thenameisanacronymfor
simultaneousperipheraloperationon-line.Spooling,inessence,usesthedisk
asahugebufferforreadingasfaraheadaspossibleoninputdevicesandfor
storingoutputfilesuntiltheoutputdevicesareabletoacceptthem.
disk
I/O
on-line
CPU
card reader line printer
FigureA.5 Spooling.A.3 Atlas 9
Spooling is also used for processing data at remote sites. The CPU sends
the data via communication paths to a remote printer (or accepts an entire
inputjobfromaremotecardreader).Theremoteprocessingisdoneatitsown
speed, with no CPU intervention. The CPU just needs to be notified when the
processingiscompleted,sothatitcanspoolthenextbatchofdata.
Spooling overlaps the I/O of one job with the computation of other jobs.
Eveninasimplesystem,thespoolermaybereadingtheinputofonejobwhile
printingtheoutputofadifferentjob.Duringthistime,stillanotherjob(orother
jobs)maybeexecuted,readingits“cards”fromdiskand“printing”itsoutput
linesontothedisk.
Spooling has a direct beneficial effect on the performance of the system.
For the cost of some disk space and a few tables, the computation of one job
and the I/O of other jobs can take place at the same time. Thus, spooling can
keepboththeCPUandtheI/Odevicesworkingatmuchhigherrates.Spooling
leads naturally to multiprogramming, which is the foundation of all modern
operatingsystems.
A.3 Atlas
The Atlas operating system was designed at the University of Manchester in
Englandinthelate1950sandearly1960s.Manyofitsbasicfeaturesthatwere
novel at the time have become standard parts of modern operating systems.
Devicedriverswereamajorpartofthesystem.Inaddition,systemcallswere
addedbyasetofspecialinstructionscalledextracodes.
Atlas was a batch operating system with spooling. Spooling allowed the
systemtoschedulejobsaccordingtotheavailabilityofperipheraldevices,such
asmagnetictapeunits,papertapereaders,papertapepunches,lineprinters,
cardreaders,andcardpunches.
ThemostremarkablefeatureofAtlas,however,wasitsmemorymanage-
ment. Core memory was new and expensive at the time. Many computers,
like the IBM 650, used a drum for primary memory. The Atlas system used a
drumforitsmainmemory,butithadasmallamountofcorememorythatwas
usedasacacheforthedrum.Demandpagingwasusedtotransferinformation
betweencorememoryandthedrumautomatically.
The Atlas system used a British computer with 48-bit words. Addresses
were 24 bits but were encoded in decimal, which allowed 1 million words to
be addressed. At that time, this was an extremely large address space. The
physicalmemoryfor Atlaswas a98-KB-word drumand16-KB wordsofcore.
Memory was divided into 512-word pages, providing 32 frames in physical
memory. An associative memory of 32 registers implemented the mapping
fromavirtualaddresstoaphysicaladdress.
Ifapagefaultoccurred,apage-replacementalgorithmwasinvoked.One
memory frame was always kept empty, so that a drum transfer could start
immediately. The page-replacement algorithm attempted to predict future
memory-accessing behavior based on past behavior. Areference bit for each
framewassetwhenevertheframewasaccessed.Thereferencebitswereread
intomemoryevery1,024instructions,andthelast32valuesofthesebitswere
retained. This history was used to define the time since the most recent ref-10 AppendixA Influentia OperatingSystems
erence (t ) and the interval between the last two references (t ). Pages were
1 2
chosenforreplacementinthefollowingorder:
1. Any page with t > t + 1 is considered to be no longer in use and is
1 2
replaced.
2. Ift ≤t forallpages,thenreplacethepagewiththelargestvaluefort
1 2 2
−t .
1
The page-replacement algorithm assumes that programs access memory in
loops.Ifthetimebetweenthelasttworeferencesist ,thenanotherreferenceis
2
expectedt timeunitslater.Ifareferencedoesnotoccur(t >t ),itisassumed
2 1 2
that the page is no longer being used, and the page is replaced. If all pages
are still in use, then the page that will not be needed for the longest time is
replaced.Thetimetothenextreferenceisexpectedtobet −t .
2 1
A.4 XDS-940
The XDS-940operatingsystemwas designedat the UniversityofCaliforniaat
Berkeleyintheearly1960s.LiketheAtlassystem,itusedpagingformemory
management.UnliketheAtlassystem,itwasatime-sharedsystem.Thepaging
was usedonlyfor relocation;itwas notusedfor demandpaging.Thevirtual
memoryofanyuserprocesswasmadeupof16-KBwords,whereasthephysical
memorywasmadeupof64-KBwords.Eachpagewasmadeupof2-KBwords.
The page table was kept in registers. Since physical memory was larger than
virtualmemory,severaluserprocessescouldbeinmemoryatthesametime.
The number of users could be increased by page sharing when the pages
containedread-onlyreentrantcode.Processeswerekeptonadrumandwere
swappedinandoutofmemoryasnecessary.
The XDS-940 system was constructed from a modified XDS-930. The mod-
ifications were typical of the changes made to a basic computer to allow an
operating system to be written properly. A user-monitor mode was added.
Certain instructions, such as I/O and halt, were defined to be privileged. An
attempt to execute a privileged instruction in user mode would trap to the
operatingsystem.
Asystem-callinstructionwasaddedtotheuser-modeinstructionset.This
instructionwasusedtocreatenewresources,suchasfiles,allowingtheoperat-
ingsystemtomanagethephysicalresources.Files,forexample,wereallocated
in 256-word blocks on the drum. A bitmap was used to manage free drum
blocks. Each file had an index block with pointers to the actual data blocks.
Indexblockswerechainedtogether.
The XDS-940 system also provided system calls to allow processes to cre-
ate,start,suspend,and destroysubprocesses.Aprogrammercould construct
a system of processes.Separateprocesses could share memory for communi-
cationandsynchronization.Processcreationdefinedatreestructure,wherea
processistherootanditssubprocessesarenodesbelowitinthetree.Eachof
thesubprocessescould,inturn,createmoresubprocesses.A.6 RC4000 11
A.5 THE
The THE operating system was designed at the Technische Hogeschool in
EindhovenintheNetherlandsinthemid-1960s.Itwasabatchsystemrunning
on a Dutch computer, the ELX8, with 32-KB of 27-bit words. The system was
mainlynotedforitscleandesign,particularlyitslayerstructure,anditsuseof
asetofconcurrentprocessesemployingsemaphoresforsynchronization.
Unlike the processes in the XDS-940 system, the set of processes in the
THE system was static. The operating system itself was designed as a set of
cooperatingprocesses.Inaddition,fiveuserprocesseswerecreatedthatserved
as the active agents to compile, execute, and print user programs. When one
jobwasfinished,theprocesswouldreturntotheinputqueuetoselectanother
job.
ApriorityCPU-schedulingalgorithmwasused.Theprioritieswererecom-
putedevery2secondsandwereinverselyproportionaltotheamountofCPU
timeusedrecently(inthelast8to10seconds).Thisschemegavehigherpriority
toI/O-boundprocessesandtonewprocesses.
Memorymanagementwaslimitedbythelackofhardwaresupport.How-
ever,sincethesystemwaslimitedanduserprogramscouldbewrittenonlyin
Algol,asoftwarepagingschemewasused.TheAlgolcompilerautomatically
generatedcallstosystemroutines,whichmadesuretherequestedinformation
wasinmemory,swappingifnecessary.Thebacking storewas a512-KB-word
drum.A512-wordpagewasused,withanLRUpage-replacementstrategy.
Another major concern of the THE system was deadlock control. The
banker’salgorithmwasusedtoprovidedeadlockavoidance.
Closely relatedtothe THE system is the Venus system.The Venus system
wasalsoalayer-structureddesign,usingsemaphorestosynchronizeprocesses.
Thelowerlevelsofthedesignwereimplementedinmicrocode,however,pro-
vidingamuchfastersystem.Paged-segmentedmemorywasusedformemory
management. In addition,the system was designedas a time-sharing system
ratherthanabatchsystem.
A.6 RC 4000
TheRC4000system,liketheTHEsystem,wasnotableprimarilyforitsdesign
concepts. It was designed in the late 1960s for the Danish 4000 computer
by Regnecentralen, particularly by Brinch-Hansen. The objective was not to
designabatchsystem,oratime-sharingsystem,oranyotherspecificsystem.
Rather,thegoalwastocreateanoperating-systemnucleus,orkernel,onwhich
a complete operating system could be built. Thus, the system structure was
layered,andonlythelowerlevels—comprisingthekernel—wereprovided.
The kernelsupportedacollectionofconcurrent processes.Around-robin
CPUschedulerwasused.Althoughprocessescouldsharememory,theprimary
communicationandsynchronizationmechanismwasthemessagesystempro-
videdbythekernel.Processescouldcommunicatewitheachotherbyexchang-
ingfixed-sizedmessagesofeightwordsinlength.Allmessageswerestoredin
buffers from a common buffer pool. When a message buffer was no longer
required,itwasreturnedtothecommonpool.12 AppendixA Influentia OperatingSystems
A message queue was associated with each process. It contained all the
messages that had been sent to that process but had not yet been received.
MessageswereremovedfromthequeueinFIFOorder.Thesystemsupported
fourprimitiveoperations,whichwereexecutedatomically:
• send-message(inreceiver,inmessage,outbuffer)
• wait-message(outsender,outmessage,outbuffer)
• send-answer(outresult,inmessage,inbuffer)
• wait-answer(outresult,outmessage,inbuffer)
The last two operations allowed processes to exchange several messages at a
time.
TheseprimitivesrequiredthataprocessserviceitsmessagequeueinFIFO
orderandthatitblockitselfwhileotherprocesseswerehandlingitsmessages.
Toremovetheserestrictions,thedevelopersprovidedtwoadditionalcommu-
nication primitives that allowed a process to wait for the arrival of the next
messageortoanswerandserviceitsqueueinanyorder:
• wait-event(inprevious-buffer,outnext-buffer,outresult)
• get-event(outbuffer)
I/O devices were also treated as processes. The device drivers were code
thatconvertedthedeviceinterruptsandregistersintomessages.Thus,apro-
cesswouldwritetoaterminalbysendingthatterminalamessage.Thedevice
driverwouldreceivethemessageandoutputthecharactertotheterminal.An
inputcharacterwouldinterruptthesystemandtransfertoadevicedriver.The
devicedriverwouldcreateamessagefromtheinputcharacterandsendittoa
waitingprocess.
A.7 CTSS
TheCompatibleTime-SharingSystem(CTSS)wasdesignedatMITasanexper-
imental time-sharing system and first appeared in 1961. It was implemented
onanIBM7090andeventuallysupportedupto32interactiveusers.Theusers
wereprovidedwithasetofinteractivecommandsthatallowedthemtomanip-
ulatefilesandtocompileandrunprogramsthroughaterminal.
The7090hada32-KBmemorymadeupof36-bitwords.Themonitorused
5-KB words, leaving27KB for the users.Usermemory imageswere swapped
between memory and a fast drum. CPU scheduling employed a multilevel-
feedback-queuealgorithm. The timequantum for leveli was 2∗ i time units.
If a program did not finish its CPU burst in one time quantum, it was moved
downtothenextlevelofthequeue,givingittwiceasmuchtime.Theprogram
atthehighestlevel(withtheshortestquantum)wasrunfirst.Theinitiallevel
ofaprogramwasdeterminedbyitssize,sothatthetimequantumwasatleast
aslongastheswaptime.
CTSS was extremely successful and was in use as late as 1972. Although
it was limited, it succeeded in demonstrating that time sharing was a con-A.9 IBMOS/360 13
venient and practical mode of computing. One result of CTSS was increased
developmentoftime-sharingsystems.Anotherresultwasthedevelopmentof
MULTICS.
A.8 MULTICS
The MULTICS operating system was designed from 1965 to 1970 at MIT as a
natural extensionof CTSS.CTSSand other earlytime-sharing systemswereso
successfulthattheycreatedanimmediatedesiretoproceedquicklytobigger
and better systems. As larger computers became available, the designers of
CTSS set out to create a time-sharing utility. Computing service would be
provided like electrical power. Large computer systems would be connected
by telephone wires to terminals in offices and homes throughout a city. The
operatingsystemwouldbeatime-sharedsystemrunningcontinuouslywitha
vastfilesystemofsharedprogramsanddata.
MULTICS was designedby a team from MIT, GE (which later sold its com-
puterdepartmenttoHoneywell),andBellLaboratories(whichdroppedoutof
the project in 1969). The basic GE 635 computer was modified to a new com-
putersystemcalledtheGE645,mainlybytheadditionofpaged-segmentation
memoryhardware.
InMULTICS,avirtualaddresswascomposedofan18-bitsegmentnumber
and a 16-bit word offset. The segmentswere then pagedin 1-KB-word pages.
Thesecond-chancepage-replacementalgorithmwasused.
Thesegmentedvirtualaddressspacewasmergedintothefilesystem;each
segmentwasafile.Segmentswereaddressedbythenameofthefile.Thefile
systemitselfwasamultileveltreestructure,allowinguserstocreatetheirown
subdirectorystructures.
LikeCTSS,MULTICSusedamultilevelfeedbackqueueforCPUscheduling.
Protection was accomplished through an access list associated with each file
and a set of protection rings for executing processes. The system, which was
writtenalmost entirelyin PL/1,comprisedabout 300,000lines ofcode.It was
extendedtoamultiprocessorsystem,allowingaCPUtobetakenoutofservice
formaintenancewhilethesystemcontinuedrunning.
A.9 IBM OS/360
Thelongestlineofoperating-systemdevelopmentisundoubtedlythatofIBM
computers. The early IBM computers, such as the IBM 7090 and the IBM 7094,
areprimeexamplesofthedevelopmentofcommonI/Osubroutines,followed
bydevelopmentofaresidentmonitor,privilegedinstructions,memoryprotec-
tion, and simplebatch processing. These systems were developedseparately,
often at independent sites. As a result, IBM was faced with many different
computers,withdifferentlanguagesanddifferentsystemsoftware.
The IBM/360—which first appeared in the mid 1960s—was designed to
alterthissituation.TheIBM/360wasdesignedasafamilyofcomputersspan-
ning the complete range from small business machines to large scientific
machines.Onlyonesetofsoftwarewouldbeneededforthesesystems,which
allusedthesameoperatingsystem:OS/360.Thisarrangementwasintendedto14 AppendixA Influentia OperatingSystems
reduce maintenance problems for IBM and to allow users to move programs
andapplicationsfreelyfromoneIBMsystemtoanother.
Unfortunately, OS/360 tried to be all things to all people. As a result, it
did none of its tasks especially well. The file system included a type field
that defined the type of each file, and different file types were defined for
fixed-lengthandvariable-lengthrecordsandforblockedandunblockedfiles.
Contiguousallocationwasused,sotheuserhadtoguessthesizeofeachoutput
file. The Job Control Language (JCL) added parameters for every possible
option,makingitincomprehensibletotheaverageuser.
The memory-management routines were hampered by the architecture.
Althoughabase-registeraddressingmodewasused,theprogramcouldaccess
andmodifythebaseregister,sothatabsoluteaddressesweregeneratedbythe
CPU.Thisarrangementpreventeddynamicrelocation;theprogramwasbound
tophysicalmemoryatloadtime.Twoseparateversionsoftheoperatingsystem
wereproduced:OS/MFTusedfixedregionsandOS/MVTusedvariableregions.
The system was written in assembly language by thousands of program-
mers,resultinginmillionsoflinesofcode.Theoperatingsystemitselfrequired
largeamountsofmemoryforitscodeandtables.Operating-systemoverhead
oftenconsumedone-halfofthetotalCPUcycles.Overtheyears,newversions
werereleasedtoaddnewfeaturesandtofixerrors.However,fixingoneerror
oftencausedanotherinsomeremotepartofthesystem,sothatthenumberof
knownerrorsinthesystemremainedfairlyconstant.
Virtual memory was added to OS/360 with the change to the IBM/370
architecture. The underlying hardware provided a segmented-paged virtual
memory. New versions of OS used this hardware in different ways. OS/VS1
createdonelargevirtualaddressspaceandranOS/MFTinthatvirtualmemory.
Thus,theoperatingsystemitselfwaspaged,aswellasuserprograms.OS/VS2
Release 1 ran OS/MVT in virtual memory. Finally, OS/VS2 Release 2, which is
nowcalledMVS,providedeachuserwithhisownvirtualmemory.
MVSisstillbasicallyabatchoperatingsystem.TheCTSSsystemwasrunon
an IBM 7094, but the developers at MIT decided that the address space of the
360, IBM’s successor tothe 7094, was toosmall for MULTICS, sothey switched
vendors.IBMthendecidedtocreateitsowntime-sharingsystem,TSS/360.Like
MULTICS,TSS/360wassupposedtobealarge,time-sharedutility.Thebasic360
architecturewasmodifiedinthemodel67toprovidevirtualmemory.Several
sitespurchasedthe360/67inanticipationofTSS/360.
TSS/360wasdelayed,however,soothertime-sharingsystemsweredevel-
opedastemporarysystemsuntilTSS/360wasavailable.Atime-sharingoption
(TSO)wasaddedtoOS/360.IBM’sCambridgeScientificCenterdevelopedCMS
asasingle-usersystemandCP/67toprovideavirtualmachinetoruniton.
When TSS/360 was eventually delivered, it was a failure. It was too large
and too slow. As a result, no site would switch from its temporary system to
TSS/360.Today,timesharingonIBMsystemsislargelyprovidedeitherbyTSO
underMVSorbyCMSunderCP/67(renamedVM).
Neither TSS/360 nor MULTICS achieved commercial success. What went
wrong? Part of the problem was that these advanced systems were too large
andtoocomplextobeunderstood.Anotherproblemwastheassumptionthat
computing power would be available from a large, remote source. Minicom-A.11 CP/MandMS/DOS 15
puterscamealonganddecreasedtheneedforlargemonolithicsystems.They
werefollowedbyworkstationsandthenpersonalcomputers,whichputcom-
putingpowercloserandclosertotheendusers.
A.10 TOPS-20
DEC created many influential computer systems during its history. Probably
the most famous operating system associated with DEC is VMS, a popular
business-oriented system that is still in use today as OpenVMS, a product of
Hewlett-Packard.ButperhapsthemostinfluentialofDEC’soperatingsystems
wasTOPS-20.
TOPS-20 started life as a research project at Bolt, Beranek, and Newman
(BBN)around1970.BBNtookthebusiness-orientedDECPDP-10computerrun-
ningTOPS-10,addedahardwarememory-pagingsystemtoimplementvirtual
memory,andwroteanewoperatingsystemforthatcomputertotakeadvan-
tage of the new hardware features. The result was TENEX, a general-purpose
time-sharing system. DEC then purchased the rights to TENEX and created a
new computer with a built-in hardware pager. The resulting system was the
DECSYSTEM-20andtheTOPS-20operatingsystem.
TOPS-20hadanadvancedcommand-lineinterpreterthatprovidedhelpas
needed to users. That, in combination with the power of the computer and
its reasonable price, made the DECSYSTEM-20 the most popular time-sharing
system of its time. In 1984, DEC stopped work on its line of 36-bit PDP-10
computerstoconcentrateon32-bitVAXsystemsrunningVMS.
A.11 CP/M and MS/DOS
Earlyhobbyist computers weretypicallybuiltfrom kitsand ranasinglepro-
gramatatime.Thesystemsevolvedintomoreadvancedsystemsascomputer
components improved. An early “standard” operating system for these com-
putersofthe1970swasCP/M,shortforControlProgram/Monitor,writtenby
GaryKindallofDigitalResearch,Inc.CP/Mranprimarilyonthefirst“personal
computer” CPU,the8-bitIntel8080.CP/Moriginallysupportedonly64KBof
memoryandranonlyoneprogramatatime.Ofcourse,itwastext-based,with
a command interpreter. The command interpreter resembled those in other
operatingsystemsofthetime,suchastheTOPS-10fromDEC.
WhenIBMenteredthepersonalcomputerbusiness,itdecidedtohaveBill
Gatesandcompany writeanewoperatingsystemforits16-bitCPUofchoice
—theIntel8086.Thisoperatingsystem,MS-DOS,wassimilartoCP/Mbuthad
arichersetofbuilt-incommands,againmostlymodeledafterTOPS-10.MS-DOS
became the most popular personal-computer operating system of its time,
startingin1981andcontinuingdevelopmentuntil2000.Itsupported640KBof
memory,withtheabilitytoaddress“extended”and“expanded”memorytoget
somewhatbeyondthatlimit.Itlackedfundamentalcurrentoperating-system
features,however,especiallyprotectedmemory.16 AppendixA Influentia OperatingSystems
A.12 Macintosh Operating System and Windows
With the advent of 16-bit CPUs, operating systems for personal computers
couldbecomemoreadvanced,featurerich,andusable.TheAppleMacintosh
computerwasarguablythefirstcomputerwithaGUIdesignedforhomeusers.
It was certainly the most successful for a while, starting at its launch in 1984.
Itusedamouseforscreenpointingandselectingandcamewithmanyutility
programsthattookadvantageofthenewuserinterface.Hard-diskdriveswere
relatively expensive in 1984, so it came only with a 400-KB-capacity floppy
drivebydefault.
TheoriginalMacOSranonlyonApplecomputersandslowlywaseclipsed
byMicrosoftWindows(startingwithVersion1.0in1985),whichwaslicensed
torunonmanydifferentcomputersfromamultitudeofcompanies.Asmicro-
processor CPUs evolved to 32-bit chips with advanced features, such as pro-
tectedmemoryandcontextswitching,theseoperatingsystemsaddedfeatures
thathadpreviouslybeenfoundonlyonmainframesandminicomputers.Over
time,personalcomputersbecameaspowerfulasthosesystemsandmoreuse-
ful for many purposes. Minicomputers died out, replaced by general- and
special-purpose“servers.”Althoughpersonalcomputerscontinuetoincrease
incapacityandperformance,serverstendtostayaheadoftheminamountof
memory,diskspace,andnumberandspeedofavailableCPUs.Today,servers
typicallyrunin datacenters or machine rooms,while personal computerssit
onornexttodesksandtalktoeachotherandserversacrossanetwork.
The desktop rivalry between Apple and Microsoft continues today, with
new versions of Windows and Mac OS trying to outdo each other in fea-
tures, usability, and application functionality. Other operating systems, such
as AmigaOSand OS/2, haveappearedovertimebut have not beenlong-term
competitorstothetwoleadingdesktopoperatingsystems.Meanwhile,Linux
initsmanyformscontinuestogaininpopularityamongmoretechnicalusers
—andevenwithnontechnicalusersonsystemsliketheOneLaptopperChild
(OLPC)children’sconnectedcomputernetwork(http://laptop.org/).
A.13 Mach
The Mach operating system traces its ancestry to the Accent operating sys-
temdevelopedatCarnegieMellonUniversity(CMU).Mach’scommunication
system and philosophy are derived from Accent, but many other significant
portionsofthesystem(forexample,thevirtualmemorysystemandtaskand
threadmanagement)weredevelopedfromscratch.
WorkonMachbeganinthemid1980.Theoperatingsystemwasdesigned
withthefollowingthreecriticalgoalsinmind:
1. Emulate4.3BSDUNIXsothattheexecutablefilesfromaUNIXsystemcan
runcorrectlyunderMach.
2. Be a modern operating system that supports many memory models, as
wellasparallelanddistributedcomputing.
3. Haveakernelthatissimplerandeasiertomodifythan4.3BSD.A.13 Mach 17
Mach’s development followed an evolutionary path from BSD UNIX sys-
tems.Machcodewasinitiallydevelopedinsidethe4.2BSDkernel,withBSDker-
nelcomponentsreplacedbyMachcomponentsastheMachcomponentswere
completed. The BSD components were updated to 4.3BSD when that became
available. By 1986, the virtual memory and communication subsystems were
running on the DEC VAX computer family, including multiprocessor versions
of the VAX. Versions for the IBM RT/PC and for SUN 3 workstations followed
shortly. Then, 1987 saw the completion of the Encore Multimax and Sequent
Balancemultiprocessorversions,includingtaskandthreadsupport,aswellas
thefirstofficialreleasesofthesystem,Release0andRelease1.
Through Release 2, Mach providedcompatibility with the corresponding
BSDsystemsbyincludingmuchofBSD’scodeinthekernel.Thenewfeatures
andcapabilitiesofMachmadethekernelsinthesereleaseslargerthanthecor-
respondingBSDkernels.Mach3movedtheBSDcodeoutsidethekernel,leaving
a much smaller microkernel. This system implements only basic Mach fea-
turesinthekernel;allUNIX-specificcodehasbeenevictedtoruninuser-mode
servers.ExcludingUNIX-specificcodefromthekernelallowsthereplacement
ofBSDwithanotheroperatingsystemorthesimultaneousexecutionofmulti-
pleoperating-systeminterfacesontopofthemicrokernel.InadditiontoBSD,
user-modeimplementationshavebeendevelopedforDOS,theMacintoshoper-
atingsystem,andOSF/1.Thisapproachhassimilaritiestothevirtualmachine
concept,butherethevirtualmachineisdefinedbysoftware(theMachkernel
interface),rather thanby hardware.WithRelease3.0,Machbecame available
on a wide variety of systems, including single-processor SUN, Intel, IBM, and
DECmachinesandmultiprocessorDEC,Sequent,andEncoresystems.
MachwaspropelledtotheforefrontofindustryattentionwhentheOpen
Software Foundation (OSF) announced in 1989 that it would use Mach 2.5 as
thebasisforitsnewoperatingsystem,OSF/1.(Mach2.5wasalsothebasisfor
theoperatingsystemontheNeXTworkstation,thebrainchildofSteveJobsof
AppleComputerfame.)TheinitialreleaseofOSF/1occurredayearlater,and
this system competed with UNIX System V, Release 4, the operating system
of choice at that time among UNIX International (UI) members. OSF members
includedkeytechnologicalcompaniessuchasIBM,DEC,andHP.OSFhassince
changeditsdirection,andonlyDECUNIXisbasedontheMachkernel.
Unlike UNIX, which was developed without regard for multiprocessing,
Mach incorporates multiprocessing support throughout. This support is also
exceedinglyflexible,rangingfromshared-memorysystemstosystemswithno
memory shared between processors. Mach uses lightweight processes, in the
form of multiple threads of execution within one task (or address space), to
support multiprocessing and parallel computation. Its extensive use of mes-
sagesastheonlycommunicationmethodensuresthatprotectionmechanisms
are complete and efficient. By integrating messages with the virtual memory
system,Machalsoensuresthatmessagescanbehandledefficiently.Finally,by
havingthevirtualmemorysystemusemessagestocommunicatewiththedae-
monsmanagingthebackingstore,Machprovidesgreatflexibilityinthedesign
and implementation of these memory-object-managing tasks. By providing
low-level, or primitive, system calls from which more complex functions can
bebuilt,Machreducesthesizeofthekernelwhilepermittingoperating-system
emulationattheuserlevel,muchlikeIBM’svirtualmachinesystems.18 AppendixA Influentia OperatingSystems
Today, the only remaining pure Mach implementationis in GNUHURD, a
little-usedoperatingsystem.Machstillliveson,however,inXNU—thekernel
driving macOSand the iOSvariants. XNU—whose codebase Apple obtained
with the acquisition of NeXT and its NeXTSTEP operating system—is a Mach
corewithatoplayerofBSDAPIs.Applecontinuestosupportandmaintainthe
Mach APIs (still accessible through specialized system calls known as traps,
andviaMachMessages),andthekernelcontinuesevolvingwithnewfeatures
tothisday.
SomepreviouseditionsofOperatingSystemConceptsincludedanentire
chapteronMach.Thischapter,asitappearedinthefourthedition,isavailable
ontheweb(http://www.os-book.com).
A.14 Capability-based Systems—Hydra and CAP
Inthissection,wesurveytwocapability-basedprotectionsystems.Thesesys-
tems differin their complexity and in the types of policies that can be imple-
mentedonthem.Neithersystemiswidelyused,butbothprovideinteresting
provinggroundsforprotectiontheories.
A.14.1 Hydra
Hydraisacapability-basedprotectionsystemthatprovidesconsiderableflex-
ibility. The system implements a fixed set of possible access rights, including
suchbasicformsofaccessastherighttoread,write,orexecuteamemoryseg-
ment.Inaddition,auser(oftheprotectionsystem)candeclareotherrights.The
interpretationofuser-definedrightsisperformedsolelybytheuser’sprogram,
but the system provides access protection for the use of these rights, as well
asfortheuseofsystem-definedrights.Thesefacilitiesconstituteasignificant
developmentinprotectiontechnology.
Operationsonobjectsaredefinedprocedurally.Theproceduresthatimple-
ment such operations are themselves a form of object, and they are accessed
indirectlybycapabilities.Thenamesofuser-definedproceduresmustbeiden-
tified to the protection system if it is to deal with objects of the user-defined
type. When the definition of an object is made known to Hydra, the names
of operations on the type become auxiliary rights. Auxiliary rights can be
describedin acapability for an instance ofthe type.For aprocesstoperform
anoperationonatypedobject,thecapabilityitholdsforthatobjectmustcon-
tainthenameoftheoperationbeinginvokedamongitsauxiliaryrights.This
restriction enables discrimination of access rights to be made on an instance-
by-instanceandprocess-by-processbasis.
Hydraalsoprovidesrightsamplificatio .Thisschemeallowsaprocedure
tobecertifiedastrustworthytoactonaformalparameterofaspecifiedtype
onbehalfofanyprocessthatholdsarighttoexecutetheprocedure.Therights
held by a trustworthy procedure are independent of, and may exceed, the
rights held by the calling process. However, such a procedure must not be
regarded as universally trustworthy (the procedure is not allowed to act on
othertypes,forinstance),andthetrustworthinessmustnotbeextendedtoany
otherproceduresorprogramsegmentsthatmightbeexecutedbyaprocess.A.14 Capability-basedSystems—HydraandCAP 19
Amplificationallowsimplementationproceduresaccesstotherepresenta-
tionvariablesofanabstractdatatype.Ifaprocessholdsacapabilitytoatyped
objectA,forinstance,thiscapabilitymayincludeanauxiliaryrighttoinvoke
someoperationPbutdoesnotincludeanyoftheso-calledkernelrights,such
asread,write,orexecute,onthesegmentthatrepresentsA.Suchacapability
gives a process a means of indirect access (through the operation P) to the
representationofA,butonlyforspecificpurposes.
When a process invokes the operation P on an object A, however, the
capabilityforaccesstoAmaybeamplifiedascontrolpassestothecodebody
of P. This amplification may be necessary to allow P the right to access the
storagesegmentrepresentingAsoastoimplementtheoperationthatPdefines
on the abstract data type. The code body of P may be allowed to read or to
write to the segment of A directly, even though the calling process cannot.
On return from P, the capability for A is restored to its original, unamplified
state.Thiscaseisatypicaloneinwhichtherightsheldbyaprocessforaccess
to a protected segment must change dynamically, depending on the task to
be performed. The dynamic adjustment of rights is performed to guarantee
consistency ofaprogrammer-definedabstraction.Amplificationofrightscan
bestatedexplicitlyinthedeclarationofanabstracttypetotheHydraoperating
system.
Whenauserpassesanobjectasanargumenttoaprocedure,wemayneed
toensurethattheprocedurecannotmodifytheobject.Wecanimplementthis
restriction readily by passing an access right that does not have the modifi-
cation (write) right. However, if amplification may occur, the right to modify
maybereinstated.Thus,theuser-protectionrequirementcanbecircumvented.
Ingeneral, ofcourse, a user may trustthat a procedureperformsits task cor-
rectly.Thisassumptionisnotalwayscorrect,however,becauseofhardwareor
softwareerrors.Hydrasolvesthisproblembyrestrictingamplifications.
Theprocedure-callmechanismofHydrawasdesignedasadirectsolution
totheproblemofmutuallysuspicioussubsystems.Thisproblemisdefinedas
follows. Suppose that a program can be invoked as a service by a number of
different users (for example, a sort routine, a compiler, a game). When users
invokethisserviceprogram,theytaketheriskthattheprogramwillmalfunc-
tion and will either damage the given data or retain some access right to the
data to be used (without authority) later. Similarly, the service program may
havesomeprivatefiles(foraccountingpurposes,forexample)thatshouldnot
beaccesseddirectlybythecallinguserprogram.Hydraprovidesmechanisms
fordirectlydealingwiththisproblem.
AHydrasubsystemisbuiltontopofitsprotectionkernelandmayrequire
protection of its own components. A subsystem interacts with the kernel
throughcallsonasetofkernel-definedprimitivesthatdefineaccessrightsto
resourcesdefinedby thesubsystem.Thesubsystemdesignercan definepoli-
ciesforuseoftheseresourcesbyuserprocesses,butthepoliciesareenforced
byuseofthestandardaccessprotectionprovidedbythecapabilitysystem.
Programmerscanmakedirectuseoftheprotectionsystemafteracquaint-
ing themselves with its features in the appropriate reference manual. Hydra
provides a large library of system-defined procedures that can be called by
user programs. Programmers can explicitlyincorporate calls on these system
procedures into their program code or can use a program translator that has
beeninterfacedtoHydra.20 AppendixA Influentia OperatingSystems
A.14.2 Cambridge CAP System
A different approach to capability-based protection has been taken in the
design of the Cambridge CAPsystem. CAP’s capability system is simpler and
superficially less powerful than that of Hydra. However, closer examination
shows that it, too, can be used to provide secure protection of user-defined
objects. CAP has two kinds of capabilities. The ordinary kind is called a data
capability.Itcanbeusedtoprovideaccesstoobjects,buttheonlyrightspro-
videdarethestandardread,write,andexecuteoftheindividualstorageseg-
mentsassociatedwiththeobject.Datacapabilitiesareinterpretedbymicrocode
intheCAPmachine.
Thesecondkindofcapabilityistheso-calledsoftwarecapability,whichis
protected,butnotinterpreted,bytheCAPmicrocode.Itisinterpretedbyapro-
tected(thatis,privileged)procedure,whichmaybewrittenbyanapplication
programmer as part of a subsystem. Aparticular kind of rights amplification
is associated with a protected procedure. When executing the code body of
suchaprocedure,aprocesstemporarilyacquirestherighttoreadorwritethe
contents of a software capability itself. This specific kind of rights amplifica-
tioncorrespondstoanimplementationofthesealandunsealprimitiveson
capabilities.Ofcourse,thisprivilegeisstillsubjecttotypeverificationtoensure
that only software capabilities for a specified abstract type are passed to any
such procedure. Universal trust is not placed in any code other than the CAP
machine’s microcode. (See the bibliographical notes at the end of the chapter
forreferences.)
The interpretation of a software capability is left completely to the sub-
system, through the protected procedures it contains. This scheme allows a
varietyofprotectionpoliciestobeimplemented.Althoughprogrammerscan
define their own protected procedures (any of which might be incorrect), the
security of the overall system cannot be compromised. The basic protection
systemwillnotallowanunverified,user-defined,protectedprocedureaccess
to any storage segments (or capabilities) that do not belong to the protection
environmentinwhichitresides.Themostseriousconsequenceofaninsecure
protectedprocedureisaprotectionbreakdownofthesubsystemforwhichthat
procedurehasresponsibility.
The designers of the CAP system have noted that the use of software
capabilities allowed them to realize considerable economies in formulating
andimplementingprotectionpoliciescommensuratewiththerequirementsof
abstract resources. However, subsystem designers who want to make use of
thisfacilitycannotsimplystudyareferencemanual,asisthecasewithHydra.
Instead,theymustlearntheprinciplesandtechniquesofprotection,sincethe
systemprovidesthemwithnolibraryofprocedures.
A.15 Other Systems
Thereare,ofcourse,otheroperatingsystems,andmostofthemhaveinterest-
ingproperties.TheMCPoperatingsystemfortheBurroughscomputerfamily
was the first to be written in a system programming language. It supported
segmentation and multiple CPUs. The SCOPE operating system for the CDC
6600 was also a multi-CPU system. The coordination and synchronization of
themultipleprocessesweresurprisinglywelldesigned.Bibliography 21
Historyislitteredwithoperatingsystemsthatsuitedapurposeforatime
(beitalongorashorttime)andthen,whenfaded,werereplacedbyoperating
systemsthathadmorefeatures,supportednewerhardware,wereeasiertouse,
orwerebettermarketed.Wearesurethistrendwillcontinueinthefuture.
Further Reading
Loomsandcalculatorsaredescribedin[Frah(2001)]andshowngraphicallyin
[Frauenfelder(2005)].
TheManchesterMark1isdiscussedby[RojasandHashagen(2000)],and
itsoffspring,theFerrantiMark1,isdescribedby[Ceruzzi(1998)].
[Kilburnetal.(1961)]and[Howarthetal.(1961)]examinetheAtlasoper-
atingsystem.
The XDS-940 operating system is described by [Lichtenberger and Pirtle
(1965)].
TheTHEoperatingsystemiscoveredby[Dijkstra(1968)]andby[McKeag
andWilson(1976)].
TheVenussystemisdescribedby[Liskov(1972)].
[Brinch-Hansen (1970)] and [Brinch-Hansen (1973)] discuss the RC 4000
system.
TheCompatibleTime-SharingSystem(CTSS)ispresentedby[Corbatoetal.
(1962)].
The MULTICS operating system is described by [Corbato and Vyssotsky
(1965)]and[Organick(1972)].
[Mealy et al. (1966)] presented the IBM/360. [Lett and Konigsford (1968)]
coverTSS/360.
CP/67 is described by [Meyer and Seawright (1970)] and [Parmelee et al.
(1972)].
DEC VMS is discussedby [Kenah et al. (1988)], and TENEX is described by
[Bobrowetal.(1972)].
AdescriptionoftheAppleMacintoshappearsin[Apple(1987)].Formore
informationontheseoperatingsystemsandtheirhistory,see[Freibergerand
Swaine(2000)].
TheMachoperatingsystemanditsancestor,theAccentoperatingsystem,
are described by [Rashid and Robertson (1981)]. Mach’s communication
system is covered by [Rashid (1986)], [Tevanian et al. (1989)], and [Accetta
et al. (1986)]. The Mach scheduler is described in detail by [Tevanian
et al. (1987a)] and [Black (1990)]. An early version of the Mach shared-
memory and memory-mapping system is presented by [Tevanian et al.
(1987b)]. A good resource describing the Mach project can be found at
http://www.cs.cmu.edu/afs/cs/project/mach/public/www/mach.html.
[McKeag and Wilson (1976)] discuss the MCP operating system for the
BurroughscomputerfamilyaswellastheSCOPEoperatingsystemfortheCDC
6600.
The Hydra system was described by [Wulf et al. (1981)]. The CAPsystem
was describedby [Needham and Walker (1977)]. [Organick (1972)] discussed
theMULTICSring-protectionsystem.22 AppendixA Influentia OperatingSystems
Bibliography
[Accettaetal.(1986)] M.Accetta,R.Baron,W.Bolosky,D.B.Golub,R.Rashid,
A.Tevanian,andM.Young,“Mach:ANewKernelFoundationforUNIXDevel-
opment”,ProceedingsoftheSummerUSENIXConference(1986),pages93–112.
[Apple(1987)] Apple Technical Introduction to the Macintosh Family. Addison-
Wesley(1987).
[Black(1990)] D. L. Black, “Scheduling Support for Concurrency and Paral-
lelism in the Mach Operating System”, IEEE Computer, Volume 23, Number 5
(1990),pages35–43.
[Bobrowetal.(1972)] D.G.Bobrow,J.D.Burchfiel,D.L.Murphy,andR.S.Tom-
linson,“TENEX,aPagedTimeSharingSystemforthePDP-10”,Communications
oftheACM,Volume15,Number3(1972).
[Brinch-Hansen(1970)] P. Brinch-Hansen, “The Nucleus of a Multiprogram-
mingSystem”,CommunicationsoftheACM,Volume13,Number4(1970),pages
238–241and250.
[Brinch-Hansen(1973)] P.Brinch-Hansen,OperatingSystemPrinciples,Prentice
Hall(1973).
[Ceruzzi(1998)] P.E.Ceruzzi,AHistoryofModernComputing,MITPress(1998).
[CorbatoandVyssotsky(1965)] F.J.CorbatoandV.A.Vyssotsky,“Introduction
and Overview of the MULTICS System”, Proceedings of the AFIPS Fall Joint
ComputerConference(1965),pages185–196.
[Corbatoetal.(1962)] F. J. Corbato, M. Merwin-Daggett, and R. C. Daley, “An
ExperimentalTime-SharingSystem”,ProceedingsoftheAFIPSFallJointComputer
Conference(1962),pages335–344.
[Dijkstra(1968)] E.W.Dijkstra,“TheStructureoftheTHEMultiprogramming
System”,CommunicationsoftheACM,Volume11,Number5(1968),pages341–
346.
[Frah(2001)] G. Frah, The UniversalHistory ofComputing, John Wiley and Sons
(2001).
[Frauenfelder(2005)] M. Frauenfelder, The Computer—An Illustrated History,
CarltonBooks(2005).
[FreibergerandSwaine(2000)] P.FreibergerandM.Swaine,FireintheValley—
TheMakingofthePersonalComputer,McGraw-Hill(2000).
[Howarthetal.(1961)] D. J. Howarth, R. B. Payne, and F. H. Sumner, “The
Manchester University Atlas Operating System, Part II: User’s Description”,
ComputerJournal,Volume4,Number3(1961),pages226–229.
[Kenahetal.(1988)] L. J. Kenah, R. E. Goldenberg, and S. F. Bate, VAX/VMS
InternalsandDataStructures,DigitalPress(1988).
[Kilburnetal.(1961)] T.Kilburn,D.J.Howarth,R.B.Payne,andF.H.Sumner,
“TheManchesterUniversityAtlasOperatingSystem,PartI:InternalOrganiza-
tion”,ComputerJournal,Volume4,Number3(1961),pages222–225.Bibliography 23
[LettandKonigsford(1968)] A. L. Lett and W. L. Konigsford, “TSS/360: A
Time-Shared Operating System”, Proceedings of the AFIPS Fall Joint Computer
Conference(1968),pages15–28.
[LichtenbergerandPirtle(1965)] W. W. Lichtenberger and M. W. Pirtle, “A
Facility for Experimentation in Man-Machine Interaction”, Proceedings of the
AFIPSFallJointComputerConference(1965),pages589–598.
[Liskov(1972)] B.H.Liskov,“TheDesignoftheVenusOperatingSystem”,Com-
municationsoftheACM,Volume15,Number3(1972),pages144–149.
[McKeagandWilson(1976)] R.M.McKeagandR.Wilson,StudiesinOperating
Systems,AcademicPress(1976).
[Mealyetal.(1966)] G. H. Mealy, B. I. Witt, and W. A. Clark, “The Functional
Structure of OS/360”,IBM Systems Journal, Volume 5, Number 1 (1966), pages
3–11.
[MeyerandSeawright(1970)] R. A. Meyer and L. H. Seawright, “A Virtual
Machine Time-Sharing System”, IBM Systems Journal, Volume 9, Number 3
(1970),pages199–218.
[NeedhamandWalker(1977)] R.M.NeedhamandR.D.H.Walker,“TheCam-
bridgeCAPComputerandItsProtectionSystem”,ProceedingsoftheSixthSym-
posiumonOperatingSystemPrinciples(1977),pages1–10.
[Organick(1972)] E.I.Organick,TheMulticsSystem:AnExaminationofItsStruc-
ture,MITPress(1972).
[Parmeleeetal.(1972)] R.P.Parmelee,T.I.Peterson,C.C.Tillman,andD.Hat-
field, “Virtual Storage and Virtual Machine Concepts”, IBM Systems Journal,
Volume11,Number2(1972),pages99–130.
[Rashid(1986)] R.F.Rashid,“FromRIGtoAccenttoMach:TheEvolutionofa
NetworkOperatingSystem”,ProceedingsoftheACM/IEEEComputerSociety,Fall
JointComputerConference(1986),pages1128–1137.
[RashidandRobertson(1981)] R. Rashid and G. Robertson, “Accent: ACom-
munication-Oriented Network Operating System Kernel”, Proceedings of the
ACMSymposiumonOperatingSystemPrinciples(1981),pages64–75.
[RojasandHashagen(2000)] R.RojasandU.Hashagen,TheFirstComputers—
HistoryandArchitectures,MITPress(2000).
[Tevanianetal.(1987a)] A.Tevanian,Jr.,R.F.Rashid,D.B.Golub,D.L.Black,
E.Cooper,andM.W.Young,“MachThreadsandtheUnixKernel:TheBattlefor
Control”,ProceedingsoftheSummerUSENIXConference(1987).
[Tevanianetal.(1987b)] A.Tevanian,Jr.,R.F.Rashid,M.W.Young,D.B.Golub,
M. R. Thompson, W. Bolosky, and R. Sanzi, “A UNIX Interface for Shared
MemoryandMemoryMappedFilesUnderMach”,Technicalreport,Carnegie-
MellonUniversity(1987).
[Tevanianetal.(1989)] A. Tevanian, Jr., and B. Smith, “Mach: The Model for
FutureUnix”,Byte(1989).24 AppendixA Influentia OperatingSystems
[Wulfetal.(1981)] W. A. Wulf, R. Levin,andS. P. Harbison,Hydra/C.mmp:An
ExperimentalComputerSystem,McGraw-Hill(1981).B
Appendix
Windows 7
Updatedby DaveProbert
The Microsoft Windows 7 operating system is a 32-/64-bit preemptive mul-
titasking client operating system for microprocessors implementing the Intel
IA-32andAMD64instructionsetarchitectures(ISAs).Microsoft’scorresponding
serveroperatingsystem,WindowsServer2008R2,isbasedonthesamecode
as Windows 7 but supports only the 64-bit AMD64 and IA64 (Itanium) ISAs.
Windows 7 is the latest in a series of Microsoft operating systems based on
its NT code, which replaced the earlier systems based on Windows 95/98. In
thisappendix,wediscussthekeygoalsofWindows7,thelayeredarchitecture
of the system that has made it so easy to use, the file system, the networking
features,andtheprogramminginterface.
CHAPTER OBJECTIVES
• Explore the principles underlying Windows 7’s design and the specific
componentsofthesystem.
• ProvideadetaileddiscussionoftheWindows7filesystem.
• IllustratethenetworkingprotocolssupportedinWindows7.
• Describe the interface available in Windows 7 to system and application
programmers.
• DescribetheimportantalgorithmsimplementedwithWindows7.
B.1 History
Inthemid-1980s,MicrosoftandIBMcooperatedtodeveloptheOS/2operating
system, which was written in assembly language for single-processor Intel
80286 systems. In 1988, Microsoft decided to end the joint effort with IBM
and develop its own “new technology” (or NT) portable operating system to
supportboththeOS/2andPOSIXapplication-programminginterfaces(APIs).In
12 AppendixB Windows7
October1988,DaveCutler,thearchitectoftheDECVAX/VMSoperatingsystem,
washiredandgiventhecharterofbuildingMicrosoft’snewoperatingsystem.
Originally, the team planned to use the OS/2 API as NT’s native environ-
ment,butduringdevelopment,NTwaschangedtouseanew32-bitWindows
API(calledWin32),basedonthepopular16-bitAPIusedinWindows 3.0.The
first versions of NT were Windows NT 3.1 and Windows NT 3.1 Advanced
Server. (At that time, 16-bit Windows was at Version 3.1.) Windows NT Ver-
sion 4.0 adopted the Windows 95 user interface and incorporated Internet
web-serverandweb-browsersoftware.Inaddition,user-interfaceroutinesand
all graphics code were moved into the kernel to improve performance, with
the side effect of decreased system reliability. Although previous versions of
NThadbeenportedtoothermicroprocessorarchitectures,theWindows 2000
version, released in February 2000, supported only Intel (and compatible)
processors due to marketplace factors. Windows 2000 incorporated signifi-
cant changes. It added Active Directory (an X.500-based directory service),
better networking and laptop support, support for plug-and-play devices, a
distributedfilesystem,andsupportformoreprocessorsandmorememory.
InOctober2001,WindowsXPwasreleasedasbothanupdatetotheWin-
dows 2000 desktop operating system and a replacement for Windows 95/98.
In 2002, the servereditionof Windows XPbecame available (called Windows
.Net Server). Windows XP updated the graphical user interface (GUI) with
a visual design that took advantage of more recent hardware advances and
many new ease-of-use features. Numerous features were added to automat-
ically repair problems in applications and the operating system itself. As a
result of these changes, Windows XP provided better networking and device
experience(includingzero-configurationwireless,instantmessaging,stream-
ing media, and digital photography/video), dramatic performance improve-
mentsforboththedesktopandlargemultiprocessors,andbetterreliabilityand
securitythanearlierWindowsoperatingsystems.
The long-awaited update to Windows XP, called Windows Vista, was
released in November 2006, but it was not well received. Although Win-
dows Vista included many improvements that later showed up in Windows
7, these improvements were overshadowed by Windows Vista’s perceived
sluggishness and compatibility problems. Microsoft responded to criticisms
of Windows Vista by improving its engineering processes and working more
closelywiththemakersofWindowshardwareandapplications.Theresultwas
Windows 7, which was released in October 2009, along with corresponding
servereditionsofWindows.Amongthesignificantengineeringchangesisthe
increaseduseofexecutiontracingratherthancountersorprofilingtoanalyze
systembehavior.Tracingrunsconstantlyinthesystem,watchinghundredsof
scenarios execute. When one of these scenarios fails, or when it succeeds but
doesnotperformwell,thetracescanbeanalyzedtodeterminethecause.
Windows7usesaclient–serverarchitecture(likeMach)toimplementtwo
operating-system personalities, Win32 and POSIX, with user-level processes
calledsubsystems.(Atonetime,WindowsalsosupportedanOS/2subsystem,
butitwasremovedinWindowsXPduetothedemiseofOS/2.)Thesubsystem
architectureallowsenhancementstobemadetooneoperating-systemperson-
alitywithoutaffectingtheapplicationcompatibilityoftheother.Althoughthe
POSIX subsystem continues to be available for Windows 7, the Win32API has
becomeverypopular,andthePOSIXAPIsareusedbyonlyafewsites.Thesub-
systemapproachcontinuestobeinterestingtostudyfromanoperating-systemB.2 DesignPrinciples 3
perspective, but machine-virtualization technologies are now becoming the
dominantwayofrunningmultipleoperatingsystemsonasinglemachine.
Windows 7 is a multiuser operating system, supporting simultaneous
access through distributed services or through multiple instances of the GUI
viatheWindowsterminalservices.TheservereditionsofWindows7support
simultaneous terminal server sessions from Windows desktop systems. The
desktopeditionsofterminalservermultiplexthekeyboard,mouse,andmon-
itor between virtual terminal sessions for each logged-on user. This feature,
calledfastuserswitching,allowsuserstopreempteachotherattheconsoleof
aPCwithouthavingtologoffandlogon.
We noted earlierthat some GUI implementationmoved into kernel mode
in Windows NT 4.0. It started to move into user mode again with Windows
Vista, which included the desktop window manager (DWM) as a user-mode
process.DWMimplementsthedesktopcompositingofWindows,providingthe
WindowsAerointerfacelookontopoftheWindowsDirectXgraphicsoftware.
DirectX continues to run in the kernel, as does the code implementing Win-
dows’previouswindowingandgraphicsmodels(Win32kandGDI).Windows
7 made substantial changes to the DWM, significantly reducing its memory
footprintandimprovingitsperformance.
WindowsXPwasthefirstversionofWindowstoshipa64-bitversion(for
the IA64 in 2001 and the AMD64 in 2005). Internally, the native NT file system
(NTFS) and many of the Win32 APIs have always used 64-bit integers where
appropriate—so the major extension to 64-bit in Windows XP was support
forlargevirtualaddresses.However,64-biteditionsofWindowsalsosupport
much larger physical memories.By the time Windows 7 shipped, the AMD64
ISAhadbecomeavailableonalmostallCPUsfrombothIntelandAMD.Inaddi-
tion, by that time, physical memories on client systems frequently exceeded
the4-GBlimitoftheIA-32.Asaresult,the64-bitversionofWindows7isnow
commonly installedonlargerclientsystems.Becausethe AMD64 architecture
supportshigh-fidelityIA-32compatibilityatthelevelofindividualprocesses,
32-and64-bitapplicationscanbefreelymixedinasinglesystem.
IntherestofourdescriptionofWindows7,wewillnotdistinguishbetween
theclienteditionsofWindows7andthecorrespondingservereditions.They
are based on the same core components and run the same binary files for
the kernel and most drivers. Similarly, although Microsoft ships a variety of
differenteditionsofeachreleasetoaddressdifferentmarketpricepoints,few
of the differences between editions are reflected in the core of the system. In
thischapter,wefocusprimarilyonthecorecomponentsofWindows7.
B.2 Design Principles
Microsoft’s design goals for Windows included security, reliability, Windows
andPOSIXapplicationcompatibility,highperformance,extensibility,portabil-
ity, and international support. Some additional goals, energy efficiency and
dynamicdevicesupport,haverecentlybeenaddedtothislist.Next,wediscuss
eachofthesegoalsandhowitisachievedinWindows7.
B.2.1 Security
Windows7securitygoalsrequiredmorethanjustadherencetothedesignstan-
dardsthathadenabledWindowsNT4.0toreceiveaC2securityclassification4 AppendixB Windows7
from the U.S. government. (A C2 classification signifies a moderate level of
protectionfromdefectivesoftwareandmaliciousattacks.Classificationswere
defined by the Department of Defense Trusted Computer System Evaluation
Criteria,alsoknownastheOrangeBook.)Extensivecodereviewandtesting
were combined with sophisticated automatic analysis tools to identify and
investigatepotentialdefectsthatmightrepresentsecurityvulnerabilities.
Windows bases security on discretionary access controls. System objects,
including files, registry settings, and kernel objects, are protected by access-
control lists (ACLs) (see Section 13.4.2). ACLs are vulnerable to user and pro-
grammererrors,however,aswellastothemostcommonattacksonconsumer
systems,inwhichtheuseristrickedintorunningcode,oftenwhilebrowsing
theweb.Windows7includesamechanismcalledintegritylevelsthatactsas
arudimentarycapabilitysystemforcontrollingaccess.Objectsandprocesses
aremarkedashavinglow,medium,orhighintegrity.Windowsdoesnotallow
aprocesstomodifyanobjectwithahigherintegritylevel,nomatterwhatthe
settingoftheACL.
Other security measures include address-space layout randomization
(ASLR),nonexecutablestacksandheaps,andencryptionanddigitalsignature
facilities.ASLRthwartsmanyformsofattackbypreventingsmallamountsof
injectedcodefromjumpingeasilytocodethatisalreadyloadedinaprocessas
part of normal operation. This safeguard makes it likely that a system under
attackwillfailorcrashratherthanlettheattackingcodetakecontrol.
Recent chips from both Intel and AMD are based on the AMD64 architec-
ture, which allows memory pages to be marked so that they cannot contain
executableinstructioncode.Windowstriestomarkstacksandmemoryheaps
sothattheycannotbeusedtoexecutecode,thuspreventingattacksinwhich
a program bug allows a buffer to overflow and then is tricked into executing
the contents of the buffer. This technique cannot be applied to all programs,
becausesomerelyonmodifyingdataandexecutingit.Acolumnlabeled“data
execution prevention” in the Windows task manager shows which processes
aremarkedtopreventtheseattacks.
Windowsusesencryptionaspartofcommonprotocols,suchasthoseused
to communicate securely with websites. Encryption is also used to protect
user files stored on disk from prying eyes. Windows 7 allows users to easily
encryptvirtuallyawholedisk,aswellasremovablestoragedevicessuchasUSB
flash drives,with afeaturecalledBitLocker.Ifacomputer withan encrypted
diskisstolen,thethieveswillneedverysophisticatedtechnology(suchasan
electron microscope) to gain access to any of the computer’s files. Windows
usesdigitalsignaturestosignoperatingsystembinariessoitcanverifythatthe
fileswereproducedbyMicrosoftoranotherknowncompany.Insomeeditions
ofWindows,acodeintegritymoduleisactivatedatboottoensurethatallthe
loaded modules in the kernel have valid signatures, assuring that they have
notbeentamperedwithbyanoff-lineattack.
B.2.2 Reliability
Windowsmaturedgreatlyasanoperatingsysteminitsfirsttenyears,leading
toWindows2000.Atthesametime,itsreliabilityincreasedduetosuchfactors
asmaturityinthesourcecode,extensivestresstestingofthesystem,improved
CPU architectures, and automatic detection of many serious errors in drivers
from both Microsoft and third parties. Windows has subsequently extendedB.2 DesignPrinciples 5
thetoolsforachievingreliabilitytoincludeautomaticanalysisofsourcecode
forerrors,teststhatincludeprovidinginvalidorunexpectedinputparameters
(knownasfuzzing)todetectvalidationfailures,andanapplicationversionof
thedriververifierthat appliesdynamicchecking for anextensivesetofcom-
monuser-modeprogrammingerrors.Otherimprovementsinreliabilityhave
resultedfrommovingmorecodeoutofthekernelandintouser-modeservices.
Windowsprovidesextensivesupportforwritingdriversinusermode.System
facilities that were once in the kernel and are now in user mode include the
DesktopWindowManagerandmuchofthesoftwarestackforaudio.
OneofthemostsignificantimprovementsintheWindowsexperiencecame
from adding memory diagnostics as an option at boot time. This addition is
especiallyvaluablebecausesofewconsumerPCshaveerror-correctingmem-
ory.WhenbadRAMstartstodropbitshereandthere,theresultisfrustratingly
erratic behavior in the system. The availability of memory diagnostics has
greatlyreducedthestresslevelsofuserswithbadRAM.
Windows7introducedafault-tolerantmemoryheap.Theheaplearnsfrom
applicationcrashesandautomaticallyinsertsmitigationsintofutureexecution
of an application that has crashed. This makes the application more reliable
even if it contains common bugs such as using memory after freeing it or
accessingpasttheendoftheallocation.
AchievinghighreliabilityinWindowsisparticularlychallengingbecause
almost one billion computers run Windows. Even reliability problems that
affect only a small percentage of users still impact tremendous numbers of
human beings. The complexity of the Windows ecosystem also adds to the
challenges.Millionsofinstancesofapplications,drivers,andothersoftwareare
beingconstantlydownloadedandrunonWindowssystems.Ofcourse,there
is also a constant stream of malware attacks. As Windows itself has become
hardertoattackdirectly,exploitsincreasinglytargetpopularapplications.
Tocopewiththesechallenges,Microsoftisincreasinglyrelyingoncommu-
nications from customer machines to collect large amounts of data from the
ecosystem. Machines can be sampled to see how they are performing, what
software they are running, and what problems they are encountering. Cus-
tomerscansenddatatoMicrosoftwhensystemsorsoftwarecrashesorhangs.
This constant stream of data from customer machines is collected very care-
fully,withtheusers’consentand withoutinvadingprivacy.Theresultisthat
Microsoft is building an ever-improving picture of what is happening in the
Windows ecosystem that allows continuous improvements through software
updates,aswellasprovidingdatatoguidefuturereleasesofWindows.
B.2.3 Windows and POSIX Application Compatibility
As mentioned, Windows XP was both an update of Windows 2000 and a
replacementforWindows95/98.Windows2000focusedprimarilyoncompat-
ibilityforbusinessapplications.TherequirementsforWindowsXPincludeda
much greater compatibility with the consumer applications that ran on Win-
dows 95/98. Application compatibility is difficult to achieve because many
applicationscheck foraparticularversionofWindows, may dependtosome
extentonthequirksoftheimplementationofAPIs,mayhavelatentapplication
bugsthatweremaskedintheprevioussystem,andsoforth.Applicationsmay6 AppendixB Windows7
alsohavebeencompiledforadifferentinstructionset.Windows7implements
severalstrategiestorunapplicationsdespiteincompatibilities.
Like Windows XP, Windows 7 has a compatibility layer that sits between
applications and the Win32 APIs. This layer makes Windows 7 look (almost)
bug-for-bugcompatiblewithpreviousversionsofWindows.Windows7,like
earlier NT releases, maintains support for running many 16-bit applications
using a thunking, or conversion, layer that translates 16-bit API calls into
equivalent 32-bit calls. Similarly, the 64-bit version of Windows 7 provides a
thunkinglayerthattranslates32-bitAPIcallsintonative64-bitcalls.
TheWindowssubsystemmodelallowsmultipleoperating-systemperson-
alitiestobesupported.Asnotedearlier,althoughtheAPImostcommonlyused
withWindowsistheWin32API,someeditionsofWindows7supportaPOSIX
subsystem.POSIXisastandardspecificationforUNIXthatallowsmostavailable
UNIX-compatiblesoftwaretocompileandrunwithoutmodification.
Asafinalcompatibilitymeasure,severaleditionsofWindows7providea
virtualmachinethatrunsWindowsXPinsideWindows7.Thisallowsapplica-
tionstogetbug-for-bugcompatibilitywithWindowsXP.
B.2.4 High Performance
Windows was designed to provide high performance on desktop systems
(whicharelargelyconstrainedbyI/Operformance),serversystems(wherethe
CPUisoftenthebottleneck),andlargemultithreadedandmultiprocessorenvi-
ronments (where locking performance and cache-line management are keys
toscalability).Tosatisfyperformancerequirements,NTusedavarietyoftech-
niques, such as asynchronous I/O, optimized protocols for networks, kernel-
based graphics rendering, and sophisticated caching of file-system data. The
memory-managementandsynchronizationalgorithmsweredesignedwithan
awarenessoftheperformanceconsiderationsrelatedtocachelinesandmulti-
processors.
Windows NT was designed for symmetrical multiprocessing (SMP); on a
multiprocessorcomputer,severalthreadscanrunatthesametime,eveninthe
kernel.OneachCPU,WindowsNTusespriority-basedpreemptivescheduling
of threads. Except while executing in the kernel dispatcher or at interrupt
level,threadsinanyprocessrunninginWindowscanbepreemptedbyhigher-
prioritythreads.Thus,thesystemrespondsquickly(seeChapter5).
The subsystems that constitute Windows NT communicate with one
another efficiently through a local procedure call (LPC) facility that provides
high-performance message passing. When a thread requests a synchronous
service from another process through an LPC, the servicing thread is marked
ready, and its priority is temporarily boosted to avoid the scheduling delays
thatwouldoccurifithadtowaitforthreadsalreadyinthequeue.
Windows XP further improved performance by reducing the code-path
length in critical functions, using better algorithms and per-processor data
structures, using memory coloring for non-uniform memory access (NUMA)
machines,andimplementingmorescalablelockingprotocols,suchasqueued
spinlocks. The new locking protocols helped reduce system bus cycles and
included lock-free lists and queues, atomic read–modify–write operations
(likeinterlockedincrement),andotheradvancedsynchronizationtechniques.B.2 DesignPrinciples 7
By the time Windows 7 was developed, several major changes had come
to computing. Client/server computing had increased in importance, so
an advanced local procedure call (ALPC) facility was introduced to provide
higher performance and more reliability than LPC. The number of CPUs and
the amount of physical memory available in the largest multiprocessors
had increased substantially, so quite a lot of effort was put into improving
operating-systemscalability.
The implementation of SMP in Windows NT used bitmasks to represent
collectionsofprocessorsandtoidentify,forexample,whichsetofprocessorsa
particularthreadcouldbescheduledon.Thesebitmasksweredefinedasfitting
withinasinglewordofmemory,limitingthenumberofprocessorssupported
within a system to 64. Windows 7 added the concept of processor groups to
represent arbitrary numbers of CPUs, thus accommodating more CPU cores.
ThenumberofCPUcoreswithinsinglesystemshascontinuedtoincreasenot
only because of more cores but also because of cores that support more than
onelogicalthreadofexecutionatatime.
All these additional CPUs created a great deal of contention for the locks
usedforschedulingCPUsandmemory.Windows7broketheselocksapart.For
example,beforeWindows7,asinglelockwasusedbytheWindowsscheduler
to synchronize access to the queues containing threads waiting for events. In
Windows 7, each object has its own lock, allowing the queues to be accessed
concurrently.Also,manyexecutionpathsintheschedulerwererewrittentobe
lock-free. This change resulted in good scalability performance for Windows
evenonsystemswith256hardwarethreads.
Other changes are due to the increasing importance of support for par-
allel computing. For years, the computer industry has been dominated by
Moore’s Law, leading to higher densities of transistors that manifest them-
selvesas faster clock rates for each CPU. Moore’s Lawcontinues tohold true,
but limits have been reached that prevent CPU clock rates from increasing
further. Instead,transistors are being used to build more and more CPUs into
eachchip.Newprogrammingmodelsforachievingparallelexecution,suchas
Microsoft’s Concurrency RunTime (ConcRT) and Intel’s Threading Building
Blocks (TBB), are being used to express parallelism in C++ programs. Where
Moore’s Law has governed computing for forty years, it now seems that
Amdahl’sLaw,whichgovernsparallelcomputing,willrulethefuture.
To support task-based parallelism, Windows 7 provides a new form of
user-mode scheduling (UMS). UMS allows programs to be decomposed into
tasks, and the tasks are then scheduled on the available CPUs by a scheduler
thatoperatesinusermoderatherthaninthekernel.
The advent of multiple CPUs on the smallest computers is only part of
theshifttakingplacetoparallelcomputing.Graphicsprocessingunits(GPUs)
accelerate the computational algorithms needed for graphics by using SIMD
architectures to execute a single instruction for multiple data at the same
time. This has given rise to the use of GPUs for general computing, not just
graphics. Operating-system support for software like OpenCL and CUDA is
allowing programs to take advantage of the GPUs. Windows supports use of
GPUs through software in its DirectX graphics support. This software, called
DirectCompute,allowsprogramstospecifycomputationalkernelsusingthe
sameHLSL(high-levelshaderlanguage)programmingmodelusedtoprogram
theSIMDhardwareforgraphicsshaders.Thecomputationalkernelsrunvery8 AppendixB Windows7
quicklyon the GPUand returntheirresultstothe maincomputation running
ontheCPU.
B.2.5 Extensibility
Extensibility refers to the capacity of an operating system to keep up with
advances in computing technology. To facilitate change over time, the devel-
opersimplementedWindowsusingalayeredarchitecture.TheWindowsexec-
utiverunsinkernelmodeandprovidesthebasicsystemservicesandabstrac-
tions that support shared use of the system. On top of the executive, several
serversubsystemsoperateinusermode.Amongthemareenvironmentalsub-
systemsthatemulatedifferentoperatingsystems.Thus,programswrittenfor
theWin32APIsandPOSIXallrunonWindowsintheappropriateenvironment.
Because of the modular structure, additional environmental subsystems can
beaddedwithoutaffectingtheexecutive.Inaddition,Windowsusesloadable
driversin the I/O system,so new file systems,new kinds of I/O devices,and
newkindsofnetworkingcanbeaddedwhilethesystemisrunning.Windows
usesaclient–servermodelliketheMachoperatingsystemandsupportsdis-
tributedprocessingbyremoteprocedurecalls(RPCs)asdefinedbytheOpen
SoftwareFoundation.
B.2.6 Portability
An operating system is portable if it can be moved from one CPU architec-
turetoanotherwithfewchanges.Windowswasdesignedtobeportable.Like
the UNIX operating system, Windows is written primarily in C and C++. The
architecture-specific source code is relatively small, and there is very little
use of assembly code. Porting Windows to a new architecture mostly affects
the Windows kernel, since the user-mode code in Windows is almost exclu-
sively written to be architecture independent. To port Windows, the kernel’s
architecture-specific code must be ported,and sometimes conditional compi-
lationis neededin otherparts ofthekernelbecause ofchanges inmajor data
structures, such as the page-table format. The entire Windows system must
thenberecompiledforthenewCPUinstructionset.
Operating systems are sensitive not only to CPU architecture but also to
CPU support chips and hardware boot programs. The CPU and support chips
arecollectivelyknownasachipset.Thesechipsetsandtheassociatedbootcode
determinehowinterruptsaredelivered,describethephysicalcharacteristicsof
eachsystem,andprovideinterfacestodeeperaspectsoftheCPUarchitecture,
such as error recovery and power management. It would be burdensome to
have to port Windows to each type of support chip as well as to each CPU
architecture.Instead,Windowsisolatesmostofthechipset-dependentcodein
adynamiclinklibrary(DLL),calledthehardware-abstractionlayer(HAL),that
isloadedwiththekernel.TheWindowskerneldependsontheHALinterfaces
rather than on the underlying chipset details. This allows the single set of
kernelanddriverbinariesforaparticularCPUtobeusedwithdifferentchipsets
simplybyloadingadifferentversionoftheHAL.
Over the years, Windows has been ported to a number of different CPU
architectures:IntelIA-32-compatible32-bitCPUs,AMD64-compatibleandIA64
64-bit CPUs, the DEC Alpha, and the MIPS and PowerPC CPUs. Most of these
CPUarchitecturesfailedinthemarket.WhenWindows7shipped,onlytheIA-B.2 DesignPrinciples 9
32 and AMD64 architectures were supported on client computers, along with
AMD64andIA64onservers.
B.2.7 International Support
Windows was designed for international and multinational use. It provides
support for different locales via the national-language-support (NLS) API.
The NLS API provides specialized routines to format dates, time, and money
in accordance with national customs. String comparisons are specialized to
account for varying character sets. UNICODE is Windows’s native character
code. Windows supports ANSI characters by converting them to UNICODE
characters before manipulating them (8-bit to 16-bit conversion). System text
strings are kept in resource files that can be replaced to localize the system
for different languages. Multiple locales can be used concurrently, which is
importanttomultilingualindividualsandbusinesses.
B.2.8 Energy Efficiency
Increasing energy efficiency for computers causes batteries to last longer for
laptopsandnetbooks,savessignificantoperatingcostsforpowerandcooling
ofdatacenters,and contributes togreeninitiativesaimedat loweringenergy
consumption by businesses and consumers. For some time, Windows has
implementedseveralstrategiesfordecreasingenergyuse.TheCPUsaremoved
tolowerpowerstates—forexample,byloweringclockfrequency—whenever
possible. In addition, when a computer is not being actively used, Windows
mayputtheentirecomputerintoalow-powerstate(sleep)ormayevensave
allofmemorytodiskandshutthecomputeroff(hibernation).Whentheuser
returns,thecomputerpowersupandcontinuesfromitspreviousstate,sothe
userdoesnotneedtorebootandrestartapplications.
Windows7addedsomenewstrategiesforsavingenergy.ThelongeraCPU
canstayunused,themoreenergycanbesaved.Becausecomputersaresomuch
fasterthanhumanbeings,alotofenergycanbesavedjustwhilehumansare
thinking. The problem is that too many programs are constantly polling to
see what is happening in the system. Aswarm of software timers are firing,
keepingtheCPUfromstayingidlelongenoughtosavemuchenergy.Windows
7extendsCPUidletimebyskippingclockticks,coalescingsoftwaretimersinto
smaller numbers of events, and “parking” entire CPUs when systems are not
heavilyloaded.
B.2.9 Dynamic Device Support
Early in the history of the PC industry, computer configurations were fairly
static. Occasionally, new devices might be plugged into the serial, printer, or
gameports on the back ofacomputer, but that was it.The next stepstoward
dynamicconfigurationofPCswerelaptopdocksandPCMIAcards.APCcould
suddenlybeconnectedtoordisconnectedfromawholesetofperipherals.In
acontemporaryPC,thesituationhascompletelychanged.PCsaredesignedto
let users to plug and unplug a huge host of peripherals all the time; external
disks,thumbdrives,cameras,andthelikeareconstantlycomingandgoing.
Support for dynamic configuration of devices is continually evolving in
Windows. The system can automatically recognize devices when they are10 AppendixB Windows7
logon OS/2 Win16 Win32 MS-DOS POSIX
process applications applications applications applications applications
security OS/2 Win18 MS-DOS POSIX
subsystem subsystem VDM VDM subsystem
authentication
package
security account
manager database Win32
subsystem
user mode
executive
I/O manager
security plug and virtual local
file cs ay cs hte em mo ab nj ae gct er re mfe or ne in toc re mpr ao nc ae gs es r map nla ay
ger
mm ae nm ao gr ey
r
proc ce ad llure mw ain nd ao gw
er
manager facility
device
drivers
kernel graphic
network
drivers device
drivers
hardware abstraction layer
hardware
FigureB.1 Windowsblockdiagram.
pluggedinandcanfind,install,andloadtheappropriatedrivers—oftenwith-
outuserintervention.Whendevicesareunplugged,thedriversautomatically
unload,andsystemexecutioncontinueswithoutdisruptingothersoftware.
B.3 System Components
ThearchitectureofWindowsisalayeredsystemofmodules,asshowninFig-
ureB.1.ThemainlayersaretheHAL,thekernel,andtheexecutive,allofwhich
runinkernelmode,andacollectionofsubsystemsandservicesthatruninuser
mode.The user-modesubsystems fall intotwo categories:the environmental
subsystems, which emulate different operating systems, and the protection
subsystems,whichprovidesecurityfunctions.Oneofthechiefadvantagesof
thistypeofarchitectureisthatinteractionsbetweenmodulesarekeptsimple.
Theremainderofthissectiondescribestheselayersandsubsystems.
B.3.1 Hardware-Abstraction Layer
The HAL is the layer of software that hides hardware chipset differences
from upper levels of the operating system. The HAL exports a virtual hard-
ware interface that is used by the kernel dispatcher, the executive, and the
device drivers. Only a single version of each device driver is required forB.3 SystemComponents 11
eachCPUarchitecture,nomatterwhatsupportchipsmightbepresent.Device
drivers map devices and access them directly, but the chipset-specific details
ofmappingmemory,configuringI/Obuses,settingupDMA,andcopingwith
motherboard-specificfacilitiesareallprovidedbytheHALinterfaces.
B.3.2 Kernel
ThekernellayerofWindowshasfourmainresponsibilities:threadscheduling,
low-level processor synchronization, interrupt and exception handling, and
switching between user mode and kernel mode. The kernel is implemented
intheClanguage,usingassemblylanguageonlywhereabsolutelynecessary
tointerfacewiththelowestlevelofthehardwarearchitecture.
Thekernelisorganizedaccordingtoobject-orienteddesignprinciples.An
objecttypeinWindowsisasystem-defineddatatypethathasasetofattributes
(datavalues)andasetofmethods(forexample,functions oroperations).An
object is an instance of an object type.The kernel performs its job by using a
setofkernelobjectswhoseattributesstorethekerneldataandwhosemethods
performthekernelactivities.
B.3.2.1 KernelDispatcher
Thekerneldispatcherprovidesthefoundation for theexecutiveand the sub-
systems.Mostofthedispatcherisneverpagedoutofmemory,anditsexecu-
tion is never preempted. Its main responsibilities are thread scheduling and
contextswitching,implementationofsynchronizationprimitives,timerman-
agement, software interrupts (asynchronous and deferred procedure calls),
andexceptiondispatching.
B.3.2.2 ThreadsandScheduling
Like many other modern operating systems, Windows uses processes and
threads for executable code. Each process has one or more threads, and each
threadhasitsownschedulingstate,includingactualpriority,processoraffinity,
andCPUusageinformation.
There are six possible thread states: ready, standby, running, waiting,
transition, and terminated. Ready indicates that the thread is waiting to
run. The highest-priority ready thread is moved to the standby state, which
meansitisthenextthreadtorun.Inamultiprocessorsystem,eachprocessor
keepsonethreadinastandbystate.Athreadisrunningwhenitisexecuting
on a processor. It runs until it is preemptedby a higher-priority thread, until
itterminates,untilitsallottedexecutiontime(quantum)ends,oruntilitwaits
onadispatcherobject,suchasaneventsignalingI/Ocompletion.Athreadis
inthe waiting statewhen it is waiting for adispatcher object tobe signaled.
Athreadis inthe transitionstatewhileitwaits for resourcesnecessaryfor
execution;forexample,itmaybewaitingforitskernelstacktobeswappedin
fromdisk.Athreadenterstheterminatedstatewhenitfinishesexecution.
The dispatcher uses a 32-level priority scheme to determine the order of
threadexecution.Prioritiesaredividedintotwoclasses:variableclassandreal-
time class. The variable class contains threads having priorities from 1 to 15,
andthereal-timeclasscontains threadswithprioritiesranging from16to31.12 AppendixB Windows7
Thedispatcherusesaqueueforeachschedulingpriorityandtraversestheset
ofqueuesfromhighesttolowestuntilitfindsathreadthatisreadytorun.Ifa
threadhasaparticularprocessoraffinitybutthatprocessorisnotavailable,the
dispatcherskipspastitandcontinueslookingforareadythreadthatiswilling
to run on the available processor. If no ready thread is found, the dispatcher
executesaspecialthreadcalledtheidlethread.Priorityclass0isreservedfor
theidlethread.
When a thread’s time quantum runs out, the clock interrupt queues a
quantum-end deferred procedure call (DPC) to the processor. Queuing the
DPC results in a software interrupt when the processor returns to normal
interrupt priority. The software interrupt causes the dispatcher to reschedule
the processor to execute the next available thread at the preempted thread’s
prioritylevel.
The priorityof the preemptedthread may be modifiedbefore it is placed
back on the dispatcher queues. If the preempted thread is in the variable-
priority class, its priority is lowered. The priority is never lowered below the
base priority.Lowering the thread’s prioritytendstolimitthe CPU consump-
tion of compute-bound threads versus I/O-bound threads. When a variable-
priority thread is released from a wait operation, the dispatcher boosts the
priority.Theamountoftheboostdependsonthedeviceforwhichthethread
waswaiting.Forexample,athreadwaitingforkeyboardI/Owouldgetalarge
priority increase, whereas a thread waiting for a disk operation would get a
moderate one. This strategy tends to give good response times to interactive
threadsusingamouseandwindows.ItalsoenablesI/O-boundthreadstokeep
the I/O devices busy while permitting compute-bound threads to use spare
CPUcyclesinthebackground.Inaddition,thethreadassociatedwiththeuser’s
activeGUIwindowreceivesapriorityboosttoenhanceitsresponsetime.
Scheduling occurs when a thread enters the ready or wait state, when a
threadterminates,or when an applicationchanges athread’s priorityor pro-
cessoraffinity.Ifahigher-prioritythreadbecomesreadywhilealower-priority
thread is running, the lower-priority thread is preempted. This preemption
givesthehigher-prioritythreadpreferentialaccesstotheCPU.Windowsisnot
ahardreal-timeoperatingsystem,however,becauseitdoesnotguaranteethat
a real-time thread will start to execute within a particular time limit; threads
are blocked indefinitely while DPCs and interrupt service routines (ISRs) are
running(asdiscussedfurtherbelow).
Traditionally,operating-systemschedulersusedsamplingtomeasureCPU
utilizationbythreads.Thesystemtimerwouldfireperiodically,andthetimer
interrupthandlerwouldtakenoteofwhatthreadwascurrentlyscheduledand
whetheritwasexecutinginuserorkernelmodewhentheinterruptoccurred.
This sampling technique was necessary because either the CPU did not have
a high-resolution clock or the clock was too expensiveor unreliable to access
frequently.Although efficient, sampling was inaccurate and led to anomalies
suchasincorporatinginterruptservicingtimeasthreadtimeanddispatching
threadsthathadrunforonlyafractionofthequantum.StartingwithWindows
Vista,CPUtimeinWindows has beentrackedusingthehardwaretimestamp
counter (TSC) included in recent processors. Using the TSC results in more
accurateaccountingofCPUusage,andtheschedulerwillnotpreemptthreads
beforetheyhaverunforafullquantum.B.3 SystemComponents 13
B.3.2.3 ImplementationofSynchronizationPrimitives
Key operating-system data structures are managed as objects using common
facilities for allocation, reference counting, and security. Dispatcher objects
control dispatching and synchronization in the system. Examples of these
objectsincludethefollowing:
• Theeventobjectisusedtorecordaneventoccurrenceandtosynchronize
this occurrence with some action. Notification events signal all waiting
threads,andsynchronizationeventssignalasinglewaitingthread.
• Themutantprovideskernel-modeoruser-modemutualexclusionassoci-
atedwiththenotionofownership.
• Themutex,availableonlyinkernelmode,providesdeadlock-freemutual
exclusion.
• The semaphore object acts as a counter or gate to control the number of
threadsthataccessaresource.
• Thethreadobjectistheentitythatisscheduledbythekerneldispatcher.
Itisassociatedwithaprocessobject,whichencapsulatesavirtualaddress
space.Thethreadobjectissignaledwhenthethreadexits,andtheprocess
object,whentheprocessexits.
• Thetimerobjectisusedtokeeptrackoftimeandtosignaltimeoutswhen
operations take too long and need to be interrupted or when a periodic
activityneedstobescheduled.
Many of the dispatcher objects are accessed from user mode via an open
operationthatreturnsahandle.Theuser-modecodepollsorwaitsonhandles
to synchronize with other threads as well as with the operating system (see
SectionB.7.1).
B.3.2.4 SoftwareInterrupts:AsynchronousandDeferredProcedureCalls
The dispatcher implements two types of software interrupts: asynchronous
procedurecalls(APCs)anddeferredprocedurecalls(DPCs,mentionedearlier).
An asynchronous procedure call breaks into an executing thread and calls
a procedure. APCs are used to begin execution of new threads, suspend or
resume existing threads, terminate threads or processes, deliver notification
that an asynchronous I/O has completed, and extract the contents of the CPU
registersfromarunningthread.APCsarequeuedtospecificthreadsandallow
the system to execute both system and user code within a process’s context.
User-modeexecutionofanAPCcannotoccuratarbitrarytimes,butonlywhen
thethreadiswaitinginthekernelandmarkedalertable.
DPCsare used to postpone interruptprocessing. After handling all urgent
device-interrupt processing, the ISR schedules the remaining processing by
queuingaDPC.TheassociatedsoftwareinterruptwillnotoccuruntiltheCPUis
nextataprioritylowerthanthepriorityofallI/Odeviceinterruptsbuthigher
than the priority at which threads run. Thus, DPCs do not block other device
ISRs.Inadditiontodeferringdevice-interruptprocessing,thedispatcheruses14 AppendixB Windows7
DPCstoprocesstimerexpirationsandtopreemptthreadexecutionattheend
oftheschedulingquantum.
Execution of DPCs prevents threads from being scheduled on the current
processor and also keeps APCs from signaling the completion of I/O. This is
done so that completion of DPC routines does not take an extended amount
oftime.Asanalternative,thedispatchermaintains apoolofworkerthreads.
ISRsandDPCsmayqueueworkitemstotheworkerthreadswheretheywillbe
executed using normal thread scheduling. DPC routines are restricted so that
they cannot take page faults (be paged out of memory), call system services,
ortakeanyotheractionthatmightresultinanattempttowaitforadispatcher
object to be signaled. Unlike APCs, DPC routines make no assumptions about
whatprocesscontexttheprocessorisexecuting.
B.3.2.5 ExceptionsandInterrupts
The kernel dispatcher also provides trap handling for exceptions and
interrupts generated by hardware or software. Windows defines several
architecture-independentexceptions,including:
• Memory-accessviolation
• Integeroverflow
• Floating-pointoverfloworunderflow
• Integerdividebyzero
• Floating-pointdividebyzero
• Illegalinstruction
• Datamisalignment
• Privilegedinstruction
• Page-readerror
• Accessviolation
• Pagingfilequotaexceeded
• Debuggerbreakpoint
• Debuggersinglestep
The trap handlers deal with simple exceptions. Elaborate exception handling
is performed by the kernel’s exception dispatcher. The exception dispatcher
creates an exceptionrecord containing the reason for the exception and finds
anexceptionhandlertodealwithit.
Whenanexceptionoccursinkernelmode,theexceptiondispatchersimply
calls a routine to locate the exception handler. If no handler is found, a fatal
system error occurs, and the user is left with the infamous “blue screen of
death”thatsignifiessystemfailure.
Exception handling is more complex for user-mode processes, because
an environmental subsystem (such as the POSIX system) sets up a debugger
port and an exception port for every process it creates. (For details on ports,B.3 SystemComponents 15
see Section B.3.3.4.) If a debugger port is registered, the exception handler
sendstheexceptiontothe port.Ifthe debuggerportis not found or doesnot
handlethatexception,thedispatcherattemptstofindanappropriateexception
handler.Ifnohandlerisfound,thedebuggeriscalledagaintocatchtheerror
for debugging. If no debugger is running, a message is sent to the process’s
exceptionport to give the environmental subsystem a chance to translate the
exception.Forexample,thePOSIXenvironmenttranslatesWindowsexception
messages into POSIX signals before sending them to the thread that caused
theexception.Finally,ifnothing elseworks, thekernelsimplyterminatesthe
processcontainingthethreadthatcausedtheexception.
WhenWindowsfailstohandleanexception,itmayconstructadescription
of the error that occurred and request permission from the user to send the
information back to Microsoft for further analysis. In some cases, Microsoft’s
automated analysis may be able to recognize the error immediately and sug-
gestafixorworkaround.
Theinterruptdispatcherinthekernelhandlesinterruptsbycallingeither
aninterruptserviceroutine(ISR)suppliedbyadevicedriverorakerneltrap-
handlerroutine.Theinterruptisrepresentedbyaninterruptobjectthatcon-
tains all the information needed to handle the interrupt. Using an interrupt
object makes it easy to associate interrupt-service routines with an interrupt
withouthavingtoaccesstheinterrupthardwaredirectly.
Differentprocessorarchitectureshavedifferenttypesandnumbersofinter-
rupts. For portability, the interrupt dispatcher maps the hardware interrupts
into a standard set. The interrupts are prioritized and are serviced in prior-
ity order. There are 32 interrupt request levels (IRQLs) in Windows. Eight are
reservedforusebythekernel;theremaining24representhardwareinterrupts
viatheHAL(althoughmostIA-32systemsuseonly16).TheWindowsinterrupts
aredefinedinFigureB.2.
The kernel uses an interrupt-dispatch table to bind each interrupt level
toaserviceroutine.Inamultiprocessorcomputer,Windowskeepsaseparate
interrupt-dispatchtable(IDT)foreachprocessor,andeachprocessor’sIRQLcan
besetindependentlytomaskoutinterrupts.Allinterruptsthatoccuratalevel
equaltoorlessthantheIRQLofaprocessorareblockeduntiltheIRQLislowered
interrupt levels types of interrupts
31 machine check or bus error
30 power fail
29 interprocessor notification (request another processor
to act; e.g., dispatch a process or update the TLB)
28 clock (used to keep track of time)
27 profile
3–26 traditional PC IRQ hardware interrupts
2 dispatch and deferred procedure call (DPC) (kernel)
1 asynchronous procedure call (APC)
0 passive
FigureB.2 Windowsinterrupt-requestlevels.16 AppendixB Windows7
by a kernel-level thread or by an ISR returning from interrupt processing.
Windows takes advantage of this property and uses software interrupts to
deliver APCs and DPCs, to perform system functions such as synchronizing
threadswithI/Ocompletion,tostartthreadexecution,andtohandletimers.
B.3.2.6 SwitchingbetweenUser-ModeandKernel-ModeThreads
WhattheprogrammerthinksofasathreadintraditionalWindowsisactually
two threads: a user-mode thread (UT) and a kernel-mode thread (KT). Each
has its own stack, register values, and execution context. A UT requests a
system serviceby executing an instruction that causes a trap to kernel mode.
The kernel layer runs a trap handler that switches between the UT and the
correspondingKT.WhenaKThascompleteditskernelexecutionandisready
toswitchbacktothecorrespondingUT,thekernellayeriscalledtomakethe
switchtotheUT,whichcontinuesitsexecutioninusermode.
Windows 7 modifies the behavior of the kernel layer to support user-
mode scheduling of the UTs. User-mode schedulers in Windows 7 support
cooperative scheduling. A UT can explicitly yield to another UT by calling
the user-mode scheduler; it is not necessary to enter the kernel. User-mode
schedulingisexplainedinmoredetailinSectionB.7.3.7.
B.3.3 Executive
TheWindowsexecutiveprovidesasetofservicesthatallenvironmentalsub-
systems use. The services are grouped as follows: object manager, virtual
memorymanager,processmanager,advancedlocalprocedurecallfacility,I/O
manager,cachemanager,securityreferencemonitor,plug-and-playandpower
managers,registry,andbooting.
B.3.3.1 ObjectManager
For managing kernel-mode entities, Windows uses a generic set of interfaces
that are manipulated by user-mode programs. Windows calls these entities
objects, and the executive component that manipulates them is the object
manager. Examples of objects are semaphores, mutexes, events, processes,
and threads; all these are dispatcher objects. Threads can block in the ker-
nel dispatcher waiting for any of these objects to be signaled. The process,
thread, and virtual memory APIs use process and thread handles to identify
the process or thread to be operated on. Other examples of objects include
files, sections, ports, and various internal I/O objects. File objects are used to
maintain the open state of files and devices. Sections are used to map files.
Local-communicationendpointsareimplementedasportobjects.
User-mode code accesses these objects using an opaque value called a
handle, which is returned by many APIs. Each process has a handle table
containing entriesthat tracktheobjectsusedbytheprocess.Thesystem pro-
cess, which contains the kernel, has its own handle table, which is protected
fromusercode.ThehandletablesinWindowsarerepresentedbyatreestruc-
ture,whichcanexpandfromholding1,024handlestoholdingover16million.
Kernel-modecodecanaccessanobjectbyusingeitherahandleorareferenced
pointer.B.3 SystemComponents 17
Aprocessgetsahandlebycreatinganobject,byopeninganexistingobject,
by receiving a duplicated handle from another process, or by inheriting a
handlefromtheparentprocess.Whenaprocessexits,allitsopenhandlesare
implicitly closed. Since the object manager is the only entity that generates
object handles, it is the natural place to check security. The object manager
checks whether a process has the right to access an object when the process
tries to open the object. The object manager also enforces quotas, such as the
maximumamountofmemoryaprocessmayuse,bychargingaprocessforthe
memory occupied by all its referenced objects and refusing to allocate more
memorywhentheaccumulatedchargesexceedtheprocess’squota.
Theobjectmanagerkeepstrackoftwocountsforeachobject:thenumber
of handles for the object and the number of referenced pointers. The handle
count is the number of handles that refer to the object in the handle tables
of all processes, including the system process that contains the kernel. The
referenced pointer count is incremented whenever a new pointer is needed
bythekernelanddecrementedwhenthekernelisdonewiththepointer.The
purposeofthesereferencecountsistoensurethatanobjectisnotfreedwhile
itisstillreferencedbyeitherahandleoraninternalkernelpointer.
The object manager maintains the Windows internal name space. In con-
trasttoUNIX,whichrootsthesystemnamespaceinthefilesystem,Windows
usesanabstractnamespaceandconnectsthefilesystemsasdevices.Whether
a Windows object has a name is up to its creator. Processes and threads are
createdwithoutnamesandreferencedeitherbyhandleorthroughaseparate
numericalidentifier.Synchronizationeventsusuallyhavenames,sothatthey
can be opened by unrelated processes. A name can be either permanent or
temporary.Apermanent name representsan entity,such as a diskdrive,that
remainsevenifnoprocessisaccessingit.Atemporarynameexistsonlywhile
aprocessholdsahandletotheobject.Theobjectmanagersupportsdirectories
and symbolic links in the name space. As an example, MS-DOS drive letters
areimplementedusingsymboliclinks;∖Global??∖C:isasymboliclinktothe
device object ∖Device∖HarddiskVolume2,representing a mounted file-system
volumeinthe∖Devicedirectory.
Eachobject,asmentionedearlier,isaninstanceofanobjecttype.Theobject
type specifies how instances are to be allocated, how the data fields are to
be defined, and how the standard set of virtual functions used for all objects
aretobeimplemented.Thestandardfunctionsimplementoperationssuchas
mappingnamestoobjects,closinganddeleting,andapplyingsecuritychecks.
Functions that are specific to a particular type of object are implemented by
system servicesdesignedto operate on that particular object type, not by the
methodsspecifiedintheobjecttype.
The parse() function is the most interesting of the standard object func-
tions. It allows the implementationof an object. The file systems,the registry
configuration store, and GUI objects are the most notable users of parse func-
tionstoextendtheWindowsnamespace.
Returning to our Windows naming example, device objects used to rep-
resent file-system volumes provide a parse function. This allows a name like
∖Global??∖C:∖foo∖bar.docto be interpreted as the file ∖foo∖bar.doc on the
volume represented by the device object HarddiskVolume2.We can illustrate
how naming, parse functions, objects, and handles work together by looking
atthestepstoopenthefileinWindows:18 AppendixB Windows7
1. AnapplicationrequeststhatafilenamedC:∖foo∖bar.docbeopened.
2. The object manager finds the device object HarddiskVolume2, looks up
theparseprocedureIopParseDevicefromtheobject’stype,andinvokes
itwiththefile’snamerelativetotherootofthefilesystem.
3. IopParseDevice()allocatesafileobjectandpassesittothefilesystem,
whichfillsinthedetailsofhowtoaccessC:∖foo∖bar.doconthevolume.
4. When the file system returns,IopParseDevice() allocates an entry for
thefileobject inthehandletableforthecurrentprocessandreturnsthe
handletotheapplication.
If the file cannot successfully be opened, IopParseDevice() deletes the
fileobjectitallocatedandreturnsanerrorindicationtotheapplication.
B.3.3.2 VirtualMemoryManager
The executive component that manages the virtual address space, physi-
cal memory allocation, and paging is the virtual memory (VM) manager.
The design of the VM manager assumes that the underlying hardware sup-
portsvirtual-to-physicalmapping,apagingmechanism,andtransparentcache
coherenceonmultiprocessorsystems,aswellasallowingmultiplepage-table
entriestomaptothesamephysicalpageframe.TheVMmanagerinWindows
uses a page-based management scheme with page sizes of 4 KB and 2 MB on
AMD64 and IA-32-compatible processors and 8 KB on the IA64. Pages of data
allocatedtoaprocessthatarenotinphysicalmemoryareeitherstoredinthe
paging file on disk or mapped directly to a regular file on a local or remote
filesystem.Apagecanalsobemarkedzero-fill-on-demand,which initializes
thepagewithzerosbeforeitisallocated,thuserasingthepreviouscontents.
On IA-32 processors, each process has a 4-GB virtual address space. The
upper2GBaremostlyidenticalforallprocessesandareusedbyWindowsin
kernelmodetoaccesstheoperating-systemcodeanddatastructures.Forthe
AMD64 architecture, Windows provides a 8-TB virtual address space for user
modeoutofthe16EBsupportedbyexistinghardwareforeachprocess.
Keyareasofthekernel-moderegionthatarenotidenticalforallprocesses
are the self-map, hyperspace, and session space. The hardware references a
process’s page table using physical page-frame numbers, and the page table
self-mapmakesthecontentsoftheprocess’spagetableaccessibleusingvirtual
addresses. Hyperspace maps the current process’s working-set information
intothekernel-modeaddressspace.Sessionspaceisusedtoshareaninstance
of the Win32 and other session-specific drivers among all the processes in
the same terminal-server (TS) session. Different TS sessions share different
instancesofthesedrivers,yettheyaremappedatthesamevirtualaddresses.
Thelower,user-moderegionofvirtualaddressspaceisspecifictoeachprocess
andaccessiblebybothuser-andkernel-modethreads.
The Windows VM manager uses a two-step process to allocate virtual
memory.The first stepreserves one or more pages of virtualaddressesin the
process’s virtual address space. The second step commits the allocation by
assigningvirtualmemoryspace(physicalmemoryorspaceinthepagingfiles).
Windows limits the amount of virtual memory space a process consumes by
enforcingaquotaoncommittedmemory.AprocessdecommitsmemorythatitB.3 SystemComponents 19
isnolongerusingtofreeupvirtualmemoryspaceforusebyotherprocesses.
TheAPIsusedtoreservevirtualaddressesandcommitvirtualmemorytakea
handleonaprocessobjectasaparameter.Thisallowsoneprocesstocontrolthe
virtualmemoryofanother.Environmentalsubsystemsmanagethememoryof
theirclientprocessesinthisway.
Windows implementssharedmemorybydefiningasectionobject.After
gettingahandletoasectionobject,aprocessmapsthememoryofthesectionto
arangeofaddresses,calledaview.Aprocesscanestablishaviewoftheentire
section or only the portion it needs. Windows allows sections to be mapped
notjustintothecurrentprocessbutintoanyprocessforwhichthecallerhasa
handle.
Sectionscanbeusedinmanyways.Asectioncanbebackedbydiskspace
eitherinthesystem-pagingfileorinaregularfile(amemory-mappedfile).A
sectioncanbebased,meaningthatitappearsatthesamevirtualaddressforall
processesattemptingtoaccessit.Sectionscanalsorepresentphysicalmemory,
allowing a 32-bit process to access more physical memory than can fit in its
virtual address space. Finally, the memory protection of pages in the section
canbesettoread-only,read-write,read-write-execute,execute-only,noaccess,
orcopy-on-write.
Let’slookmorecloselyatthelasttwooftheseprotectionsettings:
• A no-access page raises an exception if accessed. The exception can be
used, for example, to check whether a faulty program iterates beyond
the end of an array or simply to detect that the program attempted to
access virtual addresses that are not committed to memory. User- and
kernel-mode stacks use no-access pages as guard pages to detect stack
overflows.Anotheruseistolookforheapbufferoverruns.Boththeuser-
modememoryallocatorandthespecialkernelallocatorusedbythedevice
verifier can be configured to map each allocation onto the end of a page,
followed by a no-access page to detect programming errors that access
beyondtheendofanallocation.
• The copy-on-write mechanism enables the VM manager to use physical
memorymoreefficiently.Whentwoprocesseswantindependentcopiesof
datafromthesamesectionobject,theVMmanagerplacesasingleshared
copyintovirtualmemoryandactivatesthecopy-on-writepropertyforthat
region of memory. If one of the processes tries to modify data in a copy-
on-write page, the VM manager makes a private copy of the page for the
process.
The virtual address translation in Windows uses a multilevel page table.
For IA-32 and AMD64 processors, each process has a page directory that con-
tains512page-directoryentries(PDEs)8bytesinsize.EachPDEpointstoaPTE
tablethatcontains512page-tableentries(PTEs)8bytesinsize.EachPTEpoints
toa4-KBpageframeinphysicalmemory.Foravarietyofreasons,thehardware
requiresthatthepagedirectoriesorPTEtablesateachlevelofamultilevelpage
tableoccupyasinglepage.Thus,thenumberofPDEsorPTEsthatfitinapage
determinehowmanyvirtualaddressesaretranslatedbythatpage.SeeFigure
B.3foradiagramofthisstructure.
Thestructuredescribedsofarcanbeusedtorepresentonly1GBofvirtual
address translation. For IA-32, a second page-directory level is needed, con-20 AppendixB Windows7
page directory pointer table
pointer 0 pointer 1 pointer 2 pointer 3
page page page page page page
directory directory directory directory directory directory
entry 0 0 entry 511 entry 0 3 entry 511
page table page page table page table page page table
entry 0 table 0 entry 511 entry 0 table 511 entry 511
4-KB 4-KB 4-KB 4-KB
page page page page
FigureB.3 Page-tablelayout.
tainingonlyfourentries,asshowninthediagram.On64-bitprocessors,more
levels are needed. For AMD64, Windows uses a total of four full levels. The
totalsizeofallpage-tablepagesneededtofullyrepresentevena32-bitvirtual
address space for a process is 8 MB. The VM manager allocates pages of PDEs
andPTEsasneededandmovespage-tablepagestodiskwhennotinuse.The
page-tablepagesarefaultedbackintomemorywhenreferenced.
We next consider how virtual addresses are translated into physical
addresses on IA-32-compatible processors. A 2-bit value can represent the
values0,1,2,3.A9-bitvaluecanrepresentvaluesfrom0to511;a12-bitvalue,
values from 0 to 4,095. Thus, a 12-bit value can select any byte within a 4-KB
page of memory. A9-bit value can represent any of the 512 PDEs or PTEs in a
pagedirectoryorPTE-tablepage.AsshowninFigureB.4,translatingavirtual
address pointer to a byte address in physical memory involves breaking the
32-bitpointerintofourvalues,startingfromthemostsignificantbits:
• Two bits are used to index into the four PDEs at the top level of the page
table.TheselectedPDEwillcontainthephysicalpagenumberforeachof
thefourpage-directorypagesthatmap1GBoftheaddressspace.
31 0
PTR PDE index PTE index page offset
FigureB.4 Virtual-to-physicaladdresstranslationonIA-32.B.3 SystemComponents 21
• NinebitsareusedtoselectanotherPDE,thistimefromasecond-levelpage
directory. This PDE will contain the physical page numbers of up to 512
PTE-tablepages.
• Nine bits are used to select one of 512 PTEs from the selected PTE-table
page.TheselectedPTEwillcontainthephysicalpagenumberforthebyte
weareaccessing.
• Twelvebitsareusedasthebyteoffsetintothepage.Thephysicaladdress
ofthebyteweareaccessingisconstructedbyappendingthelowest12bits
ofthevirtualaddresstotheendofthephysicalpagenumberwefoundin
theselectedPTE.
Thenumberofbitsinaphysicaladdressmaybedifferentfromthenumber
ofbitsinavirtualaddress.IntheoriginalIA-32architecture,thePTEand PDE
were32-bitstructuresthathadroomforonly20bitsofphysicalpagenumber,
sothe physical addresssizeandthe virtualaddresssizewerethe same.Such
systems could address only 4 GB of physical memory. Later, the IA-32 was
extendedtothelarger64-bitPTEsizeusedtoday,andthehardwaresupported
24-bit physical addresses.These systems could support 64 GB and were used
onserversystems.Today,allWindowsserversarebasedoneithertheAMD64
ortheIA64andsupportvery,verylargephysicaladdresses—morethanwecan
possiblyuse.(Ofcourse,onceuponatime4GBseemedoptimisticallylargefor
physicalmemory.)
To improve performance, the VM manager maps the page-directory and
PTE-tablepagesintothesamecontiguousregionofvirtualaddressesinevery
process.Thisself-mapallowstheVMmanagertousethesamepointertoaccess
thecurrentPDEorPTEcorrespondingtoaparticularvirtualaddressnomatter
what process is running. The self-map for the IA-32 takes a contiguous 8-MB
region of kernel virtual address space; the AMD64 self-map occupies 512 GB.
Although the self-map occupies significant address space, it does not require
any additional virtualmemory pages.It alsoallows the pagetable’s pagesto
beautomaticallypagedinandoutofphysicalmemory.
Inthecreationofaself-map,oneofthePDEsinthetop-levelpagedirectory
refers to the page-directory page itself, forming a “loop” in the page-table
translations.Thevirtualpagesareaccessediftheloopisnottaken,thePTE-table
pages are accessed if the loop is taken once, the lowest-level page-directory
pagesareaccessediftheloopistakentwice,andsoforth.
Theadditionallevelsofpagedirectoriesusedfor64-bitvirtualmemoryare
translatedinthesamewayexceptthatthevirtualaddresspointerisbrokenup
intoevenmorevalues.FortheAMD64,Windowsusesfourfulllevels,eachof
whichmaps512pages,or9+9+9+9+12=48bitsofvirtualaddress.
To avoid the overhead of translating every virtual address by looking up
thePDEandPTE,processorsusetranslationlook-asidebuffer(TLB)hardware,
whichcontainsanassociativememorycacheformappingvirtualpagestoPTEs.
TheTLBispartofthememory-managementunit(MMU)withineachprocessor.
The MMU needs to “walk” (navigate the data structures of) the page table in
memoryonlywhenaneededtranslationismissingfromtheTLB.
The PDEs and PTEs contain more than just physical page numbers. They
alsohavebitsreservedforoperating-systemuseandbitsthatcontrolhowthe
hardwareusesmemory,suchaswhetherhardwarecachingshouldbeusedfor22 AppendixB Windows7
eachpage.Inaddition,theentriesspecifywhatkindsofaccessareallowedfor
bothuserandkernelmodes.
APDEcanalsobemarkedtosaythatitshouldfunctionasaPTEratherthan
aPDE.OnaIA-32,thefirst11bitsofthevirtualaddresspointerselectaPDEin
thefirsttwolevelsoftranslation.IftheselectedPDEismarkedtoactasaPTE,
thentheremaining21bitsofthepointerareusedastheoffsetofthebyte.This
resultsin a 2-MB size for the page.Mixing and matching 4-KB and 2-MB page
sizeswithinthepagetableiseasyfortheoperatingsystemandcansignificantly
improvetheperformanceofsomeprogramsbyreducinghowoftenthe MMU
needs to reload entries in the TLB, since one PDE mapping 2 MB replaces 512
PTEseachmapping4KB.
Managingphysicalmemorysothat2-MBpagesareavailablewhenneeded
is difficult, however, as they may continually be broken up into 4-KB pages,
causing external fragmentation of memory. Also, the large pages can result
in very significant internal fragmentation. Because of these problems, it is
typically only Windows itself, along with large server applications, that use
large pages to improve the performance of the TLB. They are better suited to
do so because operating-system and server applications start running when
thesystemboots,beforememoryhasbecomefragmented.
Windows manages physical memory by associating each physical page
with one of seven states: free, zeroed, modified, standby, bad, transition, or
valid.
• Afreepageisapagethathasnoparticularcontent.
• A zeroed page is a free page that has been zeroed out and is ready for
immediateusetosatisfyzero-on-demandfaults.
• Amodifiedpagehasbeenwrittenbyaprocessandmustbesenttothedisk
beforeitisallocatedforanotherprocess.
• Astandbypage is a copy ofinformation alreadystored on disk.Standby
pages may be pages that were not modified, modified pages that have
already been written to the disk, or pages that were prefetched because
theyareexpectedtobeusedsoon.
• Abadpageisunusablebecauseahardwareerrorhasbeendetected.
• Atransition page is on its way in from disk to a page frame allocated in
physicalmemory.
• Avalid page is part of the working set of one or more processes and is
containedwithintheseprocesses’pagetables.
While valid pages are contained in processes’ page tables, pages in other
statesarekeptinseparatelistsaccordingtostatetype.Thelistsareconstructed
bylinkingthecorrespondingentriesinthepageframenumber(PFN)database,
whichincludesanentryforeachphysicalmemorypage.ThePFNentriesalso
include information such as reference counts, locks, and NUMAinformation.
NotethatthePFNdatabaserepresentspagesofphysicalmemory,whereasthe
PTEsrepresentpagesofvirtualmemory.
When the valid bit in a PTE is zero, hardware ignores all the other bits,
andtheVMmanagercandefinethemforitsownuse.Invalidpagescanhavea
numberofstatesrepresentedbybitsinthePTE.Page-filepagesthathaveneverB.3 SystemComponents 23
63 32
page file offset
31 0
page
T P prot V
file
FigureB.5 Page-filepage-tableentry.Thevalidbitiszero.
been faulted in are marked zero-on-demand. Pages mapped through section
objects encode apointer tothe appropriatesectionobject. PTEs for pages that
havebeenwrittentothepagefilecontainenoughinformationtolocatethepage
ondisk,andsoforth.Thestructureofthepage-filePTEisshowninFigureB.5.
TheT,P,andVbitsareallzeroforthistypeofPTE.ThePTEincludes5bitsfor
pageprotection,32bitsforpage-fileoffset,and4bitstoselectthepagingfile.
Therearealso20bitsreservedforadditionalbookkeeping.
Windows uses a per-working-set, least-recently-used (LRU) replacement
policytotakepagesfromprocessesasappropriate.Whenaprocessisstarted,
it is assigned a default minimum working-set size. The working set of each
process is allowed to grow until the amount of remaining physical memory
starts to run low, at which point the VM manager starts to track the age of
the pages in each working set. Eventually, when the available memory runs
criticallylow,theVMmanagertrimstheworkingsettoremoveolderpages.
Howoldapageisdependsnotonhowlongithasbeeninmemorybuton
whenitwaslastreferenced.Thisisdeterminedbyperiodicallymakingapass
through the working set of each process and incrementing the age for pages
thathavenotbeenmarkedinthePTEasreferencedsincethelastpass.Whenit
becomesnecessarytotrimtheworkingsets,theVMmanagerusesheuristicsto
decidehowmuchtotrimfromeachprocessandthenremovestheoldestpages
first.
Aprocesscanhaveitsworkingsettrimmedevenwhenplentyofmemory
isavailable,ifitwasgivenahardlimitonhowmuchphysicalmemoryitcould
use.InWindows7,theVMmanagerwillalsotrimprocessesthataregrowing
rapidly,evenifmemoryisplentiful.Thispolicychangesignificantlyimproves
theresponsivenessofthesystemforotherprocesses.
Windows tracks working sets not only for user-mode processes but also
for the system process, which includes all the pageable data structures and
codethatruninkernelmode.Windows7createdadditionalworkingsetsfor
the system process and associated them with particular categories of kernel
memory; the file cache, kernel heap, and kernel code now have their own
workingsets.ThedistinctworkingsetsallowtheVMmanagertousedifferent
policiestotrimthedifferentcategoriesofkernelmemory.24 AppendixB Windows7
The VM manager does not fault in only the page immediately needed.
Research shows that the memory referencing of a thread tends to have a
locality property.Thatis,whenapageisused,itislikelythatadjacentpages
will be referenced in the near future. (Think of iterating over an array or
fetching sequential instructions that form the executable code for a thread.)
Because of locality, when the VM manager faults in a page, it also faults in a
fewadjacentpages.Thisprefetchingtendstoreducethetotalnumberofpage
faultsandallowsreadstobeclusteredtoimproveI/Operformance.
In addition to managing committed memory, the VM manager manages
eachprocess’sreservedmemory,orvirtualaddressspace.Eachprocesshasan
associatedtreethat describestheranges ofvirtualaddressesinuse and what
theusesare.ThisallowstheVMmanagertofaultinpage-tablepagesasneeded.
IfthePTEfor afaulting addressisuninitialized,the VMmanager searchesfor
theaddressintheprocess’streeofvirtualaddressdescriptors(VADs)anduses
this information to fill in the PTE and retrievethe page. In some cases, a PTE-
tablepageitselfmaynotexist;suchapagemustbetransparentlyallocatedand
initializedbytheVMmanager.Inothercases,thepagemaybesharedaspart
ofasectionobject,andtheVADwillcontainapointertothatsectionobject.The
sectionobject contains informationon how tofind the sharedvirtualpage so
thatthePTEcanbeinitializedtopointatitdirectly.
B.3.3.3 ProcessManager
The Windows process manager provides services for creating, deleting, and
using processes, threads, and jobs. It has no knowledge about parent–child
relationshipsorprocesshierarchies;thoserefinementsarelefttotheparticular
environmentalsubsystemthatownstheprocess.Theprocessmanagerisalso
notinvolvedintheschedulingofprocesses,otherthansettingtheprioritiesand
affinities in processes and threads when they are created. Thread scheduling
takesplaceinthekerneldispatcher.
Each process contains one or more threads. Processes themselves can be
collected into larger units called job objects. The use of job objects allows
limits to be placed on CPU usage, working-set size, and processor affinities
that control multiple processes at once. Job objects are used to manage large
data-centermachines.
AnexampleofprocesscreationintheWin32environmentisasfollows:
1. AWin32applicationcallsCreateProcess().
2. Amessageis sent to the Win32 subsystem to notify it that the process is
beingcreated.
3. CreateProcess()intheoriginalprocessthencallsanAPIintheprocess
manageroftheNTexecutivetoactuallycreatetheprocess.
4. The process manager calls the object manager to create a process object
andreturnstheobjecthandletoWin32.
5. Win32 calls the process manager again tocreate athread for the process
andreturnshandlestothenewprocessandthread.
The Windows APIs for manipulating virtual memory and threads and
for duplicating handles take a process handle, so subsystems can performB.3 SystemComponents 25
operations on behalf of a new process without having to execute directly in
the new process’s context. Once a new process is created, the initial thread
is created, and an asynchronous procedure call is delivered to the thread
to prompt the start of execution at the user-mode image loader. The loader
is in ntdll.dll, which is a link library automatically mapped into every
newlycreatedprocess.WindowsalsosupportsaUNIXfork()styleofprocess
creationinordertosupportthePOSIXenvironmentalsubsystem.Althoughthe
Win32environmentcallstheprocessmanagerdirectlyfromtheclientprocess,
POSIX uses the cross-process nature of the Windows APIs to create the new
processfromwithinthesubsystemprocess.
The process manager relies on the asynchronous procedure calls (APCs)
implemented by the kernel layer. APCs are used to initiate thread execution,
suspend and resume threads, access thread registers, terminate threads and
processes,andsupportdebuggers.
ThedebuggersupportintheprocessmanagerincludestheAPIstosuspend
andresumethreadsandtocreatethreadsthatbegininsuspendedmode.There
arealsoprocess-managerAPIs that getand setathread’sregistercontext and
accessanotherprocess’svirtualmemory.Threadscanbecreatedinthecurrent
process; they can also be injected into another process. The debugger makes
useofthreadinjectiontoexecutecodewithinaprocessbeingdebugged.
While running in the executive, a thread can temporarily attach to a dif-
ferent process. Thread attach is used by kernel worker threads that need to
executeinthecontextoftheprocessoriginatingaworkrequest.Forexample,
the VM manager might use thread attach when it needs access to a process’s
workingsetorpagetables,andtheI/Omanagermightuseitinupdatingthe
statusvariableinaprocessforasynchronousI/Ooperations.
The process manager also supports impersonation. Each thread has an
associated security token. When the login process authenticates a user, the
securitytokenisattachedtotheuser’sprocessandinheritedbyitschildpro-
cesses.Thetokencontainsthesecurityidentity(SID)oftheuser,theSIDsofthe
groupstheuserbelongsto,theprivilegestheuserhas,andtheintegritylevel
oftheprocess.Bydefault,allthreadswithinaprocessshareacommontoken,
representingtheuserandtheapplicationthatstartedtheprocess.However,a
threadrunninginaprocesswithasecuritytokenbelongingtooneusercanset
athread-specifictokenbelongingtoanotherusertoimpersonatethatuser.
Theimpersonationfacilityisfundamentaltotheclient–serverRPCmodel,
whereservicesmustactonbehalfofavarietyofclientswithdifferentsecurity
IDs.The right toimpersonateauser is most oftendeliveredas part ofan RPC
connectionfromaclientprocesstoaserverprocess.Impersonationallowsthe
servertoaccesssystemservicesasifitweretheclientinordertoaccessorcreate
objectsandfilesonbehalfoftheclient.Theserverprocessmustbetrustworthy
andmustbecarefullywrittentoberobustagainstattacks.Otherwise,oneclient
could take over a serverprocess and then impersonateany user who made a
subsequentclientrequest.
B.3.3.4 FacilitiesforClient–ServerComputing
TheimplementationofWindowsusesaclient–servermodelthroughout.The
environmental subsystems are servers that implement particular operating-
system personalities. Many other services, such as user authentication, net-26 AppendixB Windows7
workfacilities,printerspooling,webservices,networkfilesystems,andplug-
and-play,arealsoimplementedusingthismodel.Toreducethememoryfoot-
print, multiple services are often collected into a few processes running the
svchost.exeprogram.Eachserviceisloadedasadynamic-linklibrary(DLL),
whichimplementstheservicebyrelyingontheuser-modethread-poolfacili-
tiestosharethreadsandwaitformessages(seeSectionB.3.3.3).
The normal implementation paradigm for client–server computing is to
useRPCstocommunicaterequests.TheWin32APIsupportsastandardRPCpro-
tocol,asdescribedinSectionB.6.2.7.RPCusesmultipletransports(forexample,
namedpipesandTCP/IP)andcanbeusedtoimplementRPCsbetweensystems.
When an RPC always occurs between a client and server on the local system,
theadvancedlocalprocedurecallfacility(ALPC)canbeusedasthetransport.
Atthelowestlevelofthesystem,intheimplementationoftheenvironmental
systems,andforservicesthatmustbeavailableintheearlystagesofbooting,
RPCisnotavailable.Instead,nativeWindowsservicesuseALPCdirectly.
ALPC is a message-passing mechanism. The server process publishes a
globally visible connection-port object. When a client wants services from a
subsystem or service,it opens ahandle to the server’sconnection-port object
and sends a connection request to the port. The server creates a channel and
returns a handle to the client. The channel consists of a pair of private com-
munication ports: one for client-to-server messages and the other for server-
to-client messages. Communication channels support a callback mechanism,
so the client and server can accept requests when they would normally be
expectingareply.
WhenanALPCchanneliscreated,oneofthreemessage-passingtechniques
ischosen.
1. Thefirsttechniqueissuitableforsmalltomediummessages(upto63KB).
Inthiscase,theport’smessagequeueisusedasintermediatestorage,and
themessagesarecopiedfromoneprocesstotheother.
2. The second technique is for larger messages. In this case, a shared-
memorysectionobjectiscreatedforthechannel.Messagessentthrough
theport’smessagequeuecontainapointerandsizeinformationreferring
to the section object. This avoids the need to copy large messages. The
sender places data into the shared section, and the receiver views them
directly.
3. ThethirdtechniqueusesAPIsthatreadandwritedirectlyintoaprocess’s
address space. ALPC provides functions and synchronization so that a
server can access the data in a client. This technique is normally used
byRPCtoachievehigherperformanceforspecificscenarios.
TheWin32windowmanagerusesitsownformofmessagepassing,which
isindependentoftheexecutiveALPCfacilities.Whenaclientasksforaconnec-
tionthatuseswindow-managermessaging,theserversetsupthreeobjects:(1)
adedicatedserverthreadtohandlerequests,(2)a64-KBsharedsectionobject,
and (3) an event-pair object. An event-pair object is a synchronization object
usedbytheWin32subsystemtoprovidenotificationwhentheclientthreadhas
copiedamessagetotheWin32server,orviceversa.Thesectionobjectisused
topassthemessages,andtheevent-pairobjectprovidessynchronization.B.3 SystemComponents 27
Window-managermessaginghasseveraladvantages:
• Thesectionobjecteliminatesmessagecopying,sinceitrepresentsaregion
ofsharedmemory.
• The event-pair object eliminates the overhead of using the port object to
passmessagescontainingpointersandlengths.
• Thededicatedserverthreadeliminatestheoverheadofdeterminingwhich
clientthreadiscallingtheserver,sincethereisoneserverthreadperclient
thread.
• The kernel givesscheduling preferenceto these dedicatedserverthreads
toimproveperformance.
B.3.3.5 I/OManager
TheI/Omanagerisresponsibleformanagingfilesystems,devicedrivers,and
networkdrivers.Itkeepstrackofwhichdevicedrivers,filterdrivers,andfile
systems are loaded, and it also manages buffers for I/O requests. It works
with the VM manager to provide memory-mapped file I/O and controls the
Windowscachemanager,whichhandlescachingfortheentireI/Osystem.The
I/O manager is fundamentally asynchronous, providing synchronous I/O by
explicitlywaitingforanI/Ooperationtocomplete.TheI/Omanagerprovides
several models of asynchronous I/O completion, including setting of events,
updatingofastatusvariableinthecallingprocess,deliveryofAPCstoinitiating
threads,anduseofI/Ocompletionports,whichallowasinglethreadtoprocess
I/Ocompletionsfrommanyotherthreads.
Device drivers are arranged in a list for each device (called a driver or
I/O stack). Adriver is represented in the system as a driver object. Because
asingledrivercanoperateonmultipledevices,thedriversarerepresentedin
the I/O stack by a device object, which contains a link to the driver object.
TheI/Omanagerconvertstherequestsitreceivesintoastandardformcalled
an I/O request packet (IRP). It then forwards the IRP to the first driver in the
targeted I/O stack for processing. After a driver processes the IRP, it calls the
I/O manager either to forward the IRP to the next driver in the stack or, if all
processingisfinished,tocompletetheoperationrepresentedbytheIRP.
The I/O request may be completed in a context different from the one in
which it was made. For example, if a driver is performing its part of an I/O
operationandisforcedtoblockforanextendedtime,itmayqueuetheIRPto
a worker thread to continue processing in the system context. In the original
thread, the driver returns a status indicating that the I/O request is pending
so that the thread can continue executing in parallel with the I/O operation.
An IRP may also be processed in interrupt-service routines and completed in
anarbitraryprocesscontext. Becausesomefinal processing mayneedtotake
place inthe context that initiatedthe I/O, the I/O manager uses an APC todo
finalI/O-completionprocessingintheprocesscontextoftheoriginatingthread.
The I/O stack model is very flexible. As a driver stack is built, vari-
ous drivers have the opportunity to insert themselves into the stack as filte
drivers.FilterdriverscanexamineandpotentiallymodifyeachI/Ooperation.
Mount management, partition management, and disk striping and mirroring
areallexamplesoffunctionalityimplementedusingfilterdriversthatexecute28 AppendixB Windows7
beneath the file system in the stack. File-system filter drivers execute above
thefilesystemand havebeenusedtoimplementfunctionalitiessuchashier-
archical storage management, single instancing of files for remote boot, and
dynamicformatconversion.Thirdpartiesalsousefile-systemfilterdriversto
implementvirusdetection.
Device drivers for Windows are written to the Windows Driver Model
(WDM) specification. This model lays out all the requirements for device
drivers, including how to layer filter drivers, share common code for han-
dlingpowerandplug-and-playrequests,buildcorrectcancellationlogic,and
soforth.
Because of the richness of the WDM, writing a full WDM device driver
for each new hardware device can involve a great deal of work. Fortunately,
the port/miniport model makes it unnecessary to do this. Within a class of
similar devices, such as audio drivers, SATA devices, or Ethernet controllers,
each instance of a device shares a common driverfor that class, called a port
driver. The port driver implements the standard operations for the class and
then calls device-specific routines in the device’s miniport driver to imple-
ment device-specific functionality. The TCP/IP network stack is implemented
inthisway,withthendis.sysclassdriverimplementingmuchofthenetwork
driverfunctionalityandcallingouttothenetworkminiportdriversforspecific
hardware.
Recent versions of Windows, including Windows 7, provide additional
simplifications for writing devicedriversfor hardware devices.Kernel-mode
drivers can now be written using the Kernel-Mode Driver Framework
(KMDF), which provides a simplified programming model for drivers on top
ofWDM.AnotheroptionistheUser-ModeDriverFramework(UMDF).Many
driversdonotneedtooperateinkernelmode,anditiseasiertodevelopand
deploydriversinuser mode. It alsomakes the system more reliable,because
afailureinauser-modedriverdoesnotcauseakernel-modecrash.
B.3.3.6 CacheManager
In many operating systems, caching is done by the file system. Instead, Win-
dowsprovidesacentralizedcachingfacility.Thecachemanagerworksclosely
withthe VMmanager toprovidecache servicesfor allcomponents underthe
control ofthe I/Omanager. Caching inWindows isbasedon filesrather than
rawblocks.Thesizeofthecachechangesdynamicallyaccordingtohowmuch
free memory is available in the system. The cache manager maintains a pri-
vate working set rather than sharing the system process’s working set. The
cachemanagermemory-mapsfilesintokernelmemoryandthenusesspecial
interfacestotheVMmanagertofaultpagesintoortrimthemfromthisprivate
workingset.
Thecacheisdividedintoblocksof256KB.Eachcacheblockcanholdaview
(that is,a memory-mappedregion)of afile. Eachcache block is describedby
avirtualaddresscontrolblock(VACB)thatstoresthevirtualaddressandfile
offsetfortheview,aswellasthenumberofprocessesusingtheview.TheVACBs
resideinasinglearraymaintainedbythecachemanager.
When the I/O manager receives a file’s user-level read request, the I/O
managersendsanIRPtotheI/Ostackforthevolumeonwhichthefileresides.
Forfilesthataremarkedascacheable,thefilesystemcallsthecachemanagerB.3 SystemComponents 29
process
I/O I/O manager
cached I/O
cache manager file system
data copy noncached I/O
page fault
VM manager disk driver
FigureB.6 FileI/O.
to look up the requested data in its cached file views. The cache manager
calculates which entry of that file’sVACB indexarray corresponds tothe byte
offset of the request. The entry either points to the view in the cache or is
invalid. If it is invalid, the cache manager allocates a cache block (and the
correspondingentryintheVACBarray)andmapstheviewintothecacheblock.
The cache manager then attempts to copy data from the mapped file to the
caller’sbuffer.Ifthecopysucceeds,theoperationiscompleted.
If the copy fails, it does so because of a page fault, which causes the
VM manager to send a noncached read request to the I/O manager. The I/O
manager sends another request down the driver stack, this time requesting
a paging operation, which bypasses the cache manager and reads the data
from the file directly into the page allocated for the cache manager. Upon
completion,theVACBissettopointatthepage.Thedata,nowinthecache,are
copiedtothecaller’sbuffer,andtheoriginalI/Orequestiscompleted.Figure
B.6showsanoverviewoftheseoperations.
Akernel-levelreadoperationissimilar,exceptthatthedatacanbeaccessed
directly from the cache rather than being copied to a buffer in user space.
To use file-system metadata (data structures that describe the file system),
the kernel uses the cache manager’s mapping interface to read the metadata.
To modify the metadata, the file system uses the cache manager’s pinning
interface.Pinningapagelocksthepageintoaphysical-memorypageframeso
thattheVMmanagercannotmovethepageorpageitout.Afterupdatingthe
metadata,thefilesystemasksthecachemanagertounpinthepage.Amodified
pageismarkeddirty,andsotheVMmanagerflushesthepagetodisk.
Toimproveperformance,thecachemanagerkeepsasmallhistoryofread
requestsandfromthishistoryattemptstopredictfuturerequests.Ifthecache
manager finds a pattern in the previous three requests, such as sequential
access forward or backward, it prefetches data into the cache before the next
requestissubmittedby theapplication. Inthis way, the applicationmay find
itsdataalreadycachedandnotneedtowaitfordiskI/O.
ThecachemanagerisalsoresponsiblefortellingtheVMmanagertoflush
thecontentsofthecache.Thecachemanager’sdefaultbehavioriswrite-back30 AppendixB Windows7
caching:itaccumulateswritesfor4to5secondsandthenwakesupthecache-
writerthread.Whenwrite-throughcachingisneeded,aprocesscansetaflag
whenopeningthefile,ortheprocesscancallanexplicitcache-flushfunction.
Afast-writingprocesscouldpotentiallyfillallthefreecachepagesbefore
the cache-writer threadhadachance towake up andflush thepagestodisk.
Thecachewriterpreventsaprocessfromfloodingthesysteminthefollowing
way.Whentheamountoffreecachememorybecomeslow,thecachemanager
temporarily blocks processes attempting to write data and wakes the cache-
writer thread to flush pages to disk. If the fast-writing process is actually a
network redirector for a network file system, blocking it for too long could
causenetworktransferstotimeoutandberetransmitted.Thisretransmission
wouldwastenetworkbandwidth.Topreventsuchwaste,networkredirectors
caninstructthecachemanagertolimitthebacklogofwritesinthecache.
Becauseanetworkfilesystemneedstomovedatabetweenadiskandthe
network interface, the cache manager also provides a DMAinterface to move
the data directly. Moving data directly avoids the need to copy data through
anintermediatebuffer.
B.3.3.7 SecurityReferenceMonitor
Centralizing management of system entities in the object manager enables
Windows touse auniform mechanism toperformrun-timeaccess validation
and audit checks for every user-accessible entity in the system. Whenever a
process opens a handle to an object, the security reference monitor (SRM)
checks the process’s security token and the object’s access-control list to see
whethertheprocesshasthenecessaryaccessrights.
The SRM is also responsible for manipulating the privileges in security
tokens. Specialprivilegesare requiredfor users toperform backup or restore
operations on file systems, debug processes, and so forth. Tokens can also be
markedasbeingrestrictedintheirprivilegessothattheycannotaccessobjects
that are available to most users. Restricted tokens are used primarily to limit
thedamagethatcanbedonebyexecutionofuntrustedcode.
Theintegritylevelofthecodeexecutinginaprocessisalsorepresentedbya
token.Integritylevelsareatypeofcapabilitymechanism,asmentionedearlier.
Aprocesscannotmodifyanobjectwithanintegritylevelhigherthanthatofthe
codeexecutingintheprocess,whateverotherpermissionshavebeengranted.
Integrity levels were introduced to make it harder for code that successfully
attacksoutward-facingsoftware,likeInternetExplorer,totakeoverasystem.
Another responsibility of the SRM is logging security audit events. The
DepartmentofDefense’sCommonCriteria(the2005successortotheOrange
Book) requires that a secure system have the ability to detect and log all
attemptstoaccesssystemresourcessothatitcanmoreeasilytraceattemptsat
unauthorizedaccess.BecausetheSRMisresponsibleformakingaccesschecks,
itgeneratesmostoftheauditrecordsinthesecurity-eventlog.
B.3.3.8 Plug-and-PlayManager
Theoperatingsystemusestheplug-and-play(PnP)managertorecognizeand
adapt to changes in the hardware configuration. PnP devices use standard
protocolstoidentifythemselvestothesystem.ThePnPmanagerautomatically
recognizes installed devices and detects changes in devices as the systemB.3 SystemComponents 31
operates.Themanageralsokeepstrackofhardwareresourcesusedbyadevice,
as well as potential resources that could be used, and takes care of loading
theappropriatedrivers.Thismanagementofhardwareresources—primarily
interruptsand I/O memory ranges—has the goal of determininga hardware
configurationinwhichalldevicesareabletooperatesuccessfully.
The PnP manager handles dynamic reconfiguration as follows. First, it
gets a list of devices from each bus driver (for example, PCI or USB). It loads
theinstalleddriver(afterfindingone,ifnecessary)andsendsanadd-device
requesttotheappropriatedriverforeachdevice.ThePnPmanagerthenfigures
out the optimal resource assignments and sends a start-device request to
each driver specifying the resource assignments for the device. If a device
needstobereconfigured,thePnPmanagersendsaquery-stoprequest,which
asks the driver whether the device can be temporarily disabled. If the driver
can disable the device, then all pending operations are completed, and new
operationsarepreventedfromstarting.Finally,thePnPmanagersendsastop
requestandcanthenreconfigurethedevicewithanewstart-devicerequest.
The PnP manager also supports other requests. For example, query-
remove, which operates similarly to query-stop, is employed when a user
isgettingreadytoejectaremovabledevice,suchasaUSBstoragedevice.The
surprise-removerequestisusedwhenadevicefailsor,morelikely,whena
user removes a device without telling the system to stop it first. Finally, the
removerequesttellsthedrivertostopusingadevicepermanently.
Many programs in the system are interested in the addition or removal
ofdevices,sothePnPmanagersupportsnotifications.Suchanotification,for
example, gives GUI file menus the information they need to update their list
ofdiskvolumeswhenanewstoragedeviceisattachedorremoved.Installing
devicesoftenresultsinaddingnewservicestothesvchost.exeprocessesin
the system. These services frequently set themselves up to run whenever the
systembootsandcontinuetoruneveniftheoriginaldeviceisneverplugged
into the system. Windows 7 introduced a service-trigger mechanism in the
servicecontrolmanager(SCM),whichmanagesthesystemservices.Withthis
mechanism,servicescanregisterthemselvestostartonlywhenSCMreceivesa
notification from the PnPmanager that the deviceof interesthas been added
tothesystem.
B.3.3.9 PowerManager
Windows works with the hardware toimplement sophisticatedstrategiesfor
energy efficiency, as described in Section B.2.8. The policies that drive these
strategiesareimplementedbythepowermanager.Thepowermanagerdetects
current system conditions, such as the load on CPUs or I/O devices, and
improvesenergyefficiencybyreducingtheperformanceandresponsivenessof
thesystemwhenneedislow.Thepowermanagercanalsoputtheentiresystem
intoaveryefficientsleepmodeandcanevenwriteallthecontentsofmemory
todiskandturnoffthepowertoallowthesystemtogointohibernation.
Theprimaryadvantageofsleepisthatthesystemcanenterfairlyquickly,
perhaps just a few seconds after the lid closes on a laptop. The return from
sleepisalsofairlyquick.ThepoweristurneddownlowontheCPUsandI/O
devices,butthememorycontinuestobepoweredenoughthatitscontentsare
notlost.32 AppendixB Windows7
Hibernationtakesconsiderablylongerbecausetheentirecontentsofmem-
ory must be transferredtodisk before the system is turned off. However,the
fact that the system is, in fact, turned off is a significant advantage. If there
is a loss of power to the system, as when the battery is swapped on a lap-
toporadesktopsystemisunplugged,thesavedsystemdatawillnotbelost.
Unlikeshutdown,hibernationsavesthecurrentlyrunningsystemsoausercan
resumewhere sheleftoff, andbecause hibernation doesnot requirepower,a
systemcanremaininhibernationindefinitely.
Like the PnP manager, the power manager provides notifications to the
restofthesystemaboutchangesinthepowerstate.Someapplicationswantto
knowwhenthesystemisabouttobeshutdownsotheycanstartsavingtheir
statestodisk.
B.3.3.10 Registry
Windows keeps much of its configuration information in internal databases,
calledhives,thataremanagedbytheWindowsconfigurationmanager,which
is commonly known as the registry. There are separate hives for system
information,defaultuserpreferences,softwareinstallation,security,andboot
options. Because the information in the system hive is required to boot the
system,theregistrymanagerisimplementedasacomponentoftheexecutive.
Theregistryrepresentstheconfigurationstateineachhiveasahierarchical
namespaceofkeys(directories),eachofwhichcancontainasetoftypedvalues,
suchasUNICODEstring,ANSIstring,integer,oruntypedbinarydata.Intheory,
new keys and values are created and initialized as new software is installed;
thentheyaremodifiedtoreflectchangesintheconfigurationofthatsoftware.
In practice, the registry is often used as a general-purpose database, as an
interprocess-communication mechanism, and for many other such inventive
purposes.
Restarting applications, or even the system, every time a configuration
change was made would be a nuisance. Instead, programs rely on various
kindsofnotifications,suchasthoseprovidedbythePnPandpowermanagers,
tolearnaboutchangesinthesystemconfiguration.Theregistryalsosupplies
notifications; it allows threads to register to be notified when changes are
made to some part of the registry. The threads can thus detect and adapt to
configurationchangesrecordedintheregistryitself.
Whenever significant changes are made to the system, such as when
updatestotheoperatingsystemordriversareinstalled,thereisadangerthat
the configuration data may be corrupted (for example, if a working driver is
replacedbyanonworkingdriveroranapplicationfailstoinstallcorrectlyand
leaves partial information in the registry). Windows creates a system restore
point before making such changes. The restore point contains a copy of the
hivesbeforethechange andcan beusedtoreturntothis versionofthe hives
andtherebygetacorruptedsystemworkingagain.
To improve the stability of the registry configuration, Windows added a
transaction mechanism beginning with Windows Vista that can be used to
prevent the registry from being partially updated with a collection of related
configurationchanges.Registrytransactionscanbepartofmoregeneraltrans-
actionsadministeredbythekerneltransactionmanager(KTM),whichcanalsoB.3 SystemComponents 33
includefile-systemtransactions.KTMtransactionsdonothavethefullseman-
ticsfoundinnormaldatabasetransactions,andtheyhavenotsupplantedthe
systemrestorefacilityforrecoveringfromdamagetotheregistryconfiguration
causedbysoftwareinstallation.
B.3.3.11 Booting
The booting of a Windows PC begins when the hardware powers on and
firmware begins executing from ROM. In older machines, this firmware was
knownastheBIOS,butmoremodernsystemsuseUEFI(theUnifiedExtensible
Firmware Interface), which is faster and more general and makes better use
ofthefacilitiesincontemporaryprocessors.Thefirmwarerunspower-onself-
test (POST) diagnostics;identifiesmany ofthe devicesattached tothe system
andinitializesthemtoaclean,power-upstate;andthenbuildsthedescription
used by the advanced configuratio and power interface (ACPI). Next, the
firmware finds the system disk, loads the Windows bootmgr program, and
beginsexecutingit.
Inamachinethathasbeenhibernating,thewinresumeprogramisloaded
next.Itrestorestherunningsystemfromdisk,andthesystemcontinuesexecu-
tionatthepointithadreachedrightbeforehibernating.Inamachinethathas
beenshutdown,thebootmgrperformsfurtherinitializationofthesystemand
thenloadswinload.Thisprogramloadshal.dll,thekernel(ntoskrnl.exe),
any drivers needed in booting, and the system hive. winload then transfers
executiontothekernel.
The kernel initializes itself and creates two processes. The system pro-
cess contains all the internal kernel worker threads and never executes in
user mode. The first user-mode process created is SMSS, for session manager
subsystem, which is similar to the INIT (initialization) process in UNIX. SMSS
performsfurtherinitializationofthesystem,includingestablishingthepaging
files,loadingmoredevicedrivers,andmanagingtheWindowssessions.Each
session is used to represent a logged-on user, except for session 0, which is
used to run system-wide background services, such as LSASS and SERVICES.
Asessionis anchored by an instance of the CSRSS process.Each sessionother
than 0 initially runs the WINLOGON process. This process logs on a user and
then launches the EXPLORER process, which implements the Windows GUI
experience.Thefollowinglistitemizessomeoftheseaspectsofbooting:
• SMSS completessysteminitializationandthenstartsupsession0andthe
firstloginsession.
• WININITrunsinsession0toinitializeusermodeandstartLSASS,SERVICES,
andthelocalsessionmanager,LSM.
• LSASS,thesecuritysubsystem,implementsfacilitiessuchasauthentication
ofusers.
• SERVICES contains the servicecontrol manager, or SCM, which supervises
all background activities in the system, including user-mode services. A
number of services will have registered to start when the system boots.
Otherswillbestartedonlyondemandorwhentriggeredbyaneventsuch
asthearrivalofadevice.34 AppendixB Windows7
• CSRSSistheWin32environmentalsubsystemprocess.Itisstartedinevery
session—unlike the POSIX subsystem, which is started only on demand
whenaPOSIXprocessiscreated.
• WINLOGONisrunineachWindowssessionotherthansession0tologon
auser.
The system optimizes the boot process by prepaging from files on disk
based on previous boots of the system. Disk access patterns at boot are also
used to lay out system files on disk to reduce the number of I/O operations
required.Theprocessesnecessarytostartthesystemarereducedbygrouping
servicesintofewerprocesses.Alloftheseapproachescontributetoadramatic
reduction in system boot time. Of course, system boot time is less important
thanitoncewasbecauseofthesleepandhibernationcapabilitiesofWindows.
B.4 Terminal Services and Fast User Switching
Windows supports a GUI-based console that interfaces with the user viakey-
board,mouse,anddisplay.Mostsystemsalsosupportaudioandvideo.Audio
inputisusedbyWindowsvoice-recognitionsoftware;voicerecognitionmakes
the system more convenient and increases its accessibility for users with dis-
abilities.Windows7addedsupportformulti-touchhardware,allowingusers
to input data by touching the screen and making gestures with one or more
fingers.Eventually,thevideo-inputcapability,whichiscurrentlyusedforcom-
municationapplications,islikelytobeusedforvisuallyinterpretinggestures,
as Microsoft has demonstrated for its Xbox 360 Kinect product. Other future
inputexperiencesmayevolvefromMicrosoft’ssurfacecomputer.Mostoften
installed at public venues, such as hotels and conference centers, the surface
computer is a table surface with special cameras underneath. It can track the
actionsofmultipleusersatonceandrecognizeobjectsthatareplacedontop.
ThePCwas,ofcourse,envisionedasapersonalcomputer—aninherently
single-usermachine.ModernWindows,however,supportsthesharingofaPC
amongmultipleusers.EachuserthatisloggedonusingtheGUIhasasession
createdtorepresenttheGUIenvironmenthewillbeusingandtocontainallthe
processescreatedtorunhisapplications.Windowsallowsmultiplesessionsto
existatthesametimeonasinglemachine.However,Windowsonlysupports
asingleconsole,consistingofallthemonitors,keyboards,andmiceconnected
tothePC.Onlyonesessioncanbeconnectedtotheconsoleatatime.Fromthe
logonscreendisplayedontheconsole,userscancreatenewsessionsorattach
toanexistingsessionthat was previouslycreated.This allowsmultipleusers
toshareasinglePCwithouthavingtologoffandonbetweenusers.Microsoft
callsthisuseofsessionsfastuserswitching.
Userscanalsocreatenewsessions,orconnecttoexistingsessions,onone
PC from a session running on another Windows PC. The terminal server (TS)
connectsoneoftheGUIwindowsinauser’slocalsessiontotheneworexisting
session,calledaremotedesktop,ontheremotecomputer.Themostcommon
use of remote desktops is for users to connect to a session on their work PC
fromtheirhomePC.
Many corporations use corporate terminal-server systems maintained in
datacenterstorunallusersessionsthataccesscorporateresources,ratherthanB.5 FileSystem 35
allowinguserstoaccessthoseresourcesfromthePCsineachuser’soffice.Each
server computer may handle many dozens of remote-desktop sessions. This
is a form of thin-client computing, in which individual computers rely on a
server for many functions. Relying on data-center terminal servers improves
reliability,manageability,andsecurityofthecorporatecomputingresources.
TheTSisalsousedbyWindowstoimplementremoteassistance.Aremote
usercanbeinvitedtoshareasessionwiththeuserloggedontothesessionon
the console. The remote user can watch the user’s actions and even be given
controlofthedesktoptohelpresolvecomputingproblems.
B.5 File System
The native file system in Windows is NTFS. It is used for all local volumes.
However,associatedUSBthumbdrives,flashmemoryoncameras,andexternal
disksmaybeformattedwiththe32-bitFATfilesystemforportability.FATisa
much older file-system format that is understood by many systems besides
Windows, such as the software running on cameras. A disadvantage is that
the FAT file system does not restrict file access to authorized users. The only
solutionforsecuringdatawithFATistorunanapplicationtoencryptthedata
beforestoringitonthefilesystem.
In contrast, NTFS uses ACLs to control access to individual files and sup-
portsimplicitencryptionofindividualfilesorentirevolumes(usingWindows
BitLocker feature). NTFS implements many other features as well, including
data recovery, fault tolerance, very large files and file systems, multiple data
streams,UNICODEnames,sparsefiles,journaling,volumeshadowcopies,and
filecompression.
B.5.1 NTFS Internal Layout
ThefundamentalentityinNTFSisavolume.AvolumeiscreatedbytheWin-
dowslogicaldiskmanagementutilityandisbasedonalogicaldiskpartition.
Avolumemayoccupyaportionofadiskoranentiredisk,ormayspanseveral
disks.
NTFSdoesnotdealwithindividualsectorsofadiskbutinsteadusesclus-
tersastheunitsofdiskallocation.Aclusterisanumberofdisksectorsthatis
apowerof2.TheclustersizeisconfiguredwhenanNTFSfilesystemisformat-
ted. The default cluster size is based on the volume size—4 KB for volumes
larger than 2 GB. Given the size of today’s disks, it may make sense to use
clustersizeslargerthantheWindowsdefaultstoachievebetterperformance,
although these performance gains will come at the expense of more internal
fragmentation.
NTFSuseslogicalclusternumbers(LCNs)asdiskaddresses.Itassignsthem
by numbering clusters from the beginning of the disk to the end. Using this
scheme,thesystemcancalculateaphysicaldiskoffset(inbytes)bymultiplying
theLCNbytheclustersize.
A file in NTFS is not a simple byte stream as it is in UNIX; rather, it is a
structured object consisting of typed attributes. Each attribute of a file is an
independentbytestreamthatcanbecreated,deleted,read,andwritten.Some
attribute types are standard for all files, including the file name (or names, if
thefilehasaliases,suchasanMS-DOSshort name),thecreationtime,andthe36 AppendixB Windows7
securitydescriptorthatspecifiestheaccesscontrollist.Userdataarestoredin
dataattributes.
Most traditional data files have an unnamed data attribute that contains
all the file’s data. However, additional data streams can be created with
explicitnames.Forinstance,inMacintoshfilesstoredonaWindowsserver,the
resourceforkisanameddatastream.TheIPropinterfacesoftheComponent
ObjectModel(COM)useanameddatastreamtostorepropertiesonordinary
files, including thumbnails of images. In general, attributes may be added as
necessary and are accessed using a file-name:attribute syntax. NTFS returns
only the size of the unnamed attribute in response to file-query operations,
suchaswhenrunningthedircommand.
EveryfileinNTFSisdescribedbyoneormorerecordsinanarraystoredina
specialfilecalledthemasterfiletable(MFT).Thesizeofarecordisdetermined
when the file system is created; it ranges from 1 to 4 KB. Small attributes
are stored in the MFT record itself and are called resident attributes. Large
attributes, such as the unnamed bulk data, are called nonresident attributes
and are stored in one or more contiguous extents on the disk. A pointer to
eachextentisstoredintheMFTrecord.Forasmallfile,eventhedataattribute
may fit inside the MFT record. If a file has many attributes—or if it is highly
fragmented, so that many pointers are needed to point to all the fragments
—one record in the MFT might not be large enough. In this case, the file is
described by a record called the base fil record, which contains pointers to
overflowrecordsthatholdtheadditionalpointersandattributes.
EachfileinanNTFSvolumehasauniqueIDcalledafil reference.Thefile
reference is a 64-bit quantity that consists of a 48-bit file number and a 16-bit
sequencenumber.Thefilenumberistherecordnumber(thatis,thearrayslot)
inthe MFTthat describesthe file.Thesequencenumber is incrementedevery
time an MFT entry is reused. The sequence number enables NTFS to perform
internalconsistencychecks,suchascatchingastalereferencetoadeletedfile
aftertheMFTentryhasbeenreusedforanewfile.
B.5.1.1 NTFSB+Tree
AsinUNIX,theNTFSnamespaceisorganizedasahierarchyofdirectories.Each
directoryusesadatastructurecalledaB+treetostoreanindexofthefilenames
inthatdirectory.InaB+tree,thelengthofeverypathfromtherootofthetreeto
aleafisthesame,andthecostofreorganizingthetreeiseliminated.Theindex
root of a directory contains the top level of the B+ tree. For a large directory,
this top level contains pointers to disk extents that hold the remainder of the
tree. Each entry in the directory contains the name and file reference of the
file, as well as a copy of the update timestamp and file size taken from the
file’sresidentattributesintheMFT.Copiesofthisinformationarestoredinthe
directorysothatadirectorylistingcanbeefficientlygenerated.Becauseallthe
filenames,sizes,andupdatetimesareavailablefromthedirectoryitself,there
isnoneedtogathertheseattributesfromtheMFTentriesforeachofthefiles.
B.5.1.2 NTFSMetadata
TheNTFSvolume’smetadataareallstoredinfiles.ThefirstfileistheMFT.The
second file, which is used during recovery if the MFT is damaged, contains aB.5 FileSystem 37
copy of the first 16 entries of the MFT. The next few files are also special in
purpose.Theyincludethefilesdescribedbelow.
• Thelogfilerecordsallmetadataupdatestothefilesystem.
• Thevolumefilecontainsthenameofthevolume,theversionofNTFSthat
formatted the volume, and a bit that tells whether the volume may have
beencorruptedandneedstobecheckedforconsistencyusingthechkdsk
program.
• Theattribute-definitio tableindicateswhichattributetypesareusedin
thevolumeandwhatoperationscanbeperformedoneachofthem.
• Therootdirectoryisthetop-leveldirectoryinthefile-systemhierarchy.
• Thebitmapfil indicateswhichclustersonavolumeareallocatedtofiles
andwhicharefree.
• Thebootfil containsthestartupcodeforWindowsandmustbelocated
ataparticulardiskaddresssothatitcanbefoundeasilybyasimpleROM
bootstrap loader. The boot file also contains the physical address of the
MFT.
• Thebad-clusterfilekeepstrackofanybadareasonthevolume;NTFSuses
thisrecordforerrorrecovery.
KeepingalltheNTFSmetadatainactualfileshasausefulproperty.Asdis-
cussedinSectionB.3.3.6,thecachemanagercachesfiledata.SincealltheNTFS
metadataresideinfiles,thesedatacanbecachedusingthesamemechanisms
usedforordinarydata.
B.5.2 Recovery
In many simple file systems, a power failure at the wrong time can damage
thefile-systemdatastructuressoseverelythattheentirevolumeisscrambled.
ManyUNIXfilesystems,includingUFSbutnotZFS,storeredundantmetadata
onthedisk,andtheyrecoverfromcrashesbyusingthefsckprogramtocheck
all the file-system data structures and restore them forcibly to a consistent
state. Restoring them often involves deleting damaged files and freeing data
clustersthathadbeenwrittenwithuserdatabutnotproperlyrecordedinthe
filesystem’smetadatastructures.Thischeckingcanbeaslowprocessandcan
causethelossofsignificantamountsofdata.
NTFStakesadifferentapproachtofile-systemrobustness.InNTFS,allfile-
systemdata-structureupdatesareperformedinsidetransactions.Beforeadata
structureisaltered,thetransactionwritesalogrecordthat contains redoand
undo information. Afterthe datastructure has been changed, the transaction
writesacommitrecordtothelogtosignifythatthetransactionsucceeded.
After a crash, the system can restore the file-system data structures to
a consistent state by processing the log records, first redoing the operations
for committed transactions and then undoing the operations for transactions
thatdidnotcommitsuccessfullybeforethecrash.Periodically(usuallyevery
5 seconds), a checkpoint record is written to the log. The system does not
needlogrecordspriortothecheckpoint torecoverfromacrash. Theycanbe38 AppendixB Windows7
discarded, so the log file does not grow without bounds. The first time after
systemstartupthatanNTFSvolumeisaccessed,NTFSautomaticallyperforms
file-systemrecovery.
This scheme does not guarantee that all the user-file contents are correct
afteracrash.Itensuresonlythatthefile-systemdatastructures(themetadata
files)areundamagedandreflectsomeconsistentstatethatexistedpriortothe
crash.Itwouldbepossibletoextendthetransactionschemetocoveruserfiles,
andMicrosofttooksomestepstodothisinWindowsVista.
Thelogisstoredinthethirdmetadatafileatthebeginningofthevolume.
It is created with a fixed maximum size when the file system is formatted. It
hastwosections:theloggingarea,whichisacircularqueueoflogrecords,and
the restart area, which holds context information, such as the position in the
logging area where NTFS should start reading during a recovery. In fact, the
restart area holds two copies of its information, so recovery is still possible if
onecopyisdamagedduringthecrash.
The logging functionality is provided by the log-file service. In addition
towritingthelogrecordsandperformingrecoveryactions,thelog-fileservice
keepstrackofthefreespaceinthelogfile.Ifthefreespacegetstoolow,thelog-
fileservicequeuespendingtransactions,andNTFShaltsallnewI/Ooperations.
After the in-progress operations complete, NTFS calls the cache manager to
flushalldataandthenresetsthelogfileandperformsthequeuedtransactions.
B.5.3 Security
The security of an NTFS volume is derived from the Windows object model.
EachNTFSfilereferencesasecuritydescriptor,whichspecifiestheownerofthe
file,andanaccess-control list,which contains theaccess permissionsgranted
ordeniedtoeachuserorgrouplisted.EarlyversionsofNTFSusedaseparate
securitydescriptorasanattributeofeachfile.BeginningwithWindows2000,
the security-descriptors attribute points to a shared copy, with a significant
savings in disk and caching space; many, many files have identical security
descriptors.
In normal operation, NTFS does not enforce permissions on traversal of
directories in file path names. However, for compatibility with POSIX, these
checks can be enabled. Traversal checks are inherently more expensive, since
modernparsingoffilepathnamesusesprefixmatchingratherthandirectory-
by-directoryparsingofpathnames.Prefixmatchingisanalgorithmthatlooks
upstringsinacacheandfindstheentrywiththelongestmatch—forexample,
anentryfor∖foo∖bar∖dirwouldbeamatchfor∖foo∖bar∖dir2∖dir3∖myfile.
The prefix-matching cache allows path-name traversal to begin much deeper
inthetree,savingmanysteps.Enforcingtraversalchecksmeansthattheuser’s
accessmustbecheckedateachdirectorylevel.Forinstance,ausermightlack
permission to traverse ∖foo∖bar, so starting at the access for ∖foo∖bar∖dir
wouldbeanerror.
B.5.4 Volume Management and Fault Tolerance
FtDisk is the fault-tolerant disk driver for Windows. When installed, it pro-
videsseveralwaystocombinemultiplediskdrivesintoonelogicalvolumeso
astoimproveperformance,capacity,orreliability.B.5 FileSystem 39
disk 1 (2.5 GB) disk 2 (2.5 GB)
disk C: (FAT) 2 GB
LCNs 128001–783361
logical drive D: (NTFS) 3 GB
LCNs 0–128000
FigureB.7 Volumesetontwodrives.
B.5.4.1 VolumeSetsandRAIDSets
Onewaytocombinemultipledisksistoconcatenatethemlogicallytoforma
largelogicalvolume,asshowninFigureB.7.InWindows,thislogicalvolume,
called a volume set, can consist of up to 32 physical partitions. Avolume set
thatcontainsanNTFSvolumecanbeextendedwithoutdisturbanceofthedata
alreadystoredinthefilesystem.ThebitmapmetadataontheNTFSvolumeare
simply extended to cover the newly added space. NTFS continues to use the
same LCN mechanism that it uses for a single physical disk, and the FtDisk
driversuppliesthemappingfromalogical-volumeoffsettotheoffsetonone
particulardisk.
Anotherwaytocombinemultiplephysicalpartitionsistointerleavetheir
blocks in round-robin fashion to form a stripe set. This scheme is also called
RAIDlevel0,ordiskstriping.(FormoreonRAID(redundantarraysofinexpen-
sivedisks),seeSection11.8.)FtDiskusesastripesizeof64KB.Thefirst64KB
ofthelogicalvolumearestoredinthefirstphysicalpartition,thesecond64KB
inthesecondphysicalpartition,andsoon,untileachpartitionhascontributed
64 KB of space. Then, the allocation wraps around to the first disk, allocating
the second 64-KB block. Astripe set forms one large logical volume, but the
physicallayoutcanimprovetheI/Obandwidth,becauseforalargeI/O,allthe
diskscantransferdatainparallel.WindowsalsosupportsRAIDlevel5,stripe
setwithparity,andRAIDlevel1,mirroring.
B.5.4.2 SectorSparingandClusterRemapping
Todealwithdisksectorsthatgobad,FtDiskusesahardwaretechniquecalled
sector sparing, and NTFS uses a software technique called cluster remapping.
Sectorsparingisahardwarecapabilityprovidedbymanydiskdrives.When
adiskdriveisformatted,itcreatesamapfromlogicalblocknumberstogood
sectorsonthedisk.Italsoleavesextrasectorsunmapped,asspares.Ifasector
fails,FtDiskinstructsthediskdrivetosubstituteaspare.Clusterremapping40 AppendixB Windows7
is a software technique performed by the file system. If a disk block goes
bad, NTFS substitutes a different, unallocated block by changing any affected
pointersintheMFT.NTFSalsomakesanotethatthebadblockshouldneverbe
allocatedtoanyfile.
When a disk block goes bad, the usual outcome is a data loss. But sector
sparingorclusterremappingcanbecombinedwithfault-tolerantvolumesto
mask the failure of a disk block. If a read fails, the system reconstructs the
missingdatabyreadingthemirrororbycalculatingtheexclusive orparity
inastripesetwithparity.Thereconstructeddataarestoredinanewlocation
thatisobtainedbysectorsparingorclusterremapping.
B.5.5 Compression
NTFS can perform data compression on individual files or on all data files
in a directory. To compress a file, NTFS divides the file’s data into compres-
sion units, which are blocks of 16 contiguous clusters. When a compression
unit is written, a data-compression algorithm is applied.If the result fits into
fewerthan16clusters,thecompressedversionisstored.Whenreading,NTFS
can determine whether data have been compressed: if they have been, the
lengthofthestoredcompressionunitislessthan16clusters.Toimproveper-
formance when reading contiguous compression units, NTFS prefetches and
decompressesaheadoftheapplicationrequests.
For sparsefiles or filesthat contain mostlyzeros,NTFSuses another tech-
niquetosavespace.Clustersthatcontainonlyzerosbecausetheyhavenever
beenwrittenarenotactuallyallocatedorstoredondisk.Instead,gapsareleft
inthesequenceofvirtual-clusternumbersstoredintheMFTentryforthefile.
When reading a file,if NTFS finds a gap inthe virtual-clusternumbers, it just
zero-fillsthatportionofthecaller’sbuffer.ThistechniqueisalsousedbyUNIX.
B.5.6 Mount Points, Symbolic Links, and Hard Links
Mount points are a form of symbolic link specific to directories on NTFS that
wereintroducedinWindows2000.Theyprovideamechanismfororganizing
disk volumes that is more flexible than the use of global names (like drive
letters). A mount point is implemented as a symbolic link with associated
data that contains the true volume name. Ultimately, mount points will sup-
plant drive letters completely, but there will be a long transition due to the
dependenceofmanyapplicationsonthedrive-letterscheme.
Windows Vista introduced support for a more general form of symbolic
links,similartothosefoundinUNIX.Thelinkscanbeabsoluteorrelative,can
point to objects that do not exist, and can point to both files and directories
evenacrossvolumes.NTFSalsosupportshardlinks,whereasinglefilehasan
entryinmorethanonedirectoryofthesamevolume.
B.5.7 Change Journal
NTFS keeps a journal describing all changes that have been made to the file
system.User-modeservicescanreceivenotificationsofchangestothejournal
and then identify what files have changed by reading from the journal. The
searchindexerserviceusesthechangejournaltoidentifyfilesthatneedtobeB.6 Networking 41
re-indexed.The file-replication service uses it to identify files that need to be
replicatedacrossthenetwork.
B.5.8 Volume Shadow Copies
Windows implements the capability of bringing a volume to a known state
and then creating a shadow copy that can be used to back up a consistent
viewof the volume. This technique is known as snapshots in some other file
systems.Makingashadowcopyofavolumeisaformofcopy-on-write,where
blocks modified after the shadow copy is created are stored in their original
form in the copy. To achieve a consistent state for the volume requires the
cooperationofapplications,sincethesystemcannotknowwhenthedataused
by the application are in a stable state from which the application could be
safelyrestarted.
TheserverversionofWindowsusesshadowcopiestoefficientlymaintain
oldversionsoffilesstoredonfileservers.Thisallowsuserstoseedocuments
storedonfileserversastheyexistedatearlierpointsintime.Theusercanuse
thisfeaturetorecoverfilesthatwereaccidentallydeletedorsimplytolookat
apreviousversionofthefile,allwithoutpullingoutbackupmedia.
B.6 Networking
Windows supports both peer-to-peer and client–server networking. It also
has facilities for network management. The networking components in Win-
dowsprovidedatatransport,interprocesscommunication,filesharingacross
anetwork,andtheabilitytosendprintjobstoremoteprinters.
B.6.1 Network Interfaces
TodescribenetworkinginWindows,wemustfirstmentiontwooftheinternal
networkinginterfaces:thenetworkdeviceinterfacespecificatio (NDIS)and
thetransportdriverinterface(TDI).TheNDISinterfacewasdevelopedin1989
byMicrosoftand3Comtoseparatenetworkadaptersfromtransportprotocols
so that either could be changed without affecting the other. NDIS resides at
the interface between the data-link and network layers in the ISO model and
enables many protocols to operate over many different network adapters. In
terms of the ISO model, the TDI is the interface between the transport layer
(layer4)andthesessionlayer(layer5).Thisinterfaceenablesanysession-layer
component to use any available transport mechanism. (Similar reasoning led
to the streams mechanism in UNIX.) The TDI supports both connection-based
andconnectionlesstransportandhasfunctionstosendanytypeofdata.
B.6.2 Protocols
Windows implements transport protocols as drivers. These drivers can be
loaded and unloaded from the system dynamically, although in practice the
system typically has to be rebooted after a change. Windows comes with
severalnetworkingprotocols.Next,wediscussanumberoftheseprotocols.42 AppendixB Windows7
B.6.2.1 Server-MessageBlock
Theserver-message-block(SMB)protocolwasfirstintroducedinMS-DOS3.1.
ThesystemusestheprotocoltosendI/Orequestsoverthenetwork.TheSMB
protocolhasfourmessagetypes.Session controlmessagesarecommands
thatstartandendaredirectorconnectiontoasharedresourceattheserver.A
redirectorusesFilemessagestoaccess filesat theserver.Printermessages
areusedtosenddatatoaremoteprintqueueandtoreceivestatusinformation
fromthequeue,andMessagemessagesareusedtocommunicatewithanother
workstation. A version of the SMB protocol was published as the common
Internetfil system(CIFS)andissupportedonanumberofoperatingsystems.
B.6.2.2 TransmissionControlProtocol/InternetProtocol
Thetransmissioncontrolprotocol/Internetprotocol(TCP/IP)suitethatisused
on the Internet has become the de facto standard networking infrastructure.
Windows uses TCP/IP to connect to a wide variety of operating systems
and hardware platforms. The Windows TCP/IP package includes the simple
network-management protocol (SNM), the dynamichost-configuration proto-
col (DHCP), and the older Windows Internet name service (WINS). Windows
Vista introduced a new implementation of TCP/IP that supports both IPv4
andIPv6inthesamenetworkstack.Thisnewimplementationalsosupports
offloadingofthenetworkstackontoadvancedhardware,toachieveveryhigh
performanceforservers.
WindowsprovidesasoftwarefirewallthatlimitstheTCPportsthatcanbe
used by programs for network communication. Network firewalls are com-
monly implemented in routers and are a very important security measure.
Having a firewall built into the operating system makes a hardware router
unnecessary,anditalsoprovidesmoreintegratedmanagementandeasieruse.
B.6.2.3 Point-to-PointTunnelingProtocol
The point-to-pointtunnelingprotocol(PPTP)is aprotocolprovidedby Win-
dowstocommunicatebetweenremote-accessservermodulesrunningonWin-
dows server machines and other client systems that are connected over the
Internet. The remote-access servers can encrypt data sent over the connec-
tion,andtheysupportmultiprotocolvirtualprivatenetworks(VPNs)overthe
Internet.
B.6.2.4 HTTPProtocol
TheHTTPprotocolisusedtoget/putinformationusingtheWorldWideWeb.
Windows implements HTTP using a kernel-mode driver, so web servers can
operate with a low-overhead connection to the networking stack. HTTP is a
fairlygeneralprotocolthatWindowsmakesavailableasatransportoptionfor
implementingRPC.
B.6.2.5 Web-DistributedAuthoringandVersioningProtocol
Web-distributedauthoringandversioning(WebDAV)isanHTTP-basedproto-
col for collaborative authoring across a network. Windows builds a WebDAVB.6 Networking 43
redirectorintothefilesystem.Beingbuiltdirectlyintothefilesystemenables
WebDAVtoworkwithotherfile-systemfeatures,suchasencryption.Personal
filescanthenbestoredsecurelyinapublicplace.BecauseWebDAVusesHTTP,
which is a get/put protocol, Windows has to cache the files locally so pro-
gramscanusereadandwriteoperationsonpartsofthefiles.
B.6.2.6 NamedPipes
Namedpipesareaconnection-orientedmessagingmechanism.Aprocesscan
usenamedpipestocommunicate withotherprocessesonthesamemachine.
Sincenamedpipesareaccessedthroughthefile-systeminterface,thesecurity
mechanismsusedforfileobjectsalsoapplytonamedpipes.TheSMBprotocol
supports named pipes, so they can also be used for communication between
processesondifferentsystems.
The format of pipe names follows the uniform naming convention
(UNC). A UNC name looks like a typical remote file name. The format is
∖∖server name∖share name∖x∖y∖z, where server name identifies a server
on the network; share name identifies any resource that is made available
to network users, such as directories, files, named pipes, and printers; and
∖x∖y∖zisanormalfilepathname.
B.6.2.7 RemoteProcedureCalls
A remote procedure call (RPC) is a client–server mechanism that enables an
application on one machine to make a procedure call to code on another
machine. The client calls a local procedure—a stub routine—that packs its
arguments into a message and sends them across the network to a particular
serverprocess.Theclient-sidestubroutinethenblocks.Meanwhile,theserver
unpacksthemessage,callstheprocedure,packsthereturnresultsintoames-
sage,andsendsthembacktotheclientstub.Theclientstubunblocks,receives
themessage,unpackstheresultsoftheRPC,andreturnsthemtothecaller.This
packingofargumentsissometimescalledmarshaling.Theclientstubcodeand
the descriptors necessary to pack and unpack the arguments for an RPC are
compiled from a specification written in the Microsoft Interface Definitio
Language.
The Windows RPC mechanism follows the widely used distributed-
computing-environment standard for RPC messages, so programs written to
useWindows RPCsarehighlyportable.TheRPCstandardisdetailed.Ithides
many of the architectural differences among computers, such as the sizes
of binary numbers and the order of bytes and bits in computer words, by
specifyingstandarddataformatsforRPCmessages.
B.6.2.8 ComponentObjectModel
Thecomponentobjectmodel(COM)isamechanismforinterprocesscommu-
nicationthatwasdevelopedforWindows.COMobjectsprovideawell-defined
interfacetomanipulatethedataintheobject.For instance,COM istheinfras-
tructureusedbyMicrosoft’sobjectlinkingandembedding(OLE)technology
for inserting spreadsheets into Microsoft Word documents. Many Windows
services provide COM interfaces. Windows has a distributed extension called44 AppendixB Windows7
DCOMthatcanbeusedoveranetworkutilizingRPCtoprovideatransparent
methodofdevelopingdistributedapplications.
B.6.3 Redirectors and Servers
InWindows, anapplicationcanuse theWindows I/OAPItoaccess filesfrom
aremotecomputerasthoughtheywerelocal,providedthat theremotecom-
puterisrunningaCIFSserversuchasthoseprovidedbyWindows.Aredirector
is the client-side object that forwards I/O requests to a remote system, where
theyaresatisfiedbyaserver.Forperformanceandsecurity,theredirectorsand
serversruninkernelmode.
Inmoredetail,accesstoaremotefileoccursasfollows:
1. TheapplicationcallstheI/Omanagertorequestthatafilebeopenedwith
afilenameinthestandardUNCformat.
2. The I/O manager builds an I/O request packet, as described in Section
B.3.3.5.
3. TheI/Omanagerrecognizesthattheaccessisforaremotefileandcallsa
drivercalledamultipleuniversal-naming-conventionprovider(MUP).
4. The MUP sends the I/O request packet asynchronously to all registered
redirectors.
5. Aredirector that can satisfy the request responds to the MUP. To avoid
askingalltheredirectorsthesamequestioninthefuture,theMUPusesa
cachetorememberwhichredirectorcanhandlethisfile.
6. Theredirectorsendsthenetworkrequesttotheremotesystem.
7. Theremote-systemnetworkdriversreceivetherequestandpassittothe
serverdriver.
8. Theserverdriverhandstherequesttotheproperlocalfile-systemdriver.
9. Theproperdevicedriveriscalledtoaccessthedata.
10. The results are returned to the serverdriver, which sends the data back
to the requesting redirector. The redirector then returns the data to the
callingapplicationviatheI/Omanager.
AsimilarprocessoccursforapplicationsthatusetheWin32networkAPI,rather
than the UNC services,except that a module called a multi-provider router is
usedinsteadofaMUP.
For portability, redirectorsand servers use the TDI API for network trans-
port.Therequeststhemselvesareexpressedinahigher-levelprotocol,which
bydefaultistheSMBprotocoldescribedinSectionB.6.2.Thelistofredirectors
ismaintainedinthesystemhiveoftheregistry.
B.6.3.1 DistributedFileSystem
UNC names are not always convenient, because multiple file servers may be
availabletoservethesamecontentandUNCnamesexplicitlyincludethenameB.6 Networking 45
oftheserver.Windowssupportsadistributedfile-syste (DFS)protocolthat
allowsanetworkadministratortoserveupfilesfrommultipleserversusinga
singledistributednamespace.
B.6.3.2 FolderRedirectionandClient-SideCaching
To improve the PC experience for users who frequently switch among com-
puters,Windowsallowsadministratorstogiveusersroamingprofile ,which
keepusers’preferencesandothersettingsonservers.Folderredirectionisthen
usedtoautomaticallystoreauser’sdocumentsandotherfilesonaserver.
This works well until one of the computers is no longer attached to the
network,aswhenausertakesalaptopontoanairplane.Togiveusersoff-line
access to their redirected files, Windows uses client-side caching (CSC). CSC
is also used when the computer is on-line to keep copies of the server files
on the local machine for better performance. The files are pushed up to the
serverastheyarechanged.Ifthecomputerbecomesdisconnected,thefilesare
stillavailable,and the updateofthe serveris deferreduntil the nexttimethe
computerisonline.
B.6.4 Domains
Manynetworkedenvironmentshavenaturalgroupsofusers,suchasstudents
inacomputerlaboratoryatschooloremployeesinonedepartmentinabusi-
ness. Frequently, we want all the members of the group to be able to access
sharedresourcesontheirvariouscomputersinthegroup.Tomanagetheglobal
accessrightswithinsuchgroups,Windowsusestheconceptofadomain.Pre-
viously, these domains had no relationship whatsoever to the domain-name
system (DNS) that maps Internet host names to IP addresses. Now, however,
theyarecloselyrelated.
Specifically,aWindows domainisagroupofWindows workstationsand
serversthatshareacommonsecuritypolicyanduserdatabase.SinceWindows
usestheKerberosprotocolfortrustandauthentication,aWindowsdomainis
the same thing as a Kerberos realm. Windows uses a hierarchical approach
for establishing trust relationships between related domains. The trust rela-
tionships are based on DNS and allow transitive trusts that can flow up and
down the hierarchy. This approach reducesthe number of trusts requiredfor
ndomainsfromn ∗ (n−1)toO(n).Theworkstations inthe domaintrustthe
domain controller to give correct information about the access rights of each
user(loadedintotheuser’saccesstokenbyLSASS).Allusersretaintheabilityto
restrictaccesstotheirownworkstations,however,nomatterwhatanydomain
controllermaysay.
B.6.5 Active Directory
Active Directory is the Windows implementation of lightweight directory-
access protocol (LDAP) services. Active Directory stores the topology infor-
mation about the domain, keeps the domain-based user and group accounts
andpasswords,andprovidesadomain-basedstoreforWindowsfeaturesthat
needit,suchasWindowsgrouppolicy.Administratorsusegrouppoliciesto
establish uniform standards for desktop preferences and software. For many46 AppendixB Windows7
corporateinformation-technology groups,this uniformitydrasticallyreduces
thecostofcomputing.
B.7 Programmer Interface
TheWin32APIisthefundamentalinterfacetothecapabilitiesofWindows.This
section describes five main aspects of the Win32API: access to kernel objects,
sharingofobjectsbetweenprocesses,processmanagement,interprocesscom-
munication,andmemorymanagement.
B.7.1 Access to Kernel Objects
The Windows kernel provides many services that application programs can
use. Application programs obtain these services by manipulating kernel
objects. A process gains access to a kernel object named XXX by calling the
CreateXXX function to open a handle to an instance of XXX. This handle is
unique to the process. Depending on which object is being opened, if the
Create() function fails, it may return 0, or it may return a special constant
named INVALID HANDLE VALUE.Aprocess can close any handle by calling the
CloseHandle()function,andthesystemmaydeletetheobjectifthecountof
handlesreferencingtheobjectinallprocessesdropstozero.
B.7.2 Sharing Objects between Processes
Windows provides three ways to share objects between processes. The first
way is for a child process to inherit a handle to the object. When the parent
calls the CreateXXX function, the parent supplies a SECURITIES ATTRIBUTES
structure with the bInheritHandle field set to TRUE. This field creates an
inheritable handle.Next,the child processis created,passing avalueof TRUE
to the CreateProcess() function’s bInheritHandle argument. Figure B.8
shows a code sample that creates a semaphore handle inherited by a child
process.
SECURITY ATTRIBUTES sa;
sa.nlength = sizeof(sa);
sa.lpSecurityDescriptor = NULL;
sa.bInheritHandle = TRUE;
Handle a semaphore = CreateSemaphore(&sa, 1, 1, NULL);
char comand line[132];
ostrstream ostring(command line, sizeof(command line));
ostring << a semaphore << ends;
CreateProcess("another process.exe", command line,
NULL, NULL, TRUE, . . .);
FigureB.8 Codeenablingachildtoshareanobjectbyinheritingahandle.B.7 ProgrammerInterface 47
// Process A
. . .
HANDLE a semaphore = CreateSemaphore(NULL, 1, 1, "MySEM1");
. . .
// Process B
. . .
HANDLE b semaphore = OpenSemaphore(SEMAPHORE ALL ACCESS,
FALSE, "MySEM1");
. . .
FigureB.9 Codeforsharinganobjectbynamelookup.
Assuming the child process knows which handles are shared, the parent
andchildcanachieveinterprocesscommunicationthroughthesharedobjects.
In the example in Figure B.8, the child process gets the value of the handle
from the first command-line argument and then shares the semaphore with
theparentprocess.
The second way to share objects is for one process to give the object a
namewhentheobjectiscreatedandforthesecondprocesstoopenthename.
This method has two drawbacks: Windows does not provide a way to check
whether an object with the chosen name already exists, and the object name
spaceisglobal,withoutregardtotheobjecttype.Forinstance,twoapplications
maycreateandshareasingleobjectnamed“foo”whentwodistinctobjects—
possiblyofdifferenttypes—weredesired.
Named objects have the advantage that unrelated processes can readily
sharethem.ThefirstprocesscallsoneoftheCreateXXXfunctionsandsupplies
a name as a parameter. The second process gets a handle to share the object
by calling OpenXXX() (or CreateXXX) with the same name, as shown in the
exampleinFigureB.9.
ThethirdwaytoshareobjectsisviatheDuplicateHandle()function.This
method requires some other method of interprocess communication to pass
theduplicatedhandle.Givena handletoa processand the valueofahandle
withinthatprocess,asecond processcangetahandletothesameobject and
thusshareit.AnexampleofthismethodisshowninFigureB.10.
B.7.3 Process Management
InWindows,aprocessisaloadedinstanceofanapplicationandathreadisan
executableunit of code that can be scheduledby the kerneldispatcher.Thus,
a process contains one or more threads. A process is created when a thread
insomeotherprocesscallstheCreateProcess()API.Thisroutineloadsany
dynamiclinklibrariesusedby theprocessandcreatesaninitialthreadinthe
process. Additional threads can be created by the CreateThread() function.
Each thread is created with its own stack, which defaults to 1 MB unless
otherwisespecifiedinanargumenttoCreateThread().48 AppendixB Windows7
// Process A wants to give Process B access to a semaphore
// Process A
HANDLE a semaphore = CreateSemaphore(NULL, 1, 1, NULL);
// send the value of the semaphore to Process B
// using a message or shared memory object
. . .
// Process B
HANDLE process a = OpenProcess(PROCESS ALL ACCESS, FALSE,
process id of A);
HANDLE b semaphore;
DuplicateHandle(process a, a semaphore,
GetCurrentProcess(), &b semaphore,
0, FALSE, DUPLICATE SAME ACCESS);
// use b semaphore to access the semaphore
. . .
FigureB.10 Codeforsharinganobjectbypassingahandle.
B.7.3.1 SchedulingRule
Priorities in the Win32 environment are based on the native kernel (NT)
scheduling model, but not all priority values may be chosen. The Win32 API
usesfourpriorityclasses:
1. IDLE PRIORITY CLASS(NTprioritylevel4)
2. NORMAL PRIORITY CLASS(NTprioritylevel8)
3. HIGH PRIORITY CLASS(NTprioritylevel13)
4. REALTIME PRIORITY CLASS(NTprioritylevel24)
Processes are typically members of the NORMAL PRIORITY CLASS unless the
parent of the process was of the IDLE PRIORITY CLASS or another class was
specified when CreateProcess was called. The priority class of a process is
the default for all threads that execute in the process. It can be changed with
the SetPriorityClass() function or by passing an argument to the START
command.Onlyuserswiththeincreaseschedulingpriorityprivilegecanmove
aprocessintotheREALTIME PRIORITY CLASS.Administratorsandpowerusers
havethisprivilegebydefault.
When a user is running an interactive process, the system needs to
schedule the process’s threads to provide good responsiveness. For this
reason, Windows has a special scheduling rule for processes in the NOR-
MAL PRIORITY CLASS.Windows distinguishes between the process associated
with the foreground window on the screen and the other (background)
processes.Whenaprocessmovesintotheforeground,Windowsincreasesthe
scheduling quantum for all its threads by a factor of 3; CPU-bound threadsB.7 ProgrammerInterface 49
in the foreground process will run three times longer than similar threads in
backgroundprocesses.
B.7.3.2 ThreadPriorities
A thread starts with an initial priority determined by its class. The priority
canbealteredbytheSetThreadPriority()function. Thisfunctiontakesan
argumentthatspecifiesapriorityrelativetothebasepriorityofitsclass:
• THREAD PRIORITY LOWEST:base−2
• THREAD PRIORITY BELOW NORMAL:base−1
• THREAD PRIORITY NORMAL:base+0
• THREAD PRIORITY ABOVE NORMAL:base+1
• THREAD PRIORITY HIGHEST:base+2
Two other designations are also used to adjust the priority. Recall from
Section B.3.2.2 that the kernel has two priority classes: 16–31 for the real-
time class and 1–15 for the variable class. THREAD PRIORITY IDLE sets the
priority to 16 for real-time threads and to 1 for variable-priority threads.
THREAD PRIORITY TIME CRITICAL sets the priority to 31 for real-time threads
andto15forvariable-prioritythreads.
AsdiscussedinSectionB.3.2.2,thekerneladjuststhepriorityofavariable
class thread dynamically depending on whether the thread is I/O bound or
CPU bound. The Win32API provides a method to disable this adjustment via
SetProcessPriorityBoost()andSetThreadPriorityBoost()functions.
B.7.3.3 ThreadSuspendandResume
Athreadcanbecreatedinasuspendedstateorcanbeplacedinasuspended
statelaterbyuseoftheSuspendThread()function.Beforeasuspendedthread
can be scheduled by the kernel dispatcher, it must be moved out of the sus-
pended state by use of the ResumeThread() function. Both functions set a
countersothatifathreadissuspendedtwice,itmustberesumedtwicebefore
itcanrun.
B.7.3.4 ThreadSynchronization
Tosynchronizeconcurrentaccesstosharedobjectsbythreads,thekernelpro-
vides synchronization objects, such as semaphores and mutexes. These are
dispatcherobjects,asdiscussedinSectionB.3.2.2.Threadscanalsosynchronize
withkernel servicesoperating on kernelobjects—such as threads, processes,
andfiles—becausethesearealsodispatcherobjects.Synchronizationwithker-
neldispatcherobjectscanbeachievedbyuseoftheWaitForSingleObject()
and WaitForMultipleObjects() functions; these functions wait for one or
moredispatcherobjectstobesignaled.
Anothermethodofsynchronizationisavailabletothreadswithinthesame
processthatwanttoexecutecodeexclusively.TheWin32criticalsectionobject
is a user-mode mutex object that can often be acquired and released without
enteringthekernel.Onamultiprocessor,aWin32 criticalsectionwillattempt
tospinwhilewaitingforacriticalsectionheldbyanotherthreadtobereleased.50 AppendixB Windows7
Ifthespinningtakestoolong,theacquiringthreadwillallocateakernelmutex
andyielditsCPU.Criticalsectionsareparticularlyefficientbecausethekernel
mutex is allocated only when there is contention and then used only after
attempting to spin. Most mutexes in programs are never actually contended,
sothesavingsaresignificant.
Before using a critical section, some thread in the process must call
InitializeCriticalSection(). Each thread that wants to acquire the
mutex calls EnterCriticalSection() and then later calls LeaveCritical-
Section()toreleasethemutex.ThereisalsoaTryEnterCriticalSection()
function,whichattemptstoacquirethemutexwithoutblocking.
For programs that want user-mode reader–writer locks rather than a
mutex, Win32 supports slim reader–writer (SRW) locks. SRW locks have
APIs similar to those for critical sections, such as InitializeSRWLock,
AcquireSRWLockXXX, and ReleaseSRWLockXXX, where XXX is either
Exclusive or Shared, depending on whether the thread wants write
accessorjustreadaccesstotheobjectprotectedbythelock.TheWin32APIalso
supports condition variables, which can be used with either critical sections
orSRWlocks.
B.7.3.5 ThreadPool
Repeatedly creating and deleting threads can be expensive for applications
and services that perform small amounts of work in each instantiation. The
Win32threadpoolprovidesuser-modeprogramswiththreeservices:aqueue
towhichworkrequestsmaybesubmitted(viatheSubmitThreadpoolWork()
function),anAPIthatcanbeusedtobindcallbackstowaitablehandles(Regis-
terWaitForSingleObject()),andAPIstoworkwithtimers(CreateThread-
poolTimer()andWaitForThreadpoolTimerCallbacks())andtobindcall-
backstoI/Ocompletionqueues(BindIoCompletionCallback()).
Thegoalofusingathreadpoolistoincreaseperformanceandreducemem-
ory footprint. Threads are relatively expensive, and each processor can only
be executing one thread at a timeno matter how many threads are available.
Thethreadpoolattemptstoreducethenumberofrunnablethreadsbyslightly
delayingworkrequests(reusingeachthreadformanyrequests)whileprovid-
ingenoughthreadstoeffectivelyutilizethemachine’sCPUs.ThewaitandI/O-
and timer-callback APIs allow the thread pool to further reduce the number
of threads in a process, using far fewer threads than would be necessary if
a process were to devote separate threads to servicing each waitable handle,
timer,orcompletionport.
B.7.3.6 Fibers
A fibe is user-mode code that is scheduled according to a user-defined
schedulingalgorithm.Fibersarecompletelyauser-modefacility;thekernelis
notawarethattheyexist.ThefibermechanismusesWindowsthreadsasifthey
were CPUs to executethe fibers. Fibers are cooperativelyscheduled,meaning
that they are never preempted but must explicitly yield the thread on which
theyarerunning.Whenafiberyieldsathread,anotherfibercanbescheduled
onitbytherun-timesystem(theprogramminglanguagerun-timecode).
The system creates a fiber by calling either ConvertThreadToFiber()
or CreateFiber(). The primary difference between these functions is thatB.7 ProgrammerInterface 51
CreateFiber()doesnotbeginexecutingthefiberthatwascreated.Tobegin
execution, the application must call SwitchToFiber(). The application can
terminateafiberbycallingDeleteFiber().
Fibers are not recommended for threads that use Win32 APIs rather than
standardC-libraryfunctionsbecauseofpotentialincompatibilities.Win32user-
modethreadshaveathread-environmentblock(TEB)thatcontainsnumerous
per-threadfieldsusedbytheWin32APIs.FibersmustsharetheTEBofthethread
onwhichtheyarerunning.ThiscanleadtoproblemswhenaWin32interface
puts state information into the TEB for one fiber and then the information is
overwrittenbyadifferentfiber.FibersareincludedintheWin32APItofacilitate
the porting of legacy UNIX applications that were written for a user-mode
threadmodelsuchasPthreads.
B.7.3.7 User-ModeScheduling(UMS)andConcRT
A new mechanism in Windows 7, user-mode scheduling (UMS), addresses
severallimitationsoffibers.First,recallthatfibersareunreliableforexecuting
Win32APIs because theydonot have theirown TEBs.When athreadrunning
a fiber blocks in the kernel, the user scheduler loses control of the CPU for a
timeasthekerneldispatchertakesoverscheduling.Problemsmayresultwhen
fiberschangethekernelstateofathread,suchasthepriorityorimpersonation
token,orwhentheystartasynchronousI/O.
UMS provides an alternative model by recognizing that each Windows
thread is actually two threads: a kernel thread (KT) and a user thread (UT).
Each type of thread has its own stack and its own set of saved registers. The
KT and UT appear as a single thread to the programmer because UTs can
neverblockbutmustalwaysenterthekernel,whereanimplicitswitchtothe
corresponding KT takes place. UMS uses each UT’s TEB to uniquely identify
theUT.WhenaUTentersthekernel,anexplicitswitchismadetotheKTthat
correspondstotheUTidentifiedbythecurrentTEB.Thereasonthekerneldoes
not know which UT is running is thatUTs can invoke auser-modescheduler,
as fibers do. But in UMS, the scheduler switches UTs, including switching the
TEBs.
When a UT enters the kernel, its KT may block. When this happens, the
kernel switches to a scheduling thread, which UMS calls a primary, and uses
this thread to reenter the user-mode scheduler so that it can pick another UT
to run. Eventually, a blocked KT will complete its operation and be ready to
returntousermode.SinceUMShasalreadyreenteredtheuser-modescheduler
to run a different UT, UMS queues the UT corresponding to the completed KT
toacompletionlistinusermode.Whentheuser-modeschedulerischoosing
anew UTtoswitchto, itcan examinethecompletionlistand treatany UT on
thelistasacandidateforscheduling.
Unlike fibers, UMS is not intended to be used directly by the program-
mer.Thedetailsofwritinguser-modeschedulerscanbeverychallenging,and
UMSdoesnotincludesuchascheduler.Rather,theschedulerscomefrompro-
gramminglanguagelibrariesthatbuildontopofUMS.MicrosoftVisualStudio
2010shippedwithConcurrencyRuntime(ConcRT),aconcurrentprogramming
framework for C++. ConcRT provides a user-mode scheduler together with
facilities for decomposing programs into tasks, which can then be scheduled
on the available CPUs. ConcRT provides support for par for styles of con-52 AppendixB Windows7
KT blocks
NTOS executive 0
KT 0 KT 1 KT 2 primary
trap code thread
thread parking
kernel
user
UT completion list
user-mode
UT
0 scheduler
Only primary thread runs in user-mode
Trap code switches to parked KT
KT blocks
=>
primary returns to user-mode
KT unblocks & parks => queue UT completion UT 1 UT 0
FigureB.11 User-modescheduling.
structs,aswellasrudimentaryresourcemanagementandtasksynchronization
primitives.ThekeyfeaturesofUMSaredepictedinFigureB.11.
B.7.3.8 Winsock
Winsock is the Windows sockets API. Winsock is a session-layer interface
that is largely compatible with UNIX sockets but has some added Windows
extensions. It provides a standardized interface to many transport protocols
thatmayhavedifferentaddressingschemes,sothatanyWinsock application
canrunonanyWinsock-compliantprotocolstack.Winsockunderwentamajor
update in Windows Vista to add tracing, IPv6 support, impersonation, new
securityAPIs andmanyotherfeatures.
Winsock follows the Windows Open System Architecture (WOSA) model,
which provides a standard service provider interface (SPI) between applica-
tions and networking protocols. Applications can load and unload layered
protocols that build additional functionality, such as additional security, on
top of the transport protocol layers. Winsock supports asynchronous opera-
tionsandnotifications,reliablemulticasting,securesockets,andkernelmode
sockets.Thereisalsosupportforsimplerusagemodels,liketheWSAConnect-
ByName()function,whichacceptsthetargetasstringsspecifyingthenameor
IPaddressoftheserverandtheserviceorportnumberofthedestinationport.
B.7.4 IPC Using Windows Messaging
Win32 applications handle interprocess communication in several ways. One
way is by using shared kernel objects. Another is by using the Windows
messaging facility, an approach that is particularly popular for Win32
GUI applications. One thread can send a message to another thread or to a
windowbycallingPostMessage(),PostThreadMessage(),SendMessage(),
SendThreadMessage(),orSendMessageCallback().Postingamessageand
sendingamessagedifferinthisway:thepostroutinesareasynchronous,they
return immediately,and the calling thread does not know when the messageB.7 ProgrammerInterface 53
// allocate 16 MB at the top of our address space
void *buf = VirtualAlloc(0, 0x1000000, MEM RESERVE | MEM TOP DOWN,
PAGE READWRITE);
// commit the upper 8 MB of the allocated space
VirtualAlloc(buf + 0x800000, 0x800000, MEM COMMIT, PAGE READWRITE);
// do something with the memory
. . .
// now decommit the memory
VirtualFree(buf + 0x800000, 0x800000, MEM DECOMMIT);
// release all of the allocated address space
VirtualFree(buf, 0, MEM RELEASE);
FigureB.12 Codefragmentsforallocatingvirtualmemory.
isactuallydelivered.Thesendroutinesaresynchronous:theyblockthecaller
untilthemessagehasbeendeliveredandprocessed.
In addition to sending a message, a thread can send data with the mes-
sage. Since processes have separate address spaces, the data must be copied.
The system copies data by calling SendMessage() to send a message of type
WM COPYDATA with a COPYDATASTRUCT data structure that contains the length
andaddressofthedatatobetransferred.Whenthemessageissent,Windows
copiesthedatatoanewblockofmemoryandgivesthevirtualaddressofthe
newblocktothereceivingprocess.
Every Win32 thread has its own input queue from which it receives mes-
sages.IfaWin32applicationdoesnotcallGetMessage()tohandleeventson
its input queue, the queue fills up, and after about five seconds, the system
markstheapplicationas“NotResponding”.
B.7.5 Memory Management
TheWin32APIprovidesseveralwaysforanapplicationtousememory:virtual
memory,memory-mappedfiles,heaps,andthread-localstorage.
B.7.5.1 VirtualMemory
An application calls VirtualAlloc() to reserve or commit virtual memory
and VirtualFree() to decommit or release the memory. These functions
enable the application to specify the virtual address at which the memory is
allocated. They operate on multiples of the memory page size. Examples of
thesefunctionsappearinFigureB.12.
Aprocessmaylocksomeofitscommittedpagesintophysicalmemoryby
callingVirtualLock().Themaximumnumberofpagesaprocesscanlockis
30,unlesstheprocessfirstcallsSetProcessWorkingSetSize()toincreasethe
maximumworking-setsize.
B.7.5.2 Memory-MappingFiles
Another way for an applicationtouse memory is by memory-mapping afile
into its address space. Memory mapping is also a convenient way for two54 AppendixB Windows7
// open the file or create it if it does not exist
HANDLE hfile = CreateFile("somefile", GENERIC READ | GENERIC WRITE,
FILE SHARE READ | FILE SHARE WRITE, NULL,
OPEN ALWAYS, FILE ATTRIBUTE NORMAL, NULL);
// create the file mapping 8 MB in size
HANDLE hmap = CreateFileMapping(hfile, PAGE READWRITE,
SEC COMMIT, 0, 0x800000, "SHM 1");
// now get a view of the space mapped
void *buf = MapViewOfFile(hmap, FILE MAP ALL ACCESS,
0, 0, 0, 0x800000);
// do something with the mapped file
. . .
// now unmap the file
UnMapViewOfFile(buf);
CloseHandle(hmap);
CloseHandle(hfile);
FigureB.13 Codefragmentsformemorymappingofafile.
processestosharememory:bothprocessesmapthesamefileintotheirvirtual
memory. Memory mapping is a multistage process, as you can see in the
exampleinFigureB.13.
Ifaprocesswantstomapsomeaddressspacejusttoshareamemoryregion
with another process, no file is needed. The process calls CreateFileMap-
ping() with a file handle of 0xffffffff and a particular size. The resulting
file-mappingobjectcanbesharedbyinheritance,bynamelookup,orbyhandle
duplication.
B.7.5.3 Heaps
Heaps provideathirdway for applications tousememory,just as withmal-
loc()andfree()instandardC.AheapintheWin32environmentisaregion
of reserved address space. When a Win32 process is initialized, it is created
withadefaultheap.SincemostWin32applicationsaremultithreaded,accessto
theheapissynchronizedtoprotecttheheap’sspace-allocationdatastructures
frombeingdamagedbyconcurrentupdatesbymultiplethreads.
Win32providesseveralheap-managementfunctionssothataprocesscan
allocateandmanageaprivateheap.ThesefunctionsareHeapCreate(),Hea-
pAlloc(), HeapRealloc(), HeapSize(), HeapFree(), and HeapDestroy().
TheWin32APIalsoprovidestheHeapLock()andHeapUnlock()functionsto
enable a thread to gain exclusive access to a heap. Unlike VirtualLock(),
these functions perform only synchronization; they do not lock pages into
physicalmemory.
The original Win32 heap was optimized for efficient use of space. This
ledtosignificantproblemswithfragmentationoftheaddressspaceforlarger
serverprograms that ran for long periodsof time.Anew low-fragmentation
heap (LFH) design introduced in Windows XP greatly reduced the fragmen-Summary 55
// reserve a slot for a variable
DWORD var index = T1sAlloc();
// set it to the value 10
T1sSetValue(var index, 10);
// get the value
int var T1sGetValue(var index);
// release the index
T1sFree(var index);
FigureB.14 Codefordynamicthread-localstorage.
tationproblem.TheWindows 7heapmanager automaticallyturns onLFHas
appropriate.
B.7.5.4 Thread-LocalStorage
Afourthwayforapplicationstousememoryisthroughathread-localstorage
(TLS) mechanism. Functions that rely on global or static data typically fail to
work properly in a multithreaded environment. For instance, the C run-time
function strtok() uses a static variable to keep track of its current position
while parsing a string. For two concurrent threads to execute strtok() cor-
rectly,theyneedseparatecurrent positionvariables.TLSprovidesawayto
maintain instances of variables that are global to the function being executed
butnotsharedwithanyotherthread.
TLS provides both dynamic and static methods of creating thread-local
storage.ThedynamicmethodisillustratedinFigureB.14.TheTLSmechanism
allocates global heap storage and attaches it to the thread environment block
thatWindowsallocatestoeveryuser-modethread.TheTEBisreadilyaccessible
by each thread and is used not just for TLS but for all the per-thread state
informationinusermode.
To use a thread-local static variable, the application declares the variable
asfollowstoensurethateverythreadhasitsownprivatecopy:
declspec(thread)DWORDcur pos = 0;
B.8 Summary
Microsoft designed Windows to be an extensible, portable operating system
—one able to take advantage of new techniques and hardware. Windows
supports multiple operating environments and symmetric multiprocessing,
including both 32-bit and 64-bit processorsand NUMAcomputers.The use of
kernel objects to provide basic services, along with support for client–server
computing,enablesWindowstosupportawidevarietyofapplicationenviron-
ments.Windowsprovidesvirtualmemory,integratedcaching,andpreemptive
scheduling. It supports elaborate security mechanisms and includes interna-
tionalizationfeatures.Windowsrunsonawidevarietyofcomputers,sousers
can choose and upgrade hardware to match their budgets and performance
requirementswithoutneedingtoaltertheapplicationstheyrun.56 AppendixB Windows7
Practice Exercises
B.1 What type of operating system is Windows? Describe two of its major
features.
B.2 ListthedesigngoalsofWindows.Describetwoindetail.
B.3 DescribethebootingprocessforaWindowssystem.
B.4 DescribethethreemainarchitecturallayersoftheWindowskernel.
B.5 Whatisthejoboftheobjectmanager?
B.6 Whattypesofservicesdoestheprocessmanagerprovide?
B.7 Whatisalocalprocedurecall?
B.8 WhataretheresponsibilitiesoftheI/Omanager?
B.9 WhattypesofnetworkingdoesWindowssupport?HowdoesWindows
implementtransportprotocols?Describetwonetworkingprotocols.
B.10 HowistheNTFSnamespaceorganized?
B.11 HowdoesNTFShandledatastructures?HowdoesNTFSrecoverfroma
systemcrash?Whatisguaranteedafterarecoverytakesplace?
B.12 HowdoesWindowsallocateusermemory?
B.13 Describesomeofthewaysinwhichanapplicationcanusememoryvia
theWin32API.
Further Reading
[Russinovich et al.(2017)] providesanoverviewofWindows 7 and consider-
able technical detail about system internals and components. [Brown (2000)]
presentsdetailsofthesecurityarchitectureofWindows.
The Microsoft Developer Network Library (http://msdn.microsoft.com)
supplies a wealth of information on Windows and other Microsoft products,
includingdocumentationofallthepublishedAPIs.
[Iseminger(2000)]providesagoodreferenceontheWindowsActiveDirec-
tory. Detailed discussions of writing programs that use the Win32API appear
in[Richter(1997)].
The source code for a 2005 WRK version of the Windows kernel, together
withacollectionofslidesandotherCRKcurriculummaterials,isavailablefrom
www.microsoft.com/WindowsAcademicforusebyuniversities.
Bibliography
[Brown(2000)] K. Brown, Programming Windows Security, Addison-Wesley
(2000).
[Iseminger(2000)] D.Iseminger,Active DirectoryServicesfor MicrosoftWindows
2000.TechnicalReference,MicrosoftPress(2000).Bibliography 57
[Richter(1997)] J.Richter,AdvancedWindows,MicrosoftPress(1997).
[Russinovichetal.(2017)] M.Russinovich,D.A.Solomon,andA.Ionescu,Win-
dowsInternals–Part1,SeventhEdition,MicrosoftPress(2017).C
Appendix
BSD UNIX
Thischapterwasfirs writtenin1991andhasbeenupdatedovertime.
In Chapter 20, we presented an in-depth examination of the Linux operating
system.Inthischapter,weexamineanotherpopularUNIXversion—UnixBSD.
We start by presenting a brief history of the UNIX operating system. We then
describethesystem’suserandprogrammerinterfaces.Finally,wediscussthe
internaldatastructuresandalgorithmsusedbytheFreeBSDkerneltosupport
theuser–programmerinterface.
C.1 UNIX History
The first version of UNIX was developed in 1969 by Ken Thompson of the
Research Group at Bell Laboratories to use an otherwise idle PDP-7. Thomp-
son was soon joined by Dennis Ritchie and they, with other members of the
ResearchGroup,producedtheearlyversionsofUNIX.
RitchiehadpreviouslyworkedontheMULTICSproject,andMULTICShada
stronginfluenceontheneweroperatingsystem.EventhenameUNIX isapun
onMULTICS.Thebasicorganizationofthefilesystem,theideaofthecommand
interpreter (or the shell) as a user process, the use of a separate process for
eachcommand,theoriginalline-editingcharacters(#toerasethelastcharacter
and @ to erase the entire line), and numerous other features came directly
fromMULTICS.Ideasfromotheroperatingsystems,suchasMIT’sCTSSandthe
XDS-940system,werealsoused.
Ritchie and Thompson worked quietly on UNIX for many years. They
movedittoaPDP-11/20forasecondversion;forathirdversion,theyrewrote
mostoftheoperatingsysteminthesystems-programminglanguageC,instead
ofthepreviouslyusedassemblylanguage.CwasdevelopedatBellLaborato-
ries to support UNIX. UNIX was also moved to larger PDP-11 models, such as
the11/45and11/70.Multiprogrammingandotherenhancementswereadded
whenitwasrewritteninCandmovedtosystems(suchasthe11/45)thathad
hardwaresupportformultiprogramming.
As UNIX developed, it became widely used within Bell Laboratories and
graduallyspreadtoafewuniversities.Thefirstversionwidelyavailableout-
12 AppendixC BSDUNIX
sideBellLaboratorieswasVersion6,releasedin1976.(Theversionnumberfor
early UNIX systems corresponds to the edition number of the UNIX Program-
mer’s Manual thatwas currentwhen thedistributionwas made;thecodeand
themanualwererevisedindependently.)
In1978,Version7wasdistributed.ThisUNIXsystemranonthePDP-11/70
and the Interdata 8/32 and is the ancestor of most modern UNIX systems. In
particular, it was soon ported to other PDP-11 models and to the VAX com-
puterline.TheversionavailableontheVAX was known as32V.Researchhas
continuedsincethen.
C.1.1 UNIX Support Group
After the distribution of Version 7 in 1978, the UNIX Support Group (USG)
assumed administrative control and responsibility from the Research Group
fordistributionsofUNIXwithinAT&T,theparentorganizationforBellLabora-
tories.UNIX was becoming a product, rather than simply a researchtool. The
ResearchGroupcontinuedtodeveloptheirownversionsofUNIX,however,to
supporttheirinternalcomputing.Version8includedafacilitycalledthestream
I/O system, which allows flexibleconfiguration of kernelIPC modules.It also
containedRFS,aremotefilesystemsimilartoSun’sNFS.Thecurrentversionis
Version10,releasedin1989andavailableonlywithinBellLaboratories.
USG mainly provided support for UNIX within AT&T. The first external
distributionfromUSGwasSystemIII,in1982.SystemIIIincorporatedfeatures
of Version 7 and 32V, as well as features of several UNIX systems developed
by groupsotherthan Research.Forexample,featuresof UNIX/RT,areal-time
UNIXsystem,andnumerousportionsoftheProgrammer’sWorkBench(PWB)
softwaretoolspackagewereincludedinSystemIII.
USG released System V in 1983; it is largely derived from System III.
The divestiture of the various Bell operating companies from AT&T left AT&T
in a position to market System V aggressively. USG was restructured as the
UNIX System Development Laboratory (USDL), which released UNIX System
V Release 2 (V.2) in 1984. UNIX System V Release 2, Version 4 (V.2.4) added a
newimplementationofvirtualmemorywithcopy-on-writepagingandshared
memory. USDL was in turn replaced by AT&T Information Systems (ATTIS),
which distributed System V Release 3 (V.3) in 1987. V.3 adapts the V8 imple-
mentationofthestreamI/OsystemandmakesitavailableasSTREAMS.Italso
includesRFS,theNFS-likeremotefilesystemmentionedearlier.
C.1.2 Berkeley Begins Development
Thesmallsize,modularity,andcleandesignofearlyUNIXsystemsledtoUNIX-
basedworkatnumerousothercomputer-scienceorganizations,suchasRAND,
BBN,theUniversityofIllinois,Harvard,Purdue,andDEC.Themostinfluential
UNIXdevelopmentgroupoutsideofBellLaboratoriesandAT&T,however,has
beentheUniversityofCaliforniaatBerkeley.
BillJoyandOzalpBabaogludidthefirstBerkeleyVAXUNIXworkin1978.
They added virtual memory, demand paging, and page replacement to 32V
to produce 3BSD UNIX. This version was the first to implement any of these
facilities on a UNIX system. The large virtual memory space of 3BSD allowed
the development of very large programs, such as Berkeley’s own Franz LISP.
The memory-management work convinced the Defense Advanced ResearchC.1 UNIXHistory 3
Projects Agency (DARPA)to fund Berkeleyfor the developmentofa standard
UNIXsystemforgovernmentuse;4BSDUNIXwastheresult.
The 4 BSD work for DARPA was guided by a steering committee that
included many notable people from the UNIX and networking communities.
One of the goals of this project was to provide support for the DARPA Inter-
net networking protocols (TCP/IP). This support was provided in a general
manner. It is possible in 4.2 BSD to communicate uniformly among diverse
networkfacilities,includinglocal-areanetworks(suchasEthernetsandtoken
rings)andwide-areanetworks(suchasNSFNET).Thisimplementationwasthe
mostimportantreasonforthecurrentpopularityoftheseprotocols.Manyven-
dorsofUNIXcomputersystemsuseditasthebasisfortheirimplementations,
and it was even used in other operating systems. It permitted the Internet to
growfrom60connectednetworksin1984tomorethan8,000networksandan
estimated10millionusersin1993.
Inaddition,Berkeleyadaptedmanyfeaturesfromcontemporaryoperating
systems to improve the design and implementation of UNIX. Many of the
terminal line-editing functions of the TENEX (TOPS-20) operating system were
providedby a new terminal driver.Anew user interface (the C Shell), a new
text editor (ex/vi), compilers for Pascal and LISP, and many new systems
programswerewrittenatBerkeley.For4.2BSD,certainefficiencyimprovements
wereinspiredbytheVMSoperatingsystem.
UNIXsoftwarefromBerkeleywasreleasedinBerkeleySoftwareDistribu-
tions(BSD).ItisconvenienttorefertotheBerkeleyVAXUNIXsystemsfollowing
3BSD as 4BSD, but there were actually several specific releases, most notably
4.1 BSD and 4.2 BSD; 4.2 BSD, first distributed in 1983, was the culmination of
the original Berkeley DARPA UNIX project. The equivalent version for PDP-11
systemswas2.9BSD.
In 1986, 4.3BSD was released. It was very similar to 4.2 BSD but included
numerousinternalchanges,suchasbugfixesandperformanceimprovements.
Somenewfacilitieswerealsoadded,includingsupportfortheXeroxNetwork
Systemprotocols.
Thenextversionwas4.3BSDTahoe,releasedin1988.Itincludedimproved
networking congestion control and TCP/IP performance. Disk configurations
were separated from the device drivers and read off the disks themselves.
Expanded time-zone support was also included. 4.3BSD Tahoe was actually
developed on and for the CCI Tahoe system (Computer Console, Inc., Power
6 computer), rather than for the usual VAX base. The corresponding PDP-11
releasewas2.10.1BSD;itwasdistributedbytheUSENIXassociation,whichalso
publishedthe4.3BSDmanuals.The4.3.2BSDRenoreleasesawtheinclusionof
animplementationofISO/OSInetworking.
ThelastBerkeleyrelease,4.4BSD,wasfinalizedinJuneof1993.Itincluded
new X.25 networking support and POSIX standard compliance. It also had a
radicallynewfilesystemorganization,withanewvirtualfilesysteminterface
andsupportforstackablefilesystems,allowingfilesystemstobelayeredon
top of each other for easy inclusion of new features. An implementation of
NFSwasincludedintherelease(Section15.8),alongwithanewlog-basedfile
system(seeChapter11).The4.4BSDvirtualmemorysystemwasderivedfrom
Mach (described in Section A.13). Several other changes, such as enhanced
security and improved kernel structure, were also included. With the release
ofversion4.4,Berkeleyhalteditsresearchefforts.4 AppendixC BSDUNIX
C.1.3 The Spread of UNIX
UNIX 4 BSD was the operating system of choice for the VAX from its initial
release(in1979)untilthereleaseofUltrix,DEC’sBSDimplementation.Indeed,
4 BSD is still the best choice for many research and networking installations.
The current set of UNIX operating systems is not limited to those from Bell
Laboratories(which is currentlyowned by Lucent Technology)and Berkeley,
however.SunMicrosystemshelpedpopularizetheBSDflavorofUNIXbyship-
ping it on Sun workstations. As UNIX grew in popularity, it was moved to
many computers and computer systems. A wide variety of UNIX and UNIX-
likeoperatingsystemshavebeencreated.DEC supporteditsUNIX (Ultrix)on
its workstations and is replacing Ultrix with another UNIX-derivedoperating
system, OSF/1. Microsoft rewrote UNIX for the Intel 8088 family and called
it XENIX, and its Windows NT operating system was heavily influenced by
UNIX. IBM has UNIX (AIX) on its PCs, workstations, and mainframes. In fact,
UNIXisavailableonalmostallgeneral-purposecomputers.Itrunsonpersonal
computers, workstations, minicomputers, mainframes, and supercomputers,
fromAppleMacintoshIIstoCrayIIs.Becauseofitswideavailability,itisused
inenvironmentsrangingfromacademictomilitarytomanufacturingprocess
control. Most of these systems are based on Version 7, System III, 4.2BSD, or
SystemV.
The wide popularity of UNIX with computer vendors has made UNIX the
mostportableofoperatingsystems,anduserscanexpectaUNIXenvironment
independentofany specificcomputer manufacturer. But the largenumber of
implementationsofthesystemhasledtoremarkablevariationintheprogram-
minganduserinterfacesdistributedbythevendors.Fortruevendorindepen-
dence,application-programdevelopersneedconsistentinterfaces.Suchinter-
faceswouldallowall“ UNIX”applicationstorunonallUNIXsystems,whichis
certainlynotthecurrentsituation.ThisissuehasbecomeimportantasUNIXhas
becomethepreferredprogram-developmentplatformforapplicationsranging
fromdatabasestographicsandnetworking,andithasledtoastrongmarket
demandforUNIXstandards.
Several standardization projects have been undertaken. The first was the
/usr/group1984Standard,sponsoredbytheUniForumindustryuser’sgroup.
Sincethen,manyofficialstandardsbodieshavecontinuedtheeffort,including
IEEE and ISO (the POSIX standard). The X/Open Group international consor-
tiumcompletedXPG3,aCommonApplicationEnvironment,whichsubsumes
the IEEE interface standard. Unfortunately, XPG3 is based on a draft of the
ANSICstandardratherthanthefinalspecification,andthereforeneededtobe
redoneasXPG4.In1989,theANSIstandardsbodystandardizedtheCprogram-
minglanguage,producinganANSICspecificationthatvendorswerequickto
adopt.
As such projects continue, the flavors of UNIX will converge and lead
to one programming interface to UNIX, allowing UNIX to become even more
popular. In fact, two separate sets of powerful UNIX vendors are working on
thisproblem:TheAT&T-guidedUNIXInternational(UI)andtheOpenSoftware
Foundation (OSF) have both agreed to follow the POSIX standard. Recently,
many of the vendors involved in those two groups have agreed on further
standardization(theCOSEagreement).C.1 UNIXHistory 5
USG/USDL/ATTIS First Edition Bell Labs Berkley
1969
DSG/USO/USL Research Software
Fifth Edition Distributions
1973
1976 PDP-11 Sixth Edition PDP-11
1BSD
1977 PWB MERT CB UNIX
VAX
1978 UNIX/RT Seventh Edition 32V 2BSD
3BSD
1979
3.0 4.0BSD
VAX
1980 XENIX
3.0.1
4.1BSD
1981 4.0.1
4.1aBSD
1982 5.0 System III 2.8BSD
Eighth 4.1cBSD
1983 5.2 System V XENIX 3 Edition 2.9BSD
4.2BSD
1984 System V SunOS
Release 2
1985
1986 Mach SunOS 3
Ninth 4.3BSD
System V
1987 Chorus Edition 2.10BSD
Release 3
XENIX 5
1988
Tenth 4.3BSD
UNIX
Edition Tahoe
1989 Chorus System V SunOS 4
Release 4 Plan 9
V3 4.3BSD
1990 OSF/1 Reno
1991
1992 Solaris 4.4BSD
1993 Solaris 2
FigureC.1 HistoryofUNIXversionsupto1993.
AT&TreplaceditsATTISgroupin1989withtheUNIXSoftwareOrganization
(USO),whichshippedthefirstmergedUNIX,SystemVRelease4.Thissystem
combines features from System V, 4.3BSD, and Sun’s SunOS, including long
file names, the Berkeley file system, virtual memory management, symbolic
links,multipleaccessgroups,jobcontrol,andreliablesignals;italsoconforms
tothepublishedPOSIXstandard,POSIX.1.AfterUSOproducedSVR4,itbecame
an independent AT&T subsidiary named Unix System Laboratories (USL); in
1993,itwaspurchasedbyNovell,Inc.FigureC.1summarizestherelationships
amongthevariousversionsofUNIX.6 AppendixC BSDUNIX
The UNIX system has grown from a personal project of two Bell Labora-
tories employees to an operating system defined by multinational standard-
ization bodies. At the same time, UNIX is an excellent vehicle for academic
study, and we believe it will remain an important part of operating-system
theory and practice. For example,the Tunis operating system,the Xinu oper-
ating system, and the Minix operating system are based on the concepts of
UNIXbutweredevelopedexplicitlyforclassroomstudy.Thereisaplethoraof
ongoing UNIX-relatedresearchsystems, including Mach, Chorus, Comandos,
andRoisin.Theoriginaldevelopers,RitchieandThompson,werehonoredin
1983bytheAssociationforComputingMachineryTuringAwardfortheirwork
onUNIX.
C.1.4 History of FreeBSD
The specific UNIX version used in this chapter is the Intel version of FreeBSD.
Thissystemimplementsmanyinterestingoperating-systemconcepts,suchas
demand paging with clustering, as well as networking. The FreeBSD project
began in early 1993 to produce a snapshot of 386 BSD to solve problems that
couldnotberesolvedusingtheexistingpatchmechanism.386BSDwasderived
from 4.3BSD-Lite (Net/2) and was released in June 1992 by William Jolitz.
FreeBSD(coinedbyDavidGreenman)1.0wasreleasedinDecember1993,and
FreeBSD1.1wasreleasedinMay1994.Bothversionswerebasedon4.3BSD-Lite.
LegalissuesbetweenUCBandNovellrequiredthat4.3BSD-Litecodenolonger
beused,sothefinal4.3BSD-LitereleasewasmadeinJuly1994(FreeBSD1.1.5.1).
FreeBSDwasthenreinventedbasedon4.4BSD-Litecode,whichwasincom-
plete.FreeBSD2.0wasreleasedinNovember1994.Laterreleasesincluded2.0.5
inJune1995,2.1.5inAugust1996,2.1.7.1inFebruary1997,2.2.1inApril1997,
2.2.8inNovember1998, 3.0inOctober 1998, 3.1inFebruary 1999, 3.2inMay
1999,3.3inSeptember1999,3.4inDecember1999,3.5inJune2000,4.0inMarch
2000,4.1inJuly2000,and4.2inNovember2000.
ThegoaloftheFreeBSDprojectistoprovidesoftwarethatcanbeusedfor
any purpose with no strings attached. The idea is that the code will get the
widestpossibleuseandprovidethemostbenefit.Atpresent,itrunsprimarily
onIntelplatforms,althoughAlphaplatformsaresupported.Workisunderway
toporttootherprocessorplatformsaswell.
C.2 Design Principles
UNIX was designed to be a time-sharing system. The standard user interface
(theshell)issimpleandcanbereplacedbyanother,ifdesired.Thefilesystem
isamultileveltree,whichallowsuserstocreatetheirownsubdirectories.Each
userdatafileissimplyasequenceofbytes.
DiskfilesandI/Odevicesaretreatedassimilarlyaspossible.Thus,device
dependenciesandpeculiaritiesarekeptinthekernelasmuchaspossible.Even
inthekernel,mostofthemareconfinedtothedevicedrivers.
UNIX supports multiple processes. A process can easily create new pro-
cesses. CPU scheduling is a simple priority algorithm. FreeBSD uses demandC.2 DesignPrinciples 7
pagingasamechanismtosupportmemory-managementandCPU-scheduling
decisions.Swappingisusedifasystemissufferingfromexcesspaging.
Because UNIX was originated by Thompson and Ritchie as a system for
theirown convenience, it was small enough tounderstand.Most ofthe algo-
rithmswereselectedforsimplicity,notforspeedorsophistication.Theintent
wastohavethekernelandlibrariesprovideasmallsetoffacilitiesthatwassuf-
ficientlypowerfultoallowapersontobuildamorecomplexsystemifneeded.
UNIX’scleandesignhasresultedinmanyimitationsandmodifications.
Although the designers of UNIX had a significant amount of knowledge
aboutotheroperatingsystems,UNIXhadnoelaboratedesignspelledoutbefore
itsimplementation.Thisflexibilityappearstohavebeenoneofthekeyfactors
in the development of the system. Some design principles were involved,
however,eventhoughtheywerenotmadeexplicitattheoutset.
The UNIX system was designedby programmersfor programmers.Thus,
it has always been interactive, and facilities for program development have
always been a high priority.Such facilities include the programmake (which
canbeusedtocheckwhichofacollectionofsourcefilesforaprogramneedto
becompiledandthentodothecompiling)andtheSourceCodeControlSystem
(SCCS) (which is used to keep successive versions of files available without
having to store the entire contents of each step). The primary version-control
systemusedbyUNIXistheConcurrentVersionsSystem(CVS)duetothelarge
numberofdevelopersoperatingonandusingthecode.
The operating system is written mostly in C, which was developed to
support UNIX, since neither Thompson nor Ritchie enjoyed programming in
assembly language. The avoidance of assembly language was also necessary
becauseoftheuncertaintyaboutthemachinesonwhichUNIXwouldberun.It
hasgreatlysimplifiedtheproblemsofmovingUNIXfromonehardwaresystem
toanother.
From the beginning, UNIX development systems have had all the UNIX
sources available online, and the developers have used the systems under
development as their primary systems. This pattern of development has
greatly facilitated the discovery of deficiencies and their fixes, as well as
of new possibilities and their implementations. It has also encouraged the
plethoraofUNIXvariantsexistingtoday,butthebenefitshaveoutweighedthe
disadvantages. If something is broken, it can be fixed at a local site; there is
no need to wait for the next release of the system. Such fixes, as well as new
facilities,maybeincorporatedintolaterdistributions.
The size constraints of the PDP-11 (and earlier computers used for UNIX)
haveforcedacertainelegance.Whereothersystemshaveelaboratealgorithms
for dealing with pathological conditions, UNIX just does a controlled crash
calledpanic.Insteadofattemptingtocure suchconditions, UNIX triestopre-
vent them. Where other systems would use brute force or macro-expansion,
UNIXmostlyhashadtodevelopmoresubtle,oratleastsimpler,approaches.
These early strengths of UNIX produced much of its popularity, which in
turnproducednewdemandsthatchallengedthosestrengths.UNIXwasused
for tasks such as networking, graphics, and real-time operation, which did
not always fitintoitsoriginal text-orientedmodel.Thus, changes weremade
to certain internal facilities, and new programming interfaces were added.
Supporting these new facilities and others—particularly window interfaces8 AppendixC BSDUNIX
—requiredlargeamountsofcode,radicallyincreasingthesizeofthesystem.
Forinstance,bothnetworkingandwindowingdoubledthesizeofthesystem.
ThispatterninturnpointedoutthecontinuedstrengthofUNIX—whenevera
new development occurred in the industry, UNIX could usually absorb it but
remainUNIX.
C.3 Programmer Interface
Likemostoperatingsystems,UNIXconsistsoftwoseparableparts:thekernel
and the systems programs. We can view the UNIX operating system as being
layered,asshowninFigureC.2.Everythingbelowthesystem-callinterfaceand
abovethephysicalhardwareisthekernel.Thekernelprovidesthefilesystem,
CPUscheduling,memorymanagement,andotheroperating-systemfunctions
throughsystemcalls.Systemsprogramsusethekernel-supportedsystemcalls
toprovideusefulfunctions,suchascompilationandfilemanipulation.
System calls define the programmer interface to UNIX. The set of systems
programscommonlyavailabledefinestheuserinterface.Theprogrammerand
userinterfacedefinethecontextthatthekernelmustsupport.
Most systems programs are written in C, and the UNIX Programmer’s
ManualpresentsallsystemcallsasCfunctions.AsystemprogramwritteninC
forFreeBSDonthePentiumcangenerallybemovedtoanAlphaFreeBSDsystem
andsimplyrecompiled,eventhoughthetwosystemsarequitedifferent.The
detailsofsystemcallsareknownonlytothecompiler.Thisfeatureisamajor
reasonfortheportabilityofUNIXprograms.
System calls for UNIX can be roughly grouped into three categories: file
manipulation, process control, and information manipulation. In Chapter 2,
welistedafourthcategory,devicemanipulation,butsincedevicesinUNIXare
treatedas (special) files, the same system calls support both files and devices
(althoughthereisanextrasystemcallforsettingdeviceparameters).
(the users)
shells and commands
compilers and interpreters
system libraries
system-call interface to the kernel
signals terminal file system CPU scheduling
handling swapping block I/O page replacement
character I/O system system demand paging
terminal drivers disk and tape drivers virtual memory
kernel interface to the hardware
terminal controllers device controllers memory controllers
terminals disks and tapes physical memory
FigureC.2 4.4BSDlayerstructure.C.3 ProgrammerInterface 9
C.3.1 File Manipulation
AfileinUNIXisasequenceofbytes.Differentprogramsexpectvariouslevels
of structure,but the kernel does not impose a structureon files.For instance,
the convention for text files is lines of ASCII characters separated by a single
newline character (which is the linefeed character in ASCII), but the kernel
knowsnothingofthisconvention.
Files are organized in tree-structured directories. Directories are them-
selves files that contain information on how to find other files. Apath name
to a file is a text string that identifies a file by specifying a path through the
directorystructureto the file. Syntactically,it consists of individualfile-name
elements separated by the slash character. For example, in /usr/local/font, the
firstslashindicatestherootofthedirectorytree,calledtherootdirectory.The
nextelement,usr,isasubdirectoryoftheroot,localisasubdirectoryofusr,and
fontisafileordirectoryinthedirectorylocal.Whetherfontisanordinaryfile
oradirectorycannotbedeterminedfromthepath-namesyntax.
The UNIX file system has both absolute path names and relative path
names. Absolute path names start at the root of the file system and are dis-
tinguished by a slash at the beginning of the path name; /usr/local/font is an
absolutepathname.Relativepathnamesstartatthecurrentdirectory,which
isanattributeoftheprocessaccessingthepathname.Thus,local/fontindicatesa
fileordirectorynamedfontinthedirectorylocalinthecurrentdirectory,which
mightormightnotbe/usr.
Afile may be known by more than one name in one or more directories.
Such multiple names are known as links, and all links are treated equally by
the operating system. FreeBSD also supports symbolic links, which are files
containingthepathnameofanotherfile.Thetwokindsoflinksarealsoknown
ashardlinksandsoftlinks.Soft(symbolic)links,unlikehardlinks,maypoint
todirectoriesandmaycrossfile-systemboundaries.
Thefilename“.”inadirectoryisahardlinktothedirectoryitself.Thefile
name“..”isahardlinktotheparentdirectory.Thus,ifthecurrentdirectoryis
/user/jlp/programs,then../bin/wdf refersto/user/jlp/bin/wdf.
Hardware devices have names in the file system. These device special
filesor special filesareknown tothe kernelas deviceinterfaces,but they are
nonetheless accessed by the user by much the same system calls as are other
files.
FigureC.3showsatypicalUNIXfilesystem.Theroot(/)normallycontains
a small number of directories as well as /kernel, the binary boot image of the
operating system; /dev contains the device special files, such as /dev/console,
/dev/lp0, /dev/mt0, and so on; and /bin contains the binaries of the essential
UNIX systems programs. Other binaries may be in /usr/bin (for applications
systems programs, such as text formatters), /usr/compat (for programs from
otheroperatingsystems,suchasLinux),or/usr/local/bin(forsystemsprograms
written at the local site). Library files—such as the C, Pascal, and FORTRAN
subroutinelibraries—arekeptin/lib(or/usr/libor/usr/local/lib).
The files of users themselves are stored in a separate directory for each
user, typically in /usr. Thus, the user directory for carol would normally be in
/usr/carol.Foralargesystem,thesedirectoriesmaybefurthergroupedtoease
administration, creating a file structure with /usr/prof/avi and /usr/staff/carol.
Administrativefilesandprograms,suchasthepasswordfile,arekeptin/etc.10 AppendixC BSDUNIX
vmunix
console spell
dev lp0 bin troff
(cid:129) (cid:129) (cid:129) (cid:129) (cid:129) (cid:129)
sh telnet
bin csh ucb man
(cid:129) (cid:129) (cid:129) (cid:129) (cid:129) (cid:129)
bin
libc.a
lib local lib
(cid:129) (cid:129) (cid:129)
(cid:129) (cid:129) (cid:129)
/ usr include
jlp
tmac
user avi lib
troff
(cid:129) (cid:129) (cid:129)
(cid:129) (cid:129) (cid:129)
passwd
group
tmp
etc
init
(cid:129) (cid:129) (cid:129)
(cid:129) (cid:129) (cid:129)
tmp
FigureC.3 TypicalUNIXdirectorystructure.
Temporary files can be put in /tmp, which is normally erased during system
boot,orin/usr/tmp.
Eachofthesedirectoriesmayhaveconsiderablymorestructure.Forexam-
ple,thefont-descriptiontablesforthetroffformatterfortheMerganthaler202C.3 ProgrammerInterface 11
typesetter are kept in /usr/lib/troff/dev202. All the conventions concerning the
location of specific files and directories have been defined by programmers
andtheirprograms.Theoperating-systemkernelneedsonly/etc/init,whichis
usedtoinitializeterminalprocesses,tobeoperable.
System calls for basic file manipulation are creat(), open(), read(),
write(), close(), unlink(), and trunc(). The creat() system call, given
a path name, creates an empty file (or truncates an existing one). An existing
fileisopenedbytheopen()systemcall,whichtakesapathnameandamode
(such as read, write, or read–write) and returns a small integer, called a file
descriptor. The file descriptor may then be passed to a read() or write()
systemcall(alongwithabufferaddressandthenumberofbytestotransfer)to
performdatatransferstoorfromthefile.Afileisclosedwhenitsfiledescriptor
ispassedtotheclose()systemcall.Thetrunc()callreducesthelengthofa
fileto0.
Afiledescriptorisanindexintoasmalltableofopenfilesforthisprocess.
Descriptorsstartat 0and seldomgethigherthan 6or 7for typicalprograms,
dependingonthemaximumnumberofsimultaneouslyopenfiles.
Each read() or write() updates the current offset into the file, which is
associated with the file-table entry and is used to determine the position in
the file for the next read() or write(). The lseek() system call allows the
positiontoberesetexplicitly.Italsoallowsthecreationofsparsefiles(fileswith
“holes”inthem).Thedup()and dup2()systemcallscan beusedtoproduce
a new file descriptor that is a copy of an existing one. The fcntl() system
callcanalsodothatandinadditioncanexamineorsetvariousparametersof
an open file. For example, it can make each succeeding write() to an open
fileappendtotheendofthatfile.Thereisanadditionalsystemcall,ioctl(),
formanipulatingdeviceparameters.Itcansetthebaudrateofaserialportor
rewindatape,forinstance.
Information about the file (such as its size, protection modes, owner, and
so on) can be obtained by the stat() system call. Several system calls allow
someofthisinformationtobechanged:rename()(changefilename),chmod()
(change the protection mode), and chown() (change the owner and group).
Manyofthesesystemcallshavevariantsthatapplytofiledescriptorsinstead
of file names. The link() system call makes a hard link for an existing file,
creatinganewnameforanexistingfile.Alinkisremovedbytheunlink(())
systemcall; ifitis the last link, the file is deleted.Thesymlink()systemcall
makesasymboliclink.
Directories are made by the mkdir() system call and are deleted by
rmdir().Thecurrentdirectoryischangedbycd().
Althoughthestandardfilecalls(open()andothers)canbeusedondirecto-
ries,itisinadvisabletodoso,sincedirectorieshaveaninternalstructurethat
must be preserved. Instead, another set of system calls is provided to open
a directory, to step through each file entry within the directory, to close the
directory, and to perform other functions; these are opendir(), readdir(),
closedir(),andothers.
C.3.2 Process Control
Aprocess is a program in execution. Processes are identified by their process
identifier,whichisaninteger.Anewprocessiscreatedbythefork()system12 AppendixC BSDUNIX
call. The new process consists of a copy of the address space of the original
process(thesameprogramandthesamevariableswiththesamevalues).Both
processes(theparentandthechild)continueexecutionattheinstructionafter
thefork()withonedifference:thereturncodeforthefork()iszeroforthe
new (child) process, whereas the (nonzero) process identifier of the child is
returnedtotheparent.
Typically, the execve() system call is used after a fork by one of the two
processestoreplacethatprocess’svirtualmemoryspacewithanewprogram.
The execve() system call loads a binary file into memory (destroying the
memoryimageoftheprogramcontainingtheexecve()systemcall)andstarts
itsexecution.
Aprocess may terminate by using the exit() system call, and its parent
process may wait for that event by using the wait() system call. If the child
processcrashes,thesystemsimulatestheexit()call.Thewait()systemcall
providestheprocessIDofaterminatedchildsothattheparentcantellwhichof
possiblymanychildrenterminated.Asecondsystemcall,wait3(),issimilar
towait()butalsoallowstheparenttocollectperformancestatisticsaboutthe
child.Betweenthetimethechildexitsandthetimetheparentcompletesoneof
thewait()systemcalls,thechildisdefunct.Adefunctprocesscandonothing
but exists merely so that the parent can collect its status information. If the
parentprocessofadefunctprocessexitsbeforeachild,thedefunctprocessis
inheritedbytheinitprocess(whichinturnwaitsonit)andbecomesazombie
process.AtypicaluseofthesefacilitiesisshowninFigureC.4.
Thesimplestformofcommunicationbetweenprocessesisbypipes.Apipe
may be createdbeforethe fork(),and its endpointsarethen setup between
thefork()andtheexecve().Apipeisessentiallyaqueueofbytesbetween
two processes. The pipe is accessed by a file descriptor, like an ordinary file.
One process writes into the pipe, and the other reads from the pipe. The size
of the original pipe system was fixed by the system. With FreeBSD pipes are
implemented on top of the socket system, which has variable-sized buffers.
Readingfromanemptypipeorwritingintoafullpipecausestheprocesstobe
blocked until the state of the pipe changes. Special arrangements are needed
forapipetobeplacedbetweenaparentandchild(soonlyoneisreadingand
oneiswriting).
All user processes are descendants of one original process, called init
(whichhasprocessidentifier1).Eachterminalportavailableforinteractiveuse
hasagettyprocessforkedforitbyinit.Thegettyprocessinitializestermi-
nallineparametersandwaitsforauser’sloginname,whichitpassesthrough
shell process parent process shell process
fork wait
zombie process
child process
execve program executes
exit
program
FigureC.4 Ashellforksasubprocesstoexecuteaprogram.C.3 ProgrammerInterface 13
an execve() as an argument to a login process. The login process collects
the user’s password, encrypts it, and compares the result to an encrypted
stringtakenfromthefile/etc/passwd.Ifthecomparisonissuccessful,theuseris
allowedtologin.Theloginprocessexecutesashell,orcommandinterpreter,
aftersettingthenumericuseridentifieroftheprocesstothatoftheuserlogging
in.(Theshellandtheuseridentifierarefoundin/etc/passwdbytheuser’slogin
name.) It is with this shell that the user ordinarily communicates for the rest
of the login session. The shell itselfforks subprocesses for the commands the
usertellsittoexecute.
Theuseridentifierisusedbythekerneltodeterminetheuser’spermissions
for certain system calls, especially those involving file accesses. There is also
a group identifier, which is used to provide similar privileges to a collection
of users. In FreeBSD a process may be in several groups simultaneously. The
loginprocessputstheshellinallthegroupspermittedtotheuserbythefiles
/etc/passwdand/etc/group.
Twouseridentifiersareusedbythekernel:theeffectiveuseridentifierand
the real user identifier. The effective user identifier is used to determine file
access permissions.Ifthefile ofaprogram being loadedby an execve()has
thesetuidbitsetinitsinode,theeffectiveuseridentifieroftheprocessisset
to the user identifier of the owner of the file, whereas the real user identifier
is left as it was. This scheme allows certain processes to have more than
ordinaryprivilegeswhile stillbeing executableby ordinaryusers. The setuid
ideawas patented by Dennis Ritchie (U.S. Patent 4,135,240) and is one of the
distinctivefeaturesofUNIX.Asimilarsetgidbitexistsforgroups.Aprocess
may determine its real and effective user identifier with the getuid() and
geteuid() calls, respectively. The getgid() and getegid() calls determine
the process’s real and effective group identifier, respectively. The rest of a
process’sgroupsmaybefoundwiththegetgroups()systemcall.
C.3.3 Signals
Signals are a facility for handling exceptional conditions similar to software
interrupts. There are 20 different signals, each corresponding to a distinct
condition. Asignal may be generatedby a keyboard interrupt,by an error in
aprocess(suchasabadmemoryreference),orbyanumberofasynchronous
events(suchastimersorjob-controlsignalsfromtheshell).Almostanysignal
mayalsobegeneratedbythekill()systemcall.
Theinterruptsignal,SIGINT,isusedtostopacommandbeforethatcom-
mand completes. It is usually produced by the ˆC character (ASCII 3). As of
4.2BSD,theimportantkeyboardcharactersaredefinedbyatableforeachtermi-
nalandcanberedefinedeasily.Thequitsignal,SIGQUIT,isusuallyproduced
bytheˆbscharacter(ASCII28).Thequitsignalbothstopsthecurrentlyexecut-
ingprogramanddumpsitscurrentmemoryimagetoafilenamedcoreinthe
currentdirectory.Thecorefilecanbeusedbydebuggers.SIGILLisproducedby
anillegalinstructionandSIGSEGVbyanattempttoaddressmemoryoutsideof
thelegalvirtualmemoryspaceofaprocess.
Arrangementscan bemadeeitherformost signalstobeignored(tohave
noeffect)orforaroutineintheuserprocess(asignalhandler)tobecalled.A
signalhandlermaysafelydooneoftwothingsbeforereturningfromcatching
a signal: call the exit() system call or modify a global variable. One signal14 AppendixC BSDUNIX
(the kill signal, number 9, SIGKILL) cannot be ignored or caught by a signal
handler.SIGKILLisused,forexample,tokillarunawayprocessthatisignoring
othersignalssuchasSIGINTandSIGQUIT.
Signals can be lost. If another signal of the same kind is sent before a
previous signal has been accepted by the process to which it is directed, the
first signal will be overwritten, and only the last signal will be seen by the
process. In other words, a call to the signal handler tells a process that there
hasbeenatleastoneoccurrenceofthesignal.Also,thereisnorelativepriority
amongUNIXsignals.Iftwodifferentsignalsaresenttothesameprocessatthe
sametime,wecannotknowwhichonetheprocesswillreceivefirst.
Signals were originally intended to deal with exceptional events. As is
trueofmostUNIXfeatures,however,signalusehassteadilyexpanded.4.1BSD
introduced job control, which uses signals to start and stop subprocesses on
demand.Thisfacilityallowsoneshelltocontrolmultipleprocesses—starting,
stopping,andbackgrounding themastheuserwishes.TheSIGWINCHsignal,
inventedbySunMicrosystems,isusedforinformingaprocessthatthewindow
inwhich outputisbeing displayedhas changed size.Signalsarealsousedto
deliverurgentdatafromnetworkconnections.
Userswantedmorereliablesignalsandabugfixinaninherentracecondi-
tionintheoldsignalimplementation.Thus,4.2BSDbroughtwithitarace-free,
reliable,separatelyimplementedsignalcapability.Itallowsindividualsignals
tobeblockedduringcriticalsections,andithasanewsystemcalltoletapro-
cess sleep until interrupted. It is similar to hardware-interrupt functionality.
ThiscapabilityisnowpartofthePOSIXstandard.
C.3.4 Process Groups
Groups of related processes frequently cooperate to accomplish a common
task. For instance, processes may create, and communicate over, pipes. Such
a set of processes is termed a process group, or a job. Signals may be sent to
all processes in a group. Aprocess usually inherits its process group from its
parent,butthesetpgrp()systemcallallowsaprocesstochangeitsgroup.
Process groups are used by the C shell to control the operation of mul-
tiple jobs. Only one process group may use a terminal device for I/O at any
time.Thisforegroundjobhas theattentionoftheuseronthat terminal,while
all other nonattached jobs (background jobs) perform their functions without
userinteraction.Accesstotheterminaliscontrolledbyprocessgroupsignals.
Each job has a controlling terminal (again, inherited from its parent). If the
processgroupofthecontrollingterminalmatchesthegroupofaprocess,that
process is in the foreground and is allowed to performI/O. Ifa nonmatching
(background)processattemptsthesame,aSIGTTINorSIGTTOUsignalissentto
itsprocessgroup.Thissignalusuallycausestheprocessgrouptofreezeuntil
it is foregrounded by the user, at which point it receives a SIGCONT signal,
indicating that the process can perform the I/O. Similarly, a SIGSTOP may be
senttotheforegroundprocessgrouptofreezeit.
C.3.5 Information Manipulation
System calls exist to set and return both an interval timer (getitimer()/
setitimer()) and the current time (gettimeofday()/settimeofday()) inC.4 UserInterface 15
microseconds.Inaddition,processescanaskfortheirprocessidentifier(get-
pid()),theirgroupidentifier(getgid()),thename ofthemachine onwhich
theyareexecuting(gethostname()),andmanyothervalues.
C.3.6 Library Routines
The system-call interface to UNIX is supported and augmented by a large
collection of library routines and header files. The header files provide the
definitionofcomplexdatastructuresusedinsystemcalls.Inaddition,alarge
libraryoffunctionsprovidesadditionalprogramsupport.
Forexample,theUNIXI/Osystemcallsprovideforthereadingandwriting
ofblocksofbytes.Someapplicationsmaywanttoreadandwriteonly1byte
atatime.Althoughpossible,thatwouldrequireasystemcallforeachbyte—a
veryhighoverhead.Instead,asetofstandardlibraryroutines(thestandardI/O
packageaccessedthroughtheheaderfile<stdio.h>)providesanotherinterface,
which reads and writes several thousand bytes at a time using local buffers
and transfers between these buffers (in user memory) when I/O is desired.
FormattedI/OisalsosupportedbythestandardI/Opackage.
Additional library support is provided for mathematical functions, net-
work access, data conversion, and so on. The FreeBSD kernel supports over
300 system calls; the C program library has over 300 library functions. The
libraryfunctionseventuallyresultinsystemcallswherenecessary(forexam-
ple,thegetchar()libraryroutinewillresultinaread()systemcallifthefile
bufferisempty).However,theprogrammergenerallydoesnotneedtodistin-
guishbetweenthebasicsetofkernelsystemcallsandtheadditionalfunctions
providedbylibraryfunctions.
C.4 User Interface
BoththeprogrammerandtheuserofaUNIXsystemdealmainlywiththeset
of systems programs that have been written and are available for execution.
Theseprogramsmakethenecessarysystemcallstosupporttheirfunction,but
thesystemcallsthemselvesarecontainedwithintheprogramanddonotneed
tobeobvioustotheuser.
The common systems programs can be grouped into several categories;
mostofthemarefileordirectoryoriented.Forexample,thesystemsprograms
tomanipulatedirectoriesaremkdirtocreateanewdirectory,rmdirtoremove
adirectory,cdtochangethecurrentdirectorytoanother,andpwdtoprintthe
absolutepathnameofthecurrent(working)directory.
Thelsprogramliststhenamesofthefilesinthecurrentdirectory.Anyof
28options can ask that propertiesofthe files be displayedalso. For example,
the-loptionasksforalonglistingshowingthefilename,owner,protection,
dateandtimeofcreation,andsize.Thecpprogramcreatesanewfilethatisa
copyofanexistingfile.Themvprogrammovesafilefromoneplacetoanother
in the directory tree. In most cases, this move simply requires a renaming of
thefile.Ifnecessary,however,thefileiscopiedtothenewlocation,andtheold
copyisdeleted.Afileisdeletedbythermprogram(whichmakesanunlink()
systemcall).16 AppendixC BSDUNIX
Todisplayafileontheterminal,ausercanruncat.Thecatprogramtakes
alistoffilesandconcatenatesthem,copyingtheresulttothestandardoutput,
commonly the terminal. On a high-speed cathode-ray tube (CRT) display, of
course, the file may speed by too fast to be read. The more program displays
thefileonescreenatatime,pausinguntiltheusertypesacharactertocontinue
tothenextscreen.Theheadprogramdisplaysjustthefirstfewlinesofafile;
tailshowsthelastfewlines.
These are the basic systems programs widely used in UNIX. In addition,
there are a number of editors (ed, sed, emacs, vi, and so on), compilers (C,
python, FORTRAN, and so on), and text formatters (troff, TEX, scribe, and so
on).Therearealsoprogramsforsorting(sort)andcomparingfiles(cmp,diff),
lookingforpatterns(grep,awk),sendingmailtootherusers(mail),andmany
otheractivities.
C.4.1 Shells and Commands
Bothuser-writtenandsystemsprogramsarenormallyexecutedbyacommand
interpreter.ThecommandinterpreterinUNIXisauserprocesslikeanyother.
As noted earlier, it is called a shell—because it surrounds the kernel of the
operatingsystem.Userscanwritetheirownshells,and,infact,severalshells
areingeneraluse.TheBourneshell,writtenbySteveBourne,isprobablythe
mostwidelyused—or,atleast,themostwidelyavailable.TheCshell,mostly
the work of Bill Joy, a founder of Sun Microsystems, is the most popular on
BSD systems. The Korn shell, by Dave Korn, has become popular because it
combinesthefeaturesoftheBourneshellandtheCshell.
Thecommonshellssharemuchoftheircommand-languagesyntax.UNIX
is normally an interactive system. The shell indicates its readiness to accept
another command by typing a prompt, and the user types a command on a
singleline.Forinstance,intheline
%ls-l
thepercentsignistheusualCshellprompt,andthels -l(typedbytheuser)
is the (long) list-directory command. Commands can take arguments, which
theusertypesafterthecommandname onthesameline,separatedby white
space(spacesortabs).
Although afewcommands are built intothe shells (such ascd), atypical
command is an executable binary object file. Alist of several directories, the
search path, is kept by the shell. For each command, each of the directories
in the search pathis searched,in order, for a file of the same name. If a file is
found, it is loaded and executed. The search path can be set by the user. The
directories/binand/usr/binarealmostalwaysinthesearchpath,andatypical
searchpathonaFreeBSDsystemmightbe
(./usr/avi/bin /usr/local/bin/bin/usr/bin)
Thelscommand’sobjectfileis/bin/ls,andtheshellitselfis/bin/sh(theBourne
shell)or/bin/csh(theCshell).
Executionof a command is done by a fork() system call followed by an
execve() of the object file. The shell usually then does a wait() to suspendC.4 UserInterface 17
itsownexecutionuntilthecommandcompletes(FigureC.4).Thereisasimple
syntax (an ampersand [&] at the end of the command line) to indicate that
theshellshouldnotwaitforthecompletionofthecommand.Acommandleft
runninginthismannerwhiletheshellcontinuestointerpretfurthercommands
is said to be a background command, or to be running in the background.
Processesforwhichtheshelldoeswaitaresaidtorunintheforeground.
The C shellin FreeBSD systemsprovidesa facility calledjob control(par-
tiallyimplementedinthekernel),asmentionedpreviously.Jobcontrolallows
processestobemovedbetweentheforegroundandthebackground.Thepro-
cesses can be stopped and restarted on various conditions, such as a back-
groundjobwanting input from theuser’s terminal.This schemeallows most
ofthe control of processesprovidedby windowing or layering interfaces but
requires no special hardware. Job control is also useful in window systems,
such as the X Window System developed at MIT. Each window is treated as
aterminal,allowingmultipleprocessestobeintheforeground(oneperwin-
dow) at any one time. Of course, background processes may exist on any of
the windows. The Korn shell also supports job control, and job control (and
processgroups)willlikelybestandardinfutureversionsofUNIX.
C.4.2 Standard I/O
Processes can open files as they like, but most processes expect three file
descriptors(numbers0,1,and2)tobeopenwhentheystart.Thesefiledescrip-
torsareinheritedacrossthefork()(andpossiblytheexecve())thatcreated
the process. They are known as standard input (0), standard output (1), and
standard error (2). All three are frequently open to the user’s terminal. Thus,
theprogramcanreadwhattheusertypesbyreadingstandardinput,andthe
program can send output to the user’s screen by writing to standard output.
Thestandard-errorfiledescriptorisalsoopenforwritingandisusedforerror
output;standardoutputisusedforordinaryoutput.Mostprogramscanalso
accept a file (rather than a terminal) for standard input and standard output.
Theprogramdoesnotcarewhereitsinputiscomingfromandwhereitsoutput
isgoing.ThisisoneoftheelegantdesignfeaturesofUNIX.
Thecommonshellshaveasimplesyntaxforchangingwhatfilesareopen
for the standard I/O streams of a process. Changing a standard file is called
I/O redirection. The syntax for I/O redirection is shown in Figure C.5. In this
command meaning of command
% ls > filea direct output of ls to file filea
% pr < filea > fileb input from filea and output to fileb
% lpr < fileb input from fileb
% % make program > & errs save both standard output and
standard error in a file
FigureC.5 Standard/io/redirection.18 AppendixC BSDUNIX
example,thelscommandproducesalistingofthenamesoffilesinthecurrent
directory,theprcommandformatsthatlistintopagessuitableforaprinter,and
thelprcommandspoolstheformattedoutputtoaprinter,suchas/dev/lp0.The
subsequentcommandforcesalloutputandallerrormessagestoberedirected
toafile.Withouttheampersand,errormessagesappearontheterminal.
C.4.3 Pipelines, Filters, and Shell Scripts
ThefirstthreecommandsofFigureC.5couldhavebeencoalescedintotheone
command
%ls|pr|lpr
Each vertical bar tells the shell to arrange for the output of the preceding
commandtobepassedasinputtothefollowingcommand.Apipeisusedto
carry thedatafromoneprocesstotheother.Oneprocesswritesintooneend
ofthepipe,andanotherprocessreadsfromtheotherend.Intheexample,the
write end of one pipe would be set up by the shell to be the standard output
ofls,andthereadendofthepipewouldbethestandardinputofpr.Another
pipewouldbebetweenprandlpr.
Acommandsuchasprthatpassesitsstandardinputtoitsstandardoutput,
performingsomeprocessingonit,iscalledafilter.ManyUNIXcommandscan
beusedasfilters.Complicatedfunctionscanbepiecedtogetheraspipelinesof
common commands. Also,common functions, such as output formatting, do
not need to be built into numerous commands, because the output of almost
anyprogramcanbepipedthroughpr(orsomeotherappropriatefilter).
Both of the common UNIX shells are also programming languages, with
shellvariablesandtheusualhigher-levelprogramming-languagecontrolcon-
structs (loops, conditionals). The execution of a command is analogous to a
subroutine call. Afile of shell commands, a shell script, can be executed like
any other command, with the appropriate shell being invoked automatically
toreadit.Shellprogrammingthuscanbeusedtocombineordinaryprograms
convenientlyforsophisticatedapplicationswithouttheneedforanyprogram-
minginconventionallanguages.
ThisexternaluserviewiscommonlythoughtofasthedefinitionofUNIX,
yet it is the most easily changed definition. Writing a new shell with a quite
differentsyntaxandsemanticswouldgreatlychangetheuserviewwhilenot
changing the kernel or even the programmer interface. Several menu-driven
and iconic interfaces for UNIX exist, and the X Window System is rapidly
becomingastandard.TheheartofUNIXis,ofcourse,thekernel.Thiskernelis
muchmoredifficulttochangethanistheuserinterface,becauseallprograms
depend on the system calls that it provides to remain consistent. Of course,
new system calls can be added to increase functionality, but programs must
thenbemodifiedtousethenewcalls.
C.5 Process Management
A major design problem for operating systems is the representation of pro-
cesses. One substantial difference between UNIX and many other systems is
theeasewithwhichmultipleprocessescanbecreatedandmanipulated.TheseC.5 ProcessManagement 19
processes are represented in UNIX by various control blocks. No system con-
trolblocksareaccessibleinthevirtualaddressspaceofauserprocess;control
blocks associated with a process are stored in the kernel. The kernel uses the
informationinthesecontrolblocksforprocesscontrolandCPUscheduling.
C.5.1 Process Control Blocks
Themostbasicdatastructureassociatedwithprocessesistheprocessstructure.
Aprocessstructurecontainseverythingthatthesystemneedstoknowabouta
processwhentheprocessisswappedout,suchasitsuniqueprocessidentifier,
schedulinginformation(forexample,thepriorityoftheprocess),andpointers
toothercontrolblocks.Thereisanarrayofprocessstructureswhoselengthis
defined at system-linking time. The process structures of ready processes are
keptlinkedtogetherbytheschedulerinadoublylinkedlist(thereadyqueue),
and there are pointers from each process structure to the process’s parent, to
itsyoungestlivingchild,andtovariousotherrelativesofinterest,suchasalist
ofprocessessharingthesameprogramcode(text).
The virtual address space of a user process is divided into text (program
code), data, and stack segments. The data and stack segments are always in
thesameaddressspace,buttheymaygrowseparately,andusuallyinopposite
directions.Mostfrequently,thestackgrowsdownasthedatagrowuptoward
it.Thetextsegmentissometimes(asonanIntel8086withseparateinstruction
and data space) in an address space different from the data and stack, and it
isusuallyread-only.Thedebuggerputsatextsegmentinread–writemodeto
allowinsertionofbreakpoints.
Everyprocesswithsharabletext(almostall,underFreeBSD)hasapointer
from its process structure to a text structure. The text structure records how
many processes are using the text segment, including a pointer into a list of
theirprocessstructures,andwherethepagetableforthetextsegmentcanbe
foundondiskwhenitisswapped.Thetextstructureitselfisalways resident
inmainmemory.Anarrayofsuchstructuresisallocatedatsystemlink time.
The text, data, and stack segments for the processes may be swapped. When
thesegmentsareswappedin,theyarepaged.
The page tables record information on the mapping from the process’s
virtual memory to physical memory. The process structure contains pointers
to the page table, for use when the process is resident in main memory, or
the addressof the processon the swap device,when the process isswapped.
Thereisnospecialseparatepagetableforasharedtextsegment;everyprocess
sharingthetextsegmenthasentriesforitspagesintheprocess’spagetable.
Information about the process needed only when the process is resident
(that is, not swapped out) is kept in the user structure (or u structure), rather
than in the process structure. This structure is mapped read-only into user
virtual address space, so user processes can read its contents. It is writable
bythekernel.Theuserstructurecontainsacopyoftheprocesscontrolblock,
or PCB, which is kept here for saving the process’s general registers, stack
pointer, program counter, and page-table base registers when the process is
notrunning.Thereisspacetokeepsystem-callparametersandreturnvalues.
Alluserandgroupidentifiersassociatedwiththeprocess(notjusttheeffective
useridentifierkeptintheprocessstructure)arekepthere.Signals,timers,and
quotas have data structures here. Of more obvious relevance to the ordinary20 AppendixC BSDUNIX
user, the current directory and the table of open files are maintained in the
userstructure.
Everyprocesshasbothauserandasystemmode.Mostordinaryworkis
doneinusermode,butwhenasystemcallismade,itisperformedinsystem
mode.Thesystemanduserphasesofaprocessneverexecutesimultaneously.
When a process is executing in system mode, a kernel stack for that process
isused,ratherthan theuser stackbelonging tothat process.The kernelstack
for the process immediately follows the user structure. The kernel stack and
theuserstructuretogethercomposethesystemdatasegment fortheprocess.
Thekernelhas itsown stackfor usewhenitisnot doingwork onbehalfofa
process(forinstance,forinterrupthandling).
FigureC.6illustrateshowtheprocessstructureisusedtofindthevarious
partsofaprocess.
The fork() system call allocates a new process structure (with a new
process identifier) for the child process and copies the user structure. There
is ordinarily no need for a new text structure, as the processes share their
text.Theappropriatecountersandlistsaremerelyupdated.Anewpagetable
is constructed, and new main memory is allocated for the data and stack
segmentsofthechildprocess.Thecopyingoftheuserstructurepreservesopen
file descriptors,user and group identifiers,signal handling, and most similar
propertiesofaprocess.
The vfork() system call does not copy the data and stack to the new
process; rather, the new process simply shares the page table of the old one.
Anewuserstructureandanewprocessstructurearestillcreated.Acommon
useofthissystemcalloccurswhenashellexecutesacommandandwaitsfor
itscompletion.Theparentprocessusesvfork()toproducethechildprocess.
Becausethechildprocesswishestouseanexecve()immediatelytochangeits
virtual address space completely, there is no need for a complete copy of the
process user kernel
structure structure stack
system data structure
stack
data
text
text
structure
user space
resident tables
swappable process image
FigureC.6 Findingpartsofaprocessusingtheprocessstructure.C.5 ProcessManagement 21
parent process. Such data structures as are necessary for manipulating pipes
may be kept in registers between the vfork() and the execve(). Files may
be closed in one process without affecting the other process, since the kernel
datastructuresinvolveddependontheuserstructure,whichisnotshared.The
parentissuspendedwhenitcallsvfork()untilthechildeithercallsexecve()
orterminates,sothattheparentwillnotchangememorythatthechildneeds.
Whentheparentprocessislarge,vfork()canproducesubstantialsavings
in system CPU time. However, it is a fairly dangerous system call, since any
memorychangeoccursinbothprocessesuntiltheexecve()occurs.Analter-
nativeistoshareallpagesbyduplicatingthepagetablebuttomarktheentries
of both page tables as copy-on-write. The hardware protection bits are set to
trap any attempt to write in these shared pages. If such a trap occurs, a new
frame is allocated,and the shared page is copied tothe new frame.The page
tablesareadjustedtoshowthatthispageisnolongershared(andthereforeno
longerneedstobewrite-protected),andexecutioncanresume.
Anexecve()systemcallcreatesnonewprocessoruserstructure.Rather,
thetextanddataoftheprocessarereplaced.Openfilesarepreserved(although
there is a way to specify that certain file descriptors are to be closed on an
execve()).Mostsignal-handling propertiesarepreserved,butarrangements
tocallaspecificuserroutineonasignalarecanceled,forobviousreasons.The
processidentifierandmostotherpropertiesoftheprocessareunchanged.
C.5.2 CPU Scheduling
CPUscheduling inUNIXisdesignedtobenefitinteractiveprocesses.Processes
aregivensmallCPUtimeslicesbyapriorityalgorithmthatreducestoround-
robinschedulingforCPU-boundjobs.
Everyprocesshasaschedulingpriorityassociatedwithit;largernumbers
indicatelowerpriority.ProcessesdoingdiskI/Oorotherimportanttaskshave
priorities less than “pzero” and cannot be killed by signals. Ordinary user
processeshavepositiveprioritiesandthusarelesslikelytoberunthanisany
systemprocess,although userprocessescansetprecedenceoverone another
throughthenicecommand.
The more CPU time a process accumulates, the lower (more positive) its
priority becomes, and vice versa. This negative feedback in CPU scheduling
makesitdifficultforasingleprocesstotakealltheCPUtime.Processagingis
employedtopreventstarvation.
OlderUNIXsystemsuseda1-secondquantumfortheround-robinschedul-
ing.FreeBSDreschedulesprocessesevery0.1secondandrecomputespriorities
every second. The round-robin scheduling is accomplished by the timeout
mechanism, which tells the clock interrupt driver to call a kernel subroutine
after a specified interval. The subroutine to be called in this case causes the
rescheduling and then resubmits a timeout to call itself again. The priority
recomputationisalsotimedbyasubroutinethatresubmitsatimeoutforitself.
Thereisnopreemptionofoneprocessbyanotherinthekernel.Aprocess
may relinquish the CPU because it is waiting for I/O or because its time slice
has expired. When a process chooses to relinquish the CPU, it goes to sleep
on an event. The kernel primitive used for this purpose is called sleep()
(not to be confused with the user-level library routine of the same name).
Sleep()takesanargumentthatis,byconvention,theaddressofakerneldata22 AppendixC BSDUNIX
structure related to an event for which a process is waiting. When the event
occurs,thesystemprocessthatknowsaboutitcallswakeup()withtheaddress
correspondingtotheevent,andallprocessesthathaddoneasleeponthesame
addressareputinthereadyqueuetoberun.
For example,a process waiting for disk I/O to complete will sleep on the
addressofthebufferheadercorrespondingtothedatabeingtransferred.When
the interrupt routine for the disk driver notes that the transfer is complete, it
calls wakeup() on the buffer header. The interrupt uses the kernel stack for
whatever process happened to be running at the time, and the wakeup() is
donefromthatsystemprocess.
The process that actually does run is chosen by the scheduler. Sleep()
takes a second argument, which is the scheduling priority to be used for this
purpose.Thispriorityargument,iflessthan“pzero,”alsopreventstheprocess
frombeingawakenedprematurelybysomeexceptionalevent,suchasasignal.
When a signal is generated, it is left pending until the system half of the
affected process next runs. This event usually happens soon, since the signal
normallycausestheprocesstobeawakenediftheprocesshasbeenwaitingfor
someothercondition.
No memory is associated with events. The caller of the routine that does
a sleep() on an event must be prepared to deal with a premature return,
includingthepossibilitythatthereasonforwaitinghasvanished.
Raceconditionsareinvolvedintheeventmechanism.Ifaprocessdecides
(becauseofcheckingaflaginmemory,forinstance)tosleeponanevent,and
the event occurs before the process can execute the primitive that does the
sleep()ontheevent,theprocesssleepingmaythensleepforever.Weprevent
this situation by raising the hardware processor priority during the critical
sectionsothatnointerruptscanoccur.Thus,onlytheprocessdesiringtheevent
canrununtilitissleeping.Hardwareprocessorpriorityisusedinthismanner
toprotectcriticalregionsthroughoutthekernelandisthegreatestobstacleto
portingUNIXtomultiple-processormachines.However,thisproblemhasnot
preventedsuchportingfrombeingdonerepeatedly.
Many processes, such as text editors, are I/O bound and are, in general,
scheduledmainlyonthebasisofwaitingforI/O.Experiencesuggeststhatthe
UNIX schedulerperformsbestwith I/O-bound jobs,as can be observedwhen
several CPU-bound jobs, such as text formatters or language interpreters, are
running.
WhathasbeenreferredtohereasCPUschedulingcorrespondscloselytothe
short-termschedulingofChapter3.However,thenegative-feedbackproperty
of the priority scheme provides some long-term scheduling in that it largely
determines the long-term job mix. Medium-term scheduling is done by the
swappingmechanismdescribedinSectionC.6.
C.6 Memory Management
MuchofUNIX’searlydevelopmentwasdoneonaPDP-11.ThePDP-11hasonly
eightsegmentsinitsvirtualaddressspace,andthesizeofeachisatmost8,192
bytes. The larger machines, such as the PDP-11/70, allow separate instruction
and address spaces, effectively doubling the address space and number of
segments,butthisaddressspaceisstillrelativelysmall.Inaddition,thekernelC.6 MemoryManagement 23
was even more severely constrained due to dedication of one data segment
tointerruptvectors,anothertopointattheper-processsystemdatasegment,
and yet another for the UNIBUS (system I/O bus) registers. Further, on the
smallerPDP-11s,totalphysicalmemorywaslimitedto256KB.Thetotalmemory
resourceswereinsufficienttojustifyorsupportcomplexmemory-management
algorithms.Thus,UNIXswappedentireprocessmemoryimages.
Berkeley introduced paging to UNIX with 3BSD. VAX 4.2BSD is a demand-
paged virtual memory system. Paging eliminates external fragmentation of
memory.(Internalfragmentationstilloccurs,butitisnegligiblewithareason-
ablysmallpagesize.)Becausepagingallowsexecutionwithonlypartsofeach
processinmemory,morejobscanbekeptinmainmemory,andswappingcan
be kept to a minimum. Demand paging is done in a straightforward manner.
Whenaprocessneedsapageandthepageisnotthere,apagefaulttothekernel
occurs,aframeofmainmemoryisallocated,andtheproperdiskpageisread
intotheframe.
Thereareafewoptimizations.Ifthepageneededisstillinthepagetable
fortheprocessbuthasbeenmarkedinvalidbythepage-replacementprocess,it
canbemarkedvalidandusedwithoutanyI/Otransfer.Pagescansimilarlybe
retrievedfromthe listoffreeframes.Whenmost processesarestarted,many
of their pages are prepaged and are put on the free list for recovery by this
mechanism.Arrangementscanalsobemadeforaprocesstohavenoprepaging
on startup. That is seldom done, however, because it results in more page-
faultoverhead,beingclosertopuredemandpaging.FreeBSDimplementspage
coloring with paging queues. The queues are arranged according to the size
of the processor’s L1and L2 caches. When a new page needs to be allocated,
FreeBSD tries to get one that is optimally aligned for the cache. If the page
has to be fetched from disk, it must be locked in memory for the duration of
the transfer. This locking ensures that the page will not be selected for page
replacement. Once the page is fetched and mapped properly, it must remain
lockedifrawphysicalI/Oisbeingdoneonit.
Thepage-replacementalgorithmismoreinteresting.4.2BSDusesamodifi-
cationofthesecond-chance(clock)algorithmdescribedinSection10.4.5.The
map of all nonkernel main memory (the core map or cmap) is swept linearly
andrepeatedlybyasoftwareclockhand.Whentheclockhandreachesagiven
frame,iftheframeismarkedasbeinginusebysomesoftwarecondition(for
example,ifphysicalI/Oisinprogressusing it)or iftheframeisalreadyfree,
the frame is left untouched, and the clock hand sweeps to the next frame.
Otherwise, the corresponding text or process page-table entry for this frame
is located. If the entry is already invalid, the frame is added to the free list.
Otherwise, the page-table entry is made invalid but reclaimable (that is, if it
hasnotbeenpagedoutbythenexttimeitiswanted,itcanjustbemadevalid
again).
BSD Tahoe added support for systems that implement the reference bit.
Onsuchsystems,onepassoftheclockhandturnsthereferencebitoff,anda
secondpassplacesthosepageswhosereferencebitsremainoffontothefreelist
forreplacement.Ofcourse,ifthepageisdirty,itmustfirst bewrittentodisk
before being added to the free list. Pageouts are done in clusters to improve
performance.
There are checks to make sure that the number of valid data pages for a
processdoesnotfalltoolowandtokeepthepagingdevicefrombeingflooded24 AppendixC BSDUNIX
with requests. There is also a mechanism by which a process can limit the
amountofmainmemoryituses.
The LRUclock-hand scheme is implementedin the pagedaemon,which is
process 2. (Remember that the swapper is process 0 and init is process 1.)
This process spends most of its time sleeping, but a check is done several
times per second (scheduled by a timeout) to see if action is necessary. If it
is, process 2 is awakened. Whenever the number of free frames falls below a
threshold,lotsfree,thepagedaemonisawakened.Thus,ifthereisalwaysa
largeamountoffreememory,thepagedaemonimposesnoloadonthesystem,
becauseitneverruns.
The sweep of the clock hand each time the pagedaemon process is awak-
ened (that is, the number of frames scanned, which is usually more than the
number paged out) is determined both by the number of frames lacking to
reach lotsfree and by the number of frames that the scheduler has deter-
minedareneededforvariousreasons(themoreframesneeded,thelongerthe
sweep). If the number of frames free rises to lotsfree before the expected
sweepiscompleted,thehand stops,andthepagedaemonprocesssleeps.The
parameters that control the range of the clock-hand sweep are determined at
systemstartupaccordingtotheamountofmainmemory,suchthatpagedae-
mondoesnotusemorethan10percentofallCPUtime.
If the scheduler decides that the paging system is overloaded, processes
will be swapped out whole until the overload is relieved. This swapping
usually happens only if several conditions are met:load average is high; free
memory has fallen below a low limit, minfree; and the average memory
available over recent time is less than a desirable amount, desfree, where
lotsfree > desfree > minfree. In other words, only a chronic shortage
of memory with several processes trying to run will cause swapping, and
eventhenfreememoryhastobeextremelylowatthemoment.(Anexcessive
paging rate or a need for memory by the kernel itselfmay also enter into the
calculations, in rare cases.) Processes may be swapped by the scheduler, of
course,forotherreasons(suchassimplybecausetheyhavenotrunforalong
time).
The parameter lotsfree is usually one-quarter of the memory in the
map that the clock hand sweeps, and desfree and minfree are usually the
same across different systems but are limited to fractions of available mem-
ory. FreeBSD dynamically adjusts its paging queues so these virtual memory
parameters will rarely need to be adjusted. Minfree pages must be kept free
inordertosupplyanypagesthatmightbeneededatinterrupttime.
Every process’s text segment is, by default, shared and read-only. This
scheme is practical with paging, because there is no external fragmentation,
andtheswapspacegainedbysharingmorethanoffsetsthenegligibleamount
ofoverheadinvolved,asthekernelvirtualspaceislarge.
CPU scheduling, memory swapping, and paging interact. The lower the
priority of a process, the more likely that its pages will be paged out and
the more likely that it will be swapped in its entirety. The age preferences
in choosing processes to swap guard against thrashing, but paging does so
more effectively. Ideally, processes will not be swapped out unless they are
idle,becauseeachprocesswillneedonlyasmallworkingsetofpagesinmain
memory at any one time, and the pagedaemon will reclaim unused pages for
usebyotherprocesses.C.7 FileSystem 25
The amount of memory the process will need is some fraction of that
process’s total virtual size—up to one-half if that process has been swapped
outforalongtime.
C.7 File System
TheUNIXfilesystemsupportstwomainobjects:filesanddirectories.Directo-
riesarejustfileswithaspecialformat,sotherepresentationofafileisthebasic
UNIXconcept.
C.7.1 Blocks and Fragments
Mostofthefilesystemistakenupbydatablocks,whichcontainwhateverthe
usershaveputintheirfiles.Let’sconsiderhowthesedatablocksarestoredon
thedisk.
The hardware disk sector is usually 512 bytes. A block size larger than
512 bytes is desirable for speed. However, because UNIX file systems usually
contain a very large number of small files, much larger blocks would cause
excessiveinternalfragmentation.Thatiswhytheearlier4.1BSDfilesystemwas
limitedtoa1,024-byte(1-KB)block.The4.2BSDsolutionistousetwoblocksizes
forfilesthat havenoindirectblocks. Alltheblocks ofafileareofalargesize
(such as 8 KB) except the last. The last block is an appropriate multiple of a
smallerfragmentsize(forexample,1,024KB)tofilloutthefile.Thus,afileof
size 18,000 bytes would have two 8-KB blocks and one 2-KB fragment (which
wouldnotbefilledcompletely).
Theblockandfragmentsizesaresetduringfile-systemcreationaccording
to the intended use of the file system. If many small files are expected, the
fragmentsizeshouldbesmall;ifrepeatedtransfersoflargefilesareexpected,
thebasicblocksizeshouldbelarge.Implementationdetailsforceamaximum
block-to-fragment ratio of 8:1 and a minimum block size of 4 KB, so typical
choicesare4,096:512fortheformercaseand8,192:1,024forthelatter.
Suppose data are written to a file in transfer sizes of 1-KB bytes, and the
block and fragment sizes of the file system are 4 KB and 512 bytes. The file
systemwillallocatea1-KBfragmenttocontainthedatafromthefirsttransfer.
Thenexttransferwillcauseanew2-KBfragmenttobeallocated.Thedatafrom
theoriginalfragmentmustbecopiedintothisnewfragment,followedbythe
second1-KBtransfer.Theallocationroutinesattempttofindtherequiredspace
on the disk immediately following the existing fragment so that no copying
is necessary. If they cannot do so, up to seven copies may be required before
the fragment becomes a block. Provisions have been made for programs to
discover the block size for a file so that transfers of that size can be made, to
avoidfragmentrecopying.
C.7.2 Inodes
Afileisrepresentedbyaninode,whichisarecordthatstoresmostoftheinfor-
mationaboutaspecificfileonthedisk.(SeeFigureC.7.)Thenameinode(pro-
nounced EYE node) is derived from “index node” and was originally spelled
“i-node”; the hyphen fell out of use over the years. The term is sometimes
spelled“Inode.”26 AppendixC BSDUNIX
mode
owners (2)
timestamps (3)
data
size block count
data
data
(cid:129)
(cid:129)
direct blocks (cid:129) (cid:129)
(cid:129) data
(cid:129)
single indirect (cid:129) (cid:129) data (cid:129) data
(cid:129)
double indirect (cid:129) data (cid:129) (cid:129) data
(cid:129)
(cid:129)
triple indirect (cid:129) data
(cid:129)
(cid:129) data
FigureC.7 TheUNIXinode.
Theinodecontainstheuserandgroupidentifiersofthefile,thetimesofthe
lastfilemodificationandaccess,acountofthenumberofhardlinks(directory
entries)tothe file, and the type ofthe file (plain file, directory,symbolic link,
character device, block device, or socket). In addition, the inode contains 15
pointers to the disk blocks containing the data contents of the file. The first
12 of these pointers point to direct blocks. That is, they contain addresses of
blocksthatcontaindataofthefile.Thus,thedataforsmallfiles(nomorethan
12blocks)canbereferencedimmediately,becauseacopyoftheinodeiskept
inmainmemorywhileafileisopen.Iftheblocksizeis4KB,thenupto48KB
ofdatacanbeaccesseddirectlyfromtheinode.
The next three pointers in the inode point to indirect blocks. If the file is
largeenoughtouseindirectblocks,eachoftheindirectblocksisofthemajor
blocksize;thefragmentsizeappliesonlytodatablocks.Thefirstindirectblock
pointeristheaddressofasingleindirectblock.Thesingleindirectblockisan
index block containing not data but the addresses of blocks that do contain
data.Then,thereisadouble-indirect-blockpointer,theaddressofablockthat
containstheaddressesofblocksthatcontainpointerstotheactualdatablocks.
Thelastpointerwouldcontaintheaddressofatripleindirectblock;however,
thereisnoneedforit.
Theminimumblocksizeforafilesystemin4.2BSDis4KB,sofileswithas
many as 232 bytes will use only double, not triple, indirection. That is, since
each block pointer takes 4 bytes, we have 49,152 bytes accessible in direct
blocks, 4,194,304 bytes accessible by a single indirection, and 4,294,967,296
bytes reachable through double indirection, for a total of 4,299,210,752 bytes,
which is larger than 232 bytes. The number 232 is significant because the file
offset in the file structure in main memory is kept in a 32-bit word. Files
thereforecannotbelargerthan232bytes.SincefilepointersaresignedintegersC.7 FileSystem 27
(for seeking backward and forward in a file), the actual maximum file size is
232−1
bytes.Twogigabytesislargeenoughformostpurposes.
C.7.3 Directories
Plain files are not distinguished from directories at this level of implementa-
tion.Directorycontentsarekeptindatablocks,anddirectoriesarerepresented
by an inode in the same way as plain files. Only the inode type field distin-
guishesbetweenplainfilesanddirectories.Plainfilesarenotassumedtohavea
structure,whereasdirectorieshaveaspecificstructure.InVersion7,filenames
werelimitedto14characters,sodirectorieswerealistof16-byteentries:2bytes
foraninodenumberand14bytesforafilename.
In FreeBSD file names are of variable length, up to255 bytes, sodirectory
entries are also of variable length. Each entry contains first the length of the
entry, then the file name and the inode number. This variable-length entry
makes the directory management and search routines more complex, but it
allowsuserstochoosemuchmoremeaningfulnamesfortheirfilesanddirec-
tories. The first two names in every directory are “.” and “..”. New directory
entries are added to the directory in the first space available, generally after
theexistingfiles.Alinearsearchisused.
The user refers to a file by a path name, whereas the file system uses the
inodeas its definitionofafile.Thus, the kernelhas tomap the supplieduser
pathnametoaninode.Thedirectoriesareusedforthismapping.
First, a starting directory is determined. As mentioned earlier, if the first
character of the path name is “/,” the starting directory is the root directory.
If the path name starts with any character other than a slash, the starting
directoryisthecurrentdirectoryofthecurrentprocess.Thestartingdirectory
ischeckedforproperfiletypeandaccesspermissions,andanerrorisreturned
ifnecessary.Theinodeofthestartingdirectoryisalwaysavailable.
Thenextelementofthepathname,uptothenext“/”ortotheendofthe
pathname,isafilename.Thestartingdirectoryissearchedforthisname,and
anerrorisreturnedifthenameisnotfound.Ifthepathnamehasyetanother
element, the current inode must refer to a directory; an error is returned if it
doesnotorifaccessisdenied.Thisdirectoryissearchedinthesamewayasthe
previousone.Thisprocesscontinuesuntiltheendofthepathnameisreached
andthedesiredinodeisreturned.Thisstep-by-stepprocessisneededbecause
atanydirectoryamountpoint(orsymboliclink,asdiscussedbelow)maybe
encountered,causingthetranslationtomovetoadifferentdirectorystructure
forcontinuation.
Hardlinksaresimplydirectoryentrieslikeanyother.Wehandlesymbolic
links for the most part by starting the search over with the path name taken
fromthe contents ofthe symboliclink.We preventinfinite loops by counting
the number of symbolic links encountered during a path-name search and
returninganerrorwhenalimit(eight)isexceeded.
Nondisk files (such as devices) do not have data blocks allocated on the
disk. The kernel notices these file types (as indicated in the inode) and calls
appropriatedriverstohandleI/Oforthem.
Once the inode is found by, for instance, the open() system call, a file
structure is allocated to point to the inode. The file descriptor given to the
user refers to this file structure. FreeBSD has a directory name cache to hold28 AppendixC BSDUNIX
data
blocks
•
… •
read (4, ) •
sync
inode
tables of open file-structure in-core
list
files table inode
(per process) list
user space system space disk space
FigureC.8 File-systemcontrolblocks.
recentdirectory-to-inodetranslations,whichgreatlyincreasesfile-systemper-
formance.
C.7.4 Mapping a File Descriptor to an Inode
A system call that refers to an open file indicates the file by passing a file
descriptor as an argument. The file descriptor is used by the kernel to index
a table of open files for the current process. Each entry in the table contains
a pointer to a file structure. This file structure in turn points to the inode; see
FigureC.8.Theopenfiletablehasafixedlength,whichissettableonlyatboot
time.Therefore,thereisafixedlimitonthenumberofconcurrentlyopenfiles
inasystem.
The read() and write() system calls do not take a position in the file
asanargument.Rather,thekernelkeepsafileoffset,whichisupdatedbyan
appropriateamountaftereachread()orwrite()accordingtothenumberof
dataactuallytransferred.Theoffsetcanbesetdirectlybythelseek()system
call. If the file descriptor indexed an array of inode pointers instead of file
pointers,thisoffsetwouldhavetobekeptintheinode.Becausemorethanone
processmayopenthesamefile,andeachsuchprocessneedsitsownoffsetfor
thefile,keepingtheoffsetintheinodeisinappropriate.Thus,thefilestructure
is used to contain the offset. File structures are inherited by the child process
after a fork(), so several processes may share the same offset location for a
file.
Theinodestructurepointedtobythefilestructureisanin-corecopyofthe
inodeonthedisk.Thein-coreinodehasafewextrafields,suchasareference
countofhowmanyfilestructuresarepointingatit,andthefilestructurehasa
similarreferencecountforhowmanyfiledescriptorsrefertoit.Whenacount
becomeszero,theentryisnolongerneededandmaybereclaimedandreused.
C.7.5 Disk Structures
Thefilesystemthattheuserseesissupportedbydataonamassstoragedevice
—usually, a disk. The user ordinarily knows of only one file system, but this
one logical file system may actually consist of several physical file systems,
eachonadifferentdevice.Becausedevicecharacteristicsdiffer,eachseparateC.7 FileSystem 29
hardwaredevicedefinesitsownphysicalfilesystem.Infact,wegenerallywant
topartitionlargephysicaldevices,suchasdisks,intomultiplelogicaldevices.
Each logical device defines a physical file system. Figure C.9 illustrates how
a directory structure is partitioned into file systems, which are mapped onto
logicaldevices,whicharepartitionsofphysicaldevices.Thesizesandlocations
ofthesepartitionswerecodedintodevicedriversinearliersystems,butthey
aremaintainedonthediskbyFreeBSD.
Partitioningaphysicaldeviceintomultiplefilesystemshasseveralbene-
fits.Differentfilesystemscansupportdifferentuses.Althoughmostpartitions
willbe usedby the file system,at least one willbe neededas aswap areafor
the virtual memory software. Reliability is improved,because software dam-
ageisgenerallylimitedtoonlyonefilesystem.Wecanimproveefficiencyby
varyingthefile-systemparameters(suchas theblock andfragmentsizes)for
eachpartition.Also,havingseparatefilesystemspreventsoneprogramfrom
usingallavailablespaceforalargefile,becausefilescannotbesplitacrossfile
systems.Finally,diskbackupsaredoneperpartition,anditisfastertosearch
a backup tape for a file if the partition is smaller. Restoring the full partition
fromtapeisalsofaster.
The number of file systems on a drive varies according to the size of the
diskandthepurposeofthecomputersystemasawhole.Onefilesystem,the
root
swap
logical file system file systems logical devices physical devices
FigureC.9 Mappingofalogicalfilesystemtophysicaldevices.30 AppendixC BSDUNIX
rootfilesystem,isalwaysavailable.Otherfilesystemsmaybemounted—that
is,integratedintothedirectoryhierarchyoftherootfilesystem.
A bit in the inode structure indicates that the inode has a file system
mounted on it. Areference to this file causes the mount table to be searched
tofindthedevicenumberofthemounteddevice.Thedevicenumberisused
to find the inode of the root directory of the mounted file system, and that
inodeisused.Conversely,ifapath-nameelementis“..”andthedirectorybeing
searchedistherootdirectoryofafilesystemthatismounted,themounttable
issearchedtofindtheinodeitismountedon,andthatinodeisused.
Eachfilesystemisaseparatesystemresourceandrepresentsasetoffiles.
The first sector on the logical device is the boot block, possibly containing a
primarybootstrapprogram,whichmaybeusedtocallasecondarybootstrap
program residing in the next 7.5 KB. Asystem needs only one partition con-
taining boot-block data, but the system manager may install duplicates via
privileged programs, to allow booting when the primary copy is damaged.
Thesuperblockcontainsstaticparametersofthefilesystem.Theseparameters
includethetotalsizeofthefilesystem,theblockandfragmentsizesofthedata
blocks,andassortedparametersthataffectallocationpolicies.
C.7.6 Implementations
The user interface to the file system is simple and well defined, allowing the
implementationofthefilesystemitselftobechangedwithoutsignificanteffect
on the user. The file system was changed betweenVersion6 and Version7 of
3BSD,andagainbetweenVersion7and4BSD.ForVersion7,thesizeofinodes
doubled, the maximum file and file-system sizes increased, and the details
of free-list handling and superblock information changed. At that time also,
seek() (with a 16-bit offset) became lseek() (with a 32-bit offset), to allow
specificationofoffsetsinlargerfiles,butfewotherchangeswerevisibleoutside
thekernel.
In4.0BSD,thesizeofblocksusedinthefilesystemwasincreasedfrom512
bytesto1,024bytes.Althoughthisincreasedsizeproducedincreasedinternal
fragmentation on the disk, it doubled throughput, due mainly to the greater
numberofdataaccessedoneachdisktransfer.Thisideawaslateradoptedby
SystemV,alongwithanumberofotherideas,devicedrivers,andprograms.
4.2BSD added the Berkeley Fast File System, which increased speed and
wasaccompaniedbynewfeatures.Symboliclinksrequirednewsystemcalls.
Long file names necessitated new directory system calls to traverse the now-
complex internal directory structure. Finally, truncate() calls were added.
TheFastFileSystemwasasuccessandisnowfoundinmostimplementations
ofUNIX.Itsperformanceismadepossiblebyitslayoutandallocationpolicies,
whichwediscussnext.InSection14.4.4,wediscussedchangesmadeinSunOS
toincreasediskthroughputfurther.
C.7.7 Layout and Allocation Policies
Thekernelusesa<logicaldevicenumber,inodenumber>pairtoidentifyafile.
Thelogicaldevicenumberdefinesthefilesysteminvolved.Theinodesinthe
file system are numbered in sequence. In the Version 7 file system, all inodes
areinanarrayimmediatelyfollowingasinglesuperblockatthebeginningofC.7 FileSystem 31
thelogicaldevice,withthedatablocksfollowingtheinodes.Theinodenumber
iseffectivelyjustanindexintothisarray.
WiththeVersion7filesystem,ablockofafilecanbeanywhereonthedisk
betweentheendoftheinodearrayandtheendofthefilesystem.Freeblocks
arekeptinalinkedlistinthesuperblock.Blocksarepushedontothefrontof
thefreelistandareremovedfromthefrontasneededtoservenewfilesorto
extendexistingfiles.Thus,theblocksofafilemaybearbitrarilyfarfromboth
theinodeandoneanother.Furthermore,themoreafilesystemofthiskindis
used, the more disorganized the blocks in a file become. We can reverse this
processonlybyreinitializingandrestoringtheentirefilesystem,whichisnot
aconvenienttasktoperform.ThisprocesswasdescribedinSection14.7.4.
Another difficulty is that the reliability of the file system is suspect. For
speed,thesuperblockofeachmountedfilesystemiskeptinmemory.Keeping
the superblock in memory allows the kernel to access a superblock quickly,
especially for using the free list. Every 30 seconds, the superblock is written
to the disk, to keep the in-core and disk copies synchronized (by the update
program, using the sync() system call). However, system bugs or hardware
failures may cause a system crash, which destroys the in-core superblock
between updates to the disk. Then, the free list on disk does not accurately
reflect the state of the disk. To reconstruct it, we must perform a lengthy
examinationofallblocksinthefilesystem.(Thisproblemremainsinthenew
filesystem.)
The 4.2BSD file-system implementation is radically different from that of
Version 7. This reimplementation was done primarily to improve efficiency
androbustness,andmostsuchchangesareinvisibleoutsidethekernel.Other
changes introduced at the same time are visible at both the system-call and
the user levels; examples include symbolic links and long file names (up to
255characters).Mostofthechangesrequiredforthesefeatureswerenotinthe
kernel,however,butintheprogramsthatusethem.
Spaceallocationisespeciallydifferent.ThemajornewconceptinFreeBSDis
thecylindergroup.Thecylindergroupwasintroducedtoallowlocalizationof
theblocksinafile.Eachcylindergroupoccupiesoneormoreconsecutivecylin-
dersofthedisk,sothatdiskaccesseswithinthecylindergrouprequireminimal
diskheadmovement.Everycylindergrouphasasuperblock,acylinderblock,
anarrayofinodes,andsomedatablocks(FigureC.10).
data blocks
superblock
cylinder block
inodes
data blocks
FigureC.10 4.3BSDcylindergroup.32 AppendixC BSDUNIX
The superblocks in all cylinder groups are identical, so that a superblock
can be recovered from any one of them in the event of disk corruption. The
cylinderblockcontains dynamicparametersoftheparticularcylindergroup.
Theseincludeabitmapoffreedatablocksandfragmentsandabitmapoffree
inodes. Statistics on recent progress of the allocation strategies are also kept
here.
The header information in a cylinder group (the superblock, the cylinder
block, and the inodes) is not always at the beginning of the group. If it were,
the header information for every cylinder group might be on the same disk
platter, and a single disk head crash could wipe out all of them. Therefore,
each cylinder group has its header information at a different offset from the
beginningofthegroup.
Thedirectory-listingcommandlscommonlyreadsalltheinodesofevery
file in a directory, making it desirable for all such inodes to be close together
on the disk. For this reason, the inode for a file is usually allocated from
the cylinder group containing the inode of the file’s parent directory. Not
everythingcanbelocalized,however,soaninodeforanewdirectoryisputin
adifferentcylindergroupfromthatofitsparentdirectory.Thecylindergroup
chosen for such a new directory inode is that with the greatest number of
unusedinodes.
To reduce disk head seeks involved in accessing the data blocks of a file,
weallocateblocksfromthesamecylindergroupasoftenaspossible.Becausea
singlefilecannotbeallowedtotakeupalltheblocksinacylindergroup,afile
exceedingacertainsize(suchas2MB)hasfurtherblockallocationredirectedto
adifferentcylindergroup;thenewgroupischosenfromamongthosehaving
morethanaveragefreespace.Ifthefilecontinues togrow,allocationisagain
redirected(ateachmegabyte)toyetanothercylindergroup.Thus,alltheblocks
of a small file are likely to be in the same cylinder group, and the number of
longheadseeksinvolvedinaccessingalargefileiskeptsmall.
There are two levels of disk-block-allocation routines. The global policy
routines select a desired disk block according to the considerations already
discussed. The local policy routines use the specific information recorded in
the cylinderblocks tochoose ablock near the one requested.Iftherequested
blockisnotinuse,itisreturned.Otherwise,theroutinereturnseithertheblock
rotationally closest to the one requested in the same cylinder or a block in a
different cylinder but in the same cylinder group. If no more blocks are in
the cylinder group, a quadratic rehash is done among all the other cylinder
groupstofindablock.Ifthatfails,anexhaustivesearchisdone.Ifenoughfree
space (typically 10 percent)is left in the file system, blocks are usually found
where desired, the quadratic rehash and exhaustive search are not used, and
performanceofthefilesystemdoesnotdegradewithuse.
BecauseoftheincreasedefficiencyoftheFastFileSystem,typicaldisksare
now utilized at 30 percent of their raw transfer capacity. This percentage is a
markedimprovementoverthatrealizedwiththeVersion7filesystem,which
usedabout3percentofthebandwidth.
BSD Tahoe introduced the Fat Fast File System, which allows the number
of inodes per cylinder group, the number of cylinders per cylinder group,
and the number of distinguished rotational positions to be set when the file
system is created. FreeBSD previously set these parameters according to the
diskhardwaretype.C.8 I/OSystem 33
C.8 I/O System
One of the purposes of an operating system is to hide the peculiarities of
specifichardwaredevicesfromtheuser.Forexample,thefilesystempresentsa
simple,consistentstoragefacility(thefile)independentoftheunderlyingdisk
hardware. In UNIX, the peculiarities of I/O devices are also hidden from the
bulkofthekernelitselfbytheI/Osystem.TheI/Osystemconsistsofabuffer
cachingsystem,generaldevice-drivercode,anddriversforspecifichardware
devices.Onlythedevicedriverknowsthepeculiaritiesofaspecificdevice.The
majorpartsoftheI/OsystemarediagrammedinFigureC.11.
There are three main kinds of I/O in FreeBSD: block devices, character
devices, and the socket interface. The socket interface, together with its pro-
tocolsandnetworkinterfaces,willbedescribedinSectionC.9.1.
Block devices include disksand tapes.Their distinguishing characteristic
is that they are directly addressable in a fixed block size—usually 512 bytes.
Ablock-devicedriverisrequiredtoisolatedetailsoftracks,cylinders,andso
on from the rest of the kernel. Block devices are accessible directly through
appropriatedevicespecialfiles(suchas/dev/rp0),buttheyaremorecommonly
accessedindirectlythroughthefilesystem.Ineithercase,transfersarebuffered
throughtheblockbuffercache,whichhasaprofoundeffectonefficiency.
Character devices include terminals and line printers but also include
almosteverythingelse(exceptnetworkinterfaces)thatdoesnotusetheblock
buffer cache. For instance, /dev/mem is an interface to physical main memory,
and/dev/nullisabottomlesssinkfordataandanendlesssourceofend-of-file
markers.Somedevices,suchashigh-speedgraphicsinterfaces,mayhavetheir
ownbuffersormayalwaysdoI/Odirectlyintotheuser’sdataspace;because
they do not use the block buffer cache, they are classed as character devices.
Terminalsandterminal-likedevicesuseC-lists,whicharebufferssmallerthan
thoseoftheblockbuffercache.
Blockdevicesandcharacterdevicesarethetwomaindeviceclasses.Device
drivers are accessed by one of two arrays of entry points. One array is for
block devices;the other is for character devices.Adeviceis distinguished by
a class (block or character) and a device number. The device number consists
oftwoparts.Themajordevicenumberisusedtoindexthearrayforcharacter
or block devices to find entries into the appropriate device driver.The minor
system-call interface to the kernel
socket plain file cooked TTY
cooked raw raw tty
protocols file block block interface line
system interface interface discipline
network
block-device driver character-device driver
interface
the hardware
FigureC.11 4.3BSDkernelI/Ostructure.34 AppendixC BSDUNIX
devicenumberisinterpretedbythedevicedriveras,forexample,alogicaldisk
partitionoraterminalline.
Adevicedriverisconnectedtotherestofthekernelonlybytheentrypoints
recordedinthearrayforitsclassandbyitsuseofcommonbufferingsystems.
Thissegregationisimportantforportabilityandforsystemconfiguration.
C.8.1 Block Buffer Cache
The block devices, as mentioned, use a block buffer cache. The buffer cache
consists of a number of buffer headers, each of which can point to a piece of
physical memory as well as to a device number and a block number on the
device. The buffer headers for blocks not currently in use are kept in several
linkedlists,oneforeachofthefollowing:
• Buffersrecentlyused,linkedinLRUorder(theLRUlist)
• Buffersnotrecentlyusedorwithoutvalidcontents(theAGElist)
• EMPTYbufferswithnophysicalmemoryassociatedwiththem
Thebuffersintheselistsarealsohashedbydeviceandblocknumberforsearch
efficiency.
Whenablockiswantedfromadevice(aread),thecacheissearched.Ifthe
block is found, it is used, and no I/O transfer is necessary. If it is not found,
a buffer is chosen from the AGE list or, if that list is empty, the LRU list. Then
thedevicenumberandblocknumberassociatedwithitareupdated,memory
is found for it if necessary, and the new data are transferred into it from the
device.Iftherearenoemptybuffers,theLRUbufferiswrittentoitsdevice(if
itismodified),andthebufferisreused.
Onawrite,iftheblockinquestionisalreadyinthebuffercache,thenew
dataareputinthebuffer(overwritinganypreviousdata),thebufferheaderis
markedtoindicatethatthebufferhasbeenmodified,andnoI/Oisimmediately
necessary.Thedatawillbewrittenwhenthebufferisneededforotherdata.If
the block is not found inthe buffer cache, an empty buffer is chosen (as with
a read), and a transfer is done to this buffer. Writes are periodically forced
for dirty buffer blocks to minimize potential file-system inconsistencies after
acrash.
The number of data in a buffer in FreeBSD is variable, up to a maximum
overallfilesystems,usually8KB.Theminimumsizeisthepaging-clustersize,
usually1,024bytes.Buffersarepage-clusteraligned,andanypageclustermay
bemappedintoonlyonebufferatatime,justasanydiskblockmaybemapped
intoonlyonebufferatatime.TheEMPTYlistholdsbufferheaders,whichare
usedifaphysicalmemoryblockof8KBissplittoholdmultiple,smallerblocks.
HeadersareneededfortheseblocksandareretrievedfromEMPTY.
The number of data in a buffer may grow as a user process writes more
data following those already in the buffer. When this increase occurs, a new
bufferlargeenoughtoholdallthedatais allocated,and theoriginaldataare
copied into it, followed by the new data. If a buffer shrinks, a buffer is takenC.8 I/OSystem 35
offtheemptyqueue,excesspagesareputinit,andthatbufferisreleasedtobe
writtentodisk.
Some devices, such as magnetic tapes, require that blocks be written in a
certainorder.Facilitiesarethereforeprovidedtoforceasynchronouswriteof
buffers to these devicesin the correct order. Directory blocks are also written
synchronously,toforestallcrashinconsistencies.Considerthechaosthatcould
occur if many changes were made to a directory but the directory entries
themselveswerenotupdated!
Thesizeofthebuffercachecanhaveaprofoundeffectontheperformance
ofa system, because, ifit is large enough, the percentageof cache hits can be
highandthenumberofactualI/Otransferslow.FreeBSDoptimizesthebuffer
cachebycontinuallyadjustingtheamountofmemoryusedbyprogramsand
thediskcache.
Someinterestinginteractionsoccuramongthebuffercache,thefilesystem,
andthediskdrivers.Whendataarewrittentoadiskfile,theyarebufferedin
thecache,andthediskdriversortsitsoutputqueueaccordingtodiskaddress.
These two actions allow the disk driver to minimize disk head seeks and to
write data at times optimized for disk rotation. Unless synchronous writes
are required, a process writing to disk simply writes into the buffer cache,
andthesystemasynchronouslywritesthedatatodiskwhenconvenient.The
user process sees very fast writes. When data are read from a disk file, the
block I/O system does some read-ahead; however, writes are much nearer to
asynchronousthanarereads.Thus,outputtothediskthroughthefilesystem
isoftenfasterthanisinputforlargetransfers,countertointuition.
C.8.2 Raw Device Interfaces
Almosteveryblock devicealsohas a character interface,and these arecalled
rawdeviceinterfaces.Suchaninterfacediffersfromtheblockinterfaceinthat
theblockbuffercacheisbypassed.
Each disk driver maintains a queue of pending transfers. Each record in
the queue specifies whether it is a read or a write and gives a main memory
addressforthetransfer(usuallyin512-byteincrements),adeviceaddressfor
thetransfer(usuallytheaddressofadisksector),andatransfersize(insectors).
Itissimpletomaptheinformationfromablockbuffertowhatisrequiredfor
thisqueue.
It is almost as simple to map a piece of main memory corresponding to
partofauserprocess’svirtualaddressspace.Thismappingiswhatarawdisk
interface, for instance, does. Unbuffered transfers directly to or from a user’s
virtualaddressspacearethusallowed.Thesizeofthetransferislimitedbythe
physicaldevices,someofwhichrequireanevennumberofbytes.
The kernel accomplishes transfers for swapping and paging simply by
putting the appropriate request on the queue for the appropriate device. No
specialswappingorpagingdevicedriverisneeded.
The 4.2BSD file-system implementation was actually written and largely
tested as a user process that used a raw disk interface, before the code was
movedintothekernel.Inaninterestingabout-face,theMachoperatingsystem36 AppendixC BSDUNIX
hasnofilesystemperse.Filesystemscanbeimplementedasuser-leveltasks
(seeAppendixD).
C.8.3 C-Lists
As mentioned, terminals and terminal-like devices use a character-buffering
system that keeps small blocks of characters (usually 28 bytes) in linked lists
called C-lists. Although all free character buffers are kept in a single free list,
mostdevicedriversthatusethemlimitthenumberofcharactersthatmaybe
queuedatonetimeforanygiventerminalline.
There are routines to enqueue and dequeue characters for such lists. A
write()systemcalltoaterminalenqueuescharactersonalistforthedevice.
Aninitialtransferisstarted,andinterruptscausedequeuingofcharactersand
furthertransfers.
Inputissimilarlyinterruptdriven.Terminaldriverstypicallysupporttwo
inputqueues,however,andconversionfromthefirst(rawqueue)totheother
(canonical queue) is triggered when the interrupt routine puts an end-of-line
character on the raw queue. The process doing a read on the device is then
awakened,anditssystemphasedoestheconversion.Thecharactersthusput
onthecanonicalqueuearethenavailabletobereturnedtotheuserprocessby
theread.
The device driver can bypass the canonical queue and return characters
directly from the raw queue. This mode of operation is known as raw mode.
Full-screen editors, as well as other programs that need to react to every
keystroke,usethismode.
C.9 Interprocess Communication
Althoughmanytaskscanbeaccomplishedinisolatedprocesses,manyothers
require interprocess communication. Isolated computing systems have long
servedfor many applications, but networking is increasingly important. Fur-
thermore, with the increasing use of personal workstations, resource sharing
isbecomingmorecommon.Interprocesscommunicationhasnottraditionally
beenoneofUNIX’sstrongpoints.
C.9.1 Sockets
The pipe (discussed in Section C.4.3) is the IPC mechanism most characteris-
ticofUNIX. Apipepermitsareliableunidirectional bytestreambetweentwo
processes.Itistraditionallyimplementedasanordinaryfile,withafewexcep-
tions. It has no name in the file system, being created instead by the pipe()
system call. Its size is fixed, and when a process attempts to write to a full
pipe,theprocessissuspended.Oncealldatapreviouslywrittenintothepipe
havebeenreadout,writingcontinuesatthebeginningofthefile(pipesarenot
truecircularbuffers).Onebenefitofthesmallsizeofpipes(usually4,096bytes)
is that pipe data are seldom actually written to disk; they usually are kept in
memorybythenormalblockbuffercache.
In FreeBSD pipes are implemented as a special case of the socket mecha-
nism.Thesocketmechanismprovidesageneralinterfacenotonlytofacilities
suchaspipes,whicharelocaltoonemachine,butalsotonetworkingfacilities.C.9 InterprocessCommunication 37
Evenon the same machine, a pipecan be usedonly by two processesrelated
throughuseofthefork()systemcall.Thesocketmechanismcanbeusedby
unrelatedprocesses.
Asocketisanendpointofcommunication.Asocketinuseusuallyhasan
addressboundtoit.Thenatureoftheaddressdependsonthecommunication
domain of the socket. Acharacteristic property of a domain is that processes
communicating in the same domain use the same address format. A single
socketcancommunicateinonlyonedomain.
ThethreedomainscurrentlyimplementedinFreeBSDaretheUNIXdomain
(AF UNIX), the Internet domain (AF INET), and the XEROX Network Services
(NS) domain (AF NS). The address format of the UNIX domain is that of an
ordinaryfile-systempathname,suchas/alpha/beta/gamma.Processescommu-
nicatingintheInternetdomainuseDARPAInternetcommunicationsprotocols
(suchasTCP/IP)andInternetaddresses,whichconsistofa32-bithostnumber
anda32-bitportnumber(representingarendezvouspointonthehost).
There are several socket types, which represent classes of services. Each
typemayormaynotbeimplementedinanycommunicationdomain.Ifatype
is implemented in a given domain, it may be implemented by one or more
protocols,whichmaybeselectedbytheuser:
• Stream sockets. These sockets provide reliable, duplex, sequenced data
streams.Nodataarelostorduplicatedindelivery,andtherearenorecord
boundaries. This type is supported in the Internet domain by TCP. In the
UNIX domain,pipesareimplementedas apair ofcommunicating stream
sockets.
• Sequencedpacketsockets.Thesesocketsprovidedatastreamslikethose
ofstreamsockets,exceptthatrecordboundariesareprovided.Thistypeis
usedintheXEROXAF NSprotocol.
• Datagram sockets. These sockets transfer messages of variable size in
either direction. There is no guarantee that such messages will arrive in
the same order they were sent, or that they will be unduplicated, or that
theywillarriveatall,buttheoriginalmessage(orrecord)sizeispreserved
in any datagram that does arrive. This type is supported in the Internet
domainbyUDP.
• Reliablydeliveredmessagesockets.Thesesocketstransfermessagesthat
are guaranteed to arrive and that otherwise are like the messages trans-
ferredusingdatagramsockets.Thistypeiscurrentlyunsupported.
• Rawsockets.Thesesocketsallowdirectaccessbyprocessestotheproto-
cols that support the other socket types. The protocols accessible include
notonlytheuppermostonesbutalsolower-levelprotocols.Forexample,
in the Internet domain, it is possible to reach TCP, IP beneath that, or an
Ethernet protocol beneath that. This capability is useful for developing
newprotocols.
Asetofsystemcallsisspecifictothesocketfacility.Thesocket()system
callcreatesasocket.Ittakesasargumentsspecificationsofthecommunication
domain,thesockettype,andtheprotocoltobeusedtosupportthattype.The
valuereturnedbythecallisasmallintegercalledasocketdescriptor,which38 AppendixC BSDUNIX
occupiesthesamenamespaceasfiledescriptors.Thesocketdescriptorindexes
the array of open files in the u structure in the kernel and has a file structure
allocated for it. The FreeBSD file structure may point to a socket structure
instead of to an inode. In this case, certain socket information (such as the
socket’stype,itsmessagecount,andthedatainitsinputandoutputqueues)
iskeptdirectlyinthesocketstructure.
For another process to address a socket, the socket must have a name. A
name is bound to a socket by the bind() system call, which takes the socket
descriptor,apointertothename,andthelengthofthenameasabytestring.
Thecontentsandlengthofthebytestringdependontheaddressformat.The
connect() system call is used to initiate a connection. The arguments are
syntacticallythesameasthoseforbind();thesocketdescriptorrepresentsthe
localsocket,andtheaddressisthatoftheforeignsockettowhichtheattempt
toconnectismade.
Manyprocessesthatcommunicate usingthesocketIPC followtheclient–
server model. In this model, the server process provides a service to the client
process. When the service is available, the server process listens on a well-
knownaddress,andtheclientprocessusesconnect()toreachtheserver.
A server process uses socket() to create a socket and bind() to bind
the well-known address of its service to that socket. Then, it uses the lis-
ten()systemcalltotellthekernelthatitisreadytoacceptconnections from
clientsandtospecifyhowmanypendingconnectionsthekernelshouldqueue
until the server can service them. Finally, the server uses the accept() sys-
temcall toaccept individualconnections. Bothlisten()and accept()take
as an argument the socket descriptor of the original socket. The system call
accept() returns a new socket descriptor corresponding to the new connec-
tion; the original socket descriptor is still open for further connections. The
server usually uses fork() to produce a new process after the accept() to
servicetheclientwhiletheoriginalserverprocesscontinuestolistenformore
connections.Therearealsosystemcallsforsettingparametersofaconnection
andforreturningtheaddressoftheforeignsocketafteranaccept().
Whenaconnectionforasockettype,suchasastreamsocket,isestablished,
the addresses of both endpoints are known, and no further addressing infor-
mation is neededto transfer data. The ordinary read() and write() system
callsmaythenbeusedtotransferdata.
Thesimplestwaytoterminateaconnection,andtodestroytheassociated
socket,istousetheclose()systemcallonitssocketdescriptor.Wemayalso
wishtoterminateonlyonedirectionofcommunicationofaduplexconnection;
theshutdown()systemcallcanbeusedforthispurpose.
Somesockettypes,suchasdatagramsockets,donotsupportconnections.
Instead,theirsocketsexchangedatagramsthatmustbeaddressedindividually.
The system calls sendto() and recvfrom() are used for such connections.
Bothtakeasargumentsasocketdescriptor,abufferpointerandlength,andan
address-bufferpointerandlength.Theaddressbuffercontainstheappropriate
address for sendto() and is filled in with the address of the datagram just
receivedbyrecvfrom().Thenumberofdataactuallytransferredisreturned
bybothsystemcalls.
Theselect()systemcallcanbeusedtomultiplexdatatransfersonsev-
eralfiledescriptorsand/orsocketdescriptors.Itcanevenbeusedtoallowone
serverprocesstolistenforclientconnectionsformanyservicesandtofork()C.9 InterprocessCommunication 39
a process for each connection as the connection is made. The server does a
socket(),bind(),andlisten()foreachserviceandthendoesaselect()
onallthesocketdescriptors.Whenselect()indicatesactivityonadescriptor,
the server does an accept() on it and forks a process on the new descriptor
returnedbyaccept(),leavingtheparentprocesstodoaselect()again.
C.9.2 Network Support
Almost all current UNIX systems support the UUCP network facilities, which
aremostlyusedoverdial-uptelephonelinestosupporttheUUCPmailnetwork
andtheUSENET newsnetwork.Theseare,however,rudimentarynetworking
facilities; they do not support even remote login, much less remote proce-
dure calls or distributed file systems. These facilities are almost completely
implementedasuserprocessesandarenotpartoftheoperatingsystemitself.
FreeBSDsupportstheDARPAInternetprotocolsUDP,TCP,IP,andICMPona
widerangeofEthernet,token-ring,andARPANETinterfaces.Theframeworkin
thekerneltosupporttheseprotocolsisintendedtofacilitatetheimplementa-
tionoffurtherprotocols,andallprotocolsareaccessibleviathesocketinterface.
Rob GurwitzofBBN wrote thefirst versionofthe code as anadd-onpackage
for4.1BSD.
The International Standards Organization’s (ISO) Open System Intercon-
nection (OSI) Reference Model for networking prescribes seven layers of net-
workprotocolsandstrictmethodsofcommunicationbetweenthem.Animple-
mentationofaprotocolmaycommunicateonlywithapeerentityspeakingthe
same protocol at the same layer or with the protocol–protocol interface of a
protocolinthelayerimmediatelyaboveorbelowinthesamesystem.TheISO
networkingmodelisimplementedinFreeBSDRenoand4.4BSD.
TheFreeBSDnetworkingimplementation,andtoacertainextentthesocket
facility, is more oriented toward the ARPANET Reference Model (ARM). The
ARPANET initsoriginal form servedas aproofof concept for many network-
ing ideas, such as packet switching and protocol layering. The ARPANET was
retiredin 1988because the hardwarethat supporteditwas no longer stateof
the art. Its successors, such as the NSFNET and the Internet, are even larger
andserveascommunicationsutilitiesforresearchersandtest-bedsforInternet
gatewayresearch.TheARMpredatestheISOmodel;theISOmodelwasinlarge
partinspiredbytheARPANETresearch.
Although the ISO model is often interpreted as setting a limit of one pro-
tocol communicating per layer, the ARM allows severalprotocols in the same
layer.ThereareonlyfourprotocollayersintheARM:
• Process/applications. This layer subsumes the application, presentation,
and sessionlayersoftheISO model.Suchuser-levelprograms asthefile-
transferprotocol(FTP)andTelnet(remotelogin)existatthislevel.
• Host–host. This layer corresponds to ISO’s transport and the top part
of its network layers. Both the Transmission Control Protocol (TCP) and
the Internet Protocol (IP) are in this layer, with TCP on top of IP. TCP
correspondstoanISOtransportprotocol,and IPperformstheaddressing
functionsoftheISOnetworklayer.
• Networkinterface.ThislayerspansthelowerpartoftheISOnetworklayer
andtheentiredata-linklayer.Theprotocolsinvolvedheredependonthe40 AppendixC BSDUNIX
physicalnetworktype.TheARPANETusestheIMP-Hostprotocols,whereas
anEthernetusesEthernetprotocols.
• Network hardware. The ARM is primarily concerned with software, so
thereisnoexplicitnetworkhardwarelayer.However,anyactualnetwork
willhavehardwarecorrespondingtotheISOphysicallayer.
ThenetworkingframeworkinFreeBSDismoregeneralizedthaneitherthe
ISO model or the ARM, although it is most closely related to the ARM (Figure
C.12).
Userprocessescommunicatewithnetworkprotocols(andthuswithother
processes on other machines) via the socket facility. This facility corresponds
to the ISO session layer, as it is responsible for setting up and controlling
communications.
Sockets are supported by protocols—possibly by several, layered one on
another.Aprotocolmayprovideservicessuchasreliabledelivery,suppression
of duplicate transmissions, flow control, and addressing, depending on the
sockettypebeingsupportedandtheservicesrequiredbyanyhigherprotocols.
Aprotocol may communicate with another protocol or with the network
interfacethatisappropriateforthenetworkhardware.Thereislittlerestriction
in the general framework on what protocols may communicate with what
other protocols or on how many protocols may be layered on top of one
another.Theuserprocessmay,bymeansoftherawsockettype,directlyaccess
any layer of protocol from the uppermost used to support one of the other
sockettypes,suchasstreams,downtoarawnetworkinterface.Thiscapability
isusedbyroutingprocessesandalsofornewprotocoldevelopment.
Most often, there is one network-interface driver per network controller
type.Thenetworkinterfaceisresponsibleforhandlingcharacteristicsspecific
tothelocalnetworkbeingaddressed.Thisarrangementensuresthattheproto-
colsusingtheinterfacedonotneedtobeconcernedwiththesecharacteristics.
The functions of the network interface depend largely on the network
hardware,whichiswhateverisnecessaryforthenetwork.Somenetworksmay
ISO ARPANET
4.2BSD example
reference reference
layers layering
model model
application user programs
process telnet
presentation and libraries
applications
session transport sockets sock_stream
TCP
host–host protocol
network IP
data link
network network Ethernet
hardware interface interfaces driver
network network interlan
hardware hardware controller
FigureC.12 Networkreferencemodelsandlayering.C.10 Summary 41
support reliable transmission at this level, but most do not. Some networks
providebroadcastaddressing,butmanydonot.
The socket facility and the networking framework use a common set of
memory buffers, or mbufs. These are intermediate in size between the large
buffersusedbytheblockI/OsystemandtheC-listsusedbycharacterdevices.
Anmbuf is128byteslong;112bytesmaybeusedfordata,andtherestisused
forpointerstolinkthembuf intoqueuesandforindicatorsofhowmuchofthe
dataareaisactuallyinuse.
Data are ordinarily passed between layers—socket–protocol, protocol–
protocol, or protocol–network interface—in mbufs. The ability to pass the
buffers containing the data eliminates some data copying, but there is still
frequentlyaneedtoremoveoraddprotocolheaders.Itisalsoconvenientand
efficientformanypurposestobeabletoholddatathatoccupyanareathesize
ofthememory-managementpage.Thus,thedataofanmbuf mayresidenotin
the mbuf itself but elsewhere in memory. There is an mbuf page table for this
purpose,aswellasapoolofpagesdedicatedtombuf use.
C.10 Summary
The early advantages of UNIX were that it was written in a high-level lan-
guage, was distributed in source form, and provided powerful operating-
systemprimitivesonaninexpensiveplatform.TheseadvantagesledtoUNIX’s
popularityateducational,research,andgovernmentinstitutionsandeventu-
allyinthecommercialworld.ThispopularityproducedmanystrainsofUNIX
withvaryingandimprovedfacilities.
UNIX provides a file system with tree-structured directories. The kernel
supportsfilesasunstructuredsequencesofbytes.Directaccessandsequential
accessaresupportedthroughsystemcallsandlibraryroutines.
Filesarestoredasanarrayoffixed-sizedatablockswithperhapsatrailing
fragment.Thedatablocksarefoundbypointersintheinode.Directoryentries
pointtoinodes.Diskspaceisallocatedfromcylindergroupstominimizehead
movementandtoimproveperformance.
UNIX is a multiprogrammedsystem.Processes can easily create new pro-
cesseswiththefork()systemcall.Processescancommunicatewithpipesor,
moregenerally,sockets.Theymaybegroupedintojobsthatmaybecontrolled
withsignals.
Processes are represented by two structures: the process structure and
the user structure. CPU scheduling is a priority algorithm with dynamically
computed priorities that reduces to round-robin scheduling in the extreme
case.
FreeBSD memory management uses swapping supported by paging. A
pagedaemon process uses a modified second-chance page-replacement algo-
rithmtokeepenoughfreeframestosupporttheexecutingprocesses.
PageandfileI/Ousesablockbuffercachetominimizetheamountofactual
I/O.Terminaldevicesuseaseparatecharacter-bufferingsystem.
Networking support is one of the most important features in FreeBSD.
The socket concept provides the programming mechanism to access other
processes,evenacross a network. Sockets providean interface to severalsets
ofprotocols.42 AppendixC BSDUNIX
Further Reading
[McKusick et al. (2015)] provides a good general discussion of FreeBSD. A
modern scheduler for FreeBSD is described in [Roberson (2003)]. Locking in
theMultithreadedFreeBSDKernelisdescribedin[Baldwin(2002)].
FreeBSD is described in The FreeBSD Handbook, which can be downloaded
fromhttp://www.freebsd.org.
Bibliography
[Baldwin(2002)] J. Baldwin, “Locking in the Multithreaded FreeBSD Kernel”,
USENIXBSD(2002).
[McKusicketal.(2015)] M.K.McKusick,G.V.Neville-Neil,andR.N.M.Wat-
son,TheDesignandImplementationoftheFreeBSDUNIXOperatingSystem–Second
Edition,Pearson(2015).
[Roberson(2003)] J. Roberson,“ULE: AModernScheduler For FreeBSD”,Pro-
ceedingsoftheUSENIXBSDConConference(2003),pages17–28.The D
Appendix
Mach
System
Thischapterwasfirs writtenin1991andhasbeenupdatedovertimebutis
nolongermodified
In this appendix we examine the Mach operating system. Mach is designed
to incorporate the many recent innovations in operating-system research to
produce a fully functional, technically advanced system. Unlike UNIX, which
was developed without regard for multiprocessing, Mach incorporates mul-
tiprocessingsupportthroughout.Thissupportisexceedinglyflexible,accom-
modatingshared-memorysystemsaswellassystemswithnomemoryshared
between processors. Mach is designed to run on computer systems ranging
fromoneprocessortothousandsofprocessors.Inaddition,itiseasilyportedto
manyvariedcomputerarchitectures.AkeygoalofMachistobeadistributed
systemcapableoffunctioningonheterogeneoushardware.
Althoughmanyexperimentaloperatingsystemsarebeingdesigned,built,
andused,Machsatisfiestheneedsofmostusersbetterthantheothersbecause
it offers full compatibility with UNIX 4.3BSD. This compatibility also gives
us a unique opportunity to compare two functionally similar, but internally
dissimilar,operatingsystems.MachandUNIXdifferintheiremphases,soour
Mach discussion does not exactly parallel our UNIX discussion. In addition,
we do not include a section on the user interface, because that component is
similartotheuserinterfacein4.3BSD.Asyouwillsee,Machprovidestheability
tolayeremulationofotheroperatingsystemsaswell;otheroperatingsystems
canevenrunconcurrentlywithMach.
D.1 History of the Mach System
MachtracesitsancestrytotheAccentoperatingsystemdevelopedatCarnegie
Mellon University (CMU). Although Accent pioneered a number of novel
operating-system concepts, its utility was limited by its inability to execute
UNIXapplications anditsstrong tiestoasinglehardwarearchitecture,which
made it difficult to port. Mach’s communication system and philosophy
are derived from Accent, but many other significant portions of the system
(for example, the virtual memory system and the management of tasks and
threads) were developed from scratch. An important goal of the Mach effort
wassupportformultiprocessors.
12 AppendixD TheMachSystem
Mach’s development followed an evolutionary path from BSD UNIX sys-
tems.Machcodewasinitiallydevelopedinsidethe4.2BSDkernel,withBSDker-
nelcomponentsreplacedbyMachcomponentsastheMachcomponentswere
completed. The BSD components were updated to 4.3BSD when that became
available. By 1986, the virtual memory and communication subsystems were
running on the DEC VAX computer family, including multiprocessor versions
of the VAX. Versions for the IBM RT/PC and for Sun 3 workstations followed
shortly;1987sawthecompletionoftheEncoreMultimaxandSequentBalance
multiprocessorversions,includingtaskandthreadsupport,aswellasthefirst
officialreleasesofthesystem,Release0andRelease1.
Through Release2, Mach providedcompatibility with the corresponding
BSDsystemsbyincludingmuchofBSD’scodeinthekernel.Thenewfeatures
and capabilities of Mach made the kernels in these releases larger than the
corresponding BSD kernels. Mach 3 (Figure D.1) moved the BSD code outside
of the kernel, leaving a much smaller microkernel. This system implements
onlybasicMachfeaturesinthekernel;allUNIX-specificcodehasbeenevicted
to run in user-mode servers. Excluding UNIX-specific code from the kernel
allowsreplacementofBSDwithanotheroperatingsystemorthesimultaneous
execution of multiple operating-system interfaces on top of the microkernel.
InadditiontoBSD,user-modeimplementationshavebeendevelopedforDOS,
theMacintoshoperatingsystem,andOSF/1. Thisapproachhas similaritiesto
the virtual machine concept, but the virtual machine is defined by software
(the Mach kernelinterface), rather than by hardware.With Release3.0, Mach
becameavailableonawidevarietyofsystems,includingsingle-processorSun,
Intel, IBM, and DEC machines and multiprocessor DEC, Sequent, and Encore
systems.
MachwaspropelledtotheforefrontofindustryattentionwhentheOpen
SoftwareFoundation(OSF)announcedin1989thatitwoulduseMach2.5asthe
basisforitsnewoperatingsystem,OSF/1.ThereleaseofOSF/1occurredayear
later,anditnowcompeteswithUNIXSystemV,Release4,theoperatingsystem
ofchoiceamongUNIXInternational(UI)members.OSFmembersincludekey
technological companies such as IBM, DEC, and HP. Mach 2.5 is also the basis
fortheoperatingsystemontheNeXTworkstation,thebrainchildofSteveJobs,
of Apple Computer fame. OSF is evaluating Mach 3 as the basis for a future
OSF/1
OS/2
HPUX
database
4.3 BSD system
tasks and IPC virtual scheduling
threads memory
Mach
FigureD.1 Mach3structure.D.2 DesignPrinciples 3
operating-system release, and research on Mach continues at CMU, OSF, and
elsewhere.
D.2 Design Principles
The Mach operating system was designed to provide basic mechanisms that
mostcurrentoperatingsystemslack.Thegoalistodesignanoperatingsystem
thatisBSD-compatibleand,inaddition,excelsinthefollowingareas:
• Supportfordiversearchitectures,includingmultiprocessorswithvarying
degrees of shared memory access: uniform memory access (UMA), non-
uniformmemoryaccess(NUMA),andnoremotememoryaccess(NORMA)
• Ability to function with varying intercomputer network speeds, from
wide-areanetworkstohigh-speedlocal-areanetworksandtightlycoupled
multiprocessors
• Simplifiedkernelstructure,witha small number of abstractions (inturn,
theseabstractionsaresufficientlygeneraltoallowotheroperatingsystems
tobeimplementedontopofMach.)
• Distributed operation, providing network transparency to clients and an
object-orientedorganizationbothinternallyandexternally
• Integrated memory management and interprocess communication, to
provide efficient communication of large numbers of data as well as
communication-basedmemorymanagement
• Heterogeneoussystemsupport,tomakeMachwidelyavailableandinter-
operableamongcomputersystemsfrommultiplevendors
ThedesignersofMachhavebeenheavilyinfluencedbyBSD(andbyUNIX
ingeneral),whosebenefitsinclude
• Asimple programmer interface,with a good set of primitivesand a con-
sistentsetofinterfacestosystemfacilities
• Easyportabilitytoawideclassofsingleprocessors
• Anextensivelibraryofutilitiesandapplications
• Theabilitytocombineutilitieseasilyviapipes
Of course, the designers also wanted to redress what they saw as the
drawbacksofBSD:
• Akernelthathasbecometherepositoryofmanyredundantfeatures—and
thatconsequentlyisdifficulttomanageandmodify
• Original design goals that made it difficult to provide support for
multiprocessors, distributed systems, and shared program libraries (for
instance,becausethekernelwasdesignedforsingleprocessors,ithasno
provisionsforlockingcodeordatathatotherprocessorsmightbeusing.)4 AppendixD TheMachSystem
• Toomanyfundamentalabstractions,providingtoomanysimilar,compet-
ingmeanswithwhichtoaccomplishthesametasks
ThedevelopmentofMachcontinuestobeahugeundertaking.Thebenefits
of such a system are equally large, however. The operating system runs on
many existing single-processor and multiprocessor architectures, and it can
be easily ported to future ones. It makes research easier, because computer
scientistscanaddfeaturesviauser-levelcode,insteadofhavingtowritetheir
own tailor-made operating system. Areas of experimentationinclude operat-
ingsystems,databases,reliabledistributedsystems,multiprocessorlanguages,
security,anddistributedartificialintelligence.Initscurrentversion,theMach
systemisusuallyasefficientasothermajorversionsofUNIXwhenperforming
similartasks.
D.3 System Components
To achieve the design goals of Mach, the developers reduced the operating-
systemfunctionalitytoasmallsetofbasicabstractions,outofwhichallother
functionalitycanbederived.TheMachapproachistoplaceaslittleaspossible
within the kernel but to make what is there powerful enough that all other
featurescanbeimplementedattheuserlevel.
Mach’s design philosophy is to have a simple, extensible kernel, concen-
tratingoncommunicationfacilities.Forinstance,allrequeststothekernel,and
alldatamovementamongprocesses,arehandledthroughonecommunication
mechanism. Mach is therefore able to provide system-wide protection to its
usersbyprotectingthecommunicationmechanism.Optimizingthisonecom-
municationpathcanresultinsignificant performancegains,and itissimpler
thantryingtooptimizeseveralpaths.Machisextensible,becausemanytradi-
tionallykernel-basedfunctionscanbeimplementedasuser-levelservers.For
instance, all pagers (including the default pager) can be implemented exter-
nallyandcalledbythekernelfortheuser.
Mach is an example of an object-oriented system where the data and the
operationsthatmanipulatethatdataareencapsulatedintoanabstract object.
Onlytheoperationsoftheobjectareabletoactontheentitiesdefinedinit.The
detailsofhowtheseoperationsareimplementedarehidden,asaretheinternal
data structures. Thus, a programmer can use an object only by invoking its
defined, exported operations. A programmer can change the internal opera-
tionswithoutchangingtheinterfacedefinition,sochangesandoptimizations
donotaffectotheraspectsofsystemoperation.Theobject-orientedapproach
supported by Mach allows objects to reside anywhere in a network of Mach
systems,transparenttotheuser.The portmechanism,discussedlaterinthis
section,makesallofthispossible.
Mach’sprimitiveabstractionsaretheheartofthesystemandareasfollows:
• Ataskisanexecutionenvironmentthatprovidesthebasicunitofresource
allocation. It consists of a virtual address space and protected access to
systemresourcesviaports,anditmaycontainoneormorethreads.
• Athreadisthebasicunitofexecutionandmustruninthecontextofatask
(which provides the address space). All threads within a task share theD.3 SystemComponents 5
task’sresources(ports,memory,andsoon).Thereisnonotionofaprocess
inMach.Rather,atraditionalprocessisimplementedasataskwithasingle
threadofcontrol.
• A port is the basic object-reference mechanism in Mach and is imple-
mentedasakernel-protectedcommunicationchannel.Communicationis
accomplished by sending messages to ports; messages are queued at the
destination port if no thread is immediately ready to receive them. Ports
areprotectedbykernel-managedcapabilities,orportrights.Ataskmust
haveaportrighttosendamessagetoaport.Theprogrammerinvokesan
operationonanobjectbysendingamessagetoaportassociatedwiththat
object.Theobjectbeingrepresentedbyaportreceivesthemessages.
• Aportsetisagroupofportssharingacommonmessagequeue.Athread
can receive messages for a port set and thus service multiple ports. Each
receivedmessageidentifiestheindividualport(withintheset)fromwhich
itwasreceived.Thereceivercanusethistoidentifytheobjectreferredto
bythemessage.
• A message is the basic method of communication between threads in
Mach.Itisatypedcollectionofdataobjects.Foreachobject,itmaycontain
the actual data or a pointer to out-of-line data. Port rights are passed in
messages;thisistheonlywaytomovethemamongtasks.(Passingaport
rightinsharedmemorydoesnotwork,becausetheMachkernelwillnot
permitthenewtasktousearightobtainedinthismanner.)
• Amemory object is a source of memory. Tasks can access it by mapping
portions of an object (or the entire object) into their address spaces. The
object can be managed by a user-mode external memory manager. One
exampleisafilemanagedbyafileserver;however,amemoryobjectcan
be anyobject forwhich memory-mappedaccessmakessense.Amapped
bufferimplementationofaUNIXpipeisanotherexample.
Figure D.2 illustrates these abstractions, which we explain further in the
remainderofthischapter.
An unusual feature of Mach, and a key to the system’s efficiency, is the
blendingofmemoryandinterprocess-communication(IPC)features.Whereas
some other distributed systems (such as Solaris, with its NFS features) have
special-purposeextensionstothefilesystemtoextenditoveranetwork,Mach
providesageneral-purpose,extensiblemergerofmemoryandmessagesatthe
heartofitskernel.ThisfeaturenotonlyallowsMachtobeusedfordistributed
andparallelprogrammingbutalsohelpsintheimplementationofthekernel
itself.
MachconnectsmemorymanagementandIPCbyallowingeachtobeused
intheimplementationoftheother.Memorymanagementisbasedontheuse
of memory objects. Amemory object is represented by a port (or ports), and
IPCmessagesaresenttothisporttorequestoperations(forexample,pagein,
pageout) on the object. Because IPC is used, memory objects can reside on
remotesystemsandbeaccessedtransparently.Thekernelcachesthecontents
of memory objects in local memory. Conversely, memory-management tech-
niques are used in the implementation of message passing. Where possible,6 AppendixD TheMachSystem
text region
message
threads
port
program
counter
task
data region
port set
secondary storage
memory
object
FigureD.2 Mach’sbasicabstractions.
Mach passes messages by moving pointers to shared memory objects, rather
thanbycopyingtheobjectsthemselves.
IPC tends to involve considerable system overhead. For intrasystem mes-
sages,itisgenerallylessefficientthancommunicationaccomplishedthrough
shared memory. Because Mach is a message-based kernel, message handling
mustbecarriedoutefficiently.Mostoftheinefficiencyofmessagehandlingin
traditionaloperatingsystemsisduetoeitherthecopyingofmessagesfromone
task to another (for intracomputer messages) or low network-transfer speed
(for intercomputer messages). To solve these problems, Mach uses virtual
memoryremappingtotransferthecontentsoflargemessages.Inotherwords,
the message transfer modifies the receiving task’s address space to include a
copy of the message contents. Virtual copy (or copy-on-write) techniques are
usedtoavoidordelaytheactualcopyingofthedata.Thisapproachhasseveral
advantages:
• Increasedflexibilityinmemorymanagementforuserprograms
• Greatergenerality,allowingthevirtualcopyapproachtobeusedintightly
andlooselycoupledcomputers
• ImprovedperformanceoverUNIXmessagepassing
• Easiertaskmigration(becauseportsarelocationindependent,ataskand
all its ports can be moved from one machine to another. All tasks that
previously communicated with the moved task can continue to do so
because they reference the task only by its ports and communicate via
messagestotheseports.)D.4 ProcessManagement 7
Inthesectionsthatfollow,wedetailtheoperationofprocessmanagement,
IPC,andmemorymanagement.Then,wediscussMach’schameleonlikeability
tosupportmultipleoperating-systeminterfaces.
D.4 Process Management
Ataskcanbethoughtofasatraditionalprocessthatdoesnothaveaninstruc-
tion pointer or a register set. Atask contains a virtual address space, a set of
port rights, and accounting information. A task is a passive entity that does
nothingunlessithasoneormorethreadsexecutinginit.
D.4.1 Basic Structure
A task containing one thread is similar to a UNIX process. Just as a fork()
system call produces a new UNIX process, Mach creates a new task by using
fork(). The new task’s memory is a duplicate of the parent’s address space,
asdictatedbytheinheritanceattributesoftheparent’smemory.Thenewtask
containsonethread,whichisstartedatthesamepointasthecreatingfork()
callintheparent.Threadsandtaskscanalsobesuspendedandresumed.
Threads are especially useful in server applications, which are common
inUNIX,sinceonetaskcanhavemultiplethreadstoservicemultiplerequests
to the task. Threads also allow efficient use of parallel computing resources.
Ratherthanhavingoneprocessoneachprocessor,withthecorrespondingper-
formancepenaltyandoperating-systemoverhead,ataskcanhaveitsthreads
spread among parallel processors. Threads add efficiency to user-level pro-
grams as well. For instance, in UNIX, an entire process must wait when a
page fault occurs or when a system call is executed. In a task with multiple
threads, only the thread that causes the page fault or executes a system call
is delayed; all other threads continue executing. Because Mach has kernel-
supported threads (Chapter 4), the threads have some cost associated with
them.Theymusthavesupportingdatastructuresinthekernel,andmorecom-
plex kernel-scheduling algorithms must be provided. These algorithms and
threadstatesarediscussedinChapter4.
Attheuserlevel,threadsmaybeinoneoftwostates:
• Running.The thread is eitherexecuting or waiting tobe allocated apro-
cessor.Athreadisconsideredtoberunningevenifitisblockedwithinthe
kernel(waitingforapagefaulttobesatisfied,forinstance).
• Suspended. The thread is neither executing on a processor nor waiting
tobe allocated aprocessor.Athread can resumeits executiononly ifit is
returnedtotherunningstate.
These two states are also associated with a task. An operation on a task
affects all threads in a task, so suspending a task involves suspending all the
threads in it. Task and thread suspensions are separate, independent mecha-
nisms, however, so resuming a thread in a suspended task does not resume
thetask.
Machprovidesprimitivesfromwhichthread-synchronizationtoolscanbe
built. This practice is consistent with Mach’s philosophy of providing mini-8 AppendixD TheMachSystem
mum yet sufficient functionality in the kernel. The Mach IPC facility can be
usedforsynchronization,withprocessesexchangingmessagesatrendezvous
points. Thread-level synchronization is provided by calls to start and stop
threads at appropriate times. A suspend count is kept for each thread. This
count allows multiple suspend() calls to be executed on a thread, and only
whenanequalnumberofresume()callsoccuristhethreadresumed.Unfor-
tunately,thisfeaturehasitsownlimitation.Becauseitisanerrorforastart()
call to be executed before a stop() call (the suspend count would become
negative), these routines cannot be used to synchronize shared data access.
However,wait()andsignal()operationsassociatedwithsemaphores,and
usedforsynchronization,canbeimplementedviatheIPCcalls.Wediscussthis
methodinSectionD.5.
D.4.2 The C Threads Package
Mach provides low-level but flexible routines instead of polished, large, and
more restrictive functions. Rather than making programmers work at this
lowlevel,Machprovidesmany higher-levelinterfacesforprogramminginC
and other languages. For instance, the C threads package provides multiple
threadsofcontrol,sharedvariables,mutualexclusionforcriticalsections,and
condition variables for synchronization. In fact, C threads is one of the major
influences on the POSIX Pthreads standard, which many operating systems
support. As a result, there are strong similarities between the C threads and
Pthreadsprogramminginterfaces.Thethread-controlroutinesincludecallsto
performthesetasks:
• Createanewthreadwithinatask,givenafunctiontoexecuteandparam-
eters as input. The thread then executes concurrently with the creating
thread,whichreceivesathreadidentifierwhenthecallreturns.
• Destroythecallingthread,andreturnavaluetothecreatingthread.
• Wait for a specific thread to terminate before allowing the calling thread
tocontinue.Thiscallisasynchronizationtool,muchliketheUNIXwait()
systemcalls.
• Yield use of a processor, signaling that the scheduler can run another
threadatthispoint.Thiscallisalsousefulinthepresenceofapreemptive
scheduler, as it can be used to relinquish the CPU voluntarily before the
time quantum (or scheduling interval) expires if a thread has no use for
theCPU.
Mutualexclusionisachievedthroughtheuseofspinlocks,asdiscussedin
Chapter6.Theroutinesassociatedwithmutualexclusionarethese:
• Theroutinemutex alloc()dynamicallycreatesamutexvariable.
• Theroutinemutex free()deallocatesadynamicallycreatedmutexvari-
able.
• The routine mutex lock() locks a mutex variable. The executing thread
loopsinaspinlockuntilthelockisattained.Adeadlockresultsifathread
with a lock tries to lock the same mutex variable. Bounded waiting isD.4 ProcessManagement 9
not guaranteed by the C threads package. Rather, it is dependent on the
hardwareinstructionsusedtoimplementthemutexroutines.
• The routine mutex unlock() unlocks a mutex variable, much like the
typicalsignal()operationofasemaphore.
General synchronization without busy waiting can be achieved through
the use of condition variables, which can be used to implement a monitor,
as described in Chapter 6. A condition variable is associated with a mutex
variable and reflects a Boolean state of that variable. The routines associated
withgeneralsynchronizationarethese:
• The routine condition alloc() dynamically allocates a condition vari-
able.
• The routine condition free() deletes a dynamically created condition
variableallocatedasaresultofcondition alloc().
• The routine condition wait() unlocks the associated mutex variable
and blocks the thread until a condition signal() is executed on the
condition variable, indicating that the event being waited for may have
occurred. The mutex variable is then locked, and the thread continues.
Acondition signal() doesnot guarantee that the condition stillholds
when the unblocked thread finally returns from its condition wait()
call,sotheawakenedthreadmustloop,executingthecondition wait()
routineuntilitisunblockedandtheconditionholds.
As an example of the C threads routines, consider the bounded-buffer
synchronization problem of Section 7.1.1. The producer and consumer are
representedas threads that access the common bounded-buffer pool. We use
amutexvariabletoprotectthebufferwhileitisbeingupdated.Oncewehave
exclusiveaccesstothebuffer,weuseconditionvariablestoblocktheproducer
thread if the buffer is full and to block the consumer thread if the buffer is
empty. As in Chapter 6, we assume that the buffer consists of n slots, each
capableofholdingoneitem.Themutexsemaphoreprovidesmutualexclusion
foraccessestothebufferpoolandisinitializedtothevalue1.Theemptyand
fullsemaphorescountthenumberofemptyandfullbuffers,respectively.The
semaphoreemptyisinitializedtothevaluen;thesemaphorefullisinitialized
to the value 0. The condition variable nonempty is true while the buffer has
items in it, and nonfull is true if the buffer has an empty slot. The first step
includestheallocationofthemutexandconditionvariables:
mutex alloc(mutex);
condition alloc(nonempty, nonfull);
ThecodefortheproducerthreadisshowninFigureD.3,andthecodefor
the consumer thread is shown in Figure D.4. When the program terminates,
themutexandconditionvariablesneedtobedeallocated:
mutex free(mutex);
condition free(nonempty, nonfull);10 AppendixD TheMachSystem
do {
. . .
// produce an item into nextp
. . .
mutex lock(mutex);
while(full)
condition wait(nonfull, mutex);
. . .
// add nextp to buffer
. . .
condition signal(nonempty);
mutex unlock(mutex);
} while(TRUE);
FigureD.3 Thestructureoftheproducerprocess.
D.4.3 The CPU Scheduler
TheCPUschedulerforathread-basedmultiprocessoroperatingsystemismore
complex than its process-based relatives. There are generally more threads
in a multithreaded system than there are processes in a multitasking system.
Keepingtrackofmultipleprocessorsisalsodifficultandisarelativelynewarea
ofresearch.Machusesasimplepolicytokeeptheschedulermanageable.Only
threadsarescheduled,sonoknowledgeoftasksisneededinthescheduler.All
threadscompeteequallyforresources,includingtimequanta.
Eachthreadhasanassociatedprioritynumberrangingfrom0through127,
which is based on the exponential average of its usage of the CPU. That is, a
thread that recently used the CPU for a large amount of time has the lowest
do {
mutex lock(mutex);
while(empty)
condition wait(nonempty, mutex);
. . .
// remove an item from the buffe to nextc
. . .
condition signal(nonfull);
mutex unlock(mutex);
. . .
// consume the item in nextc
. . .
} until(FALSE);
FigureD.4 Thestructureoftheconsumerprocess.D.4 ProcessManagement 11
priority. Mach uses the priority to place the thread in one of 32 global run
queues.Thesequeuesaresearchedinpriorityorderforwaitingthreadswhen
aprocessorbecomesidle.Machalsokeepsper-processor,orlocal,runqueues.
Alocalrunqueueisusedforthreadsthatareboundtoanindividualprocessor.
Forinstance,adevicedriverforadeviceconnectedtoanindividualCPUmust
runononlythatCPU.
Instead of a central dispatcher that assigns threads to processors, each
processor consults the local and global run queues to select the appropriate
nextthreadtorun.Threadsinthelocalrunqueuehaveabsolutepriorityover
thoseintheglobalqueues,becauseitisassumedthattheyareperformingsome
chore for the kernel. The run queues—like most other objects in Mach—are
locked when they are modified to avoid simultaneous changes by multiple
processors. To speed dispatching of threads on the global run queue, Mach
maintainsalistofidleprocessors.
Additionalschedulingdifficultiesarisefromthemultiprocessornatureof
Mach. A fixed time quantum is not appropriate because, for instance, there
may be fewer runnable threads than there are available processors. It would
bewastefultointerruptathreadwithacontextswitchtothekernelwhenthat
thread’s quantum runs out, only to have the thread be placed right back in
therunningstate.Thus,insteadofusingafixed-lengthquantum,Machvaries
thesizeofthetimequantuminverselywiththetotalnumberofthreadsinthe
system. It keeps the time quantum over the entire system constant, however.
Forexample,inasystemwith10processors,11threads,anda100-millisecond
quantum, a context switch needs to occur on each processor only once per
secondtomaintainthedesiredquantum.
Ofcourse,complicationsstillexist.EvenrelinquishingtheCPUwhilewait-
ing for aresourceismoredifficult than itis ontraditionaloperating systems.
First,a thread must issue a call to alert the scheduler that the thread is about
to block. This alert avoids race conditions and deadlocks, which could occur
whentheexecutiontakesplaceinamultiprocessorenvironment.Asecondcall
actuallycausesthethreadtobemovedofftherunqueueuntiltheappropriate
eventoccurs. The scheduler uses many other internal thread states to control
threadexecution.
D.4.4 Exception Handling
Machwasdesignedtoprovideasingle,simple,consistentexception-handling
system,withsupportforstandardaswellasuser-definedexceptions.Toavoid
redundancyinthekernel,Machuseskernelprimitiveswheneverpossible.For
instance, an exception handler is just another thread in the task in which the
exceptionoccurs.Remoteprocedurecall(RPC)messagesareusedtosynchro-
nizetheexecutionofthethreadcausingtheexception(thevictim)andthatof
thehandlerandtocommunicateinformationabouttheexceptionbetweenthe
victimandhandler.MachexceptionsarealsousedtoemulatetheBSDsignal
package.
Disruptionstonormalprogramexecutioncomeintwovarieties:internally
generated exceptions and external interrupts. Interrupts are asynchronously
generateddisruptionsofathreadortask,whereasexceptionsarecausedbythe
occurrenceofunusualconditionsduringathread’sexecution.Mach’sgeneral-
purpose exception facility is used for error detection and debugger support.12 AppendixD TheMachSystem
This facility is also useful for other functions, such as taking a core dump of
abadtask,allowingtaskstohandletheirownerrors(mostlyarithmetic),and
emulatinginstructionsnotimplementedinhardware.
Mach supports two different granularities of exception handling. Error
handling is supported by per-thread exception handling, whereas debuggers
useper-taskhandling.Itmakeslittlesensetotrytodebugonlyonethreadorto
haveexceptionsfrommultiplethreadsinvokemultipledebuggers.Asidefrom
thisdistinction,theonlydifferencebetweenthetwotypesofexceptionsliesin
theirinheritancefromaparenttask.Task-wideexception-handlingfacilitiesare
passedfromtheparenttochildtasks,sodebuggersareabletomanipulatean
entiretreeoftasks.Errorhandlersarenotinheritedanddefaulttonohandler
atthread-andtask-creationtime.Finally,errorhandlerstakeprecedenceover
debuggersiftheexceptionsoccursimultaneously.Thereasonforthisapproach
isthaterrorhandlersarenormallypartofthetaskandthereforeshouldexecute
normallyeveninthepresenceofadebugger.
Exceptionhandlingproceedsasfollows:
• The victim thread causes notification of an exception’s occurrence via a
raise()RPCmessagesenttothehandler.
• Thevictimthencallsaroutinetowaituntiltheexceptionishandled.
• Thehandlerreceivesnotificationoftheexception,usuallyincludinginfor-
mationabouttheexception,thethread,andthetaskcausingtheexception.
• Thehandlerperformsitsfunctionaccordingtothetypeofexception.The
handler’s action involves clearing the exception, causing the victim to
resume,orterminatingthevictimthread.
To support the execution of BSD programs, Mach needs to support BSD-
style signals. Signals provide software-generated interrupts and exceptions.
Unfortunately,signalsareoflimitedfunctionalityinmultithreadedoperating
systems.Thefirstproblemisthat,inUNIX,asignal’shandlermustbearoutine
inthe process receivingthe signal. Ifthe signal is causedby aproblem inthe
processitself(forexample,adivisionby0),theproblemcannot beremedied,
because a processhas limitedaccess toits own context. Asecond, more trou-
blesomeaspect ofsignals isthat they weredesignedfor only single-threaded
programs.Forinstance,itmakesnosenseforallthreadsinatasktogetasignal,
buthowcanasignalbeseenbyonlyonethread?
Becausethesignalsystemmustworkcorrectlywithmultithreadedappli-
cations for Mach to run 4.3BSD programs, signals could not be abandoned.
Producing a functionally correct signal package required several rewrites of
thecode,however.Afinal problemwithUNIXsignalsisthat theycanbelost.
Thislossoccurswhenanothersignalofthesametypeoccursbeforethefirstis
handled.MachexceptionsarequeuedasaresultoftheirRPCimplementation.
Externallygeneratedsignals,includingthosesentfromoneBSDprocessto
another,areprocessedbytheBSDserversectionoftheMach2.5kernel.Their
behavior is therefore the same as it is under BSD. Hardware exceptions are a
differentmatter,becauseBSDprogramsexpecttoreceivehardwareexceptions
assignals.Therefore,ahardwareexceptioncausedbyathreadmustarriveat
thethreadasasignal.Sothatthisresultisproduced,hardwareexceptionsareD.5 InterprocessCommunication 13
converted to exception RPCs. For tasks and threads that do not make explicit
useoftheMachexception-handlingfacility,thedestinationofthisRPCdefaults
to an in-kernel task. This task has only one purpose: Its thread runs in a
continuous loop, receiving the exception RPCs. For each RPC, it converts the
exceptionintotheappropriatesignal,whichissenttothethreadthatcausedthe
hardwareexception.ItthencompletestheRPC,clearingtheoriginalexception
condition.WiththecompletionoftheRPC,theinitiatingthreadreenterstherun
state.It immediatelyseesthe signal and executesits signal-handling code. In
this manner, all hardware exceptions begin in a uniform way—as exception
RPCs. Threads not designed to handle such exceptions, however, receive the
exceptions as they would on a standard BSD system—as signals. In Mach
3.0, the signal-handling code is moved entirely into a server, but the overall
structureandflowofcontrolissimilartothoseofMach2.5.
D.5 Interprocess Communication
Most commercial operating systems, such as UNIX, provide communication
between processes and between hosts with fixed, global names (or Internet
addresses).Thereisnolocationindependenceoffacilities,becauseanyremote
systemneedingtouseafacilitymustknowthenameofthesystemproviding
thatfacility.Usually,datainthemessagesareuntypedstreamsofbytes.Mach
simplifies this picture by sending messages between location-independent
ports. The messages contain typed data for ease of interpretation. All BSD
communicationmethodscanbeimplementedwiththissimplifiedsystem.
The two components of Mach IPC are ports and messages.Almost every-
thing in Mach is an object, and all objects are addressed via their commu-
nication ports. Messages are sent to these ports to initiate operations on the
objectsbytheroutinesthatimplementtheobjects.Bydependingononlyports
andmessagesforallcommunication,Machdeliverslocationindependenceof
objectsandsecurityofcommunication.Dataindependenceisprovidedbythe
NetMsgServertask(SectionD.5.3).
Mach ensures security by requiring that message senders and receivers
haverights.Arightconsistsofaportnameandacapability—sendorreceive—
onthatport,andismuchlikeacapabilityinobject-orientedsystems.Onlyone
taskmayhavereceiverightstoanygivenport,butmanytasksmayhavesend
rights. When an object is created, its creator also allocates a port to represent
theobjectandobtainstheaccessrightstothatport.Rightscanbegivenoutby
the creator of the object, including the kernel, and are passed in messages. If
the holder of a receiveright sends that right in a message,the receiverof the
message gains the right, and the sender loses it. Atask may allocate ports to
allow access to any objects it owns or for communication. The destruction of
eitheraportortheholderofthereceiverightcausestherevocationofallrights
tothatport,andthetasksholdingsendrightscanbenotifiedifdesired.
D.5.1 Ports
Aportisimplementedasaprotected,boundedqueuewithinthekernelofthe
system on which the object resides. If a queue is full, a sender may abort the14 AppendixD TheMachSystem
send,waitforaslottobecomeavailableinthequeue,orhavethekerneldeliver
themessage.
Severalsystemcallsprovidetheportwiththefollowingfunctionalities:
• Allocateanewportinaspecifiedtaskandgivethecaller’staskallaccess
rightstothenewport.Theportnameisreturned.
• Deallocateatask’saccessrightstoaport.Ifthetaskholdsthereceiveright,
theportisdestroyed,andallothertaskswithsendrightsare,potentially,
notified.
• Getthecurrentstatusofatask’sport.
• Createabackupport,whichisgiventhereceiverightforaportifthetask
containingthereceiverightrequestsitsdeallocationorterminates.
Whenataskiscreated,thekernelcreatesseveralportsforit.Thefunction
task self()returnsthenameoftheportthatrepresentsthetaskincallstothe
kernel.Forinstance,toallocateanewport,ataskcallsport allocate()with
task self() as the name of the task that will own the port. Thread creation
resultsinasimilarthread self()threadkernelport.This scheme is similar
tothestandardprocess-IDconceptfoundinUNIX.Anotherportisreturnedby
task notify();thisistheporttowhichthekernelwillsendevent-notification
messages(suchasnotificationsofportterminations).
Portscanalsobecollectedintoportsets.Thisfacilityisusefulifonethread
istoservicerequestscominginonmultipleports—forexample,formultiple
objects. A port may be a member of no more than one port set at a time.
Furthermore,ifaportisinaset,itmaynotbeuseddirectlytoreceivemessages.
Instead,messageswillberoutedtotheportset’squeue.Aportsetmaynotbe
passed in messages, unlike a port. Port sets are objects that serve a purpose
similartothe4.3BSDselect()systemcall,buttheyaremoreefficient.
D.5.2 Messages
Amessage consists of a fixed-length header and a variable number of typed
data objects. The header contains the destination’s port name, the name of
thereplyporttowhichreturnmessagesshouldbesent,andthelengthofthe
message (Figure D.5). The data in the message (or in-line data) were limited
to less than 8 KB in Mach 2.5 systems, but Mach 3.0 has no limit. Each data
sectionmaybeasimpletype(numbersorcharacters),portrights,orpointers
toout-of-linedata.Eachsectionhasanassociatedtype,sothatthereceivercan
unpack the data correctly even if it uses a byte ordering different from that
used by the sender. The kernel also inspects the message for certain types of
data.Forinstance,thekernelmustprocessportinformationwithinamessage,
eitherbytranslatingtheportnameintoaninternalportdatastructureaddress
orbyforwardingitforprocessingtotheNetMsgServer(SectionD.5.3).
Theuseofpointersinamessageprovidesthemeanstotransfertheentire
address space of a task in one single message. The kernel also must process
pointers to out-of-line data, since a pointer to data in the sender’s address
spacewouldbeinvalidinthereceiver’s—especiallyifthesenderandreceiver
resideondifferentsystems.Generally,systemssendmessagesbycopyingthe
datafromthesendertothereceiver.Becausethistechniquecanbeinefficient,
especiallyforlargemessages,Machtakesadifferentapproach.Thedatarefer-D.5 InterprocessCommunication 15
port
message queue message message
destination port
reply port
size/operation
pure typed data
port port rights
out-of-line-data
(cid:129) (cid:129) (cid:129)
message control
memory cache object memory cache object
FigureD.5 Machmessages.
enced by a pointer in a message being sent to a port on the same system are
not copied between the sender and the receiver. Instead, the address map of
thereceivingtaskismodifiedtoincludeacopy-on-writecopyofthepagesof
themessage.Thisoperationismuchfasterthanadatacopyandmakesmessage
passingmoreefficient.Inessence,messagepassingisimplementedviavirtual
memorymanagement.
In Version 2.5, this operation was implemented in two phases. Apointer
to a region of memory caused the kernel to map that region into its own
space temporarily, setting the sender’s memory map to copy-on-write mode
to ensure that any modifications did not affect the original version of the
data. When a message was received at its destination, the kernel moved its
mapping to the receiver’s address space, using a newly allocated region of
virtualmemorywithinthattask.
InVersion3,thisprocesswassimplified.Thekernelcreatesadatastructure
thatwouldbeacopyoftheregionifitwerepartofanaddressmap.Onreceipt,
thisdatastructureisaddedtothereceiver’smapandbecomesacopyaccessible
tothereceiver.
The newly allocated regions in a task do not need to be contiguous with
previous allocations, so Mach virtual memory is said to be sparse, consisting
ofregionsofdataseparatedbyunallocatedaddresses.Afullmessagetransfer
isshowninFigureD.6.
D.5.3 The NetMsgServer
Foramessagetobe sentbetweencomputers,themessage’sdestinationmust
belocated,andthemessagemustbetransmittedtothedestination.UNIXtra-
ditionallyleavesthesemechanismstothelow-levelnetworkprotocols,which
requirethe useofstaticallyassignedcommunication endpoints(for example,16 AppendixD TheMachSystem
A B A B
P1 P1
A map kernel map B map A map kernel map B map
send operation receive operation
FigureD.6 Machmessagetransfer.
the port number for services based on TCP or UDP). One of Mach’s tenets is
that all objects within the system are location independent and that the loca-
tion is transparent to the user. This tenet requires Mach to provide location-
transparentnamingandtransporttoextendIPCacrossmultiplecomputers.
ThisnamingandtransportareperformedbytheNetworkMessageServer
(NetMsgServer), a user-level, capability-based networking daemon that for-
wards messages between hosts. It also provides a primitive network-wide
nameservicethatallowstaskstoregisterportsforlookupbytasksonanyother
computerinthenetwork.Machportscanbetransferredonlyinmessages,and
messagesmustbesenttoports.Theprimitivenameservicesolvestheproblem
oftransferringthefirstport.SubsequentIPCinteractionsarefullytransparent,
because the NetMsgServer tracks all rights and out-of-line memory passed
in intercomputer messages and arranges for the appropriate transfers. The
NetMsgServers maintain among themselves a distributed database of port
rightsthathavebeentransferredbetweencomputersandoftheportstowhich
theserightscorrespond.
The kernel uses the NetMsgServer when a message needs to be sent to
a port that is not on the kernel’s computer. Mach’s kernel IPC is used to
transferthe messagetothelocal NetMsgServer.TheNetMsgServerthenuses
whatevernetworkprotocolsareappropriatetotransferthemessagetoitspeer
ontheothercomputer.ThenotionofaNetMsgServerisprotocolindependent,
and NetMsgServers have been built to use various protocols. Of course, the
NetMsgServersinvolvedinatransfermustagreeontheprotocolused.Finally,
the NetMsgServeron the destination computer uses that kernel’s IPC to send
themessagetothecorrectdestinationtask.
TheabilitytoextendlocalIPCtransparentlyacrossnodesissupportedby
theuseofproxyports.Whenasendrightistransferredfromonecomputerto
another, the NetMsgServer on the destination computer creates a new port,
or proxy, to represent the original port at the destination. Messages sent to
thisproxyarereceivedbytheNetMsgServerandareforwardedtransparentlyD.5 InterprocessCommunication 17
to the original port. This procedure is one example of how NetMsgServers
cooperatetomakeaproxyindistinguishablefromtheoriginalport.
BecauseMachisdesignedtofunctioninanetworkofheterogeneoussys-
tems,itmustprovideawayforsystemstosenddataformattedinawaythatis
understandablebyboththesenderandthereceiver.Unfortunately,computers
differ in the formats they use to store various types of data. For instance, an
integerononesystemmighttake2bytestostore,andthemostsignificantbyte
mightbestoredbeforetheleastsignificantone.Anothersystemmightreverse
thisordering.TheNetMsgServerthereforeusesthetypeinformationstoredin
a message to translate the data from the sender’s to the receiver’s format. In
thisway,alldataarerepresentedcorrectlywhentheyreachtheirdestination.
The NetMsgServer on a given computer accepts RPCs that add, look up,
andremovenetworkportsfromtheNetMsgServer’snameservice.Asasecu-
rityprecaution,aportvalueprovidedinanaddrequestforaportmustmatch
that in the remove request for a thread to ask for a port name to be removed
fromthedatabase.
AsanexampleoftheNetMsgServer’soperation,considerathreadonnode
A sending a message to a port that happens to be in a task on node B. The
program simply sends a message to a port to which it has a send right. The
message is first passed to the kernel, which delivers it to its first recipient,
the NetMsgServer on node A. The NetMsgServer then contacts (through its
database information) the NetMsgServer on node B and sends the message.
The NetMsgServer on node B presents the message to the kernel with the
appropriate local port for node B. The kernel finally provides the message to
the receiving task when a thread in that task executes a msg receive() call.
ThissequenceofeventsisshowninFigureD.7.
Mach 3.0 provides an alternative to the NetMsgServer as part of its
improvedsupportforNORMAmultiprocessors.TheNORMAIPCsubsystemof
Mach3.0implementsfunctionalitysimilartotheNetMsgServerdirectlyinthe
system A system B
user user
process process
NetMsg- NetMsg-
server server
kernel kernel
sender receiver
FigureD.7 NetworkIPCforwardingbyNetMsgServer.18 AppendixD TheMachSystem
Machkernel,providingmuchmoreefficientinternodeIPCformulticomputers
withfastinterconnectionhardware.Forexample,thetime-consumingcopying
of messages between the NetMsgServer and the kernel is eliminated. Use of
theNORMAIPCdoesnotprecludeuseoftheNetMsgServer;theNetMsgServer
canstillbeusedtoprovideMachIPCserviceovernetworksthatlinkaNORMA
multiprocessor to other computers. In addition to the NORMA IPC, Mach 3.0
also providessupport for memory management across a NORMAsystem and
enables a task in such a system to create child tasks on nodes other than its
own. These features support the implementation of a single-system-image
operating system on a NORMA multiprocessor. The multiprocessor behaves
like one large system rather than an assemblage of smaller systems (for both
usersandapplications).
D.5.4 Synchronization Through IPC
The IPC mechanism is extremely flexible and is used throughout Mach. For
example,itmay beusedforthreadsynchronization. Aportmaybeusedasa
synchronization variable and may have n messages sent to it for n resources.
Anythreadwishingtousearesourceexecutesareceivecallonthatport.The
threadwillreceiveamessageiftheresourceisavailable.Otherwise,itwillwait
ontheportuntilamessageisavailablethere.Toreturnaresourceafteruse,the
threadcansendamessagetotheport.Inthisregard,receivingisequivalentto
thesemaphoreoperationwait(),andsendingisequivalenttosignal().This
methodcanbeusedforsynchronizingsemaphoreoperationsamongthreadsin
thesametask,butitcannotbeusedforsynchronizationamongtasks,because
only one task may have receive rights to a port. For more general-purpose
semaphores,asimpledaemoncanbewrittentoimplementthesamemethod.
D.6 Memory Management
Given the object-oriented nature of Mach, it is not surprising that a principal
abstractioninMachisthememoryobject.Memoryobjectsareusedtomanage
secondary storage and generally represent files, pipes, or other data that are
mapped into virtual memory for reading and writing (Figure D.8). Memory
objectsmaybebackedbyuser-levelmemorymanagers,whichtaketheplaceof
themoretraditionalkernel-incorporatedvirtualmemorypagerfoundinother
operatingsystems.Incontrasttothetraditionalapproachofhavingthekernel
manage secondary storage, Mach treats secondary-storage objects (usually
files)asitdoesallotherobjectsinthesystem.Eachobjecthasaportassociated
withitandmaybemanipulatedbymessagessenttoitsport.Memoryobjects
—unlikethememory-managementroutinesinmonolithic,traditionalkernels
—alloweasyexperimentationwithnewmemory-manipulationalgorithms.
D.6.1 Basic Structure
Thevirtualaddressspaceofataskisgenerallysparse,consistingofmanyholes
ofunallocatedspace.Forinstance,amemory-mappedfileisplacedinsomeset
ofaddresses.Largemessagesarealsotransferredassharedmemorysegments.
For each of these segments, a section of virtual memory address is used to
providethethreadswithaccesstothemessage.AsnewitemsaremappedorD.6 MemoryManagement 19
user
address
space
previous entry
next entry
head tail
address space
start/end
initialized uninitialized
text stack inheritance
data data
protection
current/max
object
cached
pages
offset therein
port for
secondary
storage map entry
virtual memory
object
FigureD.8 Machvirtualmemorytaskaddressmap.
removedfrom the address space, holes of unallocated memory appear in the
addressspace.
Mach makes no attempt to compress the address space, although a task
mayfail(orcrash)ifithasnoroomforarequestedregioninitsaddressspace.
Given that address spaces are 4 GB or more, this limitation is not currently a
problem.However,maintainingaregularpagetablefora4-GBaddressspace
foreachtask,especiallyone withholesinit,would useexcessiveamounts of
memory (1 MB or more). The key to sparse address spaces is that page-table
spaceisusedonlyforcurrentlyallocatedregions.Whenapagefaultoccurs,the
kernelmustchecktoseewhetherthepageisinavalidregion,ratherthansim-
plyindexingintothepagetableandcheckingtheentry.Althoughtheresulting
lookupismorecomplex,thebenefitsofreducedmemory-storagerequirements
andsimpleraddress-spacemaintenancemaketheapproachworthwhile.
Machalsohassystemcallstosupportstandardvirtualmemoryfunction-
ality, including the allocation, deallocation, and copying of virtual memory.
When allocating a new virtual memory object, the thread may provide an
addressfortheobjectormayletthekernelchoosetheaddress.Physicalmem-
oryisnotallocateduntilpagesinthisobjectareaccessed.Theobject’sbacking
storeismanagedbythedefaultpager(SectionD.6.2).Virtualmemoryobjects20 AppendixD TheMachSystem
are also allocated automatically when a task receives a message containing
out-of-linedata.
Associated system calls return information about a memory object in a
task’s address space, change the access protection of the object, and specify
howanobjectistobepassedtochildtasksatthetimeoftheircreation(shared,
copy-on-write,ornotpresent).
D.6.2 User-Level Memory Managers
Asecondary-storage object is usually mapped into the virtual address space
of a task. Mach maintains a cache of memory-resident pages of all mapped
objects, as in other virtual memory implementations. However, a page fault
occurringwhenathreadaccessesanonresidentpageisexecutedasamessage
to the object’s port. The concept that a memory object can be created and
serviced by nonkernel tasks (unlike threads, for instance, which are created
andmaintainedonlybythekernel)isimportant.Theendresultisthat,inthe
traditional sense, memory can be paged by user-written memory managers.
When the object is destroyed, it is up to the memory manager to write back
anychangedpagestosecondarystorage.NoassumptionsaremadebyMach
aboutthecontentorimportanceofmemoryobjects,sothememoryobjectsare
independentofthekernel.
In several circumstances, user-level memory managers are insufficient.
For instance, a task allocating a new region of virtual memory might not
haveamemorymanagerassignedtothatregion,sinceitdoesnotrepresenta
secondary-storageobject(butmustbepaged),oramemorymanagermightfail
toperformpageout.Machitselfalsoneedsamemorymanagertotakecareof
itsmemoryneeds.Forthesecases,Machprovidesadefaultmemorymanager.
TheMach2.5defaultmemorymanagerusesthestandardfilesystemtostore
datathatmustbewrittentodisk,ratherthanrequiringaseparateswapspace,
asin4.3BSD.InMach3.0(andOSF/1),thedefaultmemorymanageriscapable
ofusingeitherfilesinastandardfilesystemordedicateddiskpartitions.The
defaultmemorymanagerhasaninterfacesimilartothatoftheuser-levelones,
butwithsomeextensionstosupportitsroleasthememorymanagerthatcan
bereliedontoperformpageoutwhenuser-levelmanagersfailtodoso.
Pageout policy is implemented by an internal kernel thread, the pageout
daemon.ApagingalgorithmbasedonFIFOwithsecondchance(Section10.4.5)
is used to select pages for replacement. The selected pages are sent to the
appropriatemanager (eitheruserlevelor default)for actual pageout.Auser-
level manager may be more intelligent than the default manager, and it may
implementadifferentpagingalgorithmsuitabletotheobjectitisbacking(that
is, by selecting some other page and forcibly paging it out). If a user-level
manager fails to reduce the resident set of pages when asked to do so by the
kernel,thedefaultmemorymanagerisinvoked,anditpagesouttheuser-level
managertoreducetheuser-levelmanager’sresidentsetsize.Shouldtheuser-
levelmanagerrecoverfromtheproblemthatpreventeditfromperformingits
own pageouts, it will touch these pages (causing the kernel to page them in
again)andcanthenpagethemoutasitseesfit.
If a thread needs access to data in a memory object (for instance, a file),
it invokes the vm map() system call. Included in this system call is a port
that identifies the object and the memory manager that is responsible for theD.6 MemoryManagement 21
region. The kernel executes calls on this port when data are to be read or
writteninthatregion.Anaddedcomplexityisthatthekernelmakesthesecalls
asynchronously, since it would not be reasonable for the kernelto be waiting
on a user-level thread. Unlike the situation with pageout, the kernel has no
recourse if its request is not satisfied by the external memory manager. The
kernelhasnoknowledgeofthecontentsofanobjectorofhowthatobjectmust
bemanipulated.
Memory managers are responsible for the consistency of the contents of
a memory object mapped by tasks on different machines. (Tasks on a single
machineshareasinglecopyofamappedmemoryobject.)Considerasituation
in which tasks on two different machines attempt to modify the same page
ofanobject atthesametime.Itisuptothemanager todecidewhetherthese
modificationsmustbeserialized.Aconservativemanagerimplementingstrict
memory consistency would force the modifications to be serialized by grant-
ing write access to only one kernel at a time. Amore sophisticated manager
couldallowbothaccessestoproceedconcurrently(forexample,ifthemanager
knew that the two tasks were modifying distinct areas within the page and
that it could merge the modifications successfully at some future time). Most
externalmemory managerswrittenforMach (for example,those implement-
ing mapped files) do not implement logic for dealing with multiple kernels,
duetothecomplexityofsuchlogic.
Whenthefirstvm map()callismadeonamemoryobject,thekernelsends
amessagetothememorymanagerportpassedinthecall,invokingthemem-
ory manager init() routine, which the memory manager must provide as
part of its support of a memory object. The two ports passed to the mem-
ory manager are a control port and a name port. The control port is used
by the memory manager to provide data to the kernel—for example, pages
to be made resident. Name ports are used throughout Mach. They do not
receivemessages but are used simply as points of reference and comparison.
Finally, the memory object must respond to a memory manager init() call
with a memory object set attributes() call to indicate that it is ready to
acceptrequests.Whenalltaskswithsendrightstoamemoryobjectrelinquish
thoserights,thekerneldeallocatestheobject’sports,thusfreeingthememory
managerandmemoryobjectfordestruction.
Severalkernelcallsareneededtosupportexternalmemorymanagers.The
vm map() call was just discussed. In addition, some commands get and set
attributes and provide page-level locking when it is required (for instance,
after a page fault has occurred but before the memory manager has returned
theappropriatedata).Anothercallisusedbythememorymanagertopassa
page(ormultiplepages,ifread-aheadisbeingused)tothekernelinresponse
to a page fault. This call is necessary since the kernel invokes the memory
manager asynchronously. Finally,severalcalls allowthe memory manager to
reporterrorstothekernel.
Thememorymanageritselfmustprovidesupportforseveralcallssothatit
cansupportanobject.Wehavealreadydiscussedmemory object init()and
others.Whenathreadcausesapagefaultonamemoryobject’spage,theker-
nel sends a memory object data request() to the memory object’s port on
behalfofthefaultingthread.Thethreadisplacedinawaitstateuntilthemem-
ory manager either returns the page in a memory object data provided()
call or returns an appropriate error to the kernel. Any of the pages that have22 AppendixD TheMachSystem
beenmodified,orany“preciouspages”thatthekernelneedstoremovefrom
resident memory (due to page aging, for instance), are sent to the memory
object via memory object data write(). Precious pages are pages that may
nothavebeenmodifiedbutthatcannotbediscardedastheyotherwisewould
bebecausethememorymanagernolongerretainsacopy.Thememoryman-
agerdeclaresthesepagestobepreciousandexpectsthekerneltoreturnthem
whentheyareremovedfrommemory.Preciouspagessaveunnecessarydupli-
cationandcopyingofmemory.
In the current version, Mach does not allow external memory managers
to affect the page-replacement algorithm directly. Mach does not export the
memory-accessinformationthatwouldbeneededforanexternaltasktoselect
theleastrecentlyusedpage,forinstance.Methodsofprovidingsuchinforma-
tion are currently under investigation. An external memory manager is still
usefulforavarietyofreasons,however:
• Itmayrejectthekernel’sreplacementvictimifitknowsofabettercandi-
date(forinstance,MRUpagereplacement).
• It may monitor the memory object it is backing and request pages to be
pagedoutbeforethememoryusageinvokesMach’spageoutdaemon.
• Itisespeciallyimportantinmaintainingconsistencyofsecondarystorage
forthreadsonmultipleprocessors,asweshowinSectionD.6.3.
• It can control the order of operations on secondary storage to enforce
consistencyconstraintsdemandedbydatabasemanagementsystems.For
example,intransactionlogging,transactionsmustbewrittentoalogfile
ondiskbeforetheymodifythedatabasedata.
• Itcancontrolmappedfileaccess.
D.6.3 Shared Memory
Mach uses shared memory toreduce the complexityof various system facili-
ties,aswellastoprovidethesefeaturesinanefficientmanner.Sharedmemory
generally providesextremelyfast interprocesscommunication, reduces over-
headinfilemanagement,andhelpstosupportmultiprocessinganddatabase
management. Mach does not use shared memory for all these traditional
shared-memory roles, however. For instance, all threads in a task share that
task’s memory, so no formal shared-memory facility is needed within a task.
However,Machmuststillprovidetraditionalsharedmemorytosupportother
operating-systemconstructs,suchastheUNIXfork()systemcall.
Itisobviouslydifficultfortasksonmultiplemachinestosharememoryand
tomaintaindataconsistency.Machdoesnottrytosolvethisproblemdirectly;
rather,itprovidesfacilitiestoallowtheproblemtobesolved.Machsupports
consistentsharedmemoryonlywhenthememoryissharedbytasksrunning
onprocessorsthatsharememory.Aparenttaskisabletodeclarewhichregions
of memory are to be inherited by its children and which are to be readable
–writable. This scheme is different from copy-on-write inheritance, in which
each task maintains its own copy of any changed pages. Awritable object is
addressedfromeachtask’saddressmap,andallchangesaremadetothesame
copy. The threads within the tasks are responsible for coordinating changes
to memory so that they do not interfere with one another (by writing to theD.7 ProgrammerInterface 23
same location concurrently). This coordination can be done through normal
synchronizationmethods:criticalsectionsormutual-exclusionlocks.
Forthecaseofmemorysharedamongseparatemachines,Machallowsthe
useofexternalmemorymanagers.Ifasetofunrelatedtaskswishestosharea
sectionofmemory,thetaskscanusethesameexternalmemorymanagerand
access the same secondary-storage areas through it. The implementor of this
systemwouldneedtowritethetasksandtheexternalpager.Thispagercould
be as simple or as complicated as needed. A simple implementation would
allownoreaderswhileapagewasbeingwrittento.Anywriteattemptwould
cause the pager to invalidate the page in all tasks currently accessing it. The
pager would then allow the write and would revalidate the readers with the
newversionofthepage.Thereaderswouldsimplywaitonapagefaultuntil
thepageagainbecameavailable.Machprovidessuchamemorymanager:the
Network Memory Server (NetMemServer). For multicomputers, the NORMA
configuration of Mach 3.0 provides similar support as a standard part of the
kernel. This XMM subsystem allows multicomputer systems to use external
memory managers that do not incorporate logic for dealing with multiple
kernels. The XMM subsystem is responsible for maintaining data consistency
among multiple kernels that share memory and makes these kernels appear
tobeasinglekerneltothememorymanager.TheXMMsubsystemalsoimple-
ments virtual copy logic for the mapped objects that it manages. This virtual
copylogicincludesbothcopy-on-referenceamongmulticomputerkernelsand
sophisticatedcopy-on-writeoptimizations.
D.7 Programmer Interface
AprogrammercanworkatseverallevelswithinMach.Thereis,ofcourse,the
system-call level, which, in Mach 2.5, is equivalent to the 4.3BSD system-call
interface. Version 2.5 includes most of 4.3BSD as one thread in the kernel. A
BSD system call traps to the kernel and is serviced by this thread on behalf
of the caller, much as standard BSD would handle it. The emulation is not
multithreaded,soithaslimitedefficiency.
Mach 3.0 has moved from the single-servermodel to support of multiple
servers. It has therefore become a true microkernel without the full features
normallyfoundinakernel.Rather,fullfunctionalitycanbeprovidedviaemu-
lationlibraries,servers,oracombinationofthetwo.Inkeepingwiththedefini-
tionofamicrokernel,theemulationlibrariesandserversrunoutsidethekernel
atuserlevel.Inthisway,multipleoperatingsystemscanrunconcurrentlyon
oneMach3.0kernel.
Anemulationlibraryisasetofroutinesthatlivesinaread-onlypartofa
program’s addressspace. Any operating-systemcalls the program makes are
translated into subroutine calls to the library. Single-user operating systems,
suchasMS-DOSandtheMacintoshoperatingsystem,havebeenimplemented
solelyasemulationlibraries.Forefficiencyreasons,theemulationlibrarylives
intheaddressspaceoftheprogramneedingitsfunctionality;intheory,how-
ever,itcouldbeaseparatetask.
Morecomplexoperatingsystemsareemulatedthroughtheuseoflibraries
andoneormoreservers.Systemcallsthatcannotbeimplementedinthelibrary
are redirected to the appropriate server. Servers can be multithreaded for24 AppendixD TheMachSystem
improvedefficiency;BSDandOSF/1areimplementedassinglemultithreaded
servers. Systems can be decomposed into multiple servers for greater modu-
larity.
Functionally, a system call starts in a task and passes through the kernel
beforebeingredirected,ifappropriate,tothelibraryinthetask’saddressspace
ortoaserver.Althoughthisextratransferofcontroldecreasestheefficiencyof
Mach,thisdecreaseisbalancedtosomeextentbytheabilityofmultiplethreads
toexecuteBSD-likecodeconcurrently.
AtthenexthigherprogramminglevelistheCthreadspackage.Thispack-
ageisarun-timelibrarythatprovidesaClanguageinterfacetothebasicMach
threads primitives. It provides convenient access to these primitives, includ-
ing routines for theforking and joining ofthreads,mutual exclusionthrough
mutex variables (Section D.4.2), and synchronization through use of condi-
tion variables. Unfortunately, it is not appropriate for the C threads package
tobe usedbetweensystemsthat sharenomemory(NORMAsystems),sinceit
dependsonsharedmemorytoimplementitsconstructs.Thereiscurrentlyno
equivalentofCthreadsforNORMAsystems.Otherrun-timelibrarieshavebeen
writtenforMach,includingthreadssupportforotherlanguages.
Although the use of primitives makes Mach flexible, it also makes many
programming tasks repetitive. For instance, significant amounts of code are
associated with sending and receiving messages in each task that uses mes-
sages(which,inMach,ismosttasks).ThedesignersofMachthereforeprovide
aninterfacegenerator(orstubgenerator)calledMIG.MIGisessentiallyacom-
pilerthattakesasinputadefinitionoftheinterfacetobeused(declarationsof
variables,types,andprocedures)andgeneratestheRPCinterfacecodeneeded
to send and receive the messages fitting this definition and to connect the
messagestothesendingandreceivingthreads.
D.8 Summary
TheMach operatingsystemisdesignedtoincorporate themany recentinno-
vationsinoperating-systemresearchtoproduceafullyfunctional,technically
advancedoperatingsystem.
TheMachoperatingsystemwasdesignedwiththreecriticalgoalsinmind:
• Emulate 4.3BSD UNIX so that the executable files from a UNIX system can
runcorrectlyunderMach.
• Haveamodernoperatingsystemthatsupportsmanymemorymodelsand
parallelanddistributedcomputing.
• Designakernelthatissimplerandeasiertomodifythanis4.3BSD.
Aswehaveshown,Machiswellonitswaytoachievingthesegoals.
Mach 2.5 includes 4.3BSD in its kernel, which provides the emulation
neededbutenlargesthekernel.This4.3BSDcodehasbeenrewrittentoprovide
the same4.3functionality but tousethe Machprimitives.This change allows
the4.3BSDsupportcodetoruninuserspaceonaMach3.0system.FurtherReading 25
Mach uses lightweight processes, in the form of multiple threads of exe-
cution within one task (or address space), to support multiprocessing and
parallel computation. Its extensive use of messages as the only communica-
tion method ensures that protection mechanisms are complete and efficient.
By integrating messages with the virtual memory system, Mach also ensures
thatmessagescanbehandledefficiently.Finally,byhavingthevirtualmemory
systemusemessagestocommunicatewiththedaemonsmanagingthebacking
store,Machprovidesgreatflexibilityinthedesignandimplementationofthese
memory-object-managingtasks.
By providinglow-level,or primitive,system calls from which more com-
plexfunctionscanbebuilt,Machreducesthesizeofthekernelwhilepermitting
operating-systememulationattheuserlevel,muchlikeIBM’svirtualmachine
systems.
Further Reading
TheAccentoperatingsystemwasdescribedby[RashidandRobertson(1981)].
A historical overview of the progression from an even earlier system, RIG,
through Accent to Mach was given by [Rashid (1986)]. General discussions
concerningtheMachmodelwereofferedby[Tevanianetal.(1989)].
[Accettaetal.(1986)]presentedanoverviewoftheoriginaldesignofMach.
The Mach scheduler was described in detail by [Tevanian et al. (1987a)] and
[Black (1990)]. An early version of the Mach shared memory and memory-
mappingsystemwaspresented[Tevanianetal.(1987b)].
Bibliography
[Accettaetal.(1986)] M.Accetta,R.Baron,W.Bolosky,D.B.Golub,R.Rashid,
A.Tevanian,andM.Young,“Mach:ANewKernelFoundationforUNIXDevel-
opment”,ProceedingsoftheSummerUSENIXConference(1986),pages93–112.
[Black(1990)] D. L. Black, “Scheduling Support for Concurrency and Paral-
lelism in the Mach Operating System”, IEEE Computer, Volume 23, Number 5
(1990),pages35–43.
[Rashid(1986)] R.F.Rashid,“FromRIGtoAccenttoMach:TheEvolutionofa
NetworkOperatingSystem”,ProceedingsoftheACM/IEEEComputerSociety,Fall
JointComputerConference(1986),pages1128–1137.
[RashidandRobertson(1981)] R. Rashid and G. Robertson, “Accent: ACom-
munication-Oriented Network Operating System Kernel”, Proceedings of the
ACMSymposiumonOperatingSystemPrinciples(1981),pages64–75.
[Tevanianetal.(1987a)] A.Tevanian,Jr.,R.F.Rashid,D.B.Golub,D.L.Black,
E.Cooper,andM.W.Young,“MachThreadsandtheUnixKernel:TheBattlefor
Control”,ProceedingsoftheSummerUSENIXConference(1987).
[Tevanianetal.(1987b)] A.Tevanian,Jr.,R.F.Rashid,M.W.Young,D.B.Golub,
M. R. Thompson, W. Bolosky, and R. Sanzi, “A UNIX Interface for Shared26 AppendixD TheMachSystem
MemoryandMemoryMappedFilesUnderMach”,Technicalreport,Carnegie-
MellonUniversity(1987).
[Tevanianetal.(1989)] A. Tevanian, Jr., and B. Smith, “Mach: The Model for
FutureUnix”,Byte(1989).Credits
• Figure1.14:FromHennesyandPatterson,ComputerArchitecture:AQuan-
titativeApproach,ThirdEdition,(cid:2)c2002,MorganKaufmannPublishers,Fig-
ure5.3,p.394.Reprintedwithpermissionofthepublisher.
• Figure 5.19: From Khanna/Sebree/Zolnowsky, “Realtime Scheduling in
SunOS5.0,”ProceedingsofWinterUSENIX,January1992,SanFrancisco,
California.Derivedwithpermissionoftheauthors.
• Figure5.30adaptedwithpermissionfromSunMicrosystems,Inc.
• Figure 10.20: From IBM Systems Journal, Vol. 10, No. 3, (cid:2)c1971, Interna-
tional Business Machines Corporation. Reprinted by permission of IBM
Corporation.
• Figure12.5:BasedonatablefromPentiumProcessorUser’sManual:Archi-
tectureandProgrammingManual,Volume3,(cid:2)c1993.
• Figure14.8:FromLeffler/McKusick/Karels/Quarterman,TheDesignand
Implementation of the 4.3BSD UNIX Operating System, (cid:2)c1989 by Addison-
Wesley Publishing Co., Inc., Reading, Massachusetts. Figure 7.6, p. 196.
Reprintedwithpermissionofthepublisher.
• Figures19.5,19.6,and19.8:FromHalsall,DataCommunications,Computer
Networks, and Open Systems, Third Edition, (cid:2)c1992, Addison-Wesley Pub-
lishingCo.,Inc.,Reading,Massachusetts.Figure1.9,p.14,Figure1.10,p.
15,andFigure1.11,p.18.Reprintedwithpermissionofthepublisher.
963Index
4-bytepages,363,364 mandatory,684-685
32-bytememory,363,364 role-based,683-684
50-percentrule,359 access-controllists(ACLs),552,555,826
64-bitcomputing,383 accessedbits,437
accessmask,849
A accessmatrix,675-685
defined,675
ABI(applicationbinaryinterface),78-79 implementationof,679-682
abortingprocesses,342 andmandatoryaccesscontrol,684-685
absolutecode,352 andrevocationofaccessrights,682-683
absolutepathnames,546 androle-basedaccesscontrol,683-684
abstractdatatype(ADT),277-278 accessrights,534,673,680,682-683
access,539-541 accounting,110,659,788
anonymous,605 ACG(ArbitraryCodeGuard),827
controlling,552-554 acknowledgmentpacket,748
direct(relative),539-541 ACLs,seeaccess-controllists
effectiveaccesstime,397-398 ACPI(advancedconfiguratio andpower
kernelobject,884-885 interface),516
lightweightdirectory-accessprotocol, activationrecord,107
607,884 activedirectory,607,884
memory,15,18,19,418-419,498-500 acyclicgraphs,547
processmigrationfor,753 acyclic-graphdirectories,547-549
andprotection,551 additional-reference-bitsalgorithm,
random-accessdevices,502 409-410
random-accesstime,450 additionalsensecode,512
read,292 additionalsense-codequalifie,512
relative,539-540 address(es):
RemoteAccessTool,625 defined,496
remotefile,764-767 linear,380,382
securityaccesstokens,662 logical,353,379
sequential,539,541 MAC,745
wirelessaccesspoints,736 physical,354,379
write,292 trusted,638
accesscontrol: virtual,354
discretionary,684 addressbinding,352-353
inLinux,816-818 addressmapping,456-457
MACaddress,745 addressresolutionprotocol(ARP),745
965966 Index
addressspace: processhierarchy,122-123
logicalvs.physical,353-355 protectiondomain,675
virtual,390,391,799-800 RPC,151-153
address-spaceidentifier (ASIDs),366 threadpools,178
address-spacelayoutrandomization TrustZone,670,671
(ASLR),656,827 anomalydetection,656
AddressWindowExtension(AWE) anonymousaccess,605
memory,894-895 anonymousmemory,399,469
admission-controlalgorithms,230 anonymouspipes,141-145
ADT(abstractdatatype),277-278 AOT(ahead-of-time)compilation,89,90
advancedconfiguratio andpower APCs(asynchronousprocedurecalls),
interface(ACPI),516 189-190,846
advancedencryptionstandard(AES),640 APFS(AppleFileSystem),592
advancedlocalprocedurecall(ALPC), API(applicationprograminterface),
138,834 63-66.Seealsospecifictypes
advancedtechnologyattachment(ATA) appendingfiles 551
buses,456 AppleFileSystem(APFS),592
advisoryfile-lockin mechanisms,535 applicationbinaryinterface(ABI),78-79
AES(advancedencryptionstandard),640 applicationcomponent,151-152
affinit ,processor,225-226 ApplicationContainer,868
age,page,800 applicationcontainment,703,718-719
aging,213 applicationframeworkslayer(macOS
ahead-of-time(AOT)compilation,89,90 andiOS),87
alertablethreads,846 applicationinterface(I/Osystems),
allocation: 500-508
buddy-system,427,428 blockandcharacterdevices,503-504
committing,852 clocksandtimers,505-506
contiguous,356-360,570-573 networkdevices,504-505
equal,414 nonblockingandasynchronousI/O,
frame,413-419 506-507
freeframesbeforeandafter,364 applicationlayer(OSImodel),742
global,415-418 applicationprograms(apps),4,75,823
indexed,575-577 compatibilityof,830-831
kernelmemory,426-430 disinfectionof,658
linked,573-575 packaged,859
local,415-418 securityof,624
over-,401 specificityof,77-79
proportional,414-415 systemservices,75
resource,57 userIDsfor,675
ofsecondarystorage,570-578 applicationprograminterface(API),
slab,427-430,797-798 63-66.Seealsospecifictypes
Allocation(datastructure),335,336,339 applicationproxyfire alls,660
allocationproblem,358,540,571 applicationstate,378
ALPC(advancedlocalprocedurecall), Aquainterface,59,87
138,834 ArbitraryCodeGuard(ACG),827
altitudes,863 architecture(s),15-21
AMD64architecture,382 AMD64,382
Amdahl’sLaw,164 ARMv8,383-384,671,672
AMDvirtualizationtechnology big.LITTLE,226-227
(AMD-V),710-711 clusteredsystems,19-21
amplification write,462 IA-32,379-382
analyticevaluation,245 IA-64,382
Andrewfil system(OpenAFS),759 multiprocessing,124
Androidoperatingsystem,89-91 multiprocessorsystems,16-19Index 967
NFS,614 andencryption,641-644
single-processorsystems,15-16 inLinux,816
vonNeumann,12 multifactor,653
x86-64,382 two-factor,652
Arduino,70 user,648-653
argumentvector,787 automaticworking-settrimming,438
armoredviruses,634 automountfeature,763
ARMv8architecture,383-384,671,672 autoprobes,785
ARP(addressresolutionprotocol),745 availability,breachof,622
arrays: Available(datastructure),334,336,338
redundant,seeRAID[redundantarrays AWEmemory,894-895
ofinexpensivedisks]
storage,472-473,481 B
ASICs,46
ASIDs(address-spaceidentifiers) 366 backdoor,503,626,627,638
ASLR(address-spacelayout backgroundclass,186
randomization),656,827 backgroundprocesses,74-75,115,123,
assignmentedge,323 215,241
asymmetricclustering,19 backingstore,376
asymmetricencryption,641,645 back-pointers,682
asymmetricencryptionalgorithm,641 backups,588-589
asymmetricmultiprocessing,220 badblocks,466-467
asymmetry,inaddressing,129 bad-clusterfile,877
asynchronouscancellation,190 badpage,856
asynchronousdevices,502,506-507 balance,inmulticoreprogramming,163
asynchronousmessagepassing,130 balancedbinarysearchtrees,38
asynchronousprocedurecalls(APCs), balloonmemorymanager,721
189-190,846 bandwidth,457
asynchronousthreading,169 banker’salgorithm,333-337
asynchronouswrites,585 barriers,memory,265-266
ATAbuses,456 basedsections,852
"atmostonce"functionality,150 basefil record,876
atomicinstructions,266,269 baseregister,351-352
atomicsafe-save,592 bash(bourne-againshell),58,783
atomicvariables,269-270 basicfilesystems,564,565
attacks,622 Bayes’theorem,657
buffer-overflow,628-631 BCC(BPFCompilerCollection),98-100
code-injection,628-631 Belady’sanomaly,406
codereuse,827 best-fi strategy,358,359
denial-of-service,622,636 BGP(BorderGatewayProtocol),745
informationleak,827 bigcores,226-227
man-in-the-middle,623,635,645 bigdata,22
replay,622 big-endian,150
withtunneling,659-660 big.LITTLEarchitecture,226-227
zero-day,656 binaryformat,785
attackers,622 binarygeneraltree,38
attacksurface,624 binarysearchtrees,38,39
attributes,551,826,875-876 binarysemaphore,273
attribute-definitio table,877 binarytranslation,708-710
auditing,659 binarytrees,38,39
audittrail,669 binders,151
augmented-realityapplications,42 binding,352
authentication: biometrics,652-653
breachingof,622 Bionicstandard,90968 Index
BIOS,94 booting,86,94-95,863-864,872-874
bit(s): bootloaders,seebootstrapprograms
accessed,437 bootpartition,465
additional-reference-bitsalgorithm, bootsector,466
409-410 bootstrapport,136
contiguous,432-433 bootstrapprograms(bootloaders,
defined,12 bootstraploaders),11,70,94,465,
mode,24 601
modify(dirty),402 bootstrapserver,136
reference,409 bootviruses,632,633
setuid,674-675 BorderGatewayProtocol(BGP),745
64-bitcomputing,383 bottlenecks,95
valid-invalid,368-369 bottomhalf(interruptserviceroutines),
bit-levelstriping,475 793-794
BitLocker,863 boundedbuffer,126
bitmaps(bitvectors),38-39,579,877 bounded-bufferproblem,290,304
BKL,runningon,794 boundedcapacity(ofqueue),131-132
bladeservers,18-19 boundedwaiting,261
block(s),186 bourne-againshell(bash),58,783
bad,466-467 BPFCompilerCollection(BCC),98-100
boot,94,464-466,566 breachofavailability,622
bootcontrol,566 breachofconfidentialit ,622
defined,564 breachofintegrity,622
direct,576 bridging,723
disk,40 broadcasting,745
file-control,565,567 brokers,837
index,575-577 browserprocess,124
indirect,576,577 BSDUNIX,49-50
logical,456 bss(blockstartedbysymbol)field,108
processcontrol,109-110 B+tree(NTFS),876
threadbuilding,186-188 buddies,427
threadenvironment,889-890 buddyheap(Linux),796
TRIMingunused,581-582 buddysystem(Linux),796
virtualaddresscontrol,865 buddy-systemallocation,427,428
volumecontrol,566 buffers:
blockciphers,639 boundedandunbounded,126
blockdevices,502-504,810-811 bounded-bufferproblem,290,304
blockdeviceinterface,503 circular,587,716-717
blockgroups,806 defined,509
blocking,indefinite 213 translationlook-aside,365-368,376,384,
blockingI/O,506 855
blocking(synchronous)messagepassing, buffercache,583-585
130 buffering,131-132,412,499,509-510
block-interleaveddistributedparity, buffer-overflo attacks,628-631
477-478 bugs,66
block-levelstriping,475 bugbountyprograms,826
blocknumber,relative,540 bus(es),7,456
blockstartedbysymbol(bss)field 108 advancedtechnologyattachment,456
blocksynchronization,305 defined,490-491
body(value),187 eSATA,456
bootblock,94,465-466,566 expansion,490
bootcontrolblock,566 fibrechannel,456
bootdisk(systemdisk),465 I/O,456
bootfile 877 PCIe,490Index 969
serialATA,456 changejournal(Windows10),879
serial-attachedSCSI,456,490 characterdevices(Linux),810-812
universalserial,456 character-streamdevices,502,504
busywaiting,272,493-494 character-streaminterface,504
byte,11 checksums,462,746
bytecode,727 children,38,111
bytestream,748 chipmultithreading(CMT),222,223
chipsets,835
C Chrome,124
CIFS(commonInternetfilesystem),607,
caches,583-586 880
buffer,583-584 ciphers,639,640
defined,510 circularbuffers,587,716-717
inLinux,797,798 circularlylinkedlists,37,38
locationof,765-766 circularSCAN(C-SCAN)scheduling
asmemorybuffer,350 algorithm,460
page,583,798 circular-waitcondition(deadlocks),321,
andperformanceimprovement,583-586 328-330
policyforupdating,766-767 claimedge,333
slabsin,427,428 classes(Java),694
unifiedbuffer,583-585 classloader,727
cachecoherency,32 cleanuphandler,191
cache-consistencyproblem,765 clearinginterrupts,9,494
cachemanagement,30-31 CLI(command-lineinterface),56
cachemanager(Windows10),864-866 Clibrary,seelibc
caching,30-31,510-511 client(s),73
basicscheme,764-765 inclient-servermodel,606
client-side,883 defined,757
double,584 diskless,762
write-back,766 indistributedsystems,734
cancellation,thread,190-192 thin,40
cancellationpoints,191 client-initiatedapproachtoverifying
Canonical,779 cacheddata,767
capability(-ies),680,682-683,685-686,697 clientinterface,757
capability-basedprotectionsystems, client-serverDFSmodel,758-759
685-687 client-serverdistributedsystem,734
capabilitylists,680-681 client-servermodel,606,758-759,861-862
capabilitysystems,826 client-serversystems,42-43,734
capacity,ofqueue,131-132 client-sidecaching(CSC),883
cascadingtermination,121 clientsystems,42
catchinginterrupts,9,494 clocks,505-506
CAV(constantangularvelocity),457 clockalgorithm,410-411
cdcommand,751 clockowner,837
centralprocessingunits,18,318.Seealso clones,591,705
entriesbeginningCPU clone()systemcall,195-196
Ceph,484 closed-sourceoperatingsystems,46
certificat authorities,644 closures,174,186
CET(Control-flo Enforcement cloudcomputing,44-45,706
Technology),828 cloudstorage,471,751
CFG(Control-FlowGuard),827 clusters,19-21,464,574,875
CFQscheduler,461,811 cluster-basedDFSmodel,758-760
CFS,seeCompletelyFairScheduler clusteredfilesystem(CFS),768
CFS(clusteredfilesystem),768 clusteredpagetables,374
challengingpasswords,652 clusteredsystems,19-21970 Index
clustering,19,20,438 compaction,360,572
CLV(constantlinearvelocity),456-457 compare and swap()instruction,267-269
CMT(chipmultithreading),222,223 compartmentalization,669
coarse-grainedmultithreading,222 compiler-basedenforcement,691-693
coaxialcables,736 compiletime,352
Cocoaframework,87 CompletelyFairQueuing(CFQ)
CocoaTouch,87 scheduler,461,811
code: CompletelyFairScheduler(CFS),236,
absolute,352 237,790
additionalsense,512 complexmessages,136
byte-,727 ComponentObjectModel(COM),882
error-correction,462-463 compression,425-426,757,858,878-879
injectionof,628-631 compressionratio,426
kernel,261 compressionunits,878
message-authentication,643 computationalkernels,833
position-independent,803 computationmigration,752
reentrant(pure),370 computationspeedup,123,735,753
relocatable,353 computerprograms,seeapplication
code-injectionattack,628-631 programs
codeintegritymodule(Windows10),828 computersystem(s):
codereuseattacks,827 architectureof,15-21
codereview,627,628 clusteredsystems,19-21
codesigning,644,690 multiprocessorsystems,16-19
codewords,697 single-processorsystems,15-16
COM(ComponentObjectModel),882 distributedsystems,35-36
com(top-leveldomain),739 firewallingtoprotect,659-660
combinedschemeindexblock,576 I/Ostructurein,14-15
commandinterpreter,58-59 operatingsystemviewedby,5
command-lineinterface(CLI),56 organization,7-15
committingallocations,852 interrupts,8-11
CommonCriteria,869 I/Ostructure,14-15
commonInternetfilesystem(CIFS),607, storagestructure,11-14
880 processmanagementin,27-28
commonname,647 protectionin,33-34
communication(s): real-timeembeddedsystems,45-46
direct,128 secure,622
indirect,129 securityin,33-34
inter-computer,522 storagein,11-14
interprocess,seeinterprocess storagemanagementin,30,32
communication[IPC] threatsto,634-637
network,738-749 compute-serverssystem,42-43
communicationprotocols,741-745 computing:
andnaming/nameresolution,738-741 64-bit,383
TCP/IPexample,745-746 cloud,44-45,706
UDPandTCPtransportprotocols, high-performance,20
746-749 mobile,41-42
asoperatingsystemservice,57 peer-to-peer,43-44
secure,withsymmetricencryption,639, safe,658
640 thin-client,874-875
systemsprogramsfor,74 traditional,40-41
communicationlinks,128 computingenvironments,40-46
communicationports,138 client-servercomputing,42-43
communicationprotocols,741-745 cloudcomputing,44-45
communicationsystemcalls,72-73 mobilecomputing,41-42Index 971
peer-to-peercomputing,43-44 host,456
real-timeembeddedsystems,45-46 controlpartitions,714
traditional,40-41 controlprograms,5
virtualization,34-35 controlregister,492
concurrency,163 convenience,1
ConcurrencyRuntime(ConcRT),241-242, convoyeffect,207
890 cooperatingprocesses,123,257
concurrentdispatchqueue,185 cooperativescheduling,202
conditional-waitconstruct,281 coordination,amongprocesses,260
conditionvariables,278,279,302-303, copy-on-writetechnique,399-401,853
309-311,889 copyrights,accessmatrixwith,677
confidentialit ,breachof,622 copysemantics,510
confinemen problem,678 core(s),15-16,18
conflic phase(ofdispatchlatency),229 bigandlittle,226-227
conflict-resolutio mechanism(Linux), dual-coredesign,17,18
784,785 multicoreprocessors,221-224
congestioncontrol,749 multicoreprogramming,162-166
ConnectedStandby,837 multicoresystems,16-18
connectionlessprotocols,747 schedulingprocessestorunon,199
connectionless(UDP)sockets,147 coredump,95-96
connection-orientedprotocols,748 coreframeworks(macOSandiOS),87
connection-oriented(TCP)sockets,147 CoreUI,825
connectionports,138 counts,533,534
consistency,ofdistributedfil systems, counters,96-97
767 LRUpagereplacementwith,408
consistencychecker,586-587 program,27,106,109
consistencychecking,586-587 timestamp,845
consistencysemantics,608-609 counting,580
consolidation,706 counting-basedpagereplacement
constantangularvelocity(CAV),457 algorithm,411-412
constantlinearvelocity(CLV),456-457 countingsemaphore,273
consumerprocess,126-127,290,291, Cprogram,memorylayoutin,108
559-560 CPUs(centralprocessingunits),18,318
containers,592,718,719 CPU-boundprocesses,112
containerobjects(Windows10),664 CPUburst,201
containment,application,703,718-719 CPU-I/Oburstcycle,201
contaminants,344 CPUregisters,110
contendedlocks,271 CPUscheduler,113-114,201
content-addressablestorage,484 CPUscheduling,24,199-251
contentionscope,217-218 about,201
context(ofprocess),114 algorithmsfor,205-217
context(ofthread),194 evaluationof,244-249
contextswitches,114-115,204 first-come,first-servedschedulingof,
contiguousallocation,356-360,570-573 206-207
contiguousbit,432-433 multilevelfeedback-queuescheduling
Control-flo EnforcementTechnology of,216-217
(CET),828 multilevelqueueschedulingof,
Control-FlowGuard(CFG),827 214-216
controlledaccess,552-554 priorityschedulingof,211-214
controller(s),456 round-robinschedulingof,209-211
defined,491 shortest-job-firstschedulingof,
device,456 207-209
direct-memory-access,498 criteria,204-205
fibrechannelbus,491 dispatcher,roleof,203-204972 Index
andI/O-CPUburstcycle,201 currentdirectory,546
multi-processorscheduling,220-227 current-file-positio pointer,532
approachesto,220-221 cyclestealing,499
heterogeneousmultiprocessing, cyclicredundancychecks(CRCs),462
226-227 cylinder(harddiskdrive),450
andloadbalancing,224-225 cylindergroups,806
andmulticoreprocessors,221-224
andprocessoraffinity,225-226
D
operating-systemexamples,234-244
Linuxscheduling,234-239
d(pageoffset),360
Solarisscheduling,242-244
DAC(discretionaryaccesscontrol),684
Windowsscheduling,239-242
daemons,22,781
preemptivevs.nonpreemptive
daemonprocesses,690
scheduling,202-203
daisychain,490
real-time,227-234
DAM(DesktopActivityModerator),837
earliest-deadline-firstscheduling,
darkweb,634
232-233
Darwinoperatingsystem,85,88,687-688
andminimizinglatency,227-229
dataattributes,875
POSIXreal-timescheduling,233-234
priority-basedscheduling,229-230 databases,341,842,856
proportionalsharescheduling,233 datadependency,164
rate-monotonicscheduling,230-232 data-encryptionstandard(DES),639
threadscheduling,217-219 DataExecutionPrevention(DEP),827
virtualmachines,720 datagrams,743
CPU-schedulinginformation(PCBs),110 data-inregister,492
CPUutilization,204 data-linklayer,742
crashes,96 data-linklayerprotocol,645
crashdumps,96 dataloss,meantimeof,474
CRCs(cyclicredundancychecks),462 datamigration,751-752
creation: data-outregister,492
offiles,532,542 dataparallelism,165,166
ofprocesses,116-121 datapassing,betweenprocesses,813
credentials,787 datasection(ofprocess),106
criticalsections,260 datasplitting,164
critical-sectionobject,297,888 datastriping,475
critical-sectionproblem,260-270 dataviewattribute,862
Peterson’ssolutionto,262-265 DCOM,882
andsemaphores,272-276 DDoSattacks,636
andsynchronizationhardware,265-270 deadlinescheduler,460,461
cryptography,637-648 deadlock(s),283-284,317-343
defined,638 avoidanceof,326,330-337
andencryption,638-645 withbanker’salgorithm,333-337
asymmetricencryption,641 withresource-allocation-graph
authentication,641-644 algorithm,333
keydistribution,644-645 withsafe-statealgorithm,331-333
symmetricencryption,639-640 characterization,321-326
implementationof,645-646 defined,317
TLSexampleof,646-648 detectionof,337-341
CSC(client-sidecaching),883 methodsforhandling,326-327
C-SCANscheduling,460 inmultithreadedapplications,319-321
C-SCANschedulingalgorithm,460 necessaryconditionsfor,321-323
Cshell,58 preventionof,326-330
ctfs(fil system),598 recoveryfrom,341-343
cumulativeACK,748 systemmodelfor,318-319Index 973
systemresource-allocationgraphsfor developmentkernels(Linux),777
describing,321-323 devicecontrollers,456.SeealsoI/O
Debian,779 devicedirectory,seedirectory(-ies)
debuggers,66 devicedrivers,7,490,785
debugging,95-100,165 DeviceGuard,828
dedicateddevices,502 device-managementsystemcalls,71-72
deduplication,757 deviceobjects,863
defaultaccessrights,680 devicereservation,511
defaultheap,893 devicestacks,862
defaultsignalhandlers,189 device-statustable,508-509
defenseindepth,653,669 DFSs,seedistributedfil systems
deferredcancellation,190 digitalcertificates 644
deferredprocedurecalls(DPCs),841,847 digitalsignatures,643,828
degreeofmultiprogramming,112 digital-signaturealgorithm,643
delayedrevocation,682 dining-philosophersproblem,293-295
delayed-writepolicy,766 dircommand,751
deletingfiles,532,542,551 directaccess(files) 539-541
demandpaging,392-399,430-436 directblocks,576
basicmechanism,393-396 directcommunication,128
defined,393 Direct-Compute,825
free-framelist,396-397 directI/O,504
withinvertedpagetables,433 directmemoryaccess(DMA),15,498-500
andI/Ointerlock,434-436 direct-memory-access(DMA)controller,
andpagesize,431-432 498
andperformance,397-399 directory(-ies),541-550
andprepaging,430-431 active,607,884
andprogramstructure,433-434 acyclic-graph,547-549
pure,395 current,546
andTLBreach,432-433 fastsizingof,592
demand-zeromemory,799 file-systeminterface,541-550
demilitarizedzone(DMZ),659 generalgraph,549-550
denial-of-service(DOS)attacks,622,636 implementationof,568-570
dentryobjects,605,804,805 lightweightdirectory-accessprotocol,
DEP(DataExecutionPrevention),827 607
DES(data-encryptionstandard),639 listing,542
designofoperatingsystems,79-80 masterfile,543
distributedsystems,753-757 page,381,853
Linux,780-783 protecting,554
Windows10,826-838 root,877
applicationcompatibility,830-831 single-level,542-543
dynamicdevicesupport,837-838 tree-structured,545-547
energyefficiency,836-837 two-level,543-545
extensibility,833-834 userfile,543
internationalsupport,835-836 directoryobject,850
performance,831-833 directvirtualmemoryaccess(DVMA),
portability,838-839 500
reliability,828-829 dirtybits(modifybits),402
security,826-828 discretionaryaccesscontrol(DAC),684
desktop,59 disinfection,program,658
DesktopActivityModerator(DAM),837 disk(s).Seealsomass-storagestructure;
DesktopWindowManager(DWM),825 RAID(redundantarraysof
detection-algorithmusage(deadlock), inexpensivedisks)
340-341 boot(system),465
deterministicmodeling,245-247 mini-,704974 Index
raw,413,464,601 dockers,719
diskarm,450 document(s):
diskblocks,40 FileSystemHierarchyStandard,778-779
diskimage,723-724 living,653
disklessclients,762 domains:
DiskManagementtool,465 capabilitylistsfor,680-681
disk-schedulingalgorithms,460-461 protection,671-675,711
dispatchedprocess,112 publicdomainsoftware,779-780
dispatchers,203-204,239,840-841 scheduling,238
dispatcherdatabase,842 security,659
dispatcherobjects,297,845-846 Windows10,884
dispatchinginterrupts,9,494 domain-namesystem(DNS),607,739-740
dispatchlatency,203,228,229 domainswitching,673,674
dispatchqueue,185 DOSattacks,622,636
distinguishedname,647 doublebuffering,499,509
DistributedDenial-of-Service(DDoS) doublecaching,584
attacks,636 doubleindirectblocks,576
distributedfil systems(DFSs),605, doublylinkedlists,37
757-768
downtime,572
client-servermodel,758-759
DPCs(deferredprocedurecalls),841,847
cluster-basedmodel,759-761
DRAM(dynamicrandom-access
defined,757
memory),11
implementationtechniques,763-764
driveformatting,463,464
namingin,761-764
drivemirroring,476
remotefileaccessin,764-767
driverend(STREAM),519
trendsin,767-768
driverobjects,863
Windows10,883
driver-registrationsystem(Linux),784,
distributedinformationsystems
785
(distributednamingservices),607
DriveWritesPerDay(DWPD),453
distributedlockmanager(DLM),21
droppedpackets:
distributedoperatingsystems,749-753
TCPtransferwith,748,749
distributedsystems,35-36
UDPtransferwith,747-748
advantagesof,733-735
dual-bootedsystems,601
defined,733
dual-coredesign,17,18
designissuesin,753-757
dual-modeoperation,24-25
distributedfilesystems,757-768
DVMA(directvirtualmemoryaccess),
client-servermodel,758-759
500
cluster-basedmodel,759-761
DWM(DesktopWindowManager),825
defined,757
DWPD(DriveWritesPerDay),453
implementationtechniques,763-764
dynamicallylinkedlibraries(DLLs),76,
namingin,761-764
355-356
remotefileaccessin,764-767
dynamicdevicesupport(Windows10),
trendsin,767-768
837-838
distributedoperatingsystems,749-753
dynamiclinking,803
distributions(GNU/Linux),48
dynamicloading,355
DLLs(dynamicallylinkedlibraries),76,
dynamicprotection,673
355-356
dynamicrandom-accessmemory
DLM(distributedlockmanager),21
(DRAM),11
DMA(directmemoryaccess),15,498-500
dynamicstorage-allocationproblem,358,
DMA-acknowledge,499
571
DMAcontroller,498
dynamictick,836-837
DMA-request,499
DMZ(demilitarizedzone),659
DNS(domain-namesystem),607,739-740 EIndex 975
earliest-deadline-firs (EDF)scheduling, error-correctingorganization,476-477
232-233 error-correctioncode(ECC),462-463
easeofuse,4,822 errordetection,57,462
easilyrememberedpasswords,651 errorhandling,511-512
eBPFtracingtool,99,100 eSATAbuses,456
ec2,44 escalateprivileges,34
ECC(error-correctioncode),462-463 escape(operatingsystems),503
economicbenefits ofmultithreaded Ethernetpackets,745-746
processes,162 events,297
EDF(earliest-deadline-first scheduling, eventlatency,227-228
232-233 eventobjects(Windows10),845
edu(top-leveldomain),739 eventtracing,822
effectiveaccesstime,397-398 event-vectortable,11
effectivecapabilities,685 eVM,729
effectivememory-accesstime,367 "exactlyonce"functionality,150
effectivetransferrates,451,486 exceptions,22,497,847-848
effectiveUID,34 exceptiondispatcher,847
efficienc ,1,582-583,692,836-837 exclusivelocks,534
electricalstoragesystems,14 exec()systemcall,188,786-789
elevatoralgorithm,seeSCANscheduling ExecutableandLinkableFormat,seeELF
algorithm executablefiles 75,107,530
ELF(ExecutableandLinkableFormat), executingfiles,551
76-77,801,802 executionofuserprograms,801-803
embeddedcomputers,5 executiontime,353
emptyprocesses,123 executive(Windows10),848-874
emptyslabs,429,798 booting,872-874
emulation,34,717-718 cachemanager,864-866
emulators,703 facilitiesforclient-servercomputing,
encapsulation(Java),696 861-862
encryptedviruses,633 I/Omanager,862-864
encryption,638-645 objectmanager,849-851
asymmetric,641,645 plug-and-playmanager,869-870
authentication,641-644 powermanager,870-871
defined,638 processmanager,858-860
keydistribution,644-645 registry,871-872
public-key,641 securityreferencemonitor,866-869
symmetric,639-640 virtualmemorymanager,851-858
energyefficienc ,836-837 exitsection,260
enhancedsecond-chance exit()systemcall,121-122
page-replacementalgorithm, expansionbus,490
410-411 exponentialaverage,208
entitlements(Darwin),686-687 exportlist,612
entrysection,260
ext2(secondextendedfilesystem),805
entryset,303,304,307
ext3(thirdextendedfilesystem),805-807
environment:
ext4(fourthextendedfilesystem),805
computing,40-46
extendedfileattributes,531
kernel,88
extendedfilesystem(extfs),566,805
operatingsystemas,4 extensibility,ofWindows10,833-834
programming,703,717 extent(contiguousspace),572
run-time,64-65 externaldatarepresentation(XDR),150
threadenvironmentblocks,889-890 externalfragmentation,359-360,571-572
environmentvector,787
extfs(extendedfilesystem),566,805
equalallocation,414
errors,462-463,467,511-512 F976 Index
failure(s),473,474,754-756 fil infowindow(macOS),531
failureanalysis,95-96 fil management,74
failuremodes(remotefil systems), file-managemen systemcalls,71
607-608 fil mapping,555,557
fairnessparameter,307 fil migration,761-762
fairscheduling,791 fil modification 74
falsenegatives,656 fil objects,605,804-805,862
falsepositives,656 file-ope count,534
fastdirectorysizing,592 file-organizatio module,565
fastI/Omechanism,865-866 fil pointers,534
fast-userswitching,825,874-875 fil reference,876
FAT(file-allocatio table),574-575 fil replication,761
fault,page,394-395 file-serve system,43
faulttolerance,19,754 fil sessions,608
fault-tolerantsystems,754 fil sharing,602-603
FC(fibe channel),470 fil systems,597-616
FCB(file-contro block),565,567 Andrew,759
FCbuses,456 Apple,592
FCbuscontroller,491 basic,564,565
FCFSscheduling,458,459 clustered,768
FCFSschedulingalgorithm,206-207,458 commonInternet,607,880
fd(fil descriptor),568,788 consistencysemanticsin,608-609
fences,memory,266 defined,564
fibers 241,889-890 distributed,seedistributedfil systems
fibe opticcables,736 (DFSs)
fibr channel(FC),470 extended,566,805
fibr channel(FC)buses,456 filesharing,602-603
fibr channel(FC)buscontroller,491 Google,759-761
fidelit ,704 Hadoop,484
FIFO,38 Linux,803-810
FIFOpagereplacementalgorithm, ext3filesystem,805-807
404-406 journaling,808
50-percentrule,359 /procfilesystem,808-810
file(s) 29-30,529-530.Seealso virtual,804-805
directory(-ies);specifictypes log-basedtransaction-oriented,587-588
appending,551 logical,565
attributesof,530-531 mountingof,598-602
defined,255,527,529 network,610-615
deleting,532,542,551 networkfile,610-615,759
executing,551 operations,566-568
internalstructureof,537-539 parallel,768
locking,534-536 partitionsin,601-602
opening,532 registrationof,785
operationson,532-536 remote,605-608
paging,851 Solaris,482-484,597,599
reading,532,551 special-purpose,597-598
renaming,542 structure,564-566
searchesfor,541,542 traversing,542
truncating,532 traversingof,542
writing,532,551 UNIX,565-566,598
file-allocatio table(FAT),574-575 usage,568
file-contro block(FCB),565,567 virtual,603-605,804-805
fil descriptor(fd),568,788 Windows10,875-879
fil handle,568 write-anywherefilelayout,589-593Index 977
ZFS,482-484,581,588,598 flexibilit ,ofcompiler-based
file-syste context,788 enforcement,692
FileSystemHierarchyStandard FLIH(first-leve interrupthandler),496
document,778-779 flo control,519,748,749
fil systemimplementation,563-593 flushing 366
allocationmethods,570-578 folderredirection,883
contiguousallocation,570-573 folders,59
indexedallocation,575-577 foregroundpriorityseparationboost,843
linkedallocation,573-575 foregroundprocesses,115,122,215,241
performance,577-578 fork()andexec()processmodel(Linux),
directoryimplementation,568-570 786-789
efficiency,582-583 fork-joinmodel,180-184
file-systemoperations,566-568 fork()systemcall,118-119,188,786-789
file-systemstructure,564-566 formatting,463,464
free-spacemanagement,578-582 forwarding,466
performance,583-586 forward-mappedpagetables,371
recovery,586-589 4-bytepages,363,364
WAFLexample,589-593
four-layeredmodelofsecurity,623-625
file-syste interface,529-560 fourthextendedfilesystem(ext4),805
accessmethods,539-541,551-554
fragments,packet,815
directorystructure,541-550
fragmentation,359-360,571-572
acyclic-graphdirectories,547-549
frame(s),360
generalgraphdirectory,549-550
indata-linklayer,742
single-leveldirectory,542-543
free,364,396-397,425-426
tree-structureddirectories,545-547
minimumnumberof,413-414
two-leveldirectory,543-545
page,853
fileattributes,530-531
pagefaultsvs.,404,405
andfileconcept,529-530
victim,402
fileoperations,532-536
frameallocation,413-419
filestructure,537-539
allocationalgorithms,403,414-415
filetypes,536-537
equal,414
memory-mappedfiles,555-560
globalvs.local,415-418
protection,550-555
minimumnumberofframes,413-414
file-syste management,29-30
non-uniformmemoryaccess,418-419
file-syste manipulation(operating
proportional,414-415
systemservice),56-57
frame-allocationalgorithm,403,414-415
fil table,788
frametable,365
fil transfer,750-751
free-behindtechnique,585
fil viruses,632
filte drivers,863 FreeBSD,70,71
filtering system-call,688 freeframes,allocationand,364
filte management,863 free-framelist,396-397,425-426
fine-graine multithreading,222 freepage,856
Finish(datastructure),335,339 FreeSoftwareFoundation(FSF),48
fire alls,41,659-660 free-spacelist,578-579
fire allchains,815 free-spacemanagement,578-582
fire allmanagement,815 freshvalue,647
firm are,11,12 front-endprocessors,522
first-come first-serve (FCFS)scheduling FSF(FreeSoftwareFoundation),48
algorithm,206-207,458 fsgidproperty,818
first-fitstrategy,358,359 fsuidproperty,818
first-leve interrupthandler(FLIH),496 FTL(flas translationlayer),453-454
firs readers,291 fullbackup,589
flas translationlayer(FTL),453-454 fullslabs,429,798978 Index
functionalprogramminglanguages, Hadoop,22
313-314 Hadoopdistributedfil system(HDFS),
759,760
G Hadoopfil system(HDFS),484
HAL(hardware-abstractionlayer),835,
Galoisfiel math,478 840
Ganttchart,206 handles,849
garbagecollection,454,549,550,727 handletables,849
GB(gigabyte),11 handling,signal,188-189
gcc(GNUCcompiler),778 handshake,three-way,748
GCD(GrandCentralDispatch),185-186 hardaffinit ,225
GDT(globaldescriptortable),379 hard-codingtechniques,129
generalgraphdirectories,549-550 harddiskdrives(HDDs),13
generalrevocation,682 componentsof,450-451
gestures,60 defined,449
getcommand,751 scheduling,457-461
GFS(Googlefilesystem),759-761 harderrors,463,467
gigabyte(GB),11 hardlimits,438,857
git,50 hardlinks,532,549,879
globalallocation,415-418 hardpagefaults,416
globaldescriptortable(GDT),379 hardreal-timesystems,227
globaldispatchqueues,185 hardware,4
globalreplacement,415-418 instructions,266-269
globaltable,679 I/Osystem,490-500
GNOMEdesktop,60 directmemoryaccess,498-500
GNUCcompiler(gcc),778 interrupts,494-498
GNUGeneralPublicLicense(GPL),48 polling,493-494
GNU/Linux,48 andmainmemory,350-352
GoogleAndroid,42 andmemorymanagement,28
Googlefilesystem(GFS),759-761 processmigrationand,753
GPFS,768 forrelocationandlimitregisters,357
GPL(GNUGeneralPublicLicense),48 forstoringpagetables,365-368
GPU(graphicsprocessingunit),735 synchronization,265-270
gracefuldegradation,19 transformationofrequeststooperations
GrandCentralDispatch(GCD),185-186 by,516-519
granularity,minimum,791 virtualmachine,710-713
graphs,acyclic,547 hardware-abstractionlayer(HAL),835,
graphicaluserinterfaces(GUIs),56,59-61 840
graphicsprocessingunit(GPU),735 hardwareobjects,672
greenthreads,167 hardwarethreads,222
group(userclass),551 hardwaretransactionalmemory(HTM),
groupidentifiers 33-34 312
grouping,580 hardworking-setlimits,438
grouppolicies,884 hashcollision,39
grouprights(Linux),817 hashedpagetables,373-374
GRUB,94 hashfunctions,38-39,643
guardpages,852 hashmap,39
guest(operatingsystem),34 hashtables,570
guestprocesses,702 hashvalue(messagedigest),643
GUIs(graphicaluserinterfaces),56,59-61 HBA(hostbusadapter),491
HDDs,seeharddiskdrives
H HDFS(Hadoopdistributedfil system),
759,760
hackers,622 HDFS(Hadoopfil system),484Index 979
headcrash,451 I
heaps,893-894
heapsection(ofprocess),107
IA-32architecture,379-382
heartbeatprocedure,754-755
IA-64architecture,382
heterogeneousmultiprocessing,226-227
IaaS(infrastructureasaservice),44
hibernation,870
IB(InfiniBand) 473
hierarchicalpaging,371-373
icons,59
high-availabilityservice,19
idealprocessors,242,842
highcontention,271,286
idempotent,759
highmemory,795
identifiers
high-performancecomputing,20
address-space,366
high-performanceeventtimer(HPET),
file,530
505
group,33-34
highpriority,212
hostnamesvs.,738
hijacking,session,623
location-independentfile,764
hitratio,367,432 process,116
hives,871 spoofed,606
hold-and-waitcondition(deadlocks),321, user,33
327-328 idleprocess,872
holes,358 idlethreads,239,842
HoloLens,874 IKEprotocol,646
honeypot,655-656 image,disk,723-724
horizontalscalability,484 immediaterevocation,682
host(s): immutablesharedfiles,609
distributedsystem,734 immutable-shared-fil semantics,609
operatingsystem,35,177 imperativelanguages,313
virtualmachine,702 impersonation,867
host-attachedstorage,470 implementation:
hostbusadapter(HBA),491 CPUschedulingalgorithm,249
hostcontroller,456 cryptography,645-646
host-id,739 directory,568-570
hostname,73,738 filesystem,seefil system
hotspare(drive),480 implementation
hot-standbymode,19,20 monitor,280-281
HPET(high-performanceeventtimer), ofnamingtechniques,763-764
505 ofoperatingsystems,80-81
HTM(hardwaretransactionalmemory), Pthread,169,170
312 ofsecuritydefenses,653-662
HTTPprotocol,881 andaccounting,659
hugepages,363,432 andauditing,659
HybridBoot,873-874 andfirewalling,659-660
hybridcloud,44 andintrusionprevention,655-657
hybridoperatingsystems,86-91 levelsofdefenses,661-662
hypercalls,717 andlogging,659
hypercallinterface,839 andsecuritypolicy,653
hyper-threading,222,832 andvirusprotection,657-659
Hyper-VforClient,831 andvulnerabilityassessment,653-655
hyper-Vhypervisor,839 semaphore,274-276
hypervisors,670,702 synchronizationprimitive,845-846
separation,729 virtualmachine,713-719
type0,702,713-714 applicationcontainment,718-719
type1,703,714-715 emulation,717-718
type2,703,715-716 paravirtualization,716-717980 Index
programming-environment defined,501
virtualization,717 speedsof,510
type0hypervisors,713-714 interlock,I/O,434-436
type1hypervisors,714-715 intermachineinterface,757
type2hypervisors,715-716 internalfragmentation,359
andvirtualmachinelifecycle,713 internationalsupport(Windows10),
implicitthreading,176-188 835-836
forkjoin,180-183 Internet,737
GrandCentralDispatch,185-186 InternetKeyExchange(IKE),646
Intelthreadbuildingblocks,186-188 Internetmodel,742
OpenMPand,183-185 InternetProtocol(IP),743-746.Seealso
threadpoolsand,177-180 TransmissionControl
importancehierarchy(Android),122 Protocol/InternetProtocol(TCP/IP)
includefile 40 InternetServiceProviders(ISPs),737
increaseschedulingpriorityprivilege, interpretedlanguages,717
887 interprocesscommunication(IPC),
incrementalbackup,589 123-153
indefinit blocking(starvation),213,343 inclient-serversystems,145-153
independence,location,762,769 remoteprocedurecalls,149-153
independentprocesses,123 sockets,146-149
indexes,540,542,576 inLinux,777,812-813
indexblocks,575-577 Machexampleof,135-138
indexedallocation,575-577 inmessage-passingsystems,127-132
indexroot,876 pipesin,139-145
indirectblocks,576,577 POSIXshared-memoryexampleof,
indirectcommunication,129 132-135
indirection,683,703 inshared-memorysystems,125-127
InfiniBan (IB),473 Windowsexampleof,138-139
informationleakattacks,827 interrupt(s),8-11,494-498
information-maintenancesystemcalls,72 defined,494
informationsharing,123 inLinux,794
infrastructureasaservice(IaaS),44 maskable,10,495-496
inheritablecapabilities,685 nonmaskable,10,495
initprocess,117 software(traps),497
in-memoryfile-systemstructures,568,569 inWindows10,846-848
inode,482,565,577 interruptchaining,10,496
inodeobjects,605,804 interrupt-controllerhardware,9,495
input/output,seeI/O interrupt-dispatchtable(Windows10),
input/outputoperationspersecond 848
(IOPS),461 interrupt-handlerroutine,9,494-495
insert()method,305-307 interruptlatency,228
InServstoragearray,481 interruptobjects,848
instructionregister,12 interruptprioritylevels,10-11,497
integrity,622,687-688 interruptrequestlevels(IRQLs),841,846
integritylabel(Windows10),663 interrupt-requestline,9,494
integritylevels,826 interruptserviceroutines(ISRs),844
Intelprocessors,379-382 interruptvector,9,496
event-vectortable,496 intruders,622
IA-32architecture,379-382 intrusionprevention,655-657
IA-64architecture,382 intrusion-preventionsystems(IPSs),656
threadbuildingblocks,186-188 invertedpagetables,374-375,433
inter-computercommunications,522 involuntarycontextswitches,204
interface(s).Seealsospecifictypes I/O(input/output):
choiceof,60-62 fastmechanismfor,865-866Index 981
raw,464,465 IPIs(Windows10),847-848
structureof,14-15 IPSec,646
invirtualmachines,722-723 IPSs(intrusion-preventionsystems),656
I/O-boundprocesses,112 IRP(I/Orequestpacket),863
I/Oburst,201 IRQLs(interruptrequestlevels),841,846
I/Obus,456 iSCSI,471
I/Ochannel,522 ISPs(InternetServiceProviders),737
I/Ocontrollevel(fil system),564 ISRs(interruptserviceroutines),844
I/Ointerlock,434-436 Itanium,382
I/Omanager,862-864 iterationspace,187
I/Ooperations,56
IOPS(input/outputoperationsper J
second),461
I/Orequestpacket(IRP),863 Java:
iOSoperatingsystem,42,87-89 DNSlookupin,740
I/Ostatusinformation(PCBs),110 filelockingin,534,535
I/Osubsystem(s),32-33 fork-joinin,180-184
kernelsin,508-516 Lambdaexpressionsin,174
proceduressupervisedby,516 language-basedprotectionin,694-696
I/Osystem(s),489-525 synchronization,303-311
applicationinterface,500-508 conditionvariables,309-311
blockandcharacterdevices,503-504 monitors,303-307
clocksandtimers,505-506 reentrantlocks,307-308
networkdevices,504-505 semaphores,308-309
nonblockingandasynchronousI/O, threaddumpsin,339
506-507 threadpoolsin,179-180
vectoredI/O,507-508 JavaExecutorinterface,175-176
hardware,490-500 Javathreads,173-176
directmemoryaccess,498-500 JavaVirtualMachine(JVM),177,717,
interrupts,494-498 727-728
formemory-mappedI/O,491-493 JBOD(JustaBunchofDisks),472
polling,493-494 JITcompilers,728
summary,500 jobs,processesvs.,106
kernelsubsystem,508-516 jobobjects,859
buffering,509-510 jobscheduling,106
caching,510-511 journaling,587-588,808
datastructures,512-514 JustaBunchofDisks(JBOD),472
errorhandling,511-512 just-in-time(JIT)compilers,728
I/Oscheduling,508-509 JVM,seeJavaVirtualMachine
powermanagement,514-516
proceduressupervisedby,516 K
protection,512
spoolinganddevicereservation,511 KB(kilobyte),11
Linux,810-812 KDesktopEnvironment(KDE),60
overview,489-490 Kerberosnetworkauthentication
STREAMSmechanism,519-521 protocol,607
andsystemperformance,521-524 kernel(s),6,7,501,508-516
transformationofrequeststohardware buffering,509-510
operations,516-519 caching,510-511
IP(InternetProtocol),743-746.Seealso computational,833
TransmissionControl datastructures,36-40,512-514
Protocol/InternetProtocol(TCP/IP) errorhandling,511-512
IPC,seeinterprocesscommunication I/Oscheduling,508-509
iPhone,60 andI/Osubsystems,516982 Index
Linux,776-778,781 language-basedprotectionsystems,
nonpreemptive,262 690-696
powermanagement,514-516 compiler-basedenforcement,691-693
preemptive,262 inJava,694-696
protection,512 LANs(local-areanetworks),36,735-737
secure,839-840 largeobjects,430
spoolinganddevicereservation,511 latency:
synchronizationof,295-299,792-794 dispatch,203,228,229
uni-,728 event,227-228
Windows10,839-848 interrupt,228
kernelabstractions,89 inreal-timesystems,227-229
kernelcode,261 rotational,451
kerneldatastructures,36-40,512-514 target,236,791
kernelenvironment,88 latencycommand,494
kernelextensions(kexts),89 layers(ofnetworkprotocols),645
kernelmemoryallocation,426-430 layeredapproach(operatingsystem
kernelmode,24,25,782 structure),83-84
Kernel-ModeDriverFramework layeredprotocols,891
(KMDF),864 LBA(logicalblockaddress),456
kernel-modethreads(KT),841 LCNs(logicalclusternumbers),875
kernelmodules,86,783-786 LDAP(lightweightdirectory-access
kernelmodulemanagement,784 protocol),607,884
kernelobjectaccess(Windows10), LDT(localdescriptortable),379
884-885 least-frequentlyused(LFU)
kernelthreads,166,217,234 page-replacementalgorithm,
kernelvirtualmemory,801 411-412
Kernighan’sLaw,98 leastprivilege,principleof,626,627,
kexts(kernelextensions),89 668-669
keys: least-recently-used(LRU)algorithm,
forcapabilities,683 407-408
defined,638 leftchild,38
InternetKeyExchange,646 LFHdesign,894
inlock-keyschemes,681 LFUpage-replacementalgorithm,411-412
master,683 lgroups,419
private,641 libc(Clibrary),63,69,370,781
public,641 libraries:
sense,512 C,63,69,370,781
session,647 Linuxsystem,781
keydistribution,644-645 shared,356,392
keyring,644 thread,168-176
keystreams,640 about,168-169
keystrokelogger,634 Java,173-176
kilobyte(KB),11 Pthreads,169-171
KMDF(Kernel-ModeDriver Windows,171-173
Framework),864 libraryoperatingsystems,728
Kornshell,58 licensing,Linux,779-780
KT(kernel-modethreads),841 lifecycle:
Kubernetes,719 I/Orequest,518-519
virtualmachine,713
L lifetime,virtualaddressspace,799-800
LIFO,37-38
labels,formandatoryaccesscontrol,685 lightweightdirectory-accessprotocol
Lambdaexpressions,174 (LDAP),607,884
languages,313-314,717 lightweightprocess(LWP),193Index 983
limitregister,351-352 access,679-680
linearaddresses,380,382 access-control,552,555,826
linearlists(files) 569-570 capability,680-681
linediscipline,811-812 export,612
link(s): free-frame,396-397,425-426
communication,128 free-space,578-579
defined,548 linear,569-570
hard,532,549,879 linked,37,38,579-580
resolving,548 usercontrol,561
symbolic,879 listingdirectories,542
linkedallocation,573-575 listingfilenamesandattributes,551
linkedlists,37,38,579-580 littlecores,227
linkedschemeindexblock,576 little-endian,150
linkers,75,76 Little’sformula,247
linking,355-356,803,882 liveCD,48
Linux,48,775-819 liveDVD,48
capabilitiesin,685-686 livelock,320-322
designprinciplesfor,780-783 livemigration(virtualmachines),706,
filesystems,803-810 724-726
ext3filesystem,805-807 liveness,283-284
journaling,808 livingdocuments,653
/procfilesystem,808-810 loadablekernelmodules(LKMs),86
virtual,804-805 loadbalancing,224-225,735,753
historyof,775-780 loaders,75-77,695,727,783.Seealso
inputandoutput,810-812 bootstrapprograms
interprocesscommunication,812-813 loading,355,801-803
kernelmodules,783-786 loadsharing,220
lockdeptool,330 loadtime,353
memorymanagement,795-803 localallocation,415-418
executionandloadingofuser local-areanetworks(LANs),36,735-737
programs,801-803 localdescriptortable(LDT),379
physicalmemory,795-798 localitymodel,421
virtualmemory,436-437,798-801 localityofreference,395
networkstructure,813-815 localityproperty,857
processmanagement,786-790 local-name,763
processrepresentationin,111 localreplacement,415-418
schedulingin,234-239,790-794 localreplacementalgorithm,420-421
securitymodel,816-818 location,file 530,534
swap-spacemanagementin,468-470 locationindependence,761,762
synchronizationin,296-298 location-independentfil identifiers 764
systemstructure,83 locationtransparency,761
threadsexample,195-196 locks,681.Seealsodeadlock(s)
treeofprocesses,116 advisory,535
Windowssubsystemfor,91 exclusive,534
Linuxdistributions,776,779 inJavaAPI,534,535
Linuxinstance,91 mandatory,535
Linuxkernel,776-778,781 mutex,270-272,299-300
Linuxkerneldatastructures,40 nonrecursive,299
Linuxsystem(s),776 Pushlocks,831
componentsof,781-783 reader-writer,292-293
historyof,778-779 reentrant,307-308
obtainingpagesizeon,364 scopeof,305
Linuxtimers,27 shared,534
lists,37 forshareddata,70984 Index
lock-freealgorithms,284 macroviruses,632
locking,page,434-436 magicnumber(files) 537
lockingfiles,534-536 magnetictapes,455
lock-keyscheme,681 mailboxes,129-130
lofs(fil system),598 mainmemory,349-385
log-basedtransaction-orientedfil andaddressbinding,352-353
systems,587-588 ARMv8architecture,383-384
logfiles,95,876
contiguousallocationof,356-360
log-fil service,878 anddynamiclinking,355-356
logging,57,659 anddynamicloading,355
loggingarea,878 andhardware,350-352
logicaladdress,353,379 Intel32and64-bitarchitectures,379-382
logicaladdressspace,353-355 andlogicalvs.physicaladdressspace,
logicalblocks,456 353-355
logicalblockaddress(LBA),456 pagingformanagementof,360-376
logicalclusternumbers(LCNs),875 basicmethod,360-365
logicalfilesystem,565
hardware,365-368
logicalformatting,464 hashedpagetables,373-374
logicalmemory,24,362.Seealsovirtual hierarchicalpaging,371-373
memory invertedpagetables,374-375
logicalprocessors,832 andOracleSPARCSolaris,375-376
logicalrecords,539 protection,368-369
logicbomb,627 andsharedpages,369-371
login,remote,750 swappingwith,377
loopback,148 sharedlibraries,356
looselycoupledsystem,83 andswapping,376-378
loosely-coupledsystems,19 mainqueue,185
lovebugvirus,658 mainTLB,384
lowcontention,271 majorpagefaults,416
low-fragmentationheap(LFH)design, malware,625-628
894 MANs(metropolitan-areanetworks),36
low-levelformatting(disks),463 mandatoryaccesscontrol(MAC),684-685
lowpriority,212 mandatoryfile-lockin mechanisms,535
LRUalgorithm,407-408 mandatorypolicy,826
LRU-approximationpagereplacement man-in-the-middleattack,623,635,645
algorithm,409-411 many-to-manymultithreadingmodel,
LRUpagereplacement,407-409 167-168
lscommand,751 many-to-onemultithreadingmodel,
Lustre,768 166-167
LWP(lightweightprocess),193 mapping,39
LXCcontainers,718,719 address,456-457
file,555,557
M memory,802-803
MapReducesystem,22,761
MAC(mandatoryaccesscontrol),684-685 marshaling,150,882
MAC(message-authenticationcode),643 MarsPathfinde,285
MACaddress,745 maskableinterrupts,10,495-496
Mach-Oformat,77 masquerading,622,623,635
Machoperatingsystem,84,135-138 mass-storagemanagement,30
macOSoperatingsystem: mass-storagestructure,449-486
GUI,61 addressmapping,456-457
ashybridsystem,87-89 attachmentofstorage,469-473
latencycommand,494 devicemanagement,463-467
sandboxingin,690-691 errordetectionandcorrection,462-463Index 985
harddiskdrives,450-451,457-461 over-allocationof,401
nonvolatilememorydevices,452-454, physical,24,362,390,391,795-798
461-462 secondary,395
overview,449-450 semiconductor,14
RAID,473-485 shared,57,73,123,125,556-560
extensions,481-482 softwaretransactional,312
forobjectstorage,483-485 32-byte,363,364
performanceimprovement,475 transactional,311-312
problemswith,482-483 virtual,seevirtualmemory
RAIDlevels,475-481 volatile,454-455
reliabilityimprovement,473-475 memoryaccess:
scheduling,457-462 direct,15,498-500
secondarystorageconnectionmethods, directvirtual,500
456 effectivememory-accesstime,367
swap-spacemanagement,467-469 non-uniform,18,19,418-419
volatilememory,454-455 memory-addressregister,354
masterbookrecord(MBR),465,466 memoryallocation,358-359,426-430
masterfil directory(MFD),543 memorybarriers,265-266
masterfil table,566 memorycompression,425-426,858
masterkey,683 memorydevices:
mastersecret(TLS),647 managementof,463-467
matchmakers,151 nonvolatile,452-454
Max(datastructure),335 defined,449
maximumnumberofresources, NANDflashcontrolleralgorithmsfor,
declarationof,330 453-454
MB(megabyte),11 overview,452-453
MBR(masterbookrecord),465,466 scheduling,461-462
MD5messagedigest,643 memoryfences,266
meantimebetweenfailures(MTBF),473, memorymanagement,28-29
474 inLinux,795-803
meantimeofdataloss,474 executionandloadingofuser
meantimetorepair,474 programs,801-803
mechanicalstoragesystems,14 physicalmemory,795-798
mechanisms,80,668.Seealsospecific virtualmemory,798-801
mechanisms withvirtualmachines,721-722
mediumaccesscontrol(MAC)address, inWindows10,892-895
745 memory-managementinformation
mediumobjects,430 (PCBs),110
megabyte(MB),11 memory-managementunit(MMU),354,
memory: 855
AddressWindowExtension,894-895 memorymanager(MM),851
anonymous,399,469 memory-mappedfiles,555-560,892-893
defined,14 memory-mappedI/O,491-493
demand-zero,799 memorymapping(Linux),802-803
directmemoryaccess,14,498-500 memorymodel,265-266
directvirtualmemoryaccess,500 memoryprotection,357,368-369
high,795 memorystall,221-222
in-memoryfile-systemstructures, memory-styleerror-correcting
568,569 organization,476-477
layoutof,inCprogram,108 memorytransactions,311
layoutofprocessin,106 messages,135
logical,24,362 complex,136
main,seemainmemory indistributedsystems,734
networkvirtualmemory,765 OSInetwork,742,744986 Index
inWin32API,891 pluggableauthentication,816
message-authenticationcode(MAC),643 stream,519
messagedigest(hashvalue),643 moduleloader,783
messagemodification 622-623 module-managementsystem,783,784
messagepassing,123,125,130 moduleunloader,783
message-passingmodel,57,72-73,127-132 monitors,276-282
buffering,131-132 dining-philosopherssolutionwith,
Machexample,135-138 295,296
naming,128-130 implementationof,usingsemaphores,
synchronization,130-131 280-281
metadata,607,876 inJava,303-307
metaslabs,581 resumptionofprocesseswithin,281-282
methods(Java),694 securityreference,866-869
Metro,823 usageof,277-280
metropolitan-areanetworks(MANs),36 monitorcalls,seesystemcalls
MFD(masterfil directory),543 monitortype,277
MFUpage-replacementalgorithm,412 monoculture,634
microkernels,84-86 monolithicoperatingsystems,82-83
MicrosoftInterfaceDefinitio Language Moore’sLaw,5
(MIDL),150,882 most-frequentlyused(MFU)
MicrosoftWindows,seeWindows page-replacementalgorithm,412
operatingsystem(generally) motherboard,20
microTLBs,384 motivation,formultithreading,160-161
middleware,6,7 mounting,464,598-602
MIDL(MicrosoftInterfaceDefinitio mountpoints,598,879
Language),150,882 mountprotocol(NFS),612
migration: mounttable,517,567
computation,752 MTBF(meantimebetweenfailures),473,
data,751-752 474
file,761-762 MUIsupport,840
process,752-753 multicoreprocessors,221-224
pushandpull,224 multicoreprogramming,162-166
withvirtualmachines,706,724-726 multicoresystems,16-18
minidisks,704 multidimensionalRAIDlevel6,478
minifilters 863 multifactorauthentication,653
minimumgranularity,791 multilevelfeedback-queuescheduling
miniportdriver,864 algorithm,216-217
minorpagefaults,416 multilevelindex,576
mirroredvolume,474 multilevelqueueschedulingalgorithm,
mirroring,474,476 214-216
MM(memorymanager),851 multimodeoperation,25-26
MMU(memory-managementunit),354, multipartiteviruses,634
855 MultipleUNCProvider(MUP),882-883
mobilecomputing,41-42 multipleuserinterface(MUI)support,
mobilesystems,115,377-378 840
modebits,24 multiprocessing,16,220,226-227,794
moderatecontention,285 multiprocessors,18,220
Modern,823 multi-processorscheduling,220-227
modifie page,856 approachesto,220-221
modifybits(dirtybits),402 examples,234-242
modularity,123 Linux,234-239
modules: Solaris,242-244
file-organization,565 Windows,239-242
kernel,86,783-786 heterogeneousmultiprocessing,226-227Index 987
andloadbalancing,224-225 NANDflas controlleralgorithms,
andmulticoreprocessors,221-224 453-454
andprocessoraffinity,225-226 NAS(network-attachedstorage),470-471
multiprocessorsystems,16-19 NAT(networkaddresstranslation),723
multiprogramming,23,112,420 national-language-support(NLS)API,
multi-providerrouter,883 835
multitasking,23,115,790 NDIS(NetworkDeviceInterface
multithreadedprocesses,160 specification) 880
benefitsof,162 Need(datastructure),335,336
deadlocksin,319-321 need-to-knowprinciple,672
andexec()systemcall,188 nestedpagetables(NPTs),710,712
andfork()systemcall,188 network(s):
modelsof,166-168 communicationstructure,738-749
motivationfor,160-161 communicationprotocols,741-745
andsignalhandling,188-189 andnaming/nameresolution,738-741
multithreading: TCP/IPexample,745-746
chip,222,223 UDPandTCPtransportprotocols,
coarse-grained,222 746-749
fine-grained,222 defined,36
many-to-many,167-168 firewallingtoprotect,659-660
many-to-one,166-167 inLinux,813-815
one-to-one,167 local-area,36,735-737
simultaneous,222 metropolitan-area,36
multi-touchhardware,874 networkoperatingsystems,749-751
MUP(MultipleUNCProvider),882-883 personal-area,36
mutexlocks,270-272,299-300 asresourcetypes,318
mutualexclusion(mutex),260,267,268, securityin,623
845 storage-area,21,470,472
mutual-exclusioncondition(deadlocks), structureof,735-738
321,327 threatsto,634-637
virtualprivate,646,881
wide-area,36,735,737-738
N
wireless,41,736-737
networkaddresstranslation(NAT),723
names: network-attachedstorage(NAS),470-471
commonanddistinguished,647 networkcomputers,40
host,73,738 networkdevices,504-505,810
resolutionof,738-741 NetworkDeviceInterfacespecificatio
namedconditionvariables,309 (NDIS),880
namedpipes,143-145,881-882 networkfilesystem(NFS),610-615,759
namedsemaphores,300-301 networkinformationservice(NIS),607
namedshared-memoryobject,559 networking,880-884
nameserver,739 networkinterfaces(Windows10),880
namespaces,787 networklayer,742
naming,128-130 network-layerprotocol,645
defined,761 networkoperatingsystems,36,749-751
indistributedfilesystems,761-764 networkprotocols,registrationof,785
distributednamingservices,607 networktimeprotocol(NTP),505
domainnamesystem,607 networkvirtualmemory,765
file,530 newstate,108
andnetworkcommunication,738-741 NFS(networkfilesystem),610-615,759
port,135-136 NFSprotocol,612-614
namingschemes,763 nicevalue,236,790
namingstructures(DFS),761-763 NIS(networkinformationservice),607988 Index
NLSAPI,835 hardware,672
no-accesspage,852 inode,605,804
nonblockingI/O,506-507 interrupt,848
nonblockingmessagepassing,130 job,859
noncontainerobjects(Windows10),664 inLinux,797,804
nonmaskableinterrupts,10,495 namedshared-memory,559
nonpreemptivekernels,262 noncontainer,664
nonpreemptivescheduling,202 section,139,852
nonrecursivelocks,299 semaphore,845
nonrepudiation,644 sharing,885-886
nonresidentattributes,876 small,medium,andlarge,430
nonsignaledstate,297 software,672
non-uniformmemoryaccess(NUMA),18, superblock,605,804,805
19,418-419 timer,845
nonvolatilememory(NVM)devices,13, inWindows10,664,845-846,848,849
14,452-454 ObjectLinkingandEmbedding(OLE),
defined,449 882
NANDflashcontrolleralgorithmsfor, objectmanager(Windows10),849-851
453-454 objectstorage,483-485
overview,452-453 objecttypes,849,850
scheduling,461-462 objfs(fil system),598
nonvolatilestorage(NVS),14,449 off-linecompactionofspace,572
NOOPscheduler,461 OLE(ObjectLinkingandEmbedding),
no-preemptioncondition(deadlocks), 882
321,328 one-timepasswords,652
NormalWorld,838 one-to-onemultithreadingmodel,167
notify()method,305-307 on-linecompactionofspace,572
Notifyport,135 OOM(out-of-memory)killers,418
NPTs(nestedpagetables),710,712 OpenAFS(Andrewfil system),759
NTFS,875-877 opencount,533
NTP(networktimeprotocol),505 open-fil table,533,567
NUMA,seenon-uniformmemoryaccess openingfiles,532
NUMA-awarealgorithms,225-226 OpenMP,183-185,312-313
NUMAmode,238-239 openoperatingsystems,634
NVMdevices,seenonvolatilememory open-sourceoperatingsystems,46-51
devices OpenSystemsInterconnection(OSI)
NVMexpress(NVMe),456 model,741-744
NVS(nonvolatilestorage),14,449 operatingsystem(s):
applicationspecificityto,77-79
O booting,94-95
building,92-93
objects: closed-source,46
accesslistsfor,679-680 computingenvironments,40-46
incache,428 CPUschedulingin,234-244
container,664 Linuxscheduling,234-239
critical-section,297,888 Solarisscheduling,242-244
defined,672 Windowsscheduling,239-242
dentry,605,804,805 debugging,95-100
device,863 defined,1,3,5-7
directory,850 designgoalsfor,79-80
dispatcher,297,845-846 featuresof,3
driver,863 functioningof,4-7
event,845 implementationof,80-81
file,605,804-805,862 kerneldatastructures,36-40Index 989
linkersandloaders,75-77 file,603
network,36 asuserclass,551
open-source,46-51 ownerrights,678,817
operations,21-27
dual-modeandmultimode,24-26 P
multiprogrammingandmultitasking,
23-24 p(pagenumber),360
andtimer,26-27 PaaS(platformasaservice),44
reasonsforstudying,6 packagedapplications,859
asresourceallocator,5 packagesystems,823
resourcemanagementby,27-32 PAE(pageaddressextension),381
securityin,623-624 pages.Seealsospecifictypes
servicesprovidedby,55-58 defined,360
structure,81-91 locking,434-436
hybridsystems,86-91 obtainingsizeof,364
layeredapproach,83-84 pageaddressextension(PAE),381
microkernels,84-86 pageallocator(Linux),796
modules,86 page-bufferingalgorithms,412
monolithic,82-83 pagecache,583,798
studyof,50 pagedirectory,381,853
systemcalls,62-74 page-directoryentries(PDEs),853
andAPI,63-66 pagedirectorypointertable,381
functioningof,62-63 pagefaults,394-395,405,416
typesofcalls,66-74 page-fault-frequency(PFF),424-425
systemservices,74-75 page-faultrate,398,423
system’sviewof,5 pageframes,853
threadsin,194-196 page-framenumber(PFN)database,856
userinterfacewith,4-5,58-62 pagein,377
virtualizationcomponents,719-726 pagelocking,434-436
CPUscheduling,720 pagenumber(p),360
I/Odevices,722-723 pageoffset(d),360
livemigration,724-726 pageout,377
memorymanagement,721-722 pageoutpolicy(Linux),800
optimalpagereplacement,406-407 pageoutprocess(Solaris),439
optimalpagereplacementalgorithm, pagereplacement,401-413.Seealsoframe
406-407 allocation
optimisticapproach,285 andapplicationperformance,412-413
OracleSPARCSolaris,375-376 basicmechanism,401-404
OrangeBook,826 counting-basedpagereplacement,
ordinarypipes,140-143 411-412
org(top-leveldomain),739 defined,401
orphanprocesses,122 FIFOpagereplacement,404-406
OS/2operatingsystem,821-822 globalvs.local,415-418
OSImodel,741-744 LRU-approximationpagereplacement,
OSInetworkmodel,741-744 409-411
OSIprotocolstack,742-744 LRUpagereplacement,407-409
otherusers(class),551 optimalpagereplacement,406-407
out-of-bandkeydelivery,644 andpage-bufferingalgorithms,412
out-of-memory(OOM)killers,418 pagereplacementalgorithm,403
over-allocationofmemory,401 pagesize,363,364,431-432
overcommitment,720 pageslots,469
over-provisioning,454 pagetable(s),361-378,393
owners: clustered,374
clock,837 defined,361990 Index
fordemandpaging,395 raw,468
forward-mapped,371 root,601
hardwareforstoring,365-368 storagedevice,463-465
hashed,373-374 variable-partitionschemes,358
forhierarchicalpaging,371-373 partitionbootsector,566
inverted,374-375,433 partitioning,device,463-464
nested,710,712 passphrases,651
OracleSPARCSolaris,375-376 passwords,554,649-652
page-tablebaseregister(PTBR),365 pathnames,544,546
page-tableentries(PTEs),853 path-nametranslation(NFS),614-615
page-tablelengthregister(PTLR),369 PB(petabyte),12
paging,360-376 PCBs(processcontrolblocks),109-110
basicmethod,360-365 PCIebus,490
demand,392-399,430-436 PCmotherboard,20
basicmechanism,393-396 PCS(process-contentionscope),217-218
defined,393 PCsystems,874
free-framelist,396-397 PDEs(page-directoryentries),853
withinvertedpagetables,433 peer-to-peercomputing,43-44
andI/Ointerlock,434-436 peer-to-peerdistributedsystems,734
andpagesize,431-432 PE(PortableExecutable)format,77
andperformance,397-399 penetrationtest,654
andprepaging,430-431 performance:
andprogramstructure,433-434 andallocationofsecondarystorage,
pure,395 578-579
andTLBreach,432-433 anddemandpaging,397-399
hardware,365-368 andfilesystemimplementation,583-586
forhashedpagetables,373-374 andI/Osystem,521-524
hierarchical,371-373 andpagereplacement,412-413
IA-32,380-381 RAIDstructuretoimprove,475
inverted,374-375 underswapping,378
inLinux,800 virtualizationrequirementrelatedto,
andmemoryprotection,368-369 704
andOracleSPARCSolaris,375-376 ofWindows10,831-833
priority,440 performancemonitoring,96-97
andsharedpages,369-371 performancetuning,95-97
swappingwith,377,378 periodicprocesses,230
pagingfiles 851 periodictaskrate,230
pairedpasswords,652 permanentrevocation,682
PAM(pluggableauthentication permissions,553,669
modules),816 permittedcapabilities,685
PAN(personal-areanetwork),36 per-processopen-fil table,567
parallelfilesystem(PFS),768 per-processtools,96,97
parallelism,163,165-166,475 personal-areanetwork(PAN),36
parallelization,20 personalcomputer(PC)systems,874
parallelregions,183-184 personalfire alls,660
paravirtualization,703,716-717 personalidentificatio number(PIN),652
parent-childrelationship,140 personalities,87,787
parentprocess,111 pessimisticapproach,285
partialrevocation,682 petabyte(PB),12
partialslabs,429,798 Peterson’ssolution,262-265
partitions: PFF(page-fault-frequency),424-425
boot,465 PFNdatabase,856
control,714 PFS(parallelfilesystem),768
file-system,601-602 phishing,624Index 991
PHY(ports),490 well-known,146
physicaladdress,354,379 portability,834-835
physicaladdressspace,353-355 PortableExecutable(PE)format,77
physicalformatting,463 portals,40
physicallayer,741,742 portdriver,864
physicalmemory,24,362,390,391,795-798 portnumber,746-747
physicalsecurity,623 portrights,135
physical-to-virtual(P-to-V)conversion, portscanning,637
724 position-independentcode(PIC),803
PIC(position-independentcode),803 positioningtime(disks),450
Picoprocess,91 POSIX:
PicoProviders,823 interprocesscommunicationexample,
pid(processidentifier) 116,787 132-135
PIN(personalidentificatio number),652 real-timescheduling,232-234
pinning,436,866 synchronizationexamples,299-303
PIO(programmedI/O),498 POSIX1e,685,686
pipes,139-145 possession(ofcapability),680
anonymous,141-145 POST(power-onself-test),872
implementationconsiderations,139-140 postingmessages,891
named,143-145,881-882 powerframework(PoFX),870
ordinary,140-143 powermanagement,514-516
useof,146 powermanager(Windows10),870-871
pipemechanism,813 power-of-2allocator,427
platformasaservice(PaaS),44 power-onself-test(POST),872
platter(disks),450 powerusers,60-61
PLM(ProcessLifetimeManager),837 PPTP(Point-to-PointTunneling
plug-and-playand(PnP)managers, Protocol),881
869-870 P+Qredundancyscheme,478
pluggableauthenticationmodules preemptivekernels,262
(PAM),816 preemptivemultitasking,790
plug-inprocess,124 preemptivescheduling,202-203
PnPmanagers,869-870 premastersecret(TLS),647
PoFX(powerframework),870 prepaging,430-431
Point-to-PointTunnelingProtocol presentationlayer,742
(PPTP),881 primarythread,890
policy(-ies),80 principleofleastprivilege,626,627,
cacheupdating,766-767 668-669
delayed-write,766 priority(field) 243
group,884 priority-basedscheduling,229-230
mandatory,826 priority-inheritanceprotocol,284
mechanismsvs.,668 priorityinversion,284,285
pageout,800 prioritynumber,281
security,653 prioritypaging,440
write-on-close,766-767 priorityreplacementalgorithm,420-421
write-through,766 priorityschedulingalgorithm,211-214
policyalgorithm(Linux),800 privatecloud,44
polling,493-494 privatedispatchqueues,185
polymorphicviruses,633 privatekeys,641
pools,177-180,483,889 privilegedinstructions,25
pop,66 privilegedmode,seekernelmode
ports,78,129,490 privilegeescalation,623
connectionandcommunication,138 privilegeseparation,669
namingof,135-136 procedurallanguages,313
inremoteprocedurecalls,150 procedures,asdomains,674992 Index
process(es),23,105-154 ProcessLifetimeManager(PLM),837
aborting,342 processmanagement:
background,74-75,115,123,215,241 about,27-28
browser,124 inLinux,786-790
communicationbetween,see Windows10,886-891
interprocesscommunication processmanager(Windows10),858-860
componentsof,106-107 processmigration,752-753
consumer,126-127,290,291,559-560 processname,73
contextof,788-789 processors,18
cooperating,123,257 distributedsystem,734
coordinationamong,260 front-end,522
daemon,690 ideal,242,842
defined,103,105 Intel,379-382
dispatched,112 event-vectortable,496
asdomains,674 IA-32architecture,379-382
empty,123 IA-64architecture,382
environmentof,787-788 threadbuildingblocks,186-188
foreground,115,122,215,241 logical,832
guest,702 multi-,18,220
idle,872 multicore,221-224
independent,123 processoraffinit ,225-226
init,117 processorgroups,832
I/O-vs.CPU-bound,112 processreflection 860
jobvs.,106 processrepresentation(Linux),111
lightweight,193 processscheduler,110-112
inLinux,789-790 processscheduling,110-115,199,234
multithreaded,seemultithreaded processsynchronization,260.Seealso
processes;multithreading synchronizationtools
operationson,116-123 processtermination,deadlockrecovery
creation,116-121 by,342
termination,121-123 /procfilesystem(Linux),808-810
orphan,122 procfs(fil system),598
parent,111 producerprocess,126-127,290,558-559
passingdatabetween,813 productionkernels(Linux),777
periodic,230 programcounters,27,106,109
Pico,91 programexecution(operatingsystem
plug-in,124 service),56
producer,126-127,290,558-559 programloadingandexecution,74
renderer,124 programmableintervaltimer,505
service,123 programmedI/O(PIO),498
sibling,111 programmerinterface(Windows10),
single-threaded,160 884-895
stateof,107-109 IPCwithWindowsmessaging,891-892
system,872 kernelobjectaccess,884-885
systemd,117 memorymanagement,892-895
threadsperformedby,110 processmanagement,886-891
visible,122 sharingobjectsbetweenprocesses,
inWindows10,886 885-886
zombie,122 programming:
process-contentionscope(PCS),217-218 multi-,23,112,420
processcontrolblocks(PCBs),109-110 multicore,162-166
process-controlsystemcalls,66-71 programming-environment
processidentifie (pid),116,787 virtualization,703,717
processidentity(Linux),787 programminglanguages,313-314Index 993
programming-languagesupport,74 publickeys,641
programstructure,fordemandpaging, public-keyencryption,641
433-434 pullmigration,224
programthreats,625-634 purecode(reentrant),370
codeinjection,628-631 puredemandpaging,395
malware,625-628 pushing,66,519
viruses,631-634 Pushlocks,831
worms,631,632 pushmigration,224
progress(requirement),260 putcommand,751
projects,244
proportionalallocation,414-415 Q
proportionalsharescheduling,233
proprietarysoftware,46-47 Quest-V,729
protection,667-698 queue(s),38
accessmatrixmodel,675-685 dispatch,185
implementation,679-682 main,185
mandatoryaccesscontrol,684-685 ready,112,221,843
andrevocationofaccessrights, scheduling,112-113
682-683 wait,112
role-basedaccesscontrol,683-684 queuingdiagram,112,113
capability-basedsystems,685-687 queuing-networkanalysis,247
codesigning,690
incomputersystems,33-34 R
withcontiguousmemoryallocation,357
domainof,671-675 racecondition,259,261
file,531 RAID(redundantarraysofinexpensive
file-systeminterface,550-555 disks),473-485
goalsof,667-668 extensions,481-482
I/O,512 levelsof,475-481
language-basedsystems,690-696 forobjectstorage,483-485
compiler-basedenforcement,691-693 performanceimprovement,475
inJava,694-696 problemswith,482-483
asoperatingsystemservice,57-58 reliabilityimprovement,473-475
inpagedenvironment,368-369 structuring,474
andprincipleofleastprivilege,668-669 RAIDlevel0,476
ringsof,669-671 RAIDlevel0+1,478-479
sandboxing,689-690 RAIDlevel1,476
staticvs.dynamic,673 RAIDlevel1+0,478-479
system-callfiltering,688 RAIDlevel4,476-477
systemintegrity,687-688 RAIDlevel5,477-478
fromviruses,657-659 RAIDlevel6,478
protectiondomains,671-675,711 RAIDlevels,475-481
protectionmask(Linux),817 common,475-478
protectionrings,25,669-671 selecting,480-481
protectionsystemcalls,73-74 variationsin,478-480
pseudo-devicedriver,721-722 raisinginterrupts,9,494
PTBR(page-tablebaseregister),365 RAM(random-accessmemory),11
PTEs(page-tableentries),853 RAMdrives,454,455
PTEtables,853 random-accessdevices,502
Pthreads,169-171,218-219 random-accessmemory(RAM),11
PTLR(page-tablelengthregister),369 random-accesstime(disks),450
P-to-Vconversion,724 range(value),187
publiccloud,44 ransomware,626
publicdomainsoftware,779-780 RAT(RemoteAccessTool),625994 Index
rate-monotonicscheduling,230-232 redundantarraysofinexpensivedisks,
rate-monotonicschedulingalgorithm, seeRAID
230-232 reentrantcode(purecode),370
rawdisk,413,464,601 reentrantlocks,307-308
rawI/O,464,465,503-504 reference,localityof,395
rawpartitions,468 referencebits,409
RBAC(role-basedaccesscontrol),683-684 referencedpointer,849
RDP,707 referencestring,404,406
reacquisition,ofcapabilities,682 reflection process,860
readaccess,lockswith,292 reflecto,864
read-aheadtechnique,585 regions,383
read-end(ofpipe),140 register(s):
readers,291,292 base,351-352
readers-writersproblem,290-293 control,492
reader-writerlocks,292-293 CPU,110
readingfiles,532,551 data-in,492
data-out,492
read-modify-writecycle,477
instruction,12
readonlydevices,502
limit,351-352
readpointer,532
memory-address,354
read-writedevices,502
page-tablebase,365
readyqueues,112,221,843
page-tablelength,369
readystate,108,109
relocation,354
real-timeclass,239
status,492
real-timeCPUscheduling,227-234
translationtablebase,383
earliest-deadline-firstscheduling,
registry,74,871-872
232-233
regressiontesting,249
andminimizinglatency,227-229
relativeaccess,539-540
POSIXreal-timescheduling,233-234
relativeblocknumber,540
priority-basedscheduling,229-230
relativepathnames,546
proportionalsharescheduling,233
release,ofresources,318
rate-monotonicscheduling,230-232
reliability:
real-timeembeddedsystems,45-46
ofdistributedsystems,735
real-timeoperatingsystems,46
RAIDforimproving,473-475
real-timerange(Linuxschedulers),790
ofTCP,748
real-timescheduling(Linux),792
ofUDP,747
reapers,417-418
ofWindows10,828-829
receives,blockingvs.nonblocking,130
relocatablecode,353
reconfiguration 755 relocatableobjectfile,75
records:
relocation,75,76
activation,107
relocationregister,354
basefile,876 remaindersection,260
logical,539 RemoteAccessTool(RAT),625
masterboot,465,466 remotedesktop,874
recovery: remotefil access,764-767
fromdeadlock,341-343 remotefile-systems 605-608
fromfailure,755-756 remotefil transfer,750-751
andfilesystemimplementation,586-589 remotelogin,750
Windows10,877-878 remoteoperations(NFS),615
recoverymode,95 remoteprocedurecalls(RPCs),149-153,
red-blacktrees,38,40 834
RedHat,779 remote-servicemechanism,764
redirectors,882-883 removablestoragemedia,451
redundancy,473-475 remove()method,305-307Index 995
renamingfiles 542 rights:
rendererprocesses,124 access,534,673,680,682-683
rendezvous,131 copy,677
repair,meantimeto,474 group,817
replacement,page,seepagereplacement owner,678,817
replayattacks,622 port,135
replication,480,592-593 user,817
replyport,135 world,817
repositioning(infiles) 532 rings,protection,669-671
Request(datastructure),335-336,339,340 riskassessment,653-654
requests,forresources,318 roamingprofiles 883
requestconsumer(circularbuffer),716 robustness,distributedsystem,754-756
requestedge,323 roles,683
requestmanager,811 role-basedaccesscontrol(RBAC),683-684
requestproducer(circularbuffer),716 rollback,343
residentattributes,876 rootdirectory,877
resolution: rootkitviruses,632
addressresolutionprotocol,745 rootpartition,601
conflict,784,785 rotationallatency(disks),451
oflinks,548 rotationsperminute(RPM),450
name,738-741 roundrobin,130
andpagesize,431-432 round-robin(RR)schedulingalgorithm,
resourceallocation(operatingsystem 209-211
service),57 routers,736
resource-allocationgraph,323-326,334, RPCs(remoteprocedurecalls),149-153,
338 834
resource-allocation-graphalgorithm,333 RPM(rotationsperminute),450
resourceallocator,operatingsystemas,5 RRschedulingalgorithm,209-211
resourcearbiters,869 RSAalgorithm,641,642
resourcemanagement,27-32 RTE(run-timeenvironment),64-65
resourcepreemption,deadlockrecovery RTF(richtextformat),658
by,342-343 runningstate,108,109
resource-requestalgorithm,335 runningsystem,94
resourcesharing,162,734-735 runtime,virtual,236
resourceutilization,4 run-time-basedenforcement,694-696
responses(password),652 run-timeenvironment(RTE),64-65
responseconsumer(circularbuffer),716
responseproducer(circularbuffer),716
S
responsetime,23,205
responsibility,forrun-time-based
enforcement,694 SaaS(softwareasaservice),44
responsiveness,multithreadedprocess, safecomputing,658
162 safesequence,331
restartarea,878 safestate,331-333
restore,state,114 safety,asvirtualizationrequirement,704
restorepoint,system,871 safetyalgorithm,335
restoringdata,588-589 sandbox,124,658
resuming,717,888 sandboxing,689-690
returnfromsleep,243 SANs,seestorage-areanetworks
reverseengineering,47 SASbuses,456,490
revocationofaccessrights,682-683 SATAbuses,456
RHEL7,461 save,114,592
richtextformat(RTF),658 scalability,162,484,756-757
rightchild,38 SCANscheduling,458-459996 Index
SCAN(elevator)schedulingalgorithm, secondarymemory,395
458-459 secondarystorage,13.Seealsodisk(s)
scatter-gathermethod,498,508 allocationof,570-578
schedulers: contiguousallocation,570-573
CFQ,461,811 indexedallocation,575-577
CompletelyFair,236,237,790 linkedallocation,573-575
CPU,113-114,201 andperformance,578-579
deadline,460,461 connectionmethodsfor,456
Linux,790 second-chancepage-replacement
NOOP,461 algorithm(clockalgorithm),
process,110-112 410-411
scheduleractivation,192-194 secondextendedfilesystem(ext2),805
scheduling: second-levelinterrupthandler(SLIH),
cooperative,202 496
CPU,seeCPUscheduling secondreaders,291
C-SCAN,460 sectionobjects,139,852
earliest-deadline-first,232-233 sectors,450,466,566
fair,791 sectorslipping,467
FCFS,458,459 sectorsparing,466
HDD,457-461 SecureBoot,872
I/O,508-509 securebydefault,634
job,106 securekernel,839-840
inLinux,790-794 SecureMonitorCall(SMC),670
multi-processor,seemulti-processor secureshell,116
scheduling securesystemprocess,872
nonpreemptive,202 securesystems,622
NVM,461-462 SecureWorld,838
preemptive,202-203 security,621-665.Seealsoprotection
priority-based,229-230 ofcompiler-basedenforcement,692
process,110-115,199,234 incomputersystems,33-34
proportionalshare,233 cryptographyfor,637-648
rate-monotonic,230-232 andencryption,638-645
real-time,792 implementation,645-646
SCAN,458-459 TLSexample,646-648
selectingdisk-schedulingalgorithm, implementationof,653-662
460-461 andaccounting,659
shortest-remaining-time-first,209 andauditing,659
thread,199,790-791,844-845 andfirewalling,659-660
user-mode,241,833,890-891 andintrusionprevention,655-657
inWindows10,887 levelsofdefenses,661-662
schedulingclasses,236 andlogging,659
schedulingcontext,788 andsecuritypolicy,653
schedulingdomain,238 andvirusprotection,657-659
schedulinginformation,CPU,110 andvulnerabilityassessment,653-655
schedulingrules,887 inLinux,816-818
SCM(servicecontrolmanager),870 asoperatingsystemservice,57-58
scope: asproblem,621-625
contention,217-218 andprogramthreats,625-634
oflock,305 codeinjection,628-631
scriptkiddies,631 malware,625-628
scripts,shell,61,536 viruses,631-634
SCS(system-contentionscope),218 worms,631,632
searching,forfiles,541,542 andsystem/networkthreats,634-637
searchpath,545 userauthenticationfor,648-653Index 997
inWindows10,662-664,826-828,878 serversystems,42-43,734,874-875
securityaccesstokens(Windows10),662 service(s):
securitycontext(Windows10),662-663 defined,757
securitydescriptor(Windows10),663 denialof,622,636
securitydomains,659 distributednaming,607
securityID(SID),33,867 high-availability,19
securitypolicy,653 infrastructureas,44
securityreferencemonitor(SRM),866-869 log-file,878
security-through-obscurityapproach,655 networkinformation,607
securitytokens,867 operatingsystem,55-58,74-75,115,152
seek,file,532 platformas,44
seektime(disks),450 softwareas,44
segmentation,IA-32,379-380 theftof,622
selectiverevocation,682 servicecontrolmanager(SCM),870
semantics,510,608-609 serviceprocesses,123
semaphore(s),272-276 service-triggermechanism,870
binary,273 session(s),751,874
counting,273 session0,873
defined,272 sessionhijacking,623
dining-philosopherssolutionwith, sessionkey,647
294-295 sessionlayer,742
implementation,274-276 sessionmanagersubsystem(SMSS),
inJava,308-309 872-873
monitorsusing,280-281 sessionsemantics,609
named,300-301 sets:
POSIXexamples,300-302 entry,303,304,307
unnamed,300-302 hardworking-setlimits,438
usageof,273-274 ofholes,358
semaphoreobjects(Windows10),845 SMT,242
semiconductormemory,14 wait,304,307
sends,blockingvs.nonblocking,130 working,422-424,438
sendingmessages,891 setuidattribute,34
sensekey,512 setuidbit,674-675
separationhypervisors,729 SHA-1messagedigest,643
sequencenumbers,748 shadowcopies,863
sequentialaccess(files) 539,541 sharabledevices,502
sequentialdevices,502 shares,244
serialATA(SATA)buses,456 shareddirectories,547
serial-attachedSCSI(SAS)buses,456,490 sharedfiles 609
serialdispatchqueue,185 sharedlibraries,356,392
server(s),73 sharedlock,534
blade,18-19 sharedmemory,123,125,556-560
bootstrap,136 shared-memorymodel,57,73,125-127,
inclient-servermodel,606,758-759, 132-136
861-862 sharedreadyqueue,843
defined,757 sharedsysteminterconnect,18
indistributedsystems,734 sharing:
file-serversystems,43 file,602-603
name,739 information,123
andredirectors,882-883 load,220
server-initiatedapproachtoverifying andpaging,369-371
cacheddata,767 resource,162,734-735
ServerMessageBlock(SMB),880 space,592
serversubject(Windows10),663 sharingobjects,885-886998 Index
shells,58,116,783 SMTsets,242
shellscripts,61,536 snapshots,480,588,705,879
shortdurationlocks,272 sniffing 635-636,649-650
shortest-job-firs (SJF)scheduling socialengineering,624
algorithm,207-209 sockets,146-149
shortest-next-CPU-burstalgorithm,207 socketinterface,504
shortest-remaining-time-firs scheduling, softaffinit ,225
209 softerrors,463
shouldersurfing 649 softpagefaults,416
siblingprocess,111 softreal-timesystems,227
SID(securityID),33,867 software:
SiemensJailhouseproject,729 processmigrationand,753
signals,188-189,812-813 proprietary,46-47
signal-and-continuemethod,279 publicdomain,779-780
signal-and-waitmethod,279 softwareasaservice(SaaS),44
signaledstate,297 softwareengineering,80
signalhandlers,188-189 softwareinterrupts(traps),497
signal-handlertable,789 softwareobjects,672
signatures,633,643,656,828 softwaretransactionalmemory(STM),
signature-baseddetection,656 312
silos,859 Solaris,51
SIMD,833 filesystemsin,482-484,597,599
simplemessages,136 OracleSPARC,375-376
simplesubject(Windows10),662 schedulingexample,242-244
simulations,248-249 virtualmemoryin,438-440
simultaneousmultithreading,222 ZFSfilesystem,482-484,581,588,598
singleindirectblocks,576 Solaris10:
single-leveldirectories,542-543 role-basedaccesscontrolin,683,684
single-processorsystems,15-16 zonesin,718,719
singlestep(mode),72 solid-statedisks(SSDs),452
single-threadedprocesses,160 source-codeviruses,633
single-usermode,95 sourcefiles 530
singlylinkedlists,37 spacemaps,581
SIP(SystemIntegrityProtection),687-688 spacesharing,592
Siri,5 SPARC,375-376
sites,distributedsystem,734 sparseness,374,391
64-bitcomputing,383 specialinstructions,709
SJFschedulingalgorithm,207-209 special-purposefil systems,597-598
sketch,70 specifications threadbehavior,169
slabs,427-429,797-798 speedofoperations(I/Odevices),502
slaballocation,427-430,797-798 spinlocks,272
Slackware,779 split-screen,115
sleep,returnfrom,243 spoofedidentifiers 606
SLIH(second-levelinterrupthandler), spoofing 636
496 spools,511
slimreader-writer(SRW)locks,889 spooling,511
SLOBallocator,430 Springboardinterface,60,87
SLUBallocator,430 spyware,626
smallobjects,430 SRM(securityreferencemonitor),866-869
SMB(ServerMessageBlock),880 SRW(slimreader-writer)locks,889
SMC(SecureMonitorCall),670 SSDs(solid-statedisks),452
SMP,seesymmetricmultiprocessing stacks,37-38,66
SMSS(sessionmanagersubsystem), device,862
872-873 LRUpagereplacementwith,408Index 999
OSIprotocol,742-744 streamingtransferrate,486
stackalgorithms,408-409 streammodules,519
stackinspection,694,695 STREAMSmechanism,519-521
stacksection(ofprocess),107 string,reference,404,406
stalling,350 stronglyorderedmodel,265
standardswapping,377 strongpasswords,651
standbypage,856 stubs,150
starvation(indefinit blocking),213,343 subjects(Windows10),662-663
states: subsets,stackalgorithm,408
application,378 subsystems,75
new,108 SunOS,51
nonsignaledvs.nonsignaled,297 superblock,566
ofprocesses,107-109 superblockobjects,605,804,805
ready,108,109 supervisormode,seekernelmode
running,108,109 SuSE,779
safe,331-333 suspendedstate,705,888
suspended,705,888 swapmap,469
terminated,109 swapping,113-114,376-378
unsafe,332-334 inLinux,800
waiting,108,109 onmobilesystems,377-378
stateinformation,608 withpaging,377,378
statelessDFS,608 standard,377
staterestore,114 systemperformanceunder,378
statesave,114 swapspace,395,468-469
staticlinking,355-356,803 swap-spacemanagement,467-469
staticprotection,673 SwitchBranchmechanism,830
statusinformation,74 switches,context,114-115,204
statusregister,492 switching:
stealthviruses,633 domain,673,674
STM(softwaretransactionalmemory), fast-user,825,874-875
312 symboliclinks,879
storage,11-14.Seealsomass-storage symmetricclustering,20
structure symmetricencryption,639-640
cloud,471,751 symmetricencryptionalgorithm,639
content-addressable,484 symmetricmultiprocessing(SMP),16,
definitionsandnotations,12 220,794
host-attached,470 symmetry,inaddressing,129
network-attached,470-471 synchronization,130-131,289-314
nonvolatile,14,449 alternativeapproachesto,311-314
object,483-485 block,305
secondary,13,456,570-578.Seealso bounded-bufferproblem,290
disk[s] dining-philosophersproblem,293-295
tertiary,13 forinterprocesscommunication,812-813
thread-local,192,894,895 inJava,303-311
utility,481 conditionvariables,309-311
volatile,11 monitors,303-307
storage-areanetworks(SANs),21,470,472 reentrantlocks,307-308
storagearray,472-473,481 semaphores,308-309
storageattachment,469-473 kernel,295-299,792-794
storagedevices,organizationof,597,598 inLinux,130-131,812-813
storagedevicemanagement,463-467 inmessage-passingmodel,130-131
storagemanagement,30,32,723 inPOSIX,299-303
streamciphers,640 process,260.Seealsosynchronization
streamhead,519 tools1000 Index
readers-writersproblem,290-293 systemlibraries(Linux),781
thread,888-889 systemmode,seekernelmode
synchronizationprimitives,845-846 systemmodel,fordeadlocks,318-319
synchronizationtools,257-287 systemprocesses,872
about,257-260 systemprograms,6
critical-sectionproblem,260-270 systemresource-allocationgraph,323-326
hardwaresolutionto,265-270 systemrestorepoint,871
Peterson’ssolutionto,262-265 systemutilities,74-75,781
evaluationof,284-286 SystemVinit,117
andliveness,283-284 system-wideopen-fil table,567
monitorsfor,276-282 system-widetools,96,97
resumptionofprocesseswithin,
281-282
T
semaphores,implementationusing,
280-281
usage,277-280 table(s).Seealsopagetable(s)
mutexlocks,270-272 attribute-definition,877
semaphoresfor,272-276 device-status,508-509
synchronousdevices,502,506,507 event-vector,11
synchronousmessagepassing,130 file,788
synchronousthreading,169 file-allocation,574-575
synchronouswrites,585 frame,365
systemadministrators,60 global,679
systembuild,92 globaldescriptor,379
systemcalls(monitorcalls),22,62-74 handle,849
andAPI,63-66 hash,570
clone(),195-196 masterfile,566
forcommunication,72-73 mount,517,567
fordevicemanagement,71-72 open-file,533,567
exec(),188 pagedirectorypointer,381
forfilemanagement,71 per-processopen-file,567
fork(),188 PTE,853
functioningof,62-63 signal-handler,789
forinformationmaintenance,72 system-wideopen-file,567
forI/O,512,513 tags,680
forprocesscontrol,66-71 tapes,magnetic,455
forprotection,73-74 targetlatency,236,791
system-callfiltering,688 targetthread,190
system-callfirewalls,660 tasks,106,135,195,234.Seealsouser
system-callinterface,65 programs(usertasks)
systemcomponents(Windows10), taskcontrolblocks,seeprocesscontrol
838-874 blocks
executive,848-874 taskidentification formulticore
hardware-abstractionlayer,840 programming,163
hyper-Vhypervisor,839 taskparallelism,165,166
kernel,840-848 TaskSelfport,135
securekernel,839-840 TB(terabyte),12
system-contentionscope(SCS),218 TBBs(threadbuildingblocks),186-188
systemdaemons,22,781 TCP(transmissioncontrolprotocol),
system-developmenttime,705 743-749
systemdisk,465 TCP/IP,seeTransmissionControl
systemdprocess,117 Protocol/InternetProtocol
systemgoals,79 TCPsockets,147
SystemIntegrityProtection(SIP),687-688 TDI(TransportDriverInterface),880Index 1001
TEBs(threadenvironmentblocks), Intelthreadbuildingblocks,186-188
889-890 OpenMPand,183-185
templating,706 threadpoolsand,177-180
temporaryrevocation,682 issues:
terabyte(TB),12 fork()andexcel()systemcalls,188
terminalconcentrators,522 scheduleractivations,192-194
terminalserversystems,874-875 signalhandling,188-190
terminatedstate,109 threadcancellation,190-192
termination,121-123,342 thread-localstorage,192
tertiarystoragedevices,13 multi-,166-168,222,223
testing,multicoreprogrammingin,165 synchronous,169
textfiles 530 threadlibraries,168-176
textsection(ofprocess),106 about,168-169
theftofservice,622 Java,173-176
thin-clientcomputing,874-875 Pthreads,169-171
thinclients,40 Windows,171-173
thirdextendedfilesystem(ext3),805-807 thread-localstorage(TLS),192,894,895
32-bytememory,363,364 threadpools,177-180,889
thrashing,419-425 threadscheduling,199
causeof,419-422 inLinux,790-791
currentpractice,425 inWindows10,844-845
andpage-fault-frequencystrategy, threats,622
424-425 program,625-634
andworking-setmodel,422-424 codeinjection,628-631
threads,159-197.Seealsothreading malware,625-628
alertable,846 viruses,631-634
green,167 worms,631,632
hardware,222 system/network,634-637
idle,239,842 three-wayhandshake,748
Java,173-176 throughput,204-205
kernel,166,217,234 thunking,830
kernel-mode,841 tightlycoupledsystems,83
inLinux,789-790 time:
andmulticoreprogramming,162-166 compile,352
inoperatingsystems,194-196 down,572
andprocessmodel,110 effectiveaccess,397-398
Pthreads,169-171,218-219 effectivememory-access,367
schedulingof,199 execution,353
target,190 load,353
user,166,217 meantimebetweenfailures,473,474
user-mode,841 meantimeofdataloss,474
inWindows10,841-845,886-889,894 meantimetorepair,474
Threadattach,860 positioning,450
threadbuildingblocks(TBBs),186-188 random-access,450
threadcancellation,190-192 response,23,205
threaddumps,339 seek,450
threadenvironmentblocks(TEBs), system-development,705
889-890 turnaround,205
threading: virtualrun,236
asynchronous,169 waiting,205
hyper-,222,832 timequantum,209-211,243
implicit,176-188 timequantumexpired,243
forkjoin,180-183 timers,26-27,505-506
GrandCentralDispatch,185-186 timerobjects,8451002 Index
timeslice,209-211,790-791 truncatingfiles,532
timestamps,531 trustedaddresses,638
timestampcounters(TSCs),845 Trustlets,838
TLB,seetranslationlook-asidebuffer TrustZone(TZ),670,671
TLBmiss,366 TSCs(timestampcounters),845
TLBreach,432-433 tunneling,attackswith,659-660
TLBwalk,376 turnaroundtime,205
TLS(thread-localstorage),192,894,895 twistedpaircables,736
TLS(TransportLayerSecurity),646-648 two-factorauthentication,652
tmpfs(fil system),598 two-leveldirectories,543-545
tophalf(interruptserviceroutines), two-levelmodel,168
793-794 two-levelpage-tablescheme,372-373
totalrevocation,682 type0hypervisors,702,713-714
touchscreens,5 type1hypervisors,703,714-715
touch-screeninterface,56,60 type2hypervisors,703,715-716
tracefiles,248 typesafety(Java),696
tracingtools,97-98 TZ(TrustZone),670,671
tracks,disk,450
traditionalcomputing,40-41 U
traffic network,635-636
transactions,311,587,808 UDP(userdatagramprotocol),743,
transactionalmemory,311-312 746-748
transferrates,450,451,486 UDPsockets,147
transitionpage,856 UEFI(Unifie ExtensibleFirmware
translation: Interface),94
binary,708-710 UFD(userfil directory),543
flashtranslationlayer,453-454 UFS(UNIXfil system),565-566,598
networkaddress,723 UI,seeuserinterface
path-name,614-615 UMDF(User-ModeDriverFramework),
translationgranules,383 864
translationlook-asidebuffer(TLB), UMS,seeuser-modescheduling
365-368,376,384,855 unboundedbuffer,126
translationtablebaseregister,383 unboundedcapacity(ofqueue),132
transmissioncontrolprotocol(TCP), UNC(UniformNamingConvention),881
743-749 uncontendedloads,285
TransmissionControlProtocol/Internet uncontendedlocks,271
Protocol(TCP/IP),36,743-746, unifie buffercache,583-585
880-881 Unifie ExtensibleFirmwareInterface
transparency,756,761 (UEFI),94
TransportDriverInterface(TDI),880 unifie virtualmemory,583
transportlayer,742 UniformNamingConvention(UNC),881
transport-layerprotocol(TCP),645 unikernels,728
TransportLayerSecurity(TLS),646-648 universalserialbuses(USBs),456
traps,22,89,497,847 UniversalWindowsPlatform(UWP),426
trap-and-emulatemethod,707-708 UNIXfil system(UFS),565-566,598
trapdoors,626,627 UNIXoperatingsystem:
traversingfil system,542 consistencysemantics,609
trees,38,39,116 inode,577
tree-structureddirectories,545-547 I/Okernelstructurein,513,514
TRIMingunusedblocks,581-582 permissionsin,553
trimming,automaticworking-set,438 protectiondomainin,674-675
tripleDES,639 systemcalls,68
tripleindirectblocks,576,577 systemstructure,82
Trojanhorses,625-626 unloader,module,783Index 1003
unnameddata,875 atomic,269-270
unnamedsemaphores,300-302 condition,278,279,302-303,309-311,889
unsafestate,332-334 variableclass,239
unstructureddata,484 variable-partitionschemes,358
untrustedappletprotection,695 variabletimer,26
upcalls,193 VCPU(virtualCPU),707
upcallhandler,193 vectoredI/O,507-508
updatingpolicy,cache,766-767 verifie,98
urgencyvalue,223 versioncontrolsystem,49
URLloader,695 vfork()(virtualmemoryfork),400
USBdrive,452 VFS(virtualfilesystem),804-805
USBs(universalserialbuses),456 VFSlayer,601
use,ofresources,318 victim,forresourcepreemption,343
users,4-5,603 victimframes,402
asdomains,674 views,557,852
multiple,filesharingbetween,602-603 virtualaddress,354
otherusers(class),551 virtualaddresscontrolblock(VACB),865
power,60-61 virtualaddressdescriptors(VADs),857
useraccounts,662 virtualaddressspace,390,391,799-800
userauthentication,648-653 VirtualBoxproject,704
usercontrollist,561 virtualCPU(VCPU),707
userdatagramprotocol(UDP),743, virtualfile-systems,603-605
746-748 virtualfilesystem(VFS),804-805
user-define signalhandlers,189 virtualfilesystem(VFS)layer,601
userexperiencelayer(macOSandiOS), virtualization,34-35
87 defined,701
userfil directory(UFD),543 operating-systemcomponentsfor,
usergoals,79 719-726
userIDs,33,531,675 CPUscheduling,720
user-initiatedclass,185-186 I/Odevices,722-723
user-interactiveclass,185 livemigration,724-726
userinterface(UI),4-5,56,58-62 memorymanagement,721-722
usermode,24,25,782 storagemanagement,723
User-ModeDriverFramework(UMDF), para-,703,716-717
864 programming-environment,703,717
user-modescheduling(UMS),241,833, research,728-729
890-891 virtualmachines,34,701-730.Seealso
user-modethreads(UT),841 virtualization
userprograms(usertasks),106,353, benefitsof,704-707
801-803 buildingblocks,707-713
userrights(Linux),817 binarytranslation,708-710
userthreads,166,217 hardwareassistance,710-713
UT(user-modethreads),841 trap-and-emulatemethod,707-708
utilityclass,186 examples,726-728
utilitystorage,481 featuresof,704-707
UWP(UniversalWindowsPlatform),426 historyof,703-704
implementations,713-719
V applicationcontainment,718-719
emulation,717-718
VACB(virtualaddresscontrolblock),865 paravirtualization,716-717
VADs(virtualaddressdescriptors),857 programming-environment
valid-invalidbit,368-369 virtualization,717
validpage,856 type0hypervisors,713-714
variables: type1hypervisors,714-7151004 Index
type2hypervisors,715-716 virtualmemoryfork,400
andvirtualmachinelifecycle,713 virtualmemory(VM)manager,851-858
lifecycle,713 virtualmemoryregions,799
virtualmachinecontrolstructures virtualprivatenetworks(VPNs),646,881
(VMCSs),711 virtualruntime,236
virtualmachinemanagers(VMMs),25-26, virtualtophysical(V-to-P)conversion,
35,702 724
virtualmachinesprawl,713 VirtualTrustLevels(VTLs),838
virtualmemory,24,389-441 virusdropper,632
backgroundon,389-392 viruses,631-634,657-659
andcopy-on-writetechnique,399-401 virussignatures,633
demandpagingforconserving,392-399, visibleprocesses,122
430-436 VMCSs(virtualmachinecontrol
basicmechanism,393-396 structures),711
free-framelist,396-397 VMmanager,851-858
withinvertedpagetables,433 VMMs,seevirtualmachinemanagers
andI/Ointerlock,434-436 VMware,704,726-727
andpagesize,431-432 vnode,604
andperformance,397-399 voiceoverIP(VoIP),44
andprepaging,430-431 voicerecognition,5
andprogramstructure,433-434 volatilememory,454-455
andTLBreach,432-433 volatilestorage,11
directvirtualmemoryaccess,500 volume,464-465,474
andframeallocation,413-419 volumecontrolblock,566
allocationalgorithms,414-415 volumefile,876-877
globalvs.localallocation,415-418 volumeshadowcopies,879
minimumnumberofframes,413-414 voluntarycontextswitches,204
non-uniformmemoryaccess,418-419 vonNeumannarchitecture,12
kernel,801 VPNs(virtualprivatenetworks),646,881
andkernelmemoryallocation,426-430 VSMEnclaves,840
inLinux,798-801 VTLs(VirtualTrustLevels),838
andmemorycompression,425-426 V-to-Pconversion,724
network,765 VT-xinstructions,710
operating-systemexamples,436-440 vulnerabilityassessment,653-655
pagereplacementforconserving,
401-413
W
andapplicationperformance,412-413
basicmechanism,401-404
counting-basedpagereplacement, WAFLfil system,589-593
411-412 wait-forgraph,337,338
FIFOpagereplacement,404-406 waiting,busy,272
LRU-approximationpage waitingstate,108,109
replacement,409-411 waitingtime,205
LRUpagereplacement,407-409 wait()method,305-307
optimalpagereplacement,406-407 waitqueue,112
andpage-bufferingalgorithms,412 waitset,304,307
andthrashing,419-425 wait()systemcall,119,121-122
cause,419-422 WANs,seewide-areanetworks
currentpractice,425 weaklyorderedmodel,265
page-fault-frequencystrategy,424-425 wearleveling,454
working-setmodel,422-424 Web-distributedauthoringand
unified,583 versioning(WebDAV),881
inWin32API,892,893 well-knownports,146
virtualmemorycontext,789 well-knownportnumbers,747Index 1005
wide-areanetworks(WANs),36,735, securekernel,839-840
737-738 terminalservices,874-875
WiFi(wireless)networks,41,736-737 virtualmemoryin,437-438
Win32API,884-895 WindowsDesktopBridge,823
creatingprocess,119-120 WindowsDriverFoundation,864
IPCwithWindowsmessaging,891-892 Windowsexecutive,848-874
kernelobjectaccess,884-885 booting,872-874
memorymanagement,892-895 cachemanager,864-866
processmanagement,886-891 client-servercomputing,861-862
sharedmemory,556-560 I/Omanager,862-864
sharingobjectsbetweenprocesses, objectmanager,849-851
885-886 plug-and-playmanager,869-870
Windowsoperatingsystem(generally): powermanager,870-871
anonymouspipes,141,145 processmanager,858-860
bootingfromstoragedevice,466 registry,871-872
interprocesscommunicationexample, securityreferencemonitor,866-869
138-139 virtualmemorymanager,851-858
schedulingexample,239-242 Windowsgrouppolicy,884
synchronizationwithinkernels,296-298 Windowsmessaging,891-892
systemcalls,68 WindowsStore,823
threads,194-195 WindowssubsystemforLinux(WSL),91
Windows7,465,822 WindowsTaskManager,97
Windows8,823 Windowsthreadlibrary,171-173
Windows10,821-896 WindowsVista,822
access-controllistmanagementin,555 WindowsXP,822
designprinciples,826-838 WinRT,823
applicationcompatibility,830-831 Winsock,891
dynamicdevicesupport,837-838 wireddownentries,366
energyefficiency,836-837 wirelessaccesspoints,736
extensibility,833-834 wireless(WiFi)networks,41,736-737
internationalsupport,835-836 word,11
performance,831-833 Work(datastructure),335,339,340
portabilityof,834-835 workingsets,422-424,438
reliability,828-829 working-setmaximum,438
security,826-828 working-setminimum,438
developments,823-825 working-setmodel,422-424
fast-userswitchingwith,874-875 working-setwindow,422
filesystem,875-879 Workstation(VMWare),726-727
historyof,821-825 workstealingalgorithm,182
networking,880-884 worldrights(Linux),817
programmerinterface,884-895 WorldWideWeb,605,737
IPCwithWindowsmessaging, worms,631,632
891-892 worst-fi strategy,358,359
kernelobjectaccess,884-885 writes,synchronousvs.asynchronous,
memorymanagement,892-895 585
processmanagement,886-891 writeaccess,lockswith,292
sharingobjectsbetweenprocesses, writeamplification 462
885-886 write-anywherefilelayout(WAFL)file
securityin,662-664 system,589-593
systemcomponents,838-874 write-backcaching,766
executive,848-874 write-end(ofpipe),140
hardware-abstractionlayer,840 writeoncedevices,502
hyper-Vhypervisor,839 write-on-closepolicy,766-767
kernel,840-848 writepointer,5321006 Index
writers,291
write-throughpolicy,766
writingfiles,532,551
WSL(WindowssubsystemforLinux),91
X
x86-64architecture,382
XDR(externaldatarepresentation),150
Xen,704,716-717
XMLfirewalls,660
Xtratum,729
Y
yellowpages,607
Z
zerocapacity(ofqueue),131
zero-dayattacks,656
zeroedpage,856
zero-fill-on-deman technique,397
ZFSfilesystem,482-484,581,588,598
zombieprocess,122
zombiesystems,634,635
zones,718,719,79550-percent rule A statistical fi nding that frag- RAM from the memory manager and later commit
mentation may result in the loss of 50 percent of virtual memory on top of those pages.
space.
address-space identifi er A part of a TLB entry
absolute code Code with bindings to absolute that identifi es the process associated with that
memory addresses. entry and, if the requesting process doesn’t
absolute path name A path name starting at the match the ID, causes a TLB miss for address-
top of the fi le system hierarchy. space protection.
abstract data type (ADT) A programming con- address-space layout randomization (ASRL) A
struct that encapsulates data with a set of functions Windows 7 feature that randomizes process mem-
to operate on that data that are independent of any ory addresses to avoid viruses that jump to specifi c
specifi c implementation of the ADT. code locations to gain privileges.
access matrix An abstract model of protection in admission control In real-time scheduling, a
which each row represents a domain, each column practice whereby the scheduler may not allow a
an object, and each entry a set of access rights. process to start if it cannot guarantee that the task
will be serviced by its deadline.
access right The ability to execute an operation
on an object. advanced confi guration and power interface
(ACPI) Firmware common to PCs and servers
access-control list A list of user names allowed
that manages certain aspects of hardware, includ-
to access a fi le.
ing power and device information.
acknowledgment packet In networking, a packet
advanced encryption standard (AES) The NIST
sent in response to the successful receipt of a mes-
cipher designed to replace DES and triple DES.
sage or packet.
activation record A record created when a func- advanced local procedure call (ALPC) In Win-
dows OS, a method used for communication
tion or subroutine is called; added to the stack by
between two processes on the same machine.
the call and removed when the call returns. Con-
tains function parameters, local variables, and the advanced technology attachment (ATA) An older-
return address. generation I/O bus.
active directory (AD) The Windows distributed advisory fi le-lock mechanism A fi le-locking
information system, which is the Windows imple- system in which the operating system does not
mentation of LDAP. enforce locking and fi le access, leaving it to pro-
acyclic graph In directory structure implemen- cesses to implement the details.
tation, a structure that contains no cycles (loops). AFS (OpenAFS) A network fi le system designed
adaptive mutex A Solaris scheduling feature that at Carnegie Mellon University with the goal of
starts as a standard spinlock and, if the object is enabling servers to support as many clients as
locked and the lock is not held by a thread run- possible.
ning on a CPU, blocks and sleeps until the lock is aging A solution to scheduling starvation that
released. involves gradually increasing the priority of
address space layout randomization (ASLR) An threads as they wait for CPU time.
operating system technique to avoid code-injection ahead-of-time (AOT) compilation A feature of
attacks that place memory objects like the stack the Android RunTime (ART) virtual machine envi-
and heap at unpredictable locations. ronment in which Java applications are compiled
address windowing extension (AWE) A Win- to native machine code when they are installed on
dows mechanism for memory allocation that a system (rather than just in time, when they are
allows developers to directly request free pages of executed).
G-1G-2 Glossary
allocation problem The determination by the arbitrary code guard (ACG) A Windows 7
operating system of where to store the blocks of a fi le. exploit-mitigation feature.
Amazon Elastic Compute Cloud (ec2) An instance argument vector In Linux and UNIX, a list con-
of cloud computing implemented by Amazon. taining the command-line arguments used to
AMD 64 A 64-bit CPU designed by Advanced invoke a process (and available to the process).
Micro Devices; part of a class of CPUs collectively ASIC An application-specifi c integrated circuit
known as x86-64. (hardware chip) that performs its tasks without an
AMD-V AMD CPU virtualization technology. operating system.
analytic evaluation A means of comparing assignment edge In a system resource-allocation
scheduling-algorithm effectiveness by analyzing graph, an edge (arrow) indicating a resource
an algorithm against a workload and assigning it assignment.
a score. asymmetric clustering A confi guration in which
anomaly detection In intrusion detection, the one machine in a cluster is in hot-standby mode
use of various techniques to detect anomalous while the other is running applications.
behavior that could be a sign of an attack. asymmetric encryption algorithm A cipher algo-
anonymous access Remote access that allows a rithm in which different keys are used for encryp-
user to transfer fi les without having an account on tion and decryption.
the remote system. asymmetric multiprocessing A simple multi-
anonymous memory Memory not associated processor scheduling algorithm in which only one
with a fi le. Pages not associated with a fi le, if dirty processor accesses the system data structures and
and paged out, must not lose their contents and are others run user threads, reducing the need for data
stored in swap space as anonymous memory. sharing. A boss processor controls the system; the
other processors either look to the boss for instruc-
Apple fi le system (APFS) The 2017 fi le system
tion or have predefi ned tasks.
from Apple that is the default on all modern Apple
devices; features a rich feature set, space sharing, asynchronous In I/O, a request that executes
clones, snapshots, and copy-on-write design. while the caller continues execution.
Apple iOS The mobile operating system created asynchronous procedure call (APC) A facility
by Apple Inc. that enables a user thread to specify a function that
is to be called when the user thread receives notifi -
application component In Android, a basic build-
cation of a particular event.
ing block that provides utility to an Android app.
asynchronous threading Threading in which
application containment A virtualization-like
a parent creates a child thread and then resumes
operating system feature that segregates applica-
execution, so that the parent and child execute con-
tions from the operating system (examples include
currently and independently of one another.
Solaris Zones, BSD Jails, and IBM WPARs).
asynchronous write A write that is buffered
application frameworks layer In the layered
and written in arbitrary order, with the request-
macOS and iOS operating system design, the layer
ing thread continuing execution after the write is
that that includes Cocoa and Cocoa Touch frame-
requested.
works, providing an API for Objective-C and Swift
programming languages. atomic safe-save In APFS, a feature primitive
that performs fi le, bundle of fi les, and directory
application programming interface (API) A set
renaming in single atomic operations.
of commands, functions, and other tools that can
be used by a programmer in developing a program. atomic variable A programming language con-
struct that provides atomic operations on basic
application program A program designed for
data types such as integers and booleans.
end-user execution, such as a word processor,
spreadsheet, compiler, or Web browser. atomically A computer activity (such as a CPU
instruction) that operates as one uninterruptable
application proxy fi rewall A fi rewall that under-
unit.
stands protocols spoken by applications across a
network, accepts connections to a target, and cre- attack An attempt to break a computer system’s
ates connections to that target, limiting and fi xing security.
what is sent from the originator. attack surface The sum of the methods available
application state A software construct used for to attack a system (e.g., all of the network ports
data storage. that are open, plus physical access).Glossary G-3
attacker Someone attempting to breach a com- scheme but able to deal with multiple instances of
puter system’s security. each resource type.
attribute In the Windows NTFS fi le system, one base fi le record In the Windows NTFS fi le sys-
of the elements making up a fi le. Each fi le is seen as tem, a descriptor of a large fi le containing pointers
a structured object consisting of typed attributes, to overfl ow records that hold additional pointers
with each attribute an independent byte stream and attributes.
that can be created, deleted, read, and written. base register A CPU register containing the start-
audit trail The collection of activities in a log for ing address of an address space. Together with the
monitoring or review. limit register, it defi nes the logical address space.
authentication The process of correctly identify- basic fi le system A logical layer of the operating
ing a person or device. In cryptography, constrain- system responsible for issuing generic commands
ing the set of potential senders of a message. to the I/O control layer, such as “read block x,”
and also buffering and caching I/O.
automatic working-set trimming In Windows, a
process whereby, if a threshold of minimum free batch interface A method for giving commands
memory is reached, the number of working-set to a computer in which commands are entered
frames is decreased for every process. into fi les, and the fi les are executed, without any
human interaction.
automount A network/distributed fi le system
feature in which fi le systems from remote servers Bayes’ theorem A formula for determining con-
are automatically located and mounted as needed. ditional probability—e.g., the probability of an
intrusion record detecting a real intrusion.
autoprobe In Linux, a device driver probe that
Belady’s anomaly An anomaly in frame-
auto-detects device confi guration.
allocation algorithms in which a page-fault rate
B+ tree A tree data structure in which every path
may increase as the number of allocated frames
from the root of the tree to the leaf is the same length.
increases.
back door A daemon left behind after a success-
best-fi t In memory allocation, selecting the
ful attack to allow continued access by the attacker.
smallest hole large enough to satisfy the memory
In cryptography, a method of gaining access to
request.
encrypted information without fi rst having the
big data Extremely large sets of data; distributed
secret keys. More generally, a method of passing
systems are well suited to working with big data.
arbitrary commands or information when an inter-
face does not provide a standard method. big.LITTLE ARM processor implementation
of HMP in which high-performance big cores are
background Describes a process or thread that is
combined with energy effi cient LITTLE cores.
not currently interactive (has no interactive input
directed to it), such as one not currently being used big-endian A system architecture in which the
by a user. In the Grand Central Dispatch Apple OS most signifi cant byte in a sequence of bytes is stored
scheduler, the scheduling class representing tasks fi rst.
that are not time sensitive and are not visible to binary search tree A type of binary tree data
the user. structure that requires an ordering between the
backing store The secondary storage area used parent’s two children in which left child ⇐ right
for process swapping. child.
binary semaphore A semaphore of values 0 and
backup In fi le systems, a copy or copies of the
1 that limits access to one resource (acting similarly
fi le system or changes to the fi le system that can
to a mutex lock).
be used to restore the fi le system if it is damaged
or destroyed. binary translation A virtualization method in
which, when a guest is running in virtual kernel
bad block An unusable sector on an HDD.
mode, every instruction is inspected by the virtual
balanced binary search tree A tree containing n
machine manager, and instructions that would
items that has, at most, lg n levels, thus ensuring
behave differently in real kernel mode are trans-
worst-case performance of O(lg n).
lated into a set of new instructions that perform
bandwidth The total amount of data transferred the equivalent task; used to implement virtual-
divided by the total time between the fi rst request ization on systems lacking hardware support for
for service and the completion of the last transfer. virtualization.
banker’s algorithm A deadlock avoidance algo- binary tree A tree data structure in which a par-
rithm, less effi cient than the resource-allocation graph ent may have at most two children.G-4 Glossary
binder In Android RPC, a framework (system blocked until the message is received by the receiv-
component) for developing object-oriented OS ser- ing process or by a mailbox and the receiver blocks
vices and allowing them to communicate. until a message is available. In I/O, a request that
does not return until the I/O completes.
bind Tie together. For example, a compiler binds
a symbolic address to a relocatable address so the block-level striping The splitting of data at the
routine or variable can be found during execution. block level, with each block stored on a separate
device.
Bionic A type of standard C library used by
Android; it has a smaller memory footprint than boot block A block of code stored in a specifi c
glibc and is more effi cient on slower (mobile) location on disk with the instructions to boot the
CPUs. kernel stored on that disk. The UFS boot control
block.
BIOS Code stored in fi rmware and run at boot
time to start system operation. boot control block A storage block of data con-
taining information needed by the system to boot
bit The basic unit of computer storage. A bit can
from the volume containing the block.
contain one of two values, 0 or 1.
boot disk A disk that has a boot partition and a
bit vector A string of n binary digits that can be
kernel to load to boot the system. A device that has
used to represent the status of n items. The availabil-
a boot partition and can store an operating system
ity of each item is indicated by the value of a binary
for booting the computer.
digit: 0 means that the resource is available, while 1
boot partition A storage device partition con-
indicates that it is unavailable (or vice-versa).
taining an executable operating system.
bit-level striping The splitting of data at the bit
boot sector The fi rst sector of a Windows boot
level, with each bit in a byte or word stored on a
device, containing the bootstrap code.
separate device.
booting The procedure of starting a computer by
bitmap A string of n binary digits that can be
loading the kernel.
used to represent the status of n items. The avail-
bootstrap The set of steps taken at computer
ability of each item is indicated by the value of a
power-on to bring the system to full operation.
binary digit: 0 means that the resource is available,
while 1 indicates that it is unavailable (or vice- bootstrap loader The small program that loads
versa). the kernel as part of the bootstrap procedure.
BKL In Linux kernel version 2.2, the “big kernel bootstrap port In Mach message passing, a pre-
lock” spinlock, which protected all kernel data defi ned port that allows a task to register a port it
structures. has created.
blade server A computer with multiple processor bootstrap program The program that allows the
boards, I/O boards, and networking boards placed computer to start running by initializing hardware
in the same chassis. The difference between these and loading the kernel.
and traditional multiprocessor systems is that each bootstrap server In Mach message passing, a
blade-processor board boots independently and system-wide service for registering ports.
runs its own operating system.
Border Gateway Protocol A network protocol
block A self-contained unit of work. The small- for determining network routes so that packets can
est physical storage device storage unit, typically move from source to destination across a WAN.
512B or 4KB. In the Grand Central Dispatch Apple bottleneck A performance-limiting aspect of
OS scheduler, a language extension that allows computing (e.g., poorly written code or a hard-
designation of a section of code that can be submit- ware component that is not as fast as others in the
ted to dispatch queues. system).
block cipher A cipher that works on blocks of bounded buffer A buffer with a fi xed size.
data (rather than bits).
bounded waiting A practice that places limits on
block device An I/O device that is randomly the time a thread or process is forced to wait for
accessible, with block-size chunks being the small- something.
est I/O unit.
Bourne-Again shell A common shell, or com-
block-device interface The interface for I/O to mand interpreter.
block devices. BPF compiler collection (BCC) A rich toolkit for
blocking In interprocess communication, a mode tracing system activity on Linux for debugging
of communication in which the sending process is and performance-tuning purposes.Glossary G-5
bridging In networking, the connection of two Canonical A popular Linux distribution.
devices—e.g., a virtual-machine guest and the net- capability In protection, the representation of an
work to which the host computer is connected. object in a capability list.
broadcast In networking, the sending of one or capability list In protection, a list of objects
more packets to all devices on the local network. together with the operations allowed on those
browser A process that accepts input in the form objects.
of a URL (Uniform Resource Locator), or web capability-based protection A protection facil-
address, and displays its contents on a screen. ity in which the powers of root are divided into
buddies Pairs of equal size, used in the buddy specifi c abilities, each represented by a bit in a bit
method of memory allocation. mask that is used to allow or deny operations.
buddy heap In Linux, the use of a power-of-two cascading termination A technique in which,
allocator for the kernel heap. when a process is ended, all of its children are
buffer A memory area that stores data being ended as well.
transferred (e.g., between two devices or between Ceph A brand of object storage management
a device and a process). software.
buffer cache In fi le I/O, a cache of blocks used to certifi cate authority A trusted signer of digital
decrease device I/O. certifi cates.
bug An error in computer software or hardware. character device An I/O device that has a char-
bus A communication system; e.g., within a acter (byte) as its smallest I/O unit.
computer, a bus connects various components, character-stream interface The interface for I/O
such as the CPU and I/O devices, allowing them to character devices (like keyboards).
to transfer data and commands. checksum The general term for an error detec-
busy waiting A practice that allows a thread tion and correction code.
or process to use CPU time continuously while children In a tree data structure, nodes con-
waiting for something. An I/O loop in which an nected below another node.
I/O thread continuously reads status information
chip multithreading (CMT) A CPU with multi-
while waiting for I/O to complete.
ple cores, where each core supports multiple hard-
byte Eight bits. ware threads.
bytecode A computer object code resulting from chipset The CPU and support chips that create a
compiling a program in a language (such as Java) computer and defi ne its architecture.
that runs on a virtual machine.
circular buffer A buffer that uses a fi xed amount
C library (libc) The standard UNIX/Linux sys- of storage and wraps writes from the end of the
tem API for programs written in the C program- buffer to the beginning when the buffer fi lls (so
ming language. that the buffer acts as if it’s circular in shape).
cache A temporary copy of data stored in a Circular SCAN (CSCAN) scheduling An HDD
reserved memory area to improve performance. In I/O scheduling algorithm in which the disk head
the slab allocator, a cache consists of two or more moves from one end of the disk to the other
slabs. performing I/O as the head passes the desired
cache coherency The coordination of the con- cylinders; the head then reverses direction and
tents of caches such that an update to a value continues.
stored in one cache is immediately refl ected in all claim edge In the deadlock resource-allocation-
other caches that hold that value. graph algorithm, an edge indicating that a process
cache management The management of a cache’s might claim a resource in the future.
contents. class loader In Java, a helper component that
cache-consistency problem A challenge in cach- loads .class fi les for execution by the Java virtual
ing in which the cached copies of data must be machine.
kept consistent with the master copy of the data. class In Java, a program component that is a col-
caching The use of temporary data storage areas lection of data fi elds and functions (methods) that
to improve performance. operate on those fi elds.
cancellation point With deferred thread cancel- clean-up handler A function that allows any
lation, a point in the code at which it is safe to ter- resources a thread has acquired to be released
minate the thread. before the thread is terminated.G-6 Glossary
client A computer that uses services from other instance; more complex than a client-server DFS
computers (such as a web client). The source of a but less complex than a cluster-based DFS. GPFS
communication. and Lustre are examples.
client interface In distributed computing, a set clustered page table A page table similar to a
of services provided to a caller of services. hashed page table, but a table entry refers to sev-
eral (a cluster of) pages.
client system A computer that uses services from
other computers (such as a web client). clustered system A system that gathers together
multiple CPUs. Clustered systems differ from
client-server model A mode of computing in
multiprocessor systems in that they are composed
which a server provides services to one or more
of two or more individual systems—or nodes—
clients. In distributed computing, a model in which
joined together.
a computer acts as a resource server to other com-
puters that are clients of those resources. clustering In general, gathering N items
together. In virtual memory, paging in a group of
client-side caching (CSC) In Windows, a cach-
contiguous pages when a single page is requested
ing method used to allow remote users to work
via a page fault.
off-line and then consolidate their changes once
they are online. cluster In fi le system block allocation, several
contiguous blocks.
clock In the second-chance page-replacement
coalescing In general, combining. In the buddy
algorithm, a circular queue that contains possible
memory allocation algorithm, freed memory in
victim frames. A frame is replaced only if it has not
adjacent buddies can be coalesced into larger
been recently referenced.
segments.
clone In fi le systems, a snapshot that is read-
code integrity A Windows 7 module that checks
write and modifi able. In virtualization, a copy of a
the digital signatures of kernel modules to be sure
guest that enables another instance of the guest to
they have not been tampered with by attackers.
run in a separate virtual machine.
code review A software development method in
CLOOK scheduling An HDD I/O scheduling
which the developer submits code to other devel-
algorithm that modifi es CSCAN by stopping the
opers for review and approval.
head after the fi nal request is completed (rather
than at the innermost or outermost cylinder). code signing The use of a digital signature to
authenticate a program.
closed-source An operating system or other
program available only in compiled binary code code-injection attack An attack that modifi es
format. otherwise well-behaved executable code.
closure In functional programming languages, command interpreter The operating system
a construct to provide a simple syntax for parallel component that interprets user commands and
applications. causes actions based on them.
command-line interface (CLI) A method of giv-
cloud computing A computing environment in
ing commands to a computer based on a text input
which hardware, software, or other resources are
device (such as a keyboard).
made available to customers across a WAN, such
as the Internet, usually with APIs for management. Common Criteria The international 2005 succes-
A type of computing that delivers computing, stor- sor to the Orange Book standard developed by the
age, and even applications “as a service” across a U.S. Department of Defense.
network. common Internet fi le system (CIFS) The Win-
cloud storage Storage accessed from a computer dows network fi le system, now used on many
over a network to a distant, shared resource data systems.
center. communication port In Windows OS, a port
cluster In Windows storage, a power-of-2 num- used to send messages between two processes.
ber of disk sectors collected for I/O optimization. communications A category of system calls.
cluster-based model In distributed computing, a compaction The shuffl ing of storage to consoli-
model of resource sharing where all systems are date used space and leave one or more large holes
equal users and providers of resources. available for more effi cient allocation.
clustered fi le system (CFS) A fi le system that is compartmentalization The process of protecting
LAN-based and treats N systems storing data and each system component through the use of specifi c
Y clients accessing the data as a single client-server permissions and access restrictions.Glossary G-7
Completely Fair Queuing (CFQ) In Linux, the connection port In Windows OS, a communica-
default I/O scheduler in kernel 2.6 and later versions. tions port used to maintain connection between
Completely Fair Scheduler (CFS) In Linux, the two processes, published by a server process.
priority-based, preemptive scheduler included connectionless socket (UDP) In Java, a mode of
with the 2.6 kernel. communication.
component object model (COM) The Windows connection-oriented socket (TCP) In Java, a
mechanism for interprocess communication. mode of communication.
compression The use of algorithms to reduce the consistency checker A system program, such as
amount of data stored or sent. UNIX fsck, that reads fi le system metadata and
compression ratio In memory compression, a tries to correct any inconsistencies (such as a fi le’s
measurement of the effectiveness of the compres- length being incorrectly recorded).
sion (the ratio of the compressed space to the orig-
consolidation In virtualization, the practice of
inal amount of uncompressed space).
running multiple guests per host, reducing the
compression unit In NTFS, a unit of 16 contigu- number of physical servers needed for a given
ous clusters used in memory compression. workload.
computation migration The use of a network to constant angular velocity (CAV) A device-
allow a task to remotely request resources to speed recording method in which the medium spins at
a computation. a constant velocity and the bit density decreases
computation speedup An increase in the amount from inner to outer tracks.
of CPU compute power. constant linear velocity (CLV) A device-recording
computational kernel A Windows mechanism method that keeps a constant density of bits
for specifying tasks to run on GPUs. per track by varying the rotational speed of the
compute-server system A server that provides an medium.
interface to which a client can send a request for an consumer A process role in which the process
action (e.g., read data). In response, the server exe- consumes information produced by a producer
cutes the action and sends the results to the client. process.
Concurrency Runtime (ConcRT) A Microsoft container In application containment, a virtual
Windows concurrent programming framework for layer between the operating system and a process
C++ that is designed for task-based parallelism on in which the application runs, limiting its normal
multicore processors. access to system resources.
condition variable A component of a monitor container object In Windows 10, a category of
lock; a container of threads waiting for a condition objects that contain other objects (e.g., directories,
to be true to enter the critical section. which contain fi les).
conditional-wait A component of the monitor
containers In APFS, large free spaces in storage
construct that allows for waiting on a variable
from which fi le systems can draw allocations.
with a priority number to indicate which process
containment A method for preventing deadlocks
should get the lock next.
by creation and lock management of a higher-
confi nement problem The problem of guaran-
order resource that contains the locks of lower-
teeing that no information initially held in an object
order resources.
can migrate outside of its execution environment.
contended A term describing the condition of a
confl ict phase During scheduling, the time the
lock when a thread blocks while trying to acquire it.
dispatcher spends moving a thread off a CPU and
releasing resources held by lower-priority threads content addressable storage Another term for
that are needed by the higher-priority thread that object storage; so called because objects can be
is about to be put onto the CPU. retrieved based on their contents.
confl ict-resolution mechanism In Linux, the context When describing a process, the state of
kernel module facility that allows different device its execution, including the contents of registers, its
drivers to reserve hardware resources and to pro- program counter, and its memory context, includ-
tect those resources from accidental use by other ing its stack and heap.
drivers. context switch The switching of the CPU from
congestion control In networking, the attempt to one process or thread to another; requires perform-
approximate the state of networks between send- ing a state save of the current process or thread and
ers and receivers to avoid packet loss. a state restore of the other.G-8 Glossary
contiguous allocation A fi le-block allocation core frameworks In the layered macOS and iOS
method in which all blocks of the fi le are allocated operating system design, the layer that defi nes
as a contiguous chunk on secondary storage. frameworks that support graphics and media,
including QuickTime and OpenGL.
contiguous bit In ARM v8 CPUs, a TLB bit indi-
cating that the TLB holds a mapping to contiguous counting semaphore A semaphore that has a
blocks of memory. value between 0 and N, to control access to a resource
with N instances.
contiguous memory allocation A memory allo-
cation method in which each process is contained CPU burst Scheduling process state in which the
in a single section of memory that is contiguous to process executes on CPU.
the section containing the next process. CPU scheduler Kernel routine that selects a
control partition In type 0 virtualization, a vir- thread from the threads that are ready to execute
tual hardware partition that provides services to and allocates a core to that thread.
the other partitions (and has higher privileges). CPU scheduling The process by which the sys-
control program A program that manages the tem chooses which job will run next If several jobs
execution of user programs to prevent errors and are ready to run at the same time.
improper use of the computer. It is especially CPU-bound process A process that spends more
concerned with the operation and control of I/O time executing on CPU than it does performing
devices. I/O.
control register A device I/O register where crash Termination of execution due to a problem.
commands are placed by the computer. A failure in the kernel results in a system crash and
control-fl ow guard (CFG) A Windows 7 exploit- reboot, while a process failure results in a process
mitigation feature. crash.
controller A special processor that manages I/O crash dump A copy of the state of the kernel
devices. written to disk during a crash; used for debugging.
convoy effect A scheduling phenomenon in critical section A section of code responsible for
which a number of threads wait for one thread to changing data that must only be executed by one
get off a core, causing overall device and CPU uti- thread or process at a time to avoid a race condition.
lization to be suboptimal. critical-section object A user-mode mutex object
cooperating process A process that can affect or be that can often be acquired and released without
affected by other processes executing in the system. kernel intervention; a Windows OS scheduling
feature.
cooperative A form of scheduling in which
threads voluntarily move from the running state. cryptography A tool used to constrain the poten-
tial senders and/or receivers of a message (or
coordination Ordering of the access to data by
stored data).
multiple threads or processes.
current-fi le-position pointer A per-process
copy protection The implementation of a mech-
pointer to the location in a fi le to which the next
anism to prevent the unauthorized copying of a
read or from which the next write will occur.
licensed work (e.g., media, programs, operating
systems). cycle A repeating loop.
copy semantics The meaning assigned to data cycle stealing The act of a device, such as a DMA
copying—e.g., whether a block write from a pro- controller, using the bus and preventing the CPU
cess allows the data to be modifi ed after the write from using it temporarily.
has been requested. cylinder On an HDD, the set of tracks under the
copy-on-write Generally, the practice by which read-write heads on all platters in the device.
any write causes the data to fi rst be copied and then cylinder groups A sequential collection of storage
modifi ed, rather than overwritten. In virtual mem- media (typically a group of cylinders) that are man-
ory, on a write attempt to a shared page, the page aged as a single unit and subdivided into blocks.
is fi rst copied, and the write is made to that copy. daemon A service that is provided outside of the
core Within a CPU, the component that executes kernel by system programs that are loaded into
instructions. memory at boot time and run continuously.
core dump A copy of the state of a process daisy chain In computer I/O, a connection
written to disk when a process crashes; used for method involving connecting devices to each other
debugging. in a string (device A to B, B to C, C to D, etc.).Glossary G-9
dark web The part of the World Wide Web that is default heap The heap data structure created
not easy to reach (say, by search engines) and that when a Win32 process is initialized.
is sometimes used for bad behavior (such as sell- default signal handler The signal handler that
ing information stolen in successful attacks).
receives signals unless a user-defi ned signal han-
Darwin The Apple code name for its open- dler is provided by a process.
source kernel. defense in depth The theory that more layers of
data execution prevention (DEP) A Windows 7 defense provide stronger defense than fewer layers.
exploit-mitigation feature. deferred procedure call (DPC) In Windows
data migration The entire transfer of one or more scheduling, a call initiated by the interrupt that
fi les from one site to another. occurs when a time quantum expires, eventually
causing the expired thread to be moved off a core
data parallelism A computing method that dis-
and replaced with the next thread in the ready
tributes subsets of the same data across multiple
queue.
cores and performs the same operation on each core.
degree of multiprogramming The number of
data section The data part of a program or pro-
processes in memory.
cess; it contains global variables.
delayed-write policy In caching, a policy
data striping The splitting of data across multi-
whereby data are fi rst written to a cache; later, the
ple devices.
cache writes the change to the master copy of the
data-encryption standard (DES) A cipher (algo-
data.
rithm for doing encryption and decryption) pro-
demand paging In memory management, bring-
vided by the U.S. National Institute of Standards
ing in pages from storage as needed rather than,
and Technology (NIST).
e.g., in their entirety at process load time.
datagram A basic transfer unit on a packet-
demand-zero memory In Linux, a virtual mem-
switched network like the Internet protocol (i.e., a
ory region backed by nothing; when a process tries
network packet).
to read a page in such a region, it is given a page of
data-in register A device I/O register where data
memory fi lled with zeros.
is placed to be sent to the device.
demilitarized zone In fi rewalling, a security
data-out register A device I/O register where data
domain less trusted than some other security
is placed by the device to be read by the computer.
domain (e.g., the domain containing a web server
DCOM The distributed computing extension to compared to the domain containing the crucial
object linking and embedding (OLE). company database).
deadlock The state in which two processes or denial-of-service Preventing legitimate use of a
threads are stuck waiting for an event that can only system.
be caused by one of the processes or threads.
dentry object The VFS representation of a directory.
deadlock avoidance An operating system method
desktop In a GUI, the standard workspace rep-
in which processes inform the operating system
resented by the GUI on the screen, in which a user
of which resources they will use during their life-
executes tasks.
times so the system can approve or deny requests
desktop activity moderator (DAM) A Windows 8
to avoid deadlock.
component that supports the system state “con-
deadlock prevention A set of methods intended
nected standby” on mobile devices, freezing com-
to ensure that at least one of the necessary condi-
puter activity but allowing rapid return to full
tions for deadlock cannot hold.
functionality.
deadlocked The state in which two processes or
desktop window manager A Windows Vista
threads are stuck waiting for an event that can only
user-mode component to manage GUI windows.
be caused by one of the processes or threads.
deterministic modeling A type of analytic eval-
Debian A popular Linux distribution.
uation that takes a particular predetermined work-
debugger A system program designed to aid load and defi nes the performance of each algo-
programmers in fi nding and correcting errors. rithm for that workload.
debugging The activity of fi nding and removing development kernel A kernel released for devel-
errors. opers to use, rather than for production use.
deduplication The removal of duplicate infor- device controller The I/O managing processor
mation (bits, blocks, or fi les). within a device.G-10 Glossary
device driver An operating system component disk arm An HDD component that holds the read-
that provides uniform access to various devices write head and moves over cylinders of platters.
and manages I/O to those devices.
disk image Generally, the contents of a disk
device manipulation A category of system calls. encapsulated in a fi le. In virtualization, a guest vir-
device object In Windows, the object represent- tual machine’s boot fi le system contents contained
ing a device. in a disk image.
device queue The list of processes waiting for a diskless A term describing systems that have no
particular I/O device. local storage.
device-status table A kernel data structure for dispatch latency The amount of time the dis-
tracking the status and queues of operations for patcher takes to stop one thread and put another
devices. thread onto the CPU.
digital certifi cate A public key digitally signed dispatch queue An Apple OS feature for paral-
by a trusted party. lelizing code; blocks are placed in the queue by
digital rights management The implementa- Grand Central Dispatcher (GCD) and removed to
tion of a mechanism to prevent the unauthorized be run by an available thread.
copying of a licensed work (e.g., media, programs, dispatched Selected by the process scheduler to
operating systems). be executed next.
digital signature The authenticator produced by dispatcher The kernel routine that gives control
a digital-signature algorithm. of a core to the thread selected by the scheduler.
digital-signature algorithm A cryptographic dispatcher objects A Windows scheduler feature
checksum calculated in asymmetric encryption; that controls dispatching and synchronization.
used to authenticate a message. Threads synchronize according to several different
dining-philosophers problem A classic syn- mechanisms, including mutex locks, semaphores,
chronization problem in which multiple operators events, and timers.
(philosophers) try to access multiple items (chop-
distributed denial-of-service attack (DDoS) An
sticks) simultaneously.
attack from multiple sources (frequently a botnet
direct access A fi le-access method in which of zombies) with the purpose of denying legiti-
contents are read in random order, or at least not mate use of the attacked resource.
sequentially.
distributed fi le system (DFS) A fi le system that
direct blocks In UFS, blocks containing pointers works across a network in which remote directo-
to data blocks. ries are visible from a local machine.
direct communication In interprocess commu- distributed information system A set of pro-
nication, a communication mode in which each tocols providing unifi ed information needed for
process that wants to communicate must explicitly remote computing.
name the recipient or sender of the communication.
distributed lock manager (DLM) A function
direct I/O Block I/O that bypasses operating- used by a clustered system to supply access con-
system block features such as buffering and locking. trol and locking to ensure that no confl icting oper-
direct memory access (DMA) A resource- ations occur.
conserving and performance-improving operation
distributed naming service A set of protocols
for device controllers allowing devices to transfer
providing unifi ed information needed for remote
large amounts of data directly to and from main
computing.
memory.
distributed system A collection of loosely cou-
direct virtual memory access (DVMA) DMA that
pled nodes interconnected by a communication
uses virtual addresses rather than physical mem-
network.
ory addresses as transfer sources and destinations.
distribution A release of a version of an operat-
dirty bit An MMU bit used to indicate that a
ing system.
frame has been modifi ed (and therefore must have
its contents saved before page replacement). docker An orchestration tool for containers.
discretionary access control (DAC) Optional, as domain switching The mechanism for switching
opposed to mandatory, access control. dynamic domains.
disinfecting In the context of computer viruses, domain-name system (DNS) The Internet sys-
removing the components of a virus. tem for resolving host names to host-ids, in whichGlossary G-11
a distributed information system provides host- ease of use The amount of diffi culty and complex-
name-to-network-address translations for the ity involved in using some aspect of computing.
Internet. EEPROM Electrically erasable programmable
double buffering The copying of data twice read-only memory; a type of fi rmware.
(e.g., from a device to the kernel and then from effective access time The measured or statisti-
the kernel to a process’s address space), or the cally calculated time it takes to access something;
use of two buffers to decouple producers and e.g., see effective memory-access time.
consumers.
effective memory-access time The statistical or
double caching The problem in which the same real measure of how long it takes the CPU to read
data might be in two different caches; solved by a or write to memory.
unifi ed buffer cache.
effective transfer rate The actual, measured
double indirect block In UFS, a block containing transfer rate of data between two devices (such as
pointers to a single indirect block, which points to a computer and a disk drive).
data blocks.
effective UID The UID the process is currently
down time Generally, time during which a facil- using, which can be different from the login UID
ity, system, or computing component are off-line due to, e.g., escalating privileges.
and unavailable.
electrical storage Storage devices made from
driver end The interface between STREAMS and electrical components, such as fl ash memory; one
the device being controlled. form of nonvolatile storage.
driver object In Windows, the object represent- ELF The UNIX standard format for relocatable
ing a device driver. and executable fi les.
driver-registration system In Linux, the kernel embedded computer A computer system within
module facility that tells the rest of the kernel that some other, larger system (such as a car) that per-
a new driver is available. forms specifi c, limited functions and has little or
DTrace A facility originally developed at Sun no user interface.
Microsystems that dynamically adds probes to a emulation A methodology used to enable a pro-
running system, both in user processes and in the cess to run when the compiled program’s original
kernel, for state analysis, performance tuning, and (source) CPU type is different from the target CPU
debugging. type on which the program is to run.
dual-booted A term describing a computer that emulator A program that allows applications
can boot one of two or more installed operating written for one hardware environment to run in a
systems. different hardware environment, such as a differ-
dynamic loading The loading of a process rou- ent type of CPU.
tine when it is called rather than when the process encapsulate In general, to enclose. In Java,
is started. encapsulation gives a class the ability to protect its
dynamic random-access memory (DRAM) The data and methods from other classes loaded in the
common version of RAM, which features high same JVM.
read and write speeds. encryption The use of cryptography to limit the
dynamic storage-allocation The class of fi le- receivers of a message or access to data.
block allocation methods that satisfy a request for entry section The section of code within a pro-
n blocks from a list of free holes available. cess that requests permission to enter its critical
dynamic storage-allocation problem The prob- section.
lem of how to satisfy a request for size n of mem- entry set In Java, the set of threads waiting to
ory from a list of free holes. enter a monitor.
dynamically linked libraries (DLLs) System environment vector In Linux and UNIX, a list
libraries that are linked to user programs when the containing all of the environment variables of the
processes are run, with linking postponed until shell that invoked a process (and are available to
execution time. the process).
earliest-deadline-fi rst (EDF) A real-time sched- environmental subsystem In Windows, an oper-
uling algorithm in which the scheduler dynam- ating environment that emulates a specifi c operat-
ically assigns priorities according to completion ing system by translating process API calls from
deadlines. that operating system to Windows calls.G-12 Glossary
equal allocation An allocation algorithm that extended fi le system The most common class of
assigns equal amounts of a resource to all requestors. Linux fi le systems, with ext3 and ext4 being the
In virtual memory, assigning an equal number of most commonly used fi le system types.
frames to each process. extended fi le system (extfs) The most common
error-correcting code (ECC) A value calculated class of Linux fi le systems, with ext3 and ext4
from bytes of data and recalculated later to check being the most commonly used fi le system types.
for changes in the data.
extensibility The ability of an operating system
eSATA A type of I/O bus. to accommodate advances in computing technol-
escalate privileges To gain extra permissions for ogy via extensions (such as new kernel modules
an activity, as when a user needs access to a device and new device drivers).
that is restricted. extent A chunk of contiguous storage space
escape Generally, a method of passing arbitrary added to previously allocated space; a pointer is
commands or information when an interface does used to link the spaces.
not provide a standard method. external data representation A system used
event latency The amount of time between when to resolve differences when data are exchanged
an event occurs and when it is serviced. between big- and little-endian systems.
event A Windows OS scheduling feature that is external fragmentation Fragmentation in which
similar to a condition variable. available memory contains holes that together
eVM An example of a partitioning hypervisor. have enough free space to satisfy a request but no
single hole is large enough to satisfy the request.
exception A software-generated interrupt
More generally, the fragmentation of an address
caused either by an error (such as division by zero
space into small, less usable chunks.
or invalid memory access) or by a specifi c request
from a user program than an operating-system ser- fair scheduling In the Completely Fair Sched-
vice be performed. uler, the scheduler algorithm that allots a pro-
portion of the processor’s time rather than time
exception dispatcher The Windows component
slices.
that processes exceptions.
false negatives Results indicating that some-
exclusive lock A fi le lock similar to a writer lock
thing is not a match to what is being detected, even
in that only one process at a time can obtain the
though it is.
lock.
false positives Results indicating that something
executable and linkable format (ELF) The UNIX
is a match to what is being detected, even though
standard format for relocatable and executable
it isn’t.
fi les.
fast directory sizing In APFS, a feature that
executable fi le A fi le containing a program that
tracks and rapidly reports on directory sizes.
is ready to be loaded into memory and executed.
fast I/O mechanism In Windows, a high-speed
execution tracing A Windows method of moni-
bypass of the standard I/O handling mechanism
toring process execution and recording details for
in which the driver stack is called directly rather
analysis and debugging.
than having an IRP sent and processed.
exit section The section of code within a process
that cleanly exits the critical section. fault-tolerant system A system that can suffer a
failure of any single component and still continue
expansion bus A computer bus for connecting
operation.
slow devices like keyboards.
fi ber User-mode code that can be scheduled
exponential average A calculation used in sched-
according to a user-defi ned scheduling algorithm.
uling to estimate the next CPU burst time based on
the previous burst times (with exponential decay fi bre channel (FC) A type of storage I/O bus
on older values). used in data centers to connect computers to stor-
age arrays. A storage-attachment network.
export list The list of fi le systems available for
remote mounting from a server. fi le The smallest logical storage unit; a collection
of related information defi ned by its creator.
ext3 One of the most common types of Linux fi le
systems. fi le attributes Metadata about a fi le, such as who
created it and when, fi le size, etc.
extended fi le attributes Extended metadata
about a fi le, including items such as character fi le descriptor (fd) UNIX open-fi le pointer, cre-
encoding details, fi le checksums, etc. ated and returned to a process when it opens a fi le.Glossary G-13
fi le handle Windows name for the open-fi le fi le fi rst-come fi rst-served (FCFS) The simplest
descriptor. scheduling algorithm. The thread that requests a
fi le info window A GUI view of the fi le metadata. core fi rst is allocated the core fi rst.
fi le manipulation A category of system calls. fi rst-fi t In memory allocation, selecting the fi rst
hole large enough to satisfy a memory request.
fi le mapping In Windows, the fi rst step in
memory-mapping a fi le. fi rst-level interrupt handler In some operat-
ing systems, an interrupt handler responsible for
fi le migration A fi le system feature in which a fi le’s
reception and queuing of interrupts; the inter-
location is changed automatically by the system.
rupts are actually handled at another level (by the
fi le object The VFS representation of an open fi le.
second-level handler).
fi le reference In Windows NTFS, a unique fi le ID
fl ash translation layer (FTL) For nonvolatile
that is the index of the fi le in the master fi le table
memory, a table that tracks currently valid blocks.
(much like a UNIX inode number).
fl ow control Generally, a method to pause a
fi le session The series of accesses between open()
sender of I/O. In networking, a technique to limit
and close() system calls that make up all the oper-
the rate of data fl ow (e.g., to avoid buffer overfl ow
ations on a fi le by a process.
and packet loss on a router).
fi le system The system used to control data stor-
fl ush Erasure of entries in, e.g., a TLB or other
age and retrieval; provides effi cient and conve-
cache to remove invalid data.
nient access to storage devices by allowing data to
be stored, located, and retrieved easily. folder A fi le system component that allows users
to group fi les together.
File System Hierarchy Standard A standard
document specifying the overall layout of the stan- folder redirection In Windows, for roaming
dard Linux fi le systems. users, a method for automatically storing a user’s
documents and other fi les on a remote server.
fi le-allocation table (FAT) A simple but effective
method of disk-space allocation used by MS-DOS. foreground Describes a process or thread that
A section of storage at the beginning of each vol- is interactive (has input directed to it), such as a
ume is set aside to contain the table, which has one window currently selected as active or a terminal
entry per block, is indexed by block number, and window currently selected to receive input.
contains the number of the next block in the fi le.
foreground process A process currently open
fi le-control block (FCB) A per-fi le block that con- and appearing on the display, with keyboard or
tains all the metadata about a fi le, such as its access other I/O device input directed to it.
permissions, access dates, and block locations.
fork-join A strategy for thread creation in which
fi le-organization module A logical layer of the the main parent thread creates (forks) one or more
operating system responsible for fi les and for child threads and then waits for the children to ter-
translation of logical blocks to physical blocks. minate and join with it.
fi le-server system A server that provides a forward-mapped Describes a scheme for hier-
fi le-system interface where clients can create, archical page tables in which address translation
update, read, and delete fi les (e.g., a web server starts at the outer page table and moves inward.
that delivers fi les to clients running web browsers).
fourth extended fi le system (ext4) In Linux, a
fi lter drivers In Windows, drivers allowed to
current version of the extended fi le system, the
insert themselves into the I/O processing chain.
successor to ext3.
fi rewall A computer, appliance, process, or
fragments In networking, parts of messages. A
network router that sits between trusted and
message is split into fragments if it is too large to
untrusted systems or devices. It protects a network
fi t in one packet.
from security breaches by managing and blocking
certain types of communications. frame table In paged memory, the table con-
taining frame details, including which frames
fi rewall chains In Linux, an ordered list of
are allocated, which are free, total frames in the
rules that specifi es one of a number of possible
system, etc.
fi rewall-decision functions plus matching compo-
nents. A confi guration of the fi rewall rules. frame-allocation algorithm The operating-
system algorithm for allocating frames among all
fi rmware Software stored in ROM or EEPROM
demands for frames.
for booting the system and managing low level
hardware. frames Fixed-sized blocks of physical memory.G-14 Glossary
free operating system An operating system GNU General Public License (GPL) A license
released under a license that makes its source code agreement that codifi es copylefting (allowing and
available and allows no-cost use, redistribution, requiring open sourcing of the associated pro-
and modifi cation. grams); a common license under which free soft-
ware is released.
free-behind Sequential I/O performance opti-
mization that removes a page or block from a buf- GNU/Linux (aka Linux) An open-source operat-
fer as soon as I/O to the next page is requested. ing system composed of components contributed
by the GNU foundation and Linus Torvalds, as
free-frame list A kernel-maintained data struc-
well as many others.
ture containing the list of currently available free
frames of physical memory. Google Android The mobile operating system
created by Google Inc.
free-space list In fi le-system block allocation, the
data structure tracking all free blocks in the fi le Google fi le system (GFS) A cluster-based dis-
system. tributed fi le system designed and used by Google.
front-end processors Small computers that per- GPFS A common commercial clustered fi le sys-
form certain tasks in an overall system; used by tem by IBM.
some systems to manage I/O and offl oad the graceful degradation The ability of a system to
general-purpose CPU. continue providing service proportional to the
fsgid In Linux, an added process property that level of surviving hardware.
allows fi le system access on behalf of another graphical user interface (GUI) A computer
group. interface comprising a window system with a
fsuid In Linux, an added process property that pointing device to direct I/O, choose from menus,
allows fi le system access on behalf of another user. and make selections and, usually, a keyboard to
enter text.
full backup In fi le systems, a backup that
includes all of the contents of a fi le system. graphics processing unit (GPU) A hardware
component, sometimes part of the CPU and some-
functional language A programming language
times a separate device, that provides graphics
that does not require states to be managed by pro-
computation and sometimes graphics output to a
grams written in that language (e.g., Erlang and
display.
Scala).
graphics shaders Processes that provide the
fuzzing A technique that tests for proper input val-
shading within graphics images.
idation (e.g., to avoid undetected buffer overruns).
group In fi le permissions, a collection of users
Galois fi eld math An advanced error-correcting
that have access to a fi le based on assigned access
calculation done in some forms of RAID.
rights.
Gantt chart A bar chart that can be used to illus-
group identifi er Similar to a user identifi er, but
trate a schedule.
used to identify a group of users to determine
garbage collection In general, recovery of space access rights.
containing no-longer-valid data.
group rights In fi le permissions, the access rights
general tree A tree data structure in which a par- belonging to a user group.
ent may have unlimited children.
GRUB A common open-source bootstrap loader
gestures A user interface component in which that allows selection of boot partitions and options
motions cause computer actions (e.g., “pinching” to be passed to the selected kernel.
the screen).
guard pages In Windows, no-access-allowed
gigabyte (GB) 1,024^3 bytes. pages at the tops of the kernel-mode and user-
git A version control system used for GNU/ mode stacks that detect stack overfl ows.
Linux and other programs. guest In virtualization, an operating system run-
global replacement In virtual memory frame ning in a virtual environment (rather than natively
allocation, allowing a process to select a replace- on the computer hardware).
ment frame from the set of all frames in the system, hacker Someone attempting to breach computer
not just those allocated to the process. security.
GNU C compiler (gcc) The standard C compiler Hadoop distributed fi le system (HDFS) A cluster-
of the GNU project, used throughout the industry based distributed fi le system used for big-data
on Linux and many other system. projects.Glossary G-15
Hadoop fi le system An example of object stor- and returns a numeric value. Also, an algorithm
age management software. for creating a hash (a small, fi xed-size block of data
haiku A three-line poem in which the fi rst line calculated from a larger data set, used to determine
contains fi ve syllables, the second line contains if a message has been changed).
seven syllables, and the third line contains fi ve hash map A data structure that maps [key:value]
syllables. pairs using a hash function; a hash function can then
handle Generally, an opaque value that provides be applied to a key to obtain its matching value.
access to an object or data structure; e.g., a fi le hash value The calculation resulting from a hash
handle is returned when a fi le is opened and is a function.
pointer to an entry in an open-fi le table.
hashed page table A page table that is hashed
handle table In Windows, a per-process handle for faster access; the hash value is the virtual page
table containing entries that track (by their han- number.
dles) the objects used by the process.
head crash On an HDD, a mechanical problem
hard affi nity The situation in which an operat- involving the read-write head touching a platter.
ing system allows a process’s threads to run on the
heap section The section of process memory that
same processor at all times (as opposed to being
is dynamically allocated during process run time;
moved to various processors).
it stores temporary variables.
hard disk drive (HDD) A secondary storage
heartbeat In computer clustering, a repeating
device based on mechanical components, includ-
signal to determine the state of the members of the
ing spinning magnetic media platters and moving
cluster (e.g., to determine if a system is down).
read-write heads.
heterogeneous multiprocessing (HMP) A fea-
hard error An unrecoverable error (possibly
ture of some mobile computing CPUs in which
resulting in data loss).
cores vary in their clock speeds and power
hard links File-system links in which a fi le has management.
two or more names pointing to the same inode.
high-availability Describes a service that will
hard real-time systems Systems in which a continue even if one or more systems in the cluster
thread must be serviced by its deadline; service fail.
after the deadline has expired is the same as no
high-performance computing A computing
service at all.
facility designed for use with a large number of
hard working-set limit In Windows memory resources to be used by software designed for par-
management, the maximum amount of physical allel operation.
memory that a process is allowed to use.
high-performance event timer A hardware
hardware The CPU, memory devices, input/ timer provided by some CPUs.
output (I/O) devices, and any other physical com-
hit ratio The percentage of times a cache pro-
ponents that are part of a computer.
vides a valid lookup (used, e.g., as a measure of a
hardware objects The CPU, memory devices,
TLB’s effectiveness).
input/output (I/O) devices, and any other phys-
hives In Windows, an internal repository of data.
ical components that are part of a computer
hole In variable partition memory allocation,
hardware threads Threads associated with the
a contiguous section of unused memory. Also an
processing core. A given CPU core may run mul-
alternative rock band formed by Courtney Love.
tiple hardware threads to optimize core use—e.g.,
to avoid memory stalls by switching hardware honeypot A false resource exposed to attackers;
threads if the current thread causes a stall. the resource appears real and enables the system
to monitor and gain information about the attack.
hardware transactional memory (HTM) A trans-
actional memory implementation using hardware horizontal scalability The ability to scale capac-
cache hierarchies and cache coherency protocols ity not by expanding one item but by adding more
to manage and resolve confl icts involving shared items.
data residing in separate processors’ caches. host In virtualization, the location of the virtual
hardware-abstraction layer (HAL) A kernel layer machine manager, which runs guest operating sys-
that isolates chipset-specifi c hardware aspects from tems; generally, a computer.
general-purpose code. host bus adapter (HBA) A device controller
hash function A function that takes data as its installed in a host bus port to allow connection of
input, performs a numeric operation on the data, one or more devices to the host.G-16 Glossary
host controller The I/O-managing processors I/O-bound process A process that spends more
within a computer (e.g., inside a host bus adapter). of its time doing I/O than doing computations
host name A human-readable name for a icons Images representing objects (such as fi les
computer. or applications) that users can chose via the GUI.
host-attached storage Storage accessed through idempotent Describes a function that, when
local I/O ports (directly attached to a computer, applied more than once, has the same result every
rather than across a network or SAN). time.
host-id In networking, the unique number iden- identifi er Generally, a numeric tag for a device
tifying a system on a network. or object. In networking, the unique host-id num-
ber identifying a system on a network.
hostname The alphanumeric name for a system
(such as becca.colby.edu). idle process In Windows, a process that serves as
the container of all idle threads.
hot spare An unused storage device ready to be
used to recover data (e.g., in a RAID set). idle thread In some operating systems, a special
thread that runs on the CPU when no other thread
hot-standby mode A condition in which a com-
is ready to run.
puter in a cluster does nothing but monitor the
active server. If that server fails, the hot-standby immutable shared fi le In a remote fi le system,
host becomes the active server. a fi le that, once shared by its creator, cannot be
modifi ed.
huge pages A feature that designates a region of
physical memory where especially large pages can imperative language Language for implement-
be used. ing algorithms that are state-based (e.g., C, C++,
Java, and C#).
hybrid cloud A type of cloud computing that
includes both public and private cloud components. impersonation In Windows, the representation
of a thread by a token for security purposes.
hypercall In paravirtualization, a call from a
implicit threading A programming model that
guest to the hypervisor to request a virtualization
transfers the creation and management of thread-
service, such as a page table change.
ing from application developers to compilers and
hyper-threading Intel’s technology for assigning
run-time libraries.
multiple hardware threads to a single processing
incremental backup In fi le systems, a backup
core.
that contains only some parts of a fi le system (the
hypervisor The computer function that manages
parts that have changed since the last full and
the virtual machine; also called a virtual machine
incremental backups).
manager (VMM).
indefi nite blocking A situation in which one
I/O burst Scheduling process state in which the
or more processes or threads waits indefi nitely
CPU performs I/O.
within a semaphore.
I/O bus A physical connection of an I/O device index In fi le systems, an access method built
to a computer system. on top of direct access in which a fi le contains an
I/O channel A dedicated, special-purpose CPU index with pointers to the contents of the fi le.
found in large systems like mainframes for per- index block In indexed allocation, a block that
forming I/O or offl oading the general-purpose contains pointers to the blocks containing the fi le’s
CPU. data.
I/O control A logical layer of the operating sys- index root In NTFS, the part of the directory con-
tem responsible for controlling I/O, consisting of taining the top level of the B+ tree.
device drivers and interrupt handlers.
indexed allocation In fi le-system block alloca-
I/O manager In Windows, the system compo- tion, combining all block pointers in one or more
nent responsible for I/O. index blocks to address limits in linked allocation
I/O port A hardware connector allowing connec- and allow direct access to each block.
tion of an I/O device. indirect block In UFS, a block containing point-
I/O request packet (IRP) In Windows, a data ers to direct blocks, which point to data blocks.
structure to request fi le I/O that is sent from the Infi niBand (IB) A high-speed network commu-
I/O manager to the appropriate device driver. nications link.
I/O subsystem The I/O devices and the part of infi nite blocking A scheduling risk in which a
the kernel that manages I/O. thread that is ready to run is never put onto theGlossary G-17
CPU due to the scheduling algorithm; it is starved interprocess communication (IPC) Communica-
for CPU time. tion between processes.
information maintenance A category of system interrupt A hardware mechanism that enables
calls. a device to notify the CPU that it needs attention.
infrastructure as a service (IaaS) A type of com- interrupt address A variable provided along
puting in which servers or storage are available with an interrupt signal to indicate the source of
over the Internet (e.g, storage available for making the interrupt.
backup copies of production data). interrupt chaining A mechanism by which each
inode In many fi le systems, a per-fi le data struc- element in an interrupt vector points to the head of
ture holding most of the metadata of the fi le. The a list of interrupt handlers, which are called indi-
FCB in most UNIX fi le systems. vidually until one is found to service the interrupt
request.
inode object The VFS representation of an indi-
Interrupt latency The period of time from the
vidual fi le.
arrival of an interrupt at the CPU to the start of the
input/output operations per second A measure
routine that services the interrupt.
of random access I/O performance; the number of
inputs + outputs per second. interrupt object The Windows representation of
an interrupt.
integrity label In Windows Vista and later ver-
interrupt priority level Prioritization of inter-
sions, a mandatory access control component
rupts to indicate handling order.
assigned to each securable object and subject.
interrupt request level (IRQL) A prioritization
integrity levels A mechanism, introduced in
method used in interrupt management.
Windows Vista, that acts as a rudimentary capabil-
ity system for controlling access. interrupt service routine (ISR) An operating
system routine that is called when an interrupt sig-
Intel 64 Intel 64 bit CPUs, part of a class of CPUs
nal is received.
collectively known as x86-64
interrupt vector An operating-system data struc-
interactive Describes a type of computing that
ture indexed by interrupt address and pointing
provides direct communication between the user
to the interrupt handlers. A kernel memory data
and the system.
structure that holds the addresses of the interrupt
intermachine interface In distributed comput- service routines for the various devices.
ing, a set of low-level functions for cross-machine interrupt-controller hardware Computer hard-
interaction. ware components for interrupt management.
internal fragmentation Fragmentation that is interrupt-dispatch table The Windows term for
internal to a partition. its interrupt vector.
Internet A worldwide system of interconnected interrupt-handler routine An operating system
computer networks. routine that is called when an interrupt signal is
Internet key exchange (IKE) A protocol that received.
uses public key encryption to allow secure sym- interrupt-request line The hardware connection
metric key exchange for IPSec. to the CPU on which interrupts are signaled.
Internet protocol (IP) The low-level network- intruder Someone attempting to breach security.
ing protocol on which TCP and UDP are layered; intrusion prevention The attempt to detect
responsible for routing IP datagrams through net- attempted and successful intrusions and properly
works such as the Internet. respond to them.
Internet protocol security (IPSec) A network pro- intrusion-prevention systems (IPS) Systems to
tocol suite providing authentication and symmetric- detect and prevent intrusions, usually in the form
key encryption of packets of network data. of self-modifying fi rewalls.
Internet Service Providers (ISPs) Companies inverted page table A page-table scheme that
that provide Internet access. has one entry for each real physical page frame in
memory; the entry maps to a logical page (virtual
interpretation A methodology that allows a pro-
address) value.
gram in computer language to be either executed
in its high-level form or translated to an interme- iSCSI The protocol used to communicate with
diate form rather than being compiled to native SCSI devices; used across a network for more dis-
code. tant access.G-18 Glossary
Itanium Intel IA-64 CPU. kernel-mode thread (KT) In Windows, the name
iteration space In Intel threading building for the state of a thread when it is running in kernel
mode.
blocks, the range of elements that will be iterated.
Java virtual machine In programming- Kernighan’s Law “Debugging is twice as hard as
environment virtualization, the process that writing the code in the fi rst place. Therefore, if you
implements the Java language and allows execu- write the code as cleverly as possible, you are, by
tion of Java code. defi nition, not smart enough to debug it.”
job objects In Windows, data structures for keys In the context of protection, unique bit pat-
tracking collections of processes (e.g., to set CPU terns held by domains corresponding with unique
usage limits). bit patterns (locks) held by objects. Generally,
secrets used in cryptography.
job pool The location where jobs are kept on disk
while waiting for main memory to become available. keystream An infi nite set of bits used to encrypt
a plain-text stream through an XOR operation in a
job scheduling The task of choosing which jobs
stream cipher.
to load into memory and execute.
keystroke logger A program that captures key-
job A set of commands or processes executed by
strokes entered by users.
a batch system.
journaling In a fi le system that features a write kilobyte (KB) 1,024 bytes.
transaction log, logging of write activities for Kubernetes An orchestration tool for containers.
replay across actual fi le-system structures and con-
labels In mandatory access control, identifi ers
sistency protection.
assigned to objects and/or subjects. The label is
journaling fi le system A fi le system that features checked by the operating system when an opera-
a write transaction log where all write activities are tion is requested to determine if it is allowed.
logged for replay across actual fi le-system struc-
layered approach A kernel architecture in which
tures and consistency protection.
the operating system is separated into a number of
just-in-time (JIT) In Java virtual machine layers (levels); typically, the bottom layer (layer 0)
implementations, describes a compiler that con- is the hardware, and the highest (layer N) is the
verts bytecode to native CPU instructions the fi rst user interface.
time the bytecode is interpreted to speed later
lazy swapper A swapping method in which only
execution.
pages that are requested are brought from second-
Kerberos A network authentication protocol ary storage into main memory.
invented at M.I.T. that forms the basis for the Mic-
least frequently used (LFU) In general, an algo-
rosoft network authentication protocol.
rithm that selects the item that has been used least
kernel The operating system component run- frequently. In virtual memory, when access counts
ning on the computer at all times after system boot. are available, selecting the page with the lowest
kernel abstractions Components provided with count.
the Mach microkernel to add functionality beyond
least privilege Design principle stating that
the microkernel, such as tasks, threads, memory
every program and every privileged user of the
objects, and ports.
system should operate using the least amount of
kernel environment In the layered macOS and privilege necessary to complete the job.
iOS operating system design, the Darwin layer
least recently used (LRU) In general, an algo-
that includes the Mach microkernel and the BSD
rithm that selects the item that has been used
UNIX kernel.
least recently. In memory management, selecting
kernel extensions (kexts) Third-party com- the page that has not been accessed in the longest
ponents added to the kernel (usually to support time.
third-party devices or services).
lgroups In Solaris, locality groups located in the
kernel mode A CPU mode in which all instruc- kernel; each lgroup gathers together CPUs and
tions are enabled. The kernel runs in this mode. memory, and each CPU in that group can access
See also user mode. any memory in the group within a defi ned latency
kernel threads Threads running in kernel mode. interval. A method for dealing with NUMA.
kernel-mode driver framework (KMDF) A library operating systems The applications that
framework in Windows to facilitate the writing of run on unikernels, containing both the kernel and
kernel-mode device drivers. the application code.Glossary G-19
lightweight directory-access protocol (LDAP) A liveness A set of properties that a system must
secure distributed naming service used through- satisfy to ensure that processes make progress
out the computer industry. during their execution life cycle.
lightweight process (LWP) A virtual processor- living document A document that is modifi ed
like data structure allowing a user thread to map over time to keep it up to date.
to a kernel thread.
load balancing The movement of jobs or net-
limit register A CPU register that defi nes the work packets between various components (say,
size of the range. Together with the base register, it computers in a network) to distribute the load or
defi nes the logical address space. route around failures. Load balancing attempts to
line discipline In Linux, an interpreter for the keep the workload evenly distributed across all
information from a terminal device. processors in an SMP system.
link In fi le naming, a fi le that has no contents but load sharing The ability of a system with multi-
rather points to another fi le. ple CPU cores to schedule threads on those cores.
linked allocation A type of fi le-system block loadable kernel module (LKM) A kernel
allocation in which each fi le is a linked list of allo- structure in which the kernel has a set of core
cated blocks containing the fi le’s contents. Blocks components and can link in additional services
may be scattered all over the storage device. via modules, either at boot time or during run
time.
linked list A data structure in which items are
linked to one another. loader A system service that loads a binary exe-
linker A system service that combines relocat- cutable fi le into memory, where it is eligible to run
able object fi les into a single binary executable fi le. on a CPU core.
Linux distribution A Linux system plus admin- local procedure call In Windows, a method used
istrative tools to simplify the installation, upgrad- for communication between two processes on the
ing, and management of the system. same machine.
Linux instance A set of Pico processes running in local replacement In virtual-memory frame allo-
Windows created by WSL containing an init pro- cation, allowing a process to select a replacement
cess and a bash shell (allowing executing of Linux frame only from the set of all frames allocated to
commands within Windows) the process.
Linux kernel The operating-system kernel of a local replacement algorithm A virtual-memory
Linux system. page replacement algorithm that avoids thrash-
ing by not allowing a process to steal frames from
Linux system The kernel, programs, and fi les
other processes.
that comprise a complete, runnable Linux system.
list A data structure that presents a collection of local-area network (LAN) A network that con-
nects computers within a room, a building, or a
data values as a sequence.
campus.
little-endian A system architecture that stores
the least signifi cant byte fi rst in a sequence of bytes. locality The tendency of processes to reference
memory in patterns rather than randomly.
Little’s formula A scheduling equation (n = ? ×
W) that is particularly useful because it is valid for locality model A model for page replacement
any scheduling algorithm and arrival distribution. based on the working-set strategy.
live migration In virtualization, the movement locality of reference The tendency of processes
of a running guest between two separate physical to reference memory in patterns rather than
hosts. randomly.
LiveCD An operating system that can be booted location independence In distributed comput-
and run from a CD-ROM (or more generally from ing, a feature in which the name of an object does
any media) without being installed on a system’s not need to be changed when the object’s physical
boot disk(s). location changes.
LiveDVD An operating system that can be location transparency In distributed computing,
booted and run from a DVD (or more generally a feature in which the name of an object does not
from any media) without being installed on a sys- reveal its physical location.
tem’s boot disk(s).
lock A mechanism that restricts access by pro-
livelock A condition in which a thread continu- cesses or subroutines to ensure integrity of shared
ously attempts an action that fails. data.G-20 Glossary
locked In general, fi xed in place. In memory lottery scheduling A scheduling algorithm in
management, pages can be locked into memory to which “lottery tickets” are given to threads and a
prevent them from being paged out. lottery number is chosen at random to determine
lock-free An algorithm that provides protection the next thread to get CPU time.
from race conditions without requiring the over- low-fragmentation heap (LFH) An optimization
head of locking. of the Windows default heap designed to decrease
fragmentation.
locking Protecting critical sections, data struc-
tures, or objects though the use of code that coor- low-level formatting The initialization of a stor-
dinates access. age medium in preparation for its use as a com-
puter storage device.
lock-key scheme In protection, a compromise
between access lists and capability lists in which Lustre A common open-source clustered fi le
each object has a unique bit pattern (a lock) and system.
each domain has a unique bit pattern (a key). LXC A Linux container technology.
log fi le A fi le containing error or “logging” infor- Mach An operating system with microkernel
mation; used for debugging or understanding the structure and threading; developed at Carnegie
state or activities of the system. Mellon University.
log-based transaction-oriented fi le system A fi le Mach-O The macOS format of executable fi les.
system that features a write transaction log where
magic cookie A crude method of storing a text
all write activities are logged for replay across
string at the start of a text fi le to indicate the type
actual fi le-system structures and consistency
of text in the fi le.
protection.
magic number A crude method of storing a
logic bomb A remote-access tool designed to
number at the start of a fi le to indicate the type of
operate only when a specifi c set of logical condi-
the data in the fi le.
tions is met.
magnetic tape A magnetic media storage device
logical address Address generated by the CPU;
consisting of magnetic tape spooled on reels and
must be translated to a physical address before it
passing over a read-write head. Used mostly for
is used.
backups.
logical address space The set of all logical
main queue Apple OS per-process block queue.
addresses generated by a program.
main TLB ARM CPU outer-level TLB; checked
logical blocks Logical addresses used to access
after the micro TLB lookup and before a miss
blocks on storage devices.
causes a page table walk.
logical cluster numbers In Windows, the name
mainframe The largest class of computers (along
given to secondary storage physical addresses.
with supercomputers), hosting hundreds of users
logical fi le system A logical layer of the oper- and many and/or large jobs.
ating system responsible for fi le and fi le-system
major fault In virtual memory, a page fault that
metadata management; maintains the FCBs.
can be resolved without having to page in data
logical formatting The creation of a fi le system from secondary storage.
in a volume to ready it for use.
malware Software designed to exploit, disable,
logical memory Memory as viewed by the user; or damage computer systems.
usually a large uniform array, not matching physi- mandatory access control (MAC) Access control
cal memory in virtual memory systems. settings enforced in the form of system policy.
logical records File contents logically designated mandatory fi le-lock mechanism A fi le-locking
as fi xed-length structured data. system in which the operating system enforces
LOOK An HDD I/O scheduling algorithm mod- locking and fi le access.
ifi cation of SCAN that stops the head after the last man-in-the-middle attack An attack in which
request is complete (rather than at the innermost the attacker sits in the middle of the data fl ow of
or outermost cylinder). a communication, masquerading as the sender to
loopback Communication in which a connection the receiver and vice versa.
is established back to the sender. MapReduce A Google-created big data pro-
loosely coupled Describes a kernel design in gramming model and implementation for parallel
which the kernel is composed of components that processing across nodes in a distributed cluster.
have specifi c and limited functions. A layer on top of the Google fi le system (GFS), itGlossary G-21
allows developers to carry out large-scale parallel memory fences Computer instructions that force
computations easily. any changes in memory to be propagated to all
other processors in the system.
marshaling Packaging a communication into an
expected format for transmittal and reception. memory manager (MM) The Windows name for
the component that manages memory.
maskable Describes an interrupt that can be
delayed or blocked (such as when the kernel is in memory mapping A fi le-access method in which
a critical section). a fi le is mapped into the process memory space so
that standard memory access instructions read and
masquerading A practice in which a participant
write the contents of the fi le; an alternative to the
in a communication pretends to be someone else
use of read() and write() calls.
(another host or another person).
memory model Computer architecture mem-
master boot record (MBR) Windows boot code,
ory guarantee, usually either strongly ordered or
stored in the fi rst sector of a boot partition.
weakly ordered.
master fi le directory (MFD) In two-level directory
memory resident Objects, such as pages, that are
implementation, the index pointing to each UFD.
in main memory and ready for threads to use or
master fi le table The NTFS volume control block. execute.
master key In the lock-key protection scheme, a memory stall An event that occurs when a thread
key that is associated with each object and can be is on CPU and accesses memory content that is not
defi ned or replaced with the set-key operation to in the CPU’s cache. The thread’s execution stalls
revoke or change access rights. while the memory content is fetched.
matchmaker A function that matches a caller to memory transaction A sequence of memory
a service being called (e.g., a remote procedure call read–write operations that are atomic.
attempting to fi nd a server daemon).
memory-management unit (MMU) The hard-
mean time between failure (MTBF) The statis- ware component of a computer CPU or mother-
tical mean time that a device is expected to work board that allows it to access memory.
correctly before failing. memory-mapped fi le A fi le that is loaded into
mean time to data loss The statistical mean of physical memory via virtual memory methods,
the time until data is lost. allowing access by reading and writing to the
memory address occupied by the fi le.
mean time to repair The statistical mean of the
time to repair a device (e.g., to get a replacement memory-mapped I/O A device I/O method in
and install it). which device-control registers are mapped into the
address space of the processor.
mechanical storage device A storage device
based on moving mechanical parts (such as HDDs, message In networking, a communication, con-
optical disks, and magnetic tape); one form of tained in one or more packets, that includes source
nonvolatile storage. and destination information to allow correct
delivery. In message-passing communications,
mechanism An operation that defi nes how
a packet of information with metadata about its
something will be done.
sender and receiver.
medium access control (MAC) address A
message digest The calculation resulting from a
unique byte number assigned to every Ethernet
hash function.
device allowing it to be located by packets sent
across a LAN. message passing In interprocess communi-
cation, a method of sharing data in which mes-
megabyte (MB) 1,024^2 bytes.
sages are sent and received by processes. Packets
memory Volatile storage within a computer system. of information in predefi ned formats are moved
memory barriers Computer instructions that between processes or between computers.
force any changes in memory to be propagated to message-authentication code (MAC) A cryp-
all other processors in the system. tographic checksum calculated in symmetric
memory compression In memory management, encryption; used to authenticate short values.
an alternative to paging involving compressing the message-passing model A method of interprocess
contents of frames to decrease the memory used. communication in which messages are exchanged.
memory compression process In Windows 10, metadata A set of attributes of an object. In fi le
a process that maintains a working set of com- systems, e.g., all details of a fi le except the fi le’s
pressed standby pages. contents.G-22 Glossary
metaslabs Chunks of blocks. In ZFS, a pool of stor- memory and to communicate with the rest of the
age is split into metaslabs for easier management. kernel.
methods In Java, functions that act on objects monitor A high-level language synchroniza-
and data fi elds. tion construct that protects variables from race
metropolitan-area network (MAN) A network conditions.
linking buildings within a city. monitor call A software-triggered interrupt
micro TLB ARM CPU inner-level TLBs, one for allowing a process to request a kernel service.
instructions and one for data. monoculture A community of computer systems
microkernel An operating-system structure that that are very similar to one another. This similarity
makes them easier to attack and thus represents a
removes all nonessential components from the
threat to security.
kernel and implements them as system and user-
level programs. monolithic In kernel architecture, describes a ker-
Microsoft interface defi nition language The nel without structure (such as layers or modules).
Microsoft text-based interface defi nition language; Moore’s Law A law predicting that the number
used, e.g., to write client stub code and descriptors of transistors on an integrated circuit would dou-
for RPC. ble every eighteen months.
middleware A set of software frameworks most frequently used (MFU) In general, an algo-
that provide additional services to application rithm that selects the item that has been used most
developers. frequently. In virtual memory, when access counts
minicomputer A mid-sized computer, smaller are available, selecting the page with the highest
count.
than a mainframe but larger (in resources and
users) than a workstation. mount point The location within the fi le struc-
minidisks Virtual disks used in early IBM vir- ture where a fi le system is attached.
tual systems. mount protocol The protocol for mounting a fi le
minimum granularity In the Completely Fair system in a remote fi le system.
Scheduler, a confi gurable variable representing the mount table An in-memory data structure con-
minimum length of time any process is allocated taining information about each mounted volume.
to the processor. It tracks fi le systems and how they are accessed.
miniport driver In Windows I/O, the device- mounting Making a fi le system available for use
specifi c driver. by logically attaching it to the root fi le system.
minor fault In virtual memory, a page fault multicore Multiple processing cores within the
resolved by executing an I/O to bring in the page same CPU chip or within a single system.
from secondary storage. multicore processor Multiple processing cores
mirrored volume A volume in which two within the same CPU chip.
devices are mirrored. multicore systems Systems that have two or more
mirroring In storage, a type of RAID protection hardware processors (CPU cores) in close commu-
in which two physical devices contain the same nication, sharing the computer bus and sometimes
content. If one device fails, the content can be read the clock, memory, and peripheral devices.
from the other. multifactor authentication Authentication based
mobile computing A mode of computing involv- on two or more sources of data, with more sources
ing small portable devices like smartphones and generally providing stronger authentication.
tablet computers. multilevel feedback queue A scheduling algo-
mode bit A CPU status bit used to indicate the rithm that allows a process to move between
current mode: kernel (0) or user (1). queues.
modify bit An MMU bit used to indicate that a multilevel queue A scheduling algorithm that
frame has been modifi ed (and therefore must have partitions the ready queue into several separate
its contents saved before page replacement). queues.
module loader and unloader In Linux, user-mode multiple universal-naming-convention provider
utilities that work with the module-management (MUP) The component within Windows that
system to load modules into the kernel. executes remote fi le accesses.
module-management system In Linux, the facil- multiple user interface (MUI) A Windows
ity that allows kernel modules to be loaded into Vista feature that allows multiple user interfaces,Glossary G-23
possibly confi gured for different locales, to be network address translation In networking, the
used concurrently. mapping of one header address to another by mod-
multiprocessor Multiple processors within the ifying the network packets (e.g., allowing a host
to provide IP addresses to multiple guests while
same CPU chip or within a single system.
presenting only one IP address to the connected
multiprocessor systems Systems that have two
network).
or more hardware processors (CPU cores) in close
communication, sharing the computer bus and network computer A limited computer that
sometimes the clock, memory, and peripheral understands only web-based computing.
devices. network device interface specifi cation
multiprogramming A technique that increases (NDIS) An internal Windows networking inter-
CPU utilization by organizing jobs (code and data) face separating network adapters from transport
so that the CPU always has a job to execute. protocols.
multitasking The concurrent performance of network devices I/O devices that connect to a
multiple jobs. A CPU executes multiple jobs by network.
switching among them, but the switches occur network fi le system (NFS) A common network
so frequently that users can interact with the fi le system used by UNIX, Linux, and other operat-
processes. ing systems to share fi les across a network.
multithreaded A term describing a process or network operating system A type of operating
program with multiple threads of control, allow- system that provides features such as fi le sharing
ing multiple simultaneous execution points. across a network, along with a communication
mutex lock A mutual exclusion lock; the sim- scheme that allows different processes on differ-
plest software tool for assuring mutual exclusion. ent computers to exchange messages. It provides
an environment in which users can access remote
mutual exclusion A property according to which
resources by remote login or data transfer between
only one thread or process can be executing code
remote and local systems.
at once.
network time protocol A network protocol for
name server In the domain-name system, a host
synchronizing system clocks.
or software that provides resolving services.
network virtual memory A distributed comput-
named pipes A connection-oriented messaging
ing feature similar to virtual memory but with the
mechanism—e.g., allowing processes to communi-
backing store on a remote system.
cate within a single computer system.
network-attached storage (NAS) Storage accessed
named semaphore A POSIX scheduling con-
from a computer over a network.
struct that exists in the fi le system and can be
shared by unrelated processes. NFS protocol The protocol used for remote fi le
access, remote fi le system mounting, etc., by the
named shared-memory object In Windows API,
NFS fi le system.
a section of a memory-mapped fi le accessible by
name from multiple processes. nice value One of a range of values from ?20 to
+19, where a numerically lower value indicates a
namespace In Linux, a process’s specifi c view of
higher relative scheduling priority.
the fi le system hierarchy.
NIS A distributed naming service that provides
naming In distributed computing, the mapping
username, password, hostname, and printer infor-
between logical and physical objects.
mation to a set of computers.
national-language-support (NLS) A Windows
nonblocking A type of I/O request that allows
API providing support for localization (including
the initiating thread to continue while the I/O
date, time, and money formats).
operation executes. In interprocess communi-
need-to-know principle The principle that only
cation, a communication mode in which the
those resources currently needed should be avail-
sending process sends the message and resumes
able to use at a given time.
operation and the receiver process retrieves
nested page tables (NPTs) In virtualization, a either a valid message or a null if no message is
method used by the virtual machine manager to available. In I/O, a request that returns whatever
maintain page-table state both for guests and for data is currently available, even if it is less than
the system. requested.
network In the simplest terms, a communication noncontainer objects In Windows 10, a category
path between two or more systems. of objects that cannot contain other objects.G-24 Glossary
nonmaskable interrupt An interrupt that cannot on-line Generally, a facility, system, or comput-
be delayed or blocked (such as an unrecoverable ing component that is available. In fi le system
memory error) implementation, operations executing while the
fi le system is available for use.
nonpreemptive Scheduling in which, once a core
has been allocated to a thread, the thread keeps the open count The number of processes having an
core until it releases the core either by terminating open fi le.
or by switching to the waiting state. open-fi le table An operating system data struc-
nonpreemptive kernels A type of kernel that ture containing details of every fi le open within
does not allow a process running in kernel mode the system.
to be preempted; a kernel-mode process will run open-source operating system An operating
until it exits kernel mode, blocks, or voluntarily system or other program available in source-code
yields control of the CPU. format rather than as compiled binary code.
nonrepudiation Proof that an entity performed an operating system A program that manages a
action (frequently performed by digital signatures). computer’s hardware, provides a basis for appli-
non-uniform memory access (NUMA) An archi- cation programs, and acts as an intermediary
tecture aspect of many computer systems in which between the computer user and the computer
the time to access memory varies based on which hardware.
core the thread is running on (e.g., a core interlink optimal page-replacement algorithm A theo-
is slower than accessing DIMMs directly attached retically optimal page replacement algorithm that
to core). has the lowest page-fault rate of all algorithms and
nonvolatile memory (NVM) Persistent storage never suffers from Belady’s anomaly.
based on circuits and electric charges. Orange Book U.S. Department of Defense
nonvolatile storage (NVS) Storage in which data Trusted Computer System Evaluation Criteria;
will not be lost in a power outage or similar event. a method of classifying the security of a system
design.
NOOP The Linux NVM scheduling algorithm,
fi rst come fi rst served but with adjacent requests orphan The child of a parent process that termi-
merged into fewer, larger I/O requests. nates in a system that does not require a terminat-
ing parent to cause its children to be terminated.
NUMA node One or more cores (e.g., cores
that share a cache) that are grouped together as a OS/2 A PC operating system from the mid 1980s
scheduling entity for affi nity or other uses. co-developed by IBM and Microsoft to replace
MS-DOS; generally considered to be a failure.
NVM express (NVMe) A high-speed I/O bus for
NVM storage. OSI protocol stack A set of cooperating network
protocols that form a fully functional network. The
NVRAM DRAM with battery or other backup
OSI model formalized some of the earlier work
power, rendering it nonvolatile.
done in network protocols but is currently not in
object An instance of a class or an instance of widespread use.
a data structure. In Windows and generally, an
out-of-band In networking, a term describing
instance of an object type.
data delivered in a manner independent of the
object linking and embedding (OLE) A Micro- main data stream (e.g., delivery of a symmetric key
soft technology allowing services to provide func- in a paper document).
tions to components (e.g., for inserting spread-
out-of-memory (OOM) killer In Linux, a routine
sheets into Word documents).
that executes when free memory is very low, termi-
object manager In Windows, the kernel (execu- nating processes to free memory.
tive) component that manipulates objects.
over-allocating Generally, providing access to
object type In Windows, a system-defi ned data more resources than are physically available. In
type that has a set of attributes and methods that virtual memory, allocating more virtual memory
help defi ne its behavior. than there is physical memory to back it.
off-line Generally, a facility, system, or comput- overcommitment In virtualization, providing
ing component that is unavailable. In fi le system resources to guests that exceed available physical
implementation, operations executing while the resources.
fi le system is unavailable for use. over-provisioning In non-volatile memory,
one-time password A password that is only space set aside for data writes that is not counted
valid once. in the device free space.Glossary G-25
owner In fi le permissions, the userid that owns page-replacement algorithm In memory man-
and controls access to a fi le. agement, the algorithm that chooses which victim
frame of physical memory will be replaced by a
owner rights In fi le permissions, the userid that
needed new frame of data.
owns and controls access to a fi le.
page A fi xed-sized block of logical memory.
page address extension (PAE) Intel IA-32 CPU
architecture hardware that allows 32-bit proces- page-table base register In paged memory, the
sors to access physical address space larger than CPU register pointing to the in-memory page
4GB. table.
page allocator The kernel routine responsible for page-table entry (PTE) A Windows virtual
allocating frames of physical memory. memory data structure.
page cache In fi le I/O, a cache that uses virtual page-table length register A CPU register indi-
memory techniques to cache fi le data as pages cating the size of the page table.
rather than fi le-system-oriented blocks for paging A common memory management scheme
effi ciency. that avoids external fragmentation by splitting
page directory In Intel IA-32 CPU architecture, physical memory into fi xed-sized frames and
the outermost page table. logical memory into blocks of the same size called
pages.
page directory pointer table PAE pointer to page
tables. paging fi le The Windows term for backing store.
page fault A fault resulting from a reference to a paging mechanism In Linux, the kernel compo-
non-memory-resident page of memory. nent that carries out the transfer of pages back and
forth to backing store.
page frame A Windows virtual memory data
structure. paired password In authentication, a challenge-
response set of secret keys, where only the correct
page frame number (PFN) In Windows, the
response to the challenge provides authentication.
name of the indicator of the page frame address.
parallel fi le system (PFS) A fi le system that is
page number Part of a memory address gener-
LAN-based and treats N systems storing data and
ated by the CPU in a system using paged memory;
Y clients accessing the data as a single client-server
an index into the page table.
instance; more complex than a client-server DFS
page offset Part of a memory address generated but less complex than a cluster-based DFS. GPFS
by the CPU in a system using paged memory; the and Lustre are examples.
offset of the location within the page of the word
parallel regions Blocks of code that may run in
being addressed.
parallel.
page replacement In virtual memory, the selec-
parallel systems Systems that have two or more
tion of a frame of physical memory to be replaced
hardware processors (CPU cores) in close commu-
when a new page is allocated.
nication, sharing the computer bus and sometimes
page slot In Linux swap-space management, a the clock, memory, and peripheral devices.
part of the data structure tracking swap-space use.
parallelization The process of dividing a pro-
page table In paged memory, a table containing gram into separate components that run in parallel
the base address of each frame of physical mem- on individual cores in a computer or computers in
ory, indexed by the logical page number. a cluster.
page-directory entry (PDE) A Windows virtual- paravirtualization A technique in which a guest
memory data structure. operating system is modifi ed to work in coopera-
page-fault frequency The frequency of page tion with a virtual machine manager.
faults. parent In a tree data structure, a node that has
page-fault rate A measure of how often a page one or more nodes connected below it.
fault occurs per memory access attempt. partition Logical segregation of storage space
pageout policy Generally, an algorithm for into multiple area; e.g., on HDDs, creating several
deciding which memory pages to page out. In groups of contiguous cylinders from the devices’
Linux, the virtual memory pageout policy uses a full set of cylinders.
modifi ed version of the second-chance algorithm. partition boot sector The NTFS boot control block.
pager The operating-system component that passphrase A longer, generally more secure
handles paging. password composed of multiple words.G-26 Glossary
password A secret key, usually used to authenti- physical-to-virtual (P-to-V) In virtualization, the
cate a user to a computer. conversion of a physical system’s operating sys-
path name The fi le-system name for a fi le, which tem and applications to a virtual machine.
contains all the mount-point and directory-entry Pico In WSL, a special Linux-enabling process
information needed to locate the fi le (e.g., “C:/ that translates Linux system calls to the LXCore
foo/bar.txt” and “/foo/bar.txt”) and LXSS services.
path-name translation The parsing of a fi le name pinning In memory management, locking pages
into separate directory entries, or components. into memory to prevent them from being paged out.
PCIe bus A common computer I/O bus connect- pipe A logical conduit allowing two processes to
ing the CPU to I/O devices. communicate.
peer-to-peer (p2p) A mode of distributed com- platform as a service (PaaS) A software stack
puting in which all nodes act as both clients of ready for application use via the Internet (e.g., a
other nodes and servers to other nodes. database server).
penetration test The scanning of a target entity platter An HDD component that has a magnetic
to look for known vulnerabilities. media layer for holding charges.
performance tuning The activity of improving plug-and-play (PnP) manager In Windows, the
performance by removing bottlenecks. manager responsible for detecting and enumerat-
periodic A type of real-time process that repeat- ing devices when the system is booting and adding
edly moves at fi xed intervals between two modes: and removing devices when the system is running.
needing CPU time and not needing CPU time. pluggable authentication module (PAM) A
permissions An entity’s access rights to an object shared library that can be used by any system com-
(e.g., a user’s access rights to a fi le). ponent to authenticate users.
per-process open-fi le table A kernel in-memory plug-in An add-on functionality that expands
per-process data structure containing pointers to the primary functionality of a process (e.g., a web
the system-wide open-fi le table, as well as other browser plug-in that displays a type of content dif-
information, for all fi les the process has open. ferent from what the browser can natively handle).
personal fi rewall A software layer, either part point-to-point tunneling protocol (PPTP) A
of the operating system or added to a computer, protocol in Windows and other systems allowing
limiting communication to and from a given host. communication between remote-access server
modules and client systems connected across a
personal identifi cation number A usually short
WAN.
and not very secure password composed of some
combination of digits 0-9. policy A rule that defi nes what will be done.
personal-area network (PAN) A network linking policy algorithm In Linux, a part of the paging
devices within several feet of each other (e.g., on a system that decides which pages to write out to
person). backing store and when to write them.
petabyte (PB) 1,024^5 bytes. polling An I/O loop in which an I/O thread con-
tinuously reads status information waiting for I/O
Peterson’s solution A historically interesting
to complete.
algorithm for implementing critical sections.
pool In virtual memory, a group of free pages
phishing A class of social engineering attacks in
kept available for rapid allocation (e.g., for copy-
which a legitimate-looking e-mail or website tricks
on-write). In ZFS, drives, partitions, or RAID sets
a user into breaching confi dentiality or enabling
that can contain one or more fi le systems.
privilege escalation.
pop The action of removing an item from a stack
PHY The physical hardware component that
data structure.
connects to a network (implements layer 1 in the
OSI model). port A communication address; a system may
have one IP address for network connections but
physical address Actual location in physical
many ports, each for a separate communication.
memory of code or data.
In computer I/O, a connection point for devices
physical address space The set of all physical to attach to computers. In software development,
addresses generated by a program. to move code from its current platform to another
physical formatting The initialization of a stor- platform (e.g., between operating systems or
age medium in preparation for its use as a com- hardware systems). In the Mach OS, a mailbox for
puter storage device. communication.Glossary G-27
port driver In Windows I/O, the common driver or modify kernel data that are currently being
for a class of devices. accessed by a lower-priority process.
port number In TCP/IP and UDP/IP network- priority number A number indicating the posi-
ing, an address of a service on a system. tion of a process in a conditional-wait queue in a
port set A collection of ports, as declared by a monitor construct.
task, that can be grouped together and treated as priority paging Prioritizing selection of victim
one port for the purposes of the task. frames based on some criteria, such as avoiding
portable An aspect of software that describes its selection of shared library pages.
ease of transfer between CPU architectures and priority replacement algorithm A virtual mem-
computer systems. ory page replacement algorithm that avoids
portable executable (PE) The Windows format thrashing by not allowing a process to steal frames
from other processes.
for executable fi les.
portals Gateways between requestors and ser- priority-inheritance protocol A protocol for
solving priority inversion in which all processes
vices running on provider computers.
that are accessing resources needed by a higher-
position-independent code (PIC) In Linux,
priority process inherit that higher priority until
binary code compiled from shared libraries that
they are fi nished with the resources in question.
can be loaded anywhere in memory.
priority scheduling A scheduling algorithm in
positioning time On an HDD, the time it takes the
which a priority is associated with each thread and
read-write head to position over the desired track.
the free CPU core is allocated to the thread with
power manager In Windows, the component the highest priority.
that implements power management policies.
private cloud Cloud computing run by a com-
power users Users with unusually deep knowl- pany for that company’s own use.
edge of a system.
private key In an asymmetric encryption algo-
power-of-2 allocator In the buddy system, an rithm, a key that must be kept private for use in
allocator that satisfi es memory requests, in units authenticating, encrypting, and decrypting.
sized as a power of 2, from a fi xed-sized segment
privilege escalation The enabling of more priv-
consisting of contiguous pages.
ileges than an entity (process, system, person)
power-on self-test (POST) A fi rmware routine should have.
run at system power-on that tests the system for
privileged instructions Instructions that can
hardware issues, identifi es and initializes many of
execute only if the CPU is in in kernel mode.
the attached devices, and builds the description of
privileged mode A CPU mode in which all
the devices used by the advanced confi guration
instructions are enabled. The kernel runs in this
and power interface (ACPI).
mode. See also user mode.
preemptive A form of scheduling in which pro-
proc fi le system (/proc) A pseudo fi le system
cesses or threads are involuntarily moved from the
using fi le-system interfaces to provide access to a
running state (e.g., by a timer signaling the kernel
system’s process name space.
to allow the next thread to run).
preemptive kernel A type of kernel that allows procedural language A language that imple-
ments state-based algorithms (e.g., C, C++, Java,
a process to be preempted while it is running in
and C#).
kernel mode.
preemptive multitasking A model of multitask- process A program loaded into memory and
executing.
ing in which threads on cores may be preempted
by higher-priority threads before fi nishing their process control A category of system calls.
scheduled time quanta. process control block A per-process kernel data
prepaging In virtual memory, bringing pages structure containing many pieces of information
into memory before they are requested. associated with the process.
principle of least privilege A design principle process identifi er (pid) A unique value for each
stating that every program and every privileged process in the system that can be used as an index
user of the system should operate using the least to access various attributes of a process within the
amount of privilege necessary to complete the job. kernel.
priority inversion A scheduling challenge aris- process lifetime management (PLM) A Win-
ing when a higher-priority process needs to read dows power-saving feature that suspends allG-28 Glossary
threads within a process that has not been used for protection A category of system calls. Any mecha-
a few seconds. nism for controlling the access of processes or users
process migration The movement of a process to the resources defi ned by a computer system.
between computers. protection domain In protection, a set of
process name A human-readable name for a resources that a process may access. In virtualiza-
process. tion, a virtual machine manager creates a protec-
tion domain for each guest to inform the CPU of
process scheduler A scheduler that selects an
which physical memory pages belong to that guest.
available process (possibly from a set of several
processes) for execution on a CPU. protection mask In Linux and UNIX, a set of
bits assigned to an object specifying which access
process synchronization Coordination of access
modes (read, write, execute) are to be granted to
to data by two or more threads or processes.
processes with owner, group, or world access
process-contention scope (PCS) A scheduling writes to the object.
scheme, used in systems implementing the many-
protection rings A model of privilege separation
to-one and many-to-many threading models, in
consisting of a series of rings, with each successive
which competition for the CPU takes place among
ring representing greater execution privileges.
threads belonging to the same process.
pseudo device driver In virtualization, a guest
processor affi nity A kernel scheduling method
device driver that does not directly control sys-
in which a process has an affi nity for (prefers) the
tem hardware but rather works with the virtual
processor on which it is currently running.
machine manager to access the device.
processor groups In Windows 7, processors
PTE table A Windows virtual-memory data
grouped together for management and scheduling.
structure.
producer A process role in which the process
Pthreads The POSIX standard (IEEE 1003.1c)
produces information that is consumed by a con-
defi ning an API for thread creation and synchroni-
sumer process.
zation (a specifi cation for thread behavior, not an
production kernels Kernels released for produc-
implementation).
tion use (as opposed to development use).
public cloud Cloud computing available via the
profi ling Periodically sampling the instruction
Internet to anyone willing to pay for the services
pointer to determine which code is being executed;
offered.
used in debugging and performance tuning.
public domain The total absence of copyright
program counter A CPU register indicating the
protection. Software in the public domain can be
main memory location of the next instruction to
used as desired by anyone, with no limits.
load and execute.
public key In asymmetric encryption algorithm,
programmable interval timer A hardware timer
a key that can be distributed for encrypting and
provided by many CPUs.
decrypting.
programmed I/O (PIO) A method of transfer-
public key encryption A cipher algorithm in
ring data between a CPU and a peripheral device
which different keys are used for encryption and
in which data are transferred one byte at a time.
decryption.
programming-environment virtualization Vir-
pull migration Migration that occurs when an
tualization in which a virtual machine manager
idle processor pulls a waiting thread from a busy
does not virtualize real hardware but instead
processor.
creates an optimized virtual system (examples
include Oracle Java and Microsoft.Net). pure demand paging A demand paging scheme
wherein no page is brought into memory until it is
project In Solaris scheduling, a group of pro-
referenced.
cesses scheduled as a unit.
push The action of placing a value on a stack
proportional allocation An allocation algorithm
data structure.
that assigns a resource in proportion to some
aspect of the requestor. In virtual memory, the push migration Migration in which a task peri-
assignment of page frames in proportion to the odically checks the load on each processor and, if
size each process. it fi nds an imbalance, evenly distributes the load
by moving (or pushing) threads from overloaded
proportional share A scheduler that operates by
to idle or less busy processors.
allocating T shares among all applications, ensur-
ing that each gets a specifi c portion of CPU time. Quest-V An example of a partitioning hypervisor.Glossary G-29
queue A sequentially ordered data structure that ready queue The set of processes ready and
uses the fi rst-in, fi rst-out (FIFO) principle; items waiting to execute.
are removed from a queue in the order in which real-time A term describing an execution envi-
they were inserted. ronment in which tasks are guaranteed to com-
queueing-network analysis An area of comput- plete within an agreed-to time.
ing study in which algorithms are analyzed for real-time class A scheduling class that seg-
various characteristics and effectiveness. regates real-time threads from other threads to
race condition A situation in which two threads schedule them separately and provide them with
are concurrently trying to change the value of a their needed priority.
variable. real-time operating systems (RTOS) Systems used
RAID levels The various types of RAID protection. when rigid time requirements have been placed on
the operation of a processor or the fl ow of data; often
RAM drives Sections of a system’s DRAM pre-
used as control devices in dedicated applications.
sented to the rest of the system as if they were
secondary storage devices. reapers In memory management, routines that
scan memory, freeing frames to maintain a mini-
random-access memory (RAM) Rewritable
mum level of available free memory.
memory, also called main memory. Most programs
run from RAM, which is managed by the kernel. recovery mode A system boot state providing
limited services and designed to enable the system
ransomware A class of malware that disables
admin to repair system problems and debug sys-
computer access (frequently by encrypting fi les or
tem startup.
the entire system) until a ransom is paid.
Red Hat A popular Linux distribution.
rate Generally, a measure of speed or frequency.
red-black tree A tree containing n items and hav-
A periodic real-time process has a scheduling
ing at most lg n levels, thus ensuring worst-case
rate of 1/p, where p is the length of its running
performance of O(lg n).
period.
redirector In Windows, a client-side object that
rate-monotonic A scheduling algorithm that
forwards I/O requests to a remote system.
schedules periodic tasks using a static priority pol-
icy with preemption. redundant arrays of independent disks (RAID)
A disk organization technique in which two or
raw partition A partition within a storage device
more storage devices work together, usually with
not containing a fi le system.
protection from device failure.
raw disk Direct access to a secondary storage
reentrant code Code that supports multiple con-
device as an array of blocks with no fi le system.
current threads (and can thus be shared).
raw I/O Direct access to a secondary storage
reference bit An MMU bit indicating that a page
device as an array of blocks with no fi le system.
has been referenced.
read pointer The location in a fi le from which the
reference string A trace of accesses to a resource.
next read will occur.
In virtual memory, a list of pages accessed over a
read-ahead Sequential I/O performance optimi- period of time.
zation that reads and caches several subsequent
referenced pointer In Windows, a means by
pages when a read of one page is requested.
which kernel-mode code can access objects; must
readers-writers problem A synchronization be obtained by calling a special API.
problem in which one or more processes or threads
regions In ARM v8 CPUs, contiguous areas of
write data while others only read data.
memory with separate privilege and access rules.
reader-writer lock A lock appropriate for access
registry A fi le, set of fi les, or service used to store
to an item by two types of accessors, read-only and
and retrieve confi guration information. In Win-
read-write.
dows, the manager of hives of data.
read-modify-write cycle The situation in which
regressive round-robin A variation on round-
a write of data smaller than a block requires the
robin scheduling in which a thread that uses its
entire block to be read, modifi ed, and written back.
entire CPU scheduling quantum is given a longer
read-only memory (ROM) A storage device quantum and higher priority.
whose contents are not modifi able. relative access A fi le-access method in which
read-write (RW) Access that allows reading and contents are read in random order, or at least not
writing. sequentially.G-30 Glossary
relative block number An index relative to the request edge In a system resource-allocation
beginning of a fi le. The fi rst relative block of the graph, an edge (arrow) indicating a resource request.
fi le is block 0, the next is block 1, and so on through request manager In Linux, the kernel compo-
the end of the fi le. nent that manages the reading and writing of buf-
relative path name A path name starting at a rel- fer contents to and from a block-device driver.
ative location (such as the current directory). resolve Generally, to translate from a symbolic
relocatable code Code with bindings to mem- representation to a numeric one. In networking, to
ory addresses that are changed at loading time to translate from a host name to a host-id. With fi les,
refl ect where the code is located in main memory. to follow a link and fi nd the target fi le.
relocatable object fi le The output of a compiler resource allocator An operating system or appli-
in which the contents can be loaded into any loca- cation that determines how resources are to be
tion in physical memory. used.
relocation An activity associated with linking resource manager The role of an operating sys-
and loading that assigns fi nal addresses to pro- tem in managing the computer’s resources.
gram parts and adjusts code and data in the pro- resource sharing The ability for multiple users,
gram to match those addresses. computers, etc., to access computing resources.
relocation register A CPU register whose value resource utilization The amount of a given
is added to every logical address to create a phys- resource (hardware or software) that is being used.
ical address (for primitive memory management).
response time The amount of time it takes the
remainder section Whatever code remains to be system to respond to user action.
processed after the critical and exit sections.
restore In fi le systems, the act of repairing or
remote access tool (RAT) A back-door daemon recovering fi les or a fi le system from a backup.
left behind after a successful attack to allow con-
resume In virtualization, the continuation of
tinued access by the attacker.
execution after a guest’s suspension.
remote desktop The representation of a desktop
reverse engineering The procedure of convert-
session to another system across a network, for
ing a compiled binary fi le into a human-readable
remote access to the computer’s GUI.
format.
remote desktop protocol (RDP) A network
rich text format A fi le format developed by
protocol to allow remote access to a computer’s
Microsoft that includes formatting details but can
display contents and keyboard and mouse input
be used by various applications and operating
devices.
systems, enabling fi les to be transferred between
remote fi le transfer A function of a network programs and systems.
operating system providing a means to transfer
risk assessment A systemic security analysis
fi les between network-attached computers.
that attempts to value the assets of the entity in
remote procedure calls (RPCs) Procedure calls question and determine the odds that a security
sent across a network to execute on another com- incident will affect the entity.
puter; commonly used in client-server computing.
roaming profi le In Windows, a collection of user
remote-service mechanism A facility, imple- preferences and settings that are kept on a server
mented by a feature such as RPC, in which clients and allow a user’s environment to follow that user
ask a remote system to perform a function for from computer to computer.
them.
role-based access control (RBAC) A method
renderer A process that contains logic for render- of access control in which roles rather than users
ing contents (such as web pages) onto a display. have access rights; applies the principle of least
rendezvous In interprocess communication, when privilege to the protection of operating systems.
blocking mode is used, the meeting point at which role In RBAC, a named set of privileges that can
a send is picked up by a receive. be available to a user.
replay attack The malicious or fraudulent repeti- root partition The storage partition that con-
tion of a valid transmission. tains the kernel and the root fi le system; the one
replication In fi le systems, the duplication and mounted at boot.
synchronization of a set of data over a network to rotational latency On an HDD, the time it takes
another system. In storage, the automatic duplica- the read-write head, once over the desired cylin-
tion of writes between separate sites. der, to access the desired track.Glossary G-31
round-robin (RR) A scheduling algorithm simi- scheduler activation A threading method in
lar to FCFS scheduling, but with preemption added which the kernel provides an application with a
to enable the system to switch between threads; set of LWPs, and the application can schedule user
designed especially for time-sharing systems. threads onto an available virtual processor and
receive upcalls from the kernel to be informed of
router A device or software that connects net-
certain events.
works to each other (e.g., a home network to the
Internet). scheduling classes In Linux, classes on which
scheduling is based; each class is assigned a spe-
RSA The most widely used public key cipher.
cifi c priority.
run queue The queue holding the threads that
scheduling domain A set of CPU cores that can
are ready to run on a CPU.
be balanced against one another.
running The state of the operating system after
scope The time between when a lock is acquired
boot when all kernel initialization has completed
and when it is released.
and system services have started. In general, the
system state after booting and before crashing or script kiddie An attacker who did not design the
being shut down. attack but instead is using an attack designed by a
more sophisticated attacker.
run-time environment (RTE) The full suite of
software needed to execute applications written in search path In some operating systems, the
a given programming language, including its com- sequence of directories searched for an executable
pilers, libraries, and loaders. fi le when a command is executed.
safe computing Human behavior aimed at second extended fi le system (ext2) In Linux, an
avoiding viruses and other security problems (e.g., outdated version of the extended fi le system
by avoiding downloading pirated software). secondary storage A storage system capable of
safe sequence “In deadlock avoidance, a sequence holding large amounts of data permanently; most
of processes <P1, P2, ..., Pn> in which, for each commonly, HDDs and NVM devices.
Pi, the resource requests that Pi can make can be second-chance page-replacement algorithm A
satisfi ed by the currently available resources plus FIFO page replacement algorithm in which, if the
the resources held by all Pj, with j < i.” reference bit is set, the bit is cleared and the page
safe state In deadlock avoidance, a state in which is not replaced.
a system can allocate resources to each process in second-level interrupt handler In some oper-
some order and still avoid deadlock. ating systems, the interrupt handler that actu-
sandbox A contained environment (e.g., a virtual ally handles interrupts; reception and queueing
machine). of interrupts are handled at another level (by the
fi rst-level handler).
sandboxing Restricting what an object can do by
placing it in a contained environment (e.g., run- section object The Windows data structure that
ning a process on a virtual machine). is used to implement shared memory.
SAS A common type of I/O bus. sector forwarding The replacement of an unus-
able HDD sector with another sector at some other
scalability Generally, the ability of a facility
location on the device.
or service to increase capacity as needed by the
sector slipping The renaming of sectors to avoid
users (e.g., to add more cores when the load
using a bad sector.
increases).
sector sparing The replacement of an unusable
SCAN algorithm An HDD I/O scheduling algo-
HDD sector with another sector at some other
rithm in which the disk head moves from one
location on the device.
end of the disk to the other performing I/O as the
head passes the desired cylinders; the head then sector On an HDD platter, a fi xed-size section of
reverses direction and repeats. a track.
scatter-gather An I/O method in which multiple secure The state of a system whose resources
sources or destinations of I/O are specifi ed in one are used and accessed as intended under all
command structure. circumstances.
scheduler The part of the operating system that secure by default Describes a system or com-
determines the next job to be done (e.g., the next puter whose initial confi guration decreases its
process to be executed). attack surface.G-32 Glossary
secure monitor call (SMC) An ARM processor semiconductor memory The various types of
special instruction that can be used by the kernel memory constructed from semiconductors.
to request services from the TrustZone.
sense key In the SCSI protocol, information in
secure system process In Windows, the pro- the status register indicating an error.
cess representing the fact that the secure kernel is
separation hypervisor An experimental system
loaded.
that uses virtualization to partition separate sys-
security The defense of a system from external tem components into a chip-level distributed com-
and internal attacks. Such attacks include viruses puting system.
and worms, denial-of-service attacks, identity
sequence number In networking, a counter
theft, and theft of service.
assigned to packets to order their assembly after
security access token In Windows 10, a token delivery.
created when a user logs in that contains the
sequential access A fi le-access method in which
user’s security ID, the security IDs of the groups
contents are read in order, from beginning to end.
the user belongs to, and a list of special privileges
the user has. serial-attached SCSI (SAS) A common type of
I/O bus.
security context In Windows 10, a characteris-
tic, based on a user’s access token, that enables a server In general, any computer, no matter the
program run by the user to access what the user is size, that provides resources to other computers.
allowed to access. server subject In Windows 10 security, a process
security descriptor In Windows 10, a feature that implemented as a protected server that uses the
describes the security attributes of an object. security context of the client when acting on the
client’s behalf.
security domain The separation of systems and
devices into classes, with each class having similar server system A system providing services to
security needs. other computers (e.g., a web server).
security ID (SID) In Windows, a value used server-message-block (SMB) The Windows pro-
to uniquely identify a user or group for security tocol for sending I/O requests over a network; a
purposes. version was published as the common internet fi le
system (CIFS).
security policy A document describing the set of
things being secured, how they are to be secured, service A software entity running on one or more
and how users are to behave in matters relating to machines and providing a particular type of func-
security. tion to calling clients. In Android, an application
component with no user interface; it runs in the
security reference monitor (SRM) A Windows
background while executing long-running opera-
component that checks the effective security token
tions or performing work for remote processes.
whenever a thread opens a handle to a protected
data structure. service control manager (SCM) In Windows 7,
the component that manages services associated
security through obscurity A security layer in
with plug-and-play devices.
which information is kept private or obscured in
the hope that it won’t be discovered and used by service-trigger A mechanism in Windows 7 that
attackers; an ineffective security method. allows plug-and-play device insertion to launch a
service.
security token In Windows, a token associated
with each process containing the SIDs of the user session In networking, a complete round of com-
and the user’s groups, the user’s privileges, the munication, frequently beginning with a login and
integrity level of the process, the attributes and ending with a logoff to terminate communications.
claims associated with the user, and any relevant session hijacking The interception of a commu-
capabilities. nication.
seek The operation of changing the current
session key The TLS symmetric key, used for a
fi le-position pointer.
web communication session, exchanged via asym-
seek time On an HDD, the time it takes the read- metric cryptography.
write head to position over the desired cylinder.
SHA-1 An algorithm for creating a hash (a small,
semaphore An integer variable that, apart from fi xed-size block of data calculated from a larger
initialization, is accessed only through two stan- data set, used to determine if a message has been
dard atomic operations: wait() and signal(). changed).Glossary G-33
shared libraries Libraries that can be loaded into simultaneous multithreading (SMT) The situa-
memory once and used by many processes; used tion in which, in a CPU with multiple cores, each
in systems that support dynamic linking. core supports multiple hardware threads.
shared lock A fi le lock similar to a reader lock single indirect block In UFS, a block contain-
in that several processes can obtain the lock ing pointers to direct blocks, which point to data
concurrently. blocks.
shared memory In interprocess communication, single instruction multiple data (SIMD) A form
a section of memory shared by multiple processes of parallelism in which multiple compute elements
and used for message passing. perform the same single instruction operating on
shared system interconnect A bus connecting multiple data points.
CPUs to memory in such a way that all CPUs can single step A CPU mode in which a trap is exe-
access all system memory; the basis for NUMA cuted by the CPU after every instruction (to allow
systems. examination of the system state after every instruc-
shared-memory model An interprocess com- tion); useful in debugging.
munication method in which multiple processes single-threaded A process or program that has
share memory and use that memory for message only one thread of control (and so executes on only
passing. one core at a time).
shares A basis for making scheduling decisions. single-user mode A system boot state providing
The fair-share scheduling class uses CPU shares limited services and designed to enable the system
instead of priorities to allocate CPU time. admin to repair system problems and debug system
shell One of the command interpreters on a sys- startup.
tem with multiple command interpreters to choose Siri The Apple voice-recognition system.
from.
sketch An Arduino program.
shell script A fi le containing a set series of com-
slab A section of memory made up of one or
mands (similar to a batch fi le) that are specifi c to
more contiguous pages; used in slab allocation.
the shell being used.
slab allocation A memory allocation method
shortest-job-fi rst (SJF) A scheduling algorithm
in which a slab of memory is allocated and split
that associates with each thread the length of the
into chunks that hold objects of a given size. As
thread’s next CPU burst and schedules the shortest
the objects are freed, the chunks can coalesce into
fi rst.
larger chunks, eliminating fragmentation.
shortest-remaining-time-fi rst (SJRF) A schedul-
Slackware An early but still widely used Linux
ing algorithm that gives priority to the thread with
distribution.
the shortest remaining time until completion.
shortest-seek-time-fi rst (SSTF) algorithm An slim reader-write lock (SRW) A type of lock in
HDD I/O scheduling algorithm that sorts requests modern Windows OS that favors neither readers
by the amount of seek time required to accomplish nor writers.
the request; the shortest time has the highest priority. small computer-systems interface (SCSI) One
shoulder surfi ng Attempting to learn a pass- type of interface between a system and its storage
word or other secret information by watching the (SCSI). See also ATA and SATA.
target user at the keyboard. snapshot In fi le systems, a read-only view of
siblings In a tree data structure, child nodes of a fi le system at a particular point in time; later
the same parent. changes do not affect the snapshot view.
Siemens Jailhouse An example of a partitioning sniff In network communication, to capture
hypervisor. information by recording data as it is transmitted.
signal In UNIX and other operating systems, a sniffi ng An attack in which the attacker moni-
means used to notify a process that an event has tors network traffi c to obtain useful information.
occurred. social engineering A practice in which an
signature In intrusion detection, a pattern of attacker tricks someone into performing some task
behavior associated with an attack. for the attacker (such as sending the attacker confi -
dential information).
simple subject In Windows 10 security, a sub-
ject that manages a user-initiated program’s socket An endpoint for communication. An
permissions. interface for network I/O.G-34 Glossary
soft affi nity An operating system’s policy of spoof The imitation of a legitimate identifi er
attempting to keep a process running on the same (such as an IP address) by an illegitimate user or
processor but not guaranteeing that it will do so. system.
soft error An error that is recoverable by retrying spool A buffer that holds output for a device
the operation. (such as a printer) that cannot accept interleaved
data streams.
soft real-time systems Systems that provide no
guarantee as to when a critical real-time thread will springboard The iOS touch-screen interface.
be scheduled; they guarantee only that the thread spyware A Trojan horse variation in which the
will be given preference over noncritical threads
installed malware gathers information about a
Software as a Service (SaaS) A type of comput- person or organization.
ing in which one or more applications (such as
stack A sequentially ordered data structure that
word processors or spreadsheets) are available as
uses the last-in, fi rst-out (LIFO) principle for add-
a service via the Internet.
ing and removing items; the last item placed onto
software engineering A fi eld of study and a career a stack is the fi rst item removed.
involving writing software (i.e., programming.)
stack algorithm A class of page-replacement
software interrupt A software-generated inter- algorithms that do not suffer from Belady’s anomaly.
rupt; also called a trap. The interrupt can be caused stack inspection In Java, a protection procedure
either by an error (e.g., division by zero or invalid
in which a calling sequence is checked to ensure
memory access) or by a specifi c request from a
that some caller in the sequence has been granted
user program that an operating-system service be
access to the resource called.
performed.
stack section The section of process memory that
software objects The software components that
contains the stack; it contains activation records
make up a computer or device (fi les, programs,
and other temporary data.
semaphores, etc.).
stall A CPU state occurring when the CPU is
software transactional memory (STM) Transac-
waiting for data from main memory and must
tional memory implemented exclusively in soft-
delay execution.
ware; no special hardware is needed.
starvation The situation in which a process or
Solaris A UNIX derivative that is the main oper-
thread waits indefi nitely within a semaphore.
ating system of Sun Microsystems (now owned
Also, a scheduling risk in which a thread that is
by Oracle Corporation). There is an active open
ready to run is never put onto the CPU due to the
source version called Illumos.
scheduling algorithm; it is starved for CPU time.
Solaris ZFS An advanced fi le system, fi rst
state The condition of a process, including its
included as part of Solaris.
current activity as well as its associated memory
solid-state disk A disk-drive-like storage device and disk contents.
that uses fl ash-memory-based nonvolatile memory.
state information In remote fi le systems, the
source fi le A fi le containing the source code of a set of information pertaining to connections
program. and ongoing fi le operations (e.g., which fi les are
open).
space sharing A feature of APFS in which storage
is treated as a pool and space is shared among the state restore Copying a process’s context from its
fi le systems created in that pool (much like ZFS). saved location to the CPU registers in preparation
for continuing the process’s execution.
SPARC A proprietary RISC CPU created by Sun
Microsystems and now owned by Oracle Corpora- state save Copying a process’s context to save its
tion. There is an active open source version called state in order to pause its execution in preparation
OpenSPARC. for putting another process on the CPU.
sparse In memory management, a term describ- stateless In remote fi le systems, a protocol in
ing a page table that has noncontiguous, scattered which state need not be maintained for proper
entries. A sparse address space has many holes. operation.
spinlock A locking mechanism that continuously static linking Linking in which system libraries
uses the CPU while waiting for access to the lock. are treated like other object modules and com-
bined by the loader into a binary program image.
split-screen Running multiple foreground pro-
cesses (e.g., on an iPad) but splitting the screen status register A device I/O register in which
among the processes. status is indicated.Glossary G-35
storage-area network (SAN) A local-area storage symmetric encryption algorithm A cryptogra-
network allowing multiple computers to connect phy algorithm in which the same keys are used to
to one or more storage devices. encrypt and decrypt the message or data.
stream cipher A cipher that encrypts or decrypts symmetric multiprocessing (SMP) Multipro-
a stream of bits or bytes (rather than a block). cessing in which each processor performs all tasks,
including operating-system tasks and user pro-
stream head The interface between STREAMS
cesses. Also, a multiprocessor scheduling method
and user processes.
in which each processor is self-scheduling and
stream modules In STREAMS, modules of func- may run kernel threads or user-level threads.
tionality loadable into a STREAM.
synchronous In interprocess communication,
STREAMS A UNIX I/O feature allowing the a mode of communication in which the sending
dynamic assembly of pipelines of driver code. process is blocked until the message is received
stub A small, temporary place-holder function by the receiving process or by a mailbox and the
replaced by the full function once its expected receiver blocks until a message is available. In
behavior is known. I/O, a request that does not return until the I/O
completes.
subject In Windows 10 security, an entity used to
synchronous threading Threading in which a
track and manage user permissions.
parent thread creating one or more child threads
subsystem A subset of an operating system waits for them to terminate before it resumes.
responsible for a specifi c function (e.g., memory
synchronous writes Writes that are stored in the
management).
order in which they were issued, are not buffered,
SunOS The predecessor of Solaris by Sun and have requesting threads wait for the writes to
Microsystems Inc. complete before continuing.
superblock The UFS volume control block. system administrators Computer users that con-
superblock object The VFS representation of the fi gure, monitor, and manage systems.
entire fi le system. system build Creation of an operating-system
build and confi guration for a specifi c computer
supervisor mode A CPU mode in which all
site.
instructions are enabled. The kernel runs in this
mode. See also user mode. system call Software-triggered interrupt allow-
ing a process to request a kernel service.
SuSE A popular Linux distribution.
system call The primary interface between
suspend In virtualization, to freeze a guest
processes and the operating system, providing a
operating system and its applications to pause
means to invoke services made available by the
execution.
operating system.
swap map In Linux swap-space management, a
system-call fi ltering An operating-system facil-
part of the data structure tracking swap-space use.
ity to limit which system calls can be executed by
swap space Secondary storage backing-store a process.
space used to store pages that are paged out of
system daemon A service that is provided out-
memory.
side the kernel by system programs that are loaded
swapped Moved between main memory and a into memory at boot time and run continuously.
backing store. A process may be swapped out to system disk A storage device that has a boot par-
free main memory temporarily and then swapped tition and can store an operating system and other
back in to continue execution. information for booting the computer.
swapping Moving a process between main system integrity protection (SIP) A feature of
memory and a backing store. A process may be macOS 10.11 and later versions that uses extended
swapped out to free main memory temporarily fi le attributes to mark system fi les as restricted so
and then swapped back in to continue execution. that even the root user cannot tamper with them.
swap-space management The low-level operating- system mode A CPU mode in which all instruc-
system task of managing space on secondary stor- tions are enabled. The kernel runs in this mode.
age for use in swapping and paging. See also user mode.
symmetric clustering A situation in which two system process A service that is provided out-
or more hosts are running applications and are side the kernel by system programs that are loaded
monitoring each other. into memory at boot time and run continuously. InG-36 Glossary
Windows, a process that serves as the container of task A process, a thread activity, or, generally, a
all internal kernel worker threads and other sys- unit of computation on a computer.
tem threads created by drivers for polling, house- templating In virtualization, using one standard
keeping, and other background work.
virtual-machine image as a source for multiple vir-
system program A program associated with the tual machines.
operating system but not necessarily part of the terabyte (TB) 1,024^4 bytes.
kernel.
terminal concentrator A type of front-end pro-
system resource-allocation graph A directed cessor for terminals.
graph for precise description of deadlocks.
tertiary storage A type of storage that is slower
system restore point In Windows, a copy of the and cheaper than main memory or secondary stor-
system hives taken before any signifi cant change is age; frequently magnetic tape or optical disk.
made to system confi guration.
text fi le A type of fi le containing text (alphanu-
system service A collection of applications meric characters).
included with or added to an operating system
text section The executable code of a program or
to provide services beyond those provided by the
process.
kernel.
thin client A limited computer (terminal) used
system utility A collection of applications
for web-based computing.
included with or added to an operating system to
provide services beyond what are provided by the third extended fi le system (ext3) In Linux, a cur-
kernel. rent version of the extended fi le system; the suc-
cessor to ext2.
system-call fi rewall A fi rewall within a com-
thrashing Paging memory at a high rate. A sys-
puter that limits the system calls a process can
tem thrashes when there is insuffi cient physical
trigger.
memory to meet virtual memory demand.
system-call interface An interface that serves
thread A process control structure that is an
as the link to system calls made available by the
execution location. A process with a single thread
operating system and that is called by processes to
executes only one task at a time, while a multi-
invoke system calls.
threaded process can execute a task per thread.
system-contention scope (SCS) A thread-
thread cancellation Termination of a thread
scheduling method in which kernel-level threads
before it has completed.
are scheduled onto a CPU regardless of which pro-
cess they are associated with (and thus contend thread dump In Java, a snapshot of the state of
with all other threads on the system for CPU time). all threads in an application; a useful debugging
tool for deadlocks.
system-development time The time during
which an operating system is developed, before it thread library A programming library that pro-
is made available in fi nal “release” form. vides programmers with an API for creating and
managing threads.
system-wide open-fi le table A kernel in-memory
data structure containing a copy of the FCB of each thread pool A number of threads created at pro-
open fi le, as well as other information. cess startup and placed in a pool, where they sit
and wait for work.
target latency In the Completely Fair Scheduler,
a confi gurable variable which is the interval of thread-environment block (TEB) In Win32, a
time during which every runnable task should run user-mode threads data structure that contains
at least once. numerous per-thread fi elds.
targeted latency An interval of time during thread-local storage (TLS) Data available only to
which every runnable thread should run at least a given thread.
once. threat The potential for a security violation.
task control block A per-process kernel data throughput Generally, the amount of work done
structure containing many pieces of information over time. In scheduling, the number of threads
associated with the process. completed per unit time.
task parallelism A computing method that dis- tightly coupled systems Systems with two or
tributes tasks (threads) across multiple comput- more processors in close communication, sharing
ing cores, with each task is performing a unique the computer bus and sometimes the clock, mem-
operation. ory, and peripheral devices.Glossary G-37
time quantum A small unit of time used by transmission control protocol/Internet protocol
scheduling algorithms as a basis for determining (TCP/IP) The most common network protocol;
when to preempt a thread from the CPU to allow it provides the fundamental architecture of the
another to run. Internet.
time sharing A practice in which the CPU exe- transparent In distributed computing, a term
cutes multiple jobs by switching among them, but describing the automatic sharing of resources so that
the switches occur so frequently that the users can users do not know if a resource is local or remote.
interact with the processes. transport driver interface (TDI) In Windows
time slice A small unit of time used by scheduling networking, an interface that supports connect-
algorithms as a basis for determining when to pre- based and connectionless transports on top of the
empt a thread from the CPU to allow another to run. transport layer.
timer A hardware component that can be set to transport layer security (TLS) A cryptographic
interrupt the computer after a specifi ed period. protocol that enables two computers to communi-
cate securely; the standard protocol by which web
timestamp counter (TSC) In Windows Vista, a
browsers communicate to web servers.
counter that tracks execution time.
trap A software interrupt. The interrupt can be
TLB miss A translation look-aside buffer lookup
caused either by an error (e.g., division by zero or
that fails to provide the address translation because
invalid memory access) or by a specifi c request
it is not in the TLB.
from a user program that an operating-system ser-
TLB reach The amount of memory addressable
vice be performed.
by the translation look-aside buffer.
trap door A back-door daemon left behind after a
TLB walk The steps involved in walking through
successful attack to allow continued access by the
page-table structures to locate the needed transla-
attacker.
tion and then copying that result into the TLB.
trap-and-emulate In virtualization, a method
touch screen A touch-sensitive screen used as a
used to implement virtualization on systems lack-
computer input device.
ing hardware support (such as CPU instructions)
touch-screen interface A user interface in which for virtualization; any action that would cause the
touching a screen allows the user to interact with guest to call the operating system is intercepted,
the computer. and the result is emulated.
trace tapes A tool used in the evaluation of tree A data structure that can be used to repre-
scheduling algorithms. Thread details are cap- sent data hierarchically; data values in a tree struc-
tured on real systems, and various algorithms are ture are linked through parent–child relationships.
analyzed to determine their effectiveness.
triple DES A modifi cation of DES that uses the
track On an HDD platter, the medium that is same algorithm three times and uses two or three
under the read-write head during a rotation of the keys to make the encryption more diffi cult to
platter. break.
transaction Generally, the execution of a set triple indirect block In UFS, a block containing
of steps that make up one activity. In log-based pointers to double indirect blocks, which point to
transaction-oriented fi le systems, a set of opera- single indirect blocks, which point to data blocks.
tions completed as part of a request (e.g., “write
Trojan horse A program that acts in a clandes-
this block to that fi le”).
tine or malicious manner rather than simply per-
transactional memory A type of memory sup- forming its stated function.
porting memory transactions.
TrustZone (TZ) ARM processor implementation
transfer rate The rate at which data fl ows. of the most secure protection ring.
translation granules Features of ARM v8 CPUs tunnel In computer communication, a container
that defi ne page sizes and regions. of communications within another type of com-
translation look-aside buffer (TLB) A small, munication (e.g., a VPN that allows web traffi c).
fast-lookup hardware cache used in paged mem- turnstile A Solaris scheduling feature using a
ory address translation to provide fast access to a queue structure containing threads blocked on a
subset of memory addresses. lock.
translation table base register ARM v8 CPU reg- two-factor authentication Authentication based
ister pointing to the level 0 (outer) page table for on two separate sources of data (e.g., a brain provid-
the current thread. ing a password and a fi nger providing a fi ngerprint).G-38 Glossary
type 0 hypervisor A hardware-based virtual- upcall A threading method in which the kernel
ization solution that provides support for virtual sends a signal to a process thread to communicate
machine creation and management via fi rmware an event.
(e.g., IBM LPARs and Oracle LDOMs). upcall handler A function in a process that han-
type 1 hypervisor Operating-system-like soft- dles upcalls.
ware built to provide virtualization (e.g., VMware
USB drive Nonvolatile memory in the form of a
ESX, Joyent SmartOS and Citrix Xenserver).
device that plugs into a USB port.
type 2 hypervisor An application that runs on
user The human using a computer, or the identi-
standard operating systems but provides virtual
fi cation of the human to the computer.
machine management features to guest operating
user account In Windows 10, an account belong-
systems (e.g., VMware workstation and fusion,
ing to a user (rather than a system account used by
and Oracle Virtualbox)
the computer).
type safety In Java, a feature that ensures that
user authentication The identifi cation of a user
classes cannot treat integers as pointers, write past
of a computer.
the end of an array, or otherwise access memory in
arbitrary ways. user datagram protocol (UDP) A communica-
tions protocol layered on IP that is connectionless,
unbounded buffer A buffer with no practical
is low latency, and does not guarantee delivery.
limit on its memory size.
user experience layer In the layered macOS and
uncontended A term describing a lock that is
iOS operating system design, the layer that defi nes
available when a thread attempts to acquire it.
the software interface that allows users to interact
unifi ed buffer cache In fi le I/O, a cache used for
with computing devices.
both memory-mapped I/O and direct fi le I/O.
user fi le directory (UFD) In two-level directory
unifi ed extensible fi rmware interface (UEFI) The
implementation, a per-user directory of fi les.
modern replacement for BIOS containing a com-
plete boot manager. user identifi er (user ID) (UID) A unique numer-
ical user identifi er.
unifi ed virtual memory In fi le I/O, the use of
page caching for all types of I/O (explicit fi le sys- user interface (UI) A method by which a user
tem I/O and page fault I/O). interacts with a computer.
uniform memory access (UMA) Access to all main user mode A CPU mode for executing user pro-
memory by all processors, without performance dif- cesses in which some instructions are limited or
ferences based on CPU or memory location. not allowed. See also kernel mode.
uniform naming convention (UNC) A name user programs User-level programs, as opposed
format that includes the system and its resources to system programs.
(e.g.m \\server_name\share_name\x\y\z). user rights Permissions granted to users.
unikernels Specialized machine images that user thread A thread running in user mode.
contain both an operating system and applications
user-defi ned signal handler The signal handler
for effi cient execution and increased security.
created by a process to provide non-default signal
universal serial bus (USB) A type of I/O bus. handling.
universal Windows platform (UWP) Windows user-initiated In the Grand Central Dispatch
10 architecture that provides a common app plat- Apple OS scheduler, the scheduling class repre-
form for all devices that run it, including mobile senting tasks that interact with the user but need
devices. longer processing times than user-interactive tasks.
UNIX fi le system (UFS) An early UNIX fi le sys- user-interactive In the Grand Central Dispatch
tems; uses inodes for FCB. Apple OS scheduler, the scheduling class repre-
UnixBSD A UNIX derivative based on work done senting tasks that interact with the user.
at the University of California at Berkeley (UCB). user-mode driver framework (UMDF) A frame-
unnamed semaphore A POSIX scheduling con- work in Windows to facilitate the writing of user-
struct that can only be used by threads in the same mode device drivers.
process. user-mode scheduling (UMS) A Microsoft Win-
unstructured data Data that are not in a fi xed dows 7 feature that allows applications to create
format (like a database record) but rather are free- and manage threads independently of the kernel.
form (like a twitter.com tweet). This feature supports task-based parallelism byGlossary G-39
decomposing processes into tasks, which are then physical computer. Multiple virtual machines can
scheduled on available CPUs; it is used on AMD64 run on a single physical machine (and each can
systems. have a different operating system).
user-mode thread (UT) In Windows, the state of virtual machine control structures (VMCSs)
a thread when it is running in user mode. Hardware features provided by CPUs that support
utility In the Grand Central Dispatch Apple OS virtualization to track guest state.
scheduler, the scheduling class representing tasks virtual machine manager (VMM) The computer
that require a longer time to complete but do not function that manages the virtual machine; also
demand immediate results. called a hypervisor.
utility storage An inServ feature in which stor- virtual machine sprawl The situation in which
age space can be increased as needed. there are so many virtual machines on a system
valid-invalid A page-table bit indicating that their use, history, and state become confusing
whether a page-table entry points to a page within and diffi cult to track; caused by the ease of creating
the logical address space of that process. virtual machines.
variable-partition A simple memory-allocation virtual memory A technique that allows the exe-
scheme in which each partition of memory con- cution of a process that is not completely in memory.
tains exactly one process. Also, separation of computer memory address
space from physical into logical, allowing easier
vectored I/O An I/O method in which multiple
programming and larger name space.
sources or destinations of I/O are specifi ed in one
command structure. virtual memory fork The vfork() system call,
which forks a child process, suspends the parent,
version control system Software that manages
and lets the child share the parent’s address space
software distributions by allowing contributors to
for both read and write operations (changes are
“push” changes into a repository and “pull” a ver-
visible to the parent).
sion of the software source-code tree to a system
(e.g., for compilation). virtual private network (VPN) An encrypted
tunnel between two systems, commonly using
victim frame In virtual memory, the frame
IPSec, allowing secure remote access.
selected by the page-replacement algorithm to be
replaced. virtual run time A Linux scheduling aspect that
records how long each task has run by maintaining
view In Windows, an address range mapped in
the virtual run time of each task.
shared memory. Also, the second step in memory-
mapping a fi le, allowing a process to access the fi le virtual trust level (VTL) A Windows 10 virtual-
contents. ization feature using Hyper-V to add more secure
system modes.
virtual address An address generated by the
CPU; must be translated to a physical address virtualization A technology for abstracting the
before it is used. hardware of a single computer into several differ-
ent execution environments, thereby creating the
virtual address control block (VACB) The data
illusion that each environment is running on its
structure in Windows that represents a cache block
own private computer.
in the unifi ed I/O cache.
virtual-to-physical (V-to-P) In virtualization, the
virtual address descriptor (VAD) In Windows, a
conversion of a virtual machine guest to a physical
per-process descriptor of a virtual address range,
system’s operating system and applications.
kept in a tree data structure.
virus A fragment of code embedded in a legiti-
virtual address space The logical view of how a
mate program that, when executed, can replicate
process is stored in memory.
itself; may modify or destroy fi les and cause sys-
virtual CPU (VCPU) In virtualization, a virtual- tem crashes and program malfunctions.
ized host CPU available to allocate to a guest oper-
virus dropper The part of a virus that inserts the
ating system by the virtual machine manager.
virus into the system.
virtual fi le system (VFS) The fi le-system imple-
virus signature A pattern that can be used to
mentation layer responsible for separating fi le-
identify a virus within a system.
system-generic operations and their implementation
and representing a fi le throughout a network VMware Virtualization software company.
virtual machine (VM) The abstraction of hard- VMware Workstation A popular commercial
ware allowing a virtual computer to execute on a type 2 hypervisor for x86 Windows systems.G-40 Glossary
vnode The virtual fi le system fi le representa- Winsock The Windows socket API (similar to
tion structure, similar to the FCB for local fi les but BSD sockets) for network communications.
applied to remote fi les. wired down A term describing a TLB entry that
voice recognition A computer interface based is locked into the TLB and not replaceable by the
on spoken commands, which the computer parses usual replacement algorithm.
and turns into actions.
wireless network A communication network
volatile Describes storage whose content can be composed of radio signals rather than physical
lost in a power outage or similar event. wires.
volatile storage Storage whose content can be witness A lock order verifi er.
lost in a power outage or similar event.
word A unit made up of one or more bytes. For
volume A container of storage; frequently, a device example, a computer that has 64-bit registers and
containing a mountable fi le system (including a fi le 64-bit memory addressing typically has 64-bit
containing an image of the contents of a device). (8-byte) words.
volume control block A per-volume storage working set The set of pages in the most recent
block containing data describing the volume. page references.
von Neumann architecture The structure of most working-set maximum The maximum number
computers, in which both process instructions and of frames allowed to a process in Windows.
data are stored in the same main memory.
working-set minimum The minimum number
VT-x Intel x86 CPU virtualization-supporting of frames guaranteed to a process in Windows.
instructions.
working-set model A model of memory access
wait queue In process scheduling, a queue hold- based on tracking the set of most recently accessed
ing processes waiting for an event to occur before pages.
they need to be put on CPU.
working-set window A limited set of most
wait set In Java, a set of threads, each waiting for recently accessed pages (a “window” view of the
a condition that will allow it to continue. entire set of accessed pages).
wait-for graph In deadlock detection, a variant workstation A powerful personal computer (PC)
of the resource-allocation graph with resource for engineering and other demanding workloads.
nodes removed; indicates a deadlock if the graph
world rights A category of fi le access rights.
contains a cycle
World Wide Web (WWW) The Internet; a
wear leveling In nonvolatile memory, the effort
worldwide system of interconnected computer
to select all NAND cells over time as write targets
networks.
to avoid premature media failure due to wearing
out a subset of cells. WORM Write-once, read-many-times storage.
wide-area network (WAN) A network that links worm A program that spreads malware between
buildings, cities, or countries. computers without intervention from humans.
WiFi Wireless networking, consisting of devices worst-fi t In memory allocation, selecting the
and protocols that allow devices to attach to a net- largest hole available.
work via radio waves rather than cables. write amplifi cation The creation of I/O requests
Win32 API The fundamental interface to the not by applications but by NVM devices doing
capabilities of Windows. garbage collection and space management, poten-
tially impacting the devices’ write performance.
Windows 10 A release of Microsoft Windows
from 2009. write pointer The location in a fi le to which the
next write will occur.
Windows group policy In Windows, a policy
providing centralized management and confi gura- write-anywhere fi le layout (WAFL) The fi le sys-
tion of operating systems, applications, and user tem that is the heart of the NetApp, Inc., storage
settings in an Active Directory environment. appliances.
Windows Subsystem for Linux (WSL) A Win- write-back caching In caching, a policy whereby
dows 10 component allowing native Linux appli- data are fi rst written to the cache; later, the cache
cations (ELF binaries) to run on Windows. writes the change to the master copy of the data.
Windows XP A widely popular version of Mic- write-on-close policy In caching, a policy
rosoft Windows released in 2001. whereby writes reside in the cache until the fi le isGlossary G-41
closed and are only then written back to the master zero-fi ll-on-demand The writing of zeros into
copy of the data. a page before it is made available to a process
write-through policy In caching, a policy (to keep any old data from being available to the
process).
whereby writes are not cached but are written
through the cache to the master copy of the data. ZFS Oracle fi le system, created by Sun Microsys-
x86-64 A class of 64-bit CPUs running an iden- tems, with modern algorithms and features and
few limits on fi le and device sizes.
tical instruction set; the most common CPUs in
desktop and server systems. zombie A process that has terminated but whose
Xen Virtualization software company. parent has not yet called wait() to collect its state
and accounting information.
XML fi rewall A fi rewall that examines and limits
zombie systems Compromised systems that
XML traffi c.
are being used by attackers without the owners’
Xtratum An example of a partitioning hypervisor.
knowledge.
yellow pages A distributed naming service that
zones In application containment, a virtual layer
provides username, password, hostname, and
between the operating system and a process in
printer information to a set of computers.
which the application runs, limiting its normal
zero-day attacks Attacks that have not been seen access to system resources. In Linux, the four
before and therefore cannot be detected via their regions of kernel memory.
signatures.WILEY END USER LICENSE
AGREEMENT
Go to www.wiley.com/go/eula to access Wiley’s ebook
EULA.